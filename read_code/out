list print :      (nil) (  0x884040  DKDK_HEAD)   0x884060 
list print :   0x884040 (  0x884060         if)   0x884080 
list print :   0x884060 (  0x884080        for)   0x8840a0 
list print :   0x884080 (  0x8840a0      while)      (nil) 
[ OK ] open : 3 ok... 
file : ./test/kernel/fs/afs/main.c 
[ OK ] open : 4 ok... 
buf : /* AFS client file system
buf :  *
buf :  * Copyright (C) 2002,5 Red Hat, Inc. All Rights Reserved.
buf :  * Written by David Howells (dhowells@redhat.com)
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of the GNU General Public License
ify it under the terms of the GNU General Public License 
buf :  * as published by the Free Software Foundation; either version
buf :  * 2 of the License, or (at your option) any later version.
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/moduleparam.h>
buf : #include <linux/init.h>
buf : #include <linux/completion.h>
buf : #include <linux/sched.h>
buf : #include "internal.h"
buf : 
buf : MODULE_DESCRIPTION("AFS Client File System");
buf : MODULE_AUTHOR("Red Hat, Inc.");
buf : MODULE_LICENSE("GPL");
buf : 
buf : unsigned afs_debug;
buf : module_param_named(debug, afs_debug, uint, S_IWUSR | S_IRUGO);
buf : MODULE_PARM_DESC(debug, "AFS debugging mask");
buf : 
buf : static char *rootcell;
buf : 
buf : module_param(rootcell, charp, 0);
buf : MODULE_PARM_DESC(rootcell, "root AFS cell name and VL server IP addr list");
buf : 
buf : struct afs_uuid afs_uuid;
buf : struct workqueue_struct *afs_wq;
buf : 
buf : /*
buf :  * get a client UUID
buf :  */
buf : static int __init afs_get_client_UUID(void)
buf : {
buf : 	struct timespec ts;
buf : 	u64 uuidtime;
buf : 	u16 clockseq;
buf : 	int ret;
buf : 
buf : 	/* read the MAC address of one of the external interfaces and construct
buf : 	 * a UUID from it */
buf : 	ret = afs_get_MAC_address(afs_uuid.node, sizeof(afs_uuid.node));
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	getnstimeofday(&ts);
buf : 	uuidtime = (u64) ts.tv_sec * 1000 * 1000 * 10;
buf : 	uuidtime += ts.tv_nsec / 100;
buf : 	uuidtime += AFS_UUID_TO_UNIX_TIME;
buf : 	afs_uuid.time_low = uuidtime;
buf : 	afs_uuid.time_mid = uuidtime >> 32;
buf : 	afs_uuid.time_hi_and_version = (uuidtime >> 48) & AFS_UUID_TIMEHI_MASK;
buf : 	afs_uuid.time_hi_and_version = AFS_UUID_VERSION_TIME;
buf : 
buf : 	get_random_bytes(&clockseq, 2);
buf : 	afs_uuid.clock_seq_low = clockseq;
buf : 	afs_uuid.clock_seq_hi_and_reserved =
buf : 		(clockseq >> 8) & AFS_UUID_CLOCKHI_MASK;
buf : 	afs_uuid.clock_seq_hi_and_reserved = AFS_UUID_VARIANT_STD;
buf : 
buf : 	_debug("AFS UUID: %08x-%04x-%04x-%02x%02x-%02x%02x%02x%02x%02x%02x",
buf : 	       afs_uuid.time_low,
buf : 	       afs_uuid.time_mid,
buf : 	       afs_uuid.time_hi_and_version,
buf : 	       afs_uuid.clock_seq_hi_and_reserved,
buf : 	       afs_uuid.clock_seq_low,
buf : 	       afs_uuid.node[0], afs_uuid.node[1], afs_uuid.node[2],
buf : 	       afs_uuid.node[3], afs_uuid.node[4], afs_uuid.node[5]);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * initialise the AFS client FS module
buf :  */
buf : static int __init afs_init(void)
buf : {
buf : 	int ret;
buf : 
buf : 	printk(KERN_INFO "kAFS: Red Hat AFS client v0.1 registering.\n");
buf : 
buf : 	ret = afs_get_client_UUID();
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	/* create workqueue */
buf : 	ret = -ENOMEM;
buf : 	afs_wq = alloc_workqueue("afs", 0, 0);
buf : 	if (!afs_wq)
if (!afs_wq) 
buf : 		return ret;
buf : 
buf : 	/* register the /proc stuff */
buf : 	ret = afs_proc_init();
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_proc;
buf : 
buf : #ifdef CONFIG_AFS_FSCACHE
ifdef CONFIG_AFS_FSCACHE 
buf : 	/* we want to be able to cache */
buf : 	ret = fscache_register_netfs(&afs_cache_netfs);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_cache;
buf : #endif
if 
buf : 
buf : 	/* initialise the cell DB */
buf : 	ret = afs_cell_init(rootcell);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_cell_init;
buf : 
buf : 	/* initialise the VL update process */
buf : 	ret = afs_vlocation_update_init();
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_vl_update_init;
buf : 
buf : 	/* initialise the callback update process */
buf : 	ret = afs_callback_update_init();
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_callback_update_init;
buf : 
buf : 	/* create the RxRPC transport */
buf : 	ret = afs_open_socket();
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_open_socket;
buf : 
buf : 	/* register the filesystems */
buf : 	ret = afs_fs_init();
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_fs;
buf : 
buf : 	return ret;
buf : 
buf : error_fs:
buf : 	afs_close_socket();
buf : error_open_socket:
buf : 	afs_callback_update_kill();
buf : error_callback_update_init:
buf : 	afs_vlocation_purge();
buf : error_vl_update_init:
buf : 	afs_cell_purge();
buf : error_cell_init:
buf : #ifdef CONFIG_AFS_FSCACHE
ifdef CONFIG_AFS_FSCACHE 
buf : 	fscache_unregister_netfs(&afs_cache_netfs);
buf : error_cache:
buf : #endif
if 
buf : 	afs_proc_cleanup();
buf : error_proc:
buf : 	destroy_workqueue(afs_wq);
buf : 	rcu_barrier();
buf : 	printk(KERN_ERR "kAFS: failed to register: %d\n", ret);
buf : 	return ret;
buf : }
buf : 
buf : /* XXX late_initcall is kludgy, but the only alternative seems to create
buf :  * a transport upon the first mount, which is worse. Or is it?
buf :  */
buf : late_initcall(afs_init);	/* must be called after net/ to create socket */
buf : 
buf : /*
buf :  * clean up on module removal
buf :  */
buf : static void __exit afs_exit(void)
buf : {
buf : 	printk(KERN_INFO "kAFS: Red Hat AFS client v0.1 unregistering.\n");
buf : 
buf : 	afs_fs_exit();
buf : 	afs_kill_lock_manager();
buf : 	afs_close_socket();
buf : 	afs_purge_servers();
buf : 	afs_callback_update_kill();
buf : 	afs_vlocation_purge();
buf : 	destroy_workqueue(afs_wq);
buf : 	afs_cell_purge();
buf : #ifdef CONFIG_AFS_FSCACHE
ifdef CONFIG_AFS_FSCACHE 
buf : 	fscache_unregister_netfs(&afs_cache_netfs);
buf : #endif
if 
buf : 	afs_proc_cleanup();
buf : 	rcu_barrier();
buf : }
buf : 
buf : module_exit(afs_exit);
file : ./test/kernel/fs/dlm/main.c 
[ OK ] open : 4 ok... 
buf : /******************************************************************************
buf : *******************************************************************************
buf : **
buf : **  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
buf : **  Copyright (C) 2004-2007 Red Hat, Inc.  All rights reserved.
buf : **
buf : **  This copyrighted material is made available to anyone wishing to use,
buf : **  modify, copy, or redistribute it subject to the terms and conditions
ify, copy, or redistribute it subject to the terms and conditions 
buf : **  of the GNU General Public License v.2.
buf : **
buf : *******************************************************************************
buf : ******************************************************************************/
buf : 
buf : #include "dlm_internal.h"
buf : #include "lockspace.h"
buf : #include "lock.h"
buf : #include "user.h"
buf : #include "memory.h"
buf : #include "config.h"
buf : #include "lowcomms.h"
buf : 
buf : static int __init init_dlm(void)
buf : {
buf : 	int error;
buf : 
buf : 	error = dlm_memory_init();
buf : 	if (error)
if (error) 
buf : 		goto out;
buf : 
buf : 	error = dlm_lockspace_init();
buf : 	if (error)
if (error) 
buf : 		goto out_mem;
buf : 
buf : 	error = dlm_config_init();
buf : 	if (error)
if (error) 
buf : 		goto out_lockspace;
buf : 
buf : 	error = dlm_register_debugfs();
buf : 	if (error)
if (error) 
buf : 		goto out_config;
buf : 
buf : 	error = dlm_user_init();
buf : 	if (error)
if (error) 
buf : 		goto out_debug;
buf : 
buf : 	error = dlm_netlink_init();
buf : 	if (error)
if (error) 
buf : 		goto out_user;
buf : 
buf : 	error = dlm_plock_init();
buf : 	if (error)
if (error) 
buf : 		goto out_netlink;
buf : 
buf : 	printk("DLM installed\n");
buf : 
buf : 	return 0;
buf : 
buf :  out_netlink:
buf : 	dlm_netlink_exit();
buf :  out_user:
buf : 	dlm_user_exit();
buf :  out_debug:
buf : 	dlm_unregister_debugfs();
buf :  out_config:
buf : 	dlm_config_exit();
buf :  out_lockspace:
buf : 	dlm_lockspace_exit();
buf :  out_mem:
buf : 	dlm_memory_exit();
buf :  out:
buf : 	return error;
buf : }
buf : 
buf : static void __exit exit_dlm(void)
buf : {
buf : 	dlm_plock_exit();
buf : 	dlm_netlink_exit();
buf : 	dlm_user_exit();
buf : 	dlm_config_exit();
buf : 	dlm_memory_exit();
buf : 	dlm_lockspace_exit();
buf : 	dlm_lowcomms_exit();
buf : 	dlm_unregister_debugfs();
buf : }
buf : 
buf : module_init(init_dlm);
buf : module_exit(exit_dlm);
buf : 
buf : MODULE_DESCRIPTION("Distributed Lock Manager");
buf : MODULE_AUTHOR("Red Hat, Inc.");
buf : MODULE_LICENSE("GPL");
buf : 
buf : EXPORT_SYMBOL_GPL(dlm_new_lockspace);
buf : EXPORT_SYMBOL_GPL(dlm_release_lockspace);
buf : EXPORT_SYMBOL_GPL(dlm_lock);
buf : EXPORT_SYMBOL_GPL(dlm_unlock);
buf : 
file : ./test/kernel/fs/cachefiles/main.c 
[ OK ] open : 4 ok... 
buf : /* Network filesystem caching backend to use cache files on a premounted
buf :  * filesystem
buf :  *
buf :  * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
buf :  * Written by David Howells (dhowells@redhat.com)
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of the GNU General Public Licence
ify it under the terms of the GNU General Public Licence 
buf :  * as published by the Free Software Foundation; either version
buf :  * 2 of the Licence, or (at your option) any later version.
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/init.h>
buf : #include <linux/sched.h>
buf : #include <linux/completion.h>
buf : #include <linux/slab.h>
buf : #include <linux/fs.h>
buf : #include <linux/file.h>
buf : #include <linux/namei.h>
buf : #include <linux/mount.h>
buf : #include <linux/statfs.h>
buf : #include <linux/sysctl.h>
buf : #include <linux/miscdevice.h>
buf : #include "internal.h"
buf : 
buf : unsigned cachefiles_debug;
buf : module_param_named(debug, cachefiles_debug, uint, S_IWUSR | S_IRUGO);
buf : MODULE_PARM_DESC(cachefiles_debug, "CacheFiles debugging mask");
buf : 
buf : MODULE_DESCRIPTION("Mounted-filesystem based cache");
buf : MODULE_AUTHOR("Red Hat, Inc.");
buf : MODULE_LICENSE("GPL");
buf : 
buf : struct kmem_cache *cachefiles_object_jar;
buf : 
buf : static struct miscdevice cachefiles_dev = {
buf : 	.minor	= MISC_DYNAMIC_MINOR,
buf : 	.name	= "cachefiles",
buf : 	.fops	= &cachefiles_daemon_fops,
buf : };
buf : 
buf : static void cachefiles_object_init_once(void *_object)
buf : {
buf : 	struct cachefiles_object *object = _object;
buf : 
buf : 	memset(object, 0, sizeof(*object));
buf : 	spin_lock_init(&object->work_lock);
buf : }
buf : 
buf : /*
buf :  * initialise the fs caching module
buf :  */
buf : static int __init cachefiles_init(void)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = misc_register(&cachefiles_dev);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_dev;
buf : 
buf : 	/* create an object jar */
buf : 	ret = -ENOMEM;
buf : 	cachefiles_object_jar =
buf : 		kmem_cache_create("cachefiles_object_jar",
buf : 				  sizeof(struct cachefiles_object),
buf : 				  0,
buf : 				  SLAB_HWCACHE_ALIGN,
buf : 				  cachefiles_object_init_once);
buf : 	if (!cachefiles_object_jar) {
if (!cachefiles_object_jar) { 
buf : 		pr_notice("Failed to allocate an object jar\n");
buf : 		goto error_object_jar;
buf : 	}
buf : 
buf : 	ret = cachefiles_proc_init();
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_proc;
buf : 
buf : 	pr_info("Loaded\n");
buf : 	return 0;
buf : 
buf : error_proc:
buf : 	kmem_cache_destroy(cachefiles_object_jar);
buf : error_object_jar:
buf : 	misc_deregister(&cachefiles_dev);
buf : error_dev:
buf : 	pr_err("failed to register: %d", ret);
buf : 	return ret;
buf : }
buf : 
buf : fs_initcall(cachefiles_init);
buf : 
buf : /*
buf :  * clean up on module removal
buf :  */
buf : static void __exit cachefiles_exit(void)
buf : {
buf : 	pr_info("Unloading\n");
buf : 
buf : 	cachefiles_proc_cleanup();
buf : 	kmem_cache_destroy(cachefiles_object_jar);
buf : 	misc_deregister(&cachefiles_dev);
buf : }
buf : 
buf : module_exit(cachefiles_exit);
file : ./test/kernel/fs/ecryptfs/main.c 
[ OK ] open : 4 ok... 
buf : /**
buf :  * eCryptfs: Linux filesystem encryption layer
buf :  *
buf :  * Copyright (C) 1997-2003 Erez Zadok
buf :  * Copyright (C) 2001-2003 Stony Brook University
buf :  * Copyright (C) 2004-2007 International Business Machines Corp.
buf :  *   Author(s): Michael A. Halcrow <mahalcro@us.ibm.com>
buf :  *              Michael C. Thompson <mcthomps@us.ibm.com>
buf :  *              Tyler Hicks <tyhicks@ou.edu>
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of the GNU General Public License as
ify it under the terms of the GNU General Public License as 
buf :  * published by the Free Software Foundation; either version 2 of the
buf :  * License, or (at your option) any later version.
buf :  *
buf :  * This program is distributed in the hope that it will be useful, but
buf :  * WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
buf :  * General Public License for more details.
for more details. 
buf :  *
buf :  * You should have received a copy of the GNU General Public License
buf :  * along with this program; if not, write to the Free Software
if not, write to the Free Software 
buf :  * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
buf :  * 02111-1307, USA.
buf :  */
buf : 
buf : #include <linux/dcache.h>
buf : #include <linux/file.h>
buf : #include <linux/module.h>
buf : #include <linux/namei.h>
buf : #include <linux/skbuff.h>
buf : #include <linux/crypto.h>
buf : #include <linux/mount.h>
buf : #include <linux/pagemap.h>
buf : #include <linux/key.h>
buf : #include <linux/parser.h>
buf : #include <linux/fs_stack.h>
buf : #include <linux/slab.h>
buf : #include <linux/magic.h>
buf : #include "ecryptfs_kernel.h"
buf : 
buf : /**
buf :  * Module parameter that defines the ecryptfs_verbosity level.
buf :  */
buf : int ecryptfs_verbosity = 0;
buf : 
buf : module_param(ecryptfs_verbosity, int, 0);
buf : MODULE_PARM_DESC(ecryptfs_verbosity,
buf : 		 "Initial verbosity level (0 or 1; defaults to "
buf : 		 "0, which is Quiet)");
buf : 
buf : /**
buf :  * Module parameter that defines the number of message buffer elements
buf :  */
buf : unsigned int ecryptfs_message_buf_len = ECRYPTFS_DEFAULT_MSG_CTX_ELEMS;
buf : 
buf : module_param(ecryptfs_message_buf_len, uint, 0);
buf : MODULE_PARM_DESC(ecryptfs_message_buf_len,
buf : 		 "Number of message buffer elements");
buf : 
buf : /**
buf :  * Module parameter that defines the maximum guaranteed amount of time to wait
buf :  * for a response from ecryptfsd.  The actual sleep time will be, more than
for a response from ecryptfsd.  The actual sleep time will be, more than 
buf :  * likely, a small amount greater than this specified value, but only less if
buf :  * the message successfully arrives.
buf :  */
buf : signed long ecryptfs_message_wait_timeout = ECRYPTFS_MAX_MSG_CTX_TTL / HZ;
buf : 
buf : module_param(ecryptfs_message_wait_timeout, long, 0);
buf : MODULE_PARM_DESC(ecryptfs_message_wait_timeout,
buf : 		 "Maximum number of seconds that an operation will "
buf : 		 "sleep while waiting for a message response from "
for a message response from " 
buf : 		 "userspace");
buf : 
buf : /**
buf :  * Module parameter that is an estimate of the maximum number of users
buf :  * that will be concurrently using eCryptfs. Set this to the right
buf :  * value to balance performance and memory use.
formance and memory use. 
buf :  */
buf : unsigned int ecryptfs_number_of_users = ECRYPTFS_DEFAULT_NUM_USERS;
buf : 
buf : module_param(ecryptfs_number_of_users, uint, 0);
buf : MODULE_PARM_DESC(ecryptfs_number_of_users, "An estimate of the number of "
buf : 		 "concurrent users of eCryptfs");
buf : 
buf : void __ecryptfs_printk(const char *fmt, ...)
buf : {
buf : 	va_list args;
buf : 	va_start(args, fmt);
buf : 	if (fmt[1] == '7') { /* KERN_DEBUG */
if (fmt[1] == '7') { /* KERN_DEBUG */ 
buf : 		if (ecryptfs_verbosity >= 1)
buf : 			vprintk(fmt, args);
buf : 	} else
buf : 		vprintk(fmt, args);
buf : 	va_end(args);
buf : }
buf : 
buf : /**
buf :  * ecryptfs_init_lower_file
buf :  * @ecryptfs_dentry: Fully initialized eCryptfs dentry object, with
buf :  *                   the lower dentry and the lower mount set
buf :  *
buf :  * eCryptfs only ever keeps a single open file for every lower
for every lower 
buf :  * inode. All I/O operations to the lower inode occur through that
buf :  * file. When the first eCryptfs dentry that interposes with the first
buf :  * lower dentry for that inode is created, this function creates the
for that inode is created, this function creates the 
buf :  * lower file struct and associates it with the eCryptfs
buf :  * inode. When all eCryptfs files associated with the inode are released, the
buf :  * file is closed.
buf :  *
buf :  * The lower file will be opened with read/write permissions, if
if 
buf :  * possible. Otherwise, it is opened read-only.
buf :  *
buf :  * This function does nothing if a lower file is already
if a lower file is already 
buf :  * associated with the eCryptfs inode.
buf :  *
buf :  * Returns zero on success; non-zero otherwise
buf :  */
buf : static int ecryptfs_init_lower_file(struct dentry *dentry,
buf : 				    struct file **lower_file)
buf : {
buf : 	const struct cred *cred = current_cred();
buf : 	struct path *path = ecryptfs_dentry_to_lower_path(dentry);
buf : 	int rc;
buf : 
buf : 	rc = ecryptfs_privileged_open(lower_file, path->dentry, path->mnt,
buf : 				      cred);
buf : 	if (rc) {
if (rc) { 
buf : 		printk(KERN_ERR "Error opening lower file "
buf : 		       "for lower_dentry [0x%p] and lower_mnt [0x%p]; "
for lower_dentry [0x%p] and lower_mnt [0x%p]; " 
buf : 		       "rc = [%d]\n", path->dentry, path->mnt, rc);
buf : 		(*lower_file) = NULL;
buf : 	}
buf : 	return rc;
buf : }
buf : 
buf : int ecryptfs_get_lower_file(struct dentry *dentry, struct inode *inode)
buf : {
buf : 	struct ecryptfs_inode_info *inode_info;
buf : 	int count, rc = 0;
buf : 
buf : 	inode_info = ecryptfs_inode_to_private(inode);
buf : 	mutex_lock(&inode_info->lower_file_mutex);
buf : 	count = atomic_inc_return(&inode_info->lower_file_count);
buf : 	if (WARN_ON_ONCE(count < 1))
if (WARN_ON_ONCE(count < 1)) 
buf : 		rc = -EINVAL;
buf : 	else if (count == 1) {
if (count == 1) { 
buf : 		rc = ecryptfs_init_lower_file(dentry,
buf : 					      &inode_info->lower_file);
buf : 		if (rc)
if (rc) 
buf : 			atomic_set(&inode_info->lower_file_count, 0);
buf : 	}
buf : 	mutex_unlock(&inode_info->lower_file_mutex);
buf : 	return rc;
buf : }
buf : 
buf : void ecryptfs_put_lower_file(struct inode *inode)
buf : {
buf : 	struct ecryptfs_inode_info *inode_info;
buf : 
buf : 	inode_info = ecryptfs_inode_to_private(inode);
buf : 	if (atomic_dec_and_mutex_lock(&inode_info->lower_file_count,
if (atomic_dec_and_mutex_lock(&inode_info->lower_file_count, 
buf : 				      &inode_info->lower_file_mutex)) {
buf : 		filemap_write_and_wait(inode->i_mapping);
buf : 		fput(inode_info->lower_file);
buf : 		inode_info->lower_file = NULL;
buf : 		mutex_unlock(&inode_info->lower_file_mutex);
buf : 	}
buf : }
buf : 
buf : enum { ecryptfs_opt_sig, ecryptfs_opt_ecryptfs_sig,
buf :        ecryptfs_opt_cipher, ecryptfs_opt_ecryptfs_cipher,
buf :        ecryptfs_opt_ecryptfs_key_bytes,
buf :        ecryptfs_opt_passthrough, ecryptfs_opt_xattr_metadata,
buf :        ecryptfs_opt_encrypted_view, ecryptfs_opt_fnek_sig,
buf :        ecryptfs_opt_fn_cipher, ecryptfs_opt_fn_cipher_key_bytes,
buf :        ecryptfs_opt_unlink_sigs, ecryptfs_opt_mount_auth_tok_only,
buf :        ecryptfs_opt_check_dev_ruid,
buf :        ecryptfs_opt_err };
buf : 
buf : static const match_table_t tokens = {
buf : 	{ecryptfs_opt_sig, "sig=%s"},
buf : 	{ecryptfs_opt_ecryptfs_sig, "ecryptfs_sig=%s"},
buf : 	{ecryptfs_opt_cipher, "cipher=%s"},
buf : 	{ecryptfs_opt_ecryptfs_cipher, "ecryptfs_cipher=%s"},
buf : 	{ecryptfs_opt_ecryptfs_key_bytes, "ecryptfs_key_bytes=%u"},
buf : 	{ecryptfs_opt_passthrough, "ecryptfs_passthrough"},
buf : 	{ecryptfs_opt_xattr_metadata, "ecryptfs_xattr_metadata"},
buf : 	{ecryptfs_opt_encrypted_view, "ecryptfs_encrypted_view"},
buf : 	{ecryptfs_opt_fnek_sig, "ecryptfs_fnek_sig=%s"},
buf : 	{ecryptfs_opt_fn_cipher, "ecryptfs_fn_cipher=%s"},
buf : 	{ecryptfs_opt_fn_cipher_key_bytes, "ecryptfs_fn_key_bytes=%u"},
buf : 	{ecryptfs_opt_unlink_sigs, "ecryptfs_unlink_sigs"},
buf : 	{ecryptfs_opt_mount_auth_tok_only, "ecryptfs_mount_auth_tok_only"},
buf : 	{ecryptfs_opt_check_dev_ruid, "ecryptfs_check_dev_ruid"},
buf : 	{ecryptfs_opt_err, NULL}
buf : };
buf : 
buf : static int ecryptfs_init_global_auth_toks(
buf : 	struct ecryptfs_mount_crypt_stat *mount_crypt_stat)
buf : {
buf : 	struct ecryptfs_global_auth_tok *global_auth_tok;
buf : 	struct ecryptfs_auth_tok *auth_tok;
buf : 	int rc = 0;
buf : 
buf : 	list_for_each_entry(global_auth_tok,
for_each_entry(global_auth_tok, 
buf : 			    &mount_crypt_stat->global_auth_tok_list,
buf : 			    mount_crypt_stat_list) {
buf : 		rc = ecryptfs_keyring_auth_tok_for_sig(
for_sig( 
buf : 			&global_auth_tok->global_auth_tok_key, &auth_tok,
buf : 			global_auth_tok->sig);
buf : 		if (rc) {
if (rc) { 
buf : 			printk(KERN_ERR "Could not find valid key in user "
buf : 			       "session keyring for sig specified in mount "
ified in mount " 
buf : 			       "option: [%s]\n", global_auth_tok->sig);
buf : 			global_auth_tok->flags |= ECRYPTFS_AUTH_TOK_INVALID;
buf : 			goto out;
buf : 		} else {
buf : 			global_auth_tok->flags &= ~ECRYPTFS_AUTH_TOK_INVALID;
buf : 			up_write(&(global_auth_tok->global_auth_tok_key)->sem);
buf : 		}
buf : 	}
buf : out:
buf : 	return rc;
buf : }
buf : 
buf : static void ecryptfs_init_mount_crypt_stat(
buf : 	struct ecryptfs_mount_crypt_stat *mount_crypt_stat)
buf : {
buf : 	memset((void *)mount_crypt_stat, 0,
buf : 	       sizeof(struct ecryptfs_mount_crypt_stat));
buf : 	INIT_LIST_HEAD(&mount_crypt_stat->global_auth_tok_list);
buf : 	mutex_init(&mount_crypt_stat->global_auth_tok_list_mutex);
buf : 	mount_crypt_stat->flags |= ECRYPTFS_MOUNT_CRYPT_STAT_INITIALIZED;
buf : }
buf : 
buf : /**
buf :  * ecryptfs_parse_options
buf :  * @sb: The ecryptfs super block
buf :  * @options: The options passed to the kernel
buf :  * @check_ruid: set to 1 if device uid should be checked against the ruid
if device uid should be checked against the ruid 
buf :  *
buf :  * Parse mount options:
buf :  * debug=N 	   - ecryptfs_verbosity level for debug output
for debug output 
buf :  * sig=XXX	   - description(signature) of the key to use
buf :  *
buf :  * Returns the dentry object of the lower-level (lower/interposed)
buf :  * directory; We want to mount our stackable file system on top of
buf :  * that lower directory.
buf :  *
buf :  * The signature of the key to use must be the description of a key
buf :  * already in the keyring. Mounting will fail if the key can not be
if the key can not be 
buf :  * found.
buf :  *
buf :  * Returns zero on success; non-zero on error
buf :  */
buf : static int ecryptfs_parse_options(struct ecryptfs_sb_info *sbi, char *options,
buf : 				  uid_t *check_ruid)
buf : {
buf : 	char *p;
buf : 	int rc = 0;
buf : 	int sig_set = 0;
buf : 	int cipher_name_set = 0;
buf : 	int fn_cipher_name_set = 0;
buf : 	int cipher_key_bytes;
buf : 	int cipher_key_bytes_set = 0;
buf : 	int fn_cipher_key_bytes;
buf : 	int fn_cipher_key_bytes_set = 0;
buf : 	struct ecryptfs_mount_crypt_stat *mount_crypt_stat =
buf : 		&sbi->mount_crypt_stat;
buf : 	substring_t args[MAX_OPT_ARGS];
buf : 	int token;
buf : 	char *sig_src;
buf : 	char *cipher_name_dst;
buf : 	char *cipher_name_src;
buf : 	char *fn_cipher_name_dst;
buf : 	char *fn_cipher_name_src;
buf : 	char *fnek_dst;
buf : 	char *fnek_src;
buf : 	char *cipher_key_bytes_src;
buf : 	char *fn_cipher_key_bytes_src;
buf : 	u8 cipher_code;
buf : 
buf : 	*check_ruid = 0;
buf : 
buf : 	if (!options) {
if (!options) { 
buf : 		rc = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 	ecryptfs_init_mount_crypt_stat(mount_crypt_stat);
buf : 	while ((p = strsep(&options, ",")) != NULL) {
while ((p = strsep(&options, ",")) != NULL) { 
buf : 		if (!*p)
buf : 			continue;
buf : 		token = match_token(p, tokens, args);
buf : 		switch (token) {
buf : 		case ecryptfs_opt_sig:
buf : 		case ecryptfs_opt_ecryptfs_sig:
buf : 			sig_src = args[0].from;
buf : 			rc = ecryptfs_add_global_auth_tok(mount_crypt_stat,
buf : 							  sig_src, 0);
buf : 			if (rc) {
if (rc) { 
buf : 				printk(KERN_ERR "Error attempting to register "
buf : 				       "global sig; rc = [%d]\n", rc);
buf : 				goto out;
buf : 			}
buf : 			sig_set = 1;
buf : 			break;
buf : 		case ecryptfs_opt_cipher:
buf : 		case ecryptfs_opt_ecryptfs_cipher:
buf : 			cipher_name_src = args[0].from;
buf : 			cipher_name_dst =
buf : 				mount_crypt_stat->
buf : 				global_default_cipher_name;
buf : 			strncpy(cipher_name_dst, cipher_name_src,
buf : 				ECRYPTFS_MAX_CIPHER_NAME_SIZE);
buf : 			cipher_name_dst[ECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\0';
buf : 			cipher_name_set = 1;
buf : 			break;
buf : 		case ecryptfs_opt_ecryptfs_key_bytes:
buf : 			cipher_key_bytes_src = args[0].from;
buf : 			cipher_key_bytes =
buf : 				(int)simple_strtol(cipher_key_bytes_src,
buf : 						   &cipher_key_bytes_src, 0);
buf : 			mount_crypt_stat->global_default_cipher_key_size =
buf : 				cipher_key_bytes;
buf : 			cipher_key_bytes_set = 1;
buf : 			break;
buf : 		case ecryptfs_opt_passthrough:
buf : 			mount_crypt_stat->flags |=
buf : 				ECRYPTFS_PLAINTEXT_PASSTHROUGH_ENABLED;
buf : 			break;
buf : 		case ecryptfs_opt_xattr_metadata:
buf : 			mount_crypt_stat->flags |=
buf : 				ECRYPTFS_XATTR_METADATA_ENABLED;
buf : 			break;
buf : 		case ecryptfs_opt_encrypted_view:
buf : 			mount_crypt_stat->flags |=
buf : 				ECRYPTFS_XATTR_METADATA_ENABLED;
buf : 			mount_crypt_stat->flags |=
buf : 				ECRYPTFS_ENCRYPTED_VIEW_ENABLED;
buf : 			break;
buf : 		case ecryptfs_opt_fnek_sig:
buf : 			fnek_src = args[0].from;
buf : 			fnek_dst =
buf : 				mount_crypt_stat->global_default_fnek_sig;
buf : 			strncpy(fnek_dst, fnek_src, ECRYPTFS_SIG_SIZE_HEX);
buf : 			mount_crypt_stat->global_default_fnek_sig[
buf : 				ECRYPTFS_SIG_SIZE_HEX] = '\0';
buf : 			rc = ecryptfs_add_global_auth_tok(
buf : 				mount_crypt_stat,
buf : 				mount_crypt_stat->global_default_fnek_sig,
buf : 				ECRYPTFS_AUTH_TOK_FNEK);
buf : 			if (rc) {
if (rc) { 
buf : 				printk(KERN_ERR "Error attempting to register "
buf : 				       "global fnek sig [%s]; rc = [%d]\n",
buf : 				       mount_crypt_stat->global_default_fnek_sig,
buf : 				       rc);
buf : 				goto out;
buf : 			}
buf : 			mount_crypt_stat->flags |=
buf : 				(ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES
buf : 				 | ECRYPTFS_GLOBAL_ENCFN_USE_MOUNT_FNEK);
buf : 			break;
buf : 		case ecryptfs_opt_fn_cipher:
buf : 			fn_cipher_name_src = args[0].from;
buf : 			fn_cipher_name_dst =
buf : 				mount_crypt_stat->global_default_fn_cipher_name;
buf : 			strncpy(fn_cipher_name_dst, fn_cipher_name_src,
buf : 				ECRYPTFS_MAX_CIPHER_NAME_SIZE);
buf : 			mount_crypt_stat->global_default_fn_cipher_name[
buf : 				ECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\0';
buf : 			fn_cipher_name_set = 1;
buf : 			break;
buf : 		case ecryptfs_opt_fn_cipher_key_bytes:
buf : 			fn_cipher_key_bytes_src = args[0].from;
buf : 			fn_cipher_key_bytes =
buf : 				(int)simple_strtol(fn_cipher_key_bytes_src,
buf : 						   &fn_cipher_key_bytes_src, 0);
buf : 			mount_crypt_stat->global_default_fn_cipher_key_bytes =
buf : 				fn_cipher_key_bytes;
buf : 			fn_cipher_key_bytes_set = 1;
buf : 			break;
buf : 		case ecryptfs_opt_unlink_sigs:
buf : 			mount_crypt_stat->flags |= ECRYPTFS_UNLINK_SIGS;
buf : 			break;
buf : 		case ecryptfs_opt_mount_auth_tok_only:
buf : 			mount_crypt_stat->flags |=
buf : 				ECRYPTFS_GLOBAL_MOUNT_AUTH_TOK_ONLY;
buf : 			break;
buf : 		case ecryptfs_opt_check_dev_ruid:
buf : 			*check_ruid = 1;
buf : 			break;
buf : 		case ecryptfs_opt_err:
buf : 		default:
buf : 			printk(KERN_WARNING
buf : 			       "%s: eCryptfs: unrecognized option [%s]\n",
buf : 			       __func__, p);
buf : 		}
buf : 	}
buf : 	if (!sig_set) {
if (!sig_set) { 
buf : 		rc = -EINVAL;
buf : 		ecryptfs_printk(KERN_ERR, "You must supply at least one valid "
buf : 				"auth tok signature as a mount "
buf : 				"parameter; see the eCryptfs README\n");
buf : 		goto out;
buf : 	}
buf : 	if (!cipher_name_set) {
if (!cipher_name_set) { 
buf : 		int cipher_name_len = strlen(ECRYPTFS_DEFAULT_CIPHER);
buf : 
buf : 		BUG_ON(cipher_name_len >= ECRYPTFS_MAX_CIPHER_NAME_SIZE);
buf : 		strcpy(mount_crypt_stat->global_default_cipher_name,
buf : 		       ECRYPTFS_DEFAULT_CIPHER);
buf : 	}
buf : 	if ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)
if ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES) 
buf : 	    && !fn_cipher_name_set)
buf : 		strcpy(mount_crypt_stat->global_default_fn_cipher_name,
buf : 		       mount_crypt_stat->global_default_cipher_name);
buf : 	if (!cipher_key_bytes_set)
if (!cipher_key_bytes_set) 
buf : 		mount_crypt_stat->global_default_cipher_key_size = 0;
buf : 	if ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)
if ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES) 
buf : 	    && !fn_cipher_key_bytes_set)
buf : 		mount_crypt_stat->global_default_fn_cipher_key_bytes =
buf : 			mount_crypt_stat->global_default_cipher_key_size;
buf : 
buf : 	cipher_code = ecryptfs_code_for_cipher_string(
for_cipher_string( 
buf : 		mount_crypt_stat->global_default_cipher_name,
buf : 		mount_crypt_stat->global_default_cipher_key_size);
buf : 	if (!cipher_code) {
if (!cipher_code) { 
buf : 		ecryptfs_printk(KERN_ERR,
buf : 				"eCryptfs doesn't support cipher: %s",
buf : 				mount_crypt_stat->global_default_cipher_name);
buf : 		rc = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	mutex_lock(&key_tfm_list_mutex);
buf : 	if (!ecryptfs_tfm_exists(mount_crypt_stat->global_default_cipher_name,
if (!ecryptfs_tfm_exists(mount_crypt_stat->global_default_cipher_name, 
buf : 				 NULL)) {
buf : 		rc = ecryptfs_add_new_key_tfm(
buf : 			NULL, mount_crypt_stat->global_default_cipher_name,
buf : 			mount_crypt_stat->global_default_cipher_key_size);
buf : 		if (rc) {
if (rc) { 
buf : 			printk(KERN_ERR "Error attempting to initialize "
buf : 			       "cipher with name = [%s] and key size = [%td]; "
buf : 			       "rc = [%d]\n",
buf : 			       mount_crypt_stat->global_default_cipher_name,
buf : 			       mount_crypt_stat->global_default_cipher_key_size,
buf : 			       rc);
buf : 			rc = -EINVAL;
buf : 			mutex_unlock(&key_tfm_list_mutex);
buf : 			goto out;
buf : 		}
buf : 	}
buf : 	if ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)
if ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES) 
buf : 	    && !ecryptfs_tfm_exists(
buf : 		    mount_crypt_stat->global_default_fn_cipher_name, NULL)) {
buf : 		rc = ecryptfs_add_new_key_tfm(
buf : 			NULL, mount_crypt_stat->global_default_fn_cipher_name,
buf : 			mount_crypt_stat->global_default_fn_cipher_key_bytes);
buf : 		if (rc) {
if (rc) { 
buf : 			printk(KERN_ERR "Error attempting to initialize "
buf : 			       "cipher with name = [%s] and key size = [%td]; "
buf : 			       "rc = [%d]\n",
buf : 			       mount_crypt_stat->global_default_fn_cipher_name,
buf : 			       mount_crypt_stat->global_default_fn_cipher_key_bytes,
buf : 			       rc);
buf : 			rc = -EINVAL;
buf : 			mutex_unlock(&key_tfm_list_mutex);
buf : 			goto out;
buf : 		}
buf : 	}
buf : 	mutex_unlock(&key_tfm_list_mutex);
buf : 	rc = ecryptfs_init_global_auth_toks(mount_crypt_stat);
buf : 	if (rc)
if (rc) 
buf : 		printk(KERN_WARNING "One or more global auth toks could not "
buf : 		       "properly register; rc = [%d]\n", rc);
buf : out:
buf : 	return rc;
buf : }
buf : 
buf : struct kmem_cache *ecryptfs_sb_info_cache;
buf : static struct file_system_type ecryptfs_fs_type;
buf : 
buf : /**
buf :  * ecryptfs_get_sb
buf :  * @fs_type
buf :  * @flags
buf :  * @dev_name: The path to mount over
buf :  * @raw_data: The options passed into the kernel
buf :  */
buf : static struct dentry *ecryptfs_mount(struct file_system_type *fs_type, int flags,
buf : 			const char *dev_name, void *raw_data)
buf : {
buf : 	struct super_block *s;
buf : 	struct ecryptfs_sb_info *sbi;
buf : 	struct ecryptfs_dentry_info *root_info;
buf : 	const char *err = "Getting sb failed";
buf : 	struct inode *inode;
buf : 	struct path path;
buf : 	uid_t check_ruid;
buf : 	int rc;
buf : 
buf : 	sbi = kmem_cache_zalloc(ecryptfs_sb_info_cache, GFP_KERNEL);
buf : 	if (!sbi) {
if (!sbi) { 
buf : 		rc = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 
buf : 	rc = ecryptfs_parse_options(sbi, raw_data, &check_ruid);
buf : 	if (rc) {
if (rc) { 
buf : 		err = "Error parsing options";
buf : 		goto out;
buf : 	}
buf : 
buf : 	s = sget(fs_type, NULL, set_anon_super, flags, NULL);
buf : 	if (IS_ERR(s)) {
if (IS_ERR(s)) { 
buf : 		rc = PTR_ERR(s);
buf : 		goto out;
buf : 	}
buf : 
buf : 	rc = bdi_setup_and_register(&sbi->bdi, "ecryptfs", BDI_CAP_MAP_COPY);
buf : 	if (rc)
if (rc) 
buf : 		goto out1;
buf : 
buf : 	ecryptfs_set_superblock_private(s, sbi);
buf : 	s->s_bdi = &sbi->bdi;
buf : 
buf : 	/* ->kill_sb() will take care of sbi after that point */
buf : 	sbi = NULL;
buf : 	s->s_op = &ecryptfs_sops;
buf : 	s->s_d_op = &ecryptfs_dops;
buf : 
buf : 	err = "Reading sb failed";
buf : 	rc = kern_path(dev_name, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &path);
buf : 	if (rc) {
if (rc) { 
buf : 		ecryptfs_printk(KERN_WARNING, "kern_path() failed\n");
buf : 		goto out1;
buf : 	}
buf : 	if (path.dentry->d_sb->s_type == &ecryptfs_fs_type) {
if (path.dentry->d_sb->s_type == &ecryptfs_fs_type) { 
buf : 		rc = -EINVAL;
buf : 		printk(KERN_ERR "Mount on filesystem of type "
buf : 			"eCryptfs explicitly disallowed due to "
buf : 			"known incompatibilities\n");
buf : 		goto out_free;
buf : 	}
buf : 
buf : 	if (check_ruid && !uid_eq(path.dentry->d_inode->i_uid, current_uid())) {
if (check_ruid && !uid_eq(path.dentry->d_inode->i_uid, current_uid())) { 
buf : 		rc = -EPERM;
buf : 		printk(KERN_ERR "Mount of device (uid: %d) not owned by "
buf : 		       "requested user (uid: %d)\n",
buf : 			i_uid_read(path.dentry->d_inode),
buf : 			from_kuid(&init_user_ns, current_uid()));
buf : 		goto out_free;
buf : 	}
buf : 
buf : 	ecryptfs_set_superblock_lower(s, path.dentry->d_sb);
buf : 
buf : 	/**
buf : 	 * Set the POSIX ACL flag based on whether they're enabled in the lower
buf : 	 * mount. Force a read-only eCryptfs mount if the lower mount is ro.
if the lower mount is ro. 
buf : 	 * Allow a ro eCryptfs mount even when the lower mount is rw.
buf : 	 */
buf : 	s->s_flags = flags & ~MS_POSIXACL;
buf : 	s->s_flags |= path.dentry->d_sb->s_flags & (MS_RDONLY | MS_POSIXACL);
buf : 
buf : 	s->s_maxbytes = path.dentry->d_sb->s_maxbytes;
buf : 	s->s_blocksize = path.dentry->d_sb->s_blocksize;
buf : 	s->s_magic = ECRYPTFS_SUPER_MAGIC;
buf : 
buf : 	inode = ecryptfs_get_inode(path.dentry->d_inode, s);
buf : 	rc = PTR_ERR(inode);
buf : 	if (IS_ERR(inode))
if (IS_ERR(inode)) 
buf : 		goto out_free;
buf : 
buf : 	s->s_root = d_make_root(inode);
buf : 	if (!s->s_root) {
if (!s->s_root) { 
buf : 		rc = -ENOMEM;
buf : 		goto out_free;
buf : 	}
buf : 
buf : 	rc = -ENOMEM;
buf : 	root_info = kmem_cache_zalloc(ecryptfs_dentry_info_cache, GFP_KERNEL);
buf : 	if (!root_info)
if (!root_info) 
buf : 		goto out_free;
buf : 
buf : 	/* ->kill_sb() will take care of root_info */
buf : 	ecryptfs_set_dentry_private(s->s_root, root_info);
buf : 	root_info->lower_path = path;
buf : 
buf : 	s->s_flags |= MS_ACTIVE;
buf : 	return dget(s->s_root);
buf : 
buf : out_free:
buf : 	path_put(&path);
buf : out1:
buf : 	deactivate_locked_super(s);
buf : out:
buf : 	if (sbi) {
if (sbi) { 
buf : 		ecryptfs_destroy_mount_crypt_stat(&sbi->mount_crypt_stat);
buf : 		kmem_cache_free(ecryptfs_sb_info_cache, sbi);
buf : 	}
buf : 	printk(KERN_ERR "%s; rc = [%d]\n", err, rc);
buf : 	return ERR_PTR(rc);
buf : }
buf : 
buf : /**
buf :  * ecryptfs_kill_block_super
buf :  * @sb: The ecryptfs super block
buf :  *
buf :  * Used to bring the superblock down and free the private data.
buf :  */
buf : static void ecryptfs_kill_block_super(struct super_block *sb)
buf : {
buf : 	struct ecryptfs_sb_info *sb_info = ecryptfs_superblock_to_private(sb);
buf : 	kill_anon_super(sb);
buf : 	if (!sb_info)
if (!sb_info) 
buf : 		return;
buf : 	ecryptfs_destroy_mount_crypt_stat(&sb_info->mount_crypt_stat);
buf : 	bdi_destroy(&sb_info->bdi);
buf : 	kmem_cache_free(ecryptfs_sb_info_cache, sb_info);
buf : }
buf : 
buf : static struct file_system_type ecryptfs_fs_type = {
buf : 	.owner = THIS_MODULE,
buf : 	.name = "ecryptfs",
buf : 	.mount = ecryptfs_mount,
buf : 	.kill_sb = ecryptfs_kill_block_super,
buf : 	.fs_flags = 0
buf : };
buf : MODULE_ALIAS_FS("ecryptfs");
buf : 
buf : /**
buf :  * inode_info_init_once
buf :  *
buf :  * Initializes the ecryptfs_inode_info_cache when it is created
buf :  */
buf : static void
buf : inode_info_init_once(void *vptr)
buf : {
buf : 	struct ecryptfs_inode_info *ei = (struct ecryptfs_inode_info *)vptr;
buf : 
buf : 	inode_init_once(&ei->vfs_inode);
buf : }
buf : 
buf : static struct ecryptfs_cache_info {
buf : 	struct kmem_cache **cache;
buf : 	const char *name;
buf : 	size_t size;
buf : 	void (*ctor)(void *obj);
buf : } ecryptfs_cache_infos[] = {
buf : 	{
buf : 		.cache = &ecryptfs_auth_tok_list_item_cache,
buf : 		.name = "ecryptfs_auth_tok_list_item",
buf : 		.size = sizeof(struct ecryptfs_auth_tok_list_item),
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_file_info_cache,
buf : 		.name = "ecryptfs_file_cache",
buf : 		.size = sizeof(struct ecryptfs_file_info),
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_dentry_info_cache,
buf : 		.name = "ecryptfs_dentry_info_cache",
buf : 		.size = sizeof(struct ecryptfs_dentry_info),
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_inode_info_cache,
buf : 		.name = "ecryptfs_inode_cache",
buf : 		.size = sizeof(struct ecryptfs_inode_info),
buf : 		.ctor = inode_info_init_once,
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_sb_info_cache,
buf : 		.name = "ecryptfs_sb_cache",
buf : 		.size = sizeof(struct ecryptfs_sb_info),
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_header_cache,
buf : 		.name = "ecryptfs_headers",
buf : 		.size = PAGE_CACHE_SIZE,
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_xattr_cache,
buf : 		.name = "ecryptfs_xattr_cache",
buf : 		.size = PAGE_CACHE_SIZE,
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_key_record_cache,
buf : 		.name = "ecryptfs_key_record_cache",
buf : 		.size = sizeof(struct ecryptfs_key_record),
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_key_sig_cache,
buf : 		.name = "ecryptfs_key_sig_cache",
buf : 		.size = sizeof(struct ecryptfs_key_sig),
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_global_auth_tok_cache,
buf : 		.name = "ecryptfs_global_auth_tok_cache",
buf : 		.size = sizeof(struct ecryptfs_global_auth_tok),
buf : 	},
buf : 	{
buf : 		.cache = &ecryptfs_key_tfm_cache,
buf : 		.name = "ecryptfs_key_tfm_cache",
buf : 		.size = sizeof(struct ecryptfs_key_tfm),
buf : 	},
buf : };
buf : 
buf : static void ecryptfs_free_kmem_caches(void)
buf : {
buf : 	int i;
buf : 
buf : 	/*
buf : 	 * Make sure all delayed rcu free inodes are flushed before we
fore we 
buf : 	 * destroy cache.
buf : 	 */
buf : 	rcu_barrier();
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(ecryptfs_cache_infos); i++) {
for (i = 0; i < ARRAY_SIZE(ecryptfs_cache_infos); i++) { 
buf : 		struct ecryptfs_cache_info *info;
buf : 
buf : 		info = &ecryptfs_cache_infos[i];
buf : 		if (*(info->cache))
if (*(info->cache)) 
buf : 			kmem_cache_destroy(*(info->cache));
buf : 	}
buf : }
buf : 
buf : /**
buf :  * ecryptfs_init_kmem_caches
buf :  *
buf :  * Returns zero on success; non-zero otherwise
buf :  */
buf : static int ecryptfs_init_kmem_caches(void)
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(ecryptfs_cache_infos); i++) {
for (i = 0; i < ARRAY_SIZE(ecryptfs_cache_infos); i++) { 
buf : 		struct ecryptfs_cache_info *info;
buf : 
buf : 		info = &ecryptfs_cache_infos[i];
buf : 		*(info->cache) = kmem_cache_create(info->name, info->size,
buf : 				0, SLAB_HWCACHE_ALIGN, info->ctor);
buf : 		if (!*(info->cache)) {
if (!*(info->cache)) { 
buf : 			ecryptfs_free_kmem_caches();
buf : 			ecryptfs_printk(KERN_WARNING, "%s: "
buf : 					"kmem_cache_create failed\n",
buf : 					info->name);
buf : 			return -ENOMEM;
buf : 		}
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static struct kobject *ecryptfs_kobj;
buf : 
buf : static ssize_t version_show(struct kobject *kobj,
buf : 			    struct kobj_attribute *attr, char *buff)
buf : {
buf : 	return snprintf(buff, PAGE_SIZE, "%d\n", ECRYPTFS_VERSIONING_MASK);
buf : }
buf : 
buf : static struct kobj_attribute version_attr = __ATTR_RO(version);
buf : 
buf : static struct attribute *attributes[] = {
buf : 	&version_attr.attr,
buf : 	NULL,
buf : };
buf : 
buf : static struct attribute_group attr_group = {
buf : 	.attrs = attributes,
buf : };
buf : 
buf : static int do_sysfs_registration(void)
buf : {
buf : 	int rc;
buf : 
buf : 	ecryptfs_kobj = kobject_create_and_add("ecryptfs", fs_kobj);
buf : 	if (!ecryptfs_kobj) {
if (!ecryptfs_kobj) { 
buf : 		printk(KERN_ERR "Unable to create ecryptfs kset\n");
buf : 		rc = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 	rc = sysfs_create_group(ecryptfs_kobj, &attr_group);
buf : 	if (rc) {
if (rc) { 
buf : 		printk(KERN_ERR
buf : 		       "Unable to create ecryptfs version attributes\n");
buf : 		kobject_put(ecryptfs_kobj);
buf : 	}
buf : out:
buf : 	return rc;
buf : }
buf : 
buf : static void do_sysfs_unregistration(void)
buf : {
buf : 	sysfs_remove_group(ecryptfs_kobj, &attr_group);
buf : 	kobject_put(ecryptfs_kobj);
buf : }
buf : 
buf : static int __init ecryptfs_init(void)
buf : {
buf : 	int rc;
buf : 
buf : 	if (ECRYPTFS_DEFAULT_EXTENT_SIZE > PAGE_CACHE_SIZE) {
if (ECRYPTFS_DEFAULT_EXTENT_SIZE > PAGE_CACHE_SIZE) { 
buf : 		rc = -EINVAL;
buf : 		ecryptfs_printk(KERN_ERR, "The eCryptfs extent size is "
buf : 				"larger than the host's page size, and so "
buf : 				"eCryptfs cannot run on this system. The "
buf : 				"default eCryptfs extent size is [%u] bytes; "
buf : 				"the page size is [%lu] bytes.\n",
buf : 				ECRYPTFS_DEFAULT_EXTENT_SIZE,
buf : 				(unsigned long)PAGE_CACHE_SIZE);
buf : 		goto out;
buf : 	}
buf : 	rc = ecryptfs_init_kmem_caches();
buf : 	if (rc) {
if (rc) { 
buf : 		printk(KERN_ERR
buf : 		       "Failed to allocate one or more kmem_cache objects\n");
buf : 		goto out;
buf : 	}
buf : 	rc = do_sysfs_registration();
buf : 	if (rc) {
if (rc) { 
buf : 		printk(KERN_ERR "sysfs registration failed\n");
buf : 		goto out_free_kmem_caches;
buf : 	}
buf : 	rc = ecryptfs_init_kthread();
buf : 	if (rc) {
if (rc) { 
buf : 		printk(KERN_ERR "%s: kthread initialization failed; "
buf : 		       "rc = [%d]\n", __func__, rc);
buf : 		goto out_do_sysfs_unregistration;
buf : 	}
buf : 	rc = ecryptfs_init_messaging();
buf : 	if (rc) {
if (rc) { 
buf : 		printk(KERN_ERR "Failure occurred while attempting to "
while attempting to " 
buf : 				"initialize the communications channel to "
buf : 				"ecryptfsd\n");
buf : 		goto out_destroy_kthread;
buf : 	}
buf : 	rc = ecryptfs_init_crypto();
buf : 	if (rc) {
if (rc) { 
buf : 		printk(KERN_ERR "Failure whilst attempting to init crypto; "
buf : 		       "rc = [%d]\n", rc);
buf : 		goto out_release_messaging;
buf : 	}
buf : 	rc = register_filesystem(&ecryptfs_fs_type);
buf : 	if (rc) {
if (rc) { 
buf : 		printk(KERN_ERR "Failed to register filesystem\n");
buf : 		goto out_destroy_crypto;
buf : 	}
buf : 	if (ecryptfs_verbosity > 0)
if (ecryptfs_verbosity > 0) 
buf : 		printk(KERN_CRIT "eCryptfs verbosity set to %d. Secret values "
buf : 			"will be written to the syslog!\n", ecryptfs_verbosity);
buf : 
buf : 	goto out;
buf : out_destroy_crypto:
buf : 	ecryptfs_destroy_crypto();
buf : out_release_messaging:
buf : 	ecryptfs_release_messaging();
buf : out_destroy_kthread:
buf : 	ecryptfs_destroy_kthread();
buf : out_do_sysfs_unregistration:
buf : 	do_sysfs_unregistration();
buf : out_free_kmem_caches:
buf : 	ecryptfs_free_kmem_caches();
buf : out:
buf : 	return rc;
buf : }
buf : 
buf : static void __exit ecryptfs_exit(void)
buf : {
buf : 	int rc;
buf : 
buf : 	rc = ecryptfs_destroy_crypto();
buf : 	if (rc)
if (rc) 
buf : 		printk(KERN_ERR "Failure whilst attempting to destroy crypto; "
buf : 		       "rc = [%d]\n", rc);
buf : 	ecryptfs_release_messaging();
buf : 	ecryptfs_destroy_kthread();
buf : 	do_sysfs_unregistration();
buf : 	unregister_filesystem(&ecryptfs_fs_type);
buf : 	ecryptfs_free_kmem_caches();
buf : }
buf : 
buf : MODULE_AUTHOR("Michael A. Halcrow <mhalcrow@us.ibm.com>");
buf : MODULE_DESCRIPTION("eCryptfs");
buf : 
buf : MODULE_LICENSE("GPL");
buf : 
buf : module_init(ecryptfs_init)
buf : module_exit(ecryptfs_exit)
file : ./test/kernel/fs/fscache/main.c 
[ OK ] open : 4 ok... 
buf : /* General filesystem local caching manager
buf :  *
buf :  * Copyright (C) 2004-2007 Red Hat, Inc. All Rights Reserved.
buf :  * Written by David Howells (dhowells@redhat.com)
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of the GNU General Public License
ify it under the terms of the GNU General Public License 
buf :  * as published by the Free Software Foundation; either version
buf :  * 2 of the License, or (at your option) any later version.
buf :  */
buf : 
buf : #define FSCACHE_DEBUG_LEVEL CACHE
buf : #include <linux/module.h>
buf : #include <linux/init.h>
buf : #include <linux/sched.h>
buf : #include <linux/completion.h>
buf : #include <linux/slab.h>
buf : #include <linux/seq_file.h>
buf : #include "internal.h"
buf : 
buf : MODULE_DESCRIPTION("FS Cache Manager");
buf : MODULE_AUTHOR("Red Hat, Inc.");
buf : MODULE_LICENSE("GPL");
buf : 
buf : unsigned fscache_defer_lookup = 1;
buf : module_param_named(defer_lookup, fscache_defer_lookup, uint,
buf : 		   S_IWUSR | S_IRUGO);
buf : MODULE_PARM_DESC(fscache_defer_lookup,
buf : 		 "Defer cookie lookup to background thread");
buf : 
buf : unsigned fscache_defer_create = 1;
buf : module_param_named(defer_create, fscache_defer_create, uint,
buf : 		   S_IWUSR | S_IRUGO);
buf : MODULE_PARM_DESC(fscache_defer_create,
buf : 		 "Defer cookie creation to background thread");
buf : 
buf : unsigned fscache_debug;
buf : module_param_named(debug, fscache_debug, uint,
buf : 		   S_IWUSR | S_IRUGO);
buf : MODULE_PARM_DESC(fscache_debug,
buf : 		 "FS-Cache debugging mask");
buf : 
buf : struct kobject *fscache_root;
buf : struct workqueue_struct *fscache_object_wq;
buf : struct workqueue_struct *fscache_op_wq;
buf : 
buf : DEFINE_PER_CPU(wait_queue_head_t, fscache_object_cong_wait);
buf : 
buf : /* these values serve as lower bounds, will be adjusted in fscache_init() */
buf : static unsigned fscache_object_max_active = 4;
buf : static unsigned fscache_op_max_active = 2;
buf : 
buf : #ifdef CONFIG_SYSCTL
ifdef CONFIG_SYSCTL 
buf : static struct ctl_table_header *fscache_sysctl_header;
buf : 
buf : static int fscache_max_active_sysctl(struct ctl_table *table, int write,
buf : 				     void __user *buffer,
buf : 				     size_t *lenp, loff_t *ppos)
buf : {
buf : 	struct workqueue_struct **wqp = table->extra1;
buf : 	unsigned int *datap = table->data;
buf : 	int ret;
buf : 
buf : 	ret = proc_dointvec(table, write, buffer, lenp, ppos);
buf : 	if (ret == 0)
if (ret == 0) 
buf : 		workqueue_set_max_active(*wqp, *datap);
buf : 	return ret;
buf : }
buf : 
buf : struct ctl_table fscache_sysctls[] = {
buf : 	{
buf : 		.procname	= "object_max_active",
buf : 		.data		= &fscache_object_max_active,
buf : 		.maxlen		= sizeof(unsigned),
buf : 		.mode		= 0644,
buf : 		.proc_handler	= fscache_max_active_sysctl,
buf : 		.extra1		= &fscache_object_wq,
buf : 	},
buf : 	{
buf : 		.procname	= "operation_max_active",
buf : 		.data		= &fscache_op_max_active,
buf : 		.maxlen		= sizeof(unsigned),
buf : 		.mode		= 0644,
buf : 		.proc_handler	= fscache_max_active_sysctl,
buf : 		.extra1		= &fscache_op_wq,
buf : 	},
buf : 	{}
buf : };
buf : 
buf : struct ctl_table fscache_sysctls_root[] = {
buf : 	{
buf : 		.procname	= "fscache",
buf : 		.mode		= 0555,
buf : 		.child		= fscache_sysctls,
buf : 	},
buf : 	{}
buf : };
buf : #endif
if 
buf : 
buf : /*
buf :  * initialise the fs caching module
buf :  */
buf : static int __init fscache_init(void)
buf : {
buf : 	unsigned int nr_cpus = num_possible_cpus();
buf : 	unsigned int cpu;
buf : 	int ret;
buf : 
buf : 	fscache_object_max_active =
buf : 		clamp_val(nr_cpus,
buf : 			  fscache_object_max_active, WQ_UNBOUND_MAX_ACTIVE);
buf : 
buf : 	ret = -ENOMEM;
buf : 	fscache_object_wq = alloc_workqueue("fscache_object", WQ_UNBOUND,
buf : 					    fscache_object_max_active);
buf : 	if (!fscache_object_wq)
if (!fscache_object_wq) 
buf : 		goto error_object_wq;
buf : 
buf : 	fscache_op_max_active =
buf : 		clamp_val(fscache_object_max_active / 2,
buf : 			  fscache_op_max_active, WQ_UNBOUND_MAX_ACTIVE);
buf : 
buf : 	ret = -ENOMEM;
buf : 	fscache_op_wq = alloc_workqueue("fscache_operation", WQ_UNBOUND,
buf : 					fscache_op_max_active);
buf : 	if (!fscache_op_wq)
if (!fscache_op_wq) 
buf : 		goto error_op_wq;
buf : 
buf : 	for_each_possible_cpu(cpu)
for_each_possible_cpu(cpu) 
buf : 		init_waitqueue_head(&per_cpu(fscache_object_cong_wait, cpu));
buf : 
buf : 	ret = fscache_proc_init();
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto error_proc;
buf : 
buf : #ifdef CONFIG_SYSCTL
ifdef CONFIG_SYSCTL 
buf : 	ret = -ENOMEM;
buf : 	fscache_sysctl_header = register_sysctl_table(fscache_sysctls_root);
buf : 	if (!fscache_sysctl_header)
if (!fscache_sysctl_header) 
buf : 		goto error_sysctl;
buf : #endif
if 
buf : 
buf : 	fscache_cookie_jar = kmem_cache_create("fscache_cookie_jar",
buf : 					       sizeof(struct fscache_cookie),
buf : 					       0,
buf : 					       0,
buf : 					       fscache_cookie_init_once);
buf : 	if (!fscache_cookie_jar) {
if (!fscache_cookie_jar) { 
buf : 		pr_notice("Failed to allocate a cookie jar\n");
buf : 		ret = -ENOMEM;
buf : 		goto error_cookie_jar;
buf : 	}
buf : 
buf : 	fscache_root = kobject_create_and_add("fscache", kernel_kobj);
buf : 	if (!fscache_root)
if (!fscache_root) 
buf : 		goto error_kobj;
buf : 
buf : 	pr_notice("Loaded\n");
buf : 	return 0;
buf : 
buf : error_kobj:
buf : 	kmem_cache_destroy(fscache_cookie_jar);
buf : error_cookie_jar:
buf : #ifdef CONFIG_SYSCTL
ifdef CONFIG_SYSCTL 
buf : 	unregister_sysctl_table(fscache_sysctl_header);
buf : error_sysctl:
buf : #endif
if 
buf : 	fscache_proc_cleanup();
buf : error_proc:
buf : 	destroy_workqueue(fscache_op_wq);
buf : error_op_wq:
buf : 	destroy_workqueue(fscache_object_wq);
buf : error_object_wq:
buf : 	return ret;
buf : }
buf : 
buf : fs_initcall(fscache_init);
buf : 
buf : /*
buf :  * clean up on module removal
buf :  */
buf : static void __exit fscache_exit(void)
buf : {
buf : 	_enter("");
buf : 
buf : 	kobject_put(fscache_root);
buf : 	kmem_cache_destroy(fscache_cookie_jar);
buf : #ifdef CONFIG_SYSCTL
ifdef CONFIG_SYSCTL 
buf : 	unregister_sysctl_table(fscache_sysctl_header);
buf : #endif
if 
buf : 	fscache_proc_cleanup();
buf : 	destroy_workqueue(fscache_op_wq);
buf : 	destroy_workqueue(fscache_object_wq);
buf : 	pr_notice("Unloaded\n");
buf : }
buf : 
buf : module_exit(fscache_exit);
buf : 
buf : /*
buf :  * wait_on_bit() sleep function for uninterruptible waiting
for uninterruptible waiting 
buf :  */
buf : int fscache_wait_bit(void *flags)
buf : {
buf : 	schedule();
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * wait_on_bit() sleep function for interruptible waiting
for interruptible waiting 
buf :  */
buf : int fscache_wait_bit_interruptible(void *flags)
buf : {
buf : 	schedule();
buf : 	return signal_pending(current);
buf : }
buf : 
buf : /*
buf :  * wait_on_atomic_t() sleep function for uninterruptible waiting
for uninterruptible waiting 
buf :  */
buf : int fscache_wait_atomic_t(atomic_t *p)
buf : {
buf : 	schedule();
buf : 	return 0;
buf : }
file : ./test/kernel/fs/gfs2/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
buf :  * Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
buf :  *
buf :  * This copyrighted material is made available to anyone wishing to use,
buf :  * modify, copy, or redistribute it subject to the terms and conditions
ify, copy, or redistribute it subject to the terms and conditions 
buf :  * of the GNU General Public License version 2.
buf :  */
buf : 
buf : #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
buf : 
buf : #include <linux/slab.h>
buf : #include <linux/spinlock.h>
buf : #include <linux/completion.h>
buf : #include <linux/buffer_head.h>
buf : #include <linux/module.h>
buf : #include <linux/init.h>
buf : #include <linux/gfs2_ondisk.h>
buf : #include <linux/rcupdate.h>
buf : #include <linux/rculist_bl.h>
buf : #include <linux/atomic.h>
buf : #include <linux/mempool.h>
buf : 
buf : #include "gfs2.h"
buf : #include "incore.h"
buf : #include "super.h"
buf : #include "sys.h"
buf : #include "util.h"
buf : #include "glock.h"
buf : #include "quota.h"
buf : #include "recovery.h"
buf : #include "dir.h"
buf : 
buf : struct workqueue_struct *gfs2_control_wq;
buf : 
buf : static void gfs2_init_inode_once(void *foo)
buf : {
buf : 	struct gfs2_inode *ip = foo;
buf : 
buf : 	inode_init_once(&ip->i_inode);
buf : 	init_rwsem(&ip->i_rw_mutex);
buf : 	INIT_LIST_HEAD(&ip->i_trunc_list);
buf : 	ip->i_res = NULL;
buf : 	ip->i_hash_cache = NULL;
buf : }
buf : 
buf : static void gfs2_init_glock_once(void *foo)
buf : {
buf : 	struct gfs2_glock *gl = foo;
buf : 
buf : 	INIT_HLIST_BL_NODE(&gl->gl_list);
buf : 	spin_lock_init(&gl->gl_spin);
buf : 	INIT_LIST_HEAD(&gl->gl_holders);
buf : 	INIT_LIST_HEAD(&gl->gl_lru);
buf : 	INIT_LIST_HEAD(&gl->gl_ail_list);
buf : 	atomic_set(&gl->gl_ail_count, 0);
buf : 	atomic_set(&gl->gl_revokes, 0);
buf : }
buf : 
buf : static void gfs2_init_gl_aspace_once(void *foo)
buf : {
buf : 	struct gfs2_glock *gl = foo;
buf : 	struct address_space *mapping = (struct address_space *)(gl + 1);
buf : 
buf : 	gfs2_init_glock_once(gl);
buf : 	address_space_init_once(mapping);
buf : }
buf : 
buf : /**
buf :  * init_gfs2_fs - Register GFS2 as a filesystem
buf :  *
buf :  * Returns: 0 on success, error code on failure
buf :  */
buf : 
buf : static int __init init_gfs2_fs(void)
buf : {
buf : 	int error;
buf : 
buf : 	gfs2_str2qstr(&gfs2_qdot, ".");
buf : 	gfs2_str2qstr(&gfs2_qdotdot, "..");
buf : 	gfs2_quota_hash_init();
buf : 
buf : 	error = gfs2_sys_init();
buf : 	if (error)
if (error) 
buf : 		return error;
buf : 
buf : 	error = list_lru_init(&gfs2_qd_lru);
buf : 	if (error)
if (error) 
buf : 		goto fail_lru;
buf : 
buf : 	error = gfs2_glock_init();
buf : 	if (error)
if (error) 
buf : 		goto fail;
buf : 
buf : 	error = -ENOMEM;
buf : 	gfs2_glock_cachep = kmem_cache_create("gfs2_glock",
buf : 					      sizeof(struct gfs2_glock),
buf : 					      0, 0,
buf : 					      gfs2_init_glock_once);
buf : 	if (!gfs2_glock_cachep)
if (!gfs2_glock_cachep) 
buf : 		goto fail;
buf : 
buf : 	gfs2_glock_aspace_cachep = kmem_cache_create("gfs2_glock(aspace)",
buf : 					sizeof(struct gfs2_glock) +
buf : 					sizeof(struct address_space),
buf : 					0, 0, gfs2_init_gl_aspace_once);
buf : 
buf : 	if (!gfs2_glock_aspace_cachep)
if (!gfs2_glock_aspace_cachep) 
buf : 		goto fail;
buf : 
buf : 	gfs2_inode_cachep = kmem_cache_create("gfs2_inode",
buf : 					      sizeof(struct gfs2_inode),
buf : 					      0,  SLAB_RECLAIM_ACCOUNT|
buf : 					          SLAB_MEM_SPREAD,
buf : 					      gfs2_init_inode_once);
buf : 	if (!gfs2_inode_cachep)
if (!gfs2_inode_cachep) 
buf : 		goto fail;
buf : 
buf : 	gfs2_bufdata_cachep = kmem_cache_create("gfs2_bufdata",
buf : 						sizeof(struct gfs2_bufdata),
buf : 					        0, 0, NULL);
buf : 	if (!gfs2_bufdata_cachep)
if (!gfs2_bufdata_cachep) 
buf : 		goto fail;
buf : 
buf : 	gfs2_rgrpd_cachep = kmem_cache_create("gfs2_rgrpd",
buf : 					      sizeof(struct gfs2_rgrpd),
buf : 					      0, 0, NULL);
buf : 	if (!gfs2_rgrpd_cachep)
if (!gfs2_rgrpd_cachep) 
buf : 		goto fail;
buf : 
buf : 	gfs2_quotad_cachep = kmem_cache_create("gfs2_quotad",
buf : 					       sizeof(struct gfs2_quota_data),
buf : 					       0, 0, NULL);
buf : 	if (!gfs2_quotad_cachep)
if (!gfs2_quotad_cachep) 
buf : 		goto fail;
buf : 
buf : 	gfs2_rsrv_cachep = kmem_cache_create("gfs2_mblk",
buf : 					     sizeof(struct gfs2_blkreserv),
buf : 					       0, 0, NULL);
buf : 	if (!gfs2_rsrv_cachep)
if (!gfs2_rsrv_cachep) 
buf : 		goto fail;
buf : 
buf : 	register_shrinker(&gfs2_qd_shrinker);
buf : 
buf : 	error = register_filesystem(&gfs2_fs_type);
buf : 	if (error)
if (error) 
buf : 		goto fail;
buf : 
buf : 	error = register_filesystem(&gfs2meta_fs_type);
buf : 	if (error)
if (error) 
buf : 		goto fail_unregister;
buf : 
buf : 	error = -ENOMEM;
buf : 	gfs_recovery_wq = alloc_workqueue("gfs_recovery",
buf : 					  WQ_MEM_RECLAIM | WQ_FREEZABLE, 0);
buf : 	if (!gfs_recovery_wq)
if (!gfs_recovery_wq) 
buf : 		goto fail_wq;
buf : 
buf : 	gfs2_control_wq = alloc_workqueue("gfs2_control",
buf : 					  WQ_UNBOUND | WQ_FREEZABLE, 0);
buf : 	if (!gfs2_control_wq)
if (!gfs2_control_wq) 
buf : 		goto fail_recovery;
buf : 
buf : 	gfs2_page_pool = mempool_create_page_pool(64, 0);
buf : 	if (!gfs2_page_pool)
if (!gfs2_page_pool) 
buf : 		goto fail_control;
buf : 
buf : 	gfs2_register_debugfs();
buf : 
buf : 	pr_info("GFS2 installed\n");
buf : 
buf : 	return 0;
buf : 
buf : fail_control:
buf : 	destroy_workqueue(gfs2_control_wq);
buf : fail_recovery:
buf : 	destroy_workqueue(gfs_recovery_wq);
buf : fail_wq:
buf : 	unregister_filesystem(&gfs2meta_fs_type);
buf : fail_unregister:
buf : 	unregister_filesystem(&gfs2_fs_type);
buf : fail:
buf : 	list_lru_destroy(&gfs2_qd_lru);
buf : fail_lru:
buf : 	unregister_shrinker(&gfs2_qd_shrinker);
buf : 	gfs2_glock_exit();
buf : 
buf : 	if (gfs2_rsrv_cachep)
if (gfs2_rsrv_cachep) 
buf : 		kmem_cache_destroy(gfs2_rsrv_cachep);
buf : 
buf : 	if (gfs2_quotad_cachep)
if (gfs2_quotad_cachep) 
buf : 		kmem_cache_destroy(gfs2_quotad_cachep);
buf : 
buf : 	if (gfs2_rgrpd_cachep)
if (gfs2_rgrpd_cachep) 
buf : 		kmem_cache_destroy(gfs2_rgrpd_cachep);
buf : 
buf : 	if (gfs2_bufdata_cachep)
if (gfs2_bufdata_cachep) 
buf : 		kmem_cache_destroy(gfs2_bufdata_cachep);
buf : 
buf : 	if (gfs2_inode_cachep)
if (gfs2_inode_cachep) 
buf : 		kmem_cache_destroy(gfs2_inode_cachep);
buf : 
buf : 	if (gfs2_glock_aspace_cachep)
if (gfs2_glock_aspace_cachep) 
buf : 		kmem_cache_destroy(gfs2_glock_aspace_cachep);
buf : 
buf : 	if (gfs2_glock_cachep)
if (gfs2_glock_cachep) 
buf : 		kmem_cache_destroy(gfs2_glock_cachep);
buf : 
buf : 	gfs2_sys_uninit();
buf : 	return error;
buf : }
buf : 
buf : /**
buf :  * exit_gfs2_fs - Unregister the file system
buf :  *
buf :  */
buf : 
buf : static void __exit exit_gfs2_fs(void)
buf : {
buf : 	unregister_shrinker(&gfs2_qd_shrinker);
buf : 	gfs2_glock_exit();
buf : 	gfs2_unregister_debugfs();
buf : 	unregister_filesystem(&gfs2_fs_type);
buf : 	unregister_filesystem(&gfs2meta_fs_type);
buf : 	destroy_workqueue(gfs_recovery_wq);
buf : 	destroy_workqueue(gfs2_control_wq);
buf : 	list_lru_destroy(&gfs2_qd_lru);
buf : 
buf : 	rcu_barrier();
buf : 
buf : 	mempool_destroy(gfs2_page_pool);
buf : 	kmem_cache_destroy(gfs2_rsrv_cachep);
buf : 	kmem_cache_destroy(gfs2_quotad_cachep);
buf : 	kmem_cache_destroy(gfs2_rgrpd_cachep);
buf : 	kmem_cache_destroy(gfs2_bufdata_cachep);
buf : 	kmem_cache_destroy(gfs2_inode_cachep);
buf : 	kmem_cache_destroy(gfs2_glock_aspace_cachep);
buf : 	kmem_cache_destroy(gfs2_glock_cachep);
buf : 
buf : 	gfs2_sys_uninit();
buf : }
buf : 
buf : MODULE_DESCRIPTION("Global File System");
buf : MODULE_AUTHOR("Red Hat, Inc.");
buf : MODULE_LICENSE("GPL");
buf : 
buf : module_init(init_gfs2_fs);
buf : module_exit(exit_gfs2_fs);
buf : 
file : ./test/kernel/kernel/power/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * kernel/power/main.c - PM subsystem core functionality.
buf :  *
buf :  * Copyright (c) 2003 Patrick Mochel
buf :  * Copyright (c) 2003 Open Source Development Lab
buf :  *
buf :  * This file is released under the GPLv2
buf :  *
buf :  */
buf : 
buf : #include <linux/export.h>
buf : #include <linux/kobject.h>
buf : #include <linux/string.h>
buf : #include <linux/resume-trace.h>
buf : #include <linux/workqueue.h>
buf : #include <linux/debugfs.h>
buf : #include <linux/seq_file.h>
buf : 
buf : #include "power.h"
buf : 
buf : DEFINE_MUTEX(pm_mutex);
buf : 
buf : #ifdef CONFIG_PM_SLEEP
ifdef CONFIG_PM_SLEEP 
buf : 
buf : /* Routines for PM-transition notifications */
for PM-transition notifications */ 
buf : 
buf : static BLOCKING_NOTIFIER_HEAD(pm_chain_head);
buf : 
buf : int register_pm_notifier(struct notifier_block *nb)
ifier(struct notifier_block *nb) 
buf : {
buf : 	return blocking_notifier_chain_register(&pm_chain_head, nb);
buf : }
buf : EXPORT_SYMBOL_GPL(register_pm_notifier);
ifier); 
buf : 
buf : int unregister_pm_notifier(struct notifier_block *nb)
buf : {
buf : 	return blocking_notifier_chain_unregister(&pm_chain_head, nb);
ifier_chain_unregister(&pm_chain_head, nb); 
buf : }
buf : EXPORT_SYMBOL_GPL(unregister_pm_notifier);
buf : 
buf : int pm_notifier_call_chain(unsigned long val)
ifier_call_chain(unsigned long val) 
buf : {
buf : 	int ret = blocking_notifier_call_chain(&pm_chain_head, val, NULL);
buf : 
buf : 	return notifier_to_errno(ret);
ifier_to_errno(ret); 
buf : }
buf : 
buf : /* If set, devices may be suspended and resumed asynchronously. */
buf : int pm_async_enabled = 1;
buf : 
buf : static ssize_t pm_async_show(struct kobject *kobj, struct kobj_attribute *attr,
buf : 			     char *buf)
buf : {
buf : 	return sprintf(buf, "%d\n", pm_async_enabled);
buf : }
buf : 
buf : static ssize_t pm_async_store(struct kobject *kobj, struct kobj_attribute *attr,
buf : 			      const char *buf, size_t n)
buf : {
buf : 	unsigned long val;
buf : 
buf : 	if (kstrtoul(buf, 10, &val))
if (kstrtoul(buf, 10, &val)) 
buf : 		return -EINVAL;
buf : 
buf : 	if (val > 1)
if (val > 1) 
buf : 		return -EINVAL;
buf : 
buf : 	pm_async_enabled = val;
buf : 	return n;
buf : }
buf : 
buf : power_attr(pm_async);
buf : 
buf : #ifdef CONFIG_PM_DEBUG
ifdef CONFIG_PM_DEBUG 
buf : int pm_test_level = TEST_NONE;
buf : 
buf : static const char * const pm_tests[__TEST_AFTER_LAST] = {
buf : 	[TEST_NONE] = "none",
buf : 	[TEST_CORE] = "core",
buf : 	[TEST_CPUS] = "processors",
buf : 	[TEST_PLATFORM] = "platform",
form", 
buf : 	[TEST_DEVICES] = "devices",
buf : 	[TEST_FREEZER] = "freezer",
buf : };
buf : 
buf : static ssize_t pm_test_show(struct kobject *kobj, struct kobj_attribute *attr,
buf : 				char *buf)
buf : {
buf : 	char *s = buf;
buf : 	int level;
buf : 
buf : 	for (level = TEST_FIRST; level <= TEST_MAX; level++)
for (level = TEST_FIRST; level <= TEST_MAX; level++) 
buf : 		if (pm_tests[level]) {
buf : 			if (level == pm_test_level)
if (level == pm_test_level) 
buf : 				s += sprintf(s, "[%s] ", pm_tests[level]);
buf : 			else
buf : 				s += sprintf(s, "%s ", pm_tests[level]);
buf : 		}
buf : 
buf : 	if (s != buf)
if (s != buf) 
buf : 		/* convert the last space to a newline */
buf : 		*(s-1) = '\n';
buf : 
buf : 	return (s - buf);
buf : }
buf : 
buf : static ssize_t pm_test_store(struct kobject *kobj, struct kobj_attribute *attr,
buf : 				const char *buf, size_t n)
buf : {
buf : 	const char * const *s;
buf : 	int level;
buf : 	char *p;
buf : 	int len;
buf : 	int error = -EINVAL;
buf : 
buf : 	p = memchr(buf, '\n', n);
buf : 	len = p ? p - buf : n;
buf : 
buf : 	lock_system_sleep();
buf : 
buf : 	level = TEST_FIRST;
buf : 	for (s = &pm_tests[level]; level <= TEST_MAX; s++, level++)
for (s = &pm_tests[level]; level <= TEST_MAX; s++, level++) 
buf : 		if (*s && len == strlen(*s) && !strncmp(buf, *s, len)) {
buf : 			pm_test_level = level;
buf : 			error = 0;
buf : 			break;
buf : 		}
buf : 
buf : 	unlock_system_sleep();
buf : 
buf : 	return error ? error : n;
buf : }
buf : 
buf : power_attr(pm_test);
buf : #endif /* CONFIG_PM_DEBUG */
if /* CONFIG_PM_DEBUG */ 
buf : 
buf : #ifdef CONFIG_DEBUG_FS
buf : static char *suspend_step_name(enum suspend_stat_step step)
buf : {
buf : 	switch (step) {
buf : 	case SUSPEND_FREEZE:
buf : 		return "freeze";
buf : 	case SUSPEND_PREPARE:
buf : 		return "prepare";
buf : 	case SUSPEND_SUSPEND:
buf : 		return "suspend";
buf : 	case SUSPEND_SUSPEND_NOIRQ:
buf : 		return "suspend_noirq";
buf : 	case SUSPEND_RESUME_NOIRQ:
buf : 		return "resume_noirq";
buf : 	case SUSPEND_RESUME:
buf : 		return "resume";
buf : 	default:
buf : 		return "";
buf : 	}
buf : }
buf : 
buf : static int suspend_stats_show(struct seq_file *s, void *unused)
buf : {
buf : 	int i, index, last_dev, last_errno, last_step;
buf : 
buf : 	last_dev = suspend_stats.last_failed_dev + REC_FAILED_NUM - 1;
buf : 	last_dev %= REC_FAILED_NUM;
buf : 	last_errno = suspend_stats.last_failed_errno + REC_FAILED_NUM - 1;
buf : 	last_errno %= REC_FAILED_NUM;
buf : 	last_step = suspend_stats.last_failed_step + REC_FAILED_NUM - 1;
buf : 	last_step %= REC_FAILED_NUM;
buf : 	seq_printf(s, "%s: %d\n%s: %d\n%s: %d\n%s: %d\n%s: %d\n"
buf : 			"%s: %d\n%s: %d\n%s: %d\n%s: %d\n%s: %d\n",
buf : 			"success", suspend_stats.success,
buf : 			"fail", suspend_stats.fail,
buf : 			"failed_freeze", suspend_stats.failed_freeze,
buf : 			"failed_prepare", suspend_stats.failed_prepare,
buf : 			"failed_suspend", suspend_stats.failed_suspend,
buf : 			"failed_suspend_late",
buf : 				suspend_stats.failed_suspend_late,
buf : 			"failed_suspend_noirq",
buf : 				suspend_stats.failed_suspend_noirq,
buf : 			"failed_resume", suspend_stats.failed_resume,
buf : 			"failed_resume_early",
buf : 				suspend_stats.failed_resume_early,
buf : 			"failed_resume_noirq",
buf : 				suspend_stats.failed_resume_noirq);
buf : 	seq_printf(s,	"failures:\n  last_failed_dev:\t%-s\n",
buf : 			suspend_stats.failed_devs[last_dev]);
buf : 	for (i = 1; i < REC_FAILED_NUM; i++) {
for (i = 1; i < REC_FAILED_NUM; i++) { 
buf : 		index = last_dev + REC_FAILED_NUM - i;
buf : 		index %= REC_FAILED_NUM;
buf : 		seq_printf(s, "\t\t\t%-s\n",
buf : 			suspend_stats.failed_devs[index]);
buf : 	}
buf : 	seq_printf(s,	"  last_failed_errno:\t%-d\n",
buf : 			suspend_stats.errno[last_errno]);
buf : 	for (i = 1; i < REC_FAILED_NUM; i++) {
for (i = 1; i < REC_FAILED_NUM; i++) { 
buf : 		index = last_errno + REC_FAILED_NUM - i;
buf : 		index %= REC_FAILED_NUM;
buf : 		seq_printf(s, "\t\t\t%-d\n",
buf : 			suspend_stats.errno[index]);
buf : 	}
buf : 	seq_printf(s,	"  last_failed_step:\t%-s\n",
buf : 			suspend_step_name(
buf : 				suspend_stats.failed_steps[last_step]));
buf : 	for (i = 1; i < REC_FAILED_NUM; i++) {
for (i = 1; i < REC_FAILED_NUM; i++) { 
buf : 		index = last_step + REC_FAILED_NUM - i;
buf : 		index %= REC_FAILED_NUM;
buf : 		seq_printf(s, "\t\t\t%-s\n",
buf : 			suspend_step_name(
buf : 				suspend_stats.failed_steps[index]));
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int suspend_stats_open(struct inode *inode, struct file *file)
buf : {
buf : 	return single_open(file, suspend_stats_show, NULL);
buf : }
buf : 
buf : static const struct file_operations suspend_stats_operations = {
buf : 	.open           = suspend_stats_open,
buf : 	.read           = seq_read,
buf : 	.llseek         = seq_lseek,
buf : 	.release        = single_release,
buf : };
buf : 
buf : static int __init pm_debugfs_init(void)
buf : {
buf : 	debugfs_create_file("suspend_stats", S_IFREG | S_IRUGO,
buf : 			NULL, NULL, &suspend_stats_operations);
buf : 	return 0;
buf : }
buf : 
buf : late_initcall(pm_debugfs_init);
buf : #endif /* CONFIG_DEBUG_FS */
if /* CONFIG_DEBUG_FS */ 
buf : 
buf : #endif /* CONFIG_PM_SLEEP */
buf : 
buf : #ifdef CONFIG_PM_SLEEP_DEBUG
ifdef CONFIG_PM_SLEEP_DEBUG 
buf : /*
buf :  * pm_print_times: print time taken by devices to suspend and resume.
buf :  *
buf :  * show() returns whether printing of suspend and resume times is enabled.
buf :  * store() accepts 0 or 1.  0 disables printing and 1 enables it.
buf :  */
buf : bool pm_print_times_enabled;
buf : 
buf : static ssize_t pm_print_times_show(struct kobject *kobj,
buf : 				   struct kobj_attribute *attr, char *buf)
buf : {
buf : 	return sprintf(buf, "%d\n", pm_print_times_enabled);
buf : }
buf : 
buf : static ssize_t pm_print_times_store(struct kobject *kobj,
buf : 				    struct kobj_attribute *attr,
buf : 				    const char *buf, size_t n)
buf : {
buf : 	unsigned long val;
buf : 
buf : 	if (kstrtoul(buf, 10, &val))
if (kstrtoul(buf, 10, &val)) 
buf : 		return -EINVAL;
buf : 
buf : 	if (val > 1)
if (val > 1) 
buf : 		return -EINVAL;
buf : 
buf : 	pm_print_times_enabled = !!val;
buf : 	return n;
buf : }
buf : 
buf : power_attr(pm_print_times);
buf : 
buf : static inline void pm_print_times_init(void)
buf : {
buf : 	pm_print_times_enabled = !!initcall_debug;
buf : }
buf : #else /* !CONFIG_PP_SLEEP_DEBUG */
buf : static inline void pm_print_times_init(void) {}
buf : #endif /* CONFIG_PM_SLEEP_DEBUG */
if /* CONFIG_PM_SLEEP_DEBUG */ 
buf : 
buf : struct kobject *power_kobj;
buf : 
buf : /**
buf :  * state - control system sleep states.
buf :  *
buf :  * show() returns available sleep state labels, which may be "mem", "standby",
buf :  * "freeze" and "disk" (hibernation).  See Documentation/power/states.txt for a
for a 
buf :  * description of what they mean.
buf :  *
buf :  * store() accepts one of those strings, translates it into the proper
buf :  * enumerated value, and initiates a suspend transition.
buf :  */
buf : static ssize_t state_show(struct kobject *kobj, struct kobj_attribute *attr,
buf : 			  char *buf)
buf : {
buf : 	char *s = buf;
buf : #ifdef CONFIG_SUSPEND
ifdef CONFIG_SUSPEND 
buf : 	suspend_state_t i;
buf : 
buf : 	for (i = PM_SUSPEND_MIN; i < PM_SUSPEND_MAX; i++)
for (i = PM_SUSPEND_MIN; i < PM_SUSPEND_MAX; i++) 
buf : 		if (pm_states[i].state)
buf : 			s += sprintf(s,"%s ", pm_states[i].label);
buf : 
buf : #endif
if 
buf : 	if (hibernation_available())
buf : 		s += sprintf(s, "disk ");
buf : 	if (s != buf)
if (s != buf) 
buf : 		/* convert the last space to a newline */
buf : 		*(s-1) = '\n';
buf : 	return (s - buf);
buf : }
buf : 
buf : static suspend_state_t decode_state(const char *buf, size_t n)
buf : {
buf : #ifdef CONFIG_SUSPEND
ifdef CONFIG_SUSPEND 
buf : 	suspend_state_t state = PM_SUSPEND_MIN;
buf : 	struct pm_sleep_state *s;
buf : #endif
if 
buf : 	char *p;
buf : 	int len;
buf : 
buf : 	p = memchr(buf, '\n', n);
buf : 	len = p ? p - buf : n;
buf : 
buf : 	/* Check hibernation first. */
buf : 	if (len == 4 && !strncmp(buf, "disk", len))
if (len == 4 && !strncmp(buf, "disk", len)) 
buf : 		return PM_SUSPEND_MAX;
buf : 
buf : #ifdef CONFIG_SUSPEND
ifdef CONFIG_SUSPEND 
buf : 	for (s = &pm_states[state]; state < PM_SUSPEND_MAX; s++, state++)
for (s = &pm_states[state]; state < PM_SUSPEND_MAX; s++, state++) 
buf : 		if (s->state && len == strlen(s->label)
buf : 		    && !strncmp(buf, s->label, len))
buf : 			return s->state;
buf : #endif
if 
buf : 
buf : 	return PM_SUSPEND_ON;
buf : }
buf : 
buf : static ssize_t state_store(struct kobject *kobj, struct kobj_attribute *attr,
buf : 			   const char *buf, size_t n)
buf : {
buf : 	suspend_state_t state;
buf : 	int error;
buf : 
buf : 	error = pm_autosleep_lock();
buf : 	if (error)
if (error) 
buf : 		return error;
buf : 
buf : 	if (pm_autosleep_state() > PM_SUSPEND_ON) {
if (pm_autosleep_state() > PM_SUSPEND_ON) { 
buf : 		error = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	state = decode_state(buf, n);
buf : 	if (state < PM_SUSPEND_MAX)
if (state < PM_SUSPEND_MAX) 
buf : 		error = pm_suspend(state);
buf : 	else if (state == PM_SUSPEND_MAX)
if (state == PM_SUSPEND_MAX) 
buf : 		error = hibernate();
buf : 	else
buf : 		error = -EINVAL;
buf : 
buf :  out:
buf : 	pm_autosleep_unlock();
buf : 	return error ? error : n;
buf : }
buf : 
buf : power_attr(state);
buf : 
buf : #ifdef CONFIG_PM_SLEEP
ifdef CONFIG_PM_SLEEP 
buf : /*
buf :  * The 'wakeup_count' attribute, along with the functions defined in
buf :  * drivers/base/power/wakeup.c, provides a means by which wakeup events can be
buf :  * handled in a non-racy way.
buf :  *
buf :  * If a wakeup event occurs when the system is in a sleep state, it simply is
buf :  * woken up.  In turn, if an event that would wake the system up from a sleep
if an event that would wake the system up from a sleep 
buf :  * state occurs when it is undergoing a transition to that sleep state, the
buf :  * transition should be aborted.  Moreover, if such an event occurs when the
if such an event occurs when the 
buf :  * system is in the working state, an attempt to start a transition to the
buf :  * given sleep state should fail during certain period after the detection of
buf :  * the event.  Using the 'state' attribute alone is not sufficient to satisfy
buf :  * these requirements, because a wakeup event may occur exactly when 'state'
buf :  * is being written to and may be delivered to user space right before it is
fore it is 
buf :  * frozen, so the event will remain only partially processed until the system is
buf :  * woken up by another event.  In particular, it won't cause the transition to
buf :  * a sleep state to be aborted.
buf :  *
buf :  * This difficulty may be overcome if user space uses 'wakeup_count' before
ifficulty may be overcome if user space uses 'wakeup_count' before 
buf :  * writing to 'state'.  It first should read from 'wakeup_count' and store
buf :  * the read value.  Then, after carrying out its own preparations for the system
for the system 
buf :  * transition to a sleep state, it should write the stored value to
buf :  * 'wakeup_count'.  If that fails, at least one wakeup event has occurred since
buf :  * 'wakeup_count' was read and 'state' should not be written to.  Otherwise, it
buf :  * is allowed to write to 'state', but the transition will be aborted if there
if there 
buf :  * are any wakeup events detected after 'wakeup_count' was written to.
buf :  */
buf : 
buf : static ssize_t wakeup_count_show(struct kobject *kobj,
buf : 				struct kobj_attribute *attr,
buf : 				char *buf)
buf : {
buf : 	unsigned int val;
buf : 
buf : 	return pm_get_wakeup_count(&val, true) ?
buf : 		sprintf(buf, "%u\n", val) : -EINTR;
buf : }
buf : 
buf : static ssize_t wakeup_count_store(struct kobject *kobj,
buf : 				struct kobj_attribute *attr,
buf : 				const char *buf, size_t n)
buf : {
buf : 	unsigned int val;
buf : 	int error;
buf : 
buf : 	error = pm_autosleep_lock();
buf : 	if (error)
if (error) 
buf : 		return error;
buf : 
buf : 	if (pm_autosleep_state() > PM_SUSPEND_ON) {
if (pm_autosleep_state() > PM_SUSPEND_ON) { 
buf : 		error = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	error = -EINVAL;
buf : 	if (sscanf(buf, "%u", &val) == 1) {
if (sscanf(buf, "%u", &val) == 1) { 
buf : 		if (pm_save_wakeup_count(val))
buf : 			error = n;
buf : 		else
buf : 			pm_print_active_wakeup_sources();
buf : 	}
buf : 
buf :  out:
buf : 	pm_autosleep_unlock();
buf : 	return error;
buf : }
buf : 
buf : power_attr(wakeup_count);
buf : 
buf : #ifdef CONFIG_PM_AUTOSLEEP
ifdef CONFIG_PM_AUTOSLEEP 
buf : static ssize_t autosleep_show(struct kobject *kobj,
buf : 			      struct kobj_attribute *attr,
buf : 			      char *buf)
buf : {
buf : 	suspend_state_t state = pm_autosleep_state();
buf : 
buf : 	if (state == PM_SUSPEND_ON)
if (state == PM_SUSPEND_ON) 
buf : 		return sprintf(buf, "off\n");
buf : 
buf : #ifdef CONFIG_SUSPEND
ifdef CONFIG_SUSPEND 
buf : 	if (state < PM_SUSPEND_MAX)
buf : 		return sprintf(buf, "%s\n", pm_states[state].state ?
buf : 					pm_states[state].label : "error");
buf : #endif
if 
buf : #ifdef CONFIG_HIBERNATION
buf : 	return sprintf(buf, "disk\n");
buf : #else
buf : 	return sprintf(buf, "error");
buf : #endif
if 
buf : }
buf : 
buf : static ssize_t autosleep_store(struct kobject *kobj,
buf : 			       struct kobj_attribute *attr,
buf : 			       const char *buf, size_t n)
buf : {
buf : 	suspend_state_t state = decode_state(buf, n);
buf : 	int error;
buf : 
buf : 	if (state == PM_SUSPEND_ON
if (state == PM_SUSPEND_ON 
buf : 	    && strcmp(buf, "off") && strcmp(buf, "off\n"))
buf : 		return -EINVAL;
buf : 
buf : 	error = pm_autosleep_set_state(state);
buf : 	return error ? error : n;
buf : }
buf : 
buf : power_attr(autosleep);
buf : #endif /* CONFIG_PM_AUTOSLEEP */
if /* CONFIG_PM_AUTOSLEEP */ 
buf : 
buf : #ifdef CONFIG_PM_WAKELOCKS
buf : static ssize_t wake_lock_show(struct kobject *kobj,
buf : 			      struct kobj_attribute *attr,
buf : 			      char *buf)
buf : {
buf : 	return pm_show_wakelocks(buf, true);
buf : }
buf : 
buf : static ssize_t wake_lock_store(struct kobject *kobj,
buf : 			       struct kobj_attribute *attr,
buf : 			       const char *buf, size_t n)
buf : {
buf : 	int error = pm_wake_lock(buf);
buf : 	return error ? error : n;
buf : }
buf : 
buf : power_attr(wake_lock);
buf : 
buf : static ssize_t wake_unlock_show(struct kobject *kobj,
buf : 				struct kobj_attribute *attr,
buf : 				char *buf)
buf : {
buf : 	return pm_show_wakelocks(buf, false);
buf : }
buf : 
buf : static ssize_t wake_unlock_store(struct kobject *kobj,
buf : 				 struct kobj_attribute *attr,
buf : 				 const char *buf, size_t n)
buf : {
buf : 	int error = pm_wake_unlock(buf);
buf : 	return error ? error : n;
buf : }
buf : 
buf : power_attr(wake_unlock);
buf : 
buf : #endif /* CONFIG_PM_WAKELOCKS */
if /* CONFIG_PM_WAKELOCKS */ 
buf : #endif /* CONFIG_PM_SLEEP */
buf : 
buf : #ifdef CONFIG_PM_TRACE
ifdef CONFIG_PM_TRACE 
buf : int pm_trace_enabled;
buf : 
buf : static ssize_t pm_trace_show(struct kobject *kobj, struct kobj_attribute *attr,
buf : 			     char *buf)
buf : {
buf : 	return sprintf(buf, "%d\n", pm_trace_enabled);
buf : }
buf : 
buf : static ssize_t
buf : pm_trace_store(struct kobject *kobj, struct kobj_attribute *attr,
buf : 	       const char *buf, size_t n)
buf : {
buf : 	int val;
buf : 
buf : 	if (sscanf(buf, "%d", &val) == 1) {
if (sscanf(buf, "%d", &val) == 1) { 
buf : 		pm_trace_enabled = !!val;
buf : 		if (pm_trace_enabled) {
if (pm_trace_enabled) { 
buf : 			pr_warn("PM: Enabling pm_trace changes system date and time during resume.\n"
buf : 				"PM: Correct system time has to be restored manually after resume.\n");
buf : 		}
buf : 		return n;
buf : 	}
buf : 	return -EINVAL;
buf : }
buf : 
buf : power_attr(pm_trace);
buf : 
buf : static ssize_t pm_trace_dev_match_show(struct kobject *kobj,
buf : 				       struct kobj_attribute *attr,
buf : 				       char *buf)
buf : {
buf : 	return show_trace_dev_match(buf, PAGE_SIZE);
buf : }
buf : 
buf : static ssize_t
buf : pm_trace_dev_match_store(struct kobject *kobj, struct kobj_attribute *attr,
buf : 			 const char *buf, size_t n)
buf : {
buf : 	return -EINVAL;
buf : }
buf : 
buf : power_attr(pm_trace_dev_match);
buf : 
buf : #endif /* CONFIG_PM_TRACE */
if /* CONFIG_PM_TRACE */ 
buf : 
buf : #ifdef CONFIG_FREEZER
buf : static ssize_t pm_freeze_timeout_show(struct kobject *kobj,
buf : 				      struct kobj_attribute *attr, char *buf)
buf : {
buf : 	return sprintf(buf, "%u\n", freeze_timeout_msecs);
buf : }
buf : 
buf : static ssize_t pm_freeze_timeout_store(struct kobject *kobj,
buf : 				       struct kobj_attribute *attr,
buf : 				       const char *buf, size_t n)
buf : {
buf : 	unsigned long val;
buf : 
buf : 	if (kstrtoul(buf, 10, &val))
if (kstrtoul(buf, 10, &val)) 
buf : 		return -EINVAL;
buf : 
buf : 	freeze_timeout_msecs = val;
buf : 	return n;
buf : }
buf : 
buf : power_attr(pm_freeze_timeout);
buf : 
buf : #endif	/* CONFIG_FREEZER*/
if	/* CONFIG_FREEZER*/ 
buf : 
buf : static struct attribute * g[] = {
buf : 	&state_attr.attr,
buf : #ifdef CONFIG_PM_TRACE
ifdef CONFIG_PM_TRACE 
buf : 	&pm_trace_attr.attr,
buf : 	&pm_trace_dev_match_attr.attr,
buf : #endif
if 
buf : #ifdef CONFIG_PM_SLEEP
buf : 	&pm_async_attr.attr,
buf : 	&wakeup_count_attr.attr,
buf : #ifdef CONFIG_PM_AUTOSLEEP
ifdef CONFIG_PM_AUTOSLEEP 
buf : 	&autosleep_attr.attr,
buf : #endif
if 
buf : #ifdef CONFIG_PM_WAKELOCKS
buf : 	&wake_lock_attr.attr,
buf : 	&wake_unlock_attr.attr,
buf : #endif
if 
buf : #ifdef CONFIG_PM_DEBUG
buf : 	&pm_test_attr.attr,
buf : #endif
if 
buf : #ifdef CONFIG_PM_SLEEP_DEBUG
buf : 	&pm_print_times_attr.attr,
buf : #endif
if 
buf : #endif
buf : #ifdef CONFIG_FREEZER
ifdef CONFIG_FREEZER 
buf : 	&pm_freeze_timeout_attr.attr,
buf : #endif
if 
buf : 	NULL,
buf : };
buf : 
buf : static struct attribute_group attr_group = {
buf : 	.attrs = g,
buf : };
buf : 
buf : #ifdef CONFIG_PM_RUNTIME
ifdef CONFIG_PM_RUNTIME 
buf : struct workqueue_struct *pm_wq;
buf : EXPORT_SYMBOL_GPL(pm_wq);
buf : 
buf : static int __init pm_start_workqueue(void)
buf : {
buf : 	pm_wq = alloc_workqueue("pm", WQ_FREEZABLE, 0);
buf : 
buf : 	return pm_wq ? 0 : -ENOMEM;
buf : }
buf : #else
buf : static inline int pm_start_workqueue(void) { return 0; }
buf : #endif
if 
buf : 
buf : static int __init pm_init(void)
buf : {
buf : 	int error = pm_start_workqueue();
buf : 	if (error)
if (error) 
buf : 		return error;
buf : 	hibernate_image_size_init();
buf : 	hibernate_reserved_size_init();
buf : 	power_kobj = kobject_create_and_add("power", NULL);
buf : 	if (!power_kobj)
if (!power_kobj) 
buf : 		return -ENOMEM;
buf : 	error = sysfs_create_group(power_kobj, &attr_group);
buf : 	if (error)
if (error) 
buf : 		return error;
buf : 	pm_print_times_init();
buf : 	return pm_autosleep_init();
buf : }
buf : 
buf : core_initcall(pm_init);
file : ./test/kernel/tools/power/cpupower/bench/main.c 
[ OK ] open : 4 ok... 
buf : /*  cpufreq-bench CPUFreq microbenchmark
buf :  *
buf :  *  Copyright (C) 2008 Christian Kornacker <ckornacker@suse.de>
buf :  *
buf :  *  This program is free software; you can redistribute it and/or modify
ify 
buf :  *  it under the terms of the GNU General Public License as published by
buf :  *  the Free Software Foundation; either version 2 of the License, or
buf :  *  (at your option) any later version.
buf :  *
buf :  *  This program is distributed in the hope that it will be useful,
buf :  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
buf :  *  GNU General Public License for more details.
for more details. 
buf :  *
buf :  *  You should have received a copy of the GNU General Public License
buf :  *  along with this program; if not, write to the Free Software
if not, write to the Free Software 
buf :  *  Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
buf :  */
buf : 
buf : #include <stdio.h>
buf : #include <stdlib.h>
buf : #include <string.h>
buf : #include <unistd.h>
buf : #include <getopt.h>
buf : #include <errno.h>
buf : 
buf : #include "config.h"
buf : #include "system.h"
buf : #include "benchmark.h"
buf : 
buf : static struct option long_options[] = {
buf : 	{"output",	1,	0,	'o'},
buf : 	{"sleep",	1,	0,	's'},
buf : 	{"load",	1,	0,	'l'},
buf : 	{"verbose",	0,	0,	'v'},
buf : 	{"cpu",		1,	0,	'c'},
buf : 	{"governor",	1,	0,	'g'},
buf : 	{"prio",	1,	0,	'p'},
buf : 	{"file",	1,	0,	'f'},
buf : 	{"cycles",	1,	0,	'n'},
buf : 	{"rounds",	1,	0,	'r'},
buf : 	{"load-step",	1,	0,	'x'},
buf : 	{"sleep-step",	1,	0,	'y'},
buf : 	{"help",	0,	0,	'h'},
buf : 	{0, 0, 0, 0}
buf : };
buf : 
buf : /*******************************************************************
buf :  usage
buf : *******************************************************************/
buf : 
buf : void usage()
buf : {
buf : 	printf("usage: ./bench\n");
buf : 	printf("Options:\n");
buf : 	printf(" -l, --load=<long int>\t\tinitial load time in us\n");
buf : 	printf(" -s, --sleep=<long int>\t\tinitial sleep time in us\n");
buf : 	printf(" -x, --load-step=<long int>\ttime to be added to load time, in us\n");
buf : 	printf(" -y, --sleep-step=<long int>\ttime to be added to sleep time, in us\n");
buf : 	printf(" -c, --cpu=<cpu #>\t\t\tCPU Nr. to use, starting at 0\n");
buf : 	printf(" -p, --prio=<priority>\t\t\tscheduler priority, HIGH, LOW or DEFAULT\n");
buf : 	printf(" -g, --governor=<governor>\t\tcpufreq governor to test\n");
buf : 	printf(" -n, --cycles=<int>\t\t\tload/sleep cycles\n");
buf : 	printf(" -r, --rounds<int>\t\t\tload/sleep rounds\n");
buf : 	printf(" -f, --file=<configfile>\t\tconfig file to use\n");
buf : 	printf(" -o, --output=<dir>\t\t\toutput path. Filename will be OUTPUTPATH/benchmark_TIMESTAMP.log\n");
buf : 	printf(" -v, --verbose\t\t\t\tverbose output on/off\n");
buf : 	printf(" -h, --help\t\t\t\tPrint this help screen\n");
buf : 	exit(1);
buf : }
buf : 
buf : /*******************************************************************
buf :  main
buf : *******************************************************************/
buf : 
buf : int main(int argc, char **argv)
buf : {
buf : 	int c;
buf : 	int option_index = 0;
buf : 	struct config *config = NULL;
buf : 
buf : 	config = prepare_default_config();
buf : 
buf : 	if (config == NULL)
if (config == NULL) 
buf : 		return EXIT_FAILURE;
buf : 
buf : 	while (1) {
while (1) { 
buf : 		c = getopt_long (argc, argv, "hg:o:s:l:vc:p:f:n:r:x:y:",
buf : 				long_options, &option_index);
buf : 		if (c == -1)
if (c == -1) 
buf : 			break;
buf : 
buf : 		switch (c) {
buf : 		case 'o':
buf : 			if (config->output != NULL)
if (config->output != NULL) 
buf : 				fclose(config->output);
buf : 
buf : 			config->output = prepare_output(optarg);
buf : 
buf : 			if (config->output == NULL)
if (config->output == NULL) 
buf : 				return EXIT_FAILURE;
buf : 
buf : 			dprintf("user output path -> %s\n", optarg);
buf : 			break;
buf : 		case 's':
buf : 			sscanf(optarg, "%li", &config->sleep);
buf : 			dprintf("user sleep time -> %s\n", optarg);
buf : 			break;
buf : 		case 'l':
buf : 			sscanf(optarg, "%li", &config->load);
buf : 			dprintf("user load time -> %s\n", optarg);
buf : 			break;
buf : 		case 'c':
buf : 			sscanf(optarg, "%u", &config->cpu);
buf : 			dprintf("user cpu -> %s\n", optarg);
buf : 			break;
buf : 		case 'g':
buf : 			strncpy(config->governor, optarg, 14);
buf : 			dprintf("user governor -> %s\n", optarg);
buf : 			break;
buf : 		case 'p':
buf : 			if (string_to_prio(optarg) != SCHED_ERR) {
if (string_to_prio(optarg) != SCHED_ERR) { 
buf : 				config->prio = string_to_prio(optarg);
buf : 				dprintf("user prio -> %s\n", optarg);
buf : 			} else {
buf : 				if (config != NULL) {
if (config != NULL) { 
buf : 					if (config->output != NULL)
buf : 						fclose(config->output);
buf : 					free(config);
buf : 				}
buf : 				usage();
buf : 			}
buf : 			break;
buf : 		case 'n':
buf : 			sscanf(optarg, "%u", &config->cycles);
buf : 			dprintf("user cycles -> %s\n", optarg);
buf : 			break;
buf : 		case 'r':
buf : 			sscanf(optarg, "%u", &config->rounds);
buf : 			dprintf("user rounds -> %s\n", optarg);
buf : 			break;
buf : 		case 'x':
buf : 			sscanf(optarg, "%li", &config->load_step);
buf : 			dprintf("user load_step -> %s\n", optarg);
buf : 			break;
buf : 		case 'y':
buf : 			sscanf(optarg, "%li", &config->sleep_step);
buf : 			dprintf("user sleep_step -> %s\n", optarg);
buf : 			break;
buf : 		case 'f':
buf : 			if (prepare_config(optarg, config))
if (prepare_config(optarg, config)) 
buf : 				return EXIT_FAILURE;
buf : 			break;
buf : 		case 'v':
buf : 			config->verbose = 1;
buf : 			dprintf("verbose output enabled\n");
buf : 			break;
buf : 		case 'h':
buf : 		case '?':
buf : 		default:
buf : 			if (config != NULL) {
if (config != NULL) { 
buf : 				if (config->output != NULL)
buf : 					fclose(config->output);
buf : 				free(config);
buf : 			}
buf : 			usage();
buf : 		}
buf : 	}
buf : 
buf : 	if (config->verbose) {
if (config->verbose) { 
buf : 		printf("starting benchmark with parameters:\n");
buf : 		printf("config:\n\t"
buf : 		       "sleep=%li\n\t"
buf : 		       "load=%li\n\t"
buf : 		       "sleep_step=%li\n\t"
buf : 		       "load_step=%li\n\t"
buf : 		       "cpu=%u\n\t"
buf : 		       "cycles=%u\n\t"
buf : 		       "rounds=%u\n\t"
buf : 		       "governor=%s\n\n",
buf : 		       config->sleep,
buf : 		       config->load,
buf : 		       config->sleep_step,
buf : 		       config->load_step,
buf : 		       config->cpu,
buf : 		       config->cycles,
buf : 		       config->rounds,
buf : 		       config->governor);
buf : 	}
buf : 
buf : 	prepare_user(config);
buf : 	prepare_system(config);
buf : 	start_benchmark(config);
buf : 
buf : 	if (config->output != stdout)
if (config->output != stdout) 
buf : 		fclose(config->output);
buf : 
buf : 	free(config);
buf : 
buf : 	return EXIT_SUCCESS;
buf : }
buf : 
file : ./test/kernel/init/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  *  linux/init/main.c
buf :  *
buf :  *  Copyright (C) 1991, 1992  Linus Torvalds
buf :  *
buf :  *  GK 2/5/95  -  Changed to support mounting root fs via NFS
buf :  *  Added initrd & change_root: Werner Almesberger & Hans Lermen, Feb '96
buf :  *  Moan early if gcc is old, avoiding bogus kernels - Paul Gortmaker, May '96
if gcc is old, avoiding bogus kernels - Paul Gortmaker, May '96 
buf :  *  Simplified starting of init:  Michael A. Griffith <grif@acm.org> 
buf :  */
buf : 
buf : #define DEBUG		/* Enable initcall_debug */
buf : 
buf : #include <linux/types.h>
buf : #include <linux/module.h>
buf : #include <linux/proc_fs.h>
buf : #include <linux/kernel.h>
buf : #include <linux/syscalls.h>
buf : #include <linux/stackprotector.h>
buf : #include <linux/string.h>
buf : #include <linux/ctype.h>
buf : #include <linux/delay.h>
buf : #include <linux/ioport.h>
buf : #include <linux/init.h>
buf : #include <linux/initrd.h>
buf : #include <linux/bootmem.h>
buf : #include <linux/acpi.h>
buf : #include <linux/tty.h>
buf : #include <linux/percpu.h>
buf : #include <linux/kmod.h>
buf : #include <linux/vmalloc.h>
buf : #include <linux/kernel_stat.h>
buf : #include <linux/start_kernel.h>
buf : #include <linux/security.h>
buf : #include <linux/smp.h>
buf : #include <linux/profile.h>
buf : #include <linux/rcupdate.h>
buf : #include <linux/moduleparam.h>
buf : #include <linux/kallsyms.h>
buf : #include <linux/writeback.h>
buf : #include <linux/cpu.h>
buf : #include <linux/cpuset.h>
buf : #include <linux/cgroup.h>
buf : #include <linux/efi.h>
buf : #include <linux/tick.h>
buf : #include <linux/interrupt.h>
buf : #include <linux/taskstats_kern.h>
buf : #include <linux/delayacct.h>
buf : #include <linux/unistd.h>
buf : #include <linux/rmap.h>
buf : #include <linux/mempolicy.h>
buf : #include <linux/key.h>
buf : #include <linux/buffer_head.h>
buf : #include <linux/page_cgroup.h>
buf : #include <linux/debug_locks.h>
buf : #include <linux/debugobjects.h>
buf : #include <linux/lockdep.h>
buf : #include <linux/kmemleak.h>
buf : #include <linux/pid_namespace.h>
buf : #include <linux/device.h>
buf : #include <linux/kthread.h>
buf : #include <linux/sched.h>
buf : #include <linux/signal.h>
buf : #include <linux/idr.h>
buf : #include <linux/kgdb.h>
buf : #include <linux/ftrace.h>
buf : #include <linux/async.h>
buf : #include <linux/kmemcheck.h>
buf : #include <linux/sfi.h>
buf : #include <linux/shmem_fs.h>
buf : #include <linux/slab.h>
buf : #include <linux/perf_event.h>
buf : #include <linux/file.h>
buf : #include <linux/ptrace.h>
buf : #include <linux/blkdev.h>
buf : #include <linux/elevator.h>
buf : #include <linux/sched_clock.h>
buf : #include <linux/context_tracking.h>
buf : #include <linux/random.h>
buf : #include <linux/list.h>
buf : 
buf : #include <asm/io.h>
buf : #include <asm/bugs.h>
buf : #include <asm/setup.h>
buf : #include <asm/sections.h>
buf : #include <asm/cacheflush.h>
buf : 
buf : #ifdef CONFIG_X86_LOCAL_APIC
ifdef CONFIG_X86_LOCAL_APIC 
buf : #include <asm/smp.h>
buf : #endif
if 
buf : 
buf : static int kernel_init(void *);
buf : 
buf : extern void init_IRQ(void);
buf : extern void fork_init(unsigned long);
fork_init(unsigned long); 
buf : extern void radix_tree_init(void);
buf : #ifndef CONFIG_DEBUG_RODATA
ifndef CONFIG_DEBUG_RODATA 
buf : static inline void mark_rodata_ro(void) { }
buf : #endif
if 
buf : 
buf : /*
buf :  * Debug helper: via this flag we know that we are in 'early bootup code'
buf :  * where only the boot processor is running with IRQ disabled.  This means
buf :  * two things - IRQ must not be enabled before the flag is cleared and some
fore the flag is cleared and some 
buf :  * operations which are not allowed with IRQ disabled are allowed while the
while the 
buf :  * flag is set.
buf :  */
buf : bool early_boot_irqs_disabled __read_mostly;
buf : 
buf : enum system_states system_state __read_mostly;
buf : EXPORT_SYMBOL(system_state);
buf : 
buf : /*
buf :  * Boot command-line arguments
buf :  */
buf : #define MAX_INIT_ARGS CONFIG_INIT_ENV_ARG_LIMIT
buf : #define MAX_INIT_ENVS CONFIG_INIT_ENV_ARG_LIMIT
buf : 
buf : extern void time_init(void);
buf : /* Default late time init is NULL. archs can override this later. */
buf : void (*__initdata late_time_init)(void);
buf : 
buf : /* Untouched command line saved by arch-specific code. */
ific code. */ 
buf : char __initdata boot_command_line[COMMAND_LINE_SIZE];
buf : /* Untouched saved command line (eg. for /proc) */
for /proc) */ 
buf : char *saved_command_line;
buf : /* Command line for parameter parsing */
for parameter parsing */ 
buf : static char *static_command_line;
buf : /* Command line for per-initcall parameter parsing */
for per-initcall parameter parsing */ 
buf : static char *initcall_command_line;
buf : 
buf : static char *execute_command;
buf : static char *ramdisk_execute_command;
buf : 
buf : /*
buf :  * Used to generate warnings if static_key manipulation functions are used
if static_key manipulation functions are used 
buf :  * before jump_label_init is called.
fore jump_label_init is called. 
buf :  */
buf : bool static_key_initialized __read_mostly = false;
buf : EXPORT_SYMBOL_GPL(static_key_initialized);
buf : 
buf : /*
buf :  * If set, this is an indication to the drivers that reset the underlying
buf :  * device before going ahead with the initialization otherwise driver might
fore going ahead with the initialization otherwise driver might 
buf :  * rely on the BIOS and skip the reset operation.
buf :  *
buf :  * This is useful if kernel is booting in an unreliable environment.
if kernel is booting in an unreliable environment. 
buf :  * For ex. kdump situaiton where previous kernel has crashed, BIOS has been
buf :  * skipped and devices will be in unknown state.
buf :  */
buf : unsigned int reset_devices;
buf : EXPORT_SYMBOL(reset_devices);
buf : 
buf : static int __init set_reset_devices(char *str)
buf : {
buf : 	reset_devices = 1;
buf : 	return 1;
buf : }
buf : 
buf : __setup("reset_devices", set_reset_devices);
buf : 
buf : static const char * argv_init[MAX_INIT_ARGS+2] = { "init", NULL, };
buf : const char * envp_init[MAX_INIT_ENVS+2] = { "HOME=/", "TERM=linux", NULL, };
buf : static const char *panic_later, *panic_param;
buf : 
buf : extern const struct obs_kernel_param __setup_start[], __setup_end[];
buf : 
buf : static int __init obsolete_checksetup(char *line)
buf : {
buf : 	const struct obs_kernel_param *p;
buf : 	int had_early_param = 0;
buf : 
buf : 	p = __setup_start;
buf : 	do {
buf : 		int n = strlen(p->str);
buf : 		if (parameqn(line, p->str, n)) {
if (parameqn(line, p->str, n)) { 
buf : 			if (p->early) {
buf : 				/* Already done in parse_early_param?
buf : 				 * (Needs exact match on param part).
buf : 				 * Keep iterating, as we can have early
buf : 				 * params and __setups of same names 8( */
buf : 				if (line[n] == '\0' || line[n] == '=')
if (line[n] == '\0' || line[n] == '=') 
buf : 					had_early_param = 1;
buf : 			} else if (!p->setup_func) {
if (!p->setup_func) { 
buf : 				pr_warn("Parameter %s is obsolete, ignored\n",
buf : 					p->str);
buf : 				return 1;
buf : 			} else if (p->setup_func(line + n))
if (p->setup_func(line + n)) 
buf : 				return 1;
buf : 		}
buf : 		p++;
buf : 	} while (p < __setup_end);
while (p < __setup_end); 
buf : 
buf : 	return had_early_param;
buf : }
buf : 
buf : /*
buf :  * This should be approx 2 Bo*oMips to start (note initial shift), and will
ift), and will 
buf :  * still work even if initially too large, it will just take slightly longer
buf :  */
buf : unsigned long loops_per_jiffy = (1<<12);
iffy = (1<<12); 
buf : 
buf : EXPORT_SYMBOL(loops_per_jiffy);
buf : 
buf : static int __init debug_kernel(char *str)
buf : {
buf : 	console_loglevel = CONSOLE_LOGLEVEL_DEBUG;
buf : 	return 0;
buf : }
buf : 
buf : static int __init quiet_kernel(char *str)
buf : {
buf : 	console_loglevel = CONSOLE_LOGLEVEL_QUIET;
buf : 	return 0;
buf : }
buf : 
buf : early_param("debug", debug_kernel);
buf : early_param("quiet", quiet_kernel);
buf : 
buf : static int __init loglevel(char *str)
buf : {
buf : 	int newlevel;
buf : 
buf : 	/*
buf : 	 * Only update loglevel value when a correct setting was passed,
buf : 	 * to prevent blind crashes (when loglevel being set to 0) that
buf : 	 * are quite hard to debug
buf : 	 */
buf : 	if (get_option(&str, &newlevel)) {
if (get_option(&str, &newlevel)) { 
buf : 		console_loglevel = newlevel;
buf : 		return 0;
buf : 	}
buf : 
buf : 	return -EINVAL;
buf : }
buf : 
buf : early_param("loglevel", loglevel);
buf : 
buf : /* Change NUL term back to "=", to make "param" the whole string. */
buf : static int __init repair_env_string(char *param, char *val, const char *unused)
buf : {
buf : 	if (val) {
if (val) { 
buf : 		/* param=val or param="val"? */
buf : 		if (val == param+strlen(param)+1)
if (val == param+strlen(param)+1) 
buf : 			val[-1] = '=';
buf : 		else if (val == param+strlen(param)+2) {
if (val == param+strlen(param)+2) { 
buf : 			val[-2] = '=';
buf : 			memmove(val-1, val, strlen(val)+1);
buf : 			val--;
buf : 		} else
buf : 			BUG();
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : /* Anything after -- gets handed straight to init. */
buf : static int __init set_init_arg(char *param, char *val, const char *unused)
buf : {
buf : 	unsigned int i;
buf : 
buf : 	if (panic_later)
if (panic_later) 
buf : 		return 0;
buf : 
buf : 	repair_env_string(param, val, unused);
buf : 
buf : 	for (i = 0; argv_init[i]; i++) {
for (i = 0; argv_init[i]; i++) { 
buf : 		if (i == MAX_INIT_ARGS) {
buf : 			panic_later = "init";
buf : 			panic_param = param;
buf : 			return 0;
buf : 		}
buf : 	}
buf : 	argv_init[i] = param;
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * Unknown boot options get handed to init, unless they look like
buf :  * unused parameters (modprobe will find them in /proc/cmdline).
buf :  */
buf : static int __init unknown_bootoption(char *param, char *val, const char *unused)
buf : {
buf : 	repair_env_string(param, val, unused);
buf : 
buf : 	/* Handle obsolete-style parameters */
buf : 	if (obsolete_checksetup(param))
if (obsolete_checksetup(param)) 
buf : 		return 0;
buf : 
buf : 	/* Unused module parameter. */
buf : 	if (strchr(param, '.') && (!val || strchr(param, '.') < val))
if (strchr(param, '.') && (!val || strchr(param, '.') < val)) 
buf : 		return 0;
buf : 
buf : 	if (panic_later)
if (panic_later) 
buf : 		return 0;
buf : 
buf : 	if (val) {
if (val) { 
buf : 		/* Environment option */
buf : 		unsigned int i;
buf : 		for (i = 0; envp_init[i]; i++) {
for (i = 0; envp_init[i]; i++) { 
buf : 			if (i == MAX_INIT_ENVS) {
buf : 				panic_later = "env";
buf : 				panic_param = param;
buf : 			}
buf : 			if (!strncmp(param, envp_init[i], val - param))
if (!strncmp(param, envp_init[i], val - param)) 
buf : 				break;
buf : 		}
buf : 		envp_init[i] = param;
buf : 	} else {
buf : 		/* Command line option */
buf : 		unsigned int i;
buf : 		for (i = 0; argv_init[i]; i++) {
for (i = 0; argv_init[i]; i++) { 
buf : 			if (i == MAX_INIT_ARGS) {
buf : 				panic_later = "init";
buf : 				panic_param = param;
buf : 			}
buf : 		}
buf : 		argv_init[i] = param;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static int __init init_setup(char *str)
buf : {
buf : 	unsigned int i;
buf : 
buf : 	execute_command = str;
buf : 	/*
buf : 	 * In case LILO is going to boot us with default command line,
buf : 	 * it prepends "auto" before the whole cmdline which makes
fore the whole cmdline which makes 
buf : 	 * the shell think it should execute a script with such name.
buf : 	 * So we ignore all arguments entered _before_ init=... [MJ]
fore_ init=... [MJ] 
buf : 	 */
buf : 	for (i = 1; i < MAX_INIT_ARGS; i++)
for (i = 1; i < MAX_INIT_ARGS; i++) 
buf : 		argv_init[i] = NULL;
buf : 	return 1;
buf : }
buf : __setup("init=", init_setup);
buf : 
buf : static int __init rdinit_setup(char *str)
buf : {
buf : 	unsigned int i;
buf : 
buf : 	ramdisk_execute_command = str;
buf : 	/* See "auto" comment in init_setup */
buf : 	for (i = 1; i < MAX_INIT_ARGS; i++)
for (i = 1; i < MAX_INIT_ARGS; i++) 
buf : 		argv_init[i] = NULL;
buf : 	return 1;
buf : }
buf : __setup("rdinit=", rdinit_setup);
buf : 
buf : #ifndef CONFIG_SMP
ifndef CONFIG_SMP 
buf : static const unsigned int setup_max_cpus = NR_CPUS;
buf : #ifdef CONFIG_X86_LOCAL_APIC
ifdef CONFIG_X86_LOCAL_APIC 
buf : static void __init smp_init(void)
buf : {
buf : 	APIC_init_uniprocessor();
buf : }
buf : #else
buf : #define smp_init()	do { } while (0)
while (0) 
buf : #endif
buf : 
buf : static inline void setup_nr_cpu_ids(void) { }
buf : static inline void smp_prepare_cpus(unsigned int maxcpus) { }
buf : #endif
if 
buf : 
buf : /*
buf :  * We need to store the untouched command line for future reference.
for future reference. 
buf :  * We also need to store the touched command line since the parameter
buf :  * parsing is performed in place, and we should allow a component to
formed in place, and we should allow a component to 
buf :  * store reference of name/value for future reference.
buf :  */
buf : static void __init setup_command_line(char *command_line)
buf : {
buf : 	saved_command_line =
buf : 		memblock_virt_alloc(strlen(boot_command_line) + 1, 0);
buf : 	initcall_command_line =
buf : 		memblock_virt_alloc(strlen(boot_command_line) + 1, 0);
buf : 	static_command_line = memblock_virt_alloc(strlen(command_line) + 1, 0);
buf : 	strcpy (saved_command_line, boot_command_line);
buf : 	strcpy (static_command_line, command_line);
buf : }
buf : 
buf : /*
buf :  * We need to finalize in a non-__init function or else race conditions
buf :  * between the root thread and the init thread may cause start_kernel to
buf :  * be reaped by free_initmem before the root thread has proceeded to
fore the root thread has proceeded to 
buf :  * cpu_idle.
buf :  *
buf :  * gcc-3.4 accidentally inlines this function, so use noinline.
buf :  */
buf : 
buf : static __initdata DECLARE_COMPLETION(kthreadd_done);
buf : 
buf : static noinline void __init_refok rest_init(void)
buf : {
buf : 	int pid;
buf : 
buf : 	rcu_scheduler_starting();
buf : 	/*
buf : 	 * We need to spawn init first so that it obtains pid 1, however
buf : 	 * the init task will end up wanting to create kthreads, which, if
if 
buf : 	 * we schedule it before we create kthreadd, will OOPS.
fore we create kthreadd, will OOPS. 
buf : 	 */
buf : 	kernel_thread(kernel_init, NULL, CLONE_FS);
buf : 	numa_default_policy();
buf : 	pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);
buf : 	rcu_read_lock();
buf : 	kthreadd_task = find_task_by_pid_ns(pid, &init_pid_ns);
buf : 	rcu_read_unlock();
buf : 	complete(&kthreadd_done);
buf : 
buf : 	/*
buf : 	 * The boot idle thread must execute schedule()
buf : 	 * at least once to get things moving:
buf : 	 */
buf : 	init_idle_bootup_task(current);
buf : 	schedule_preempt_disabled();
buf : 	/* Call into cpu_idle with preempt disabled */
buf : 	cpu_startup_entry(CPUHP_ONLINE);
buf : }
buf : 
buf : /* Check for early params. */
for early params. */ 
buf : static int __init do_early_param(char *param, char *val, const char *unused)
buf : {
buf : 	const struct obs_kernel_param *p;
buf : 
buf : 	for (p = __setup_start; p < __setup_end; p++) {
for (p = __setup_start; p < __setup_end; p++) { 
buf : 		if ((p->early && parameq(param, p->str)) ||
buf : 		    (strcmp(param, "console") == 0 &&
buf : 		     strcmp(p->str, "earlycon") == 0)
buf : 		) {
buf : 			if (p->setup_func(val) != 0)
if (p->setup_func(val) != 0) 
buf : 				pr_warn("Malformed early option '%s'\n", param);
formed early option '%s'\n", param); 
buf : 		}
buf : 	}
buf : 	/* We accept everything at this stage. */
buf : 	return 0;
buf : }
buf : 
buf : void __init parse_early_options(char *cmdline)
buf : {
buf : 	parse_args("early options", cmdline, NULL, 0, 0, 0, do_early_param);
buf : }
buf : 
buf : /* Arch code calls this early on, or if not, just before other parsing. */
if not, just before other parsing. */ 
buf : void __init parse_early_param(void)
buf : {
buf : 	static __initdata int done = 0;
buf : 	static __initdata char tmp_cmdline[COMMAND_LINE_SIZE];
buf : 
buf : 	if (done)
if (done) 
buf : 		return;
buf : 
buf : 	/* All fall through to do_early_param. */
buf : 	strlcpy(tmp_cmdline, boot_command_line, COMMAND_LINE_SIZE);
buf : 	parse_early_options(tmp_cmdline);
buf : 	done = 1;
buf : }
buf : 
buf : /*
buf :  *	Activate the first processor.
buf :  */
buf : 
buf : static void __init boot_cpu_init(void)
buf : {
buf : 	int cpu = smp_processor_id();
buf : 	/* Mark the boot cpu "present", "online" etc for SMP and UP case */
for SMP and UP case */ 
buf : 	set_cpu_online(cpu, true);
buf : 	set_cpu_active(cpu, true);
buf : 	set_cpu_present(cpu, true);
buf : 	set_cpu_possible(cpu, true);
buf : }
buf : 
buf : void __init __weak smp_setup_processor_id(void)
buf : {
buf : }
buf : 
buf : # if THREAD_SIZE >= PAGE_SIZE
if THREAD_SIZE >= PAGE_SIZE 
buf : void __init __weak thread_info_cache_init(void)
buf : {
buf : }
buf : #endif
if 
buf : 
buf : /*
buf :  * Set up kernel memory allocators
buf :  */
buf : static void __init mm_init(void)
buf : {
buf : 	/*
buf : 	 * page_cgroup requires contiguous pages,
buf : 	 * bigger than MAX_ORDER unless SPARSEMEM.
buf : 	 */
buf : 	page_cgroup_init_flatmem();
buf : 	mem_init();
buf : 	kmem_cache_init();
buf : 	percpu_init_late();
buf : 	pgtable_init();
buf : 	vmalloc_init();
buf : }
buf : 
buf : asmlinkage __visible void __init start_kernel(void)
buf : {
buf : 	char * command_line, *after_dashes;
buf : 	extern const struct kernel_param __start___param[], __stop___param[];
buf : 
buf : 	/*
buf : 	 * Need to run as early as possible, to initialize the
buf : 	 * lockdep hash:
buf : 	 */
buf : 	lockdep_init();
buf : 	smp_setup_processor_id();
buf : 	debug_objects_early_init();
buf : 
buf : 	/*
buf : 	 * Set up the the initial canary ASAP:
buf : 	 */
buf : 	boot_init_stack_canary();
buf : 
buf : 	cgroup_init_early();
buf : 
buf : 	local_irq_disable();
buf : 	early_boot_irqs_disabled = true;
buf : 
buf : /*
buf :  * Interrupts are still disabled. Do necessary setups, then
buf :  * enable them
buf :  */
buf : 	boot_cpu_init();
buf : 	page_address_init();
buf : 	pr_notice("%s", linux_banner);
buf : 	setup_arch(&command_line);
buf : 	mm_init_cpumask(&init_mm);
buf : 	setup_command_line(command_line);
buf : 	setup_nr_cpu_ids();
buf : 	setup_per_cpu_areas();
buf : 	smp_prepare_boot_cpu();	/* arch-specific boot-cpu hooks */
ific boot-cpu hooks */ 
buf : 
buf : 	build_all_zonelists(NULL, NULL);
buf : 	page_alloc_init();
buf : 
buf : 	pr_notice("Kernel command line: %s\n", boot_command_line);
buf : 	parse_early_param();
buf : 	after_dashes = parse_args("Booting kernel",
buf : 				  static_command_line, __start___param,
buf : 				  __stop___param - __start___param,
buf : 				  -1, -1, &unknown_bootoption);
buf : 	if (after_dashes)
if (after_dashes) 
buf : 		parse_args("Setting init args", after_dashes, NULL, 0, -1, -1,
buf : 			   set_init_arg);
buf : 
buf : 	jump_label_init();
buf : 
buf : 	/*
buf : 	 * These use large bootmem allocations and must precede
buf : 	 * kmem_cache_init()
buf : 	 */
buf : 	setup_log_buf(0);
buf : 	pidhash_init();
buf : 	vfs_caches_init_early();
buf : 	sort_main_extable();
buf : 	trap_init();
buf : 	mm_init();
buf : 
buf : 	/*
buf : 	 * Set up the scheduler prior starting any interrupts (such as the
buf : 	 * timer interrupt). Full topology setup happens at smp_init()
buf : 	 * time - but meanwhile we still have a functioning scheduler.
while we still have a functioning scheduler. 
buf : 	 */
buf : 	sched_init();
buf : 	/*
buf : 	 * Disable preemption - early bootup scheduling is extremely
buf : 	 * fragile until we cpu_idle() for the first time.
for the first time. 
buf : 	 */
buf : 	preempt_disable();
buf : 	if (WARN(!irqs_disabled(), "Interrupts were enabled *very* early, fixing it\n"))
if (WARN(!irqs_disabled(), "Interrupts were enabled *very* early, fixing it\n")) 
buf : 		local_irq_disable();
buf : 	idr_init_cache();
buf : 	rcu_init();
buf : 	tick_nohz_init();
buf : 	context_tracking_init();
buf : 	radix_tree_init();
buf : 	/* init some links before init_ISA_irqs() */
fore init_ISA_irqs() */ 
buf : 	early_irq_init();
buf : 	init_IRQ();
buf : 	tick_init();
buf : 	init_timers();
buf : 	hrtimers_init();
buf : 	softirq_init();
buf : 	timekeeping_init();
buf : 	time_init();
buf : 	sched_clock_postinit();
buf : 	perf_event_init();
buf : 	profile_init();
buf : 	call_function_init();
buf : 	WARN(!irqs_disabled(), "Interrupts were enabled early\n");
buf : 	early_boot_irqs_disabled = false;
buf : 	local_irq_enable();
buf : 
buf : 	kmem_cache_init_late();
buf : 
buf : 	/*
buf : 	 * HACK ALERT! This is early. We're enabling the console before
fore 
buf : 	 * we've done PCI setups etc, and console_init() must be aware of
buf : 	 * this. But we do want output early, in case something goes wrong.
buf : 	 */
buf : 	console_init();
buf : 	if (panic_later)
if (panic_later) 
buf : 		panic("Too many boot %s vars at `%s'", panic_later,
buf : 		      panic_param);
buf : 
buf : 	lockdep_info();
buf : 
buf : 	/*
buf : 	 * Need to run this when irqs are enabled, because it wants
buf : 	 * to self-test [hard/soft]-irqs on/off lock inversion bugs
buf : 	 * too:
buf : 	 */
buf : 	locking_selftest();
buf : 
buf : #ifdef CONFIG_BLK_DEV_INITRD
ifdef CONFIG_BLK_DEV_INITRD 
buf : 	if (initrd_start && !initrd_below_start_ok &&
buf : 	    page_to_pfn(virt_to_page((void *)initrd_start)) < min_low_pfn) {
buf : 		pr_crit("initrd overwritten (0x%08lx < 0x%08lx) - disabling it.\n",
buf : 		    page_to_pfn(virt_to_page((void *)initrd_start)),
buf : 		    min_low_pfn);
buf : 		initrd_start = 0;
buf : 	}
buf : #endif
if 
buf : 	page_cgroup_init();
buf : 	debug_objects_mem_init();
buf : 	kmemleak_init();
buf : 	setup_per_cpu_pageset();
buf : 	numa_policy_init();
buf : 	if (late_time_init)
if (late_time_init) 
buf : 		late_time_init();
buf : 	sched_clock_init();
buf : 	calibrate_delay();
buf : 	pidmap_init();
buf : 	anon_vma_init();
buf : 	acpi_early_init();
buf : #ifdef CONFIG_X86
ifdef CONFIG_X86 
buf : 	if (efi_enabled(EFI_RUNTIME_SERVICES))
buf : 		efi_enter_virtual_mode();
buf : #endif
if 
buf : #ifdef CONFIG_X86_ESPFIX64
buf : 	/* Should be run before the first non-init thread is created */
fore the first non-init thread is created */ 
buf : 	init_espfix_bsp();
buf : #endif
if 
buf : 	thread_info_cache_init();
buf : 	cred_init();
buf : 	fork_init(totalram_pages);
fork_init(totalram_pages); 
buf : 	proc_caches_init();
buf : 	buffer_init();
buf : 	key_init();
buf : 	security_init();
buf : 	dbg_late_init();
buf : 	vfs_caches_init(totalram_pages);
buf : 	signals_init();
buf : 	/* rootfs populating might need page-writeback */
buf : 	page_writeback_init();
buf : 	proc_root_init();
buf : 	cgroup_init();
buf : 	cpuset_init();
buf : 	taskstats_init_early();
buf : 	delayacct_init();
buf : 
buf : 	check_bugs();
buf : 
buf : 	sfi_init_late();
buf : 
buf : 	if (efi_enabled(EFI_RUNTIME_SERVICES)) {
if (efi_enabled(EFI_RUNTIME_SERVICES)) { 
buf : 		efi_late_init();
buf : 		efi_free_boot_services();
buf : 	}
buf : 
buf : 	ftrace_init();
buf : 
buf : 	/* Do the rest non-__init'ed, we're now alive */
buf : 	rest_init();
buf : }
buf : 
buf : /* Call all constructor functions linked into the kernel. */
buf : static void __init do_ctors(void)
buf : {
buf : #ifdef CONFIG_CONSTRUCTORS
ifdef CONFIG_CONSTRUCTORS 
buf : 	ctor_fn_t *fn = (ctor_fn_t *) __ctors_start;
buf : 
buf : 	for (; fn < (ctor_fn_t *) __ctors_end; fn++)
for (; fn < (ctor_fn_t *) __ctors_end; fn++) 
buf : 		(*fn)();
buf : #endif
if 
buf : }
buf : 
buf : bool initcall_debug;
buf : core_param(initcall_debug, initcall_debug, bool, 0644);
buf : 
buf : #ifdef CONFIG_KALLSYMS
ifdef CONFIG_KALLSYMS 
buf : struct blacklist_entry {
buf : 	struct list_head next;
buf : 	char *buf;
buf : };
buf : 
buf : static __initdata_or_module LIST_HEAD(blacklisted_initcalls);
buf : 
buf : static int __init initcall_blacklist(char *str)
buf : {
buf : 	char *str_entry;
buf : 	struct blacklist_entry *entry;
buf : 
buf : 	/* str argument is a comma-separated list of functions */
buf : 	do {
buf : 		str_entry = strsep(&str, ",");
buf : 		if (str_entry) {
if (str_entry) { 
buf : 			pr_debug("blacklisting initcall %s\n", str_entry);
buf : 			entry = alloc_bootmem(sizeof(*entry));
buf : 			entry->buf = alloc_bootmem(strlen(str_entry) + 1);
buf : 			strcpy(entry->buf, str_entry);
buf : 			list_add(&entry->next, &blacklisted_initcalls);
buf : 		}
buf : 	} while (str_entry);
while (str_entry); 
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static bool __init_or_module initcall_blacklisted(initcall_t fn)
buf : {
buf : 	struct list_head *tmp;
buf : 	struct blacklist_entry *entry;
buf : 	char *fn_name;
buf : 
buf : 	fn_name = kasprintf(GFP_KERNEL, "%pf", fn);
buf : 	if (!fn_name)
if (!fn_name) 
buf : 		return false;
buf : 
buf : 	list_for_each(tmp, &blacklisted_initcalls) {
for_each(tmp, &blacklisted_initcalls) { 
buf : 		entry = list_entry(tmp, struct blacklist_entry, next);
buf : 		if (!strcmp(fn_name, entry->buf)) {
if (!strcmp(fn_name, entry->buf)) { 
buf : 			pr_debug("initcall %s blacklisted\n", fn_name);
buf : 			kfree(fn_name);
buf : 			return true;
buf : 		}
buf : 	}
buf : 
buf : 	kfree(fn_name);
buf : 	return false;
buf : }
buf : #else
buf : static int __init initcall_blacklist(char *str)
buf : {
buf : 	pr_warn("initcall_blacklist requires CONFIG_KALLSYMS\n");
buf : 	return 0;
buf : }
buf : 
buf : static bool __init_or_module initcall_blacklisted(initcall_t fn)
buf : {
buf : 	return false;
buf : }
buf : #endif
if 
buf : __setup("initcall_blacklist=", initcall_blacklist);
buf : 
buf : static int __init_or_module do_one_initcall_debug(initcall_t fn)
buf : {
buf : 	ktime_t calltime, delta, rettime;
buf : 	unsigned long long duration;
buf : 	int ret;
buf : 
buf : 	printk(KERN_DEBUG "calling  %pF @ %i\n", fn, task_pid_nr(current));
buf : 	calltime = ktime_get();
buf : 	ret = fn();
buf : 	rettime = ktime_get();
buf : 	delta = ktime_sub(rettime, calltime);
buf : 	duration = (unsigned long long) ktime_to_ns(delta) >> 10;
buf : 	printk(KERN_DEBUG "initcall %pF returned %d after %lld usecs\n",
buf : 		 fn, ret, duration);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : int __init_or_module do_one_initcall(initcall_t fn)
buf : {
buf : 	int count = preempt_count();
buf : 	int ret;
buf : 	char msgbuf[64];
buf : 
buf : 	if (initcall_blacklisted(fn))
if (initcall_blacklisted(fn)) 
buf : 		return -EPERM;
buf : 
buf : 	if (initcall_debug)
if (initcall_debug) 
buf : 		ret = do_one_initcall_debug(fn);
buf : 	else
buf : 		ret = fn();
buf : 
buf : 	msgbuf[0] = 0;
buf : 
buf : 	if (preempt_count() != count) {
if (preempt_count() != count) { 
buf : 		sprintf(msgbuf, "preemption imbalance ");
buf : 		preempt_count_set(count);
buf : 	}
buf : 	if (irqs_disabled()) {
if (irqs_disabled()) { 
buf : 		strlcat(msgbuf, "disabled interrupts ", sizeof(msgbuf));
buf : 		local_irq_enable();
buf : 	}
buf : 	WARN(msgbuf[0], "initcall %pF returned with %s\n", fn, msgbuf);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : 
buf : extern initcall_t __initcall_start[];
buf : extern initcall_t __initcall0_start[];
buf : extern initcall_t __initcall1_start[];
buf : extern initcall_t __initcall2_start[];
buf : extern initcall_t __initcall3_start[];
buf : extern initcall_t __initcall4_start[];
buf : extern initcall_t __initcall5_start[];
buf : extern initcall_t __initcall6_start[];
buf : extern initcall_t __initcall7_start[];
buf : extern initcall_t __initcall_end[];
buf : 
buf : static initcall_t *initcall_levels[] __initdata = {
buf : 	__initcall0_start,
buf : 	__initcall1_start,
buf : 	__initcall2_start,
buf : 	__initcall3_start,
buf : 	__initcall4_start,
buf : 	__initcall5_start,
buf : 	__initcall6_start,
buf : 	__initcall7_start,
buf : 	__initcall_end,
buf : };
buf : 
buf : /* Keep these in sync with initcalls in include/linux/init.h */
buf : static char *initcall_level_names[] __initdata = {
buf : 	"early",
buf : 	"core",
buf : 	"postcore",
buf : 	"arch",
buf : 	"subsys",
buf : 	"fs",
buf : 	"device",
buf : 	"late",
buf : };
buf : 
buf : static void __init do_initcall_level(int level)
buf : {
buf : 	extern const struct kernel_param __start___param[], __stop___param[];
buf : 	initcall_t *fn;
buf : 
buf : 	strcpy(initcall_command_line, saved_command_line);
buf : 	parse_args(initcall_level_names[level],
buf : 		   initcall_command_line, __start___param,
buf : 		   __stop___param - __start___param,
buf : 		   level, level,
buf : 		   &repair_env_string);
buf : 
buf : 	for (fn = initcall_levels[level]; fn < initcall_levels[level+1]; fn++)
for (fn = initcall_levels[level]; fn < initcall_levels[level+1]; fn++) 
buf : 		do_one_initcall(*fn);
buf : }
buf : 
buf : static void __init do_initcalls(void)
buf : {
buf : 	int level;
buf : 
buf : 	for (level = 0; level < ARRAY_SIZE(initcall_levels) - 1; level++)
for (level = 0; level < ARRAY_SIZE(initcall_levels) - 1; level++) 
buf : 		do_initcall_level(level);
buf : }
buf : 
buf : /*
buf :  * Ok, the machine is now initialized. None of the devices
buf :  * have been touched yet, but the CPU subsystem is up and
buf :  * running, and memory and process management works.
buf :  *
buf :  * Now we can finally start doing some real work..
buf :  */
buf : static void __init do_basic_setup(void)
buf : {
buf : 	cpuset_init_smp();
buf : 	usermodehelper_init();
buf : 	shmem_init();
buf : 	driver_init();
buf : 	init_irq_proc();
buf : 	do_ctors();
buf : 	usermodehelper_enable();
buf : 	do_initcalls();
buf : 	random_int_secret_init();
buf : }
buf : 
buf : static void __init do_pre_smp_initcalls(void)
buf : {
buf : 	initcall_t *fn;
buf : 
buf : 	for (fn = __initcall_start; fn < __initcall0_start; fn++)
for (fn = __initcall_start; fn < __initcall0_start; fn++) 
buf : 		do_one_initcall(*fn);
buf : }
buf : 
buf : /*
buf :  * This function requests modules which should be loaded by default and is
buf :  * called twice right after initrd is mounted and right before init is
fore init is 
buf :  * exec'd.  If such modules are on either initrd or rootfs, they will be
buf :  * loaded before control is passed to userland.
fore control is passed to userland. 
buf :  */
buf : void __init load_default_modules(void)
buf : {
buf : 	load_default_elevator_module();
buf : }
buf : 
buf : static int run_init_process(const char *init_filename)
buf : {
buf : 	argv_init[0] = init_filename;
buf : 	return do_execve(getname_kernel(init_filename),
buf : 		(const char __user *const __user *)argv_init,
buf : 		(const char __user *const __user *)envp_init);
buf : }
buf : 
buf : static int try_to_run_init_process(const char *init_filename)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = run_init_process(init_filename);
buf : 
buf : 	if (ret && ret != -ENOENT) {
if (ret && ret != -ENOENT) { 
buf : 		pr_err("Starting init: %s exists but couldn't execute it (error %d)\n",
buf : 		       init_filename, ret);
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static noinline void __init kernel_init_freeable(void);
buf : 
buf : static int __ref kernel_init(void *unused)
buf : {
buf : 	int ret;
buf : 
buf : 	kernel_init_freeable();
buf : 	/* need to finish all async __init code before freeing the memory */
fore freeing the memory */ 
buf : 	async_synchronize_full();
buf : 	free_initmem();
buf : 	mark_rodata_ro();
buf : 	system_state = SYSTEM_RUNNING;
buf : 	numa_default_policy();
buf : 
buf : 	flush_delayed_fput();
buf : 
buf : 	if (ramdisk_execute_command) {
if (ramdisk_execute_command) { 
buf : 		ret = run_init_process(ramdisk_execute_command);
buf : 		if (!ret)
if (!ret) 
buf : 			return 0;
buf : 		pr_err("Failed to execute %s (error %d)\n",
buf : 		       ramdisk_execute_command, ret);
buf : 	}
buf : 
buf : 	/*
buf : 	 * We try each of these until one succeeds.
buf : 	 *
buf : 	 * The Bourne shell can be used instead of init if we are
if we are 
buf : 	 * trying to recover a really broken machine.
buf : 	 */
buf : 	if (execute_command) {
if (execute_command) { 
buf : 		ret = run_init_process(execute_command);
buf : 		if (!ret)
if (!ret) 
buf : 			return 0;
buf : 		pr_err("Failed to execute %s (error %d).  Attempting defaults...\n",
buf : 			execute_command, ret);
buf : 	}
buf : 	if (!try_to_run_init_process("/sbin/init") ||
if (!try_to_run_init_process("/sbin/init") || 
buf : 	    !try_to_run_init_process("/etc/init") ||
buf : 	    !try_to_run_init_process("/bin/init") ||
buf : 	    !try_to_run_init_process("/bin/sh"))
buf : 		return 0;
buf : 
buf : 	panic("No working init found.  Try passing init= option to kernel. "
buf : 	      "See Linux Documentation/init.txt for guidance.");
for guidance."); 
buf : }
buf : 
buf : static noinline void __init kernel_init_freeable(void)
buf : {
buf : 	/*
buf : 	 * Wait until kthreadd is all set-up.
buf : 	 */
buf : 	wait_for_completion(&kthreadd_done);
for_completion(&kthreadd_done); 
buf : 
buf : 	/* Now the scheduler is fully set up and can do blocking allocations */
buf : 	gfp_allowed_mask = __GFP_BITS_MASK;
buf : 
buf : 	/*
buf : 	 * init can allocate pages on any node
buf : 	 */
buf : 	set_mems_allowed(node_states[N_MEMORY]);
buf : 	/*
buf : 	 * init can run on any cpu.
buf : 	 */
buf : 	set_cpus_allowed_ptr(current, cpu_all_mask);
buf : 
buf : 	cad_pid = task_pid(current);
buf : 
buf : 	smp_prepare_cpus(setup_max_cpus);
buf : 
buf : 	do_pre_smp_initcalls();
buf : 	lockup_detector_init();
buf : 
buf : 	smp_init();
buf : 	sched_init_smp();
buf : 
buf : 	do_basic_setup();
buf : 
buf : 	/* Open the /dev/console on the rootfs, this should never fail */
buf : 	if (sys_open((const char __user *) "/dev/console", O_RDWR, 0) < 0)
if (sys_open((const char __user *) "/dev/console", O_RDWR, 0) < 0) 
buf : 		pr_err("Warning: unable to open an initial console.\n");
buf : 
buf : 	(void) sys_dup(0);
buf : 	(void) sys_dup(0);
buf : 	/*
buf : 	 * check if there is an early userspace init.  If yes, let it do all
if there is an early userspace init.  If yes, let it do all 
buf : 	 * the work
buf : 	 */
buf : 
buf : 	if (!ramdisk_execute_command)
if (!ramdisk_execute_command) 
buf : 		ramdisk_execute_command = "/init";
buf : 
buf : 	if (sys_access((const char __user *) ramdisk_execute_command, 0) != 0) {
if (sys_access((const char __user *) ramdisk_execute_command, 0) != 0) { 
buf : 		ramdisk_execute_command = NULL;
buf : 		prepare_namespace();
buf : 	}
buf : 
buf : 	/*
buf : 	 * Ok, we have completed the initial bootup, and
buf : 	 * we're essentially up and running. Get rid of the
buf : 	 * initmem segments and start the user-mode stuff..
buf : 	 */
buf : 
buf : 	/* rootfs is available now, try loading default modules */
buf : 	load_default_modules();
buf : }
file : ./test/kernel/arch/x86/kernel/cpu/mtrr/main.c 
[ OK ] open : 4 ok... 
buf : /*  Generic MTRR (Memory Type Range Register) driver.
buf : 
buf :     Copyright (C) 1997-2000  Richard Gooch
buf :     Copyright (c) 2002	     Patrick Mochel
buf : 
buf :     This library is free software; you can redistribute it and/or
buf :     modify it under the terms of the GNU Library General Public
ify it under the terms of the GNU Library General Public 
buf :     License as published by the Free Software Foundation; either
buf :     version 2 of the License, or (at your option) any later version.
buf : 
buf :     This library is distributed in the hope that it will be useful,
buf :     but WITHOUT ANY WARRANTY; without even the implied warranty of
buf :     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
buf :     Library General Public License for more details.
for more details. 
buf : 
buf :     You should have received a copy of the GNU Library General Public
buf :     License along with this library; if not, write to the Free
if not, write to the Free 
buf :     Software Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
buf : 
buf :     Richard Gooch may be reached by email at  rgooch@atnf.csiro.au
buf :     The postal address is:
buf :       Richard Gooch, c/o ATNF, P. O. Box 76, Epping, N.S.W., 2121, Australia.
buf : 
buf :     Source: "Pentium Pro Family Developer's Manual, Volume 3:
buf :     Operating System Writer's Guide" (Intel document number 242692),
buf :     section 11.11.7
buf : 
buf :     This was cleaned and made readable by Patrick Mochel <mochel@osdl.org>
buf :     on 6-7 March 2002.
buf :     Source: Intel Architecture Software Developers Manual, Volume 3:
buf :     System Programming Guide; Section 9.11. (1997 edition - PPro).
buf : */
buf : 
buf : #define DEBUG
buf : 
buf : #include <linux/types.h> /* FIXME: kvm_para.h needs this */
buf : 
buf : #include <linux/stop_machine.h>
buf : #include <linux/kvm_para.h>
buf : #include <linux/uaccess.h>
buf : #include <linux/module.h>
buf : #include <linux/mutex.h>
buf : #include <linux/init.h>
buf : #include <linux/sort.h>
buf : #include <linux/cpu.h>
buf : #include <linux/pci.h>
buf : #include <linux/smp.h>
buf : #include <linux/syscore_ops.h>
buf : 
buf : #include <asm/processor.h>
buf : #include <asm/e820.h>
buf : #include <asm/mtrr.h>
buf : #include <asm/msr.h>
buf : #include <asm/pat.h>
buf : 
buf : #include "mtrr.h"
buf : 
buf : /* arch_phys_wc_add returns an MTRR register index plus this offset. */
buf : #define MTRR_TO_PHYS_WC_OFFSET 1000
buf : 
buf : u32 num_var_ranges;
buf : 
buf : unsigned int mtrr_usage_table[MTRR_MAX_VAR_RANGES];
buf : static DEFINE_MUTEX(mtrr_mutex);
buf : 
buf : u64 size_or_mask, size_and_mask;
buf : static bool mtrr_aps_delayed_init;
buf : 
buf : static const struct mtrr_ops *mtrr_ops[X86_VENDOR_NUM];
buf : 
buf : const struct mtrr_ops *mtrr_if;
if; 
buf : 
buf : static void set_mtrr(unsigned int reg, unsigned long base,
buf : 		     unsigned long size, mtrr_type type);
buf : 
buf : void set_mtrr_ops(const struct mtrr_ops *ops)
buf : {
buf : 	if (ops->vendor && ops->vendor < X86_VENDOR_NUM)
if (ops->vendor && ops->vendor < X86_VENDOR_NUM) 
buf : 		mtrr_ops[ops->vendor] = ops;
buf : }
buf : 
buf : /*  Returns non-zero if we have the write-combining memory type  */
if we have the write-combining memory type  */ 
buf : static int have_wrcomb(void)
buf : {
buf : 	struct pci_dev *dev;
buf : 
buf : 	dev = pci_get_class(PCI_CLASS_BRIDGE_HOST << 8, NULL);
buf : 	if (dev != NULL) {
if (dev != NULL) { 
buf : 		/*
buf : 		 * ServerWorks LE chipsets < rev 6 have problems with
buf : 		 * write-combining. Don't allow it and leave room for other
for other 
buf : 		 * chipsets to be tagged
buf : 		 */
buf : 		if (dev->vendor == PCI_VENDOR_ID_SERVERWORKS &&
if (dev->vendor == PCI_VENDOR_ID_SERVERWORKS && 
buf : 		    dev->device == PCI_DEVICE_ID_SERVERWORKS_LE &&
buf : 		    dev->revision <= 5) {
buf : 			pr_info("mtrr: Serverworks LE rev < 6 detected. Write-combining disabled.\n");
buf : 			pci_dev_put(dev);
buf : 			return 0;
buf : 		}
buf : 		/*
buf : 		 * Intel 450NX errata # 23. Non ascending cacheline evictions to
buf : 		 * write combining memory may resulting in data corruption
buf : 		 */
buf : 		if (dev->vendor == PCI_VENDOR_ID_INTEL &&
if (dev->vendor == PCI_VENDOR_ID_INTEL && 
buf : 		    dev->device == PCI_DEVICE_ID_INTEL_82451NX) {
buf : 			pr_info("mtrr: Intel 450NX MMC detected. Write-combining disabled.\n");
buf : 			pci_dev_put(dev);
buf : 			return 0;
buf : 		}
buf : 		pci_dev_put(dev);
buf : 	}
buf : 	return mtrr_if->have_wrcomb ? mtrr_if->have_wrcomb() : 0;
if->have_wrcomb ? mtrr_if->have_wrcomb() : 0; 
buf : }
buf : 
buf : /*  This function returns the number of variable MTRRs  */
buf : static void __init set_num_var_ranges(void)
buf : {
buf : 	unsigned long config = 0, dummy;
buf : 
buf : 	if (use_intel())
if (use_intel()) 
buf : 		rdmsr(MSR_MTRRcap, config, dummy);
buf : 	else if (is_cpu(AMD))
if (is_cpu(AMD)) 
buf : 		config = 2;
buf : 	else if (is_cpu(CYRIX) || is_cpu(CENTAUR))
if (is_cpu(CYRIX) || is_cpu(CENTAUR)) 
buf : 		config = 8;
buf : 
buf : 	num_var_ranges = config & 0xff;
buf : }
buf : 
buf : static void __init init_table(void)
buf : {
buf : 	int i, max;
buf : 
buf : 	max = num_var_ranges;
buf : 	for (i = 0; i < max; i++)
for (i = 0; i < max; i++) 
buf : 		mtrr_usage_table[i] = 1;
buf : }
buf : 
buf : struct set_mtrr_data {
buf : 	unsigned long	smp_base;
buf : 	unsigned long	smp_size;
buf : 	unsigned int	smp_reg;
buf : 	mtrr_type	smp_type;
buf : };
buf : 
buf : /**
buf :  * mtrr_rendezvous_handler - Work done in the synchronization handler. Executed
buf :  * by all the CPUs.
buf :  * @info: pointer to mtrr configuration data
buf :  *
buf :  * Returns nothing.
buf :  */
buf : static int mtrr_rendezvous_handler(void *info)
buf : {
buf : 	struct set_mtrr_data *data = info;
buf : 
buf : 	/*
buf : 	 * We use this same function to initialize the mtrrs during boot,
buf : 	 * resume, runtime cpu online and on an explicit request to set a
buf : 	 * specific MTRR.
ific MTRR. 
buf : 	 *
buf : 	 * During boot or suspend, the state of the boot cpu's mtrrs has been
buf : 	 * saved, and we want to replicate that across all the cpus that come
buf : 	 * online (either at the end of boot or resume or during a runtime cpu
buf : 	 * online). If we're doing that, @reg is set to something special and on
buf : 	 * all the cpu's we do mtrr_if->set_all() (On the logical cpu that
if->set_all() (On the logical cpu that 
buf : 	 * started the boot/resume sequence, this might be a duplicate
buf : 	 * set_all()).
buf : 	 */
buf : 	if (data->smp_reg != ~0U) {
if (data->smp_reg != ~0U) { 
buf : 		mtrr_if->set(data->smp_reg, data->smp_base,
buf : 			     data->smp_size, data->smp_type);
buf : 	} else if (mtrr_aps_delayed_init || !cpu_online(smp_processor_id())) {
if (mtrr_aps_delayed_init || !cpu_online(smp_processor_id())) { 
buf : 		mtrr_if->set_all();
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static inline int types_compatible(mtrr_type type1, mtrr_type type2)
buf : {
buf : 	return type1 == MTRR_TYPE_UNCACHABLE ||
buf : 	       type2 == MTRR_TYPE_UNCACHABLE ||
buf : 	       (type1 == MTRR_TYPE_WRTHROUGH && type2 == MTRR_TYPE_WRBACK) ||
buf : 	       (type1 == MTRR_TYPE_WRBACK && type2 == MTRR_TYPE_WRTHROUGH);
buf : }
buf : 
buf : /**
buf :  * set_mtrr - update mtrrs on all processors
buf :  * @reg:	mtrr in question
buf :  * @base:	mtrr base
buf :  * @size:	mtrr size
buf :  * @type:	mtrr type
buf :  *
buf :  * This is kinda tricky, but fortunately, Intel spelled it out for us cleanly:
fortunately, Intel spelled it out for us cleanly: 
buf :  *
buf :  * 1. Queue work to do the following on all processors:
buf :  * 2. Disable Interrupts
buf :  * 3. Wait for all procs to do so
for all procs to do so 
buf :  * 4. Enter no-fill cache mode
buf :  * 5. Flush caches
buf :  * 6. Clear PGE bit
buf :  * 7. Flush all TLBs
buf :  * 8. Disable all range registers
buf :  * 9. Update the MTRRs
buf :  * 10. Enable all range registers
buf :  * 11. Flush all TLBs and caches again
buf :  * 12. Enter normal cache mode and reenable caching
buf :  * 13. Set PGE
buf :  * 14. Wait for buddies to catch up
for buddies to catch up 
buf :  * 15. Enable interrupts.
buf :  *
buf :  * What does that mean for us? Well, stop_machine() will ensure that
for us? Well, stop_machine() will ensure that 
buf :  * the rendezvous handler is started on each CPU. And in lockstep they
buf :  * do the state transition of disabling interrupts, updating MTRR's
buf :  * (the CPU vendors may each do it differently, so we call mtrr_if->set()
ifferently, so we call mtrr_if->set() 
buf :  * callback and let them take care of it.) and enabling interrupts.
buf :  *
buf :  * Note that the mechanism is the same for UP systems, too; all the SMP stuff
for UP systems, too; all the SMP stuff 
buf :  * becomes nops.
buf :  */
buf : static void
buf : set_mtrr(unsigned int reg, unsigned long base, unsigned long size, mtrr_type type)
buf : {
buf : 	struct set_mtrr_data data = { .smp_reg = reg,
buf : 				      .smp_base = base,
buf : 				      .smp_size = size,
buf : 				      .smp_type = type
buf : 				    };
buf : 
buf : 	stop_machine(mtrr_rendezvous_handler, &data, cpu_online_mask);
buf : }
buf : 
buf : static void set_mtrr_from_inactive_cpu(unsigned int reg, unsigned long base,
buf : 				      unsigned long size, mtrr_type type)
buf : {
buf : 	struct set_mtrr_data data = { .smp_reg = reg,
buf : 				      .smp_base = base,
buf : 				      .smp_size = size,
buf : 				      .smp_type = type
buf : 				    };
buf : 
buf : 	stop_machine_from_inactive_cpu(mtrr_rendezvous_handler, &data,
buf : 				       cpu_callout_mask);
buf : }
buf : 
buf : /**
buf :  * mtrr_add_page - Add a memory type region
buf :  * @base: Physical base address of region in pages (in units of 4 kB!)
buf :  * @size: Physical size of region in pages (4 kB)
buf :  * @type: Type of MTRR desired
buf :  * @increment: If this is true do usage counting on the region
buf :  *
buf :  * Memory type region registers control the caching on newer Intel and
buf :  * non Intel processors. This function allows drivers to request an
buf :  * MTRR is added. The details and hardware specifics of each processor's
ifics of each processor's 
buf :  * implementation are hidden from the caller, but nevertheless the
buf :  * caller should expect to need to provide a power of two size on an
buf :  * equivalent power of two boundary.
buf :  *
buf :  * If the region cannot be added either because all regions are in use
buf :  * or the CPU cannot support it a negative value is returned. On success
buf :  * the register number for this entry is returned, but should be treated
for this entry is returned, but should be treated 
buf :  * as a cookie only.
buf :  *
buf :  * On a multiprocessor machine the changes are made to all processors.
buf :  * This is required on x86 by the Intel processors.
buf :  *
buf :  * The available types are
buf :  *
buf :  * %MTRR_TYPE_UNCACHABLE - No caching
buf :  *
buf :  * %MTRR_TYPE_WRBACK - Write data back in bursts whenever
buf :  *
buf :  * %MTRR_TYPE_WRCOMB - Write data back soon but allow bursts
buf :  *
buf :  * %MTRR_TYPE_WRTHROUGH - Cache reads but not writes
buf :  *
buf :  * BUGS: Needs a quiet flag for the cases where drivers do not mind
for the cases where drivers do not mind 
buf :  * failures and do not wish system log messages to be sent.
buf :  */
buf : int mtrr_add_page(unsigned long base, unsigned long size,
buf : 		  unsigned int type, bool increment)
buf : {
buf : 	unsigned long lbase, lsize;
buf : 	int i, replace, error;
buf : 	mtrr_type ltype;
buf : 
buf : 	if (!mtrr_if)
if (!mtrr_if) 
buf : 		return -ENXIO;
buf : 
buf : 	error = mtrr_if->validate_add_page(base, size, type);
if->validate_add_page(base, size, type); 
buf : 	if (error)
buf : 		return error;
buf : 
buf : 	if (type >= MTRR_NUM_TYPES) {
if (type >= MTRR_NUM_TYPES) { 
buf : 		pr_warning("mtrr: type: %u invalid\n", type);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	/* If the type is WC, check that this processor supports it */
buf : 	if ((type == MTRR_TYPE_WRCOMB) && !have_wrcomb()) {
if ((type == MTRR_TYPE_WRCOMB) && !have_wrcomb()) { 
buf : 		pr_warning("mtrr: your processor doesn't support write-combining\n");
buf : 		return -ENOSYS;
buf : 	}
buf : 
buf : 	if (!size) {
if (!size) { 
buf : 		pr_warning("mtrr: zero sized request\n");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	if ((base | (base + size - 1)) >>
if ((base | (base + size - 1)) >> 
buf : 	    (boot_cpu_data.x86_phys_bits - PAGE_SHIFT)) {
buf : 		pr_warning("mtrr: base or size exceeds the MTRR width\n");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	error = -EINVAL;
buf : 	replace = -1;
buf : 
buf : 	/* No CPU hotplug when we change MTRR entries */
buf : 	get_online_cpus();
buf : 
buf : 	/* Search for existing MTRR  */
for existing MTRR  */ 
buf : 	mutex_lock(&mtrr_mutex);
buf : 	for (i = 0; i < num_var_ranges; ++i) {
for (i = 0; i < num_var_ranges; ++i) { 
buf : 		mtrr_if->get(i, &lbase, &lsize, &ltype);
buf : 		if (!lsize || base > lbase + lsize - 1 ||
if (!lsize || base > lbase + lsize - 1 || 
buf : 		    base + size - 1 < lbase)
buf : 			continue;
buf : 		/*
buf : 		 * At this point we know there is some kind of
buf : 		 * overlap/enclosure
buf : 		 */
buf : 		if (base < lbase || base + size - 1 > lbase + lsize - 1) {
if (base < lbase || base + size - 1 > lbase + lsize - 1) { 
buf : 			if (base <= lbase &&
buf : 			    base + size - 1 >= lbase + lsize - 1) {
buf : 				/*  New region encloses an existing region  */
buf : 				if (type == ltype) {
if (type == ltype) { 
buf : 					replace = replace == -1 ? i : -2;
buf : 					continue;
buf : 				} else if (types_compatible(type, ltype))
if (types_compatible(type, ltype)) 
buf : 					continue;
buf : 			}
buf : 			pr_warning("mtrr: 0x%lx000,0x%lx000 overlaps existing"
buf : 				" 0x%lx000,0x%lx000\n", base, size, lbase,
buf : 				lsize);
buf : 			goto out;
buf : 		}
buf : 		/* New region is enclosed by an existing region */
buf : 		if (ltype != type) {
if (ltype != type) { 
buf : 			if (types_compatible(type, ltype))
buf : 				continue;
buf : 			pr_warning("mtrr: type mismatch for %lx000,%lx000 old: %s new: %s\n",
for %lx000,%lx000 old: %s new: %s\n", 
buf : 				base, size, mtrr_attrib_to_str(ltype),
buf : 				mtrr_attrib_to_str(type));
buf : 			goto out;
buf : 		}
buf : 		if (increment)
if (increment) 
buf : 			++mtrr_usage_table[i];
buf : 		error = i;
buf : 		goto out;
buf : 	}
buf : 	/* Search for an empty MTRR */
for an empty MTRR */ 
buf : 	i = mtrr_if->get_free_region(base, size, replace);
buf : 	if (i >= 0) {
if (i >= 0) { 
buf : 		set_mtrr(i, base, size, type);
buf : 		if (likely(replace < 0)) {
if (likely(replace < 0)) { 
buf : 			mtrr_usage_table[i] = 1;
buf : 		} else {
buf : 			mtrr_usage_table[i] = mtrr_usage_table[replace];
buf : 			if (increment)
if (increment) 
buf : 				mtrr_usage_table[i]++;
buf : 			if (unlikely(replace != i)) {
if (unlikely(replace != i)) { 
buf : 				set_mtrr(replace, 0, 0, 0);
buf : 				mtrr_usage_table[replace] = 0;
buf : 			}
buf : 		}
buf : 	} else {
buf : 		pr_info("mtrr: no more MTRRs available\n");
buf : 	}
buf : 	error = i;
buf :  out:
buf : 	mutex_unlock(&mtrr_mutex);
buf : 	put_online_cpus();
buf : 	return error;
buf : }
buf : 
buf : static int mtrr_check(unsigned long base, unsigned long size)
buf : {
buf : 	if ((base & (PAGE_SIZE - 1)) || (size & (PAGE_SIZE - 1))) {
if ((base & (PAGE_SIZE - 1)) || (size & (PAGE_SIZE - 1))) { 
buf : 		pr_warning("mtrr: size and base must be multiples of 4 kiB\n");
buf : 		pr_debug("mtrr: size: 0x%lx  base: 0x%lx\n", size, base);
buf : 		dump_stack();
buf : 		return -1;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : /**
buf :  * mtrr_add - Add a memory type region
buf :  * @base: Physical base address of region
buf :  * @size: Physical size of region
buf :  * @type: Type of MTRR desired
buf :  * @increment: If this is true do usage counting on the region
buf :  *
buf :  * Memory type region registers control the caching on newer Intel and
buf :  * non Intel processors. This function allows drivers to request an
buf :  * MTRR is added. The details and hardware specifics of each processor's
ifics of each processor's 
buf :  * implementation are hidden from the caller, but nevertheless the
buf :  * caller should expect to need to provide a power of two size on an
buf :  * equivalent power of two boundary.
buf :  *
buf :  * If the region cannot be added either because all regions are in use
buf :  * or the CPU cannot support it a negative value is returned. On success
buf :  * the register number for this entry is returned, but should be treated
for this entry is returned, but should be treated 
buf :  * as a cookie only.
buf :  *
buf :  * On a multiprocessor machine the changes are made to all processors.
buf :  * This is required on x86 by the Intel processors.
buf :  *
buf :  * The available types are
buf :  *
buf :  * %MTRR_TYPE_UNCACHABLE - No caching
buf :  *
buf :  * %MTRR_TYPE_WRBACK - Write data back in bursts whenever
buf :  *
buf :  * %MTRR_TYPE_WRCOMB - Write data back soon but allow bursts
buf :  *
buf :  * %MTRR_TYPE_WRTHROUGH - Cache reads but not writes
buf :  *
buf :  * BUGS: Needs a quiet flag for the cases where drivers do not mind
for the cases where drivers do not mind 
buf :  * failures and do not wish system log messages to be sent.
buf :  */
buf : int mtrr_add(unsigned long base, unsigned long size, unsigned int type,
buf : 	     bool increment)
buf : {
buf : 	if (mtrr_check(base, size))
if (mtrr_check(base, size)) 
buf : 		return -EINVAL;
buf : 	return mtrr_add_page(base >> PAGE_SHIFT, size >> PAGE_SHIFT, type,
buf : 			     increment);
buf : }
buf : EXPORT_SYMBOL(mtrr_add);
buf : 
buf : /**
buf :  * mtrr_del_page - delete a memory type region
buf :  * @reg: Register returned by mtrr_add
buf :  * @base: Physical base address
buf :  * @size: Size of region
buf :  *
buf :  * If register is supplied then base and size are ignored. This is
buf :  * how drivers should call it.
buf :  *
buf :  * Releases an MTRR region. If the usage count drops to zero the
buf :  * register is freed and the region returns to default state.
buf :  * On success the register is returned, on failure a negative error
buf :  * code.
buf :  */
buf : int mtrr_del_page(int reg, unsigned long base, unsigned long size)
buf : {
buf : 	int i, max;
buf : 	mtrr_type ltype;
buf : 	unsigned long lbase, lsize;
buf : 	int error = -EINVAL;
buf : 
buf : 	if (!mtrr_if)
if (!mtrr_if) 
buf : 		return -ENXIO;
buf : 
buf : 	max = num_var_ranges;
buf : 	/* No CPU hotplug when we change MTRR entries */
buf : 	get_online_cpus();
buf : 	mutex_lock(&mtrr_mutex);
buf : 	if (reg < 0) {
if (reg < 0) { 
buf : 		/*  Search for existing MTRR  */
for existing MTRR  */ 
buf : 		for (i = 0; i < max; ++i) {
buf : 			mtrr_if->get(i, &lbase, &lsize, &ltype);
if->get(i, &lbase, &lsize, &ltype); 
buf : 			if (lbase == base && lsize == size) {
buf : 				reg = i;
buf : 				break;
buf : 			}
buf : 		}
buf : 		if (reg < 0) {
if (reg < 0) { 
buf : 			pr_debug("mtrr: no MTRR for %lx000,%lx000 found\n",
for %lx000,%lx000 found\n", 
buf : 				 base, size);
buf : 			goto out;
buf : 		}
buf : 	}
buf : 	if (reg >= max) {
if (reg >= max) { 
buf : 		pr_warning("mtrr: register: %d too big\n", reg);
buf : 		goto out;
buf : 	}
buf : 	mtrr_if->get(reg, &lbase, &lsize, &ltype);
if->get(reg, &lbase, &lsize, &ltype); 
buf : 	if (lsize < 1) {
buf : 		pr_warning("mtrr: MTRR %d not used\n", reg);
buf : 		goto out;
buf : 	}
buf : 	if (mtrr_usage_table[reg] < 1) {
if (mtrr_usage_table[reg] < 1) { 
buf : 		pr_warning("mtrr: reg: %d has count=0\n", reg);
buf : 		goto out;
buf : 	}
buf : 	if (--mtrr_usage_table[reg] < 1)
if (--mtrr_usage_table[reg] < 1) 
buf : 		set_mtrr(reg, 0, 0, 0);
buf : 	error = reg;
buf :  out:
buf : 	mutex_unlock(&mtrr_mutex);
buf : 	put_online_cpus();
buf : 	return error;
buf : }
buf : 
buf : /**
buf :  * mtrr_del - delete a memory type region
buf :  * @reg: Register returned by mtrr_add
buf :  * @base: Physical base address
buf :  * @size: Size of region
buf :  *
buf :  * If register is supplied then base and size are ignored. This is
buf :  * how drivers should call it.
buf :  *
buf :  * Releases an MTRR region. If the usage count drops to zero the
buf :  * register is freed and the region returns to default state.
buf :  * On success the register is returned, on failure a negative error
buf :  * code.
buf :  */
buf : int mtrr_del(int reg, unsigned long base, unsigned long size)
buf : {
buf : 	if (mtrr_check(base, size))
if (mtrr_check(base, size)) 
buf : 		return -EINVAL;
buf : 	return mtrr_del_page(reg, base >> PAGE_SHIFT, size >> PAGE_SHIFT);
buf : }
buf : EXPORT_SYMBOL(mtrr_del);
buf : 
buf : /**
buf :  * arch_phys_wc_add - add a WC MTRR and handle errors if PAT is unavailable
if PAT is unavailable 
buf :  * @base: Physical base address
buf :  * @size: Size of region
buf :  *
buf :  * If PAT is available, this does nothing.  If PAT is unavailable, it
buf :  * attempts to add a WC MTRR covering size bytes starting at base and
buf :  * logs an error if this fails.
if this fails. 
buf :  *
buf :  * Drivers must store the return value to pass to mtrr_del_wc_if_needed,
buf :  * but drivers should not try to interpret that return value.
buf :  */
buf : int arch_phys_wc_add(unsigned long base, unsigned long size)
buf : {
buf : 	int ret;
buf : 
buf : 	if (pat_enabled)
if (pat_enabled) 
buf : 		return 0;  /* Success!  (We don't need to do anything.) */
buf : 
buf : 	ret = mtrr_add(base, size, MTRR_TYPE_WRCOMB, true);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		pr_warn("Failed to add WC MTRR for [%p-%p]; performance may suffer.",
for [%p-%p]; performance may suffer.", 
buf : 			(void *)base, (void *)(base + size - 1));
buf : 		return ret;
buf : 	}
buf : 	return ret + MTRR_TO_PHYS_WC_OFFSET;
buf : }
buf : EXPORT_SYMBOL(arch_phys_wc_add);
buf : 
buf : /*
buf :  * arch_phys_wc_del - undoes arch_phys_wc_add
buf :  * @handle: Return value from arch_phys_wc_add
buf :  *
buf :  * This cleans up after mtrr_add_wc_if_needed.
if_needed. 
buf :  *
buf :  * The API guarantees that mtrr_del_wc_if_needed(error code) and
buf :  * mtrr_del_wc_if_needed(0) do nothing.
if_needed(0) do nothing. 
buf :  */
buf : void arch_phys_wc_del(int handle)
buf : {
buf : 	if (handle >= 1) {
if (handle >= 1) { 
buf : 		WARN_ON(handle < MTRR_TO_PHYS_WC_OFFSET);
buf : 		mtrr_del(handle - MTRR_TO_PHYS_WC_OFFSET, 0, 0);
buf : 	}
buf : }
buf : EXPORT_SYMBOL(arch_phys_wc_del);
buf : 
buf : /*
buf :  * phys_wc_to_mtrr_index - translates arch_phys_wc_add's return value
buf :  * @handle: Return value from arch_phys_wc_add
buf :  *
buf :  * This will turn the return value from arch_phys_wc_add into an mtrr
buf :  * index suitable for debugging.
for debugging. 
buf :  *
buf :  * Note: There is no legitimate use for this function, except possibly
buf :  * in printk line.  Alas there is an illegitimate use in some ancient
buf :  * drm ioctls.
buf :  */
buf : int phys_wc_to_mtrr_index(int handle)
buf : {
buf : 	if (handle < MTRR_TO_PHYS_WC_OFFSET)
if (handle < MTRR_TO_PHYS_WC_OFFSET) 
buf : 		return -1;
buf : 	else
buf : 		return handle - MTRR_TO_PHYS_WC_OFFSET;
buf : }
buf : EXPORT_SYMBOL_GPL(phys_wc_to_mtrr_index);
buf : 
buf : /*
buf :  * HACK ALERT!
buf :  * These should be called implicitly, but we can't yet until all the initcall
buf :  * stuff is done...
buf :  */
buf : static void __init init_ifs(void)
ifs(void) 
buf : {
buf : #ifndef CONFIG_X86_64
buf : 	amd_init_mtrr();
buf : 	cyrix_init_mtrr();
buf : 	centaur_init_mtrr();
buf : #endif
if 
buf : }
buf : 
buf : /* The suspend/resume methods are only for CPU without MTRR. CPU using generic
for CPU without MTRR. CPU using generic 
buf :  * MTRR driver doesn't require this
buf :  */
buf : struct mtrr_value {
buf : 	mtrr_type	ltype;
buf : 	unsigned long	lbase;
buf : 	unsigned long	lsize;
buf : };
buf : 
buf : static struct mtrr_value mtrr_value[MTRR_MAX_VAR_RANGES];
buf : 
buf : static int mtrr_save(void)
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 0; i < num_var_ranges; i++) {
for (i = 0; i < num_var_ranges; i++) { 
buf : 		mtrr_if->get(i, &mtrr_value[i].lbase,
buf : 				&mtrr_value[i].lsize,
buf : 				&mtrr_value[i].ltype);
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static void mtrr_restore(void)
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 0; i < num_var_ranges; i++) {
for (i = 0; i < num_var_ranges; i++) { 
buf : 		if (mtrr_value[i].lsize) {
buf : 			set_mtrr(i, mtrr_value[i].lbase,
buf : 				    mtrr_value[i].lsize,
buf : 				    mtrr_value[i].ltype);
buf : 		}
buf : 	}
buf : }
buf : 
buf : 
buf : 
buf : static struct syscore_ops mtrr_syscore_ops = {
buf : 	.suspend	= mtrr_save,
buf : 	.resume		= mtrr_restore,
buf : };
buf : 
buf : int __initdata changed_by_mtrr_cleanup;
buf : 
buf : #define SIZE_OR_MASK_BITS(n)  (~((1ULL << ((n) - PAGE_SHIFT)) - 1))
buf : /**
buf :  * mtrr_bp_init - initialize mtrrs on the boot CPU
buf :  *
buf :  * This needs to be called early; before any of the other CPUs are
fore any of the other CPUs are 
buf :  * initialized (i.e. before smp_init()).
buf :  *
buf :  */
buf : void __init mtrr_bp_init(void)
buf : {
buf : 	u32 phys_addr;
buf : 
buf : 	init_ifs();
ifs(); 
buf : 
buf : 	phys_addr = 32;
buf : 
buf : 	if (cpu_has_mtrr) {
if (cpu_has_mtrr) { 
buf : 		mtrr_if = &generic_mtrr_ops;
buf : 		size_or_mask = SIZE_OR_MASK_BITS(36);
buf : 		size_and_mask = 0x00f00000;
buf : 		phys_addr = 36;
buf : 
buf : 		/*
buf : 		 * This is an AMD specific MSR, but we assume(hope?) that
ific MSR, but we assume(hope?) that 
buf : 		 * Intel will implement it too when they extend the address
buf : 		 * bus of the Xeon.
buf : 		 */
buf : 		if (cpuid_eax(0x80000000) >= 0x80000008) {
if (cpuid_eax(0x80000000) >= 0x80000008) { 
buf : 			phys_addr = cpuid_eax(0x80000008) & 0xff;
buf : 			/* CPUID workaround for Intel 0F33/0F34 CPU */
for Intel 0F33/0F34 CPU */ 
buf : 			if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL &&
buf : 			    boot_cpu_data.x86 == 0xF &&
buf : 			    boot_cpu_data.x86_model == 0x3 &&
buf : 			    (boot_cpu_data.x86_mask == 0x3 ||
buf : 			     boot_cpu_data.x86_mask == 0x4))
buf : 				phys_addr = 36;
buf : 
buf : 			size_or_mask = SIZE_OR_MASK_BITS(phys_addr);
buf : 			size_and_mask = ~size_or_mask & 0xfffff00000ULL;
buf : 		} else if (boot_cpu_data.x86_vendor == X86_VENDOR_CENTAUR &&
if (boot_cpu_data.x86_vendor == X86_VENDOR_CENTAUR && 
buf : 			   boot_cpu_data.x86 == 6) {
buf : 			/*
buf : 			 * VIA C* family have Intel style MTRRs,
buf : 			 * but don't support PAE
buf : 			 */
buf : 			size_or_mask = SIZE_OR_MASK_BITS(32);
buf : 			size_and_mask = 0;
buf : 			phys_addr = 32;
buf : 		}
buf : 	} else {
buf : 		switch (boot_cpu_data.x86_vendor) {
buf : 		case X86_VENDOR_AMD:
buf : 			if (cpu_has_k6_mtrr) {
if (cpu_has_k6_mtrr) { 
buf : 				/* Pre-Athlon (K6) AMD CPU MTRRs */
buf : 				mtrr_if = mtrr_ops[X86_VENDOR_AMD];
if = mtrr_ops[X86_VENDOR_AMD]; 
buf : 				size_or_mask = SIZE_OR_MASK_BITS(32);
buf : 				size_and_mask = 0;
buf : 			}
buf : 			break;
buf : 		case X86_VENDOR_CENTAUR:
buf : 			if (cpu_has_centaur_mcr) {
if (cpu_has_centaur_mcr) { 
buf : 				mtrr_if = mtrr_ops[X86_VENDOR_CENTAUR];
buf : 				size_or_mask = SIZE_OR_MASK_BITS(32);
buf : 				size_and_mask = 0;
buf : 			}
buf : 			break;
buf : 		case X86_VENDOR_CYRIX:
buf : 			if (cpu_has_cyrix_arr) {
if (cpu_has_cyrix_arr) { 
buf : 				mtrr_if = mtrr_ops[X86_VENDOR_CYRIX];
buf : 				size_or_mask = SIZE_OR_MASK_BITS(32);
buf : 				size_and_mask = 0;
buf : 			}
buf : 			break;
buf : 		default:
buf : 			break;
buf : 		}
buf : 	}
buf : 
buf : 	if (mtrr_if) {
if (mtrr_if) { 
buf : 		set_num_var_ranges();
buf : 		init_table();
buf : 		if (use_intel()) {
if (use_intel()) { 
buf : 			get_mtrr_state();
buf : 
buf : 			if (mtrr_cleanup(phys_addr)) {
if (mtrr_cleanup(phys_addr)) { 
buf : 				changed_by_mtrr_cleanup = 1;
buf : 				mtrr_if->set_all();
if->set_all(); 
buf : 			}
buf : 		}
buf : 	}
buf : }
buf : 
buf : void mtrr_ap_init(void)
buf : {
buf : 	if (!use_intel() || mtrr_aps_delayed_init)
if (!use_intel() || mtrr_aps_delayed_init) 
buf : 		return;
buf : 	/*
buf : 	 * Ideally we should hold mtrr_mutex here to avoid mtrr entries
buf : 	 * changed, but this routine will be called in cpu boot time,
buf : 	 * holding the lock breaks it.
buf : 	 *
buf : 	 * This routine is called in two cases:
buf : 	 *
buf : 	 *   1. very earily time of software resume, when there absolutely
buf : 	 *      isn't mtrr entry changes;
buf : 	 *
buf : 	 *   2. cpu hotadd time. We let mtrr_add/del_page hold cpuhotplug
buf : 	 *      lock to prevent mtrr entry changes
buf : 	 */
buf : 	set_mtrr_from_inactive_cpu(~0U, 0, 0, 0);
buf : }
buf : 
buf : /**
buf :  * Save current fixed-range MTRR state of the first cpu in cpu_online_mask.
buf :  */
buf : void mtrr_save_state(void)
buf : {
buf : 	int first_cpu;
buf : 
buf : 	get_online_cpus();
buf : 	first_cpu = cpumask_first(cpu_online_mask);
buf : 	smp_call_function_single(first_cpu, mtrr_save_fixed_ranges, NULL, 1);
buf : 	put_online_cpus();
buf : }
buf : 
buf : void set_mtrr_aps_delayed_init(void)
buf : {
buf : 	if (!use_intel())
if (!use_intel()) 
buf : 		return;
buf : 
buf : 	mtrr_aps_delayed_init = true;
buf : }
buf : 
buf : /*
buf :  * Delayed MTRR initialization for all AP's
for all AP's 
buf :  */
buf : void mtrr_aps_init(void)
buf : {
buf : 	if (!use_intel())
if (!use_intel()) 
buf : 		return;
buf : 
buf : 	/*
buf : 	 * Check if someone has requested the delay of AP MTRR initialization,
if someone has requested the delay of AP MTRR initialization, 
buf : 	 * by doing set_mtrr_aps_delayed_init(), prior to this point. If not,
buf : 	 * then we are done.
buf : 	 */
buf : 	if (!mtrr_aps_delayed_init)
if (!mtrr_aps_delayed_init) 
buf : 		return;
buf : 
buf : 	set_mtrr(~0U, 0, 0, 0);
buf : 	mtrr_aps_delayed_init = false;
buf : }
buf : 
buf : void mtrr_bp_restore(void)
buf : {
buf : 	if (!use_intel())
if (!use_intel()) 
buf : 		return;
buf : 
buf : 	mtrr_if->set_all();
if->set_all(); 
buf : }
buf : 
buf : static int __init mtrr_init_finialize(void)
buf : {
buf : 	if (!mtrr_if)
if (!mtrr_if) 
buf : 		return 0;
buf : 
buf : 	if (use_intel()) {
if (use_intel()) { 
buf : 		if (!changed_by_mtrr_cleanup)
buf : 			mtrr_state_warn();
buf : 		return 0;
buf : 	}
buf : 
buf : 	/*
buf : 	 * The CPU has no MTRR and seems to not support SMP. They have
buf : 	 * specific drivers, we use a tricky method to support
ific drivers, we use a tricky method to support 
buf : 	 * suspend/resume for them.
for them. 
buf : 	 *
buf : 	 * TBD: is there any system with such CPU which supports
buf : 	 * suspend/resume? If no, we should remove the code.
buf : 	 */
buf : 	register_syscore_ops(&mtrr_syscore_ops);
buf : 
buf : 	return 0;
buf : }
buf : subsys_initcall(mtrr_init_finialize);
file : ./test/kernel/arch/x86/boot/main.c 
[ OK ] open : 4 ok... 
buf : /* -*- linux-c -*- ------------------------------------------------------- *
buf :  *
buf :  *   Copyright (C) 1991, 1992 Linus Torvalds
buf :  *   Copyright 2007 rPath, Inc. - All Rights Reserved
buf :  *   Copyright 2009 Intel Corporation; author H. Peter Anvin
buf :  *
buf :  *   This file is part of the Linux kernel, and is made available under
buf :  *   the terms of the GNU General Public License version 2.
buf :  *
buf :  * ----------------------------------------------------------------------- */
buf : 
buf : /*
buf :  * Main module for the real-mode kernel code
for the real-mode kernel code 
buf :  */
buf : 
buf : #include "boot.h"
buf : #include "string.h"
buf : 
buf : struct boot_params boot_params __attribute__((aligned(16)));
buf : 
buf : char *HEAP = _end;
buf : char *heap_end = _end;		/* Default end of heap = no heap */
buf : 
buf : /*
buf :  * Copy the header into the boot parameter block.  Since this
buf :  * screws up the old-style command line protocol, adjust by
buf :  * filling in the new-style command line pointer instead.
buf :  */
buf : 
buf : static void copy_boot_params(void)
buf : {
buf : 	struct old_cmdline {
buf : 		u16 cl_magic;
buf : 		u16 cl_offset;
buf : 	};
buf : 	const struct old_cmdline * const oldcmd =
buf : 		(const struct old_cmdline *)OLD_CL_ADDRESS;
buf : 
buf : 	BUILD_BUG_ON(sizeof boot_params != 4096);
buf : 	memcpy(&boot_params.hdr, &hdr, sizeof hdr);
buf : 
buf : 	if (!boot_params.hdr.cmd_line_ptr &&
if (!boot_params.hdr.cmd_line_ptr && 
buf : 	    oldcmd->cl_magic == OLD_CL_MAGIC) {
buf : 		/* Old-style command line protocol. */
buf : 		u16 cmdline_seg;
buf : 
buf : 		/* Figure out if the command line falls in the region
if the command line falls in the region 
buf : 		   of memory that an old kernel would have copied up
buf : 		   to 0x90000... */
buf : 		if (oldcmd->cl_offset < boot_params.hdr.setup_move_size)
if (oldcmd->cl_offset < boot_params.hdr.setup_move_size) 
buf : 			cmdline_seg = ds();
buf : 		else
buf : 			cmdline_seg = 0x9000;
buf : 
buf : 		boot_params.hdr.cmd_line_ptr =
buf : 			(cmdline_seg << 4) + oldcmd->cl_offset;
buf : 	}
buf : }
buf : 
buf : /*
buf :  * Query the keyboard lock status as given by the BIOS, and
buf :  * set the keyboard repeat rate to maximum.  Unclear why the latter
buf :  * is done here; this might be possible to kill off as stale code.
buf :  */
buf : static void keyboard_init(void)
buf : {
buf : 	struct biosregs ireg, oreg;
buf : 	initregs(&ireg);
buf : 
buf : 	ireg.ah = 0x02;		/* Get keyboard status */
buf : 	intcall(0x16, &ireg, &oreg);
buf : 	boot_params.kbd_status = oreg.al;
buf : 
buf : 	ireg.ax = 0x0305;	/* Set keyboard repeat rate */
buf : 	intcall(0x16, &ireg, NULL);
buf : }
buf : 
buf : /*
buf :  * Get Intel SpeedStep (IST) information.
formation. 
buf :  */
buf : static void query_ist(void)
buf : {
buf : 	struct biosregs ireg, oreg;
buf : 
buf : 	/* Some older BIOSes apparently crash on this call, so filter
buf : 	   it from machines too old to have SpeedStep at all. */
buf : 	if (cpu.level < 6)
if (cpu.level < 6) 
buf : 		return;
buf : 
buf : 	initregs(&ireg);
buf : 	ireg.ax  = 0xe980;	 /* IST Support */
buf : 	ireg.edx = 0x47534943;	 /* Request value */
buf : 	intcall(0x15, &ireg, &oreg);
buf : 
buf : 	boot_params.ist_info.signature  = oreg.eax;
buf : 	boot_params.ist_info.command    = oreg.ebx;
buf : 	boot_params.ist_info.event      = oreg.ecx;
buf : 	boot_params.ist_info.perf_level = oreg.edx;
buf : }
buf : 
buf : /*
buf :  * Tell the BIOS what CPU mode we intend to run in.
buf :  */
buf : static void set_bios_mode(void)
buf : {
buf : #ifdef CONFIG_X86_64
ifdef CONFIG_X86_64 
buf : 	struct biosregs ireg;
buf : 
buf : 	initregs(&ireg);
buf : 	ireg.ax = 0xec00;
buf : 	ireg.bx = 2;
buf : 	intcall(0x15, &ireg, NULL);
buf : #endif
if 
buf : }
buf : 
buf : static void init_heap(void)
buf : {
buf : 	char *stack_end;
buf : 
buf : 	if (boot_params.hdr.loadflags & CAN_USE_HEAP) {
if (boot_params.hdr.loadflags & CAN_USE_HEAP) { 
buf : 		asm("leal %P1(%%esp),%0"
buf : 		    : "=r" (stack_end) : "i" (-STACK_SIZE));
buf : 
buf : 		heap_end = (char *)
buf : 			((size_t)boot_params.hdr.heap_end_ptr + 0x200);
buf : 		if (heap_end > stack_end)
if (heap_end > stack_end) 
buf : 			heap_end = stack_end;
buf : 	} else {
buf : 		/* Boot protocol 2.00 only, no heap available */
buf : 		puts("WARNING: Ancient bootloader, some functionality "
buf : 		     "may be limited!\n");
buf : 	}
buf : }
buf : 
buf : void main(void)
buf : {
buf : 	/* First, copy the boot header into the "zeropage" */
buf : 	copy_boot_params();
buf : 
buf : 	/* Initialize the early-boot console */
buf : 	console_init();
buf : 	if (cmdline_find_option_bool("debug"))
if (cmdline_find_option_bool("debug")) 
buf : 		puts("early console in setup code\n");
buf : 
buf : 	/* End of heap check */
buf : 	init_heap();
buf : 
buf : 	/* Make sure we have all the proper CPU support */
buf : 	if (validate_cpu()) {
if (validate_cpu()) { 
buf : 		puts("Unable to boot - please use a kernel appropriate "
buf : 		     "for your CPU.\n");
for your CPU.\n"); 
buf : 		die();
buf : 	}
buf : 
buf : 	/* Tell the BIOS what CPU mode we intend to run in. */
buf : 	set_bios_mode();
buf : 
buf : 	/* Detect memory layout */
buf : 	detect_memory();
buf : 
buf : 	/* Set keyboard repeat rate (why?) and query the lock flags */
buf : 	keyboard_init();
buf : 
buf : 	/* Query MCA information */
formation */ 
buf : 	query_mca();
buf : 
buf : 	/* Query Intel SpeedStep (IST) information */
formation */ 
buf : 	query_ist();
buf : 
buf : 	/* Query APM information */
formation */ 
buf : #if defined(CONFIG_APM) || defined(CONFIG_APM_MODULE)
buf : 	query_apm_bios();
buf : #endif
if 
buf : 
buf : 	/* Query EDD information */
formation */ 
buf : #if defined(CONFIG_EDD) || defined(CONFIG_EDD_MODULE)
buf : 	query_edd();
buf : #endif
if 
buf : 
buf : 	/* Set the video mode */
buf : 	set_video();
buf : 
buf : 	/* Do the last things and invoke protected mode */
buf : 	go_to_protected_mode();
buf : }
file : ./test/kernel/arch/powerpc/boot/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (C) Paul Mackerras 1997.
buf :  *
buf :  * Updates for PPC64 by Todd Inglett, Dave Engebretsen & Peter Bergner.
for PPC64 by Todd Inglett, Dave Engebretsen & Peter Bergner. 
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of the GNU General Public License
ify it under the terms of the GNU General Public License 
buf :  * as published by the Free Software Foundation; either version
buf :  * 2 of the License, or (at your option) any later version.
buf :  */
buf : #include <stdarg.h>
buf : #include <stddef.h>
buf : #include "elf.h"
buf : #include "page.h"
buf : #include "string.h"
buf : #include "stdio.h"
buf : #include "ops.h"
buf : #include "gunzip_util.h"
buf : #include "reg.h"
buf : 
buf : static struct gunzip_state gzstate;
buf : 
buf : struct addr_range {
buf : 	void *addr;
buf : 	unsigned long size;
buf : };
buf : 
buf : #undef DEBUG
buf : 
buf : static struct addr_range prep_kernel(void)
buf : {
buf : 	char elfheader[256];
buf : 	void *vmlinuz_addr = _vmlinux_start;
buf : 	unsigned long vmlinuz_size = _vmlinux_end - _vmlinux_start;
buf : 	void *addr = 0;
buf : 	struct elf_info ei;
buf : 	int len;
buf : 
buf : 	/* gunzip the ELF header of the kernel */
buf : 	gunzip_start(&gzstate, vmlinuz_addr, vmlinuz_size);
buf : 	gunzip_exactly(&gzstate, elfheader, sizeof(elfheader));
buf : 
buf : 	if (!parse_elf64(elfheader, &ei) && !parse_elf32(elfheader, &ei))
if (!parse_elf64(elfheader, &ei) && !parse_elf32(elfheader, &ei)) 
buf : 		fatal("Error: not a valid PPC32 or PPC64 ELF file!\n\r");
buf : 
buf : 	if (platform_ops.image_hdr)
if (platform_ops.image_hdr) 
buf : 		platform_ops.image_hdr(elfheader);
form_ops.image_hdr(elfheader); 
buf : 
buf : 	/* We need to alloc the memsize: gzip will expand the kernel
buf : 	 * text/data, then possible rubbish we don't care about. But
buf : 	 * the kernel bss must be claimed (it will be zero'd by the
buf : 	 * kernel itself)
buf : 	 */
buf : 	printf("Allocating 0x%lx bytes for kernel ...\n\r", ei.memsize);
for kernel ...\n\r", ei.memsize); 
buf : 
buf : 	if (platform_ops.vmlinux_alloc) {
buf : 		addr = platform_ops.vmlinux_alloc(ei.memsize);
form_ops.vmlinux_alloc(ei.memsize); 
buf : 	} else {
buf : 		/*
buf : 		 * Check if the kernel image (without bss) would overwrite the
if the kernel image (without bss) would overwrite the 
buf : 		 * bootwrapper. The device tree has been moved in fdt_init()
buf : 		 * to an area allocated with malloc() (somewhere past _end).
buf : 		 */
buf : 		if ((unsigned long)_start < ei.loadsize)
if ((unsigned long)_start < ei.loadsize) 
buf : 			fatal("Insufficient memory for kernel at address 0!"
for kernel at address 0!" 
buf : 			       " (_start=%p, uncompressed size=%08lx)\n\r",
buf : 			       _start, ei.loadsize);
buf : 
buf : 		if ((unsigned long)_end < ei.memsize)
if ((unsigned long)_end < ei.memsize) 
buf : 			fatal("The final kernel image would overwrite the "
buf : 					"device tree\n\r");
buf : 	}
buf : 
buf : 	/* Finally, gunzip the kernel */
buf : 	printf("gunzipping (0x%p <- 0x%p:0x%p)...", addr,
buf : 	       vmlinuz_addr, vmlinuz_addr+vmlinuz_size);
buf : 	/* discard up to the actual load data */
buf : 	gunzip_discard(&gzstate, ei.elfoffset - sizeof(elfheader));
buf : 	len = gunzip_finish(&gzstate, addr, ei.loadsize);
buf : 	if (len != ei.loadsize)
if (len != ei.loadsize) 
buf : 		fatal("ran out of data!  only got 0x%x of 0x%lx bytes.\n\r",
buf : 				len, ei.loadsize);
buf : 	printf("done 0x%x bytes\n\r", len);
buf : 
buf : 	flush_cache(addr, ei.loadsize);
buf : 
buf : 	return (struct addr_range){addr, ei.memsize};
buf : }
buf : 
buf : static struct addr_range prep_initrd(struct addr_range vmlinux, void *chosen,
buf : 				     unsigned long initrd_addr,
buf : 				     unsigned long initrd_size)
buf : {
buf : 	/* If we have an image attached to us, it overrides anything
buf : 	 * supplied by the loader. */
buf : 	if (_initrd_end > _initrd_start) {
if (_initrd_end > _initrd_start) { 
buf : 		printf("Attached initrd image at 0x%p-0x%p\n\r",
buf : 		       _initrd_start, _initrd_end);
buf : 		initrd_addr = (unsigned long)_initrd_start;
buf : 		initrd_size = _initrd_end - _initrd_start;
buf : 	} else if (initrd_size > 0) {
if (initrd_size > 0) { 
buf : 		printf("Using loader supplied ramdisk at 0x%lx-0x%lx\n\r",
buf : 		       initrd_addr, initrd_addr + initrd_size);
buf : 	}
buf : 
buf : 	/* If there's no initrd at all, we're done */
buf : 	if (! initrd_size)
if (! initrd_size) 
buf : 		return (struct addr_range){0, 0};
buf : 
buf : 	/*
buf : 	 * If the initrd is too low it will be clobbered when the
buf : 	 * kernel relocates to its final location.  In this case,
buf : 	 * allocate a safer place and move it.
buf : 	 */
buf : 	if (initrd_addr < vmlinux.size) {
if (initrd_addr < vmlinux.size) { 
buf : 		void *old_addr = (void *)initrd_addr;
buf : 
buf : 		printf("Allocating 0x%lx bytes for initrd ...\n\r",
for initrd ...\n\r", 
buf : 		       initrd_size);
buf : 		initrd_addr = (unsigned long)malloc(initrd_size);
buf : 		if (! initrd_addr)
if (! initrd_addr) 
buf : 			fatal("Can't allocate memory for initial "
for initial " 
buf : 			       "ramdisk !\n\r");
buf : 		printf("Relocating initrd 0x%lx <- 0x%p (0x%lx bytes)\n\r",
buf : 		       initrd_addr, old_addr, initrd_size);
buf : 		memmove((void *)initrd_addr, old_addr, initrd_size);
buf : 	}
buf : 
buf : 	printf("initrd head: 0x%lx\n\r", *((unsigned long *)initrd_addr));
buf : 
buf : 	/* Tell the kernel initrd address via device tree */
buf : 	setprop_val(chosen, "linux,initrd-start", (u32)(initrd_addr));
buf : 	setprop_val(chosen, "linux,initrd-end", (u32)(initrd_addr+initrd_size));
buf : 
buf : 	return (struct addr_range){(void *)initrd_addr, initrd_size};
buf : }
buf : 
buf : /* A buffer that may be edited by tools operating on a zImage binary so as to
buf :  * edit the command line passed to vmlinux (by setting /chosen/bootargs).
buf :  * The buffer is put in it's own section so that tools may locate it easier.
buf :  */
buf : static char cmdline[BOOT_COMMAND_LINE_SIZE]
buf : 	__attribute__((__section__("__builtin_cmdline")));
buf : 
buf : static void prep_cmdline(void *chosen)
buf : {
buf : 	if (cmdline[0] == '\0')
if (cmdline[0] == '\0') 
buf : 		getprop(chosen, "bootargs", cmdline, BOOT_COMMAND_LINE_SIZE-1);
buf : 
buf : 	printf("\n\rLinux/PowerPC load: %s", cmdline);
buf : 	/* If possible, edit the command line */
buf : 	if (console_ops.edit_cmdline)
if (console_ops.edit_cmdline) 
buf : 		console_ops.edit_cmdline(cmdline, BOOT_COMMAND_LINE_SIZE);
buf : 	printf("\n\r");
buf : 
buf : 	/* Put the command line back into the devtree for the kernel */
for the kernel */ 
buf : 	setprop_str(chosen, "bootargs", cmdline);
buf : }
buf : 
buf : struct platform_ops platform_ops;
form_ops platform_ops; 
buf : struct dt_ops dt_ops;
buf : struct console_ops console_ops;
buf : struct loader_info loader_info;
buf : 
buf : void start(void)
buf : {
buf : 	struct addr_range vmlinux, initrd;
buf : 	kernel_entry_t kentry;
buf : 	unsigned long ft_addr = 0;
buf : 	void *chosen;
buf : 
buf : 	/* Do this first, because malloc() could clobber the loader's
buf : 	 * command line.  Only use the loader command line if a
if a 
buf : 	 * built-in command line wasn't set by an external tool */
buf : 	if ((loader_info.cmdline_len > 0) && (cmdline[0] == '\0'))
if ((loader_info.cmdline_len > 0) && (cmdline[0] == '\0')) 
buf : 		memmove(cmdline, loader_info.cmdline,
buf : 			min(loader_info.cmdline_len, BOOT_COMMAND_LINE_SIZE-1));
buf : 
buf : 	if (console_ops.open && (console_ops.open() < 0))
if (console_ops.open && (console_ops.open() < 0)) 
buf : 		exit();
buf : 	if (platform_ops.fixups)
if (platform_ops.fixups) 
buf : 		platform_ops.fixups();
form_ops.fixups(); 
buf : 
buf : 	printf("\n\rzImage starting: loaded at 0x%p (sp: 0x%p)\n\r",
buf : 	       _start, get_sp());
buf : 
buf : 	/* Ensure that the device tree has a /chosen node */
buf : 	chosen = finddevice("/chosen");
buf : 	if (!chosen)
if (!chosen) 
buf : 		chosen = create_node(NULL, "chosen");
buf : 
buf : 	vmlinux = prep_kernel();
buf : 	initrd = prep_initrd(vmlinux, chosen,
buf : 			     loader_info.initrd_addr, loader_info.initrd_size);
buf : 	prep_cmdline(chosen);
buf : 
buf : 	printf("Finalizing device tree...");
buf : 	if (dt_ops.finalize)
if (dt_ops.finalize) 
buf : 		ft_addr = dt_ops.finalize();
buf : 	if (ft_addr)
if (ft_addr) 
buf : 		printf(" flat tree at 0x%lx\n\r", ft_addr);
buf : 	else
buf : 		printf(" using OF tree (promptr=%p)\n\r", loader_info.promptr);
buf : 
buf : 	if (console_ops.close)
if (console_ops.close) 
buf : 		console_ops.close();
buf : 
buf : 	kentry = (kernel_entry_t) vmlinux.addr;
buf : 	if (ft_addr)
if (ft_addr) 
buf : 		kentry(ft_addr, 0, NULL);
buf : 	else
buf : 		kentry((unsigned long)initrd.addr, initrd.size,
buf : 		       loader_info.promptr);
buf : 
buf : 	/* console closed so printf in fatal below may not work */
buf : 	fatal("Error: Linux kernel returned to zImage boot wrapper!\n\r");
buf : }
file : ./test/kernel/arch/alpha/boot/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * arch/alpha/boot/main.c
buf :  *
buf :  * Copyright (C) 1994, 1995 Linus Torvalds
buf :  *
buf :  * This file is the bootloader for the Linux/AXP kernel
for the Linux/AXP kernel 
buf :  */
buf : #include <linux/kernel.h>
buf : #include <linux/slab.h>
buf : #include <linux/string.h>
buf : #include <generated/utsrelease.h>
buf : #include <linux/mm.h>
buf : 
buf : #include <asm/console.h>
buf : #include <asm/hwrpb.h>
buf : #include <asm/pgtable.h>
buf : 
buf : #include <stdarg.h>
buf : 
buf : #include "ksize.h"
buf : 
buf : extern int vsprintf(char *, const char *, va_list);
buf : extern unsigned long switch_to_osf_pal(unsigned long nr,
buf : 	struct pcb_struct * pcb_va, struct pcb_struct * pcb_pa,
buf : 	unsigned long *vptb);
buf : struct hwrpb_struct *hwrpb = INIT_HWRPB;
buf : static struct pcb_struct pcb_va[1];
buf : 
buf : /*
buf :  * Find a physical address of a virtual object..
buf :  *
buf :  * This is easy using the virtual page table address.
buf :  */
buf : 
buf : static inline void *
buf : find_pa(unsigned long *vptb, void *ptr)
buf : {
buf : 	unsigned long address = (unsigned long) ptr;
buf : 	unsigned long result;
buf : 
buf : 	result = vptb[address >> 13];
buf : 	result >>= 32;
buf : 	result <<= 13;
buf : 	result |= address & 0x1fff;
buf : 	return (void *) result;
buf : }	
buf : 
buf : /*
buf :  * This function moves into OSF/1 pal-code, and has a temporary
buf :  * PCB for that. The kernel proper should replace this PCB with
for that. The kernel proper should replace this PCB with 
buf :  * the real one as soon as possible.
buf :  *
buf :  * The page table muckery in here depends on the fact that the boot
buf :  * code has the L1 page table identity-map itself in the second PTE
buf :  * in the L1 page table. Thus the L1-page is virtually addressable
buf :  * itself (through three levels) at virtual address 0x200802000.
buf :  */
buf : 
buf : #define VPTB	((unsigned long *) 0x200000000)
buf : #define L1	((unsigned long *) 0x200802000)
buf : 
buf : void
buf : pal_init(void)
buf : {
buf : 	unsigned long i, rev;
buf : 	struct percpu_struct * percpu;
buf : 	struct pcb_struct * pcb_pa;
buf : 
buf : 	/* Create the dummy PCB.  */
buf : 	pcb_va->ksp = 0;
buf : 	pcb_va->usp = 0;
buf : 	pcb_va->ptbr = L1[1] >> 32;
buf : 	pcb_va->asn = 0;
buf : 	pcb_va->pcc = 0;
buf : 	pcb_va->unique = 0;
buf : 	pcb_va->flags = 1;
buf : 	pcb_va->res1 = 0;
buf : 	pcb_va->res2 = 0;
buf : 	pcb_pa = find_pa(VPTB, pcb_va);
buf : 
buf : 	/*
buf : 	 * a0 = 2 (OSF)
buf : 	 * a1 = return address, but we give the asm the vaddr of the PCB
buf : 	 * a2 = physical addr of PCB
buf : 	 * a3 = new virtual page table pointer
buf : 	 * a4 = KSP (but the asm sets it)
buf : 	 */
buf : 	srm_printk("Switching to OSF PAL-code .. ");
buf : 
buf : 	i = switch_to_osf_pal(2, pcb_va, pcb_pa, VPTB);
buf : 	if (i) {
if (i) { 
buf : 		srm_printk("failed, code %ld\n", i);
buf : 		__halt();
buf : 	}
buf : 
buf : 	percpu = (struct percpu_struct *)
buf : 		(INIT_HWRPB->processor_offset + (unsigned long) INIT_HWRPB);
buf : 	rev = percpu->pal_revision = percpu->palcode_avail[2];
buf : 
buf : 	srm_printk("Ok (rev %lx)\n", rev);
buf : 
buf : 	tbia(); /* do it directly in case we are SMP */
buf : }
buf : 
buf : static inline long openboot(void)
buf : {
buf : 	char bootdev[256];
buf : 	long result;
buf : 
buf : 	result = callback_getenv(ENV_BOOTED_DEV, bootdev, 255);
buf : 	if (result < 0)
if (result < 0) 
buf : 		return result;
buf : 	return callback_open(bootdev, result & 255);
buf : }
buf : 
buf : static inline long close(long dev)
buf : {
buf : 	return callback_close(dev);
buf : }
buf : 
buf : static inline long load(long dev, unsigned long addr, unsigned long count)
buf : {
buf : 	char bootfile[256];
buf : 	extern char _end;
buf : 	long result, boot_size = &_end - (char *) BOOT_ADDR;
buf : 
buf : 	result = callback_getenv(ENV_BOOTED_FILE, bootfile, 255);
buf : 	if (result < 0)
if (result < 0) 
buf : 		return result;
buf : 	result &= 255;
buf : 	bootfile[result] = '\0';
buf : 	if (result)
if (result) 
buf : 		srm_printk("Boot file specification (%s) not implemented\n",
buf : 		       bootfile);
buf : 	return callback_read(dev, count, (void *)addr, boot_size/512 + 1);
buf : }
buf : 
buf : /*
buf :  * Start the kernel.
buf :  */
buf : static void runkernel(void)
buf : {
buf : 	__asm__ __volatile__(
buf : 		"bis %1,%1,$30\n\t"
buf : 		"bis %0,%0,$26\n\t"
buf : 		"ret ($26)"
buf : 		: /* no outputs: it doesn't even return */
buf : 		: "r" (START_ADDR),
buf : 		  "r" (PAGE_SIZE + INIT_STACK));
buf : }
buf : 
buf : void start_kernel(void)
buf : {
buf : 	long i;
buf : 	long dev;
buf : 	int nbytes;
buf : 	char envval[256];
buf : 
buf : 	srm_printk("Linux/AXP bootloader for Linux " UTS_RELEASE "\n");
for Linux " UTS_RELEASE "\n"); 
buf : 	if (INIT_HWRPB->pagesize != 8192) {
buf : 		srm_printk("Expected 8kB pages, got %ldkB\n", INIT_HWRPB->pagesize >> 10);
buf : 		return;
buf : 	}
buf : 	pal_init();
buf : 	dev = openboot();
buf : 	if (dev < 0) {
if (dev < 0) { 
buf : 		srm_printk("Unable to open boot device: %016lx\n", dev);
buf : 		return;
buf : 	}
buf : 	dev &= 0xffffffff;
buf : 	srm_printk("Loading vmlinux ...");
buf : 	i = load(dev, START_ADDR, KERNEL_SIZE);
buf : 	close(dev);
buf : 	if (i != KERNEL_SIZE) {
if (i != KERNEL_SIZE) { 
buf : 		srm_printk("Failed (%lx)\n", i);
buf : 		return;
buf : 	}
buf : 
buf : 	nbytes = callback_getenv(ENV_BOOTED_OSFLAGS, envval, sizeof(envval));
buf : 	if (nbytes < 0) {
if (nbytes < 0) { 
buf : 		nbytes = 0;
buf : 	}
buf : 	envval[nbytes] = '\0';
buf : 	strcpy((char*)ZERO_PGE, envval);
buf : 
buf : 	srm_printk(" Ok\nNow booting the kernel\n");
buf : 	runkernel();
buf : 	for (i = 0 ; i < 0x100000000 ; i++)
for (i = 0 ; i < 0x100000000 ; i++) 
buf : 		/* nothing */;
buf : 	__halt();
buf : }
file : ./test/kernel/arch/um/os-Linux/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (C) 2000 - 2007 Jeff Dike (jdike@{addtoit,linux.intel}.com)
buf :  * Licensed under the GPL
buf :  */
buf : 
buf : #include <stdio.h>
buf : #include <stdlib.h>
buf : #include <unistd.h>
buf : #include <errno.h>
buf : #include <signal.h>
buf : #include <string.h>
buf : #include <sys/resource.h>
buf : #include <as-layout.h>
buf : #include <init.h>
buf : #include <kern_util.h>
buf : #include <os.h>
buf : #include <um_malloc.h>
buf : 
buf : #define PGD_BOUND (4 * 1024 * 1024)
buf : #define STACKSIZE (8 * 1024 * 1024)
buf : #define THREAD_NAME_LEN (256)
buf : 
buf : long elf_aux_hwcap;
buf : 
buf : static void set_stklim(void)
buf : {
buf : 	struct rlimit lim;
buf : 
buf : 	if (getrlimit(RLIMIT_STACK, &lim) < 0) {
if (getrlimit(RLIMIT_STACK, &lim) < 0) { 
buf : 		perror("getrlimit");
buf : 		exit(1);
buf : 	}
buf : 	if ((lim.rlim_cur == RLIM_INFINITY) || (lim.rlim_cur > STACKSIZE)) {
if ((lim.rlim_cur == RLIM_INFINITY) || (lim.rlim_cur > STACKSIZE)) { 
buf : 		lim.rlim_cur = STACKSIZE;
buf : 		if (setrlimit(RLIMIT_STACK, &lim) < 0) {
if (setrlimit(RLIMIT_STACK, &lim) < 0) { 
buf : 			perror("setrlimit");
buf : 			exit(1);
buf : 		}
buf : 	}
buf : }
buf : 
buf : static __init void do_uml_initcalls(void)
buf : {
buf : 	initcall_t *call;
buf : 
buf : 	call = &__uml_initcall_start;
buf : 	while (call < &__uml_initcall_end) {
while (call < &__uml_initcall_end) { 
buf : 		(*call)();
buf : 		call++;
buf : 	}
buf : }
buf : 
buf : static void last_ditch_exit(int sig)
buf : {
buf : 	uml_cleanup();
buf : 	exit(1);
buf : }
buf : 
buf : static void install_fatal_handler(int sig)
buf : {
buf : 	struct sigaction action;
buf : 
buf : 	/* All signals are enabled in this handler ... */
buf : 	sigemptyset(&action.sa_mask);
buf : 
buf : 	/*
buf : 	 * ... including the signal being handled, plus we want the
buf : 	 * handler reset to the default behavior, so that if an exit
if an exit 
buf : 	 * handler is hanging for some reason, the UML will just die
for some reason, the UML will just die 
buf : 	 * after this signal is sent a second time.
buf : 	 */
buf : 	action.sa_flags = SA_RESETHAND | SA_NODEFER;
buf : 	action.sa_restorer = NULL;
buf : 	action.sa_handler = last_ditch_exit;
buf : 	if (sigaction(sig, &action, NULL) < 0) {
if (sigaction(sig, &action, NULL) < 0) { 
buf : 		printf("failed to install handler for signal %d - errno = %d\n",
for signal %d - errno = %d\n", 
buf : 		       sig, errno);
buf : 		exit(1);
buf : 	}
buf : }
buf : 
buf : #define UML_LIB_PATH	":" OS_LIB_PATH "/uml"
buf : 
buf : static void setup_env_path(void)
buf : {
buf : 	char *new_path = NULL;
buf : 	char *old_path = NULL;
buf : 	int path_len = 0;
buf : 
buf : 	old_path = getenv("PATH");
buf : 	/*
buf : 	 * if no PATH variable is set or it has an empty value
if no PATH variable is set or it has an empty value 
buf : 	 * just use the default + /usr/lib/uml
buf : 	 */
buf : 	if (!old_path || (path_len = strlen(old_path)) == 0) {
if (!old_path || (path_len = strlen(old_path)) == 0) { 
buf : 		if (putenv("PATH=:/bin:/usr/bin/" UML_LIB_PATH))
buf : 			perror("couldn't putenv");
buf : 		return;
buf : 	}
buf : 
buf : 	/* append /usr/lib/uml to the existing path */
buf : 	path_len += strlen("PATH=" UML_LIB_PATH) + 1;
buf : 	new_path = malloc(path_len);
buf : 	if (!new_path) {
if (!new_path) { 
buf : 		perror("couldn't malloc to set a new PATH");
buf : 		return;
buf : 	}
buf : 	snprintf(new_path, path_len, "PATH=%s" UML_LIB_PATH, old_path);
buf : 	if (putenv(new_path)) {
if (putenv(new_path)) { 
buf : 		perror("couldn't putenv to set a new PATH");
buf : 		free(new_path);
buf : 	}
buf : }
buf : 
buf : extern void scan_elf_aux( char **envp);
buf : 
buf : int __init main(int argc, char **argv, char **envp)
buf : {
buf : 	char **new_argv;
buf : 	int ret, i, err;
buf : 
buf : 	set_stklim();
buf : 
buf : 	setup_env_path();
buf : 
buf : 	setsid();
buf : 
buf : 	new_argv = malloc((argc + 1) * sizeof(char *));
buf : 	if (new_argv == NULL) {
if (new_argv == NULL) { 
buf : 		perror("Mallocing argv");
buf : 		exit(1);
buf : 	}
buf : 	for (i = 0; i < argc; i++) {
for (i = 0; i < argc; i++) { 
buf : 		new_argv[i] = strdup(argv[i]);
buf : 		if (new_argv[i] == NULL) {
if (new_argv[i] == NULL) { 
buf : 			perror("Mallocing an arg");
buf : 			exit(1);
buf : 		}
buf : 	}
buf : 	new_argv[argc] = NULL;
buf : 
buf : 	/*
buf : 	 * Allow these signals to bring down a UML if all other
if all other 
buf : 	 * methods of control fail.
buf : 	 */
buf : 	install_fatal_handler(SIGINT);
buf : 	install_fatal_handler(SIGTERM);
buf : 
buf : #ifdef CONFIG_ARCH_REUSE_HOST_VSYSCALL_AREA
ifdef CONFIG_ARCH_REUSE_HOST_VSYSCALL_AREA 
buf : 	scan_elf_aux(envp);
buf : #endif
if 
buf : 
buf : 	do_uml_initcalls();
buf : 	change_sig(SIGPIPE, 0);
buf : 	ret = linux_main(argc, argv);
buf : 
buf : 	/*
buf : 	 * Disable SIGPROF - I have no idea why libc doesn't do this or turn
buf : 	 * off the profiling time, but UML dies with a SIGPROF just before
fore 
buf : 	 * exiting when profiling is active.
buf : 	 */
buf : 	change_sig(SIGPROF, 0);
buf : 
buf : 	/*
buf : 	 * This signal stuff used to be in the reboot case.  However,
buf : 	 * sometimes a SIGVTALRM can come in when we're halting (reproducably
buf : 	 * when writing out gcov information, presumably because that takes
formation, presumably because that takes 
buf : 	 * some time) and cause a segfault.
buf : 	 */
buf : 
buf : 	/* stop timers and set SIGVTALRM to be ignored */
buf : 	disable_timer();
buf : 
buf : 	/* disable SIGIO for the fds and set SIGIO to be ignored */
for the fds and set SIGIO to be ignored */ 
buf : 	err = deactivate_all_fds();
buf : 	if (err)
if (err) 
buf : 		printf("deactivate_all_fds failed, errno = %d\n", -err);
buf : 
buf : 	/*
buf : 	 * Let any pending signals fire now.  This ensures
buf : 	 * that they won't be delivered after the exec, when
buf : 	 * they are definitely not expected.
buf : 	 */
buf : 	unblock_signals();
buf : 
buf : 	/* Reboot */
buf : 	if (ret) {
if (ret) { 
buf : 		printf("\n");
buf : 		execvp(new_argv[0], new_argv);
buf : 		perror("Failed to exec kernel");
buf : 		ret = 1;
buf : 	}
buf : 	printf("\n");
buf : 	return uml_exitcode;
buf : }
buf : 
buf : extern void *__real_malloc(int);
buf : 
buf : void *__wrap_malloc(int size)
buf : {
buf : 	void *ret;
buf : 
buf : 	if (!kmalloc_ok)
if (!kmalloc_ok) 
buf : 		return __real_malloc(size);
buf : 	else if (size <= UM_KERN_PAGE_SIZE)
if (size <= UM_KERN_PAGE_SIZE) 
buf : 		/* finding contiguous pages can be hard*/
buf : 		ret = uml_kmalloc(size, UM_GFP_KERNEL);
buf : 	else ret = vmalloc(size);
buf : 
buf : 	/*
buf : 	 * glibc people insist that if malloc fails, errno should be
if malloc fails, errno should be 
buf : 	 * set by malloc as well. So we do.
buf : 	 */
buf : 	if (ret == NULL)
if (ret == NULL) 
buf : 		errno = ENOMEM;
buf : 
buf : 	return ret;
buf : }
buf : 
buf : void *__wrap_calloc(int n, int size)
buf : {
buf : 	void *ptr = __wrap_malloc(n * size);
buf : 
buf : 	if (ptr == NULL)
if (ptr == NULL) 
buf : 		return NULL;
buf : 	memset(ptr, 0, n * size);
buf : 	return ptr;
buf : }
buf : 
buf : extern void __real_free(void *);
buf : 
buf : extern unsigned long high_physmem;
buf : 
buf : void __wrap_free(void *ptr)
buf : {
buf : 	unsigned long addr = (unsigned long) ptr;
buf : 
buf : 	/*
buf : 	 * We need to know how the allocation happened, so it can be correctly
buf : 	 * freed.  This is done by seeing what region of memory the pointer is
buf : 	 * in -
buf : 	 * 	physical memory - kmalloc/kfree
buf : 	 *	kernel virtual memory - vmalloc/vfree
buf : 	 * 	anywhere else - malloc/free
buf : 	 * If kmalloc is not yet possible, then either high_physmem and/or
buf : 	 * end_vm are still 0 (as at startup), in which case we call free, or
buf : 	 * we have set them, but anyway addr has not been allocated from those
buf : 	 * areas. So, in both cases __real_free is called.
buf : 	 *
buf : 	 * CAN_KMALLOC is checked because it would be bad to free a buffer
buf : 	 * with kmalloc/vmalloc after they have been turned off during
buf : 	 * shutdown.
buf : 	 * XXX: However, we sometimes shutdown CAN_KMALLOC temporarily, so
buf : 	 * there is a possibility for memory leaks.
for memory leaks. 
buf : 	 */
buf : 
buf : 	if ((addr >= uml_physmem) && (addr < high_physmem)) {
if ((addr >= uml_physmem) && (addr < high_physmem)) { 
buf : 		if (kmalloc_ok)
buf : 			kfree(ptr);
buf : 	}
buf : 	else if ((addr >= start_vm) && (addr < end_vm)) {
if ((addr >= start_vm) && (addr < end_vm)) { 
buf : 		if (kmalloc_ok)
buf : 			vfree(ptr);
buf : 	}
buf : 	else __real_free(ptr);
buf : }
file : ./test/kernel/drivers/bcma/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Broadcom specific AMBA
ific AMBA 
buf :  * Bus subsystem
buf :  *
buf :  * Licensed under the GNU/GPL. See COPYING for details.
for details. 
buf :  */
buf : 
buf : #include "bcma_private.h"
buf : #include <linux/module.h>
buf : #include <linux/platform_device.h>
form_device.h> 
buf : #include <linux/bcma/bcma.h>
buf : #include <linux/slab.h>
buf : 
buf : MODULE_DESCRIPTION("Broadcom's specific AMBA driver");
ific AMBA driver"); 
buf : MODULE_LICENSE("GPL");
buf : 
buf : /* contains the number the next bus should get. */
buf : static unsigned int bcma_bus_next_num = 0;
buf : 
buf : /* bcma_buses_mutex locks the bcma_bus_next_num */
buf : static DEFINE_MUTEX(bcma_buses_mutex);
buf : 
buf : static int bcma_bus_match(struct device *dev, struct device_driver *drv);
buf : static int bcma_device_probe(struct device *dev);
buf : static int bcma_device_remove(struct device *dev);
buf : static int bcma_device_uevent(struct device *dev, struct kobj_uevent_env *env);
buf : 
buf : static ssize_t manuf_show(struct device *dev, struct device_attribute *attr, char *buf)
buf : {
buf : 	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
buf : 	return sprintf(buf, "0x%03X\n", core->id.manuf);
buf : }
buf : static DEVICE_ATTR_RO(manuf);
buf : 
buf : static ssize_t id_show(struct device *dev, struct device_attribute *attr, char *buf)
buf : {
buf : 	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
buf : 	return sprintf(buf, "0x%03X\n", core->id.id);
buf : }
buf : static DEVICE_ATTR_RO(id);
buf : 
buf : static ssize_t rev_show(struct device *dev, struct device_attribute *attr, char *buf)
buf : {
buf : 	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
buf : 	return sprintf(buf, "0x%02X\n", core->id.rev);
buf : }
buf : static DEVICE_ATTR_RO(rev);
buf : 
buf : static ssize_t class_show(struct device *dev, struct device_attribute *attr, char *buf)
buf : {
buf : 	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
buf : 	return sprintf(buf, "0x%X\n", core->id.class);
buf : }
buf : static DEVICE_ATTR_RO(class);
buf : 
buf : static struct attribute *bcma_device_attrs[] = {
buf : 	&dev_attr_manuf.attr,
buf : 	&dev_attr_id.attr,
buf : 	&dev_attr_rev.attr,
buf : 	&dev_attr_class.attr,
buf : 	NULL,
buf : };
buf : ATTRIBUTE_GROUPS(bcma_device);
buf : 
buf : static struct bus_type bcma_bus_type = {
buf : 	.name		= "bcma",
buf : 	.match		= bcma_bus_match,
buf : 	.probe		= bcma_device_probe,
buf : 	.remove		= bcma_device_remove,
buf : 	.uevent		= bcma_device_uevent,
buf : 	.dev_groups	= bcma_device_groups,
buf : };
buf : 
buf : static u16 bcma_cc_core_id(struct bcma_bus *bus)
buf : {
buf : 	if (bus->chipinfo.id == BCMA_CHIP_ID_BCM4706)
if (bus->chipinfo.id == BCMA_CHIP_ID_BCM4706) 
buf : 		return BCMA_CORE_4706_CHIPCOMMON;
buf : 	return BCMA_CORE_CHIPCOMMON;
buf : }
buf : 
buf : struct bcma_device *bcma_find_core_unit(struct bcma_bus *bus, u16 coreid,
buf : 					u8 unit)
buf : {
buf : 	struct bcma_device *core;
buf : 
buf : 	list_for_each_entry(core, &bus->cores, list) {
for_each_entry(core, &bus->cores, list) { 
buf : 		if (core->id.id == coreid && core->core_unit == unit)
buf : 			return core;
buf : 	}
buf : 	return NULL;
buf : }
buf : EXPORT_SYMBOL_GPL(bcma_find_core_unit);
buf : 
buf : bool bcma_wait_value(struct bcma_device *core, u16 reg, u32 mask, u32 value,
buf : 		     int timeout)
buf : {
buf : 	unsigned long deadline = jiffies + timeout;
iffies + timeout; 
buf : 	u32 val;
buf : 
buf : 	do {
buf : 		val = bcma_read32(core, reg);
buf : 		if ((val & mask) == value)
if ((val & mask) == value) 
buf : 			return true;
buf : 		cpu_relax();
buf : 		udelay(10);
buf : 	} while (!time_after_eq(jiffies, deadline));
iffies, deadline)); 
buf : 
buf : 	bcma_warn(core->bus, "Timeout waiting for register 0x%04X!\n", reg);
for register 0x%04X!\n", reg); 
buf : 
buf : 	return false;
buf : }
buf : 
buf : static void bcma_release_core_dev(struct device *dev)
buf : {
buf : 	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
buf : 	if (core->io_addr)
if (core->io_addr) 
buf : 		iounmap(core->io_addr);
buf : 	if (core->io_wrap)
if (core->io_wrap) 
buf : 		iounmap(core->io_wrap);
buf : 	kfree(core);
buf : }
buf : 
buf : static int bcma_register_cores(struct bcma_bus *bus)
buf : {
buf : 	struct bcma_device *core;
buf : 	int err, dev_id = 0;
buf : 
buf : 	list_for_each_entry(core, &bus->cores, list) {
for_each_entry(core, &bus->cores, list) { 
buf : 		/* We support that cores ourself */
buf : 		switch (core->id.id) {
buf : 		case BCMA_CORE_4706_CHIPCOMMON:
buf : 		case BCMA_CORE_CHIPCOMMON:
buf : 		case BCMA_CORE_PCI:
buf : 		case BCMA_CORE_PCIE:
buf : 		case BCMA_CORE_MIPS_74K:
buf : 		case BCMA_CORE_4706_MAC_GBIT_COMMON:
buf : 			continue;
buf : 		}
buf : 
buf : 		/* Only first GMAC core on BCM4706 is connected and working */
buf : 		if (core->id.id == BCMA_CORE_4706_MAC_GBIT &&
if (core->id.id == BCMA_CORE_4706_MAC_GBIT && 
buf : 		    core->core_unit > 0)
buf : 			continue;
buf : 
buf : 		core->dev.release = bcma_release_core_dev;
buf : 		core->dev.bus = &bcma_bus_type;
buf : 		dev_set_name(&core->dev, "bcma%d:%d", bus->num, dev_id);
buf : 
buf : 		switch (bus->hosttype) {
buf : 		case BCMA_HOSTTYPE_PCI:
buf : 			core->dev.parent = &bus->host_pci->dev;
buf : 			core->dma_dev = &bus->host_pci->dev;
buf : 			core->irq = bus->host_pci->irq;
buf : 			break;
buf : 		case BCMA_HOSTTYPE_SOC:
buf : 			core->dev.dma_mask = &core->dev.coherent_dma_mask;
buf : 			core->dma_dev = &core->dev;
buf : 			break;
buf : 		case BCMA_HOSTTYPE_SDIO:
buf : 			break;
buf : 		}
buf : 
buf : 		err = device_register(&core->dev);
buf : 		if (err) {
if (err) { 
buf : 			bcma_err(bus,
buf : 				 "Could not register dev for core 0x%03X\n",
for core 0x%03X\n", 
buf : 				 core->id.id);
buf : 			put_device(&core->dev);
buf : 			continue;
buf : 		}
buf : 		core->dev_registered = true;
buf : 		dev_id++;
buf : 	}
buf : 
buf : #ifdef CONFIG_BCMA_DRIVER_MIPS
ifdef CONFIG_BCMA_DRIVER_MIPS 
buf : 	if (bus->drv_cc.pflash.present) {
buf : 		err = platform_device_register(&bcma_pflash_dev);
form_device_register(&bcma_pflash_dev); 
buf : 		if (err)
buf : 			bcma_err(bus, "Error registering parallel flash\n");
buf : 	}
buf : #endif
if 
buf : 
buf : #ifdef CONFIG_BCMA_SFLASH
buf : 	if (bus->drv_cc.sflash.present) {
if (bus->drv_cc.sflash.present) { 
buf : 		err = platform_device_register(&bcma_sflash_dev);
form_device_register(&bcma_sflash_dev); 
buf : 		if (err)
buf : 			bcma_err(bus, "Error registering serial flash\n");
buf : 	}
buf : #endif
if 
buf : 
buf : #ifdef CONFIG_BCMA_NFLASH
buf : 	if (bus->drv_cc.nflash.present) {
if (bus->drv_cc.nflash.present) { 
buf : 		err = platform_device_register(&bcma_nflash_dev);
form_device_register(&bcma_nflash_dev); 
buf : 		if (err)
buf : 			bcma_err(bus, "Error registering NAND flash\n");
buf : 	}
buf : #endif
if 
buf : 	err = bcma_gpio_init(&bus->drv_cc);
buf : 	if (err == -ENOTSUPP)
if (err == -ENOTSUPP) 
buf : 		bcma_debug(bus, "GPIO driver not activated\n");
buf : 	else if (err)
if (err) 
buf : 		bcma_err(bus, "Error registering GPIO driver: %i\n", err);
buf : 
buf : 	if (bus->hosttype == BCMA_HOSTTYPE_SOC) {
if (bus->hosttype == BCMA_HOSTTYPE_SOC) { 
buf : 		err = bcma_chipco_watchdog_register(&bus->drv_cc);
buf : 		if (err)
if (err) 
buf : 			bcma_err(bus, "Error registering watchdog driver\n");
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void bcma_unregister_cores(struct bcma_bus *bus)
buf : {
buf : 	struct bcma_device *core, *tmp;
buf : 
buf : 	list_for_each_entry_safe(core, tmp, &bus->cores, list) {
for_each_entry_safe(core, tmp, &bus->cores, list) { 
buf : 		list_del(&core->list);
buf : 		if (core->dev_registered)
if (core->dev_registered) 
buf : 			device_unregister(&core->dev);
buf : 	}
buf : 	if (bus->hosttype == BCMA_HOSTTYPE_SOC)
if (bus->hosttype == BCMA_HOSTTYPE_SOC) 
buf : 		platform_device_unregister(bus->drv_cc.watchdog);
form_device_unregister(bus->drv_cc.watchdog); 
buf : }
buf : 
buf : int bcma_bus_register(struct bcma_bus *bus)
buf : {
buf : 	int err;
buf : 	struct bcma_device *core;
buf : 
buf : 	mutex_lock(&bcma_buses_mutex);
buf : 	bus->num = bcma_bus_next_num++;
buf : 	mutex_unlock(&bcma_buses_mutex);
buf : 
buf : 	/* Scan for devices (cores) */
for devices (cores) */ 
buf : 	err = bcma_bus_scan(bus);
buf : 	if (err) {
if (err) { 
buf : 		bcma_err(bus, "Failed to scan: %d\n", err);
buf : 		return err;
buf : 	}
buf : 
buf : 	/* Early init CC core */
buf : 	core = bcma_find_core(bus, bcma_cc_core_id(bus));
buf : 	if (core) {
if (core) { 
buf : 		bus->drv_cc.core = core;
buf : 		bcma_core_chipcommon_early_init(&bus->drv_cc);
buf : 	}
buf : 
buf : 	/* Try to get SPROM */
buf : 	err = bcma_sprom_get(bus);
buf : 	if (err == -ENOENT) {
if (err == -ENOENT) { 
buf : 		bcma_err(bus, "No SPROM available\n");
buf : 	} else if (err)
if (err) 
buf : 		bcma_err(bus, "Failed to get SPROM: %d\n", err);
buf : 
buf : 	/* Init CC core */
buf : 	core = bcma_find_core(bus, bcma_cc_core_id(bus));
buf : 	if (core) {
if (core) { 
buf : 		bus->drv_cc.core = core;
buf : 		bcma_core_chipcommon_init(&bus->drv_cc);
buf : 	}
buf : 
buf : 	/* Init MIPS core */
buf : 	core = bcma_find_core(bus, BCMA_CORE_MIPS_74K);
buf : 	if (core) {
if (core) { 
buf : 		bus->drv_mips.core = core;
buf : 		bcma_core_mips_init(&bus->drv_mips);
buf : 	}
buf : 
buf : 	/* Init PCIE core */
buf : 	core = bcma_find_core_unit(bus, BCMA_CORE_PCIE, 0);
buf : 	if (core) {
if (core) { 
buf : 		bus->drv_pci[0].core = core;
buf : 		bcma_core_pci_init(&bus->drv_pci[0]);
buf : 	}
buf : 
buf : 	/* Init PCIE core */
buf : 	core = bcma_find_core_unit(bus, BCMA_CORE_PCIE, 1);
buf : 	if (core) {
if (core) { 
buf : 		bus->drv_pci[1].core = core;
buf : 		bcma_core_pci_init(&bus->drv_pci[1]);
buf : 	}
buf : 
buf : 	/* Init GBIT MAC COMMON core */
buf : 	core = bcma_find_core(bus, BCMA_CORE_4706_MAC_GBIT_COMMON);
buf : 	if (core) {
if (core) { 
buf : 		bus->drv_gmac_cmn.core = core;
buf : 		bcma_core_gmac_cmn_init(&bus->drv_gmac_cmn);
buf : 	}
buf : 
buf : 	/* Register found cores */
buf : 	bcma_register_cores(bus);
buf : 
buf : 	bcma_info(bus, "Bus registered\n");
buf : 
buf : 	return 0;
buf : }
buf : 
buf : void bcma_bus_unregister(struct bcma_bus *bus)
buf : {
buf : 	struct bcma_device *cores[3];
buf : 	int err;
buf : 
buf : 	err = bcma_gpio_unregister(&bus->drv_cc);
buf : 	if (err == -EBUSY)
if (err == -EBUSY) 
buf : 		bcma_err(bus, "Some GPIOs are still in use.\n");
buf : 	else if (err)
if (err) 
buf : 		bcma_err(bus, "Can not unregister GPIO driver: %i\n", err);
buf : 
buf : 	cores[0] = bcma_find_core(bus, BCMA_CORE_MIPS_74K);
buf : 	cores[1] = bcma_find_core(bus, BCMA_CORE_PCIE);
buf : 	cores[2] = bcma_find_core(bus, BCMA_CORE_4706_MAC_GBIT_COMMON);
buf : 
buf : 	bcma_unregister_cores(bus);
buf : 
buf : 	kfree(cores[2]);
buf : 	kfree(cores[1]);
buf : 	kfree(cores[0]);
buf : }
buf : 
buf : int __init bcma_bus_early_register(struct bcma_bus *bus,
buf : 				   struct bcma_device *core_cc,
buf : 				   struct bcma_device *core_mips)
buf : {
buf : 	int err;
buf : 	struct bcma_device *core;
buf : 	struct bcma_device_id match;
buf : 
buf : 	bcma_init_bus(bus);
buf : 
buf : 	match.manuf = BCMA_MANUF_BCM;
buf : 	match.id = bcma_cc_core_id(bus);
buf : 	match.class = BCMA_CL_SIM;
buf : 	match.rev = BCMA_ANY_REV;
buf : 
buf : 	/* Scan for chip common core */
for chip common core */ 
buf : 	err = bcma_bus_scan_early(bus, &match, core_cc);
buf : 	if (err) {
if (err) { 
buf : 		bcma_err(bus, "Failed to scan for common core: %d\n", err);
for common core: %d\n", err); 
buf : 		return -1;
buf : 	}
buf : 
buf : 	match.manuf = BCMA_MANUF_MIPS;
buf : 	match.id = BCMA_CORE_MIPS_74K;
buf : 	match.class = BCMA_CL_SIM;
buf : 	match.rev = BCMA_ANY_REV;
buf : 
buf : 	/* Scan for mips core */
for mips core */ 
buf : 	err = bcma_bus_scan_early(bus, &match, core_mips);
buf : 	if (err) {
if (err) { 
buf : 		bcma_err(bus, "Failed to scan for mips core: %d\n", err);
for mips core: %d\n", err); 
buf : 		return -1;
buf : 	}
buf : 
buf : 	/* Early init CC core */
buf : 	core = bcma_find_core(bus, bcma_cc_core_id(bus));
buf : 	if (core) {
if (core) { 
buf : 		bus->drv_cc.core = core;
buf : 		bcma_core_chipcommon_early_init(&bus->drv_cc);
buf : 	}
buf : 
buf : 	/* Early init MIPS core */
buf : 	core = bcma_find_core(bus, BCMA_CORE_MIPS_74K);
buf : 	if (core) {
if (core) { 
buf : 		bus->drv_mips.core = core;
buf : 		bcma_core_mips_early_init(&bus->drv_mips);
buf : 	}
buf : 
buf : 	bcma_info(bus, "Early bus registered\n");
buf : 
buf : 	return 0;
buf : }
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : int bcma_bus_suspend(struct bcma_bus *bus)
buf : {
buf : 	struct bcma_device *core;
buf : 
buf : 	list_for_each_entry(core, &bus->cores, list) {
for_each_entry(core, &bus->cores, list) { 
buf : 		struct device_driver *drv = core->dev.driver;
buf : 		if (drv) {
if (drv) { 
buf : 			struct bcma_driver *adrv = container_of(drv, struct bcma_driver, drv);
buf : 			if (adrv->suspend)
if (adrv->suspend) 
buf : 				adrv->suspend(core);
buf : 		}
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : int bcma_bus_resume(struct bcma_bus *bus)
buf : {
buf : 	struct bcma_device *core;
buf : 
buf : 	/* Init CC core */
buf : 	if (bus->drv_cc.core) {
if (bus->drv_cc.core) { 
buf : 		bus->drv_cc.setup_done = false;
buf : 		bcma_core_chipcommon_init(&bus->drv_cc);
buf : 	}
buf : 
buf : 	list_for_each_entry(core, &bus->cores, list) {
for_each_entry(core, &bus->cores, list) { 
buf : 		struct device_driver *drv = core->dev.driver;
buf : 		if (drv) {
if (drv) { 
buf : 			struct bcma_driver *adrv = container_of(drv, struct bcma_driver, drv);
buf : 			if (adrv->resume)
if (adrv->resume) 
buf : 				adrv->resume(core);
buf : 		}
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : #endif
if 
buf : 
buf : int __bcma_driver_register(struct bcma_driver *drv, struct module *owner)
buf : {
buf : 	drv->drv.name = drv->name;
buf : 	drv->drv.bus = &bcma_bus_type;
buf : 	drv->drv.owner = owner;
buf : 
buf : 	return driver_register(&drv->drv);
buf : }
buf : EXPORT_SYMBOL_GPL(__bcma_driver_register);
buf : 
buf : void bcma_driver_unregister(struct bcma_driver *drv)
buf : {
buf : 	driver_unregister(&drv->drv);
buf : }
buf : EXPORT_SYMBOL_GPL(bcma_driver_unregister);
buf : 
buf : static int bcma_bus_match(struct device *dev, struct device_driver *drv)
buf : {
buf : 	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
buf : 	struct bcma_driver *adrv = container_of(drv, struct bcma_driver, drv);
buf : 	const struct bcma_device_id *cid = &core->id;
buf : 	const struct bcma_device_id *did;
buf : 
buf : 	for (did = adrv->id_table; did->manuf || did->id || did->rev; did++) {
for (did = adrv->id_table; did->manuf || did->id || did->rev; did++) { 
buf : 	    if ((did->manuf == cid->manuf || did->manuf == BCMA_ANY_MANUF) &&
buf : 		(did->id == cid->id || did->id == BCMA_ANY_ID) &&
buf : 		(did->rev == cid->rev || did->rev == BCMA_ANY_REV) &&
buf : 		(did->class == cid->class || did->class == BCMA_ANY_CLASS))
buf : 			return 1;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static int bcma_device_probe(struct device *dev)
buf : {
buf : 	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
buf : 	struct bcma_driver *adrv = container_of(dev->driver, struct bcma_driver,
buf : 					       drv);
buf : 	int err = 0;
buf : 
buf : 	if (adrv->probe)
if (adrv->probe) 
buf : 		err = adrv->probe(core);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int bcma_device_remove(struct device *dev)
buf : {
buf : 	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
buf : 	struct bcma_driver *adrv = container_of(dev->driver, struct bcma_driver,
buf : 					       drv);
buf : 
buf : 	if (adrv->remove)
if (adrv->remove) 
buf : 		adrv->remove(core);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int bcma_device_uevent(struct device *dev, struct kobj_uevent_env *env)
buf : {
buf : 	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
buf : 
buf : 	return add_uevent_var(env,
buf : 			      "MODALIAS=bcma:m%04Xid%04Xrev%02Xcl%02X",
buf : 			      core->id.manuf, core->id.id,
buf : 			      core->id.rev, core->id.class);
buf : }
buf : 
buf : static int __init bcma_modinit(void)
buf : {
buf : 	int err;
buf : 
buf : 	err = bus_register(&bcma_bus_type);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : #ifdef CONFIG_BCMA_HOST_PCI
ifdef CONFIG_BCMA_HOST_PCI 
buf : 	err = bcma_host_pci_init();
buf : 	if (err) {
if (err) { 
buf : 		pr_err("PCI host initialization failed\n");
buf : 		err = 0;
buf : 	}
buf : #endif
if 
buf : 
buf : 	return err;
buf : }
buf : fs_initcall(bcma_modinit);
buf : 
buf : static void __exit bcma_modexit(void)
buf : {
buf : #ifdef CONFIG_BCMA_HOST_PCI
ifdef CONFIG_BCMA_HOST_PCI 
buf : 	bcma_host_pci_exit();
buf : #endif
if 
buf : 	bus_unregister(&bcma_bus_type);
buf : }
buf : module_exit(bcma_modexit)
file : ./test/kernel/drivers/base/power/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * drivers/base/power/main.c - Where the driver meets power management.
buf :  *
buf :  * Copyright (c) 2003 Patrick Mochel
buf :  * Copyright (c) 2003 Open Source Development Lab
buf :  *
buf :  * This file is released under the GPLv2
buf :  *
buf :  *
buf :  * The driver model core calls device_pm_add() when a device is registered.
buf :  * This will initialize the embedded device_pm_info object in the device
buf :  * and add it to the list of power-controlled devices. sysfs entries for
for 
buf :  * controlling device power management will also be added.
buf :  *
buf :  * A separate list is used for keeping track of power info, because the power
for keeping track of power info, because the power 
buf :  * domain dependencies may differ from the ancestral dependencies that the
buf :  * subsystem list maintains.
buf :  */
buf : 
buf : #include <linux/device.h>
buf : #include <linux/kallsyms.h>
buf : #include <linux/export.h>
buf : #include <linux/mutex.h>
buf : #include <linux/pm.h>
buf : #include <linux/pm_runtime.h>
buf : #include <linux/resume-trace.h>
buf : #include <linux/interrupt.h>
buf : #include <linux/sched.h>
buf : #include <linux/async.h>
buf : #include <linux/suspend.h>
buf : #include <trace/events/power.h>
buf : #include <linux/cpufreq.h>
buf : #include <linux/cpuidle.h>
buf : #include <linux/timer.h>
buf : 
buf : #include "../base.h"
buf : #include "power.h"
buf : 
buf : typedef int (*pm_callback_t)(struct device *);
buf : 
buf : /*
buf :  * The entries in the dpm_list list are in a depth first order, simply
buf :  * because children are guaranteed to be discovered after parents, and
buf :  * are inserted at the back of the list on discovery.
buf :  *
buf :  * Since device_pm_add() may be called with a device lock held,
buf :  * we must never try to acquire a device lock while holding
while holding 
buf :  * dpm_list_mutex.
buf :  */
buf : 
buf : LIST_HEAD(dpm_list);
buf : static LIST_HEAD(dpm_prepared_list);
buf : static LIST_HEAD(dpm_suspended_list);
buf : static LIST_HEAD(dpm_late_early_list);
buf : static LIST_HEAD(dpm_noirq_list);
buf : 
buf : struct suspend_stats suspend_stats;
buf : static DEFINE_MUTEX(dpm_list_mtx);
buf : static pm_message_t pm_transition;
buf : 
buf : static int async_error;
buf : 
buf : static char *pm_verb(int event)
buf : {
buf : 	switch (event) {
buf : 	case PM_EVENT_SUSPEND:
buf : 		return "suspend";
buf : 	case PM_EVENT_RESUME:
buf : 		return "resume";
buf : 	case PM_EVENT_FREEZE:
buf : 		return "freeze";
buf : 	case PM_EVENT_QUIESCE:
buf : 		return "quiesce";
buf : 	case PM_EVENT_HIBERNATE:
buf : 		return "hibernate";
buf : 	case PM_EVENT_THAW:
buf : 		return "thaw";
buf : 	case PM_EVENT_RESTORE:
buf : 		return "restore";
buf : 	case PM_EVENT_RECOVER:
buf : 		return "recover";
buf : 	default:
buf : 		return "(unknown PM event)";
buf : 	}
buf : }
buf : 
buf : /**
buf :  * device_pm_sleep_init - Initialize system suspend-related device fields.
buf :  * @dev: Device object being initialized.
buf :  */
buf : void device_pm_sleep_init(struct device *dev)
buf : {
buf : 	dev->power.is_prepared = false;
buf : 	dev->power.is_suspended = false;
buf : 	dev->power.is_noirq_suspended = false;
buf : 	dev->power.is_late_suspended = false;
buf : 	init_completion(&dev->power.completion);
buf : 	complete_all(&dev->power.completion);
buf : 	dev->power.wakeup = NULL;
buf : 	INIT_LIST_HEAD(&dev->power.entry);
buf : }
buf : 
buf : /**
buf :  * device_pm_lock - Lock the list of active devices used by the PM core.
buf :  */
buf : void device_pm_lock(void)
buf : {
buf : 	mutex_lock(&dpm_list_mtx);
buf : }
buf : 
buf : /**
buf :  * device_pm_unlock - Unlock the list of active devices used by the PM core.
buf :  */
buf : void device_pm_unlock(void)
buf : {
buf : 	mutex_unlock(&dpm_list_mtx);
buf : }
buf : 
buf : /**
buf :  * device_pm_add - Add a device to the PM core's list of active devices.
buf :  * @dev: Device to add to the list.
buf :  */
buf : void device_pm_add(struct device *dev)
buf : {
buf : 	pr_debug("PM: Adding info for %s:%s\n",
for %s:%s\n", 
buf : 		 dev->bus ? dev->bus->name : "No Bus", dev_name(dev));
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	if (dev->parent && dev->parent->power.is_prepared)
if (dev->parent && dev->parent->power.is_prepared) 
buf : 		dev_warn(dev, "parent %s should not be sleeping\n",
buf : 			dev_name(dev->parent));
buf : 	list_add_tail(&dev->power.entry, &dpm_list);
buf : 	mutex_unlock(&dpm_list_mtx);
buf : }
buf : 
buf : /**
buf :  * device_pm_remove - Remove a device from the PM core's list of active devices.
buf :  * @dev: Device to be removed from the list.
buf :  */
buf : void device_pm_remove(struct device *dev)
buf : {
buf : 	pr_debug("PM: Removing info for %s:%s\n",
for %s:%s\n", 
buf : 		 dev->bus ? dev->bus->name : "No Bus", dev_name(dev));
buf : 	complete_all(&dev->power.completion);
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	list_del_init(&dev->power.entry);
buf : 	mutex_unlock(&dpm_list_mtx);
buf : 	device_wakeup_disable(dev);
buf : 	pm_runtime_remove(dev);
buf : }
buf : 
buf : /**
buf :  * device_pm_move_before - Move device in the PM core's list of active devices.
fore - Move device in the PM core's list of active devices. 
buf :  * @deva: Device to move in dpm_list.
buf :  * @devb: Device @deva should come before.
fore. 
buf :  */
buf : void device_pm_move_before(struct device *deva, struct device *devb)
fore(struct device *deva, struct device *devb) 
buf : {
buf : 	pr_debug("PM: Moving %s:%s before %s:%s\n",
buf : 		 deva->bus ? deva->bus->name : "No Bus", dev_name(deva),
buf : 		 devb->bus ? devb->bus->name : "No Bus", dev_name(devb));
buf : 	/* Delete deva from dpm_list and reinsert before devb. */
fore devb. */ 
buf : 	list_move_tail(&deva->power.entry, &devb->power.entry);
buf : }
buf : 
buf : /**
buf :  * device_pm_move_after - Move device in the PM core's list of active devices.
buf :  * @deva: Device to move in dpm_list.
buf :  * @devb: Device @deva should come after.
buf :  */
buf : void device_pm_move_after(struct device *deva, struct device *devb)
buf : {
buf : 	pr_debug("PM: Moving %s:%s after %s:%s\n",
buf : 		 deva->bus ? deva->bus->name : "No Bus", dev_name(deva),
buf : 		 devb->bus ? devb->bus->name : "No Bus", dev_name(devb));
buf : 	/* Delete deva from dpm_list and reinsert after devb. */
buf : 	list_move(&deva->power.entry, &devb->power.entry);
buf : }
buf : 
buf : /**
buf :  * device_pm_move_last - Move device to end of the PM core's list of devices.
buf :  * @dev: Device to move in dpm_list.
buf :  */
buf : void device_pm_move_last(struct device *dev)
buf : {
buf : 	pr_debug("PM: Moving %s:%s to end of list\n",
buf : 		 dev->bus ? dev->bus->name : "No Bus", dev_name(dev));
buf : 	list_move_tail(&dev->power.entry, &dpm_list);
buf : }
buf : 
buf : static ktime_t initcall_debug_start(struct device *dev)
buf : {
buf : 	ktime_t calltime = ktime_set(0, 0);
buf : 
buf : 	if (pm_print_times_enabled) {
if (pm_print_times_enabled) { 
buf : 		pr_info("calling  %s+ @ %i, parent: %s\n",
buf : 			dev_name(dev), task_pid_nr(current),
buf : 			dev->parent ? dev_name(dev->parent) : "none");
buf : 		calltime = ktime_get();
buf : 	}
buf : 
buf : 	return calltime;
buf : }
buf : 
buf : static void initcall_debug_report(struct device *dev, ktime_t calltime,
buf : 				  int error, pm_message_t state, char *info)
buf : {
buf : 	ktime_t rettime;
buf : 	s64 nsecs;
buf : 
buf : 	rettime = ktime_get();
buf : 	nsecs = (s64) ktime_to_ns(ktime_sub(rettime, calltime));
buf : 
buf : 	if (pm_print_times_enabled) {
if (pm_print_times_enabled) { 
buf : 		pr_info("call %s+ returned %d after %Ld usecs\n", dev_name(dev),
buf : 			error, (unsigned long long)nsecs >> 10);
buf : 	}
buf : }
buf : 
buf : /**
buf :  * dpm_wait - Wait for a PM operation to complete.
for a PM operation to complete. 
buf :  * @dev: Device to wait for.
buf :  * @async: If unset, wait only if the device's power.async_suspend flag is set.
if the device's power.async_suspend flag is set. 
buf :  */
buf : static void dpm_wait(struct device *dev, bool async)
buf : {
buf : 	if (!dev)
if (!dev) 
buf : 		return;
buf : 
buf : 	if (async || (pm_async_enabled && dev->power.async_suspend))
if (async || (pm_async_enabled && dev->power.async_suspend)) 
buf : 		wait_for_completion(&dev->power.completion);
for_completion(&dev->power.completion); 
buf : }
buf : 
buf : static int dpm_wait_fn(struct device *dev, void *async_ptr)
buf : {
buf : 	dpm_wait(dev, *((bool *)async_ptr));
buf : 	return 0;
buf : }
buf : 
buf : static void dpm_wait_for_children(struct device *dev, bool async)
for_children(struct device *dev, bool async) 
buf : {
buf :        device_for_each_child(dev, &async, dpm_wait_fn);
buf : }
buf : 
buf : /**
buf :  * pm_op - Return the PM operation appropriate for given PM event.
for given PM event. 
buf :  * @ops: PM operations to choose from.
buf :  * @state: PM transition of the system being carried out.
buf :  */
buf : static pm_callback_t pm_op(const struct dev_pm_ops *ops, pm_message_t state)
buf : {
buf : 	switch (state.event) {
buf : #ifdef CONFIG_SUSPEND
ifdef CONFIG_SUSPEND 
buf : 	case PM_EVENT_SUSPEND:
buf : 		return ops->suspend;
buf : 	case PM_EVENT_RESUME:
buf : 		return ops->resume;
buf : #endif /* CONFIG_SUSPEND */
if /* CONFIG_SUSPEND */ 
buf : #ifdef CONFIG_HIBERNATE_CALLBACKS
buf : 	case PM_EVENT_FREEZE:
buf : 	case PM_EVENT_QUIESCE:
buf : 		return ops->freeze;
buf : 	case PM_EVENT_HIBERNATE:
buf : 		return ops->poweroff;
buf : 	case PM_EVENT_THAW:
buf : 	case PM_EVENT_RECOVER:
buf : 		return ops->thaw;
buf : 		break;
buf : 	case PM_EVENT_RESTORE:
buf : 		return ops->restore;
buf : #endif /* CONFIG_HIBERNATE_CALLBACKS */
if /* CONFIG_HIBERNATE_CALLBACKS */ 
buf : 	}
buf : 
buf : 	return NULL;
buf : }
buf : 
buf : /**
buf :  * pm_late_early_op - Return the PM operation appropriate for given PM event.
for given PM event. 
buf :  * @ops: PM operations to choose from.
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Runtime PM is disabled for @dev while this function is being executed.
for @dev while this function is being executed. 
buf :  */
buf : static pm_callback_t pm_late_early_op(const struct dev_pm_ops *ops,
buf : 				      pm_message_t state)
buf : {
buf : 	switch (state.event) {
buf : #ifdef CONFIG_SUSPEND
ifdef CONFIG_SUSPEND 
buf : 	case PM_EVENT_SUSPEND:
buf : 		return ops->suspend_late;
buf : 	case PM_EVENT_RESUME:
buf : 		return ops->resume_early;
buf : #endif /* CONFIG_SUSPEND */
if /* CONFIG_SUSPEND */ 
buf : #ifdef CONFIG_HIBERNATE_CALLBACKS
buf : 	case PM_EVENT_FREEZE:
buf : 	case PM_EVENT_QUIESCE:
buf : 		return ops->freeze_late;
buf : 	case PM_EVENT_HIBERNATE:
buf : 		return ops->poweroff_late;
buf : 	case PM_EVENT_THAW:
buf : 	case PM_EVENT_RECOVER:
buf : 		return ops->thaw_early;
buf : 	case PM_EVENT_RESTORE:
buf : 		return ops->restore_early;
buf : #endif /* CONFIG_HIBERNATE_CALLBACKS */
if /* CONFIG_HIBERNATE_CALLBACKS */ 
buf : 	}
buf : 
buf : 	return NULL;
buf : }
buf : 
buf : /**
buf :  * pm_noirq_op - Return the PM operation appropriate for given PM event.
for given PM event. 
buf :  * @ops: PM operations to choose from.
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * The driver of @dev will not receive interrupts while this function is being
while this function is being 
buf :  * executed.
buf :  */
buf : static pm_callback_t pm_noirq_op(const struct dev_pm_ops *ops, pm_message_t state)
buf : {
buf : 	switch (state.event) {
buf : #ifdef CONFIG_SUSPEND
ifdef CONFIG_SUSPEND 
buf : 	case PM_EVENT_SUSPEND:
buf : 		return ops->suspend_noirq;
buf : 	case PM_EVENT_RESUME:
buf : 		return ops->resume_noirq;
buf : #endif /* CONFIG_SUSPEND */
if /* CONFIG_SUSPEND */ 
buf : #ifdef CONFIG_HIBERNATE_CALLBACKS
buf : 	case PM_EVENT_FREEZE:
buf : 	case PM_EVENT_QUIESCE:
buf : 		return ops->freeze_noirq;
buf : 	case PM_EVENT_HIBERNATE:
buf : 		return ops->poweroff_noirq;
buf : 	case PM_EVENT_THAW:
buf : 	case PM_EVENT_RECOVER:
buf : 		return ops->thaw_noirq;
buf : 	case PM_EVENT_RESTORE:
buf : 		return ops->restore_noirq;
buf : #endif /* CONFIG_HIBERNATE_CALLBACKS */
if /* CONFIG_HIBERNATE_CALLBACKS */ 
buf : 	}
buf : 
buf : 	return NULL;
buf : }
buf : 
buf : static void pm_dev_dbg(struct device *dev, pm_message_t state, char *info)
buf : {
buf : 	dev_dbg(dev, "%s%s%s\n", info, pm_verb(state.event),
buf : 		((state.event & PM_EVENT_SLEEP) && device_may_wakeup(dev)) ?
buf : 		", may wakeup" : "");
buf : }
buf : 
buf : static void pm_dev_err(struct device *dev, pm_message_t state, char *info,
buf : 			int error)
buf : {
buf : 	printk(KERN_ERR "PM: Device %s failed to %s%s: error %d\n",
buf : 		dev_name(dev), pm_verb(state.event), info, error);
buf : }
buf : 
buf : static void dpm_show_time(ktime_t starttime, pm_message_t state, char *info)
buf : {
buf : 	ktime_t calltime;
buf : 	u64 usecs64;
buf : 	int usecs;
buf : 
buf : 	calltime = ktime_get();
buf : 	usecs64 = ktime_to_ns(ktime_sub(calltime, starttime));
buf : 	do_div(usecs64, NSEC_PER_USEC);
buf : 	usecs = usecs64;
buf : 	if (usecs == 0)
if (usecs == 0) 
buf : 		usecs = 1;
buf : 	pr_info("PM: %s%s%s of devices complete after %ld.%03ld msecs\n",
buf : 		info ?: "", info ? " " : "", pm_verb(state.event),
buf : 		usecs / USEC_PER_MSEC, usecs % USEC_PER_MSEC);
buf : }
buf : 
buf : static int dpm_run_callback(pm_callback_t cb, struct device *dev,
buf : 			    pm_message_t state, char *info)
buf : {
buf : 	ktime_t calltime;
buf : 	int error;
buf : 
buf : 	if (!cb)
if (!cb) 
buf : 		return 0;
buf : 
buf : 	calltime = initcall_debug_start(dev);
buf : 
buf : 	pm_dev_dbg(dev, state, info);
buf : 	trace_device_pm_callback_start(dev, info, state.event);
buf : 	error = cb(dev);
buf : 	trace_device_pm_callback_end(dev, error);
buf : 	suspend_report_result(cb, error);
buf : 
buf : 	initcall_debug_report(dev, calltime, error, state, info);
buf : 
buf : 	return error;
buf : }
buf : 
buf : #ifdef CONFIG_DPM_WATCHDOG
ifdef CONFIG_DPM_WATCHDOG 
buf : struct dpm_watchdog {
buf : 	struct device		*dev;
buf : 	struct task_struct	*tsk;
buf : 	struct timer_list	timer;
buf : };
buf : 
buf : #define DECLARE_DPM_WATCHDOG_ON_STACK(wd) \
buf : 	struct dpm_watchdog wd
buf : 
buf : /**
buf :  * dpm_watchdog_handler - Driver suspend / resume watchdog handler.
buf :  * @data: Watchdog object address.
buf :  *
buf :  * Called when a driver has timed out suspending or resuming.
buf :  * There's not much we can do here to recover so panic() to
buf :  * capture a crash-dump in pstore.
buf :  */
buf : static void dpm_watchdog_handler(unsigned long data)
buf : {
buf : 	struct dpm_watchdog *wd = (void *)data;
buf : 
buf : 	dev_emerg(wd->dev, "**** DPM device timeout ****\n");
buf : 	show_stack(wd->tsk, NULL);
buf : 	panic("%s %s: unrecoverable failure\n",
buf : 		dev_driver_string(wd->dev), dev_name(wd->dev));
buf : }
buf : 
buf : /**
buf :  * dpm_watchdog_set - Enable pm watchdog for given device.
for given device. 
buf :  * @wd: Watchdog. Must be allocated on the stack.
buf :  * @dev: Device to handle.
buf :  */
buf : static void dpm_watchdog_set(struct dpm_watchdog *wd, struct device *dev)
buf : {
buf : 	struct timer_list *timer = &wd->timer;
buf : 
buf : 	wd->dev = dev;
buf : 	wd->tsk = current;
buf : 
buf : 	init_timer_on_stack(timer);
buf : 	/* use same timeout value for both suspend and resume */
for both suspend and resume */ 
buf : 	timer->expires = jiffies + HZ * CONFIG_DPM_WATCHDOG_TIMEOUT;
buf : 	timer->function = dpm_watchdog_handler;
buf : 	timer->data = (unsigned long)wd;
buf : 	add_timer(timer);
buf : }
buf : 
buf : /**
buf :  * dpm_watchdog_clear - Disable suspend/resume watchdog.
buf :  * @wd: Watchdog to disable.
buf :  */
buf : static void dpm_watchdog_clear(struct dpm_watchdog *wd)
buf : {
buf : 	struct timer_list *timer = &wd->timer;
buf : 
buf : 	del_timer_sync(timer);
buf : 	destroy_timer_on_stack(timer);
buf : }
buf : #else
buf : #define DECLARE_DPM_WATCHDOG_ON_STACK(wd)
buf : #define dpm_watchdog_set(x, y)
buf : #define dpm_watchdog_clear(x)
buf : #endif
if 
buf : 
buf : /*------------------------- Resume routines -------------------------*/
buf : 
buf : /**
buf :  * device_resume_noirq - Execute an "early resume" callback for given device.
for given device. 
buf :  * @dev: Device to handle.
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * The driver of @dev will not receive interrupts while this function is being
while this function is being 
buf :  * executed.
buf :  */
buf : static int device_resume_noirq(struct device *dev, pm_message_t state, bool async)
buf : {
buf : 	pm_callback_t callback = NULL;
buf : 	char *info = NULL;
buf : 	int error = 0;
buf : 
buf : 	TRACE_DEVICE(dev);
buf : 	TRACE_RESUME(0);
buf : 
buf : 	if (dev->power.syscore || dev->power.direct_complete)
if (dev->power.syscore || dev->power.direct_complete) 
buf : 		goto Out;
buf : 
buf : 	if (!dev->power.is_noirq_suspended)
if (!dev->power.is_noirq_suspended) 
buf : 		goto Out;
buf : 
buf : 	dpm_wait(dev->parent, async);
buf : 
buf : 	if (dev->pm_domain) {
if (dev->pm_domain) { 
buf : 		info = "noirq power domain ";
buf : 		callback = pm_noirq_op(&dev->pm_domain->ops, state);
buf : 	} else if (dev->type && dev->type->pm) {
if (dev->type && dev->type->pm) { 
buf : 		info = "noirq type ";
buf : 		callback = pm_noirq_op(dev->type->pm, state);
buf : 	} else if (dev->class && dev->class->pm) {
if (dev->class && dev->class->pm) { 
buf : 		info = "noirq class ";
buf : 		callback = pm_noirq_op(dev->class->pm, state);
buf : 	} else if (dev->bus && dev->bus->pm) {
if (dev->bus && dev->bus->pm) { 
buf : 		info = "noirq bus ";
buf : 		callback = pm_noirq_op(dev->bus->pm, state);
buf : 	}
buf : 
buf : 	if (!callback && dev->driver && dev->driver->pm) {
if (!callback && dev->driver && dev->driver->pm) { 
buf : 		info = "noirq driver ";
buf : 		callback = pm_noirq_op(dev->driver->pm, state);
buf : 	}
buf : 
buf : 	error = dpm_run_callback(callback, dev, state, info);
buf : 	dev->power.is_noirq_suspended = false;
buf : 
buf :  Out:
buf : 	complete_all(&dev->power.completion);
buf : 	TRACE_RESUME(error);
buf : 	return error;
buf : }
buf : 
buf : static bool is_async(struct device *dev)
buf : {
buf : 	return dev->power.async_suspend && pm_async_enabled
buf : 		&& !pm_trace_is_enabled();
buf : }
buf : 
buf : static void async_resume_noirq(void *data, async_cookie_t cookie)
buf : {
buf : 	struct device *dev = (struct device *)data;
buf : 	int error;
buf : 
buf : 	error = device_resume_noirq(dev, pm_transition, true);
buf : 	if (error)
if (error) 
buf : 		pm_dev_err(dev, pm_transition, " async", error);
buf : 
buf : 	put_device(dev);
buf : }
buf : 
buf : /**
buf :  * dpm_resume_noirq - Execute "noirq resume" callbacks for all devices.
for all devices. 
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Call the "noirq" resume handlers for all devices in dpm_noirq_list and
for all devices in dpm_noirq_list and 
buf :  * enable device drivers to receive interrupts.
buf :  */
buf : static void dpm_resume_noirq(pm_message_t state)
buf : {
buf : 	struct device *dev;
buf : 	ktime_t starttime = ktime_get();
buf : 
buf : 	trace_suspend_resume(TPS("dpm_resume_noirq"), state.event, true);
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	pm_transition = state;
buf : 
buf : 	/*
buf : 	 * Advanced the async threads upfront,
buf : 	 * in case the starting of async threads is
buf : 	 * delayed by non-async resuming devices.
buf : 	 */
buf : 	list_for_each_entry(dev, &dpm_noirq_list, power.entry) {
for_each_entry(dev, &dpm_noirq_list, power.entry) { 
buf : 		reinit_completion(&dev->power.completion);
buf : 		if (is_async(dev)) {
if (is_async(dev)) { 
buf : 			get_device(dev);
buf : 			async_schedule(async_resume_noirq, dev);
buf : 		}
buf : 	}
buf : 
buf : 	while (!list_empty(&dpm_noirq_list)) {
while (!list_empty(&dpm_noirq_list)) { 
buf : 		dev = to_device(dpm_noirq_list.next);
buf : 		get_device(dev);
buf : 		list_move_tail(&dev->power.entry, &dpm_late_early_list);
buf : 		mutex_unlock(&dpm_list_mtx);
buf : 
buf : 		if (!is_async(dev)) {
if (!is_async(dev)) { 
buf : 			int error;
buf : 
buf : 			error = device_resume_noirq(dev, state, false);
buf : 			if (error) {
if (error) { 
buf : 				suspend_stats.failed_resume_noirq++;
buf : 				dpm_save_failed_step(SUSPEND_RESUME_NOIRQ);
buf : 				dpm_save_failed_dev(dev_name(dev));
buf : 				pm_dev_err(dev, state, " noirq", error);
buf : 			}
buf : 		}
buf : 
buf : 		mutex_lock(&dpm_list_mtx);
buf : 		put_device(dev);
buf : 	}
buf : 	mutex_unlock(&dpm_list_mtx);
buf : 	async_synchronize_full();
buf : 	dpm_show_time(starttime, state, "noirq");
buf : 	resume_device_irqs();
buf : 	cpuidle_resume();
buf : 	trace_suspend_resume(TPS("dpm_resume_noirq"), state.event, false);
buf : }
buf : 
buf : /**
buf :  * device_resume_early - Execute an "early resume" callback for given device.
for given device. 
buf :  * @dev: Device to handle.
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Runtime PM is disabled for @dev while this function is being executed.
for @dev while this function is being executed. 
buf :  */
buf : static int device_resume_early(struct device *dev, pm_message_t state, bool async)
buf : {
buf : 	pm_callback_t callback = NULL;
buf : 	char *info = NULL;
buf : 	int error = 0;
buf : 
buf : 	TRACE_DEVICE(dev);
buf : 	TRACE_RESUME(0);
buf : 
buf : 	if (dev->power.syscore || dev->power.direct_complete)
if (dev->power.syscore || dev->power.direct_complete) 
buf : 		goto Out;
buf : 
buf : 	if (!dev->power.is_late_suspended)
if (!dev->power.is_late_suspended) 
buf : 		goto Out;
buf : 
buf : 	dpm_wait(dev->parent, async);
buf : 
buf : 	if (dev->pm_domain) {
if (dev->pm_domain) { 
buf : 		info = "early power domain ";
buf : 		callback = pm_late_early_op(&dev->pm_domain->ops, state);
buf : 	} else if (dev->type && dev->type->pm) {
if (dev->type && dev->type->pm) { 
buf : 		info = "early type ";
buf : 		callback = pm_late_early_op(dev->type->pm, state);
buf : 	} else if (dev->class && dev->class->pm) {
if (dev->class && dev->class->pm) { 
buf : 		info = "early class ";
buf : 		callback = pm_late_early_op(dev->class->pm, state);
buf : 	} else if (dev->bus && dev->bus->pm) {
if (dev->bus && dev->bus->pm) { 
buf : 		info = "early bus ";
buf : 		callback = pm_late_early_op(dev->bus->pm, state);
buf : 	}
buf : 
buf : 	if (!callback && dev->driver && dev->driver->pm) {
if (!callback && dev->driver && dev->driver->pm) { 
buf : 		info = "early driver ";
buf : 		callback = pm_late_early_op(dev->driver->pm, state);
buf : 	}
buf : 
buf : 	error = dpm_run_callback(callback, dev, state, info);
buf : 	dev->power.is_late_suspended = false;
buf : 
buf :  Out:
buf : 	TRACE_RESUME(error);
buf : 
buf : 	pm_runtime_enable(dev);
buf : 	complete_all(&dev->power.completion);
buf : 	return error;
buf : }
buf : 
buf : static void async_resume_early(void *data, async_cookie_t cookie)
buf : {
buf : 	struct device *dev = (struct device *)data;
buf : 	int error;
buf : 
buf : 	error = device_resume_early(dev, pm_transition, true);
buf : 	if (error)
if (error) 
buf : 		pm_dev_err(dev, pm_transition, " async", error);
buf : 
buf : 	put_device(dev);
buf : }
buf : 
buf : /**
buf :  * dpm_resume_early - Execute "early resume" callbacks for all devices.
for all devices. 
buf :  * @state: PM transition of the system being carried out.
buf :  */
buf : static void dpm_resume_early(pm_message_t state)
buf : {
buf : 	struct device *dev;
buf : 	ktime_t starttime = ktime_get();
buf : 
buf : 	trace_suspend_resume(TPS("dpm_resume_early"), state.event, true);
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	pm_transition = state;
buf : 
buf : 	/*
buf : 	 * Advanced the async threads upfront,
buf : 	 * in case the starting of async threads is
buf : 	 * delayed by non-async resuming devices.
buf : 	 */
buf : 	list_for_each_entry(dev, &dpm_late_early_list, power.entry) {
for_each_entry(dev, &dpm_late_early_list, power.entry) { 
buf : 		reinit_completion(&dev->power.completion);
buf : 		if (is_async(dev)) {
if (is_async(dev)) { 
buf : 			get_device(dev);
buf : 			async_schedule(async_resume_early, dev);
buf : 		}
buf : 	}
buf : 
buf : 	while (!list_empty(&dpm_late_early_list)) {
while (!list_empty(&dpm_late_early_list)) { 
buf : 		dev = to_device(dpm_late_early_list.next);
buf : 		get_device(dev);
buf : 		list_move_tail(&dev->power.entry, &dpm_suspended_list);
buf : 		mutex_unlock(&dpm_list_mtx);
buf : 
buf : 		if (!is_async(dev)) {
if (!is_async(dev)) { 
buf : 			int error;
buf : 
buf : 			error = device_resume_early(dev, state, false);
buf : 			if (error) {
if (error) { 
buf : 				suspend_stats.failed_resume_early++;
buf : 				dpm_save_failed_step(SUSPEND_RESUME_EARLY);
buf : 				dpm_save_failed_dev(dev_name(dev));
buf : 				pm_dev_err(dev, state, " early", error);
buf : 			}
buf : 		}
buf : 		mutex_lock(&dpm_list_mtx);
buf : 		put_device(dev);
buf : 	}
buf : 	mutex_unlock(&dpm_list_mtx);
buf : 	async_synchronize_full();
buf : 	dpm_show_time(starttime, state, "early");
buf : 	trace_suspend_resume(TPS("dpm_resume_early"), state.event, false);
buf : }
buf : 
buf : /**
buf :  * dpm_resume_start - Execute "noirq" and "early" device callbacks.
buf :  * @state: PM transition of the system being carried out.
buf :  */
buf : void dpm_resume_start(pm_message_t state)
buf : {
buf : 	dpm_resume_noirq(state);
buf : 	dpm_resume_early(state);
buf : }
buf : EXPORT_SYMBOL_GPL(dpm_resume_start);
buf : 
buf : /**
buf :  * device_resume - Execute "resume" callbacks for given device.
for given device. 
buf :  * @dev: Device to handle.
buf :  * @state: PM transition of the system being carried out.
buf :  * @async: If true, the device is being resumed asynchronously.
buf :  */
buf : static int device_resume(struct device *dev, pm_message_t state, bool async)
buf : {
buf : 	pm_callback_t callback = NULL;
buf : 	char *info = NULL;
buf : 	int error = 0;
buf : 	DECLARE_DPM_WATCHDOG_ON_STACK(wd);
buf : 
buf : 	TRACE_DEVICE(dev);
buf : 	TRACE_RESUME(0);
buf : 
buf : 	if (dev->power.syscore)
if (dev->power.syscore) 
buf : 		goto Complete;
buf : 
buf : 	if (dev->power.direct_complete) {
if (dev->power.direct_complete) { 
buf : 		/* Match the pm_runtime_disable() in __device_suspend(). */
buf : 		pm_runtime_enable(dev);
buf : 		goto Complete;
buf : 	}
buf : 
buf : 	dpm_wait(dev->parent, async);
buf : 	dpm_watchdog_set(&wd, dev);
buf : 	device_lock(dev);
buf : 
buf : 	/*
buf : 	 * This is a fib.  But we'll allow new children to be added below
buf : 	 * a resumed device, even if the device hasn't been completed yet.
if the device hasn't been completed yet. 
buf : 	 */
buf : 	dev->power.is_prepared = false;
buf : 
buf : 	if (!dev->power.is_suspended)
if (!dev->power.is_suspended) 
buf : 		goto Unlock;
buf : 
buf : 	if (dev->pm_domain) {
if (dev->pm_domain) { 
buf : 		info = "power domain ";
buf : 		callback = pm_op(&dev->pm_domain->ops, state);
buf : 		goto Driver;
buf : 	}
buf : 
buf : 	if (dev->type && dev->type->pm) {
if (dev->type && dev->type->pm) { 
buf : 		info = "type ";
buf : 		callback = pm_op(dev->type->pm, state);
buf : 		goto Driver;
buf : 	}
buf : 
buf : 	if (dev->class) {
if (dev->class) { 
buf : 		if (dev->class->pm) {
buf : 			info = "class ";
buf : 			callback = pm_op(dev->class->pm, state);
buf : 			goto Driver;
buf : 		} else if (dev->class->resume) {
if (dev->class->resume) { 
buf : 			info = "legacy class ";
buf : 			callback = dev->class->resume;
buf : 			goto End;
buf : 		}
buf : 	}
buf : 
buf : 	if (dev->bus) {
if (dev->bus) { 
buf : 		if (dev->bus->pm) {
buf : 			info = "bus ";
buf : 			callback = pm_op(dev->bus->pm, state);
buf : 		} else if (dev->bus->resume) {
if (dev->bus->resume) { 
buf : 			info = "legacy bus ";
buf : 			callback = dev->bus->resume;
buf : 			goto End;
buf : 		}
buf : 	}
buf : 
buf :  Driver:
buf : 	if (!callback && dev->driver && dev->driver->pm) {
if (!callback && dev->driver && dev->driver->pm) { 
buf : 		info = "driver ";
buf : 		callback = pm_op(dev->driver->pm, state);
buf : 	}
buf : 
buf :  End:
buf : 	error = dpm_run_callback(callback, dev, state, info);
buf : 	dev->power.is_suspended = false;
buf : 
buf :  Unlock:
buf : 	device_unlock(dev);
buf : 	dpm_watchdog_clear(&wd);
buf : 
buf :  Complete:
buf : 	complete_all(&dev->power.completion);
buf : 
buf : 	TRACE_RESUME(error);
buf : 
buf : 	return error;
buf : }
buf : 
buf : static void async_resume(void *data, async_cookie_t cookie)
buf : {
buf : 	struct device *dev = (struct device *)data;
buf : 	int error;
buf : 
buf : 	error = device_resume(dev, pm_transition, true);
buf : 	if (error)
if (error) 
buf : 		pm_dev_err(dev, pm_transition, " async", error);
buf : 	put_device(dev);
buf : }
buf : 
buf : /**
buf :  * dpm_resume - Execute "resume" callbacks for non-sysdev devices.
for non-sysdev devices. 
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Execute the appropriate "resume" callback for all devices whose status
for all devices whose status 
buf :  * indicates that they are suspended.
buf :  */
buf : void dpm_resume(pm_message_t state)
buf : {
buf : 	struct device *dev;
buf : 	ktime_t starttime = ktime_get();
buf : 
buf : 	trace_suspend_resume(TPS("dpm_resume"), state.event, true);
buf : 	might_sleep();
buf : 
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	pm_transition = state;
buf : 	async_error = 0;
buf : 
buf : 	list_for_each_entry(dev, &dpm_suspended_list, power.entry) {
for_each_entry(dev, &dpm_suspended_list, power.entry) { 
buf : 		reinit_completion(&dev->power.completion);
buf : 		if (is_async(dev)) {
if (is_async(dev)) { 
buf : 			get_device(dev);
buf : 			async_schedule(async_resume, dev);
buf : 		}
buf : 	}
buf : 
buf : 	while (!list_empty(&dpm_suspended_list)) {
while (!list_empty(&dpm_suspended_list)) { 
buf : 		dev = to_device(dpm_suspended_list.next);
buf : 		get_device(dev);
buf : 		if (!is_async(dev)) {
if (!is_async(dev)) { 
buf : 			int error;
buf : 
buf : 			mutex_unlock(&dpm_list_mtx);
buf : 
buf : 			error = device_resume(dev, state, false);
buf : 			if (error) {
if (error) { 
buf : 				suspend_stats.failed_resume++;
buf : 				dpm_save_failed_step(SUSPEND_RESUME);
buf : 				dpm_save_failed_dev(dev_name(dev));
buf : 				pm_dev_err(dev, state, "", error);
buf : 			}
buf : 
buf : 			mutex_lock(&dpm_list_mtx);
buf : 		}
buf : 		if (!list_empty(&dev->power.entry))
if (!list_empty(&dev->power.entry)) 
buf : 			list_move_tail(&dev->power.entry, &dpm_prepared_list);
buf : 		put_device(dev);
buf : 	}
buf : 	mutex_unlock(&dpm_list_mtx);
buf : 	async_synchronize_full();
buf : 	dpm_show_time(starttime, state, NULL);
buf : 
buf : 	cpufreq_resume();
buf : 	trace_suspend_resume(TPS("dpm_resume"), state.event, false);
buf : }
buf : 
buf : /**
buf :  * device_complete - Complete a PM transition for given device.
for given device. 
buf :  * @dev: Device to handle.
buf :  * @state: PM transition of the system being carried out.
buf :  */
buf : static void device_complete(struct device *dev, pm_message_t state)
buf : {
buf : 	void (*callback)(struct device *) = NULL;
buf : 	char *info = NULL;
buf : 
buf : 	if (dev->power.syscore)
if (dev->power.syscore) 
buf : 		return;
buf : 
buf : 	device_lock(dev);
buf : 
buf : 	if (dev->pm_domain) {
if (dev->pm_domain) { 
buf : 		info = "completing power domain ";
buf : 		callback = dev->pm_domain->ops.complete;
buf : 	} else if (dev->type && dev->type->pm) {
if (dev->type && dev->type->pm) { 
buf : 		info = "completing type ";
buf : 		callback = dev->type->pm->complete;
buf : 	} else if (dev->class && dev->class->pm) {
if (dev->class && dev->class->pm) { 
buf : 		info = "completing class ";
buf : 		callback = dev->class->pm->complete;
buf : 	} else if (dev->bus && dev->bus->pm) {
if (dev->bus && dev->bus->pm) { 
buf : 		info = "completing bus ";
buf : 		callback = dev->bus->pm->complete;
buf : 	}
buf : 
buf : 	if (!callback && dev->driver && dev->driver->pm) {
if (!callback && dev->driver && dev->driver->pm) { 
buf : 		info = "completing driver ";
buf : 		callback = dev->driver->pm->complete;
buf : 	}
buf : 
buf : 	if (callback) {
if (callback) { 
buf : 		pm_dev_dbg(dev, state, info);
buf : 		trace_device_pm_callback_start(dev, info, state.event);
buf : 		callback(dev);
buf : 		trace_device_pm_callback_end(dev, 0);
buf : 	}
buf : 
buf : 	device_unlock(dev);
buf : 
buf : 	pm_runtime_put(dev);
buf : }
buf : 
buf : /**
buf :  * dpm_complete - Complete a PM transition for all non-sysdev devices.
for all non-sysdev devices. 
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Execute the ->complete() callbacks for all devices whose PM status is not
for all devices whose PM status is not 
buf :  * DPM_ON (this allows new devices to be registered).
buf :  */
buf : void dpm_complete(pm_message_t state)
buf : {
buf : 	struct list_head list;
buf : 
buf : 	trace_suspend_resume(TPS("dpm_complete"), state.event, true);
buf : 	might_sleep();
buf : 
buf : 	INIT_LIST_HEAD(&list);
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	while (!list_empty(&dpm_prepared_list)) {
while (!list_empty(&dpm_prepared_list)) { 
buf : 		struct device *dev = to_device(dpm_prepared_list.prev);
buf : 
buf : 		get_device(dev);
buf : 		dev->power.is_prepared = false;
buf : 		list_move(&dev->power.entry, &list);
buf : 		mutex_unlock(&dpm_list_mtx);
buf : 
buf : 		device_complete(dev, state);
buf : 
buf : 		mutex_lock(&dpm_list_mtx);
buf : 		put_device(dev);
buf : 	}
buf : 	list_splice(&list, &dpm_list);
buf : 	mutex_unlock(&dpm_list_mtx);
buf : 	trace_suspend_resume(TPS("dpm_complete"), state.event, false);
buf : }
buf : 
buf : /**
buf :  * dpm_resume_end - Execute "resume" callbacks and complete system transition.
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Execute "resume" callbacks for all devices and complete the PM transition of
for all devices and complete the PM transition of 
buf :  * the system.
buf :  */
buf : void dpm_resume_end(pm_message_t state)
buf : {
buf : 	dpm_resume(state);
buf : 	dpm_complete(state);
buf : }
buf : EXPORT_SYMBOL_GPL(dpm_resume_end);
buf : 
buf : 
buf : /*------------------------- Suspend routines -------------------------*/
buf : 
buf : /**
buf :  * resume_event - Return a "resume" message for given "suspend" sleep state.
for given "suspend" sleep state. 
buf :  * @sleep_state: PM message representing a sleep state.
buf :  *
buf :  * Return a PM message representing the resume event corresponding to given
buf :  * sleep state.
buf :  */
buf : static pm_message_t resume_event(pm_message_t sleep_state)
buf : {
buf : 	switch (sleep_state.event) {
buf : 	case PM_EVENT_SUSPEND:
buf : 		return PMSG_RESUME;
buf : 	case PM_EVENT_FREEZE:
buf : 	case PM_EVENT_QUIESCE:
buf : 		return PMSG_RECOVER;
buf : 	case PM_EVENT_HIBERNATE:
buf : 		return PMSG_RESTORE;
buf : 	}
buf : 	return PMSG_ON;
buf : }
buf : 
buf : /**
buf :  * device_suspend_noirq - Execute a "late suspend" callback for given device.
for given device. 
buf :  * @dev: Device to handle.
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * The driver of @dev will not receive interrupts while this function is being
while this function is being 
buf :  * executed.
buf :  */
buf : static int __device_suspend_noirq(struct device *dev, pm_message_t state, bool async)
buf : {
buf : 	pm_callback_t callback = NULL;
buf : 	char *info = NULL;
buf : 	int error = 0;
buf : 
buf : 	if (async_error)
if (async_error) 
buf : 		goto Complete;
buf : 
buf : 	if (pm_wakeup_pending()) {
if (pm_wakeup_pending()) { 
buf : 		async_error = -EBUSY;
buf : 		goto Complete;
buf : 	}
buf : 
buf : 	if (dev->power.syscore || dev->power.direct_complete)
if (dev->power.syscore || dev->power.direct_complete) 
buf : 		goto Complete;
buf : 
buf : 	dpm_wait_for_children(dev, async);
for_children(dev, async); 
buf : 
buf : 	if (dev->pm_domain) {
buf : 		info = "noirq power domain ";
buf : 		callback = pm_noirq_op(&dev->pm_domain->ops, state);
buf : 	} else if (dev->type && dev->type->pm) {
if (dev->type && dev->type->pm) { 
buf : 		info = "noirq type ";
buf : 		callback = pm_noirq_op(dev->type->pm, state);
buf : 	} else if (dev->class && dev->class->pm) {
if (dev->class && dev->class->pm) { 
buf : 		info = "noirq class ";
buf : 		callback = pm_noirq_op(dev->class->pm, state);
buf : 	} else if (dev->bus && dev->bus->pm) {
if (dev->bus && dev->bus->pm) { 
buf : 		info = "noirq bus ";
buf : 		callback = pm_noirq_op(dev->bus->pm, state);
buf : 	}
buf : 
buf : 	if (!callback && dev->driver && dev->driver->pm) {
if (!callback && dev->driver && dev->driver->pm) { 
buf : 		info = "noirq driver ";
buf : 		callback = pm_noirq_op(dev->driver->pm, state);
buf : 	}
buf : 
buf : 	error = dpm_run_callback(callback, dev, state, info);
buf : 	if (!error)
if (!error) 
buf : 		dev->power.is_noirq_suspended = true;
buf : 	else
buf : 		async_error = error;
buf : 
buf : Complete:
buf : 	complete_all(&dev->power.completion);
buf : 	return error;
buf : }
buf : 
buf : static void async_suspend_noirq(void *data, async_cookie_t cookie)
buf : {
buf : 	struct device *dev = (struct device *)data;
buf : 	int error;
buf : 
buf : 	error = __device_suspend_noirq(dev, pm_transition, true);
buf : 	if (error) {
if (error) { 
buf : 		dpm_save_failed_dev(dev_name(dev));
buf : 		pm_dev_err(dev, pm_transition, " async", error);
buf : 	}
buf : 
buf : 	put_device(dev);
buf : }
buf : 
buf : static int device_suspend_noirq(struct device *dev)
buf : {
buf : 	reinit_completion(&dev->power.completion);
buf : 
buf : 	if (pm_async_enabled && dev->power.async_suspend) {
if (pm_async_enabled && dev->power.async_suspend) { 
buf : 		get_device(dev);
buf : 		async_schedule(async_suspend_noirq, dev);
buf : 		return 0;
buf : 	}
buf : 	return __device_suspend_noirq(dev, pm_transition, false);
buf : }
buf : 
buf : /**
buf :  * dpm_suspend_noirq - Execute "noirq suspend" callbacks for all devices.
for all devices. 
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Prevent device drivers from receiving interrupts and call the "noirq" suspend
buf :  * handlers for all non-sysdev devices.
for all non-sysdev devices. 
buf :  */
buf : static int dpm_suspend_noirq(pm_message_t state)
buf : {
buf : 	ktime_t starttime = ktime_get();
buf : 	int error = 0;
buf : 
buf : 	trace_suspend_resume(TPS("dpm_suspend_noirq"), state.event, true);
buf : 	cpuidle_pause();
buf : 	suspend_device_irqs();
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	pm_transition = state;
buf : 	async_error = 0;
buf : 
buf : 	while (!list_empty(&dpm_late_early_list)) {
while (!list_empty(&dpm_late_early_list)) { 
buf : 		struct device *dev = to_device(dpm_late_early_list.prev);
buf : 
buf : 		get_device(dev);
buf : 		mutex_unlock(&dpm_list_mtx);
buf : 
buf : 		error = device_suspend_noirq(dev);
buf : 
buf : 		mutex_lock(&dpm_list_mtx);
buf : 		if (error) {
if (error) { 
buf : 			pm_dev_err(dev, state, " noirq", error);
buf : 			dpm_save_failed_dev(dev_name(dev));
buf : 			put_device(dev);
buf : 			break;
buf : 		}
buf : 		if (!list_empty(&dev->power.entry))
if (!list_empty(&dev->power.entry)) 
buf : 			list_move(&dev->power.entry, &dpm_noirq_list);
buf : 		put_device(dev);
buf : 
buf : 		if (async_error)
if (async_error) 
buf : 			break;
buf : 	}
buf : 	mutex_unlock(&dpm_list_mtx);
buf : 	async_synchronize_full();
buf : 	if (!error)
if (!error) 
buf : 		error = async_error;
buf : 
buf : 	if (error) {
if (error) { 
buf : 		suspend_stats.failed_suspend_noirq++;
buf : 		dpm_save_failed_step(SUSPEND_SUSPEND_NOIRQ);
buf : 		dpm_resume_noirq(resume_event(state));
buf : 	} else {
buf : 		dpm_show_time(starttime, state, "noirq");
buf : 	}
buf : 	trace_suspend_resume(TPS("dpm_suspend_noirq"), state.event, false);
buf : 	return error;
buf : }
buf : 
buf : /**
buf :  * device_suspend_late - Execute a "late suspend" callback for given device.
for given device. 
buf :  * @dev: Device to handle.
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Runtime PM is disabled for @dev while this function is being executed.
for @dev while this function is being executed. 
buf :  */
buf : static int __device_suspend_late(struct device *dev, pm_message_t state, bool async)
buf : {
buf : 	pm_callback_t callback = NULL;
buf : 	char *info = NULL;
buf : 	int error = 0;
buf : 
buf : 	__pm_runtime_disable(dev, false);
buf : 
buf : 	if (async_error)
if (async_error) 
buf : 		goto Complete;
buf : 
buf : 	if (pm_wakeup_pending()) {
if (pm_wakeup_pending()) { 
buf : 		async_error = -EBUSY;
buf : 		goto Complete;
buf : 	}
buf : 
buf : 	if (dev->power.syscore || dev->power.direct_complete)
if (dev->power.syscore || dev->power.direct_complete) 
buf : 		goto Complete;
buf : 
buf : 	dpm_wait_for_children(dev, async);
for_children(dev, async); 
buf : 
buf : 	if (dev->pm_domain) {
buf : 		info = "late power domain ";
buf : 		callback = pm_late_early_op(&dev->pm_domain->ops, state);
buf : 	} else if (dev->type && dev->type->pm) {
if (dev->type && dev->type->pm) { 
buf : 		info = "late type ";
buf : 		callback = pm_late_early_op(dev->type->pm, state);
buf : 	} else if (dev->class && dev->class->pm) {
if (dev->class && dev->class->pm) { 
buf : 		info = "late class ";
buf : 		callback = pm_late_early_op(dev->class->pm, state);
buf : 	} else if (dev->bus && dev->bus->pm) {
if (dev->bus && dev->bus->pm) { 
buf : 		info = "late bus ";
buf : 		callback = pm_late_early_op(dev->bus->pm, state);
buf : 	}
buf : 
buf : 	if (!callback && dev->driver && dev->driver->pm) {
if (!callback && dev->driver && dev->driver->pm) { 
buf : 		info = "late driver ";
buf : 		callback = pm_late_early_op(dev->driver->pm, state);
buf : 	}
buf : 
buf : 	error = dpm_run_callback(callback, dev, state, info);
buf : 	if (!error)
if (!error) 
buf : 		dev->power.is_late_suspended = true;
buf : 	else
buf : 		async_error = error;
buf : 
buf : Complete:
buf : 	complete_all(&dev->power.completion);
buf : 	return error;
buf : }
buf : 
buf : static void async_suspend_late(void *data, async_cookie_t cookie)
buf : {
buf : 	struct device *dev = (struct device *)data;
buf : 	int error;
buf : 
buf : 	error = __device_suspend_late(dev, pm_transition, true);
buf : 	if (error) {
if (error) { 
buf : 		dpm_save_failed_dev(dev_name(dev));
buf : 		pm_dev_err(dev, pm_transition, " async", error);
buf : 	}
buf : 	put_device(dev);
buf : }
buf : 
buf : static int device_suspend_late(struct device *dev)
buf : {
buf : 	reinit_completion(&dev->power.completion);
buf : 
buf : 	if (pm_async_enabled && dev->power.async_suspend) {
if (pm_async_enabled && dev->power.async_suspend) { 
buf : 		get_device(dev);
buf : 		async_schedule(async_suspend_late, dev);
buf : 		return 0;
buf : 	}
buf : 
buf : 	return __device_suspend_late(dev, pm_transition, false);
buf : }
buf : 
buf : /**
buf :  * dpm_suspend_late - Execute "late suspend" callbacks for all devices.
for all devices. 
buf :  * @state: PM transition of the system being carried out.
buf :  */
buf : static int dpm_suspend_late(pm_message_t state)
buf : {
buf : 	ktime_t starttime = ktime_get();
buf : 	int error = 0;
buf : 
buf : 	trace_suspend_resume(TPS("dpm_suspend_late"), state.event, true);
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	pm_transition = state;
buf : 	async_error = 0;
buf : 
buf : 	while (!list_empty(&dpm_suspended_list)) {
while (!list_empty(&dpm_suspended_list)) { 
buf : 		struct device *dev = to_device(dpm_suspended_list.prev);
buf : 
buf : 		get_device(dev);
buf : 		mutex_unlock(&dpm_list_mtx);
buf : 
buf : 		error = device_suspend_late(dev);
buf : 
buf : 		mutex_lock(&dpm_list_mtx);
buf : 		if (error) {
if (error) { 
buf : 			pm_dev_err(dev, state, " late", error);
buf : 			dpm_save_failed_dev(dev_name(dev));
buf : 			put_device(dev);
buf : 			break;
buf : 		}
buf : 		if (!list_empty(&dev->power.entry))
if (!list_empty(&dev->power.entry)) 
buf : 			list_move(&dev->power.entry, &dpm_late_early_list);
buf : 		put_device(dev);
buf : 
buf : 		if (async_error)
if (async_error) 
buf : 			break;
buf : 	}
buf : 	mutex_unlock(&dpm_list_mtx);
buf : 	async_synchronize_full();
buf : 	if (error) {
if (error) { 
buf : 		suspend_stats.failed_suspend_late++;
buf : 		dpm_save_failed_step(SUSPEND_SUSPEND_LATE);
buf : 		dpm_resume_early(resume_event(state));
buf : 	} else {
buf : 		dpm_show_time(starttime, state, "late");
buf : 	}
buf : 	trace_suspend_resume(TPS("dpm_suspend_late"), state.event, false);
buf : 	return error;
buf : }
buf : 
buf : /**
buf :  * dpm_suspend_end - Execute "late" and "noirq" device suspend callbacks.
buf :  * @state: PM transition of the system being carried out.
buf :  */
buf : int dpm_suspend_end(pm_message_t state)
buf : {
buf : 	int error = dpm_suspend_late(state);
buf : 	if (error)
if (error) 
buf : 		return error;
buf : 
buf : 	error = dpm_suspend_noirq(state);
buf : 	if (error) {
if (error) { 
buf : 		dpm_resume_early(resume_event(state));
buf : 		return error;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL_GPL(dpm_suspend_end);
buf : 
buf : /**
buf :  * legacy_suspend - Execute a legacy (bus or class) suspend callback for device.
for device. 
buf :  * @dev: Device to suspend.
buf :  * @state: PM transition of the system being carried out.
buf :  * @cb: Suspend callback to execute.
buf :  */
buf : static int legacy_suspend(struct device *dev, pm_message_t state,
buf : 			  int (*cb)(struct device *dev, pm_message_t state),
buf : 			  char *info)
buf : {
buf : 	int error;
buf : 	ktime_t calltime;
buf : 
buf : 	calltime = initcall_debug_start(dev);
buf : 
buf : 	trace_device_pm_callback_start(dev, info, state.event);
buf : 	error = cb(dev, state);
buf : 	trace_device_pm_callback_end(dev, error);
buf : 	suspend_report_result(cb, error);
buf : 
buf : 	initcall_debug_report(dev, calltime, error, state, info);
buf : 
buf : 	return error;
buf : }
buf : 
buf : /**
buf :  * device_suspend - Execute "suspend" callbacks for given device.
for given device. 
buf :  * @dev: Device to handle.
buf :  * @state: PM transition of the system being carried out.
buf :  * @async: If true, the device is being suspended asynchronously.
buf :  */
buf : static int __device_suspend(struct device *dev, pm_message_t state, bool async)
buf : {
buf : 	pm_callback_t callback = NULL;
buf : 	char *info = NULL;
buf : 	int error = 0;
buf : 	DECLARE_DPM_WATCHDOG_ON_STACK(wd);
buf : 
buf : 	dpm_wait_for_children(dev, async);
for_children(dev, async); 
buf : 
buf : 	if (async_error)
buf : 		goto Complete;
buf : 
buf : 	/*
buf : 	 * If a device configured to wake up the system from sleep states
buf : 	 * has been suspended at run time and there's a resume request pending
buf : 	 * for it, this is equivalent to the device signaling wakeup, so the
for it, this is equivalent to the device signaling wakeup, so the 
buf : 	 * system suspend operation should be aborted.
buf : 	 */
buf : 	if (pm_runtime_barrier(dev) && device_may_wakeup(dev))
if (pm_runtime_barrier(dev) && device_may_wakeup(dev)) 
buf : 		pm_wakeup_event(dev, 0);
buf : 
buf : 	if (pm_wakeup_pending()) {
if (pm_wakeup_pending()) { 
buf : 		async_error = -EBUSY;
buf : 		goto Complete;
buf : 	}
buf : 
buf : 	if (dev->power.syscore)
if (dev->power.syscore) 
buf : 		goto Complete;
buf : 
buf : 	if (dev->power.direct_complete) {
if (dev->power.direct_complete) { 
buf : 		if (pm_runtime_status_suspended(dev)) {
buf : 			pm_runtime_disable(dev);
buf : 			if (pm_runtime_suspended_if_enabled(dev))
if (pm_runtime_suspended_if_enabled(dev)) 
buf : 				goto Complete;
buf : 
buf : 			pm_runtime_enable(dev);
buf : 		}
buf : 		dev->power.direct_complete = false;
buf : 	}
buf : 
buf : 	dpm_watchdog_set(&wd, dev);
buf : 	device_lock(dev);
buf : 
buf : 	if (dev->pm_domain) {
if (dev->pm_domain) { 
buf : 		info = "power domain ";
buf : 		callback = pm_op(&dev->pm_domain->ops, state);
buf : 		goto Run;
buf : 	}
buf : 
buf : 	if (dev->type && dev->type->pm) {
if (dev->type && dev->type->pm) { 
buf : 		info = "type ";
buf : 		callback = pm_op(dev->type->pm, state);
buf : 		goto Run;
buf : 	}
buf : 
buf : 	if (dev->class) {
if (dev->class) { 
buf : 		if (dev->class->pm) {
buf : 			info = "class ";
buf : 			callback = pm_op(dev->class->pm, state);
buf : 			goto Run;
buf : 		} else if (dev->class->suspend) {
if (dev->class->suspend) { 
buf : 			pm_dev_dbg(dev, state, "legacy class ");
buf : 			error = legacy_suspend(dev, state, dev->class->suspend,
buf : 						"legacy class ");
buf : 			goto End;
buf : 		}
buf : 	}
buf : 
buf : 	if (dev->bus) {
if (dev->bus) { 
buf : 		if (dev->bus->pm) {
buf : 			info = "bus ";
buf : 			callback = pm_op(dev->bus->pm, state);
buf : 		} else if (dev->bus->suspend) {
if (dev->bus->suspend) { 
buf : 			pm_dev_dbg(dev, state, "legacy bus ");
buf : 			error = legacy_suspend(dev, state, dev->bus->suspend,
buf : 						"legacy bus ");
buf : 			goto End;
buf : 		}
buf : 	}
buf : 
buf :  Run:
buf : 	if (!callback && dev->driver && dev->driver->pm) {
if (!callback && dev->driver && dev->driver->pm) { 
buf : 		info = "driver ";
buf : 		callback = pm_op(dev->driver->pm, state);
buf : 	}
buf : 
buf : 	error = dpm_run_callback(callback, dev, state, info);
buf : 
buf :  End:
buf : 	if (!error) {
if (!error) { 
buf : 		struct device *parent = dev->parent;
buf : 
buf : 		dev->power.is_suspended = true;
buf : 		if (parent) {
if (parent) { 
buf : 			spin_lock_irq(&parent->power.lock);
buf : 
buf : 			dev->parent->power.direct_complete = false;
buf : 			if (dev->power.wakeup_path
if (dev->power.wakeup_path 
buf : 			    && !dev->parent->power.ignore_children)
buf : 				dev->parent->power.wakeup_path = true;
buf : 
buf : 			spin_unlock_irq(&parent->power.lock);
buf : 		}
buf : 	}
buf : 
buf : 	device_unlock(dev);
buf : 	dpm_watchdog_clear(&wd);
buf : 
buf :  Complete:
buf : 	complete_all(&dev->power.completion);
buf : 	if (error)
if (error) 
buf : 		async_error = error;
buf : 
buf : 	return error;
buf : }
buf : 
buf : static void async_suspend(void *data, async_cookie_t cookie)
buf : {
buf : 	struct device *dev = (struct device *)data;
buf : 	int error;
buf : 
buf : 	error = __device_suspend(dev, pm_transition, true);
buf : 	if (error) {
if (error) { 
buf : 		dpm_save_failed_dev(dev_name(dev));
buf : 		pm_dev_err(dev, pm_transition, " async", error);
buf : 	}
buf : 
buf : 	put_device(dev);
buf : }
buf : 
buf : static int device_suspend(struct device *dev)
buf : {
buf : 	reinit_completion(&dev->power.completion);
buf : 
buf : 	if (pm_async_enabled && dev->power.async_suspend) {
if (pm_async_enabled && dev->power.async_suspend) { 
buf : 		get_device(dev);
buf : 		async_schedule(async_suspend, dev);
buf : 		return 0;
buf : 	}
buf : 
buf : 	return __device_suspend(dev, pm_transition, false);
buf : }
buf : 
buf : /**
buf :  * dpm_suspend - Execute "suspend" callbacks for all non-sysdev devices.
for all non-sysdev devices. 
buf :  * @state: PM transition of the system being carried out.
buf :  */
buf : int dpm_suspend(pm_message_t state)
buf : {
buf : 	ktime_t starttime = ktime_get();
buf : 	int error = 0;
buf : 
buf : 	trace_suspend_resume(TPS("dpm_suspend"), state.event, true);
buf : 	might_sleep();
buf : 
buf : 	cpufreq_suspend();
buf : 
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	pm_transition = state;
buf : 	async_error = 0;
buf : 	while (!list_empty(&dpm_prepared_list)) {
while (!list_empty(&dpm_prepared_list)) { 
buf : 		struct device *dev = to_device(dpm_prepared_list.prev);
buf : 
buf : 		get_device(dev);
buf : 		mutex_unlock(&dpm_list_mtx);
buf : 
buf : 		error = device_suspend(dev);
buf : 
buf : 		mutex_lock(&dpm_list_mtx);
buf : 		if (error) {
if (error) { 
buf : 			pm_dev_err(dev, state, "", error);
buf : 			dpm_save_failed_dev(dev_name(dev));
buf : 			put_device(dev);
buf : 			break;
buf : 		}
buf : 		if (!list_empty(&dev->power.entry))
if (!list_empty(&dev->power.entry)) 
buf : 			list_move(&dev->power.entry, &dpm_suspended_list);
buf : 		put_device(dev);
buf : 		if (async_error)
if (async_error) 
buf : 			break;
buf : 	}
buf : 	mutex_unlock(&dpm_list_mtx);
buf : 	async_synchronize_full();
buf : 	if (!error)
if (!error) 
buf : 		error = async_error;
buf : 	if (error) {
if (error) { 
buf : 		suspend_stats.failed_suspend++;
buf : 		dpm_save_failed_step(SUSPEND_SUSPEND);
buf : 	} else
buf : 		dpm_show_time(starttime, state, NULL);
buf : 	trace_suspend_resume(TPS("dpm_suspend"), state.event, false);
buf : 	return error;
buf : }
buf : 
buf : /**
buf :  * device_prepare - Prepare a device for system power transition.
for system power transition. 
buf :  * @dev: Device to handle.
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Execute the ->prepare() callback(s) for given device.  No new children of the
for given device.  No new children of the 
buf :  * device may be registered after this function has returned.
buf :  */
buf : static int device_prepare(struct device *dev, pm_message_t state)
buf : {
buf : 	int (*callback)(struct device *) = NULL;
buf : 	char *info = NULL;
buf : 	int ret = 0;
buf : 
buf : 	if (dev->power.syscore)
if (dev->power.syscore) 
buf : 		return 0;
buf : 
buf : 	/*
buf : 	 * If a device's parent goes into runtime suspend at the wrong time,
buf : 	 * it won't be possible to resume the device.  To prevent this we
buf : 	 * block runtime suspend here, during the prepare phase, and allow
buf : 	 * it again during the complete phase.
buf : 	 */
buf : 	pm_runtime_get_noresume(dev);
buf : 
buf : 	device_lock(dev);
buf : 
buf : 	dev->power.wakeup_path = device_may_wakeup(dev);
buf : 
buf : 	if (dev->pm_domain) {
if (dev->pm_domain) { 
buf : 		info = "preparing power domain ";
buf : 		callback = dev->pm_domain->ops.prepare;
buf : 	} else if (dev->type && dev->type->pm) {
if (dev->type && dev->type->pm) { 
buf : 		info = "preparing type ";
buf : 		callback = dev->type->pm->prepare;
buf : 	} else if (dev->class && dev->class->pm) {
if (dev->class && dev->class->pm) { 
buf : 		info = "preparing class ";
buf : 		callback = dev->class->pm->prepare;
buf : 	} else if (dev->bus && dev->bus->pm) {
if (dev->bus && dev->bus->pm) { 
buf : 		info = "preparing bus ";
buf : 		callback = dev->bus->pm->prepare;
buf : 	}
buf : 
buf : 	if (!callback && dev->driver && dev->driver->pm) {
if (!callback && dev->driver && dev->driver->pm) { 
buf : 		info = "preparing driver ";
buf : 		callback = dev->driver->pm->prepare;
buf : 	}
buf : 
buf : 	if (callback) {
if (callback) { 
buf : 		trace_device_pm_callback_start(dev, info, state.event);
buf : 		ret = callback(dev);
buf : 		trace_device_pm_callback_end(dev, ret);
buf : 	}
buf : 
buf : 	device_unlock(dev);
buf : 
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		suspend_report_result(callback, ret);
buf : 		pm_runtime_put(dev);
buf : 		return ret;
buf : 	}
buf : 	/*
buf : 	 * A positive return value from ->prepare() means "this device appears
buf : 	 * to be runtime-suspended and its state is fine, so if it really is
if it really is 
buf : 	 * runtime-suspended, you can leave it in that state provided that you
buf : 	 * will do the same thing with all of its descendants".  This only
buf : 	 * applies to suspend transitions, however.
buf : 	 */
buf : 	spin_lock_irq(&dev->power.lock);
buf : 	dev->power.direct_complete = ret > 0 && state.event == PM_EVENT_SUSPEND;
buf : 	spin_unlock_irq(&dev->power.lock);
buf : 	return 0;
buf : }
buf : 
buf : /**
buf :  * dpm_prepare - Prepare all non-sysdev devices for a system PM transition.
for a system PM transition. 
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Execute the ->prepare() callback(s) for all devices.
for all devices. 
buf :  */
buf : int dpm_prepare(pm_message_t state)
buf : {
buf : 	int error = 0;
buf : 
buf : 	trace_suspend_resume(TPS("dpm_prepare"), state.event, true);
buf : 	might_sleep();
buf : 
buf : 	mutex_lock(&dpm_list_mtx);
buf : 	while (!list_empty(&dpm_list)) {
while (!list_empty(&dpm_list)) { 
buf : 		struct device *dev = to_device(dpm_list.next);
buf : 
buf : 		get_device(dev);
buf : 		mutex_unlock(&dpm_list_mtx);
buf : 
buf : 		error = device_prepare(dev, state);
buf : 
buf : 		mutex_lock(&dpm_list_mtx);
buf : 		if (error) {
if (error) { 
buf : 			if (error == -EAGAIN) {
buf : 				put_device(dev);
buf : 				error = 0;
buf : 				continue;
buf : 			}
buf : 			printk(KERN_INFO "PM: Device %s not prepared "
buf : 				"for power transition: code %d\n",
for power transition: code %d\n", 
buf : 				dev_name(dev), error);
buf : 			put_device(dev);
buf : 			break;
buf : 		}
buf : 		dev->power.is_prepared = true;
buf : 		if (!list_empty(&dev->power.entry))
if (!list_empty(&dev->power.entry)) 
buf : 			list_move_tail(&dev->power.entry, &dpm_prepared_list);
buf : 		put_device(dev);
buf : 	}
buf : 	mutex_unlock(&dpm_list_mtx);
buf : 	trace_suspend_resume(TPS("dpm_prepare"), state.event, false);
buf : 	return error;
buf : }
buf : 
buf : /**
buf :  * dpm_suspend_start - Prepare devices for PM transition and suspend them.
for PM transition and suspend them. 
buf :  * @state: PM transition of the system being carried out.
buf :  *
buf :  * Prepare all non-sysdev devices for system PM transition and execute "suspend"
for system PM transition and execute "suspend" 
buf :  * callbacks for them.
buf :  */
buf : int dpm_suspend_start(pm_message_t state)
buf : {
buf : 	int error;
buf : 
buf : 	error = dpm_prepare(state);
buf : 	if (error) {
if (error) { 
buf : 		suspend_stats.failed_prepare++;
buf : 		dpm_save_failed_step(SUSPEND_PREPARE);
buf : 	} else
buf : 		error = dpm_suspend(state);
buf : 	return error;
buf : }
buf : EXPORT_SYMBOL_GPL(dpm_suspend_start);
buf : 
buf : void __suspend_report_result(const char *function, void *fn, int ret)
buf : {
buf : 	if (ret)
if (ret) 
buf : 		printk(KERN_ERR "%s(): %pF returns %d\n", function, fn, ret);
buf : }
buf : EXPORT_SYMBOL_GPL(__suspend_report_result);
buf : 
buf : /**
buf :  * device_pm_wait_for_dev - Wait for suspend/resume of a device to complete.
for_dev - Wait for suspend/resume of a device to complete. 
buf :  * @dev: Device to wait for.
buf :  * @subordinate: Device that needs to wait for @dev.
for @dev. 
buf :  */
buf : int device_pm_wait_for_dev(struct device *subordinate, struct device *dev)
for_dev(struct device *subordinate, struct device *dev) 
buf : {
buf : 	dpm_wait(dev, subordinate->power.async_suspend);
buf : 	return async_error;
buf : }
buf : EXPORT_SYMBOL_GPL(device_pm_wait_for_dev);
for_dev); 
buf : 
buf : /**
buf :  * dpm_for_each_dev - device iterator.
for_each_dev - device iterator. 
buf :  * @data: data for the callback.
buf :  * @fn: function to be called for each device.
for each device. 
buf :  *
buf :  * Iterate over devices in dpm_list, and call @fn for each device,
buf :  * passing it @data.
buf :  */
buf : void dpm_for_each_dev(void *data, void (*fn)(struct device *, void *))
for_each_dev(void *data, void (*fn)(struct device *, void *)) 
buf : {
buf : 	struct device *dev;
buf : 
buf : 	if (!fn)
if (!fn) 
buf : 		return;
buf : 
buf : 	device_pm_lock();
buf : 	list_for_each_entry(dev, &dpm_list, power.entry)
for_each_entry(dev, &dpm_list, power.entry) 
buf : 		fn(dev, data);
buf : 	device_pm_unlock();
buf : }
buf : EXPORT_SYMBOL_GPL(dpm_for_each_dev);
for_each_dev); 
file : ./test/kernel/drivers/mtd/nand/bcm47xxnflash/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * BCM47XX NAND flash driver
buf :  *
buf :  * Copyright (C) 2012 Rafał Miłecki <zajec5@gmail.com>
buf :  *
buf :  * This program is free software; you can redistribute it and/or modify
ify 
buf :  * it under the terms of the GNU General Public License version 2 as
buf :  * published by the Free Software Foundation.
buf :  *
buf :  */
buf : 
buf : #include "bcm47xxnflash.h"
buf : 
buf : #include <linux/module.h>
buf : #include <linux/kernel.h>
buf : #include <linux/slab.h>
buf : #include <linux/platform_device.h>
form_device.h> 
buf : #include <linux/bcma/bcma.h>
buf : 
buf : MODULE_DESCRIPTION("NAND flash driver for BCMA bus");
for BCMA bus"); 
buf : MODULE_LICENSE("GPL");
buf : MODULE_AUTHOR("Rafał Miłecki");
buf : 
buf : static const char *probes[] = { "bcm47xxpart", NULL };
buf : 
buf : static int bcm47xxnflash_probe(struct platform_device *pdev)
form_device *pdev) 
buf : {
buf : 	struct bcma_nflash *nflash = dev_get_platdata(&pdev->dev);
buf : 	struct bcm47xxnflash *b47n;
buf : 	int err = 0;
buf : 
buf : 	b47n = devm_kzalloc(&pdev->dev, sizeof(*b47n), GFP_KERNEL);
buf : 	if (!b47n)
if (!b47n) 
buf : 		return -ENOMEM;
buf : 
buf : 	b47n->nand_chip.priv = b47n;
buf : 	b47n->mtd.owner = THIS_MODULE;
buf : 	b47n->mtd.priv = &b47n->nand_chip; /* Required */
buf : 	b47n->cc = container_of(nflash, struct bcma_drv_cc, nflash);
buf : 
buf : 	if (b47n->cc->core->bus->chipinfo.id == BCMA_CHIP_ID_BCM4706) {
if (b47n->cc->core->bus->chipinfo.id == BCMA_CHIP_ID_BCM4706) { 
buf : 		err = bcm47xxnflash_ops_bcm4706_init(b47n);
buf : 	} else {
buf : 		pr_err("Device not supported\n");
buf : 		err = -ENOTSUPP;
buf : 	}
buf : 	if (err) {
if (err) { 
buf : 		pr_err("Initialization failed: %d\n", err);
buf : 		return err;
buf : 	}
buf : 
buf : 	err = mtd_device_parse_register(&b47n->mtd, probes, NULL, NULL, 0);
buf : 	if (err) {
if (err) { 
buf : 		pr_err("Failed to register MTD device: %d\n", err);
buf : 		return err;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int bcm47xxnflash_remove(struct platform_device *pdev)
form_device *pdev) 
buf : {
buf : 	struct bcma_nflash *nflash = dev_get_platdata(&pdev->dev);
buf : 
buf : 	if (nflash->mtd)
if (nflash->mtd) 
buf : 		mtd_device_unregister(nflash->mtd);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static struct platform_driver bcm47xxnflash_driver = {
form_driver bcm47xxnflash_driver = { 
buf : 	.probe	= bcm47xxnflash_probe,
buf : 	.remove = bcm47xxnflash_remove,
buf : 	.driver = {
buf : 		.name = "bcma_nflash",
buf : 		.owner = THIS_MODULE,
buf : 	},
buf : };
buf : 
buf : module_platform_driver(bcm47xxnflash_driver);
form_driver(bcm47xxnflash_driver); 
file : ./test/kernel/drivers/staging/speakup/main.c 
[ OK ] open : 4 ok... 
buf : /* speakup.c
buf :  * review functions for the speakup screen review package.
for the speakup screen review package. 
buf :  * originally written by: Kirk Reiser and Andy Berdan.
buf :  *
buf :  * extensively modified by David Borowski.
ified by David Borowski. 
buf :  *
buf :  ** Copyright (C) 1998  Kirk Reiser.
buf :  *  Copyright (C) 2003  David Borowski.
buf :  *
buf :  *  This program is free software; you can redistribute it and/or modify
ify 
buf :  *  it under the terms of the GNU General Public License as published by
buf :  *  the Free Software Foundation; either version 2 of the License, or
buf :  *  (at your option) any later version.
buf :  *
buf :  *  This program is distributed in the hope that it will be useful,
buf :  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
buf :  *  GNU General Public License for more details.
for more details. 
buf :  *
buf :  *  You should have received a copy of the GNU General Public License
buf :  *  along with this program; if not, write to the Free Software
if not, write to the Free Software 
buf :  *  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
buf : */
buf : 
buf : #include <linux/kernel.h>
buf : #include <linux/vt.h>
buf : #include <linux/tty.h>
buf : #include <linux/mm.h>		/* __get_free_page() and friends */
buf : #include <linux/vt_kern.h>
buf : #include <linux/ctype.h>
buf : #include <linux/selection.h>
buf : #include <linux/unistd.h>
buf : #include <linux/jiffies.h>
iffies.h> 
buf : #include <linux/kthread.h>
buf : #include <linux/keyboard.h>	/* for KT_SHIFT */
for KT_SHIFT */ 
buf : #include <linux/kbd_kern.h>	/* for vc_kbd_* and friends */
buf : #include <linux/input.h>
buf : #include <linux/kmod.h>
buf : 
buf : /* speakup_*_selection */
buf : #include <linux/module.h>
buf : #include <linux/sched.h>
buf : #include <linux/slab.h>
buf : #include <linux/types.h>
buf : #include <linux/consolemap.h>
buf : 
buf : #include <linux/spinlock.h>
buf : #include <linux/notifier.h>
ifier.h> 
buf : 
buf : #include <linux/uaccess.h>	/* copy_from|to|user() and others */
buf : 
buf : #include "spk_priv.h"
buf : #include "speakup.h"
buf : 
buf : #define MAX_DELAY msecs_to_jiffies(500)
iffies(500) 
buf : #define MINECHOCHAR SPACE
buf : 
buf : MODULE_AUTHOR("Kirk Reiser <kirk@braille.uwo.ca>");
buf : MODULE_AUTHOR("Daniel Drake <dsd@gentoo.org>");
buf : MODULE_DESCRIPTION("Speakup console speech");
buf : MODULE_LICENSE("GPL");
buf : MODULE_VERSION(SPEAKUP_VERSION);
buf : 
buf : char *synth_name;
buf : module_param_named(synth, synth_name, charp, S_IRUGO);
buf : module_param_named(quiet, spk_quiet_boot, bool, S_IRUGO);
buf : 
buf : MODULE_PARM_DESC(synth, "Synth to start if speakup is built in.");
if speakup is built in."); 
buf : MODULE_PARM_DESC(quiet, "Do not announce when the synthesizer is found.");
buf : 
buf : special_func spk_special_handler;
buf : 
buf : short spk_pitch_shift, synth_flags;
ift, synth_flags; 
buf : static char buf[256];
buf : int spk_attrib_bleep, spk_bleeps, spk_bleep_time = 10;
buf : int spk_no_intr, spk_spell_delay;
buf : int spk_key_echo, spk_say_word_ctl;
buf : int spk_say_ctrl, spk_bell_pos;
buf : short spk_punc_mask;
buf : int spk_punc_level, spk_reading_punc;
buf : char spk_str_caps_start[MAXVARLEN + 1] = "\0", spk_str_caps_stop[MAXVARLEN + 1] = "\0";
buf : const struct st_bits_data spk_punc_info[] = {
buf : 	{"none", "", 0},
buf : 	{"some", "/$%&@", SOME},
buf : 	{"most", "$%&#()=+*/@^<>|\\", MOST},
buf : 	{"all", "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~", PUNC},
buf : 	{"delimiters", "", B_WDLM},
buf : 	{"repeats", "()", CH_RPT},
buf : 	{"extended numeric", "", B_EXNUM},
buf : 	{"symbols", "", B_SYM},
buf : 	{NULL, NULL}
buf : };
buf : 
buf : static char mark_cut_flag;
buf : #define MAX_KEY 160
buf : static u_char *spk_shift_table;
ift_table; 
buf : u_char *spk_our_keys[MAX_KEY];
buf : u_char spk_key_buf[600];
buf : const u_char spk_key_defaults[] = {
buf : #include "speakupmap.h"
buf : };
buf : 
buf : /* Speakup Cursor Track Variables */
buf : static int cursor_track = 1, prev_cursor_track = 1;
buf : 
buf : /* cursor track modes, must be ordered same as cursor_msgs */
buf : enum {
buf : 	CT_Off = 0,
buf : 	CT_On,
buf : 	CT_Highlight,
buf : 	CT_Window,
buf : 	CT_Max
buf : };
buf : #define read_all_mode CT_Max
buf : 
buf : static struct tty_struct *tty;
buf : 
buf : static void spkup_write(const char *in_buf, int count);
buf : 
buf : static char *phonetic[] = {
buf : 	"alfa", "bravo", "charlie", "delta", "echo", "foxtrot", "golf", "hotel",
buf : 	"india", "juliett", "keelo", "leema", "mike", "november", "oscar",
buf : 	    "papa",
buf : 	"keh beck", "romeo", "sierra", "tango", "uniform", "victer", "whiskey",
iform", "victer", "whiskey", 
buf : 	"x ray", "yankee", "zulu"
buf : };
buf : 
buf : /* array of 256 char pointers (one for each character description)
for each character description) 
buf :  * initialized to default_chars and user selectable via
buf :  * /proc/speakup/characters */
buf : char *spk_characters[256];
buf : 
buf : char *spk_default_chars[256] = {
buf : /*000*/ "null", "^a", "^b", "^c", "^d", "^e", "^f", "^g",
buf : /*008*/ "^h", "^i", "^j", "^k", "^l", "^m", "^n", "^o",
buf : /*016*/ "^p", "^q", "^r", "^s", "^t", "^u", "^v", "^w",
buf : /*024*/ "^x", "^y", "^z", "control", "control", "control", "control",
buf : 	    "control",
buf : /*032*/ "space", "bang!", "quote", "number", "dollar", "percent", "and",
buf : 	    "tick",
buf : /*040*/ "left paren", "right paren", "star", "plus", "comma", "dash",
buf : 	    "dot",
buf : 	"slash",
buf : /*048*/ "zero", "one", "two", "three", "four", "five", "six", "seven",
buf : 	"eight", "nine",
buf : /*058*/ "colon", "semmy", "less", "equals", "greater", "question", "at",
buf : /*065*/ "EIGH", "B", "C", "D", "E", "F", "G",
buf : /*072*/ "H", "I", "J", "K", "L", "M", "N", "O",
buf : /*080*/ "P", "Q", "R", "S", "T", "U", "V", "W", "X",
buf : /*089*/ "Y", "ZED", "left bracket", "backslash", "right bracket",
buf : 	    "caret",
buf : 	"line",
buf : /*096*/ "accent", "a", "b", "c", "d", "e", "f", "g",
buf : /*104*/ "h", "i", "j", "k", "l", "m", "n", "o",
buf : /*112*/ "p", "q", "r", "s", "t", "u", "v", "w",
buf : /*120*/ "x", "y", "zed", "left brace", "bar", "right brace", "tihlduh",
buf : /*127*/ "del", "control", "control", "control", "control", "control",
buf : 	    "control", "control", "control", "control", "control",
buf : /*138*/ "control", "control", "control", "control", "control",
buf : 	    "control", "control", "control", "control", "control",
buf : 	    "control", "control",
buf : /*150*/ "control", "control", "control", "control", "control",
buf : 	    "control", "control", "control", "control", "control",
buf : /*160*/ "nbsp", "inverted bang",
buf : /*162*/ "cents", "pounds", "currency", "yen", "broken bar", "section",
buf : /*168*/ "diaeresis", "copyright", "female ordinal", "double left angle",
buf : /*172*/ "not", "soft hyphen", "registered", "macron",
buf : /*176*/ "degrees", "plus or minus", "super two", "super three",
buf : /*180*/ "acute accent", "micro", "pilcrow", "middle dot",
buf : /*184*/ "cedilla", "super one", "male ordinal", "double right angle",
buf : /*188*/ "one quarter", "one half", "three quarters",
buf : 	    "inverted question",
buf : /*192*/ "A GRAVE", "A ACUTE", "A CIRCUMFLEX", "A TILDE", "A OOMLAUT",
buf : 	    "A RING",
buf : /*198*/ "AE", "C CIDELLA", "E GRAVE", "E ACUTE", "E CIRCUMFLEX",
buf : 	    "E OOMLAUT",
buf : /*204*/ "I GRAVE", "I ACUTE", "I CIRCUMFLEX", "I OOMLAUT", "ETH",
buf : 	    "N TILDE",
buf : /*210*/ "O GRAVE", "O ACUTE", "O CIRCUMFLEX", "O TILDE", "O OOMLAUT",
buf : /*215*/ "multiplied by", "O STROKE", "U GRAVE", "U ACUTE",
buf : 	    "U CIRCUMFLEX",
buf : /*220*/ "U OOMLAUT", "Y ACUTE", "THORN", "sharp s", "a grave",
buf : /*225*/ "a acute", "a circumflex", "a tilde", "a oomlaut", "a ring",
buf : /*230*/ "ae", "c cidella", "e grave", "e acute",
buf : /*234*/ "e circumflex", "e oomlaut", "i grave", "i acute",
buf : 	    "i circumflex",
buf : /*239*/ "i oomlaut", "eth", "n tilde", "o grave", "o acute",
buf : 	    "o circumflex",
buf : /*245*/ "o tilde", "o oomlaut", "divided by", "o stroke", "u grave",
buf : 	    "u acute",
buf : /* 251 */ "u circumflex", "u oomlaut", "y acute", "thorn", "y oomlaut"
buf : };
buf : 
buf : /* array of 256 u_short (one for each character)
for each character) 
buf :  * initialized to default_chartab and user selectable via
buf :  * /sys/module/speakup/parameters/chartab */
buf : u_short spk_chartab[256];
buf : 
buf : static u_short default_chartab[256] = {
buf : 	B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL,	/* 0-7 */
buf : 	B_CTL, B_CTL, A_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL,	/* 8-15 */
buf : 	B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL,	/*16-23 */
buf : 	B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL,	/* 24-31 */
buf : 	WDLM, A_PUNC, PUNC, PUNC, PUNC, PUNC, PUNC, A_PUNC,	/*  !"#$%&' */
buf : 	PUNC, PUNC, PUNC, PUNC, A_PUNC, A_PUNC, A_PUNC, PUNC,	/* ()*+, -./ */
buf : 	NUM, NUM, NUM, NUM, NUM, NUM, NUM, NUM,	/* 01234567 */
buf : 	NUM, NUM, A_PUNC, PUNC, PUNC, PUNC, PUNC, A_PUNC,	/* 89:;<=>? */
buf : 	PUNC, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* @ABCDEFG */
buf : 	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* HIJKLMNO */
buf : 	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* PQRSTUVW */
buf : 	A_CAP, A_CAP, A_CAP, PUNC, PUNC, PUNC, PUNC, PUNC,	/* XYZ[\]^_ */
buf : 	PUNC, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* `abcdefg */
buf : 	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* hijklmno */
buf : 	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* pqrstuvw */
buf : 	ALPHA, ALPHA, ALPHA, PUNC, PUNC, PUNC, PUNC, 0,	/* xyz{|}~ */
buf : 	B_CAPSYM, B_CAPSYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, /* 128-134 */
buf : 	B_SYM,	/* 135 */
buf : 	B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, /* 136-142 */
buf : 	B_CAPSYM,	/* 143 */
buf : 	B_CAPSYM, B_CAPSYM, B_SYM, B_CAPSYM, B_SYM, B_SYM, B_SYM, /* 144-150 */
buf : 	B_SYM,	/* 151 */
buf : 	B_SYM, B_SYM, B_CAPSYM, B_CAPSYM, B_SYM, B_SYM, B_SYM, /*152-158 */
buf : 	B_SYM,	/* 159 */
buf : 	WDLM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_CAPSYM, /* 160-166 */
buf : 	B_SYM,	/* 167 */
buf : 	B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM,	/* 168-175 */
buf : 	B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM,	/* 176-183 */
buf : 	B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM,	/* 184-191 */
buf : 	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* 192-199 */
buf : 	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* 200-207 */
buf : 	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, B_SYM,	/* 208-215 */
buf : 	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, ALPHA,	/* 216-223 */
buf : 	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* 224-231 */
buf : 	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* 232-239 */
buf : 	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, B_SYM,	/* 240-247 */
buf : 	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA	/* 248-255 */
buf : };
buf : 
buf : struct task_struct *speakup_task;
buf : struct bleep spk_unprocessed_sound;
buf : static int spk_keydown;
buf : static u_char spk_lastkey, spk_close_press, keymap_flags;
buf : static u_char last_keycode, this_speakup_key;
buf : static u_long last_spk_jiffy;
iffy; 
buf : 
buf : struct st_spk_t *speakup_console[MAX_NR_CONSOLES];
buf : 
buf : DEFINE_MUTEX(spk_mutex);
buf : 
buf : static int keyboard_notifier_call(struct notifier_block *,
ifier_call(struct notifier_block *, 
buf : 				  unsigned long code, void *param);
buf : 
buf : static struct notifier_block keyboard_notifier_block = {
ifier_block keyboard_notifier_block = { 
buf : 	.notifier_call = keyboard_notifier_call,
buf : };
buf : 
buf : static int vt_notifier_call(struct notifier_block *,
ifier_call(struct notifier_block *, 
buf : 			    unsigned long code, void *param);
buf : 
buf : static struct notifier_block vt_notifier_block = {
ifier_block vt_notifier_block = { 
buf : 	.notifier_call = vt_notifier_call,
buf : };
buf : 
buf : static unsigned char get_attributes(u16 *pos)
buf : {
buf : 	return (u_char) (scr_readw(pos) >> 8);
buf : }
buf : 
buf : static void speakup_date(struct vc_data *vc)
buf : {
buf : 	spk_x = spk_cx = vc->vc_x;
buf : 	spk_y = spk_cy = vc->vc_y;
buf : 	spk_pos = spk_cp = vc->vc_pos;
buf : 	spk_old_attr = spk_attr;
buf : 	spk_attr = get_attributes((u_short *) spk_pos);
buf : }
buf : 
buf : static void bleep(u_short val)
buf : {
buf : 	static const short vals[] = {
buf : 		350, 370, 392, 414, 440, 466, 491, 523, 554, 587, 619, 659
buf : 	};
buf : 	short freq;
buf : 	int time = spk_bleep_time;
buf : 	freq = vals[val % 12];
buf : 	if (val > 11)
if (val > 11) 
buf : 		freq *= (1 << (val / 12));
buf : 	spk_unprocessed_sound.freq = freq;
buf : 	spk_unprocessed_sound.jiffies = msecs_to_jiffies(time);
iffies = msecs_to_jiffies(time); 
buf : 	spk_unprocessed_sound.active = 1;
buf : 	/* We can only have 1 active sound at a time. */
buf : }
buf : 
buf : static void speakup_shut_up(struct vc_data *vc)
buf : {
buf : 	if (spk_killed)
if (spk_killed) 
buf : 		return;
buf : 	spk_shut_up |= 0x01;
buf : 	spk_parked &= 0xfe;
buf : 	speakup_date(vc);
buf : 	if (synth != NULL)
if (synth != NULL) 
buf : 		spk_do_flush();
buf : }
buf : 
buf : static void speech_kill(struct vc_data *vc)
buf : {
buf : 	char val = synth->is_alive(synth);
buf : 	if (val == 0)
if (val == 0) 
buf : 		return;
buf : 
buf : 	/* re-enables synth, if disabled */
if disabled */ 
buf : 	if (val == 2 || spk_killed) {
buf : 		/* dead */
buf : 		spk_shut_up &= ~0x40;
buf : 		synth_printf("%s\n", spk_msg_get(MSG_IAM_ALIVE));
buf : 	} else {
buf : 		synth_printf("%s\n", spk_msg_get(MSG_YOU_KILLED_SPEAKUP));
buf : 		spk_shut_up |= 0x40;
buf : 	}
buf : }
buf : 
buf : static void speakup_off(struct vc_data *vc)
buf : {
buf : 	if (spk_shut_up & 0x80) {
if (spk_shut_up & 0x80) { 
buf : 		spk_shut_up &= 0x7f;
buf : 		synth_printf("%s\n", spk_msg_get(MSG_HEY_THATS_BETTER));
buf : 	} else {
buf : 		spk_shut_up |= 0x80;
buf : 		synth_printf("%s\n", spk_msg_get(MSG_YOU_TURNED_ME_OFF));
buf : 	}
buf : 	speakup_date(vc);
buf : }
buf : 
buf : static void speakup_parked(struct vc_data *vc)
buf : {
buf : 	if (spk_parked & 0x80) {
if (spk_parked & 0x80) { 
buf : 		spk_parked = 0;
buf : 		synth_printf("%s\n", spk_msg_get(MSG_UNPARKED));
buf : 	} else {
buf : 		spk_parked |= 0x80;
buf : 		synth_printf("%s\n", spk_msg_get(MSG_PARKED));
buf : 	}
buf : }
buf : 
buf : static void speakup_cut(struct vc_data *vc)
buf : {
buf : 	static const char err_buf[] = "set selection failed";
buf : 	int ret;
buf : 
buf : 	if (!mark_cut_flag) {
if (!mark_cut_flag) { 
buf : 		mark_cut_flag = 1;
buf : 		spk_xs = (u_short) spk_x;
buf : 		spk_ys = (u_short) spk_y;
buf : 		spk_sel_cons = vc;
buf : 		synth_printf("%s\n", spk_msg_get(MSG_MARK));
buf : 		return;
buf : 	}
buf : 	spk_xe = (u_short) spk_x;
buf : 	spk_ye = (u_short) spk_y;
buf : 	mark_cut_flag = 0;
buf : 	synth_printf("%s\n", spk_msg_get(MSG_CUT));
buf : 
buf : 	speakup_clear_selection();
buf : 	ret = speakup_set_selection(tty);
buf : 
buf : 	switch (ret) {
buf : 	case 0:
buf : 		break;		/* no error */
buf : 	case -EFAULT:
buf : 		pr_warn("%sEFAULT\n", err_buf);
buf : 		break;
buf : 	case -EINVAL:
buf : 		pr_warn("%sEINVAL\n", err_buf);
buf : 		break;
buf : 	case -ENOMEM:
buf : 		pr_warn("%sENOMEM\n", err_buf);
buf : 		break;
buf : 	}
buf : }
buf : 
buf : static void speakup_paste(struct vc_data *vc)
buf : {
buf : 	if (mark_cut_flag) {
if (mark_cut_flag) { 
buf : 		mark_cut_flag = 0;
buf : 		synth_printf("%s\n", spk_msg_get(MSG_MARK_CLEARED));
buf : 	} else {
buf : 		synth_printf("%s\n", spk_msg_get(MSG_PASTE));
buf : 		speakup_paste_selection(tty);
buf : 	}
buf : }
buf : 
buf : static void say_attributes(struct vc_data *vc)
buf : {
buf : 	int fg = spk_attr & 0x0f;
buf : 	int bg = spk_attr >> 4;
buf : 	if (fg > 8) {
if (fg > 8) { 
buf : 		synth_printf("%s ", spk_msg_get(MSG_BRIGHT));
buf : 		fg -= 8;
buf : 	}
buf : 	synth_printf("%s", spk_msg_get(MSG_COLORS_START + fg));
buf : 	if (bg > 7) {
if (bg > 7) { 
buf : 		synth_printf(" %s ", spk_msg_get(MSG_ON_BLINKING));
buf : 		bg -= 8;
buf : 	} else
buf : 		synth_printf(" %s ", spk_msg_get(MSG_ON));
buf : 	synth_printf("%s\n", spk_msg_get(MSG_COLORS_START + bg));
buf : }
buf : 
buf : enum {
buf : 	edge_top = 1,
buf : 	edge_bottom,
buf : 	edge_left,
buf : 	edge_right,
buf : 	edge_quiet
buf : };
buf : 
buf : static void announce_edge(struct vc_data *vc, int msg_id)
buf : {
buf : 	if (spk_bleeps & 1)
if (spk_bleeps & 1) 
buf : 		bleep(spk_y);
buf : 	if ((spk_bleeps & 2) && (msg_id < edge_quiet))
if ((spk_bleeps & 2) && (msg_id < edge_quiet)) 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_EDGE_MSGS_START + msg_id - 1));
buf : }
buf : 
buf : static void speak_char(u_char ch)
buf : {
buf : 	char *cp = spk_characters[ch];
buf : 	struct var_t *direct = spk_get_var(DIRECT);
buf : 	if (direct && direct->u.n.value) {
if (direct && direct->u.n.value) { 
buf : 		if (IS_CHAR(ch, B_CAP)) {
buf : 			spk_pitch_shift++;
ift++; 
buf : 			synth_printf("%s", spk_str_caps_start);
buf : 		}
buf : 		synth_printf("%c", ch);
buf : 		if (IS_CHAR(ch, B_CAP))
if (IS_CHAR(ch, B_CAP)) 
buf : 			synth_printf("%s", spk_str_caps_stop);
buf : 		return;
buf : 	}
buf : 	if (cp == NULL) {
if (cp == NULL) { 
buf : 		pr_info("speak_char: cp == NULL!\n");
buf : 		return;
buf : 	}
buf : 	synth_buffer_add(SPACE);
buf : 	if (IS_CHAR(ch, B_CAP)) {
if (IS_CHAR(ch, B_CAP)) { 
buf : 		spk_pitch_shift++;
buf : 		synth_printf("%s", spk_str_caps_start);
buf : 		synth_printf("%s", cp);
buf : 		synth_printf("%s", spk_str_caps_stop);
buf : 	} else {
buf : 		if (*cp == '^') {
if (*cp == '^') { 
buf : 			synth_printf("%s", spk_msg_get(MSG_CTRL));
buf : 			cp++;
buf : 		}
buf : 		synth_printf("%s", cp);
buf : 	}
buf : 	synth_buffer_add(SPACE);
buf : }
buf : 
buf : static u16 get_char(struct vc_data *vc, u16 *pos, u_char *attribs)
buf : {
buf : 	u16 ch = ' ';
buf : 	if (vc && pos) {
if (vc && pos) { 
buf : 		u16 w = scr_readw(pos);
buf : 		u16 c = w & 0xff;
buf : 
buf : 		if (w & vc->vc_hi_font_mask)
if (w & vc->vc_hi_font_mask) 
buf : 			c |= 0x100;
buf : 
buf : 		ch = inverse_translate(vc, c, 0);
buf : 		*attribs = (w & 0xff00) >> 8;
buf : 	}
buf : 	return ch;
buf : }
buf : 
buf : static void say_char(struct vc_data *vc)
buf : {
buf : 	u_short ch;
buf : 	spk_old_attr = spk_attr;
buf : 	ch = get_char(vc, (u_short *) spk_pos, &spk_attr);
buf : 	if (spk_attr != spk_old_attr) {
if (spk_attr != spk_old_attr) { 
buf : 		if (spk_attrib_bleep & 1)
buf : 			bleep(spk_y);
buf : 		if (spk_attrib_bleep & 2)
if (spk_attrib_bleep & 2) 
buf : 			say_attributes(vc);
buf : 	}
buf : 	speak_char(ch & 0xff);
buf : }
buf : 
buf : static void say_phonetic_char(struct vc_data *vc)
buf : {
buf : 	u_short ch;
buf : 	spk_old_attr = spk_attr;
buf : 	ch = get_char(vc, (u_short *) spk_pos, &spk_attr);
buf : 	if (isascii(ch) && isalpha(ch)) {
if (isascii(ch) && isalpha(ch)) { 
buf : 		ch &= 0x1f;
buf : 		synth_printf("%s\n", phonetic[--ch]);
buf : 	} else {
buf : 		if (IS_CHAR(ch, B_NUM))
if (IS_CHAR(ch, B_NUM)) 
buf : 			synth_printf("%s ", spk_msg_get(MSG_NUMBER));
buf : 		speak_char(ch);
buf : 	}
buf : }
buf : 
buf : static void say_prev_char(struct vc_data *vc)
buf : {
buf : 	spk_parked |= 0x01;
buf : 	if (spk_x == 0) {
if (spk_x == 0) { 
buf : 		announce_edge(vc, edge_left);
buf : 		return;
buf : 	}
buf : 	spk_x--;
buf : 	spk_pos -= 2;
buf : 	say_char(vc);
buf : }
buf : 
buf : static void say_next_char(struct vc_data *vc)
buf : {
buf : 	spk_parked |= 0x01;
buf : 	if (spk_x == vc->vc_cols - 1) {
if (spk_x == vc->vc_cols - 1) { 
buf : 		announce_edge(vc, edge_right);
buf : 		return;
buf : 	}
buf : 	spk_x++;
buf : 	spk_pos += 2;
buf : 	say_char(vc);
buf : }
buf : 
buf : /* get_word - will first check to see if the character under the
if the character under the 
buf :  * reading cursor is a space and if spk_say_word_ctl is true it will
buf :  * return the word space.  If spk_say_word_ctl is not set it will check to
buf :  * see if there is a word starting on the next position to the right
if there is a word starting on the next position to the right 
buf :  * and return that word if it exists.  If it does not exist it will
buf :  * move left to the beginning of any previous word on the line or the
buf :  * beginning off the line whichever comes first.. */
buf : 
buf : static u_long get_word(struct vc_data *vc)
buf : {
buf : 	u_long cnt = 0, tmpx = spk_x, tmp_pos = spk_pos;
buf : 	char ch;
buf : 	u_short attr_ch;
buf : 	u_char temp;
buf : 	spk_old_attr = spk_attr;
buf : 	ch = (char)get_char(vc, (u_short *) tmp_pos, &temp);
buf : 
buf : /* decided to take out the sayword if on a space (mis-information */
if on a space (mis-information */ 
buf : 	if (spk_say_word_ctl && ch == SPACE) {
buf : 		*buf = '\0';
buf : 		synth_printf("%s\n", spk_msg_get(MSG_SPACE));
buf : 		return 0;
buf : 	} else if ((tmpx < vc->vc_cols - 2)
if ((tmpx < vc->vc_cols - 2) 
buf : 		   && (ch == SPACE || ch == 0 || IS_WDLM(ch))
buf : 		   && ((char)get_char(vc, (u_short *) &tmp_pos + 1, &temp) >
buf : 		       SPACE)) {
buf : 		tmp_pos += 2;
buf : 		tmpx++;
buf : 	} else
buf : 		while (tmpx > 0) {
while (tmpx > 0) { 
buf : 			ch = (char)get_char(vc, (u_short *) tmp_pos - 1, &temp);
buf : 			if ((ch == SPACE || ch == 0 || IS_WDLM(ch))
if ((ch == SPACE || ch == 0 || IS_WDLM(ch)) 
buf : 			    && ((char)get_char(vc, (u_short *) tmp_pos, &temp) >
buf : 				SPACE))
buf : 				break;
buf : 			tmp_pos -= 2;
buf : 			tmpx--;
buf : 		}
buf : 	attr_ch = get_char(vc, (u_short *) tmp_pos, &spk_attr);
buf : 	buf[cnt++] = attr_ch & 0xff;
buf : 	while (tmpx < vc->vc_cols - 1) {
while (tmpx < vc->vc_cols - 1) { 
buf : 		tmp_pos += 2;
buf : 		tmpx++;
buf : 		ch = (char)get_char(vc, (u_short *) tmp_pos, &temp);
buf : 		if ((ch == SPACE) || ch == 0
if ((ch == SPACE) || ch == 0 
buf : 		    || (IS_WDLM(buf[cnt - 1]) && (ch > SPACE)))
buf : 			break;
buf : 		buf[cnt++] = ch;
buf : 	}
buf : 	buf[cnt] = '\0';
buf : 	return cnt;
buf : }
buf : 
buf : static void say_word(struct vc_data *vc)
buf : {
buf : 	u_long cnt = get_word(vc);
buf : 	u_short saved_punc_mask = spk_punc_mask;
buf : 	if (cnt == 0)
if (cnt == 0) 
buf : 		return;
buf : 	spk_punc_mask = PUNC;
buf : 	buf[cnt++] = SPACE;
buf : 	spkup_write(buf, cnt);
buf : 	spk_punc_mask = saved_punc_mask;
buf : }
buf : 
buf : static void say_prev_word(struct vc_data *vc)
buf : {
buf : 	u_char temp;
buf : 	char ch;
buf : 	u_short edge_said = 0, last_state = 0, state = 0;
buf : 	spk_parked |= 0x01;
buf : 
buf : 	if (spk_x == 0) {
if (spk_x == 0) { 
buf : 		if (spk_y == 0) {
buf : 			announce_edge(vc, edge_top);
buf : 			return;
buf : 		}
buf : 		spk_y--;
buf : 		spk_x = vc->vc_cols;
buf : 		edge_said = edge_quiet;
buf : 	}
buf : 	while (1) {
while (1) { 
buf : 		if (spk_x == 0) {
buf : 			if (spk_y == 0) {
if (spk_y == 0) { 
buf : 				edge_said = edge_top;
buf : 				break;
buf : 			}
buf : 			if (edge_said != edge_quiet)
if (edge_said != edge_quiet) 
buf : 				edge_said = edge_left;
buf : 			if (state > 0)
if (state > 0) 
buf : 				break;
buf : 			spk_y--;
buf : 			spk_x = vc->vc_cols - 1;
buf : 		} else
buf : 			spk_x--;
buf : 		spk_pos -= 2;
buf : 		ch = (char)get_char(vc, (u_short *) spk_pos, &temp);
buf : 		if (ch == SPACE || ch == 0)
if (ch == SPACE || ch == 0) 
buf : 			state = 0;
buf : 		else if (IS_WDLM(ch))
if (IS_WDLM(ch)) 
buf : 			state = 1;
buf : 		else
buf : 			state = 2;
buf : 		if (state < last_state) {
if (state < last_state) { 
buf : 			spk_pos += 2;
buf : 			spk_x++;
buf : 			break;
buf : 		}
buf : 		last_state = state;
buf : 	}
buf : 	if (spk_x == 0 && edge_said == edge_quiet)
if (spk_x == 0 && edge_said == edge_quiet) 
buf : 		edge_said = edge_left;
buf : 	if (edge_said > 0 && edge_said < edge_quiet)
if (edge_said > 0 && edge_said < edge_quiet) 
buf : 		announce_edge(vc, edge_said);
buf : 	say_word(vc);
buf : }
buf : 
buf : static void say_next_word(struct vc_data *vc)
buf : {
buf : 	u_char temp;
buf : 	char ch;
buf : 	u_short edge_said = 0, last_state = 2, state = 0;
buf : 	spk_parked |= 0x01;
buf : 
buf : 	if (spk_x == vc->vc_cols - 1 && spk_y == vc->vc_rows - 1) {
if (spk_x == vc->vc_cols - 1 && spk_y == vc->vc_rows - 1) { 
buf : 		announce_edge(vc, edge_bottom);
buf : 		return;
buf : 	}
buf : 	while (1) {
while (1) { 
buf : 		ch = (char)get_char(vc, (u_short *) spk_pos, &temp);
buf : 		if (ch == SPACE || ch == 0)
if (ch == SPACE || ch == 0) 
buf : 			state = 0;
buf : 		else if (IS_WDLM(ch))
if (IS_WDLM(ch)) 
buf : 			state = 1;
buf : 		else
buf : 			state = 2;
buf : 		if (state > last_state)
if (state > last_state) 
buf : 			break;
buf : 		if (spk_x >= vc->vc_cols - 1) {
if (spk_x >= vc->vc_cols - 1) { 
buf : 			if (spk_y == vc->vc_rows - 1) {
buf : 				edge_said = edge_bottom;
buf : 				break;
buf : 			}
buf : 			state = 0;
buf : 			spk_y++;
buf : 			spk_x = 0;
buf : 			edge_said = edge_right;
buf : 		} else
buf : 			spk_x++;
buf : 		spk_pos += 2;
buf : 		last_state = state;
buf : 	}
buf : 	if (edge_said > 0)
if (edge_said > 0) 
buf : 		announce_edge(vc, edge_said);
buf : 	say_word(vc);
buf : }
buf : 
buf : static void spell_word(struct vc_data *vc)
buf : {
buf : 	static char *delay_str[] = { "", ",", ".", ". .", ". . ." };
buf : 	char *cp = buf, *str_cap = spk_str_caps_stop;
buf : 	char *cp1, *last_cap = spk_str_caps_stop;
buf : 	u_char ch;
buf : 	if (!get_word(vc))
if (!get_word(vc)) 
buf : 		return;
buf : 	while ((ch = (u_char) *cp)) {
while ((ch = (u_char) *cp)) { 
buf : 		if (cp != buf)
buf : 			synth_printf(" %s ", delay_str[spk_spell_delay]);
buf : 		if (IS_CHAR(ch, B_CAP)) {
if (IS_CHAR(ch, B_CAP)) { 
buf : 			str_cap = spk_str_caps_start;
buf : 			if (*spk_str_caps_stop)
if (*spk_str_caps_stop) 
buf : 				spk_pitch_shift++;
buf : 			else	/* synth has no pitch */
buf : 				last_cap = spk_str_caps_stop;
buf : 		} else
buf : 			str_cap = spk_str_caps_stop;
buf : 		if (str_cap != last_cap) {
if (str_cap != last_cap) { 
buf : 			synth_printf("%s", str_cap);
buf : 			last_cap = str_cap;
buf : 		}
buf : 		if (this_speakup_key == SPELL_PHONETIC
if (this_speakup_key == SPELL_PHONETIC 
buf : 		    && (isascii(ch) && isalpha(ch))) {
buf : 			ch &= 31;
buf : 			cp1 = phonetic[--ch];
buf : 		} else {
buf : 			cp1 = spk_characters[ch];
buf : 			if (*cp1 == '^') {
if (*cp1 == '^') { 
buf : 				synth_printf("%s", spk_msg_get(MSG_CTRL));
buf : 				cp1++;
buf : 			}
buf : 		}
buf : 		synth_printf("%s", cp1);
buf : 		cp++;
buf : 	}
buf : 	if (str_cap != spk_str_caps_stop)
if (str_cap != spk_str_caps_stop) 
buf : 		synth_printf("%s", spk_str_caps_stop);
buf : }
buf : 
buf : static int get_line(struct vc_data *vc)
buf : {
buf : 	u_long tmp = spk_pos - (spk_x * 2);
buf : 	int i = 0;
buf : 	u_char tmp2;
buf : 
buf : 	spk_old_attr = spk_attr;
buf : 	spk_attr = get_attributes((u_short *) spk_pos);
buf : 	for (i = 0; i < vc->vc_cols; i++) {
for (i = 0; i < vc->vc_cols; i++) { 
buf : 		buf[i] = (u_char) get_char(vc, (u_short *) tmp, &tmp2);
buf : 		tmp += 2;
buf : 	}
buf : 	for (--i; i >= 0; i--)
for (--i; i >= 0; i--) 
buf : 		if (buf[i] != SPACE)
buf : 			break;
buf : 	return ++i;
buf : }
buf : 
buf : static void say_line(struct vc_data *vc)
buf : {
buf : 	int i = get_line(vc);
buf : 	char *cp;
buf : 	u_short saved_punc_mask = spk_punc_mask;
buf : 	if (i == 0) {
if (i == 0) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_BLANK));
buf : 		return;
buf : 	}
buf : 	buf[i++] = '\n';
buf : 	if (this_speakup_key == SAY_LINE_INDENT) {
if (this_speakup_key == SAY_LINE_INDENT) { 
buf : 		cp = buf;
buf : 		while (*cp == SPACE)
while (*cp == SPACE) 
buf : 			cp++;
buf : 		synth_printf("%d, ", (cp - buf) + 1);
buf : 	}
buf : 	spk_punc_mask = spk_punc_masks[spk_reading_punc];
buf : 	spkup_write(buf, i);
buf : 	spk_punc_mask = saved_punc_mask;
buf : }
buf : 
buf : static void say_prev_line(struct vc_data *vc)
buf : {
buf : 	spk_parked |= 0x01;
buf : 	if (spk_y == 0) {
if (spk_y == 0) { 
buf : 		announce_edge(vc, edge_top);
buf : 		return;
buf : 	}
buf : 	spk_y--;
buf : 	spk_pos -= vc->vc_size_row;
buf : 	say_line(vc);
buf : }
buf : 
buf : static void say_next_line(struct vc_data *vc)
buf : {
buf : 	spk_parked |= 0x01;
buf : 	if (spk_y == vc->vc_rows - 1) {
if (spk_y == vc->vc_rows - 1) { 
buf : 		announce_edge(vc, edge_bottom);
buf : 		return;
buf : 	}
buf : 	spk_y++;
buf : 	spk_pos += vc->vc_size_row;
buf : 	say_line(vc);
buf : }
buf : 
buf : static int say_from_to(struct vc_data *vc, u_long from, u_long to,
buf : 		       int read_punc)
buf : {
buf : 	int i = 0;
buf : 	u_char tmp;
buf : 	u_short saved_punc_mask = spk_punc_mask;
buf : 	spk_old_attr = spk_attr;
buf : 	spk_attr = get_attributes((u_short *) from);
buf : 	while (from < to) {
while (from < to) { 
buf : 		buf[i++] = (char)get_char(vc, (u_short *) from, &tmp);
buf : 		from += 2;
buf : 		if (i >= vc->vc_size_row)
if (i >= vc->vc_size_row) 
buf : 			break;
buf : 	}
buf : 	for (--i; i >= 0; i--)
for (--i; i >= 0; i--) 
buf : 		if (buf[i] != SPACE)
buf : 			break;
buf : 	buf[++i] = SPACE;
buf : 	buf[++i] = '\0';
buf : 	if (i < 1)
if (i < 1) 
buf : 		return i;
buf : 	if (read_punc)
if (read_punc) 
buf : 		spk_punc_mask = spk_punc_info[spk_reading_punc].mask;
buf : 	spkup_write(buf, i);
buf : 	if (read_punc)
if (read_punc) 
buf : 		spk_punc_mask = saved_punc_mask;
buf : 	return i - 1;
buf : }
buf : 
buf : static void say_line_from_to(struct vc_data *vc, u_long from, u_long to,
buf : 			     int read_punc)
buf : {
buf : 	u_long start = vc->vc_origin + (spk_y * vc->vc_size_row);
buf : 	u_long end = start + (to * 2);
buf : 	start += from * 2;
buf : 	if (say_from_to(vc, start, end, read_punc) <= 0)
if (say_from_to(vc, start, end, read_punc) <= 0) 
buf : 		if (cursor_track != read_all_mode)
buf : 			synth_printf("%s\n", spk_msg_get(MSG_BLANK));
buf : }
buf : 
buf : /* Sentence Reading Commands */
buf : 
buf : static int currsentence;
buf : static int numsentences[2];
buf : static char *sentbufend[2];
buf : static char *sentmarks[2][10];
buf : static int currbuf;
buf : static int bn;
buf : static char sentbuf[2][256];
buf : 
buf : static int say_sentence_num(int num, int prev)
buf : {
buf : 	bn = currbuf;
buf : 	currsentence = num + 1;
buf : 	if (prev && --bn == -1)
if (prev && --bn == -1) 
buf : 		bn = 1;
buf : 
buf : 	if (num > numsentences[bn])
if (num > numsentences[bn]) 
buf : 		return 0;
buf : 
buf : 	spkup_write(sentmarks[bn][num], sentbufend[bn] - sentmarks[bn][num]);
buf : 	return 1;
buf : }
buf : 
buf : static int get_sentence_buf(struct vc_data *vc, int read_punc)
buf : {
buf : 	u_long start, end;
buf : 	int i, bn;
buf : 	u_char tmp;
buf : 
buf : 	currbuf++;
buf : 	if (currbuf == 2)
if (currbuf == 2) 
buf : 		currbuf = 0;
buf : 	bn = currbuf;
buf : 	start = vc->vc_origin + ((spk_y) * vc->vc_size_row);
buf : 	end = vc->vc_origin + ((spk_y) * vc->vc_size_row) + vc->vc_cols * 2;
buf : 
buf : 	numsentences[bn] = 0;
buf : 	sentmarks[bn][0] = &sentbuf[bn][0];
buf : 	i = 0;
buf : 	spk_old_attr = spk_attr;
buf : 	spk_attr = get_attributes((u_short *) start);
buf : 
buf : 	while (start < end) {
while (start < end) { 
buf : 		sentbuf[bn][i] = (char)get_char(vc, (u_short *) start, &tmp);
buf : 		if (i > 0) {
if (i > 0) { 
buf : 			if (sentbuf[bn][i] == SPACE && sentbuf[bn][i - 1] == '.'
buf : 			    && numsentences[bn] < 9) {
buf : 				/* Sentence Marker */
buf : 				numsentences[bn]++;
buf : 				sentmarks[bn][numsentences[bn]] =
buf : 				    &sentbuf[bn][i];
buf : 			}
buf : 		}
buf : 		i++;
buf : 		start += 2;
buf : 		if (i >= vc->vc_size_row)
if (i >= vc->vc_size_row) 
buf : 			break;
buf : 	}
buf : 
buf : 	for (--i; i >= 0; i--)
for (--i; i >= 0; i--) 
buf : 		if (sentbuf[bn][i] != SPACE)
buf : 			break;
buf : 
buf : 	if (i < 1)
if (i < 1) 
buf : 		return -1;
buf : 
buf : 	sentbuf[bn][++i] = SPACE;
buf : 	sentbuf[bn][++i] = '\0';
buf : 
buf : 	sentbufend[bn] = &sentbuf[bn][i];
buf : 	return numsentences[bn];
buf : }
buf : 
buf : static void say_screen_from_to(struct vc_data *vc, u_long from, u_long to)
buf : {
buf : 	u_long start = vc->vc_origin, end;
buf : 	if (from > 0)
if (from > 0) 
buf : 		start += from * vc->vc_size_row;
buf : 	if (to > vc->vc_rows)
if (to > vc->vc_rows) 
buf : 		to = vc->vc_rows;
buf : 	end = vc->vc_origin + (to * vc->vc_size_row);
buf : 	for (from = start; from < end; from = to) {
for (from = start; from < end; from = to) { 
buf : 		to = from + vc->vc_size_row;
buf : 		say_from_to(vc, from, to, 1);
buf : 	}
buf : }
buf : 
buf : static void say_screen(struct vc_data *vc)
buf : {
buf : 	say_screen_from_to(vc, 0, vc->vc_rows);
buf : }
buf : 
buf : static void speakup_win_say(struct vc_data *vc)
buf : {
buf : 	u_long start, end, from, to;
buf : 	if (win_start < 2) {
if (win_start < 2) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_NO_WINDOW));
buf : 		return;
buf : 	}
buf : 	start = vc->vc_origin + (win_top * vc->vc_size_row);
buf : 	end = vc->vc_origin + (win_bottom * vc->vc_size_row);
buf : 	while (start <= end) {
while (start <= end) { 
buf : 		from = start + (win_left * 2);
buf : 		to = start + (win_right * 2);
buf : 		say_from_to(vc, from, to, 1);
buf : 		start += vc->vc_size_row;
buf : 	}
buf : }
buf : 
buf : static void top_edge(struct vc_data *vc)
buf : {
buf : 	spk_parked |= 0x01;
buf : 	spk_pos = vc->vc_origin + 2 * spk_x;
buf : 	spk_y = 0;
buf : 	say_line(vc);
buf : }
buf : 
buf : static void bottom_edge(struct vc_data *vc)
buf : {
buf : 	spk_parked |= 0x01;
buf : 	spk_pos += (vc->vc_rows - spk_y - 1) * vc->vc_size_row;
buf : 	spk_y = vc->vc_rows - 1;
buf : 	say_line(vc);
buf : }
buf : 
buf : static void left_edge(struct vc_data *vc)
buf : {
buf : 	spk_parked |= 0x01;
buf : 	spk_pos -= spk_x * 2;
buf : 	spk_x = 0;
buf : 	say_char(vc);
buf : }
buf : 
buf : static void right_edge(struct vc_data *vc)
buf : {
buf : 	spk_parked |= 0x01;
buf : 	spk_pos += (vc->vc_cols - spk_x - 1) * 2;
buf : 	spk_x = vc->vc_cols - 1;
buf : 	say_char(vc);
buf : }
buf : 
buf : static void say_first_char(struct vc_data *vc)
buf : {
buf : 	int i, len = get_line(vc);
buf : 	u_char ch;
buf : 	spk_parked |= 0x01;
buf : 	if (len == 0) {
if (len == 0) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_BLANK));
buf : 		return;
buf : 	}
buf : 	for (i = 0; i < len; i++)
for (i = 0; i < len; i++) 
buf : 		if (buf[i] != SPACE)
buf : 			break;
buf : 	ch = buf[i];
buf : 	spk_pos -= (spk_x - i) * 2;
buf : 	spk_x = i;
buf : 	synth_printf("%d, ", ++i);
buf : 	speak_char(ch);
buf : }
buf : 
buf : static void say_last_char(struct vc_data *vc)
buf : {
buf : 	int len = get_line(vc);
buf : 	u_char ch;
buf : 	spk_parked |= 0x01;
buf : 	if (len == 0) {
if (len == 0) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_BLANK));
buf : 		return;
buf : 	}
buf : 	ch = buf[--len];
buf : 	spk_pos -= (spk_x - len) * 2;
buf : 	spk_x = len;
buf : 	synth_printf("%d, ", ++len);
buf : 	speak_char(ch);
buf : }
buf : 
buf : static void say_position(struct vc_data *vc)
buf : {
buf : 	synth_printf(spk_msg_get(MSG_POS_INFO), spk_y + 1, spk_x + 1,
buf : 		     vc->vc_num + 1);
buf : 	synth_printf("\n");
buf : }
buf : 
buf : /* Added by brianb */
buf : static void say_char_num(struct vc_data *vc)
buf : {
buf : 	u_char tmp;
buf : 	u_short ch = get_char(vc, (u_short *) spk_pos, &tmp);
buf : 	ch &= 0xff;
buf : 	synth_printf(spk_msg_get(MSG_CHAR_INFO), ch, ch);
buf : }
buf : 
buf : /* these are stub functions to keep keyboard.c happy. */
buf : 
buf : static void say_from_top(struct vc_data *vc)
buf : {
buf : 	say_screen_from_to(vc, 0, spk_y);
buf : }
buf : 
buf : static void say_to_bottom(struct vc_data *vc)
buf : {
buf : 	say_screen_from_to(vc, spk_y, vc->vc_rows);
buf : }
buf : 
buf : static void say_from_left(struct vc_data *vc)
buf : {
buf : 	say_line_from_to(vc, 0, spk_x, 1);
buf : }
buf : 
buf : static void say_to_right(struct vc_data *vc)
buf : {
buf : 	say_line_from_to(vc, spk_x, vc->vc_cols, 1);
buf : }
buf : 
buf : /* end of stub functions. */
buf : 
buf : static void spkup_write(const char *in_buf, int count)
buf : {
buf : 	static int rep_count;
buf : 	static u_char ch = '\0', old_ch = '\0';
buf : 	static u_short char_type, last_type;
buf : 	int in_count = count;
buf : 	spk_keydown = 0;
buf : 	while (count--) {
while (count--) { 
buf : 		if (cursor_track == read_all_mode) {
buf : 			/* Insert Sentence Index */
buf : 			if ((in_buf == sentmarks[bn][currsentence]) &&
if ((in_buf == sentmarks[bn][currsentence]) && 
buf : 			    (currsentence <= numsentences[bn]))
buf : 				synth_insert_next_index(currsentence++);
buf : 		}
buf : 		ch = (u_char) *in_buf++;
buf : 		char_type = spk_chartab[ch];
buf : 		if (ch == old_ch && !(char_type & B_NUM)) {
if (ch == old_ch && !(char_type & B_NUM)) { 
buf : 			if (++rep_count > 2)
buf : 				continue;
buf : 		} else {
buf : 			if ((last_type & CH_RPT) && rep_count > 2) {
if ((last_type & CH_RPT) && rep_count > 2) { 
buf : 				synth_printf(" ");
buf : 				synth_printf(spk_msg_get(MSG_REPEAT_DESC),
buf : 					     ++rep_count);
buf : 				synth_printf(" ");
buf : 			}
buf : 			rep_count = 0;
buf : 		}
buf : 		if (ch == spk_lastkey) {
if (ch == spk_lastkey) { 
buf : 			rep_count = 0;
buf : 			if (spk_key_echo == 1 && ch >= MINECHOCHAR)
if (spk_key_echo == 1 && ch >= MINECHOCHAR) 
buf : 				speak_char(ch);
buf : 		} else if (char_type & B_ALPHA) {
if (char_type & B_ALPHA) { 
buf : 			if ((synth_flags & SF_DEC) && (last_type & PUNC))
buf : 				synth_buffer_add(SPACE);
buf : 			synth_printf("%c", ch);
buf : 		} else if (char_type & B_NUM) {
if (char_type & B_NUM) { 
buf : 			rep_count = 0;
buf : 			synth_printf("%c", ch);
buf : 		} else if (char_type & spk_punc_mask) {
if (char_type & spk_punc_mask) { 
buf : 			speak_char(ch);
buf : 			char_type &= ~PUNC;	/* for dec nospell processing */
for dec nospell processing */ 
buf : 		} else if (char_type & SYNTH_OK) {
buf : 			/* these are usually puncts like . and , which synth
buf : 			 * needs for expression.
for expression. 
buf : 			 * suppress multiple to get rid of long pauses and
buf : 			 * clear repeat count
buf : 			 * so if someone has
if someone has 
buf : 			 * repeats on you don't get nothing repeated count */
buf : 			if (ch != old_ch)
if (ch != old_ch) 
buf : 				synth_printf("%c", ch);
buf : 			else
buf : 				rep_count = 0;
buf : 		} else {
buf : /* send space and record position, if next is num overwrite space */
if next is num overwrite space */ 
buf : 			if (old_ch != ch)
buf : 				synth_buffer_add(SPACE);
buf : 			else
buf : 				rep_count = 0;
buf : 		}
buf : 		old_ch = ch;
buf : 		last_type = char_type;
buf : 	}
buf : 	spk_lastkey = 0;
buf : 	if (in_count > 2 && rep_count > 2) {
if (in_count > 2 && rep_count > 2) { 
buf : 		if (last_type & CH_RPT) {
buf : 			synth_printf(" ");
buf : 			synth_printf(spk_msg_get(MSG_REPEAT_DESC2), ++rep_count);
buf : 			synth_printf(" ");
buf : 		}
buf : 		rep_count = 0;
buf : 	}
buf : }
buf : 
buf : static const int NUM_CTL_LABELS = (MSG_CTL_END - MSG_CTL_START + 1);
buf : 
buf : static void read_all_doc(struct vc_data *vc);
buf : static void cursor_done(u_long data);
buf : static DEFINE_TIMER(cursor_timer, cursor_done, 0, 0);
buf : 
buf : static void do_handle_shift(struct vc_data *vc, u_char value, char up_flag)
ift(struct vc_data *vc, u_char value, char up_flag) 
buf : {
buf : 	unsigned long flags;
buf : 	if (synth == NULL || up_flag || spk_killed)
if (synth == NULL || up_flag || spk_killed) 
buf : 		return;
buf : 	spin_lock_irqsave(&speakup_info.spinlock, flags);
buf : 	if (cursor_track == read_all_mode) {
if (cursor_track == read_all_mode) { 
buf : 		switch (value) {
buf : 		case KVAL(K_SHIFT):
buf : 			del_timer(&cursor_timer);
buf : 			spk_shut_up &= 0xfe;
buf : 			spk_do_flush();
buf : 			read_all_doc(vc);
buf : 			break;
buf : 		case KVAL(K_CTRL):
buf : 			del_timer(&cursor_timer);
buf : 			cursor_track = prev_cursor_track;
buf : 			spk_shut_up &= 0xfe;
buf : 			spk_do_flush();
buf : 			break;
buf : 		}
buf : 	} else {
buf : 		spk_shut_up &= 0xfe;
buf : 		spk_do_flush();
buf : 	}
buf : 	if (spk_say_ctrl && value < NUM_CTL_LABELS)
if (spk_say_ctrl && value < NUM_CTL_LABELS) 
buf : 		synth_printf("%s", spk_msg_get(MSG_CTL_START + value));
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : }
buf : 
buf : static void do_handle_latin(struct vc_data *vc, u_char value, char up_flag)
buf : {
buf : 	unsigned long flags;
buf : 	spin_lock_irqsave(&speakup_info.spinlock, flags);
buf : 	if (up_flag) {
if (up_flag) { 
buf : 		spk_lastkey = spk_keydown = 0;
buf : 		spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 		return;
buf : 	}
buf : 	if (synth == NULL || spk_killed) {
if (synth == NULL || spk_killed) { 
buf : 		spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 		return;
buf : 	}
buf : 	spk_shut_up &= 0xfe;
buf : 	spk_lastkey = value;
buf : 	spk_keydown++;
buf : 	spk_parked &= 0xfe;
buf : 	if (spk_key_echo == 2 && value >= MINECHOCHAR)
if (spk_key_echo == 2 && value >= MINECHOCHAR) 
buf : 		speak_char(value);
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : }
buf : 
buf : int spk_set_key_info(const u_char *key_info, u_char *k_buffer)
buf : {
buf : 	int i = 0, states, key_data_len;
buf : 	const u_char *cp = key_info;
buf : 	u_char *cp1 = k_buffer;
buf : 	u_char ch, version, num_keys;
buf : 	version = *cp++;
buf : 	if (version != KEY_MAP_VER)
if (version != KEY_MAP_VER) 
buf : 		return -1;
buf : 	num_keys = *cp;
buf : 	states = (int)cp[1];
buf : 	key_data_len = (states + 1) * (num_keys + 1);
buf : 	if (key_data_len + SHIFT_TBL_SIZE + 4 >= sizeof(spk_key_buf))
if (key_data_len + SHIFT_TBL_SIZE + 4 >= sizeof(spk_key_buf)) 
buf : 		return -2;
buf : 	memset(k_buffer, 0, SHIFT_TBL_SIZE);
buf : 	memset(spk_our_keys, 0, sizeof(spk_our_keys));
buf : 	spk_shift_table = k_buffer;
ift_table = k_buffer; 
buf : 	spk_our_keys[0] = spk_shift_table;
buf : 	cp1 += SHIFT_TBL_SIZE;
buf : 	memcpy(cp1, cp, key_data_len + 3);
buf : 	/* get num_keys, states and data */
buf : 	cp1 += 2;		/* now pointing at shift states */
ift states */ 
buf : 	for (i = 1; i <= states; i++) {
for (i = 1; i <= states; i++) { 
buf : 		ch = *cp1++;
buf : 		if (ch >= SHIFT_TBL_SIZE)
if (ch >= SHIFT_TBL_SIZE) 
buf : 			return -3;
buf : 		spk_shift_table[ch] = i;
ift_table[ch] = i; 
buf : 	}
buf : 	keymap_flags = *cp1++;
buf : 	while ((ch = *cp1)) {
while ((ch = *cp1)) { 
buf : 		if (ch >= MAX_KEY)
buf : 			return -4;
buf : 		spk_our_keys[ch] = cp1;
buf : 		cp1 += states + 1;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static struct var_t spk_vars[] = {
buf : 	/* bell must be first to set high limit */
buf : 	{BELL_POS, .u.n = {NULL, 0, 0, 0, 0, 0, NULL} },
buf : 	{SPELL_DELAY, .u.n = {NULL, 0, 0, 4, 0, 0, NULL} },
buf : 	{ATTRIB_BLEEP, .u.n = {NULL, 1, 0, 3, 0, 0, NULL} },
buf : 	{BLEEPS, .u.n = {NULL, 3, 0, 3, 0, 0, NULL} },
buf : 	{BLEEP_TIME, .u.n = {NULL, 30, 1, 200, 0, 0, NULL} },
buf : 	{PUNC_LEVEL, .u.n = {NULL, 1, 0, 4, 0, 0, NULL} },
buf : 	{READING_PUNC, .u.n = {NULL, 1, 0, 4, 0, 0, NULL} },
buf : 	{CURSOR_TIME, .u.n = {NULL, 120, 50, 600, 0, 0, NULL} },
buf : 	{SAY_CONTROL, TOGGLE_0},
buf : 	{SAY_WORD_CTL, TOGGLE_0},
buf : 	{NO_INTERRUPT, TOGGLE_0},
buf : 	{KEY_ECHO, .u.n = {NULL, 1, 0, 2, 0, 0, NULL} },
buf : 	V_LAST_VAR
buf : };
buf : 
buf : static void toggle_cursoring(struct vc_data *vc)
buf : {
buf : 	if (cursor_track == read_all_mode)
if (cursor_track == read_all_mode) 
buf : 		cursor_track = prev_cursor_track;
buf : 	if (++cursor_track >= CT_Max)
if (++cursor_track >= CT_Max) 
buf : 		cursor_track = 0;
buf : 	synth_printf("%s\n", spk_msg_get(MSG_CURSOR_MSGS_START + cursor_track));
buf : }
buf : 
buf : void spk_reset_default_chars(void)
buf : {
buf : 	int i;
buf : 
buf : 	/* First, free any non-default */
buf : 	for (i = 0; i < 256; i++) {
for (i = 0; i < 256; i++) { 
buf : 		if ((spk_characters[i] != NULL)
buf : 		    && (spk_characters[i] != spk_default_chars[i]))
buf : 			kfree(spk_characters[i]);
buf : 	}
buf : 
buf : 	memcpy(spk_characters, spk_default_chars, sizeof(spk_default_chars));
buf : }
buf : 
buf : void spk_reset_default_chartab(void)
buf : {
buf : 	memcpy(spk_chartab, default_chartab, sizeof(default_chartab));
buf : }
buf : 
buf : static const struct st_bits_data *pb_edit;
buf : 
buf : static int edit_bits(struct vc_data *vc, u_char type, u_char ch, u_short key)
buf : {
buf : 	short mask = pb_edit->mask, ch_type = spk_chartab[ch];
buf : 	if (type != KT_LATIN || (ch_type & B_NUM) || ch < SPACE)
if (type != KT_LATIN || (ch_type & B_NUM) || ch < SPACE) 
buf : 		return -1;
buf : 	if (ch == SPACE) {
if (ch == SPACE) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_EDIT_DONE));
buf : 		spk_special_handler = NULL;
buf : 		return 1;
buf : 	}
buf : 	if (mask < PUNC && !(ch_type & PUNC))
if (mask < PUNC && !(ch_type & PUNC)) 
buf : 		return -1;
buf : 	spk_chartab[ch] ^= mask;
buf : 	speak_char(ch);
buf : 	synth_printf(" %s\n",
buf : 		     (spk_chartab[ch] & mask) ? spk_msg_get(MSG_ON) :
buf : 		     spk_msg_get(MSG_OFF));
buf : 	return 1;
buf : }
buf : 
buf : /* Allocation concurrency is protected by the console semaphore */
buf : static int speakup_allocate(struct vc_data *vc)
buf : {
buf : 	int vc_num;
buf : 
buf : 	vc_num = vc->vc_num;
buf : 	if (speakup_console[vc_num] == NULL) {
if (speakup_console[vc_num] == NULL) { 
buf : 		speakup_console[vc_num] = kzalloc(sizeof(*speakup_console[0]),
buf : 						  GFP_ATOMIC);
buf : 		if (speakup_console[vc_num] == NULL)
if (speakup_console[vc_num] == NULL) 
buf : 			return -ENOMEM;
buf : 		speakup_date(vc);
buf : 	} else if (!spk_parked)
if (!spk_parked) 
buf : 		speakup_date(vc);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void speakup_deallocate(struct vc_data *vc)
buf : {
buf : 	int vc_num;
buf : 
buf : 	vc_num = vc->vc_num;
buf : 	kfree(speakup_console[vc_num]);
buf : 	speakup_console[vc_num] = NULL;
buf : }
buf : 
buf : static u_char is_cursor;
buf : static u_long old_cursor_pos, old_cursor_x, old_cursor_y;
buf : static int cursor_con;
buf : 
buf : static void reset_highlight_buffers(struct vc_data *);
buf : 
buf : static int read_all_key;
buf : 
buf : static void start_read_all_timer(struct vc_data *vc, int command);
buf : 
buf : enum {
buf : 	RA_NOTHING,
buf : 	RA_NEXT_SENT,
buf : 	RA_PREV_LINE,
buf : 	RA_NEXT_LINE,
buf : 	RA_PREV_SENT,
buf : 	RA_DOWN_ARROW,
buf : 	RA_TIMER,
buf : 	RA_FIND_NEXT_SENT,
buf : 	RA_FIND_PREV_SENT,
buf : };
buf : 
buf : static void kbd_fakekey2(struct vc_data *vc, int command)
buf : {
buf : 	del_timer(&cursor_timer);
buf : 	speakup_fake_down_arrow();
buf : 	start_read_all_timer(vc, command);
buf : }
buf : 
buf : static void read_all_doc(struct vc_data *vc)
buf : {
buf : 	if ((vc->vc_num != fg_console) || synth == NULL || spk_shut_up)
if ((vc->vc_num != fg_console) || synth == NULL || spk_shut_up) 
buf : 		return;
buf : 	if (!synth_supports_indexing())
if (!synth_supports_indexing()) 
buf : 		return;
buf : 	if (cursor_track != read_all_mode)
if (cursor_track != read_all_mode) 
buf : 		prev_cursor_track = cursor_track;
buf : 	cursor_track = read_all_mode;
buf : 	spk_reset_index_count(0);
buf : 	if (get_sentence_buf(vc, 0) == -1)
if (get_sentence_buf(vc, 0) == -1) 
buf : 		kbd_fakekey2(vc, RA_DOWN_ARROW);
buf : 	else {
buf : 		say_sentence_num(0, 0);
buf : 		synth_insert_next_index(0);
buf : 		start_read_all_timer(vc, RA_TIMER);
buf : 	}
buf : }
buf : 
buf : static void stop_read_all(struct vc_data *vc)
buf : {
buf : 	del_timer(&cursor_timer);
buf : 	cursor_track = prev_cursor_track;
buf : 	spk_shut_up &= 0xfe;
buf : 	spk_do_flush();
buf : }
buf : 
buf : static void start_read_all_timer(struct vc_data *vc, int command)
buf : {
buf : 	struct var_t *cursor_timeout;
buf : 
buf : 	cursor_con = vc->vc_num;
buf : 	read_all_key = command;
buf : 	cursor_timeout = spk_get_var(CURSOR_TIME);
buf : 	mod_timer(&cursor_timer,
buf : 		  jiffies + msecs_to_jiffies(cursor_timeout->u.n.value));
iffies + msecs_to_jiffies(cursor_timeout->u.n.value)); 
buf : }
buf : 
buf : static void handle_cursor_read_all(struct vc_data *vc, int command)
buf : {
buf : 	int indcount, sentcount, rv, sn;
buf : 
buf : 	switch (command) {
buf : 	case RA_NEXT_SENT:
buf : 		/* Get Current Sentence */
buf : 		spk_get_index_count(&indcount, &sentcount);
buf : 		/*printk("%d %d  ", indcount, sentcount); */
buf : 		spk_reset_index_count(sentcount + 1);
buf : 		if (indcount == 1) {
if (indcount == 1) { 
buf : 			if (!say_sentence_num(sentcount + 1, 0)) {
buf : 				kbd_fakekey2(vc, RA_FIND_NEXT_SENT);
buf : 				return;
buf : 			}
buf : 			synth_insert_next_index(0);
buf : 		} else {
buf : 			sn = 0;
buf : 			if (!say_sentence_num(sentcount + 1, 1)) {
if (!say_sentence_num(sentcount + 1, 1)) { 
buf : 				sn = 1;
buf : 				spk_reset_index_count(sn);
buf : 			} else
buf : 				synth_insert_next_index(0);
buf : 			if (!say_sentence_num(sn, 0)) {
if (!say_sentence_num(sn, 0)) { 
buf : 				kbd_fakekey2(vc, RA_FIND_NEXT_SENT);
buf : 				return;
buf : 			}
buf : 			synth_insert_next_index(0);
buf : 		}
buf : 		start_read_all_timer(vc, RA_TIMER);
buf : 		break;
buf : 	case RA_PREV_SENT:
buf : 		break;
buf : 	case RA_NEXT_LINE:
buf : 		read_all_doc(vc);
buf : 		break;
buf : 	case RA_PREV_LINE:
buf : 		break;
buf : 	case RA_DOWN_ARROW:
buf : 		if (get_sentence_buf(vc, 0) == -1) {
if (get_sentence_buf(vc, 0) == -1) { 
buf : 			kbd_fakekey2(vc, RA_DOWN_ARROW);
buf : 		} else {
buf : 			say_sentence_num(0, 0);
buf : 			synth_insert_next_index(0);
buf : 			start_read_all_timer(vc, RA_TIMER);
buf : 		}
buf : 		break;
buf : 	case RA_FIND_NEXT_SENT:
buf : 		rv = get_sentence_buf(vc, 0);
buf : 		if (rv == -1)
if (rv == -1) 
buf : 			read_all_doc(vc);
buf : 		if (rv == 0)
if (rv == 0) 
buf : 			kbd_fakekey2(vc, RA_FIND_NEXT_SENT);
buf : 		else {
buf : 			say_sentence_num(1, 0);
buf : 			synth_insert_next_index(0);
buf : 			start_read_all_timer(vc, RA_TIMER);
buf : 		}
buf : 		break;
buf : 	case RA_FIND_PREV_SENT:
buf : 		break;
buf : 	case RA_TIMER:
buf : 		spk_get_index_count(&indcount, &sentcount);
buf : 		if (indcount < 2)
if (indcount < 2) 
buf : 			kbd_fakekey2(vc, RA_DOWN_ARROW);
buf : 		else
buf : 			start_read_all_timer(vc, RA_TIMER);
buf : 		break;
buf : 	}
buf : }
buf : 
buf : static int pre_handle_cursor(struct vc_data *vc, u_char value, char up_flag)
buf : {
buf : 	unsigned long flags;
buf : 	spin_lock_irqsave(&speakup_info.spinlock, flags);
buf : 	if (cursor_track == read_all_mode) {
if (cursor_track == read_all_mode) { 
buf : 		spk_parked &= 0xfe;
buf : 		if (synth == NULL || up_flag || spk_shut_up) {
if (synth == NULL || up_flag || spk_shut_up) { 
buf : 			spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 			return NOTIFY_STOP;
buf : 		}
buf : 		del_timer(&cursor_timer);
buf : 		spk_shut_up &= 0xfe;
buf : 		spk_do_flush();
buf : 		start_read_all_timer(vc, value + 1);
buf : 		spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 		return NOTIFY_STOP;
buf : 	}
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 	return NOTIFY_OK;
buf : }
buf : 
buf : static void do_handle_cursor(struct vc_data *vc, u_char value, char up_flag)
buf : {
buf : 	unsigned long flags;
buf : 	struct var_t *cursor_timeout;
buf : 
buf : 	spin_lock_irqsave(&speakup_info.spinlock, flags);
buf : 	spk_parked &= 0xfe;
buf : 	if (synth == NULL || up_flag || spk_shut_up || cursor_track == CT_Off) {
if (synth == NULL || up_flag || spk_shut_up || cursor_track == CT_Off) { 
buf : 		spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 		return;
buf : 	}
buf : 	spk_shut_up &= 0xfe;
buf : 	if (spk_no_intr)
if (spk_no_intr) 
buf : 		spk_do_flush();
buf : /* the key press flushes if !no_inter but we want to flush on cursor
if !no_inter but we want to flush on cursor 
buf :  * moves regardless of no_inter state */
buf : 	is_cursor = value + 1;
buf : 	old_cursor_pos = vc->vc_pos;
buf : 	old_cursor_x = vc->vc_x;
buf : 	old_cursor_y = vc->vc_y;
buf : 	speakup_console[vc->vc_num]->ht.cy = vc->vc_y;
buf : 	cursor_con = vc->vc_num;
buf : 	if (cursor_track == CT_Highlight)
if (cursor_track == CT_Highlight) 
buf : 		reset_highlight_buffers(vc);
buf : 	cursor_timeout = spk_get_var(CURSOR_TIME);
buf : 	mod_timer(&cursor_timer,
buf : 		  jiffies + msecs_to_jiffies(cursor_timeout->u.n.value));
iffies + msecs_to_jiffies(cursor_timeout->u.n.value)); 
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : }
buf : 
buf : static void update_color_buffer(struct vc_data *vc, const char *ic, int len)
buf : {
buf : 	int i, bi, hi;
buf : 	int vc_num = vc->vc_num;
buf : 
buf : 	bi = ((vc->vc_attr & 0x70) >> 4);
buf : 	hi = speakup_console[vc_num]->ht.highsize[bi];
buf : 
buf : 	i = 0;
buf : 	if (speakup_console[vc_num]->ht.highsize[bi] == 0) {
if (speakup_console[vc_num]->ht.highsize[bi] == 0) { 
buf : 		speakup_console[vc_num]->ht.rpos[bi] = vc->vc_pos;
buf : 		speakup_console[vc_num]->ht.rx[bi] = vc->vc_x;
buf : 		speakup_console[vc_num]->ht.ry[bi] = vc->vc_y;
buf : 	}
buf : 	while ((hi < COLOR_BUFFER_SIZE) && (i < len)) {
while ((hi < COLOR_BUFFER_SIZE) && (i < len)) { 
buf : 		if ((ic[i] > 32) && (ic[i] < 127)) {
buf : 			speakup_console[vc_num]->ht.highbuf[bi][hi] = ic[i];
buf : 			hi++;
buf : 		} else if ((ic[i] == 32) && (hi != 0)) {
if ((ic[i] == 32) && (hi != 0)) { 
buf : 			if (speakup_console[vc_num]->ht.highbuf[bi][hi - 1] !=
buf : 			    32) {
buf : 				speakup_console[vc_num]->ht.highbuf[bi][hi] =
buf : 				    ic[i];
buf : 				hi++;
buf : 			}
buf : 		}
buf : 		i++;
buf : 	}
buf : 	speakup_console[vc_num]->ht.highsize[bi] = hi;
buf : }
buf : 
buf : static void reset_highlight_buffers(struct vc_data *vc)
buf : {
buf : 	int i;
buf : 	int vc_num = vc->vc_num;
buf : 	for (i = 0; i < 8; i++)
for (i = 0; i < 8; i++) 
buf : 		speakup_console[vc_num]->ht.highsize[i] = 0;
buf : }
buf : 
buf : static int count_highlight_color(struct vc_data *vc)
buf : {
buf : 	int i, bg;
buf : 	int cc;
buf : 	int vc_num = vc->vc_num;
buf : 	u16 ch;
buf : 	u16 *start = (u16 *) vc->vc_origin;
buf : 
buf : 	for (i = 0; i < 8; i++)
for (i = 0; i < 8; i++) 
buf : 		speakup_console[vc_num]->ht.bgcount[i] = 0;
buf : 
buf : 	for (i = 0; i < vc->vc_rows; i++) {
for (i = 0; i < vc->vc_rows; i++) { 
buf : 		u16 *end = start + vc->vc_cols * 2;
buf : 		u16 *ptr;
buf : 		for (ptr = start; ptr < end; ptr++) {
for (ptr = start; ptr < end; ptr++) { 
buf : 			ch = get_attributes(ptr);
buf : 			bg = (ch & 0x70) >> 4;
buf : 			speakup_console[vc_num]->ht.bgcount[bg]++;
buf : 		}
buf : 		start += vc->vc_size_row;
buf : 	}
buf : 
buf : 	cc = 0;
buf : 	for (i = 0; i < 8; i++)
for (i = 0; i < 8; i++) 
buf : 		if (speakup_console[vc_num]->ht.bgcount[i] > 0)
buf : 			cc++;
buf : 	return cc;
buf : }
buf : 
buf : static int get_highlight_color(struct vc_data *vc)
buf : {
buf : 	int i, j;
buf : 	unsigned int cptr[8], tmp;
buf : 	int vc_num = vc->vc_num;
buf : 
buf : 	for (i = 0; i < 8; i++)
for (i = 0; i < 8; i++) 
buf : 		cptr[i] = i;
buf : 
buf : 	for (i = 0; i < 7; i++)
for (i = 0; i < 7; i++) 
buf : 		for (j = i + 1; j < 8; j++)
buf : 			if (speakup_console[vc_num]->ht.bgcount[cptr[i]] >
if (speakup_console[vc_num]->ht.bgcount[cptr[i]] > 
buf : 			    speakup_console[vc_num]->ht.bgcount[cptr[j]]) {
buf : 				tmp = cptr[i];
buf : 				cptr[i] = cptr[j];
buf : 				cptr[j] = tmp;
buf : 			}
buf : 
buf : 	for (i = 0; i < 8; i++)
for (i = 0; i < 8; i++) 
buf : 		if (speakup_console[vc_num]->ht.bgcount[cptr[i]] != 0)
buf : 			if (speakup_console[vc_num]->ht.highsize[cptr[i]] > 0)
if (speakup_console[vc_num]->ht.highsize[cptr[i]] > 0) 
buf : 				return cptr[i];
buf : 	return -1;
buf : }
buf : 
buf : static int speak_highlight(struct vc_data *vc)
buf : {
buf : 	int hc, d;
buf : 	int vc_num = vc->vc_num;
buf : 	if (count_highlight_color(vc) == 1)
if (count_highlight_color(vc) == 1) 
buf : 		return 0;
buf : 	hc = get_highlight_color(vc);
buf : 	if (hc != -1) {
if (hc != -1) { 
buf : 		d = vc->vc_y - speakup_console[vc_num]->ht.cy;
buf : 		if ((d == 1) || (d == -1))
if ((d == 1) || (d == -1)) 
buf : 			if (speakup_console[vc_num]->ht.ry[hc] != vc->vc_y)
buf : 				return 0;
buf : 		spk_parked |= 0x01;
buf : 		spk_do_flush();
buf : 		spkup_write(speakup_console[vc_num]->ht.highbuf[hc],
buf : 			    speakup_console[vc_num]->ht.highsize[hc]);
buf : 		spk_pos = spk_cp = speakup_console[vc_num]->ht.rpos[hc];
buf : 		spk_x = spk_cx = speakup_console[vc_num]->ht.rx[hc];
buf : 		spk_y = spk_cy = speakup_console[vc_num]->ht.ry[hc];
buf : 		return 1;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static void cursor_done(u_long data)
buf : {
buf : 	struct vc_data *vc = vc_cons[cursor_con].d;
buf : 	unsigned long flags;
buf : 	del_timer(&cursor_timer);
buf : 	spin_lock_irqsave(&speakup_info.spinlock, flags);
buf : 	if (cursor_con != fg_console) {
if (cursor_con != fg_console) { 
buf : 		is_cursor = 0;
buf : 		goto out;
buf : 	}
buf : 	speakup_date(vc);
buf : 	if (win_enabled) {
if (win_enabled) { 
buf : 		if (vc->vc_x >= win_left && vc->vc_x <= win_right &&
buf : 		    vc->vc_y >= win_top && vc->vc_y <= win_bottom) {
buf : 			spk_keydown = is_cursor = 0;
buf : 			goto out;
buf : 		}
buf : 	}
buf : 	if (cursor_track == read_all_mode) {
if (cursor_track == read_all_mode) { 
buf : 		handle_cursor_read_all(vc, read_all_key);
buf : 		goto out;
buf : 	}
buf : 	if (cursor_track == CT_Highlight) {
if (cursor_track == CT_Highlight) { 
buf : 		if (speak_highlight(vc)) {
buf : 			spk_keydown = is_cursor = 0;
buf : 			goto out;
buf : 		}
buf : 	}
buf : 	if (cursor_track == CT_Window)
if (cursor_track == CT_Window) 
buf : 		speakup_win_say(vc);
buf : 	else if (is_cursor == 1 || is_cursor == 4)
if (is_cursor == 1 || is_cursor == 4) 
buf : 		say_line_from_to(vc, 0, vc->vc_cols, 0);
buf : 	else
buf : 		say_char(vc);
buf : 	spk_keydown = is_cursor = 0;
buf : out:
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : }
buf : 
buf : /* called by: vt_notifier_call() */
ifier_call() */ 
buf : static void speakup_bs(struct vc_data *vc)
buf : {
buf : 	unsigned long flags;
buf : 	if (!speakup_console[vc->vc_num])
if (!speakup_console[vc->vc_num]) 
buf : 		return;
buf : 	if (!spin_trylock_irqsave(&speakup_info.spinlock, flags))
if (!spin_trylock_irqsave(&speakup_info.spinlock, flags)) 
buf : 		/* Speakup output, discard */
buf : 		return;
buf : 	if (!spk_parked)
if (!spk_parked) 
buf : 		speakup_date(vc);
buf : 	if (spk_shut_up || synth == NULL) {
if (spk_shut_up || synth == NULL) { 
buf : 		spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 		return;
buf : 	}
buf : 	if (vc->vc_num == fg_console && spk_keydown) {
if (vc->vc_num == fg_console && spk_keydown) { 
buf : 		spk_keydown = 0;
buf : 		if (!is_cursor)
if (!is_cursor) 
buf : 			say_char(vc);
buf : 	}
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : }
buf : 
buf : /* called by: vt_notifier_call() */
ifier_call() */ 
buf : static void speakup_con_write(struct vc_data *vc, const char *str, int len)
buf : {
buf : 	unsigned long flags;
buf : 	if ((vc->vc_num != fg_console) || spk_shut_up || synth == NULL)
if ((vc->vc_num != fg_console) || spk_shut_up || synth == NULL) 
buf : 		return;
buf : 	if (!spin_trylock_irqsave(&speakup_info.spinlock, flags))
if (!spin_trylock_irqsave(&speakup_info.spinlock, flags)) 
buf : 		/* Speakup output, discard */
buf : 		return;
buf : 	if (spk_bell_pos && spk_keydown && (vc->vc_x == spk_bell_pos - 1))
if (spk_bell_pos && spk_keydown && (vc->vc_x == spk_bell_pos - 1)) 
buf : 		bleep(3);
buf : 	if ((is_cursor) || (cursor_track == read_all_mode)) {
if ((is_cursor) || (cursor_track == read_all_mode)) { 
buf : 		if (cursor_track == CT_Highlight)
buf : 			update_color_buffer(vc, str, len);
buf : 		spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 		return;
buf : 	}
buf : 	if (win_enabled) {
if (win_enabled) { 
buf : 		if (vc->vc_x >= win_left && vc->vc_x <= win_right &&
buf : 		    vc->vc_y >= win_top && vc->vc_y <= win_bottom) {
buf : 			spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 			return;
buf : 		}
buf : 	}
buf : 
buf : 	spkup_write(str, len);
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : }
buf : 
buf : static void speakup_con_update(struct vc_data *vc)
buf : {
buf : 	unsigned long flags;
buf : 	if (speakup_console[vc->vc_num] == NULL || spk_parked)
if (speakup_console[vc->vc_num] == NULL || spk_parked) 
buf : 		return;
buf : 	if (!spin_trylock_irqsave(&speakup_info.spinlock, flags))
if (!spin_trylock_irqsave(&speakup_info.spinlock, flags)) 
buf : 		/* Speakup output, discard */
buf : 		return;
buf : 	speakup_date(vc);
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : }
buf : 
buf : static void do_handle_spec(struct vc_data *vc, u_char value, char up_flag)
buf : {
buf : 	unsigned long flags;
buf : 	int on_off = 2;
buf : 	char *label;
buf : 	if (synth == NULL || up_flag || spk_killed)
if (synth == NULL || up_flag || spk_killed) 
buf : 		return;
buf : 	spin_lock_irqsave(&speakup_info.spinlock, flags);
buf : 	spk_shut_up &= 0xfe;
buf : 	if (spk_no_intr)
if (spk_no_intr) 
buf : 		spk_do_flush();
buf : 	switch (value) {
buf : 	case KVAL(K_CAPS):
buf : 		label = spk_msg_get(MSG_KEYNAME_CAPSLOCK);
buf : 		on_off = vt_get_leds(fg_console, VC_CAPSLOCK);
buf : 		break;
buf : 	case KVAL(K_NUM):
buf : 		label = spk_msg_get(MSG_KEYNAME_NUMLOCK);
buf : 		on_off = vt_get_leds(fg_console, VC_NUMLOCK);
buf : 		break;
buf : 	case KVAL(K_HOLD):
buf : 		label = spk_msg_get(MSG_KEYNAME_SCROLLLOCK);
buf : 		on_off = vt_get_leds(fg_console, VC_SCROLLOCK);
buf : 		if (speakup_console[vc->vc_num])
if (speakup_console[vc->vc_num]) 
buf : 			speakup_console[vc->vc_num]->tty_stopped = on_off;
buf : 		break;
buf : 	default:
buf : 		spk_parked &= 0xfe;
buf : 		spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 		return;
buf : 	}
buf : 	if (on_off < 2)
if (on_off < 2) 
buf : 		synth_printf("%s %s\n",
buf : 			     label, spk_msg_get(MSG_STATUS_START + on_off));
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : }
buf : 
buf : static int inc_dec_var(u_char value)
buf : {
buf : 	struct st_var_header *p_header;
buf : 	struct var_t *var_data;
buf : 	char num_buf[32];
buf : 	char *cp = num_buf;
buf : 	char *pn;
buf : 	int var_id = (int)value - VAR_START;
buf : 	int how = (var_id & 1) ? E_INC : E_DEC;
buf : 	var_id = var_id / 2 + FIRST_SET_VAR;
buf : 	p_header = spk_get_var_header(var_id);
buf : 	if (p_header == NULL)
if (p_header == NULL) 
buf : 		return -1;
buf : 	if (p_header->var_type != VAR_NUM)
if (p_header->var_type != VAR_NUM) 
buf : 		return -1;
buf : 	var_data = p_header->data;
buf : 	if (spk_set_num_var(1, p_header, how) != 0)
if (spk_set_num_var(1, p_header, how) != 0) 
buf : 		return -1;
buf : 	if (!spk_close_press) {
if (!spk_close_press) { 
buf : 		for (pn = p_header->name; *pn; pn++) {
for (pn = p_header->name; *pn; pn++) { 
buf : 			if (*pn == '_')
buf : 				*cp = SPACE;
buf : 			else
buf : 				*cp++ = *pn;
buf : 		}
buf : 	}
buf : 	snprintf(cp, sizeof(num_buf) - (cp - num_buf), " %d ",
buf : 		 var_data->u.n.value);
buf : 	synth_printf("%s", num_buf);
buf : 	return 0;
buf : }
buf : 
buf : static void speakup_win_set(struct vc_data *vc)
buf : {
buf : 	char info[40];
buf : 	if (win_start > 1) {
if (win_start > 1) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_WINDOW_ALREADY_SET));
buf : 		return;
buf : 	}
buf : 	if (spk_x < win_left || spk_y < win_top) {
if (spk_x < win_left || spk_y < win_top) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_END_BEFORE_START));
buf : 		return;
buf : 	}
buf : 	if (win_start && spk_x == win_left && spk_y == win_top) {
if (win_start && spk_x == win_left && spk_y == win_top) { 
buf : 		win_left = 0;
buf : 		win_right = vc->vc_cols - 1;
buf : 		win_bottom = spk_y;
buf : 		snprintf(info, sizeof(info), spk_msg_get(MSG_WINDOW_LINE),
buf : 			 (int)win_top + 1);
buf : 	} else {
buf : 		if (!win_start) {
if (!win_start) { 
buf : 			win_top = spk_y;
buf : 			win_left = spk_x;
buf : 		} else {
buf : 			win_bottom = spk_y;
buf : 			win_right = spk_x;
buf : 		}
buf : 		snprintf(info, sizeof(info), spk_msg_get(MSG_WINDOW_BOUNDARY),
buf : 			 (win_start) ? spk_msg_get(MSG_END) : spk_msg_get(MSG_START),
buf : 			 (int)spk_y + 1, (int)spk_x + 1);
buf : 	}
buf : 	synth_printf("%s\n", info);
buf : 	win_start++;
buf : }
buf : 
buf : static void speakup_win_clear(struct vc_data *vc)
buf : {
buf : 	win_top = win_bottom = 0;
buf : 	win_left = win_right = 0;
buf : 	win_start = 0;
buf : 	synth_printf("%s\n", spk_msg_get(MSG_WINDOW_CLEARED));
buf : }
buf : 
buf : static void speakup_win_enable(struct vc_data *vc)
buf : {
buf : 	if (win_start < 2) {
if (win_start < 2) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_NO_WINDOW));
buf : 		return;
buf : 	}
buf : 	win_enabled ^= 1;
buf : 	if (win_enabled)
if (win_enabled) 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_WINDOW_SILENCED));
buf : 	else
buf : 		synth_printf("%s\n", spk_msg_get(MSG_WINDOW_SILENCE_DISABLED));
buf : }
buf : 
buf : static void speakup_bits(struct vc_data *vc)
buf : {
buf : 	int val = this_speakup_key - (FIRST_EDIT_BITS - 1);
buf : 	if (spk_special_handler != NULL || val < 1 || val > 6) {
if (spk_special_handler != NULL || val < 1 || val > 6) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_ERROR));
buf : 		return;
buf : 	}
buf : 	pb_edit = &spk_punc_info[val];
buf : 	synth_printf(spk_msg_get(MSG_EDIT_PROMPT), pb_edit->name);
buf : 	spk_special_handler = edit_bits;
buf : }
buf : 
buf : static int handle_goto(struct vc_data *vc, u_char type, u_char ch, u_short key)
buf : {
buf : 	static u_char goto_buf[8];
buf : 	static int num;
buf : 	int maxlen;
buf : 	char *cp;
buf : 
buf : 	if (type == KT_SPKUP && ch == SPEAKUP_GOTO)
if (type == KT_SPKUP && ch == SPEAKUP_GOTO) 
buf : 		goto do_goto;
buf : 	if (type == KT_LATIN && ch == '\n')
if (type == KT_LATIN && ch == '\n') 
buf : 		goto do_goto;
buf : 	if (type != 0)
if (type != 0) 
buf : 		goto oops;
buf : 	if (ch == 8) {
if (ch == 8) { 
buf : 		if (num == 0)
buf : 			return -1;
buf : 		ch = goto_buf[--num];
buf : 		goto_buf[num] = '\0';
buf : 		spkup_write(&ch, 1);
buf : 		return 1;
buf : 	}
buf : 	if (ch < '+' || ch > 'y')
if (ch < '+' || ch > 'y') 
buf : 		goto oops;
buf : 	goto_buf[num++] = ch;
buf : 	goto_buf[num] = '\0';
buf : 	spkup_write(&ch, 1);
buf : 	maxlen = (*goto_buf >= '0') ? 3 : 4;
buf : 	if ((ch == '+' || ch == '-') && num == 1)
if ((ch == '+' || ch == '-') && num == 1) 
buf : 		return 1;
buf : 	if (ch >= '0' && ch <= '9' && num < maxlen)
if (ch >= '0' && ch <= '9' && num < maxlen) 
buf : 		return 1;
buf : 	if (num < maxlen - 1 || num > maxlen)
if (num < maxlen - 1 || num > maxlen) 
buf : 		goto oops;
buf : 	if (ch < 'x' || ch > 'y') {
if (ch < 'x' || ch > 'y') { 
buf : oops:
buf : 		if (!spk_killed)
if (!spk_killed) 
buf : 			synth_printf(" %s\n", spk_msg_get(MSG_GOTO_CANCELED));
buf : 		goto_buf[num = 0] = '\0';
buf : 		spk_special_handler = NULL;
buf : 		return 1;
buf : 	}
buf : 
buf : 	goto_pos = simple_strtoul(goto_buf, &cp, 10);
buf : 
buf : 	if (*cp == 'x') {
if (*cp == 'x') { 
buf : 		if (*goto_buf < '0')
buf : 			goto_pos += spk_x;
buf : 		else if (goto_pos > 0)
if (goto_pos > 0) 
buf : 			goto_pos--;
buf : 
buf : 		if (goto_pos >= vc->vc_cols)
if (goto_pos >= vc->vc_cols) 
buf : 			goto_pos = vc->vc_cols - 1;
buf : 		goto_x = 1;
buf : 	} else {
buf : 		if (*goto_buf < '0')
if (*goto_buf < '0') 
buf : 			goto_pos += spk_y;
buf : 		else if (goto_pos > 0)
if (goto_pos > 0) 
buf : 			goto_pos--;
buf : 
buf : 		if (goto_pos >= vc->vc_rows)
if (goto_pos >= vc->vc_rows) 
buf : 			goto_pos = vc->vc_rows - 1;
buf : 		goto_x = 0;
buf : 	}
buf : 	goto_buf[num = 0] = '\0';
buf : do_goto:
buf : 	spk_special_handler = NULL;
buf : 	spk_parked |= 0x01;
buf : 	if (goto_x) {
if (goto_x) { 
buf : 		spk_pos -= spk_x * 2;
buf : 		spk_x = goto_pos;
buf : 		spk_pos += goto_pos * 2;
buf : 		say_word(vc);
buf : 	} else {
buf : 		spk_y = goto_pos;
buf : 		spk_pos = vc->vc_origin + (goto_pos * vc->vc_size_row);
buf : 		say_line(vc);
buf : 	}
buf : 	return 1;
buf : }
buf : 
buf : static void speakup_goto(struct vc_data *vc)
buf : {
buf : 	if (spk_special_handler != NULL) {
if (spk_special_handler != NULL) { 
buf : 		synth_printf("%s\n", spk_msg_get(MSG_ERROR));
buf : 		return;
buf : 	}
buf : 	synth_printf("%s\n", spk_msg_get(MSG_GOTO));
buf : 	spk_special_handler = handle_goto;
buf : 	return;
buf : }
buf : 
buf : static void speakup_help(struct vc_data *vc)
buf : {
buf : 	spk_handle_help(vc, KT_SPKUP, SPEAKUP_HELP, 0);
buf : }
buf : 
buf : static void do_nothing(struct vc_data *vc)
buf : {
buf : 	return;			/* flush done in do_spkup */
buf : }
buf : 
buf : static u_char key_speakup, spk_key_locked;
buf : 
buf : static void speakup_lock(struct vc_data *vc)
buf : {
buf : 	if (!spk_key_locked)
if (!spk_key_locked) 
buf : 		spk_key_locked = key_speakup = 16;
buf : 	else
buf : 		spk_key_locked = key_speakup = 0;
buf : }
buf : 
buf : typedef void (*spkup_hand) (struct vc_data *);
buf : static spkup_hand spkup_handler[] = {
buf : 	/* must be ordered same as defines in speakup.h */
buf : 	do_nothing, speakup_goto, speech_kill, speakup_shut_up,
buf : 	speakup_cut, speakup_paste, say_first_char, say_last_char,
buf : 	say_char, say_prev_char, say_next_char,
buf : 	say_word, say_prev_word, say_next_word,
buf : 	say_line, say_prev_line, say_next_line,
buf : 	top_edge, bottom_edge, left_edge, right_edge,
buf : 	spell_word, spell_word, say_screen,
buf : 	say_position, say_attributes,
buf : 	speakup_off, speakup_parked, say_line,	/* this is for indent */
for indent */ 
buf : 	say_from_top, say_to_bottom,
buf : 	say_from_left, say_to_right,
buf : 	say_char_num, speakup_bits, speakup_bits, say_phonetic_char,
buf : 	speakup_bits, speakup_bits, speakup_bits,
buf : 	speakup_win_set, speakup_win_clear, speakup_win_enable, speakup_win_say,
buf : 	speakup_lock, speakup_help, toggle_cursoring, read_all_doc, NULL
buf : };
buf : 
buf : static void do_spkup(struct vc_data *vc, u_char value)
buf : {
buf : 	if (spk_killed && value != SPEECH_KILL)
if (spk_killed && value != SPEECH_KILL) 
buf : 		return;
buf : 	spk_keydown = 0;
buf : 	spk_lastkey = 0;
buf : 	spk_shut_up &= 0xfe;
buf : 	this_speakup_key = value;
buf : 	if (value < SPKUP_MAX_FUNC && spkup_handler[value]) {
if (value < SPKUP_MAX_FUNC && spkup_handler[value]) { 
buf : 		spk_do_flush();
buf : 		(*spkup_handler[value]) (vc);
buf : 	} else {
buf : 		if (inc_dec_var(value) < 0)
if (inc_dec_var(value) < 0) 
buf : 			bleep(9);
buf : 	}
buf : }
buf : 
buf : static const char *pad_chars = "0123456789+-*/\015,.?()";
buf : 
buf : static int
buf : speakup_key(struct vc_data *vc, int shift_state, int keycode, u_short keysym,
ift_state, int keycode, u_short keysym, 
buf : 	    int up_flag)
buf : {
buf : 	unsigned long flags;
buf : 	int kh;
buf : 	u_char *key_info;
buf : 	u_char type = KTYP(keysym), value = KVAL(keysym), new_key = 0;
buf : 	u_char shift_info, offset;
ift_info, offset; 
buf : 	int ret = 0;
buf : 	if (synth == NULL)
if (synth == NULL) 
buf : 		return 0;
buf : 
buf : 	spin_lock_irqsave(&speakup_info.spinlock, flags);
buf : 	tty = vc->port.tty;
buf : 	if (type >= 0xf0)
if (type >= 0xf0) 
buf : 		type -= 0xf0;
buf : 	if (type == KT_PAD
if (type == KT_PAD 
buf : 		&& (vt_get_leds(fg_console, VC_NUMLOCK))) {
buf : 		if (up_flag) {
if (up_flag) { 
buf : 			spk_keydown = 0;
buf : 			goto out;
buf : 		}
buf : 		value = spk_lastkey = pad_chars[value];
buf : 		spk_keydown++;
buf : 		spk_parked &= 0xfe;
buf : 		goto no_map;
buf : 	}
buf : 	if (keycode >= MAX_KEY)
if (keycode >= MAX_KEY) 
buf : 		goto no_map;
buf : 	key_info = spk_our_keys[keycode];
buf : 	if (!key_info)
if (!key_info) 
buf : 		goto no_map;
buf : 	/* Check valid read all mode keys */
buf : 	if ((cursor_track == read_all_mode) && (!up_flag)) {
if ((cursor_track == read_all_mode) && (!up_flag)) { 
buf : 		switch (value) {
buf : 		case KVAL(K_DOWN):
buf : 		case KVAL(K_UP):
buf : 		case KVAL(K_LEFT):
buf : 		case KVAL(K_RIGHT):
buf : 		case KVAL(K_PGUP):
buf : 		case KVAL(K_PGDN):
buf : 			break;
buf : 		default:
buf : 			stop_read_all(vc);
buf : 			break;
buf : 		}
buf : 	}
buf : 	shift_info = (shift_state & 0x0f) + key_speakup;
ift_info = (shift_state & 0x0f) + key_speakup; 
buf : 	offset = spk_shift_table[shift_info];
buf : 	if (offset) {
if (offset) { 
buf : 		new_key = key_info[offset];
buf : 		if (new_key) {
if (new_key) { 
buf : 			ret = 1;
buf : 			if (new_key == SPK_KEY) {
if (new_key == SPK_KEY) { 
buf : 				if (!spk_key_locked)
buf : 					key_speakup = (up_flag) ? 0 : 16;
buf : 				if (up_flag || spk_killed)
if (up_flag || spk_killed) 
buf : 					goto out;
buf : 				spk_shut_up &= 0xfe;
buf : 				spk_do_flush();
buf : 				goto out;
buf : 			}
buf : 			if (up_flag)
if (up_flag) 
buf : 				goto out;
buf : 			if (last_keycode == keycode &&
if (last_keycode == keycode && 
buf : 			    last_spk_jiffy + MAX_DELAY > jiffies) {
buf : 				spk_close_press = 1;
buf : 				offset = spk_shift_table[shift_info + 32];
ift_table[shift_info + 32]; 
buf : 				/* double press? */
buf : 				if (offset && key_info[offset])
if (offset && key_info[offset]) 
buf : 					new_key = key_info[offset];
buf : 			}
buf : 			last_keycode = keycode;
buf : 			last_spk_jiffy = jiffies;
iffy = jiffies; 
buf : 			type = KT_SPKUP;
buf : 			value = new_key;
buf : 		}
buf : 	}
buf : no_map:
buf : 	if (type == KT_SPKUP && spk_special_handler == NULL) {
if (type == KT_SPKUP && spk_special_handler == NULL) { 
buf : 		do_spkup(vc, new_key);
buf : 		spk_close_press = 0;
buf : 		ret = 1;
buf : 		goto out;
buf : 	}
buf : 	if (up_flag || spk_killed || type == KT_SHIFT)
if (up_flag || spk_killed || type == KT_SHIFT) 
buf : 		goto out;
buf : 	spk_shut_up &= 0xfe;
buf : 	kh = (value == KVAL(K_DOWN))
buf : 	    || (value == KVAL(K_UP))
buf : 	    || (value == KVAL(K_LEFT))
buf : 	    || (value == KVAL(K_RIGHT));
buf : 	if ((cursor_track != read_all_mode) || !kh)
if ((cursor_track != read_all_mode) || !kh) 
buf : 		if (!spk_no_intr)
buf : 			spk_do_flush();
buf : 	if (spk_special_handler) {
if (spk_special_handler) { 
buf : 		if (type == KT_SPEC && value == 1) {
buf : 			value = '\n';
buf : 			type = KT_LATIN;
buf : 		} else if (type == KT_LETTER)
if (type == KT_LETTER) 
buf : 			type = KT_LATIN;
buf : 		else if (value == 0x7f)
if (value == 0x7f) 
buf : 			value = 8;	/* make del = backspace */
buf : 		ret = (*spk_special_handler) (vc, type, value, keycode);
buf : 		spk_close_press = 0;
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			bleep(9);
buf : 		goto out;
buf : 	}
buf : 	last_keycode = 0;
buf : out:
buf : 	spin_unlock_irqrestore(&speakup_info.spinlock, flags);
buf : 	return ret;
buf : }
buf : 
buf : static int keyboard_notifier_call(struct notifier_block *nb,
ifier_call(struct notifier_block *nb, 
buf : 				  unsigned long code, void *_param)
buf : {
buf : 	struct keyboard_notifier_param *param = _param;
ifier_param *param = _param; 
buf : 	struct vc_data *vc = param->vc;
buf : 	int up = !param->down;
buf : 	int ret = NOTIFY_OK;
buf : 	static int keycode;	/* to hold the current keycode */
buf : 
buf : 	if (vc->vc_mode == KD_GRAPHICS)
if (vc->vc_mode == KD_GRAPHICS) 
buf : 		return ret;
buf : 
buf : 	/*
buf : 	 * First, determine whether we are handling a fake keypress on
buf : 	 * the current processor.  If we are, then return NOTIFY_OK,
buf : 	 * to pass the keystroke up the chain.  This prevents us from
buf : 	 * trying to take the Speakup lock while it is held by the
while it is held by the 
buf : 	 * processor on which the simulated keystroke was generated.
buf : 	 * Also, the simulated keystrokes should be ignored by Speakup.
buf : 	 */
buf : 
buf : 	if (speakup_fake_key_pressed())
if (speakup_fake_key_pressed()) 
buf : 		return ret;
buf : 
buf : 	switch (code) {
buf : 	case KBD_KEYCODE:
buf : 		/* speakup requires keycode and keysym currently */
buf : 		keycode = param->value;
buf : 		break;
buf : 	case KBD_UNBOUND_KEYCODE:
buf : 		/* not used yet */
buf : 		break;
buf : 	case KBD_UNICODE:
buf : 		/* not used yet */
buf : 		break;
buf : 	case KBD_KEYSYM:
buf : 		if (speakup_key(vc, param->shift, keycode, param->value, up))
if (speakup_key(vc, param->shift, keycode, param->value, up)) 
buf : 			ret = NOTIFY_STOP;
buf : 		else if (KTYP(param->value) == KT_CUR)
if (KTYP(param->value) == KT_CUR) 
buf : 			ret = pre_handle_cursor(vc, KVAL(param->value), up);
buf : 		break;
buf : 	case KBD_POST_KEYSYM:{
buf : 			unsigned char type = KTYP(param->value) - 0xf0;
buf : 			unsigned char val = KVAL(param->value);
buf : 			switch (type) {
buf : 			case KT_SHIFT:
buf : 				do_handle_shift(vc, val, up);
ift(vc, val, up); 
buf : 				break;
buf : 			case KT_LATIN:
buf : 			case KT_LETTER:
buf : 				do_handle_latin(vc, val, up);
buf : 				break;
buf : 			case KT_CUR:
buf : 				do_handle_cursor(vc, val, up);
buf : 				break;
buf : 			case KT_SPEC:
buf : 				do_handle_spec(vc, val, up);
buf : 				break;
buf : 			}
buf : 			break;
buf : 		}
buf : 	}
buf : 	return ret;
buf : }
buf : 
buf : static int vt_notifier_call(struct notifier_block *nb,
ifier_call(struct notifier_block *nb, 
buf : 			    unsigned long code, void *_param)
buf : {
buf : 	struct vt_notifier_param *param = _param;
ifier_param *param = _param; 
buf : 	struct vc_data *vc = param->vc;
buf : 	switch (code) {
buf : 	case VT_ALLOCATE:
buf : 		if (vc->vc_mode == KD_TEXT)
if (vc->vc_mode == KD_TEXT) 
buf : 			speakup_allocate(vc);
buf : 		break;
buf : 	case VT_DEALLOCATE:
buf : 		speakup_deallocate(vc);
buf : 		break;
buf : 	case VT_WRITE:
buf : 		if (param->c == '\b')
if (param->c == '\b') 
buf : 			speakup_bs(vc);
buf : 		else if (param->c < 0x100) {
if (param->c < 0x100) { 
buf : 			char d = param->c;
buf : 			speakup_con_write(vc, &d, 1);
buf : 		}
buf : 		break;
buf : 	case VT_UPDATE:
buf : 		speakup_con_update(vc);
buf : 		break;
buf : 	}
buf : 	return NOTIFY_OK;
buf : }
buf : 
buf : /* called by: module_exit() */
buf : static void __exit speakup_exit(void)
buf : {
buf : 	int i;
buf : 
buf : 	unregister_keyboard_notifier(&keyboard_notifier_block);
ifier(&keyboard_notifier_block); 
buf : 	unregister_vt_notifier(&vt_notifier_block);
buf : 	speakup_unregister_devsynth();
buf : 	speakup_cancel_paste();
buf : 	del_timer(&cursor_timer);
buf : 	kthread_stop(speakup_task);
buf : 	speakup_task = NULL;
buf : 	mutex_lock(&spk_mutex);
buf : 	synth_release();
buf : 	mutex_unlock(&spk_mutex);
buf : 
buf : 	speakup_kobj_exit();
buf : 
buf : 	for (i = 0; i < MAX_NR_CONSOLES; i++)
for (i = 0; i < MAX_NR_CONSOLES; i++) 
buf : 		kfree(speakup_console[i]);
buf : 
buf : 	speakup_remove_virtual_keyboard();
buf : 
buf : 	for (i = 0; i < MAXVARS; i++)
for (i = 0; i < MAXVARS; i++) 
buf : 		speakup_unregister_var(i);
buf : 
buf : 	for (i = 0; i < 256; i++) {
for (i = 0; i < 256; i++) { 
buf : 		if (spk_characters[i] != spk_default_chars[i])
buf : 			kfree(spk_characters[i]);
buf : 	}
buf : 
buf : 	spk_free_user_msgs();
buf : }
buf : 
buf : /* call by: module_init() */
buf : static int __init speakup_init(void)
buf : {
buf : 	int i;
buf : 	long err = 0;
buf : 	struct st_spk_t *first_console;
buf : 	struct vc_data *vc = vc_cons[fg_console].d;
buf : 	struct var_t *var;
buf : 
buf : 	/* These first few initializations cannot fail. */
buf : 	spk_initialize_msgs();	/* Initialize arrays for i18n. */
for i18n. */ 
buf : 	spk_reset_default_chars();
buf : 	spk_reset_default_chartab();
buf : 	spk_strlwr(synth_name);
buf : 	spk_vars[0].u.n.high = vc->vc_cols;
buf : 	for (var = spk_vars; var->var_id != MAXVARS; var++)
for (var = spk_vars; var->var_id != MAXVARS; var++) 
buf : 		speakup_register_var(var);
buf : 	for (var = synth_time_vars;
for (var = synth_time_vars; 
buf : 	     (var->var_id >= 0) && (var->var_id < MAXVARS); var++)
buf : 		speakup_register_var(var);
buf : 	for (i = 1; spk_punc_info[i].mask != 0; i++)
for (i = 1; spk_punc_info[i].mask != 0; i++) 
buf : 		spk_set_mask_bits(NULL, i, 2);
buf : 
buf : 	spk_set_key_info(spk_key_defaults, spk_key_buf);
buf : 
buf : 	/* From here on out, initializations can fail. */
buf : 	err = speakup_add_virtual_keyboard();
buf : 	if (err)
if (err) 
buf : 		goto error_virtkeyboard;
buf : 
buf : 	first_console = kzalloc(sizeof(*first_console), GFP_KERNEL);
buf : 	if (!first_console) {
if (!first_console) { 
buf : 		err = -ENOMEM;
buf : 		goto error_alloc;
buf : 	}
buf : 
buf : 	speakup_console[vc->vc_num] = first_console;
buf : 	speakup_date(vc);
buf : 
buf : 	for (i = 0; i < MAX_NR_CONSOLES; i++)
for (i = 0; i < MAX_NR_CONSOLES; i++) 
buf : 		if (vc_cons[i].d) {
buf : 			err = speakup_allocate(vc_cons[i].d);
buf : 			if (err)
if (err) 
buf : 				goto error_kobjects;
buf : 		}
buf : 
buf : 	if (spk_quiet_boot)
if (spk_quiet_boot) 
buf : 		spk_shut_up |= 0x01;
buf : 
buf : 	err = speakup_kobj_init();
buf : 	if (err)
if (err) 
buf : 		goto error_kobjects;
buf : 
buf : 	synth_init(synth_name);
buf : 	speakup_register_devsynth();
buf : 	/*
buf : 	 * register_devsynth might fail, but this error is not fatal.
buf : 	 * /dev/synth is an extra feature; the rest of Speakup
buf : 	 * will work fine without it.
buf : 	 */
buf : 
buf : 	err = register_keyboard_notifier(&keyboard_notifier_block);
ifier(&keyboard_notifier_block); 
buf : 	if (err)
buf : 		goto error_kbdnotifier;
ifier; 
buf : 	err = register_vt_notifier(&vt_notifier_block);
buf : 	if (err)
if (err) 
buf : 		goto error_vtnotifier;
buf : 
buf : 	speakup_task = kthread_create(speakup_thread, NULL, "speakup");
buf : 
buf : 	if (IS_ERR(speakup_task)) {
if (IS_ERR(speakup_task)) { 
buf : 		err = PTR_ERR(speakup_task);
buf : 		goto error_task;
buf : 	}
buf : 
buf : 	set_user_nice(speakup_task, 10);
buf : 	wake_up_process(speakup_task);
buf : 
buf : 	pr_info("speakup %s: initialized\n", SPEAKUP_VERSION);
buf : 	pr_info("synth name on entry is: %s\n", synth_name);
buf : 	goto out;
buf : 
buf : error_task:
buf : 	unregister_vt_notifier(&vt_notifier_block);
ifier(&vt_notifier_block); 
buf : 
buf : error_vtnotifier:
buf : 	unregister_keyboard_notifier(&keyboard_notifier_block);
ifier(&keyboard_notifier_block); 
buf : 	del_timer(&cursor_timer);
buf : 
buf : error_kbdnotifier:
ifier: 
buf : 	speakup_unregister_devsynth();
buf : 	mutex_lock(&spk_mutex);
buf : 	synth_release();
buf : 	mutex_unlock(&spk_mutex);
buf : 	speakup_kobj_exit();
buf : 
buf : error_kobjects:
buf : 	for (i = 0; i < MAX_NR_CONSOLES; i++)
for (i = 0; i < MAX_NR_CONSOLES; i++) 
buf : 		kfree(speakup_console[i]);
buf : 
buf : error_alloc:
buf : 	speakup_remove_virtual_keyboard();
buf : 
buf : error_virtkeyboard:
buf : 	for (i = 0; i < MAXVARS; i++)
for (i = 0; i < MAXVARS; i++) 
buf : 		speakup_unregister_var(i);
buf : 
buf : 	for (i = 0; i < 256; i++) {
for (i = 0; i < 256; i++) { 
buf : 		if (spk_characters[i] != spk_default_chars[i])
buf : 			kfree(spk_characters[i]);
buf : 	}
buf : 
buf : 	spk_free_user_msgs();
buf : 
buf : out:
buf : 	return err;
buf : }
buf : 
buf : module_init(speakup_init);
buf : module_exit(speakup_exit);
file : ./test/kernel/drivers/tty/ipwireless/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * IPWireless 3G PCMCIA Network Driver
buf :  *
buf :  * Original code
buf :  *   by Stephen Blackheath <stephen@blacksapphire.com>,
buf :  *      Ben Martel <benm@symmetric.co.nz>
buf :  *
buf :  * Copyrighted as follows:
buf :  *   Copyright (C) 2004 by Symmetric Systems Ltd (NZ)
buf :  *
buf :  * Various driver changes and rewrites, port to new kernels
buf :  *   Copyright (C) 2006-2007 Jiri Kosina
buf :  *
buf :  * Misc code cleanups and updates
buf :  *   Copyright (C) 2007 David Sterba
buf :  */
buf : 
buf : #include "hardware.h"
buf : #include "network.h"
buf : #include "main.h"
buf : #include "tty.h"
buf : 
buf : #include <linux/delay.h>
buf : #include <linux/init.h>
buf : #include <linux/io.h>
buf : #include <linux/kernel.h>
buf : #include <linux/module.h>
buf : #include <linux/sched.h>
buf : #include <linux/slab.h>
buf : 
buf : #include <pcmcia/cisreg.h>
buf : #include <pcmcia/device_id.h>
buf : #include <pcmcia/ss.h>
buf : #include <pcmcia/ds.h>
buf : 
buf : static const struct pcmcia_device_id ipw_ids[] = {
buf : 	PCMCIA_DEVICE_MANF_CARD(0x02f2, 0x0100),
buf : 	PCMCIA_DEVICE_MANF_CARD(0x02f2, 0x0200),
buf : 	PCMCIA_DEVICE_NULL
buf : };
buf : MODULE_DEVICE_TABLE(pcmcia, ipw_ids);
buf : 
buf : static void ipwireless_detach(struct pcmcia_device *link);
buf : 
buf : /*
buf :  * Module params
buf :  */
buf : /* Debug mode: more verbose, print sent/recv bytes */
buf : int ipwireless_debug;
buf : int ipwireless_loopback;
buf : int ipwireless_out_queue = 10;
buf : 
buf : module_param_named(debug, ipwireless_debug, int, 0);
buf : module_param_named(loopback, ipwireless_loopback, int, 0);
buf : module_param_named(out_queue, ipwireless_out_queue, int, 0);
buf : MODULE_PARM_DESC(debug, "switch on debug messages [0]");
buf : MODULE_PARM_DESC(loopback,
buf : 		"debug: enable ras_raw channel [0]");
buf : MODULE_PARM_DESC(out_queue, "debug: set size of outgoing PPP queue [10]");
buf : 
buf : /* Executes in process context. */
buf : static void signalled_reboot_work(struct work_struct *work_reboot)
buf : {
buf : 	struct ipw_dev *ipw = container_of(work_reboot, struct ipw_dev,
buf : 			work_reboot);
buf : 	struct pcmcia_device *link = ipw->link;
buf : 	pcmcia_reset_card(link->socket);
buf : }
buf : 
buf : static void signalled_reboot_callback(void *callback_data)
buf : {
buf : 	struct ipw_dev *ipw = (struct ipw_dev *) callback_data;
buf : 
buf : 	/* Delegate to process context. */
buf : 	schedule_work(&ipw->work_reboot);
buf : }
buf : 
buf : static int ipwireless_probe(struct pcmcia_device *p_dev, void *priv_data)
buf : {
buf : 	struct ipw_dev *ipw = priv_data;
buf : 	int ret;
buf : 
buf : 	p_dev->resource[0]->flags &= ~IO_DATA_PATH_WIDTH;
buf : 	p_dev->resource[0]->flags |= IO_DATA_PATH_WIDTH_AUTO;
buf : 
buf : 	/* 0x40 causes it to generate level mode interrupts. */
buf : 	/* 0x04 enables IREQ pin. */
buf : 	p_dev->config_index |= 0x44;
buf : 	p_dev->io_lines = 16;
buf : 	ret = pcmcia_request_io(p_dev);
buf : 	if (ret)
if (ret) 
buf : 		return ret;
buf : 
buf : 	if (!request_region(p_dev->resource[0]->start,
if (!request_region(p_dev->resource[0]->start, 
buf : 			    resource_size(p_dev->resource[0]),
buf : 			    IPWIRELESS_PCCARD_NAME)) {
buf : 		ret = -EBUSY;
buf : 		goto exit;
buf : 	}
buf : 
buf : 	p_dev->resource[2]->flags |=
buf : 		WIN_DATA_WIDTH_16 | WIN_MEMORY_TYPE_CM | WIN_ENABLE;
buf : 
buf : 	ret = pcmcia_request_window(p_dev, p_dev->resource[2], 0);
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		goto exit1;
buf : 
buf : 	ret = pcmcia_map_mem_page(p_dev, p_dev->resource[2], p_dev->card_addr);
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		goto exit1;
buf : 
buf : 	ipw->is_v2_card = resource_size(p_dev->resource[2]) == 0x100;
buf : 
buf : 	ipw->common_memory = ioremap(p_dev->resource[2]->start,
buf : 				resource_size(p_dev->resource[2]));
buf : 	if (!request_mem_region(p_dev->resource[2]->start,
if (!request_mem_region(p_dev->resource[2]->start, 
buf : 				resource_size(p_dev->resource[2]),
buf : 				IPWIRELESS_PCCARD_NAME)) {
buf : 		ret = -EBUSY;
buf : 		goto exit2;
buf : 	}
buf : 
buf : 	p_dev->resource[3]->flags |= WIN_DATA_WIDTH_16 | WIN_MEMORY_TYPE_AM |
buf : 					WIN_ENABLE;
buf : 	p_dev->resource[3]->end = 0; /* this used to be 0x1000 */
buf : 	ret = pcmcia_request_window(p_dev, p_dev->resource[3], 0);
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		goto exit3;
buf : 
buf : 	ret = pcmcia_map_mem_page(p_dev, p_dev->resource[3], 0);
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		goto exit3;
buf : 
buf : 	ipw->attr_memory = ioremap(p_dev->resource[3]->start,
buf : 				resource_size(p_dev->resource[3]));
buf : 	if (!request_mem_region(p_dev->resource[3]->start,
if (!request_mem_region(p_dev->resource[3]->start, 
buf : 				resource_size(p_dev->resource[3]),
buf : 				IPWIRELESS_PCCARD_NAME)) {
buf : 		ret = -EBUSY;
buf : 		goto exit4;
buf : 	}
buf : 
buf : 	return 0;
buf : 
buf : exit4:
buf : 	iounmap(ipw->attr_memory);
buf : exit3:
buf : 	release_mem_region(p_dev->resource[2]->start,
buf : 			resource_size(p_dev->resource[2]));
buf : exit2:
buf : 	iounmap(ipw->common_memory);
buf : exit1:
buf : 	release_region(p_dev->resource[0]->start,
buf : 		       resource_size(p_dev->resource[0]));
buf : exit:
buf : 	pcmcia_disable_device(p_dev);
buf : 	return ret;
buf : }
buf : 
buf : static int config_ipwireless(struct ipw_dev *ipw)
buf : {
buf : 	struct pcmcia_device *link = ipw->link;
buf : 	int ret = 0;
buf : 
buf : 	ipw->is_v2_card = 0;
buf : 	link->config_flags |= CONF_AUTO_SET_IO | CONF_AUTO_SET_IOMEM |
buf : 		CONF_ENABLE_IRQ;
buf : 
buf : 	ret = pcmcia_loop_config(link, ipwireless_probe, ipw);
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		return ret;
buf : 
buf : 	INIT_WORK(&ipw->work_reboot, signalled_reboot_work);
buf : 
buf : 	ipwireless_init_hardware_v1(ipw->hardware, link->resource[0]->start,
buf : 				    ipw->attr_memory, ipw->common_memory,
buf : 				    ipw->is_v2_card, signalled_reboot_callback,
buf : 				    ipw);
buf : 
buf : 	ret = pcmcia_request_irq(link, ipwireless_interrupt);
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		goto exit;
buf : 
buf : 	printk(KERN_INFO IPWIRELESS_PCCARD_NAME ": Card type %s\n",
buf : 			ipw->is_v2_card ? "V2/V3" : "V1");
buf : 	printk(KERN_INFO IPWIRELESS_PCCARD_NAME
buf : 		": I/O ports %pR, irq %d\n", link->resource[0],
buf : 			(unsigned int) link->irq);
buf : 	if (ipw->attr_memory && ipw->common_memory)
if (ipw->attr_memory && ipw->common_memory) 
buf : 		printk(KERN_INFO IPWIRELESS_PCCARD_NAME
buf : 			": attr memory %pR, common memory %pR\n",
buf : 			link->resource[3],
buf : 			link->resource[2]);
buf : 
buf : 	ipw->network = ipwireless_network_create(ipw->hardware);
buf : 	if (!ipw->network)
if (!ipw->network) 
buf : 		goto exit;
buf : 
buf : 	ipw->tty = ipwireless_tty_create(ipw->hardware, ipw->network);
buf : 	if (!ipw->tty)
if (!ipw->tty) 
buf : 		goto exit;
buf : 
buf : 	ipwireless_init_hardware_v2_v3(ipw->hardware);
buf : 
buf : 	/*
buf : 	 * Do the RequestConfiguration last, because it enables interrupts.
buf : 	 * Then we don't get any interrupts before we're ready for them.
fore we're ready for them. 
buf : 	 */
buf : 	ret = pcmcia_enable_device(link);
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		goto exit;
buf : 
buf : 	return 0;
buf : 
buf : exit:
buf : 	if (ipw->common_memory) {
if (ipw->common_memory) { 
buf : 		release_mem_region(link->resource[2]->start,
buf : 				resource_size(link->resource[2]));
buf : 		iounmap(ipw->common_memory);
buf : 	}
buf : 	if (ipw->attr_memory) {
if (ipw->attr_memory) { 
buf : 		release_mem_region(link->resource[3]->start,
buf : 				resource_size(link->resource[3]));
buf : 		iounmap(ipw->attr_memory);
buf : 	}
buf : 	pcmcia_disable_device(link);
buf : 	return -1;
buf : }
buf : 
buf : static void release_ipwireless(struct ipw_dev *ipw)
buf : {
buf : 	release_region(ipw->link->resource[0]->start,
buf : 		       resource_size(ipw->link->resource[0]));
buf : 	if (ipw->common_memory) {
if (ipw->common_memory) { 
buf : 		release_mem_region(ipw->link->resource[2]->start,
buf : 				resource_size(ipw->link->resource[2]));
buf : 		iounmap(ipw->common_memory);
buf : 	}
buf : 	if (ipw->attr_memory) {
if (ipw->attr_memory) { 
buf : 		release_mem_region(ipw->link->resource[3]->start,
buf : 				resource_size(ipw->link->resource[3]));
buf : 		iounmap(ipw->attr_memory);
buf : 	}
buf : 	pcmcia_disable_device(ipw->link);
buf : }
buf : 
buf : /*
buf :  * ipwireless_attach() creates an "instance" of the driver, allocating
buf :  * local data structures for one device (one interface).  The device
for one device (one interface).  The device 
buf :  * is registered with Card Services.
buf :  *
buf :  * The pcmcia_device structure is initialized, but we don't actually
buf :  * configure the card at this point -- we wait until we receive a
buf :  * card insertion event.
buf :  */
buf : static int ipwireless_attach(struct pcmcia_device *link)
buf : {
buf : 	struct ipw_dev *ipw;
buf : 	int ret;
buf : 
buf : 	ipw = kzalloc(sizeof(struct ipw_dev), GFP_KERNEL);
buf : 	if (!ipw)
if (!ipw) 
buf : 		return -ENOMEM;
buf : 
buf : 	ipw->link = link;
buf : 	link->priv = ipw;
buf : 
buf : 	ipw->hardware = ipwireless_hardware_create();
buf : 	if (!ipw->hardware) {
if (!ipw->hardware) { 
buf : 		kfree(ipw);
buf : 		return -ENOMEM;
buf : 	}
buf : 	/* RegisterClient will call config_ipwireless */
buf : 
buf : 	ret = config_ipwireless(ipw);
buf : 
buf : 	if (ret != 0) {
if (ret != 0) { 
buf : 		ipwireless_detach(link);
buf : 		return ret;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * This deletes a driver "instance".  The device is de-registered with
buf :  * Card Services.  If it has been released, all local data structures
buf :  * are freed.  Otherwise, the structures will be freed when the device
buf :  * is released.
buf :  */
buf : static void ipwireless_detach(struct pcmcia_device *link)
buf : {
buf : 	struct ipw_dev *ipw = link->priv;
buf : 
buf : 	release_ipwireless(ipw);
buf : 
buf : 	if (ipw->tty != NULL)
if (ipw->tty != NULL) 
buf : 		ipwireless_tty_free(ipw->tty);
buf : 	if (ipw->network != NULL)
if (ipw->network != NULL) 
buf : 		ipwireless_network_free(ipw->network);
buf : 	if (ipw->hardware != NULL)
if (ipw->hardware != NULL) 
buf : 		ipwireless_hardware_free(ipw->hardware);
buf : 	kfree(ipw);
buf : }
buf : 
buf : static struct pcmcia_driver me = {
buf : 	.owner		= THIS_MODULE,
buf : 	.probe          = ipwireless_attach,
buf : 	.remove         = ipwireless_detach,
buf : 	.name		= IPWIRELESS_PCCARD_NAME,
buf : 	.id_table       = ipw_ids
buf : };
buf : 
buf : /*
buf :  * Module insertion : initialisation of the module.
buf :  * Register the card with cardmgr...
buf :  */
buf : static int __init init_ipwireless(void)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = ipwireless_tty_init();
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		return ret;
buf : 
buf : 	ret = pcmcia_register_driver(&me);
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		ipwireless_tty_release();
buf : 
buf : 	return ret;
buf : }
buf : 
buf : /*
buf :  * Module removal
buf :  */
buf : static void __exit exit_ipwireless(void)
buf : {
buf : 	pcmcia_unregister_driver(&me);
buf : 	ipwireless_tty_release();
buf : }
buf : 
buf : module_init(init_ipwireless);
buf : module_exit(exit_ipwireless);
buf : 
buf : MODULE_AUTHOR(IPWIRELESS_PCMCIA_AUTHOR);
buf : MODULE_DESCRIPTION(IPWIRELESS_PCCARD_NAME " " IPWIRELESS_PCMCIA_VERSION);
buf : MODULE_LICENSE("GPL");
file : ./test/kernel/drivers/ssb/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Sonics Silicon Backplane
buf :  * Subsystem core
buf :  *
buf :  * Copyright 2005, Broadcom Corporation
buf :  * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
buf :  *
buf :  * Licensed under the GNU/GPL. See COPYING for details.
for details. 
buf :  */
buf : 
buf : #include "ssb_private.h"
buf : 
buf : #include <linux/delay.h>
buf : #include <linux/io.h>
buf : #include <linux/module.h>
buf : #include <linux/platform_device.h>
form_device.h> 
buf : #include <linux/ssb/ssb.h>
buf : #include <linux/ssb/ssb_regs.h>
buf : #include <linux/ssb/ssb_driver_gige.h>
buf : #include <linux/dma-mapping.h>
buf : #include <linux/pci.h>
buf : #include <linux/mmc/sdio_func.h>
buf : #include <linux/slab.h>
buf : 
buf : #include <pcmcia/cistpl.h>
buf : #include <pcmcia/ds.h>
buf : 
buf : 
buf : MODULE_DESCRIPTION("Sonics Silicon Backplane driver");
buf : MODULE_LICENSE("GPL");
buf : 
buf : 
buf : /* Temporary list of yet-to-be-attached buses */
buf : static LIST_HEAD(attach_queue);
buf : /* List if running buses */
if running buses */ 
buf : static LIST_HEAD(buses);
buf : /* Software ID counter */
buf : static unsigned int next_busnumber;
buf : /* buses_mutes locks the two buslists and the next_busnumber.
buf :  * Don't lock this directly, but use ssb_buses_[un]lock() below. */
buf : static DEFINE_MUTEX(buses_mutex);
buf : 
buf : /* There are differences in the codeflow, if the bus is
ifferences in the codeflow, if the bus is 
buf :  * initialized from early boot, as various needed services
buf :  * are not available early. This is a mechanism to delay
buf :  * these initializations to after early boot has finished.
buf :  * It's also used to avoid mutex locking, as that's not
buf :  * available and needed early. */
buf : static bool ssb_is_early_boot = 1;
buf : 
buf : static void ssb_buses_lock(void);
buf : static void ssb_buses_unlock(void);
buf : 
buf : 
buf : #ifdef CONFIG_SSB_PCIHOST
ifdef CONFIG_SSB_PCIHOST 
buf : struct ssb_bus *ssb_pci_dev_to_bus(struct pci_dev *pdev)
buf : {
buf : 	struct ssb_bus *bus;
buf : 
buf : 	ssb_buses_lock();
buf : 	list_for_each_entry(bus, &buses, list) {
for_each_entry(bus, &buses, list) { 
buf : 		if (bus->bustype == SSB_BUSTYPE_PCI &&
buf : 		    bus->host_pci == pdev)
buf : 			goto found;
buf : 	}
buf : 	bus = NULL;
buf : found:
buf : 	ssb_buses_unlock();
buf : 
buf : 	return bus;
buf : }
buf : #endif /* CONFIG_SSB_PCIHOST */
if /* CONFIG_SSB_PCIHOST */ 
buf : 
buf : #ifdef CONFIG_SSB_PCMCIAHOST
buf : struct ssb_bus *ssb_pcmcia_dev_to_bus(struct pcmcia_device *pdev)
buf : {
buf : 	struct ssb_bus *bus;
buf : 
buf : 	ssb_buses_lock();
buf : 	list_for_each_entry(bus, &buses, list) {
for_each_entry(bus, &buses, list) { 
buf : 		if (bus->bustype == SSB_BUSTYPE_PCMCIA &&
buf : 		    bus->host_pcmcia == pdev)
buf : 			goto found;
buf : 	}
buf : 	bus = NULL;
buf : found:
buf : 	ssb_buses_unlock();
buf : 
buf : 	return bus;
buf : }
buf : #endif /* CONFIG_SSB_PCMCIAHOST */
if /* CONFIG_SSB_PCMCIAHOST */ 
buf : 
buf : #ifdef CONFIG_SSB_SDIOHOST
buf : struct ssb_bus *ssb_sdio_func_to_bus(struct sdio_func *func)
buf : {
buf : 	struct ssb_bus *bus;
buf : 
buf : 	ssb_buses_lock();
buf : 	list_for_each_entry(bus, &buses, list) {
for_each_entry(bus, &buses, list) { 
buf : 		if (bus->bustype == SSB_BUSTYPE_SDIO &&
buf : 		    bus->host_sdio == func)
buf : 			goto found;
buf : 	}
buf : 	bus = NULL;
buf : found:
buf : 	ssb_buses_unlock();
buf : 
buf : 	return bus;
buf : }
buf : #endif /* CONFIG_SSB_SDIOHOST */
if /* CONFIG_SSB_SDIOHOST */ 
buf : 
buf : int ssb_for_each_bus_call(unsigned long data,
for_each_bus_call(unsigned long data, 
buf : 			  int (*func)(struct ssb_bus *bus, unsigned long data))
buf : {
buf : 	struct ssb_bus *bus;
buf : 	int res;
buf : 
buf : 	ssb_buses_lock();
buf : 	list_for_each_entry(bus, &buses, list) {
for_each_entry(bus, &buses, list) { 
buf : 		res = func(bus, data);
buf : 		if (res >= 0) {
if (res >= 0) { 
buf : 			ssb_buses_unlock();
buf : 			return res;
buf : 		}
buf : 	}
buf : 	ssb_buses_unlock();
buf : 
buf : 	return -ENODEV;
buf : }
buf : 
buf : static struct ssb_device *ssb_device_get(struct ssb_device *dev)
buf : {
buf : 	if (dev)
if (dev) 
buf : 		get_device(dev->dev);
buf : 	return dev;
buf : }
buf : 
buf : static void ssb_device_put(struct ssb_device *dev)
buf : {
buf : 	if (dev)
if (dev) 
buf : 		put_device(dev->dev);
buf : }
buf : 
buf : static int ssb_device_resume(struct device *dev)
buf : {
buf : 	struct ssb_device *ssb_dev = dev_to_ssb_dev(dev);
buf : 	struct ssb_driver *ssb_drv;
buf : 	int err = 0;
buf : 
buf : 	if (dev->driver) {
if (dev->driver) { 
buf : 		ssb_drv = drv_to_ssb_drv(dev->driver);
buf : 		if (ssb_drv && ssb_drv->resume)
if (ssb_drv && ssb_drv->resume) 
buf : 			err = ssb_drv->resume(ssb_dev);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : out:
buf : 	return err;
buf : }
buf : 
buf : static int ssb_device_suspend(struct device *dev, pm_message_t state)
buf : {
buf : 	struct ssb_device *ssb_dev = dev_to_ssb_dev(dev);
buf : 	struct ssb_driver *ssb_drv;
buf : 	int err = 0;
buf : 
buf : 	if (dev->driver) {
if (dev->driver) { 
buf : 		ssb_drv = drv_to_ssb_drv(dev->driver);
buf : 		if (ssb_drv && ssb_drv->suspend)
if (ssb_drv && ssb_drv->suspend) 
buf : 			err = ssb_drv->suspend(ssb_dev, state);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : out:
buf : 	return err;
buf : }
buf : 
buf : int ssb_bus_resume(struct ssb_bus *bus)
buf : {
buf : 	int err;
buf : 
buf : 	/* Reset HW state information in memory, so that HW is
formation in memory, so that HW is 
buf : 	 * completely reinitialized. */
buf : 	bus->mapped_device = NULL;
buf : #ifdef CONFIG_SSB_DRIVER_PCICORE
ifdef CONFIG_SSB_DRIVER_PCICORE 
buf : 	bus->pcicore.setup_done = 0;
buf : #endif
if 
buf : 
buf : 	err = ssb_bus_powerup(bus, 0);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 	err = ssb_pcmcia_hardware_setup(bus);
buf : 	if (err) {
if (err) { 
buf : 		ssb_bus_may_powerdown(bus);
buf : 		return err;
buf : 	}
buf : 	ssb_chipco_resume(&bus->chipco);
buf : 	ssb_bus_may_powerdown(bus);
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL(ssb_bus_resume);
buf : 
buf : int ssb_bus_suspend(struct ssb_bus *bus)
buf : {
buf : 	ssb_chipco_suspend(&bus->chipco);
buf : 	ssb_pci_xtal(bus, SSB_GPIO_XTAL | SSB_GPIO_PLL, 0);
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL(ssb_bus_suspend);
buf : 
buf : #ifdef CONFIG_SSB_SPROM
ifdef CONFIG_SSB_SPROM 
buf : /** ssb_devices_freeze - Freeze all devices on the bus.
buf :  *
buf :  * After freezing no device driver will be handling a device
buf :  * on this bus anymore. ssb_devices_thaw() must be called after
buf :  * a successful freeze to reactivate the devices.
buf :  *
buf :  * @bus: The bus.
buf :  * @ctx: Context structure. Pass this to ssb_devices_thaw().
buf :  */
buf : int ssb_devices_freeze(struct ssb_bus *bus, struct ssb_freeze_context *ctx)
buf : {
buf : 	struct ssb_device *sdev;
buf : 	struct ssb_driver *sdrv;
buf : 	unsigned int i;
buf : 
buf : 	memset(ctx, 0, sizeof(*ctx));
buf : 	ctx->bus = bus;
buf : 	SSB_WARN_ON(bus->nr_devices > ARRAY_SIZE(ctx->device_frozen));
buf : 
buf : 	for (i = 0; i < bus->nr_devices; i++) {
for (i = 0; i < bus->nr_devices; i++) { 
buf : 		sdev = ssb_device_get(&bus->devices[i]);
buf : 
buf : 		if (!sdev->dev || !sdev->dev->driver ||
if (!sdev->dev || !sdev->dev->driver || 
buf : 		    !device_is_registered(sdev->dev)) {
buf : 			ssb_device_put(sdev);
buf : 			continue;
buf : 		}
buf : 		sdrv = drv_to_ssb_drv(sdev->dev->driver);
buf : 		if (SSB_WARN_ON(!sdrv->remove))
if (SSB_WARN_ON(!sdrv->remove)) 
buf : 			continue;
buf : 		sdrv->remove(sdev);
buf : 		ctx->device_frozen[i] = 1;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /** ssb_devices_thaw - Unfreeze all devices on the bus.
buf :  *
buf :  * This will re-attach the device drivers and re-init the devices.
buf :  *
buf :  * @ctx: The context structure from ssb_devices_freeze()
buf :  */
buf : int ssb_devices_thaw(struct ssb_freeze_context *ctx)
buf : {
buf : 	struct ssb_bus *bus = ctx->bus;
buf : 	struct ssb_device *sdev;
buf : 	struct ssb_driver *sdrv;
buf : 	unsigned int i;
buf : 	int err, result = 0;
buf : 
buf : 	for (i = 0; i < bus->nr_devices; i++) {
for (i = 0; i < bus->nr_devices; i++) { 
buf : 		if (!ctx->device_frozen[i])
buf : 			continue;
buf : 		sdev = &bus->devices[i];
buf : 
buf : 		if (SSB_WARN_ON(!sdev->dev || !sdev->dev->driver))
if (SSB_WARN_ON(!sdev->dev || !sdev->dev->driver)) 
buf : 			continue;
buf : 		sdrv = drv_to_ssb_drv(sdev->dev->driver);
buf : 		if (SSB_WARN_ON(!sdrv || !sdrv->probe))
if (SSB_WARN_ON(!sdrv || !sdrv->probe)) 
buf : 			continue;
buf : 
buf : 		err = sdrv->probe(sdev, &sdev->id);
buf : 		if (err) {
if (err) { 
buf : 			ssb_err("Failed to thaw device %s\n",
buf : 				dev_name(sdev->dev));
buf : 			result = err;
buf : 		}
buf : 		ssb_device_put(sdev);
buf : 	}
buf : 
buf : 	return result;
buf : }
buf : #endif /* CONFIG_SSB_SPROM */
if /* CONFIG_SSB_SPROM */ 
buf : 
buf : static void ssb_device_shutdown(struct device *dev)
buf : {
buf : 	struct ssb_device *ssb_dev = dev_to_ssb_dev(dev);
buf : 	struct ssb_driver *ssb_drv;
buf : 
buf : 	if (!dev->driver)
if (!dev->driver) 
buf : 		return;
buf : 	ssb_drv = drv_to_ssb_drv(dev->driver);
buf : 	if (ssb_drv && ssb_drv->shutdown)
if (ssb_drv && ssb_drv->shutdown) 
buf : 		ssb_drv->shutdown(ssb_dev);
buf : }
buf : 
buf : static int ssb_device_remove(struct device *dev)
buf : {
buf : 	struct ssb_device *ssb_dev = dev_to_ssb_dev(dev);
buf : 	struct ssb_driver *ssb_drv = drv_to_ssb_drv(dev->driver);
buf : 
buf : 	if (ssb_drv && ssb_drv->remove)
if (ssb_drv && ssb_drv->remove) 
buf : 		ssb_drv->remove(ssb_dev);
buf : 	ssb_device_put(ssb_dev);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int ssb_device_probe(struct device *dev)
buf : {
buf : 	struct ssb_device *ssb_dev = dev_to_ssb_dev(dev);
buf : 	struct ssb_driver *ssb_drv = drv_to_ssb_drv(dev->driver);
buf : 	int err = 0;
buf : 
buf : 	ssb_device_get(ssb_dev);
buf : 	if (ssb_drv && ssb_drv->probe)
if (ssb_drv && ssb_drv->probe) 
buf : 		err = ssb_drv->probe(ssb_dev, &ssb_dev->id);
buf : 	if (err)
if (err) 
buf : 		ssb_device_put(ssb_dev);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int ssb_match_devid(const struct ssb_device_id *tabid,
buf : 			   const struct ssb_device_id *devid)
buf : {
buf : 	if ((tabid->vendor != devid->vendor) &&
if ((tabid->vendor != devid->vendor) && 
buf : 	    tabid->vendor != SSB_ANY_VENDOR)
buf : 		return 0;
buf : 	if ((tabid->coreid != devid->coreid) &&
if ((tabid->coreid != devid->coreid) && 
buf : 	    tabid->coreid != SSB_ANY_ID)
buf : 		return 0;
buf : 	if ((tabid->revision != devid->revision) &&
if ((tabid->revision != devid->revision) && 
buf : 	    tabid->revision != SSB_ANY_REV)
buf : 		return 0;
buf : 	return 1;
buf : }
buf : 
buf : static int ssb_bus_match(struct device *dev, struct device_driver *drv)
buf : {
buf : 	struct ssb_device *ssb_dev = dev_to_ssb_dev(dev);
buf : 	struct ssb_driver *ssb_drv = drv_to_ssb_drv(drv);
buf : 	const struct ssb_device_id *id;
buf : 
buf : 	for (id = ssb_drv->id_table;
for (id = ssb_drv->id_table; 
buf : 	     id->vendor || id->coreid || id->revision;
buf : 	     id++) {
buf : 		if (ssb_match_devid(id, &ssb_dev->id))
if (ssb_match_devid(id, &ssb_dev->id)) 
buf : 			return 1; /* found */
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int ssb_device_uevent(struct device *dev, struct kobj_uevent_env *env)
buf : {
buf : 	struct ssb_device *ssb_dev = dev_to_ssb_dev(dev);
buf : 
buf : 	if (!dev)
if (!dev) 
buf : 		return -ENODEV;
buf : 
buf : 	return add_uevent_var(env,
buf : 			     "MODALIAS=ssb:v%04Xid%04Xrev%02X",
buf : 			     ssb_dev->id.vendor, ssb_dev->id.coreid,
buf : 			     ssb_dev->id.revision);
buf : }
buf : 
buf : #define ssb_config_attr(attrib, field, format_string) \
format_string) \ 
buf : static ssize_t \
buf : attrib##_show(struct device *dev, struct device_attribute *attr, char *buf) \
buf : { \
buf : 	return sprintf(buf, format_string, dev_to_ssb_dev(dev)->field); \
format_string, dev_to_ssb_dev(dev)->field); \ 
buf : } \
buf : static DEVICE_ATTR_RO(attrib);
buf : 
buf : ssb_config_attr(core_num, core_index, "%u\n")
buf : ssb_config_attr(coreid, id.coreid, "0x%04x\n")
buf : ssb_config_attr(vendor, id.vendor, "0x%04x\n")
buf : ssb_config_attr(revision, id.revision, "%u\n")
buf : ssb_config_attr(irq, irq, "%u\n")
buf : static ssize_t
buf : name_show(struct device *dev, struct device_attribute *attr, char *buf)
buf : {
buf : 	return sprintf(buf, "%s\n",
buf : 		       ssb_core_name(dev_to_ssb_dev(dev)->id.coreid));
buf : }
buf : static DEVICE_ATTR_RO(name);
buf : 
buf : static struct attribute *ssb_device_attrs[] = {
buf : 	&dev_attr_name.attr,
buf : 	&dev_attr_core_num.attr,
buf : 	&dev_attr_coreid.attr,
buf : 	&dev_attr_vendor.attr,
buf : 	&dev_attr_revision.attr,
buf : 	&dev_attr_irq.attr,
buf : 	NULL,
buf : };
buf : ATTRIBUTE_GROUPS(ssb_device);
buf : 
buf : static struct bus_type ssb_bustype = {
buf : 	.name		= "ssb",
buf : 	.match		= ssb_bus_match,
buf : 	.probe		= ssb_device_probe,
buf : 	.remove		= ssb_device_remove,
buf : 	.shutdown	= ssb_device_shutdown,
buf : 	.suspend	= ssb_device_suspend,
buf : 	.resume		= ssb_device_resume,
buf : 	.uevent		= ssb_device_uevent,
buf : 	.dev_groups	= ssb_device_groups,
buf : };
buf : 
buf : static void ssb_buses_lock(void)
buf : {
buf : 	/* See the comment at the ssb_is_early_boot definition */
buf : 	if (!ssb_is_early_boot)
if (!ssb_is_early_boot) 
buf : 		mutex_lock(&buses_mutex);
buf : }
buf : 
buf : static void ssb_buses_unlock(void)
buf : {
buf : 	/* See the comment at the ssb_is_early_boot definition */
buf : 	if (!ssb_is_early_boot)
if (!ssb_is_early_boot) 
buf : 		mutex_unlock(&buses_mutex);
buf : }
buf : 
buf : static void ssb_devices_unregister(struct ssb_bus *bus)
buf : {
buf : 	struct ssb_device *sdev;
buf : 	int i;
buf : 
buf : 	for (i = bus->nr_devices - 1; i >= 0; i--) {
for (i = bus->nr_devices - 1; i >= 0; i--) { 
buf : 		sdev = &(bus->devices[i]);
buf : 		if (sdev->dev)
if (sdev->dev) 
buf : 			device_unregister(sdev->dev);
buf : 	}
buf : 
buf : #ifdef CONFIG_SSB_EMBEDDED
ifdef CONFIG_SSB_EMBEDDED 
buf : 	if (bus->bustype == SSB_BUSTYPE_SSB)
buf : 		platform_device_unregister(bus->watchdog);
form_device_unregister(bus->watchdog); 
buf : #endif
buf : }
buf : 
buf : void ssb_bus_unregister(struct ssb_bus *bus)
buf : {
buf : 	int err;
buf : 
buf : 	err = ssb_gpio_unregister(bus);
buf : 	if (err == -EBUSY)
if (err == -EBUSY) 
buf : 		ssb_dbg("Some GPIOs are still in use\n");
buf : 	else if (err)
if (err) 
buf : 		ssb_dbg("Can not unregister GPIO driver: %i\n", err);
buf : 
buf : 	ssb_buses_lock();
buf : 	ssb_devices_unregister(bus);
buf : 	list_del(&bus->list);
buf : 	ssb_buses_unlock();
buf : 
buf : 	ssb_pcmcia_exit(bus);
buf : 	ssb_pci_exit(bus);
buf : 	ssb_iounmap(bus);
buf : }
buf : EXPORT_SYMBOL(ssb_bus_unregister);
buf : 
buf : static void ssb_release_dev(struct device *dev)
buf : {
buf : 	struct __ssb_dev_wrapper *devwrap;
buf : 
buf : 	devwrap = container_of(dev, struct __ssb_dev_wrapper, dev);
buf : 	kfree(devwrap);
buf : }
buf : 
buf : static int ssb_devices_register(struct ssb_bus *bus)
buf : {
buf : 	struct ssb_device *sdev;
buf : 	struct device *dev;
buf : 	struct __ssb_dev_wrapper *devwrap;
buf : 	int i, err = 0;
buf : 	int dev_idx = 0;
buf : 
buf : 	for (i = 0; i < bus->nr_devices; i++) {
for (i = 0; i < bus->nr_devices; i++) { 
buf : 		sdev = &(bus->devices[i]);
buf : 
buf : 		/* We don't register SSB-system devices to the kernel,
buf : 		 * as the drivers for them are built into SSB. */
for them are built into SSB. */ 
buf : 		switch (sdev->id.coreid) {
buf : 		case SSB_DEV_CHIPCOMMON:
buf : 		case SSB_DEV_PCI:
buf : 		case SSB_DEV_PCIE:
buf : 		case SSB_DEV_PCMCIA:
buf : 		case SSB_DEV_MIPS:
buf : 		case SSB_DEV_MIPS_3302:
buf : 		case SSB_DEV_EXTIF:
buf : 			continue;
buf : 		}
buf : 
buf : 		devwrap = kzalloc(sizeof(*devwrap), GFP_KERNEL);
buf : 		if (!devwrap) {
if (!devwrap) { 
buf : 			ssb_err("Could not allocate device\n");
buf : 			err = -ENOMEM;
buf : 			goto error;
buf : 		}
buf : 		dev = &devwrap->dev;
buf : 		devwrap->sdev = sdev;
buf : 
buf : 		dev->release = ssb_release_dev;
buf : 		dev->bus = &ssb_bustype;
buf : 		dev_set_name(dev, "ssb%u:%d", bus->busnumber, dev_idx);
buf : 
buf : 		switch (bus->bustype) {
buf : 		case SSB_BUSTYPE_PCI:
buf : #ifdef CONFIG_SSB_PCIHOST
ifdef CONFIG_SSB_PCIHOST 
buf : 			sdev->irq = bus->host_pci->irq;
buf : 			dev->parent = &bus->host_pci->dev;
buf : 			sdev->dma_dev = dev->parent;
buf : #endif
if 
buf : 			break;
buf : 		case SSB_BUSTYPE_PCMCIA:
buf : #ifdef CONFIG_SSB_PCMCIAHOST
ifdef CONFIG_SSB_PCMCIAHOST 
buf : 			sdev->irq = bus->host_pcmcia->irq;
buf : 			dev->parent = &bus->host_pcmcia->dev;
buf : #endif
if 
buf : 			break;
buf : 		case SSB_BUSTYPE_SDIO:
buf : #ifdef CONFIG_SSB_SDIOHOST
ifdef CONFIG_SSB_SDIOHOST 
buf : 			dev->parent = &bus->host_sdio->dev;
buf : #endif
if 
buf : 			break;
buf : 		case SSB_BUSTYPE_SSB:
buf : 			dev->dma_mask = &dev->coherent_dma_mask;
buf : 			sdev->dma_dev = dev;
buf : 			break;
buf : 		}
buf : 
buf : 		sdev->dev = dev;
buf : 		err = device_register(dev);
buf : 		if (err) {
if (err) { 
buf : 			ssb_err("Could not register %s\n", dev_name(dev));
buf : 			/* Set dev to NULL to not unregister
buf : 			 * dev on error unwinding. */
buf : 			sdev->dev = NULL;
buf : 			kfree(devwrap);
buf : 			goto error;
buf : 		}
buf : 		dev_idx++;
buf : 	}
buf : 
buf : #ifdef CONFIG_SSB_DRIVER_MIPS
ifdef CONFIG_SSB_DRIVER_MIPS 
buf : 	if (bus->mipscore.pflash.present) {
buf : 		err = platform_device_register(&ssb_pflash_dev);
form_device_register(&ssb_pflash_dev); 
buf : 		if (err)
buf : 			pr_err("Error registering parallel flash\n");
buf : 	}
buf : #endif
if 
buf : 
buf : #ifdef CONFIG_SSB_SFLASH
buf : 	if (bus->mipscore.sflash.present) {
if (bus->mipscore.sflash.present) { 
buf : 		err = platform_device_register(&ssb_sflash_dev);
form_device_register(&ssb_sflash_dev); 
buf : 		if (err)
buf : 			pr_err("Error registering serial flash\n");
buf : 	}
buf : #endif
if 
buf : 
buf : 	return 0;
buf : error:
buf : 	/* Unwind the already registered devices. */
buf : 	ssb_devices_unregister(bus);
buf : 	return err;
buf : }
buf : 
buf : /* Needs ssb_buses_lock() */
buf : static int ssb_attach_queued_buses(void)
buf : {
buf : 	struct ssb_bus *bus, *n;
buf : 	int err = 0;
buf : 	int drop_them_all = 0;
buf : 
buf : 	list_for_each_entry_safe(bus, n, &attach_queue, list) {
for_each_entry_safe(bus, n, &attach_queue, list) { 
buf : 		if (drop_them_all) {
buf : 			list_del(&bus->list);
buf : 			continue;
buf : 		}
buf : 		/* Can't init the PCIcore in ssb_bus_register(), as that
buf : 		 * is too early in boot for embedded systems
for embedded systems 
buf : 		 * (no udelay() available). So do it here in attach stage.
buf : 		 */
buf : 		err = ssb_bus_powerup(bus, 0);
buf : 		if (err)
if (err) 
buf : 			goto error;
buf : 		ssb_pcicore_init(&bus->pcicore);
buf : 		if (bus->bustype == SSB_BUSTYPE_SSB)
if (bus->bustype == SSB_BUSTYPE_SSB) 
buf : 			ssb_watchdog_register(bus);
buf : 
buf : 		err = ssb_gpio_init(bus);
buf : 		if (err == -ENOTSUPP)
if (err == -ENOTSUPP) 
buf : 			ssb_dbg("GPIO driver not activated\n");
buf : 		else if (err)
if (err) 
buf : 			ssb_dbg("Error registering GPIO driver: %i\n", err);
buf : 
buf : 		ssb_bus_may_powerdown(bus);
buf : 
buf : 		err = ssb_devices_register(bus);
buf : error:
buf : 		if (err) {
if (err) { 
buf : 			drop_them_all = 1;
buf : 			list_del(&bus->list);
buf : 			continue;
buf : 		}
buf : 		list_move_tail(&bus->list, &buses);
buf : 	}
buf : 
buf : 	return err;
buf : }
buf : 
buf : static u8 ssb_ssb_read8(struct ssb_device *dev, u16 offset)
buf : {
buf : 	struct ssb_bus *bus = dev->bus;
buf : 
buf : 	offset += dev->core_index * SSB_CORE_SIZE;
buf : 	return readb(bus->mmio + offset);
buf : }
buf : 
buf : static u16 ssb_ssb_read16(struct ssb_device *dev, u16 offset)
buf : {
buf : 	struct ssb_bus *bus = dev->bus;
buf : 
buf : 	offset += dev->core_index * SSB_CORE_SIZE;
buf : 	return readw(bus->mmio + offset);
buf : }
buf : 
buf : static u32 ssb_ssb_read32(struct ssb_device *dev, u16 offset)
buf : {
buf : 	struct ssb_bus *bus = dev->bus;
buf : 
buf : 	offset += dev->core_index * SSB_CORE_SIZE;
buf : 	return readl(bus->mmio + offset);
buf : }
buf : 
buf : #ifdef CONFIG_SSB_BLOCKIO
ifdef CONFIG_SSB_BLOCKIO 
buf : static void ssb_ssb_block_read(struct ssb_device *dev, void *buffer,
buf : 			       size_t count, u16 offset, u8 reg_width)
buf : {
buf : 	struct ssb_bus *bus = dev->bus;
buf : 	void __iomem *addr;
buf : 
buf : 	offset += dev->core_index * SSB_CORE_SIZE;
buf : 	addr = bus->mmio + offset;
buf : 
buf : 	switch (reg_width) {
buf : 	case sizeof(u8): {
buf : 		u8 *buf = buffer;
buf : 
buf : 		while (count) {
while (count) { 
buf : 			*buf = __raw_readb(addr);
buf : 			buf++;
buf : 			count--;
buf : 		}
buf : 		break;
buf : 	}
buf : 	case sizeof(u16): {
buf : 		__le16 *buf = buffer;
buf : 
buf : 		SSB_WARN_ON(count & 1);
buf : 		while (count) {
while (count) { 
buf : 			*buf = (__force __le16)__raw_readw(addr);
buf : 			buf++;
buf : 			count -= 2;
buf : 		}
buf : 		break;
buf : 	}
buf : 	case sizeof(u32): {
buf : 		__le32 *buf = buffer;
buf : 
buf : 		SSB_WARN_ON(count & 3);
buf : 		while (count) {
while (count) { 
buf : 			*buf = (__force __le32)__raw_readl(addr);
buf : 			buf++;
buf : 			count -= 4;
buf : 		}
buf : 		break;
buf : 	}
buf : 	default:
buf : 		SSB_WARN_ON(1);
buf : 	}
buf : }
buf : #endif /* CONFIG_SSB_BLOCKIO */
if /* CONFIG_SSB_BLOCKIO */ 
buf : 
buf : static void ssb_ssb_write8(struct ssb_device *dev, u16 offset, u8 value)
buf : {
buf : 	struct ssb_bus *bus = dev->bus;
buf : 
buf : 	offset += dev->core_index * SSB_CORE_SIZE;
buf : 	writeb(value, bus->mmio + offset);
buf : }
buf : 
buf : static void ssb_ssb_write16(struct ssb_device *dev, u16 offset, u16 value)
buf : {
buf : 	struct ssb_bus *bus = dev->bus;
buf : 
buf : 	offset += dev->core_index * SSB_CORE_SIZE;
buf : 	writew(value, bus->mmio + offset);
buf : }
buf : 
buf : static void ssb_ssb_write32(struct ssb_device *dev, u16 offset, u32 value)
buf : {
buf : 	struct ssb_bus *bus = dev->bus;
buf : 
buf : 	offset += dev->core_index * SSB_CORE_SIZE;
buf : 	writel(value, bus->mmio + offset);
buf : }
buf : 
buf : #ifdef CONFIG_SSB_BLOCKIO
ifdef CONFIG_SSB_BLOCKIO 
buf : static void ssb_ssb_block_write(struct ssb_device *dev, const void *buffer,
buf : 				size_t count, u16 offset, u8 reg_width)
buf : {
buf : 	struct ssb_bus *bus = dev->bus;
buf : 	void __iomem *addr;
buf : 
buf : 	offset += dev->core_index * SSB_CORE_SIZE;
buf : 	addr = bus->mmio + offset;
buf : 
buf : 	switch (reg_width) {
buf : 	case sizeof(u8): {
buf : 		const u8 *buf = buffer;
buf : 
buf : 		while (count) {
while (count) { 
buf : 			__raw_writeb(*buf, addr);
buf : 			buf++;
buf : 			count--;
buf : 		}
buf : 		break;
buf : 	}
buf : 	case sizeof(u16): {
buf : 		const __le16 *buf = buffer;
buf : 
buf : 		SSB_WARN_ON(count & 1);
buf : 		while (count) {
while (count) { 
buf : 			__raw_writew((__force u16)(*buf), addr);
buf : 			buf++;
buf : 			count -= 2;
buf : 		}
buf : 		break;
buf : 	}
buf : 	case sizeof(u32): {
buf : 		const __le32 *buf = buffer;
buf : 
buf : 		SSB_WARN_ON(count & 3);
buf : 		while (count) {
while (count) { 
buf : 			__raw_writel((__force u32)(*buf), addr);
buf : 			buf++;
buf : 			count -= 4;
buf : 		}
buf : 		break;
buf : 	}
buf : 	default:
buf : 		SSB_WARN_ON(1);
buf : 	}
buf : }
buf : #endif /* CONFIG_SSB_BLOCKIO */
if /* CONFIG_SSB_BLOCKIO */ 
buf : 
buf : /* Ops for the plain SSB bus without a host-device (no PCI or PCMCIA). */
for the plain SSB bus without a host-device (no PCI or PCMCIA). */ 
buf : static const struct ssb_bus_ops ssb_ssb_ops = {
buf : 	.read8		= ssb_ssb_read8,
buf : 	.read16		= ssb_ssb_read16,
buf : 	.read32		= ssb_ssb_read32,
buf : 	.write8		= ssb_ssb_write8,
buf : 	.write16	= ssb_ssb_write16,
buf : 	.write32	= ssb_ssb_write32,
buf : #ifdef CONFIG_SSB_BLOCKIO
ifdef CONFIG_SSB_BLOCKIO 
buf : 	.block_read	= ssb_ssb_block_read,
buf : 	.block_write	= ssb_ssb_block_write,
buf : #endif
if 
buf : };
buf : 
buf : static int ssb_fetch_invariants(struct ssb_bus *bus,
buf : 				ssb_invariants_func_t get_invariants)
buf : {
buf : 	struct ssb_init_invariants iv;
buf : 	int err;
buf : 
buf : 	memset(&iv, 0, sizeof(iv));
buf : 	err = get_invariants(bus, &iv);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 	memcpy(&bus->boardinfo, &iv.boardinfo, sizeof(iv.boardinfo));
buf : 	memcpy(&bus->sprom, &iv.sprom, sizeof(iv.sprom));
buf : 	bus->has_cardbus_slot = iv.has_cardbus_slot;
buf : out:
buf : 	return err;
buf : }
buf : 
buf : static int ssb_bus_register(struct ssb_bus *bus,
buf : 			    ssb_invariants_func_t get_invariants,
buf : 			    unsigned long baseaddr)
buf : {
buf : 	int err;
buf : 
buf : 	spin_lock_init(&bus->bar_lock);
buf : 	INIT_LIST_HEAD(&bus->list);
buf : #ifdef CONFIG_SSB_EMBEDDED
ifdef CONFIG_SSB_EMBEDDED 
buf : 	spin_lock_init(&bus->gpio_lock);
buf : #endif
if 
buf : 
buf : 	/* Powerup the bus */
buf : 	err = ssb_pci_xtal(bus, SSB_GPIO_XTAL | SSB_GPIO_PLL, 1);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	/* Init SDIO-host device (if any), before the scan */
if any), before the scan */ 
buf : 	err = ssb_sdio_init(bus);
buf : 	if (err)
if (err) 
buf : 		goto err_disable_xtal;
buf : 
buf : 	ssb_buses_lock();
buf : 	bus->busnumber = next_busnumber;
buf : 	/* Scan for devices (cores) */
for devices (cores) */ 
buf : 	err = ssb_bus_scan(bus, baseaddr);
buf : 	if (err)
if (err) 
buf : 		goto err_sdio_exit;
buf : 
buf : 	/* Init PCI-host device (if any) */
if any) */ 
buf : 	err = ssb_pci_init(bus);
buf : 	if (err)
if (err) 
buf : 		goto err_unmap;
buf : 	/* Init PCMCIA-host device (if any) */
if any) */ 
buf : 	err = ssb_pcmcia_init(bus);
buf : 	if (err)
if (err) 
buf : 		goto err_pci_exit;
buf : 
buf : 	/* Initialize basic system devices (if available) */
if available) */ 
buf : 	err = ssb_bus_powerup(bus, 0);
buf : 	if (err)
if (err) 
buf : 		goto err_pcmcia_exit;
buf : 	ssb_chipcommon_init(&bus->chipco);
buf : 	ssb_extif_init(&bus->extif);
if_init(&bus->extif); 
buf : 	ssb_mipscore_init(&bus->mipscore);
buf : 	err = ssb_fetch_invariants(bus, get_invariants);
buf : 	if (err) {
if (err) { 
buf : 		ssb_bus_may_powerdown(bus);
buf : 		goto err_pcmcia_exit;
buf : 	}
buf : 	ssb_bus_may_powerdown(bus);
buf : 
buf : 	/* Queue it for attach.
for attach. 
buf : 	 * See the comment at the ssb_is_early_boot definition. */
buf : 	list_add_tail(&bus->list, &attach_queue);
buf : 	if (!ssb_is_early_boot) {
if (!ssb_is_early_boot) { 
buf : 		/* This is not early boot, so we must attach the bus now */
buf : 		err = ssb_attach_queued_buses();
buf : 		if (err)
if (err) 
buf : 			goto err_dequeue;
buf : 	}
buf : 	next_busnumber++;
buf : 	ssb_buses_unlock();
buf : 
buf : out:
buf : 	return err;
buf : 
buf : err_dequeue:
buf : 	list_del(&bus->list);
buf : err_pcmcia_exit:
buf : 	ssb_pcmcia_exit(bus);
buf : err_pci_exit:
buf : 	ssb_pci_exit(bus);
buf : err_unmap:
buf : 	ssb_iounmap(bus);
buf : err_sdio_exit:
buf : 	ssb_sdio_exit(bus);
buf : err_disable_xtal:
buf : 	ssb_buses_unlock();
buf : 	ssb_pci_xtal(bus, SSB_GPIO_XTAL | SSB_GPIO_PLL, 0);
buf : 	return err;
buf : }
buf : 
buf : #ifdef CONFIG_SSB_PCIHOST
ifdef CONFIG_SSB_PCIHOST 
buf : int ssb_bus_pcibus_register(struct ssb_bus *bus, struct pci_dev *host_pci)
buf : {
buf : 	int err;
buf : 
buf : 	bus->bustype = SSB_BUSTYPE_PCI;
buf : 	bus->host_pci = host_pci;
buf : 	bus->ops = &ssb_pci_ops;
buf : 
buf : 	err = ssb_bus_register(bus, ssb_pci_get_invariants, 0);
buf : 	if (!err) {
if (!err) { 
buf : 		ssb_info("Sonics Silicon Backplane found on PCI device %s\n",
buf : 			 dev_name(&host_pci->dev));
buf : 	} else {
buf : 		ssb_err("Failed to register PCI version of SSB with error %d\n",
buf : 			err);
buf : 	}
buf : 
buf : 	return err;
buf : }
buf : EXPORT_SYMBOL(ssb_bus_pcibus_register);
buf : #endif /* CONFIG_SSB_PCIHOST */
if /* CONFIG_SSB_PCIHOST */ 
buf : 
buf : #ifdef CONFIG_SSB_PCMCIAHOST
buf : int ssb_bus_pcmciabus_register(struct ssb_bus *bus,
buf : 			       struct pcmcia_device *pcmcia_dev,
buf : 			       unsigned long baseaddr)
buf : {
buf : 	int err;
buf : 
buf : 	bus->bustype = SSB_BUSTYPE_PCMCIA;
buf : 	bus->host_pcmcia = pcmcia_dev;
buf : 	bus->ops = &ssb_pcmcia_ops;
buf : 
buf : 	err = ssb_bus_register(bus, ssb_pcmcia_get_invariants, baseaddr);
buf : 	if (!err) {
if (!err) { 
buf : 		ssb_info("Sonics Silicon Backplane found on PCMCIA device %s\n",
buf : 			 pcmcia_dev->devname);
buf : 	}
buf : 
buf : 	return err;
buf : }
buf : EXPORT_SYMBOL(ssb_bus_pcmciabus_register);
buf : #endif /* CONFIG_SSB_PCMCIAHOST */
if /* CONFIG_SSB_PCMCIAHOST */ 
buf : 
buf : #ifdef CONFIG_SSB_SDIOHOST
buf : int ssb_bus_sdiobus_register(struct ssb_bus *bus, struct sdio_func *func,
buf : 			     unsigned int quirks)
buf : {
buf : 	int err;
buf : 
buf : 	bus->bustype = SSB_BUSTYPE_SDIO;
buf : 	bus->host_sdio = func;
buf : 	bus->ops = &ssb_sdio_ops;
buf : 	bus->quirks = quirks;
buf : 
buf : 	err = ssb_bus_register(bus, ssb_sdio_get_invariants, ~0);
buf : 	if (!err) {
if (!err) { 
buf : 		ssb_info("Sonics Silicon Backplane found on SDIO device %s\n",
buf : 			 sdio_func_id(func));
buf : 	}
buf : 
buf : 	return err;
buf : }
buf : EXPORT_SYMBOL(ssb_bus_sdiobus_register);
buf : #endif /* CONFIG_SSB_PCMCIAHOST */
if /* CONFIG_SSB_PCMCIAHOST */ 
buf : 
buf : int ssb_bus_ssbbus_register(struct ssb_bus *bus, unsigned long baseaddr,
buf : 			    ssb_invariants_func_t get_invariants)
buf : {
buf : 	int err;
buf : 
buf : 	bus->bustype = SSB_BUSTYPE_SSB;
buf : 	bus->ops = &ssb_ssb_ops;
buf : 
buf : 	err = ssb_bus_register(bus, get_invariants, baseaddr);
buf : 	if (!err) {
if (!err) { 
buf : 		ssb_info("Sonics Silicon Backplane found at address 0x%08lX\n",
buf : 			 baseaddr);
buf : 	}
buf : 
buf : 	return err;
buf : }
buf : 
buf : int __ssb_driver_register(struct ssb_driver *drv, struct module *owner)
buf : {
buf : 	drv->drv.name = drv->name;
buf : 	drv->drv.bus = &ssb_bustype;
buf : 	drv->drv.owner = owner;
buf : 
buf : 	return driver_register(&drv->drv);
buf : }
buf : EXPORT_SYMBOL(__ssb_driver_register);
buf : 
buf : void ssb_driver_unregister(struct ssb_driver *drv)
buf : {
buf : 	driver_unregister(&drv->drv);
buf : }
buf : EXPORT_SYMBOL(ssb_driver_unregister);
buf : 
buf : void ssb_set_devtypedata(struct ssb_device *dev, void *data)
buf : {
buf : 	struct ssb_bus *bus = dev->bus;
buf : 	struct ssb_device *ent;
buf : 	int i;
buf : 
buf : 	for (i = 0; i < bus->nr_devices; i++) {
for (i = 0; i < bus->nr_devices; i++) { 
buf : 		ent = &(bus->devices[i]);
buf : 		if (ent->id.vendor != dev->id.vendor)
if (ent->id.vendor != dev->id.vendor) 
buf : 			continue;
buf : 		if (ent->id.coreid != dev->id.coreid)
if (ent->id.coreid != dev->id.coreid) 
buf : 			continue;
buf : 
buf : 		ent->devtypedata = data;
buf : 	}
buf : }
buf : EXPORT_SYMBOL(ssb_set_devtypedata);
buf : 
buf : static u32 clkfactor_f6_resolve(u32 v)
buf : {
buf : 	/* map the magic values */
buf : 	switch (v) {
buf : 	case SSB_CHIPCO_CLK_F6_2:
buf : 		return 2;
buf : 	case SSB_CHIPCO_CLK_F6_3:
buf : 		return 3;
buf : 	case SSB_CHIPCO_CLK_F6_4:
buf : 		return 4;
buf : 	case SSB_CHIPCO_CLK_F6_5:
buf : 		return 5;
buf : 	case SSB_CHIPCO_CLK_F6_6:
buf : 		return 6;
buf : 	case SSB_CHIPCO_CLK_F6_7:
buf : 		return 7;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : /* Calculate the speed the backplane would run at a given set of clockcontrol values */
buf : u32 ssb_calc_clock_rate(u32 plltype, u32 n, u32 m)
buf : {
buf : 	u32 n1, n2, clock, m1, m2, m3, mc;
buf : 
buf : 	n1 = (n & SSB_CHIPCO_CLK_N1);
buf : 	n2 = ((n & SSB_CHIPCO_CLK_N2) >> SSB_CHIPCO_CLK_N2_SHIFT);
buf : 
buf : 	switch (plltype) {
buf : 	case SSB_PLLTYPE_6: /* 100/200 or 120/240 only */
buf : 		if (m & SSB_CHIPCO_CLK_T6_MMASK)
if (m & SSB_CHIPCO_CLK_T6_MMASK) 
buf : 			return SSB_CHIPCO_CLK_T6_M1;
buf : 		return SSB_CHIPCO_CLK_T6_M0;
buf : 	case SSB_PLLTYPE_1: /* 48Mhz base, 3 dividers */
buf : 	case SSB_PLLTYPE_3: /* 25Mhz, 2 dividers */
buf : 	case SSB_PLLTYPE_4: /* 48Mhz, 4 dividers */
buf : 	case SSB_PLLTYPE_7: /* 25Mhz, 4 dividers */
buf : 		n1 = clkfactor_f6_resolve(n1);
buf : 		n2 += SSB_CHIPCO_CLK_F5_BIAS;
buf : 		break;
buf : 	case SSB_PLLTYPE_2: /* 48Mhz, 4 dividers */
buf : 		n1 += SSB_CHIPCO_CLK_T2_BIAS;
buf : 		n2 += SSB_CHIPCO_CLK_T2_BIAS;
buf : 		SSB_WARN_ON(!((n1 >= 2) && (n1 <= 7)));
buf : 		SSB_WARN_ON(!((n2 >= 5) && (n2 <= 23)));
buf : 		break;
buf : 	case SSB_PLLTYPE_5: /* 25Mhz, 4 dividers */
buf : 		return 100000000;
buf : 	default:
buf : 		SSB_WARN_ON(1);
buf : 	}
buf : 
buf : 	switch (plltype) {
buf : 	case SSB_PLLTYPE_3: /* 25Mhz, 2 dividers */
buf : 	case SSB_PLLTYPE_7: /* 25Mhz, 4 dividers */
buf : 		clock = SSB_CHIPCO_CLK_BASE2 * n1 * n2;
buf : 		break;
buf : 	default:
buf : 		clock = SSB_CHIPCO_CLK_BASE1 * n1 * n2;
buf : 	}
buf : 	if (!clock)
if (!clock) 
buf : 		return 0;
buf : 
buf : 	m1 = (m & SSB_CHIPCO_CLK_M1);
buf : 	m2 = ((m & SSB_CHIPCO_CLK_M2) >> SSB_CHIPCO_CLK_M2_SHIFT);
buf : 	m3 = ((m & SSB_CHIPCO_CLK_M3) >> SSB_CHIPCO_CLK_M3_SHIFT);
buf : 	mc = ((m & SSB_CHIPCO_CLK_MC) >> SSB_CHIPCO_CLK_MC_SHIFT);
buf : 
buf : 	switch (plltype) {
buf : 	case SSB_PLLTYPE_1: /* 48Mhz base, 3 dividers */
buf : 	case SSB_PLLTYPE_3: /* 25Mhz, 2 dividers */
buf : 	case SSB_PLLTYPE_4: /* 48Mhz, 4 dividers */
buf : 	case SSB_PLLTYPE_7: /* 25Mhz, 4 dividers */
buf : 		m1 = clkfactor_f6_resolve(m1);
buf : 		if ((plltype == SSB_PLLTYPE_1) ||
if ((plltype == SSB_PLLTYPE_1) || 
buf : 		    (plltype == SSB_PLLTYPE_3))
buf : 			m2 += SSB_CHIPCO_CLK_F5_BIAS;
buf : 		else
buf : 			m2 = clkfactor_f6_resolve(m2);
buf : 		m3 = clkfactor_f6_resolve(m3);
buf : 
buf : 		switch (mc) {
buf : 		case SSB_CHIPCO_CLK_MC_BYPASS:
buf : 			return clock;
buf : 		case SSB_CHIPCO_CLK_MC_M1:
buf : 			return (clock / m1);
buf : 		case SSB_CHIPCO_CLK_MC_M1M2:
buf : 			return (clock / (m1 * m2));
buf : 		case SSB_CHIPCO_CLK_MC_M1M2M3:
buf : 			return (clock / (m1 * m2 * m3));
buf : 		case SSB_CHIPCO_CLK_MC_M1M3:
buf : 			return (clock / (m1 * m3));
buf : 		}
buf : 		return 0;
buf : 	case SSB_PLLTYPE_2:
buf : 		m1 += SSB_CHIPCO_CLK_T2_BIAS;
buf : 		m2 += SSB_CHIPCO_CLK_T2M2_BIAS;
buf : 		m3 += SSB_CHIPCO_CLK_T2_BIAS;
buf : 		SSB_WARN_ON(!((m1 >= 2) && (m1 <= 7)));
buf : 		SSB_WARN_ON(!((m2 >= 3) && (m2 <= 10)));
buf : 		SSB_WARN_ON(!((m3 >= 2) && (m3 <= 7)));
buf : 
buf : 		if (!(mc & SSB_CHIPCO_CLK_T2MC_M1BYP))
if (!(mc & SSB_CHIPCO_CLK_T2MC_M1BYP)) 
buf : 			clock /= m1;
buf : 		if (!(mc & SSB_CHIPCO_CLK_T2MC_M2BYP))
if (!(mc & SSB_CHIPCO_CLK_T2MC_M2BYP)) 
buf : 			clock /= m2;
buf : 		if (!(mc & SSB_CHIPCO_CLK_T2MC_M3BYP))
if (!(mc & SSB_CHIPCO_CLK_T2MC_M3BYP)) 
buf : 			clock /= m3;
buf : 		return clock;
buf : 	default:
buf : 		SSB_WARN_ON(1);
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : /* Get the current speed the backplane is running at */
buf : u32 ssb_clockspeed(struct ssb_bus *bus)
buf : {
buf : 	u32 rate;
buf : 	u32 plltype;
buf : 	u32 clkctl_n, clkctl_m;
buf : 
buf : 	if (bus->chipco.capabilities & SSB_CHIPCO_CAP_PMU)
if (bus->chipco.capabilities & SSB_CHIPCO_CAP_PMU) 
buf : 		return ssb_pmu_get_controlclock(&bus->chipco);
buf : 
buf : 	if (ssb_extif_available(&bus->extif))
if (ssb_extif_available(&bus->extif)) 
buf : 		ssb_extif_get_clockcontrol(&bus->extif, &plltype,
buf : 					   &clkctl_n, &clkctl_m);
buf : 	else if (bus->chipco.dev)
if (bus->chipco.dev) 
buf : 		ssb_chipco_get_clockcontrol(&bus->chipco, &plltype,
buf : 					    &clkctl_n, &clkctl_m);
buf : 	else
buf : 		return 0;
buf : 
buf : 	if (bus->chip_id == 0x5365) {
if (bus->chip_id == 0x5365) { 
buf : 		rate = 100000000;
buf : 	} else {
buf : 		rate = ssb_calc_clock_rate(plltype, clkctl_n, clkctl_m);
buf : 		if (plltype == SSB_PLLTYPE_3) /* 25Mhz, 2 dividers */
if (plltype == SSB_PLLTYPE_3) /* 25Mhz, 2 dividers */ 
buf : 			rate /= 2;
buf : 	}
buf : 
buf : 	return rate;
buf : }
buf : EXPORT_SYMBOL(ssb_clockspeed);
buf : 
buf : static u32 ssb_tmslow_reject_bitmask(struct ssb_device *dev)
buf : {
buf : 	u32 rev = ssb_read32(dev, SSB_IDLOW) & SSB_IDLOW_SSBREV;
buf : 
buf : 	/* The REJECT bit seems to be different for Backplane rev 2.3 */
ifferent for Backplane rev 2.3 */ 
buf : 	switch (rev) {
buf : 	case SSB_IDLOW_SSBREV_22:
buf : 	case SSB_IDLOW_SSBREV_24:
buf : 	case SSB_IDLOW_SSBREV_26:
buf : 		return SSB_TMSLOW_REJECT;
buf : 	case SSB_IDLOW_SSBREV_23:
buf : 		return SSB_TMSLOW_REJECT_23;
buf : 	case SSB_IDLOW_SSBREV_25:     /* TODO - find the proper REJECT bit */
buf : 	case SSB_IDLOW_SSBREV_27:     /* same here */
buf : 		return SSB_TMSLOW_REJECT;	/* this is a guess */
buf : 	default:
buf : 		WARN(1, KERN_INFO "ssb: Backplane Revision 0x%.8X\n", rev);
buf : 	}
buf : 	return (SSB_TMSLOW_REJECT | SSB_TMSLOW_REJECT_23);
buf : }
buf : 
buf : int ssb_device_is_enabled(struct ssb_device *dev)
buf : {
buf : 	u32 val;
buf : 	u32 reject;
buf : 
buf : 	reject = ssb_tmslow_reject_bitmask(dev);
buf : 	val = ssb_read32(dev, SSB_TMSLOW);
buf : 	val &= SSB_TMSLOW_CLOCK | SSB_TMSLOW_RESET | reject;
buf : 
buf : 	return (val == SSB_TMSLOW_CLOCK);
buf : }
buf : EXPORT_SYMBOL(ssb_device_is_enabled);
buf : 
buf : static void ssb_flush_tmslow(struct ssb_device *dev)
buf : {
buf : 	/* Make _really_ sure the device has finished the TMSLOW
buf : 	 * register write transaction, as we risk running into
buf : 	 * a machine check exception otherwise.
buf : 	 * Do this by reading the register back to commit the
buf : 	 * PCI write and delay an additional usec for the device
for the device 
buf : 	 * to react to the change. */
buf : 	ssb_read32(dev, SSB_TMSLOW);
buf : 	udelay(1);
buf : }
buf : 
buf : void ssb_device_enable(struct ssb_device *dev, u32 core_specific_flags)
ific_flags) 
buf : {
buf : 	u32 val;
buf : 
buf : 	ssb_device_disable(dev, core_specific_flags);
ific_flags); 
buf : 	ssb_write32(dev, SSB_TMSLOW,
buf : 		    SSB_TMSLOW_RESET | SSB_TMSLOW_CLOCK |
buf : 		    SSB_TMSLOW_FGC | core_specific_flags);
ific_flags); 
buf : 	ssb_flush_tmslow(dev);
buf : 
buf : 	/* Clear SERR if set. This is a hw bug workaround. */
if set. This is a hw bug workaround. */ 
buf : 	if (ssb_read32(dev, SSB_TMSHIGH) & SSB_TMSHIGH_SERR)
buf : 		ssb_write32(dev, SSB_TMSHIGH, 0);
buf : 
buf : 	val = ssb_read32(dev, SSB_IMSTATE);
buf : 	if (val & (SSB_IMSTATE_IBE | SSB_IMSTATE_TO)) {
if (val & (SSB_IMSTATE_IBE | SSB_IMSTATE_TO)) { 
buf : 		val &= ~(SSB_IMSTATE_IBE | SSB_IMSTATE_TO);
buf : 		ssb_write32(dev, SSB_IMSTATE, val);
buf : 	}
buf : 
buf : 	ssb_write32(dev, SSB_TMSLOW,
buf : 		    SSB_TMSLOW_CLOCK | SSB_TMSLOW_FGC |
buf : 		    core_specific_flags);
ific_flags); 
buf : 	ssb_flush_tmslow(dev);
buf : 
buf : 	ssb_write32(dev, SSB_TMSLOW, SSB_TMSLOW_CLOCK |
buf : 		    core_specific_flags);
ific_flags); 
buf : 	ssb_flush_tmslow(dev);
buf : }
buf : EXPORT_SYMBOL(ssb_device_enable);
buf : 
buf : /* Wait for bitmask in a register to get set or cleared.
for bitmask in a register to get set or cleared. 
buf :  * timeout is in units of ten-microseconds */
buf : static int ssb_wait_bits(struct ssb_device *dev, u16 reg, u32 bitmask,
buf : 			 int timeout, int set)
buf : {
buf : 	int i;
buf : 	u32 val;
buf : 
buf : 	for (i = 0; i < timeout; i++) {
for (i = 0; i < timeout; i++) { 
buf : 		val = ssb_read32(dev, reg);
buf : 		if (set) {
if (set) { 
buf : 			if ((val & bitmask) == bitmask)
buf : 				return 0;
buf : 		} else {
buf : 			if (!(val & bitmask))
if (!(val & bitmask)) 
buf : 				return 0;
buf : 		}
buf : 		udelay(10);
buf : 	}
buf : 	printk(KERN_ERR PFX "Timeout waiting for bitmask %08X on "
for bitmask %08X on " 
buf : 			    "register %04X to %s.\n",
buf : 	       bitmask, reg, (set ? "set" : "clear"));
buf : 
buf : 	return -ETIMEDOUT;
buf : }
buf : 
buf : void ssb_device_disable(struct ssb_device *dev, u32 core_specific_flags)
ific_flags) 
buf : {
buf : 	u32 reject, val;
buf : 
buf : 	if (ssb_read32(dev, SSB_TMSLOW) & SSB_TMSLOW_RESET)
if (ssb_read32(dev, SSB_TMSLOW) & SSB_TMSLOW_RESET) 
buf : 		return;
buf : 
buf : 	reject = ssb_tmslow_reject_bitmask(dev);
buf : 
buf : 	if (ssb_read32(dev, SSB_TMSLOW) & SSB_TMSLOW_CLOCK) {
if (ssb_read32(dev, SSB_TMSLOW) & SSB_TMSLOW_CLOCK) { 
buf : 		ssb_write32(dev, SSB_TMSLOW, reject | SSB_TMSLOW_CLOCK);
buf : 		ssb_wait_bits(dev, SSB_TMSLOW, reject, 1000, 1);
buf : 		ssb_wait_bits(dev, SSB_TMSHIGH, SSB_TMSHIGH_BUSY, 1000, 0);
buf : 
buf : 		if (ssb_read32(dev, SSB_IDLOW) & SSB_IDLOW_INITIATOR) {
if (ssb_read32(dev, SSB_IDLOW) & SSB_IDLOW_INITIATOR) { 
buf : 			val = ssb_read32(dev, SSB_IMSTATE);
buf : 			val |= SSB_IMSTATE_REJECT;
buf : 			ssb_write32(dev, SSB_IMSTATE, val);
buf : 			ssb_wait_bits(dev, SSB_IMSTATE, SSB_IMSTATE_BUSY, 1000,
buf : 				      0);
buf : 		}
buf : 
buf : 		ssb_write32(dev, SSB_TMSLOW,
buf : 			SSB_TMSLOW_FGC | SSB_TMSLOW_CLOCK |
buf : 			reject | SSB_TMSLOW_RESET |
buf : 			core_specific_flags);
ific_flags); 
buf : 		ssb_flush_tmslow(dev);
buf : 
buf : 		if (ssb_read32(dev, SSB_IDLOW) & SSB_IDLOW_INITIATOR) {
if (ssb_read32(dev, SSB_IDLOW) & SSB_IDLOW_INITIATOR) { 
buf : 			val = ssb_read32(dev, SSB_IMSTATE);
buf : 			val &= ~SSB_IMSTATE_REJECT;
buf : 			ssb_write32(dev, SSB_IMSTATE, val);
buf : 		}
buf : 	}
buf : 
buf : 	ssb_write32(dev, SSB_TMSLOW,
buf : 		    reject | SSB_TMSLOW_RESET |
buf : 		    core_specific_flags);
ific_flags); 
buf : 	ssb_flush_tmslow(dev);
buf : }
buf : EXPORT_SYMBOL(ssb_device_disable);
buf : 
buf : /* Some chipsets need routing known for PCIe and 64-bit DMA */
for PCIe and 64-bit DMA */ 
buf : static bool ssb_dma_translation_special_bit(struct ssb_device *dev)
buf : {
buf : 	u16 chip_id = dev->bus->chip_id;
buf : 
buf : 	if (dev->id.coreid == SSB_DEV_80211) {
if (dev->id.coreid == SSB_DEV_80211) { 
buf : 		return (chip_id == 0x4322 || chip_id == 43221 ||
buf : 			chip_id == 43231 || chip_id == 43222);
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : u32 ssb_dma_translation(struct ssb_device *dev)
buf : {
buf : 	switch (dev->bus->bustype) {
buf : 	case SSB_BUSTYPE_SSB:
buf : 		return 0;
buf : 	case SSB_BUSTYPE_PCI:
buf : 		if (pci_is_pcie(dev->bus->host_pci) &&
if (pci_is_pcie(dev->bus->host_pci) && 
buf : 		    ssb_read32(dev, SSB_TMSHIGH) & SSB_TMSHIGH_DMA64) {
buf : 			return SSB_PCIE_DMA_H32;
buf : 		} else {
buf : 			if (ssb_dma_translation_special_bit(dev))
if (ssb_dma_translation_special_bit(dev)) 
buf : 				return SSB_PCIE_DMA_H32;
buf : 			else
buf : 				return SSB_PCI_DMA;
buf : 		}
buf : 	default:
buf : 		__ssb_dma_not_implemented(dev);
buf : 	}
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL(ssb_dma_translation);
buf : 
buf : int ssb_bus_may_powerdown(struct ssb_bus *bus)
buf : {
buf : 	struct ssb_chipcommon *cc;
buf : 	int err = 0;
buf : 
buf : 	/* On buses where more than one core may be working
buf : 	 * at a time, we must not powerdown stuff if there are
if there are 
buf : 	 * still cores that may want to run. */
buf : 	if (bus->bustype == SSB_BUSTYPE_SSB)
if (bus->bustype == SSB_BUSTYPE_SSB) 
buf : 		goto out;
buf : 
buf : 	cc = &bus->chipco;
buf : 
buf : 	if (!cc->dev)
if (!cc->dev) 
buf : 		goto out;
buf : 	if (cc->dev->id.revision < 5)
if (cc->dev->id.revision < 5) 
buf : 		goto out;
buf : 
buf : 	ssb_chipco_set_clockmode(cc, SSB_CLKMODE_SLOW);
buf : 	err = ssb_pci_xtal(bus, SSB_GPIO_XTAL | SSB_GPIO_PLL, 0);
buf : 	if (err)
if (err) 
buf : 		goto error;
buf : out:
buf : #ifdef CONFIG_SSB_DEBUG
ifdef CONFIG_SSB_DEBUG 
buf : 	bus->powered_up = 0;
buf : #endif
if 
buf : 	return err;
buf : error:
buf : 	ssb_err("Bus powerdown failed\n");
buf : 	goto out;
buf : }
buf : EXPORT_SYMBOL(ssb_bus_may_powerdown);
buf : 
buf : int ssb_bus_powerup(struct ssb_bus *bus, bool dynamic_pctl)
buf : {
buf : 	int err;
buf : 	enum ssb_clkmode mode;
buf : 
buf : 	err = ssb_pci_xtal(bus, SSB_GPIO_XTAL | SSB_GPIO_PLL, 1);
buf : 	if (err)
if (err) 
buf : 		goto error;
buf : 
buf : #ifdef CONFIG_SSB_DEBUG
ifdef CONFIG_SSB_DEBUG 
buf : 	bus->powered_up = 1;
buf : #endif
if 
buf : 
buf : 	mode = dynamic_pctl ? SSB_CLKMODE_DYNAMIC : SSB_CLKMODE_FAST;
buf : 	ssb_chipco_set_clockmode(&bus->chipco, mode);
buf : 
buf : 	return 0;
buf : error:
buf : 	ssb_err("Bus powerup failed\n");
buf : 	return err;
buf : }
buf : EXPORT_SYMBOL(ssb_bus_powerup);
buf : 
buf : static void ssb_broadcast_value(struct ssb_device *dev,
buf : 				u32 address, u32 data)
buf : {
buf : #ifdef CONFIG_SSB_DRIVER_PCICORE
ifdef CONFIG_SSB_DRIVER_PCICORE 
buf : 	/* This is used for both, PCI and ChipCommon core, so be careful. */
for both, PCI and ChipCommon core, so be careful. */ 
buf : 	BUILD_BUG_ON(SSB_PCICORE_BCAST_ADDR != SSB_CHIPCO_BCAST_ADDR);
buf : 	BUILD_BUG_ON(SSB_PCICORE_BCAST_DATA != SSB_CHIPCO_BCAST_DATA);
buf : #endif
if 
buf : 
buf : 	ssb_write32(dev, SSB_CHIPCO_BCAST_ADDR, address);
buf : 	ssb_read32(dev, SSB_CHIPCO_BCAST_ADDR); /* flush */
buf : 	ssb_write32(dev, SSB_CHIPCO_BCAST_DATA, data);
buf : 	ssb_read32(dev, SSB_CHIPCO_BCAST_DATA); /* flush */
buf : }
buf : 
buf : void ssb_commit_settings(struct ssb_bus *bus)
buf : {
buf : 	struct ssb_device *dev;
buf : 
buf : #ifdef CONFIG_SSB_DRIVER_PCICORE
ifdef CONFIG_SSB_DRIVER_PCICORE 
buf : 	dev = bus->chipco.dev ? bus->chipco.dev : bus->pcicore.dev;
buf : #else
buf : 	dev = bus->chipco.dev;
buf : #endif
if 
buf : 	if (WARN_ON(!dev))
buf : 		return;
buf : 	/* This forces an update of the cached registers. */
forces an update of the cached registers. */ 
buf : 	ssb_broadcast_value(dev, 0xFD8, 0);
buf : }
buf : EXPORT_SYMBOL(ssb_commit_settings);
buf : 
buf : u32 ssb_admatch_base(u32 adm)
buf : {
buf : 	u32 base = 0;
buf : 
buf : 	switch (adm & SSB_ADM_TYPE) {
buf : 	case SSB_ADM_TYPE0:
buf : 		base = (adm & SSB_ADM_BASE0);
buf : 		break;
buf : 	case SSB_ADM_TYPE1:
buf : 		SSB_WARN_ON(adm & SSB_ADM_NEG); /* unsupported */
buf : 		base = (adm & SSB_ADM_BASE1);
buf : 		break;
buf : 	case SSB_ADM_TYPE2:
buf : 		SSB_WARN_ON(adm & SSB_ADM_NEG); /* unsupported */
buf : 		base = (adm & SSB_ADM_BASE2);
buf : 		break;
buf : 	default:
buf : 		SSB_WARN_ON(1);
buf : 	}
buf : 
buf : 	return base;
buf : }
buf : EXPORT_SYMBOL(ssb_admatch_base);
buf : 
buf : u32 ssb_admatch_size(u32 adm)
buf : {
buf : 	u32 size = 0;
buf : 
buf : 	switch (adm & SSB_ADM_TYPE) {
buf : 	case SSB_ADM_TYPE0:
buf : 		size = ((adm & SSB_ADM_SZ0) >> SSB_ADM_SZ0_SHIFT);
buf : 		break;
buf : 	case SSB_ADM_TYPE1:
buf : 		SSB_WARN_ON(adm & SSB_ADM_NEG); /* unsupported */
buf : 		size = ((adm & SSB_ADM_SZ1) >> SSB_ADM_SZ1_SHIFT);
buf : 		break;
buf : 	case SSB_ADM_TYPE2:
buf : 		SSB_WARN_ON(adm & SSB_ADM_NEG); /* unsupported */
buf : 		size = ((adm & SSB_ADM_SZ2) >> SSB_ADM_SZ2_SHIFT);
buf : 		break;
buf : 	default:
buf : 		SSB_WARN_ON(1);
buf : 	}
buf : 	size = (1 << (size + 1));
buf : 
buf : 	return size;
buf : }
buf : EXPORT_SYMBOL(ssb_admatch_size);
buf : 
buf : static int __init ssb_modinit(void)
buf : {
buf : 	int err;
buf : 
buf : 	/* See the comment at the ssb_is_early_boot definition */
buf : 	ssb_is_early_boot = 0;
buf : 	err = bus_register(&ssb_bustype);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	/* Maybe we already registered some buses at early boot.
buf : 	 * Check for this and attach them
for this and attach them 
buf : 	 */
buf : 	ssb_buses_lock();
buf : 	err = ssb_attach_queued_buses();
buf : 	ssb_buses_unlock();
buf : 	if (err) {
if (err) { 
buf : 		bus_unregister(&ssb_bustype);
buf : 		goto out;
buf : 	}
buf : 
buf : 	err = b43_pci_ssb_bridge_init();
buf : 	if (err) {
if (err) { 
buf : 		ssb_err("Broadcom 43xx PCI-SSB-bridge initialization failed\n");
buf : 		/* don't fail SSB init because of this */
buf : 		err = 0;
buf : 	}
buf : 	err = ssb_gige_init();
buf : 	if (err) {
if (err) { 
buf : 		ssb_err("SSB Broadcom Gigabit Ethernet driver initialization failed\n");
buf : 		/* don't fail SSB init because of this */
buf : 		err = 0;
buf : 	}
buf : out:
buf : 	return err;
buf : }
buf : /* ssb must be initialized after PCI but before the ssb drivers.
fore the ssb drivers. 
buf :  * That means we must use some initcall between subsys_initcall
buf :  * and device_initcall. */
buf : fs_initcall(ssb_modinit);
buf : 
buf : static void __exit ssb_modexit(void)
buf : {
buf : 	ssb_gige_exit();
buf : 	b43_pci_ssb_bridge_exit();
buf : 	bus_unregister(&ssb_bustype);
buf : }
buf : module_exit(ssb_modexit)
file : ./test/kernel/drivers/infiniband/hw/mlx5/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
buf :  *
buf :  * This software is available to you under a choice of one of two
buf :  * licenses.  You may choose to be licensed under the terms of the GNU
buf :  * General Public License (GPL) Version 2, available from the file
buf :  * COPYING in the main directory of this source tree, or the
buf :  * OpenIB.org BSD license below:
buf :  *
buf :  *     Redistribution and use in source and binary forms, with or
forms, with or 
buf :  *     without modification, are permitted provided that the following
buf :  *     conditions are met:
buf :  *
buf :  *      - Redistributions of source code must retain the above
buf :  *        copyright notice, this list of conditions and the following
buf :  *        disclaimer.
buf :  *
buf :  *      - Redistributions in binary form must reproduce the above
form must reproduce the above 
buf :  *        copyright notice, this list of conditions and the following
buf :  *        disclaimer in the documentation and/or other materials
buf :  *        provided with the distribution.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
buf :  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
buf :  * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
buf :  * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
buf :  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
buf :  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
buf :  * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
buf :  * SOFTWARE.
buf :  */
buf : 
buf : #include <asm-generic/kmap_types.h>
buf : #include <linux/module.h>
buf : #include <linux/init.h>
buf : #include <linux/errno.h>
buf : #include <linux/pci.h>
buf : #include <linux/dma-mapping.h>
buf : #include <linux/slab.h>
buf : #include <linux/io-mapping.h>
buf : #include <linux/sched.h>
buf : #include <rdma/ib_user_verbs.h>
buf : #include <rdma/ib_smi.h>
buf : #include <rdma/ib_umem.h>
buf : #include "user.h"
buf : #include "mlx5_ib.h"
buf : 
buf : #define DRIVER_NAME "mlx5_ib"
buf : #define DRIVER_VERSION "2.2-1"
buf : #define DRIVER_RELDATE	"Feb 2014"
buf : 
buf : MODULE_AUTHOR("Eli Cohen <eli@mellanox.com>");
buf : MODULE_DESCRIPTION("Mellanox Connect-IB HCA IB driver");
buf : MODULE_LICENSE("Dual BSD/GPL");
buf : MODULE_VERSION(DRIVER_VERSION);
buf : 
buf : static int prof_sel = 2;
buf : module_param_named(prof_sel, prof_sel, int, 0444);
buf : MODULE_PARM_DESC(prof_sel, "profile selector. Valid range 0 - 2");
buf : 
buf : static char mlx5_version[] =
buf : 	DRIVER_NAME ": Mellanox Connect-IB Infiniband driver v"
buf : 	DRIVER_VERSION " (" DRIVER_RELDATE ")\n";
buf : 
buf : static struct mlx5_profile profile[] = {
buf : 	[0] = {
buf : 		.mask		= 0,
buf : 	},
buf : 	[1] = {
buf : 		.mask		= MLX5_PROF_MASK_QP_SIZE,
buf : 		.log_max_qp	= 12,
buf : 	},
buf : 	[2] = {
buf : 		.mask		= MLX5_PROF_MASK_QP_SIZE |
buf : 				  MLX5_PROF_MASK_MR_CACHE,
buf : 		.log_max_qp	= 17,
buf : 		.mr_cache[0]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[1]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[2]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[3]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[4]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[5]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[6]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[7]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[8]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[9]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[10]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[11]	= {
buf : 			.size	= 500,
buf : 			.limit	= 250
buf : 		},
buf : 		.mr_cache[12]	= {
buf : 			.size	= 64,
buf : 			.limit	= 32
buf : 		},
buf : 		.mr_cache[13]	= {
buf : 			.size	= 32,
buf : 			.limit	= 16
buf : 		},
buf : 		.mr_cache[14]	= {
buf : 			.size	= 16,
buf : 			.limit	= 8
buf : 		},
buf : 		.mr_cache[15]	= {
buf : 			.size	= 8,
buf : 			.limit	= 4
buf : 		},
buf : 	},
buf : };
buf : 
buf : int mlx5_vector2eqn(struct mlx5_ib_dev *dev, int vector, int *eqn, int *irqn)
buf : {
buf : 	struct mlx5_eq_table *table = &dev->mdev.priv.eq_table;
buf : 	struct mlx5_eq *eq, *n;
buf : 	int err = -ENOENT;
buf : 
buf : 	spin_lock(&table->lock);
buf : 	list_for_each_entry_safe(eq, n, &dev->eqs_list, list) {
for_each_entry_safe(eq, n, &dev->eqs_list, list) { 
buf : 		if (eq->index == vector) {
buf : 			*eqn = eq->eqn;
buf : 			*irqn = eq->irqn;
buf : 			err = 0;
buf : 			break;
buf : 		}
buf : 	}
buf : 	spin_unlock(&table->lock);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int alloc_comp_eqs(struct mlx5_ib_dev *dev)
buf : {
buf : 	struct mlx5_eq_table *table = &dev->mdev.priv.eq_table;
buf : 	char name[MLX5_MAX_EQ_NAME];
buf : 	struct mlx5_eq *eq, *n;
buf : 	int ncomp_vec;
buf : 	int nent;
buf : 	int err;
buf : 	int i;
buf : 
buf : 	INIT_LIST_HEAD(&dev->eqs_list);
buf : 	ncomp_vec = table->num_comp_vectors;
buf : 	nent = MLX5_COMP_EQ_SIZE;
buf : 	for (i = 0; i < ncomp_vec; i++) {
for (i = 0; i < ncomp_vec; i++) { 
buf : 		eq = kzalloc(sizeof(*eq), GFP_KERNEL);
buf : 		if (!eq) {
if (!eq) { 
buf : 			err = -ENOMEM;
buf : 			goto clean;
buf : 		}
buf : 
buf : 		snprintf(name, MLX5_MAX_EQ_NAME, "mlx5_comp%d", i);
buf : 		err = mlx5_create_map_eq(&dev->mdev, eq,
buf : 					 i + MLX5_EQ_VEC_COMP_BASE, nent, 0,
buf : 					 name, &dev->mdev.priv.uuari.uars[0]);
buf : 		if (err) {
if (err) { 
buf : 			kfree(eq);
buf : 			goto clean;
buf : 		}
buf : 		mlx5_ib_dbg(dev, "allocated completion EQN %d\n", eq->eqn);
buf : 		eq->index = i;
buf : 		spin_lock(&table->lock);
buf : 		list_add_tail(&eq->list, &dev->eqs_list);
buf : 		spin_unlock(&table->lock);
buf : 	}
buf : 
buf : 	dev->num_comp_vectors = ncomp_vec;
buf : 	return 0;
buf : 
buf : clean:
buf : 	spin_lock(&table->lock);
buf : 	list_for_each_entry_safe(eq, n, &dev->eqs_list, list) {
for_each_entry_safe(eq, n, &dev->eqs_list, list) { 
buf : 		list_del(&eq->list);
buf : 		spin_unlock(&table->lock);
buf : 		if (mlx5_destroy_unmap_eq(&dev->mdev, eq))
if (mlx5_destroy_unmap_eq(&dev->mdev, eq)) 
buf : 			mlx5_ib_warn(dev, "failed to destroy EQ 0x%x\n", eq->eqn);
buf : 		kfree(eq);
buf : 		spin_lock(&table->lock);
buf : 	}
buf : 	spin_unlock(&table->lock);
buf : 	return err;
buf : }
buf : 
buf : static void free_comp_eqs(struct mlx5_ib_dev *dev)
buf : {
buf : 	struct mlx5_eq_table *table = &dev->mdev.priv.eq_table;
buf : 	struct mlx5_eq *eq, *n;
buf : 
buf : 	spin_lock(&table->lock);
buf : 	list_for_each_entry_safe(eq, n, &dev->eqs_list, list) {
for_each_entry_safe(eq, n, &dev->eqs_list, list) { 
buf : 		list_del(&eq->list);
buf : 		spin_unlock(&table->lock);
buf : 		if (mlx5_destroy_unmap_eq(&dev->mdev, eq))
if (mlx5_destroy_unmap_eq(&dev->mdev, eq)) 
buf : 			mlx5_ib_warn(dev, "failed to destroy EQ 0x%x\n", eq->eqn);
buf : 		kfree(eq);
buf : 		spin_lock(&table->lock);
buf : 	}
buf : 	spin_unlock(&table->lock);
buf : }
buf : 
buf : static int mlx5_ib_query_device(struct ib_device *ibdev,
buf : 				struct ib_device_attr *props)
buf : {
buf : 	struct mlx5_ib_dev *dev = to_mdev(ibdev);
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int err = -ENOMEM;
buf : 	int max_rq_sg;
buf : 	int max_sq_sg;
buf : 	u64 flags;
buf : 
buf : 	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id = IB_SMP_ATTR_NODE_INFO;
buf : 
buf : 	err = mlx5_MAD_IFC(to_mdev(ibdev), 1, 1, 1, NULL, NULL, in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	memset(props, 0, sizeof(*props));
buf : 
buf : 	props->fw_ver = ((u64)fw_rev_maj(&dev->mdev) << 32) |
buf : 		(fw_rev_min(&dev->mdev) << 16) |
buf : 		fw_rev_sub(&dev->mdev);
buf : 	props->device_cap_flags    = IB_DEVICE_CHANGE_PHY_PORT |
buf : 		IB_DEVICE_PORT_ACTIVE_EVENT		|
buf : 		IB_DEVICE_SYS_IMAGE_GUID		|
buf : 		IB_DEVICE_RC_RNR_NAK_GEN;
buf : 	flags = dev->mdev.caps.flags;
buf : 	if (flags & MLX5_DEV_CAP_FLAG_BAD_PKEY_CNTR)
if (flags & MLX5_DEV_CAP_FLAG_BAD_PKEY_CNTR) 
buf : 		props->device_cap_flags |= IB_DEVICE_BAD_PKEY_CNTR;
buf : 	if (flags & MLX5_DEV_CAP_FLAG_BAD_QKEY_CNTR)
if (flags & MLX5_DEV_CAP_FLAG_BAD_QKEY_CNTR) 
buf : 		props->device_cap_flags |= IB_DEVICE_BAD_QKEY_CNTR;
buf : 	if (flags & MLX5_DEV_CAP_FLAG_APM)
if (flags & MLX5_DEV_CAP_FLAG_APM) 
buf : 		props->device_cap_flags |= IB_DEVICE_AUTO_PATH_MIG;
buf : 	props->device_cap_flags |= IB_DEVICE_LOCAL_DMA_LKEY;
buf : 	if (flags & MLX5_DEV_CAP_FLAG_XRC)
if (flags & MLX5_DEV_CAP_FLAG_XRC) 
buf : 		props->device_cap_flags |= IB_DEVICE_XRC;
buf : 	props->device_cap_flags |= IB_DEVICE_MEM_MGT_EXTENSIONS;
buf : 	if (flags & MLX5_DEV_CAP_FLAG_SIG_HAND_OVER) {
if (flags & MLX5_DEV_CAP_FLAG_SIG_HAND_OVER) { 
buf : 		props->device_cap_flags |= IB_DEVICE_SIGNATURE_HANDOVER;
buf : 		/* At this stage no support for signature handover */
for signature handover */ 
buf : 		props->sig_prot_cap = IB_PROT_T10DIF_TYPE_1 |
buf : 				      IB_PROT_T10DIF_TYPE_2 |
buf : 				      IB_PROT_T10DIF_TYPE_3;
buf : 		props->sig_guard_cap = IB_GUARD_T10DIF_CRC |
buf : 				       IB_GUARD_T10DIF_CSUM;
buf : 	}
buf : 	if (flags & MLX5_DEV_CAP_FLAG_BLOCK_MCAST)
if (flags & MLX5_DEV_CAP_FLAG_BLOCK_MCAST) 
buf : 		props->device_cap_flags |= IB_DEVICE_BLOCK_MULTICAST_LOOPBACK;
buf : 
buf : 	props->vendor_id	   = be32_to_cpup((__be32 *)(out_mad->data + 36)) &
buf : 		0xffffff;
buf : 	props->vendor_part_id	   = be16_to_cpup((__be16 *)(out_mad->data + 30));
buf : 	props->hw_ver		   = be32_to_cpup((__be32 *)(out_mad->data + 32));
buf : 	memcpy(&props->sys_image_guid, out_mad->data +	4, 8);
buf : 
buf : 	props->max_mr_size	   = ~0ull;
buf : 	props->page_size_cap	   = dev->mdev.caps.min_page_sz;
buf : 	props->max_qp		   = 1 << dev->mdev.caps.log_max_qp;
buf : 	props->max_qp_wr	   = dev->mdev.caps.max_wqes;
buf : 	max_rq_sg = dev->mdev.caps.max_rq_desc_sz / sizeof(struct mlx5_wqe_data_seg);
buf : 	max_sq_sg = (dev->mdev.caps.max_sq_desc_sz - sizeof(struct mlx5_wqe_ctrl_seg)) /
buf : 		sizeof(struct mlx5_wqe_data_seg);
buf : 	props->max_sge = min(max_rq_sg, max_sq_sg);
buf : 	props->max_cq		   = 1 << dev->mdev.caps.log_max_cq;
buf : 	props->max_cqe		   = dev->mdev.caps.max_cqes - 1;
buf : 	props->max_mr		   = 1 << dev->mdev.caps.log_max_mkey;
buf : 	props->max_pd		   = 1 << dev->mdev.caps.log_max_pd;
buf : 	props->max_qp_rd_atom	   = dev->mdev.caps.max_ra_req_qp;
buf : 	props->max_qp_init_rd_atom = dev->mdev.caps.max_ra_res_qp;
buf : 	props->max_res_rd_atom	   = props->max_qp_rd_atom * props->max_qp;
buf : 	props->max_srq		   = 1 << dev->mdev.caps.log_max_srq;
buf : 	props->max_srq_wr	   = dev->mdev.caps.max_srq_wqes - 1;
buf : 	props->max_srq_sge	   = max_rq_sg - 1;
buf : 	props->max_fast_reg_page_list_len = (unsigned int)-1;
buf : 	props->local_ca_ack_delay  = dev->mdev.caps.local_ca_ack_delay;
buf : 	props->atomic_cap	   = IB_ATOMIC_NONE;
buf : 	props->masked_atomic_cap   = IB_ATOMIC_NONE;
buf : 	props->max_pkeys	   = be16_to_cpup((__be16 *)(out_mad->data + 28));
buf : 	props->max_mcast_grp	   = 1 << dev->mdev.caps.log_max_mcg;
buf : 	props->max_mcast_qp_attach = dev->mdev.caps.max_qp_mcg;
buf : 	props->max_total_mcast_qp_attach = props->max_mcast_qp_attach *
buf : 					   props->max_mcast_grp;
buf : 	props->max_map_per_fmr = INT_MAX; /* no limit in ConnectIB */
buf : 
buf : out:
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 
buf : 	return err;
buf : }
buf : 
buf : int mlx5_ib_query_port(struct ib_device *ibdev, u8 port,
buf : 		       struct ib_port_attr *props)
buf : {
buf : 	struct mlx5_ib_dev *dev = to_mdev(ibdev);
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int ext_active_speed;
buf : 	int err = -ENOMEM;
buf : 
buf : 	if (port < 1 || port > dev->mdev.caps.num_ports) {
if (port < 1 || port > dev->mdev.caps.num_ports) { 
buf : 		mlx5_ib_warn(dev, "invalid port number %d\n", port);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	memset(props, 0, sizeof(*props));
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id  = IB_SMP_ATTR_PORT_INFO;
buf : 	in_mad->attr_mod = cpu_to_be32(port);
buf : 
buf : 	err = mlx5_MAD_IFC(dev, 1, 1, port, NULL, NULL, in_mad, out_mad);
buf : 	if (err) {
if (err) { 
buf : 		mlx5_ib_warn(dev, "err %d\n", err);
buf : 		goto out;
buf : 	}
buf : 
buf : 
buf : 	props->lid		= be16_to_cpup((__be16 *)(out_mad->data + 16));
buf : 	props->lmc		= out_mad->data[34] & 0x7;
buf : 	props->sm_lid		= be16_to_cpup((__be16 *)(out_mad->data + 18));
buf : 	props->sm_sl		= out_mad->data[36] & 0xf;
buf : 	props->state		= out_mad->data[32] & 0xf;
buf : 	props->phys_state	= out_mad->data[33] >> 4;
buf : 	props->port_cap_flags	= be32_to_cpup((__be32 *)(out_mad->data + 20));
buf : 	props->gid_tbl_len	= out_mad->data[50];
buf : 	props->max_msg_sz	= 1 << to_mdev(ibdev)->mdev.caps.log_max_msg;
buf : 	props->pkey_tbl_len	= to_mdev(ibdev)->mdev.caps.port[port - 1].pkey_table_len;
buf : 	props->bad_pkey_cntr	= be16_to_cpup((__be16 *)(out_mad->data + 46));
buf : 	props->qkey_viol_cntr	= be16_to_cpup((__be16 *)(out_mad->data + 48));
buf : 	props->active_width	= out_mad->data[31] & 0xf;
buf : 	props->active_speed	= out_mad->data[35] >> 4;
buf : 	props->max_mtu		= out_mad->data[41] & 0xf;
buf : 	props->active_mtu	= out_mad->data[36] >> 4;
buf : 	props->subnet_timeout	= out_mad->data[51] & 0x1f;
buf : 	props->max_vl_num	= out_mad->data[37] >> 4;
buf : 	props->init_type_reply	= out_mad->data[41] >> 4;
buf : 
buf : 	/* Check if extended speeds (EDR/FDR/...) are supported */
if extended speeds (EDR/FDR/...) are supported */ 
buf : 	if (props->port_cap_flags & IB_PORT_EXTENDED_SPEEDS_SUP) {
buf : 		ext_active_speed = out_mad->data[62] >> 4;
buf : 
buf : 		switch (ext_active_speed) {
buf : 		case 1:
buf : 			props->active_speed = 16; /* FDR */
buf : 			break;
buf : 		case 2:
buf : 			props->active_speed = 32; /* EDR */
buf : 			break;
buf : 		}
buf : 	}
buf : 
buf : 	/* If reported active speed is QDR, check if is FDR-10 */
if is FDR-10 */ 
buf : 	if (props->active_speed == 4) {
buf : 		if (dev->mdev.caps.ext_port_cap[port - 1] &
if (dev->mdev.caps.ext_port_cap[port - 1] & 
buf : 		    MLX_EXT_PORT_CAP_FLAG_EXTENDED_PORT_INFO) {
buf : 			init_query_mad(in_mad);
buf : 			in_mad->attr_id = MLX5_ATTR_EXTENDED_PORT_INFO;
buf : 			in_mad->attr_mod = cpu_to_be32(port);
buf : 
buf : 			err = mlx5_MAD_IFC(dev, 1, 1, port,
buf : 					   NULL, NULL, in_mad, out_mad);
buf : 			if (err)
if (err) 
buf : 				goto out;
buf : 
buf : 			/* Checking LinkSpeedActive for FDR-10 */
for FDR-10 */ 
buf : 			if (out_mad->data[15] & 0x1)
buf : 				props->active_speed = 8;
buf : 		}
buf : 	}
buf : 
buf : out:
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int mlx5_ib_query_gid(struct ib_device *ibdev, u8 port, int index,
buf : 			     union ib_gid *gid)
buf : {
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int err = -ENOMEM;
buf : 
buf : 	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id  = IB_SMP_ATTR_PORT_INFO;
buf : 	in_mad->attr_mod = cpu_to_be32(port);
buf : 
buf : 	err = mlx5_MAD_IFC(to_mdev(ibdev), 1, 1, port, NULL, NULL, in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	memcpy(gid->raw, out_mad->data + 8, 8);
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id  = IB_SMP_ATTR_GUID_INFO;
buf : 	in_mad->attr_mod = cpu_to_be32(index / 8);
buf : 
buf : 	err = mlx5_MAD_IFC(to_mdev(ibdev), 1, 1, port, NULL, NULL, in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	memcpy(gid->raw + 8, out_mad->data + (index % 8) * 8, 8);
buf : 
buf : out:
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 	return err;
buf : }
buf : 
buf : static int mlx5_ib_query_pkey(struct ib_device *ibdev, u8 port, u16 index,
buf : 			      u16 *pkey)
buf : {
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int err = -ENOMEM;
buf : 
buf : 	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id  = IB_SMP_ATTR_PKEY_TABLE;
buf : 	in_mad->attr_mod = cpu_to_be32(index / 32);
buf : 
buf : 	err = mlx5_MAD_IFC(to_mdev(ibdev), 1, 1, port, NULL, NULL, in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	*pkey = be16_to_cpu(((__be16 *)out_mad->data)[index % 32]);
buf : 
buf : out:
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 	return err;
buf : }
buf : 
buf : struct mlx5_reg_node_desc {
buf : 	u8	desc[64];
buf : };
buf : 
buf : static int mlx5_ib_modify_device(struct ib_device *ibdev, int mask,
ify_device(struct ib_device *ibdev, int mask, 
buf : 				 struct ib_device_modify *props)
buf : {
buf : 	struct mlx5_ib_dev *dev = to_mdev(ibdev);
buf : 	struct mlx5_reg_node_desc in;
buf : 	struct mlx5_reg_node_desc out;
buf : 	int err;
buf : 
buf : 	if (mask & ~IB_DEVICE_MODIFY_NODE_DESC)
if (mask & ~IB_DEVICE_MODIFY_NODE_DESC) 
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	if (!(mask & IB_DEVICE_MODIFY_NODE_DESC))
if (!(mask & IB_DEVICE_MODIFY_NODE_DESC)) 
buf : 		return 0;
buf : 
buf : 	/*
buf : 	 * If possible, pass node desc to FW, so it can generate
buf : 	 * a 144 trap.  If cmd fails, just ignore.
buf : 	 */
buf : 	memcpy(&in, props->node_desc, 64);
buf : 	err = mlx5_core_access_reg(&dev->mdev, &in, sizeof(in), &out,
buf : 				   sizeof(out), MLX5_REG_NODE_DESC, 0, 1);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	memcpy(ibdev->node_desc, props->node_desc, 64);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int mlx5_ib_modify_port(struct ib_device *ibdev, u8 port, int mask,
ify_port(struct ib_device *ibdev, u8 port, int mask, 
buf : 			       struct ib_port_modify *props)
buf : {
buf : 	struct mlx5_ib_dev *dev = to_mdev(ibdev);
buf : 	struct ib_port_attr attr;
buf : 	u32 tmp;
buf : 	int err;
buf : 
buf : 	mutex_lock(&dev->cap_mask_mutex);
buf : 
buf : 	err = mlx5_ib_query_port(ibdev, port, &attr);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	tmp = (attr.port_cap_flags | props->set_port_cap_mask) &
buf : 		~props->clr_port_cap_mask;
buf : 
buf : 	err = mlx5_set_port_caps(&dev->mdev, port, tmp);
buf : 
buf : out:
buf : 	mutex_unlock(&dev->cap_mask_mutex);
buf : 	return err;
buf : }
buf : 
buf : static struct ib_ucontext *mlx5_ib_alloc_ucontext(struct ib_device *ibdev,
buf : 						  struct ib_udata *udata)
buf : {
buf : 	struct mlx5_ib_dev *dev = to_mdev(ibdev);
buf : 	struct mlx5_ib_alloc_ucontext_req_v2 req;
buf : 	struct mlx5_ib_alloc_ucontext_resp resp;
buf : 	struct mlx5_ib_ucontext *context;
buf : 	struct mlx5_uuar_info *uuari;
buf : 	struct mlx5_uar *uars;
buf : 	int gross_uuars;
buf : 	int num_uars;
buf : 	int ver;
buf : 	int uuarn;
buf : 	int err;
buf : 	int i;
buf : 	int reqlen;
buf : 
buf : 	if (!dev->ib_active)
if (!dev->ib_active) 
buf : 		return ERR_PTR(-EAGAIN);
buf : 
buf : 	memset(&req, 0, sizeof(req));
buf : 	reqlen = udata->inlen - sizeof(struct ib_uverbs_cmd_hdr);
buf : 	if (reqlen == sizeof(struct mlx5_ib_alloc_ucontext_req))
if (reqlen == sizeof(struct mlx5_ib_alloc_ucontext_req)) 
buf : 		ver = 0;
buf : 	else if (reqlen == sizeof(struct mlx5_ib_alloc_ucontext_req_v2))
if (reqlen == sizeof(struct mlx5_ib_alloc_ucontext_req_v2)) 
buf : 		ver = 2;
buf : 	else
buf : 		return ERR_PTR(-EINVAL);
buf : 
buf : 	err = ib_copy_from_udata(&req, udata, reqlen);
buf : 	if (err)
if (err) 
buf : 		return ERR_PTR(err);
buf : 
buf : 	if (req.flags || req.reserved)
if (req.flags || req.reserved) 
buf : 		return ERR_PTR(-EINVAL);
buf : 
buf : 	if (req.total_num_uuars > MLX5_MAX_UUARS)
if (req.total_num_uuars > MLX5_MAX_UUARS) 
buf : 		return ERR_PTR(-ENOMEM);
buf : 
buf : 	if (req.total_num_uuars == 0)
if (req.total_num_uuars == 0) 
buf : 		return ERR_PTR(-EINVAL);
buf : 
buf : 	req.total_num_uuars = ALIGN(req.total_num_uuars,
buf : 				    MLX5_NON_FP_BF_REGS_PER_PAGE);
buf : 	if (req.num_low_latency_uuars > req.total_num_uuars - 1)
if (req.num_low_latency_uuars > req.total_num_uuars - 1) 
buf : 		return ERR_PTR(-EINVAL);
buf : 
buf : 	num_uars = req.total_num_uuars / MLX5_NON_FP_BF_REGS_PER_PAGE;
buf : 	gross_uuars = num_uars * MLX5_BF_REGS_PER_PAGE;
buf : 	resp.qp_tab_size      = 1 << dev->mdev.caps.log_max_qp;
buf : 	resp.bf_reg_size      = dev->mdev.caps.bf_reg_size;
buf : 	resp.cache_line_size  = L1_CACHE_BYTES;
buf : 	resp.max_sq_desc_sz = dev->mdev.caps.max_sq_desc_sz;
buf : 	resp.max_rq_desc_sz = dev->mdev.caps.max_rq_desc_sz;
buf : 	resp.max_send_wqebb = dev->mdev.caps.max_wqes;
buf : 	resp.max_recv_wr = dev->mdev.caps.max_wqes;
buf : 	resp.max_srq_recv_wr = dev->mdev.caps.max_srq_wqes;
buf : 
buf : 	context = kzalloc(sizeof(*context), GFP_KERNEL);
buf : 	if (!context)
if (!context) 
buf : 		return ERR_PTR(-ENOMEM);
buf : 
buf : 	uuari = &context->uuari;
buf : 	mutex_init(&uuari->lock);
buf : 	uars = kcalloc(num_uars, sizeof(*uars), GFP_KERNEL);
buf : 	if (!uars) {
if (!uars) { 
buf : 		err = -ENOMEM;
buf : 		goto out_ctx;
buf : 	}
buf : 
buf : 	uuari->bitmap = kcalloc(BITS_TO_LONGS(gross_uuars),
buf : 				sizeof(*uuari->bitmap),
buf : 				GFP_KERNEL);
buf : 	if (!uuari->bitmap) {
if (!uuari->bitmap) { 
buf : 		err = -ENOMEM;
buf : 		goto out_uar_ctx;
buf : 	}
buf : 	/*
buf : 	 * clear all fast path uuars
buf : 	 */
buf : 	for (i = 0; i < gross_uuars; i++) {
for (i = 0; i < gross_uuars; i++) { 
buf : 		uuarn = i & 3;
buf : 		if (uuarn == 2 || uuarn == 3)
if (uuarn == 2 || uuarn == 3) 
buf : 			set_bit(i, uuari->bitmap);
buf : 	}
buf : 
buf : 	uuari->count = kcalloc(gross_uuars, sizeof(*uuari->count), GFP_KERNEL);
buf : 	if (!uuari->count) {
if (!uuari->count) { 
buf : 		err = -ENOMEM;
buf : 		goto out_bitmap;
buf : 	}
buf : 
buf : 	for (i = 0; i < num_uars; i++) {
for (i = 0; i < num_uars; i++) { 
buf : 		err = mlx5_cmd_alloc_uar(&dev->mdev, &uars[i].index);
buf : 		if (err)
if (err) 
buf : 			goto out_count;
buf : 	}
buf : 
buf : 	INIT_LIST_HEAD(&context->db_page_list);
buf : 	mutex_init(&context->db_page_mutex);
buf : 
buf : 	resp.tot_uuars = req.total_num_uuars;
buf : 	resp.num_ports = dev->mdev.caps.num_ports;
buf : 	err = ib_copy_to_udata(udata, &resp,
buf : 			       sizeof(resp) - sizeof(resp.reserved));
buf : 	if (err)
if (err) 
buf : 		goto out_uars;
buf : 
buf : 	uuari->ver = ver;
buf : 	uuari->num_low_latency_uuars = req.num_low_latency_uuars;
buf : 	uuari->uars = uars;
buf : 	uuari->num_uars = num_uars;
buf : 	return &context->ibucontext;
buf : 
buf : out_uars:
buf : 	for (i--; i >= 0; i--)
for (i--; i >= 0; i--) 
buf : 		mlx5_cmd_free_uar(&dev->mdev, uars[i].index);
buf : out_count:
buf : 	kfree(uuari->count);
buf : 
buf : out_bitmap:
buf : 	kfree(uuari->bitmap);
buf : 
buf : out_uar_ctx:
buf : 	kfree(uars);
buf : 
buf : out_ctx:
buf : 	kfree(context);
buf : 	return ERR_PTR(err);
buf : }
buf : 
buf : static int mlx5_ib_dealloc_ucontext(struct ib_ucontext *ibcontext)
buf : {
buf : 	struct mlx5_ib_ucontext *context = to_mucontext(ibcontext);
buf : 	struct mlx5_ib_dev *dev = to_mdev(ibcontext->device);
buf : 	struct mlx5_uuar_info *uuari = &context->uuari;
buf : 	int i;
buf : 
buf : 	for (i = 0; i < uuari->num_uars; i++) {
for (i = 0; i < uuari->num_uars; i++) { 
buf : 		if (mlx5_cmd_free_uar(&dev->mdev, uuari->uars[i].index))
buf : 			mlx5_ib_warn(dev, "failed to free UAR 0x%x\n", uuari->uars[i].index);
buf : 	}
buf : 
buf : 	kfree(uuari->count);
buf : 	kfree(uuari->bitmap);
buf : 	kfree(uuari->uars);
buf : 	kfree(context);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static phys_addr_t uar_index2pfn(struct mlx5_ib_dev *dev, int index)
buf : {
buf : 	return (pci_resource_start(dev->mdev.pdev, 0) >> PAGE_SHIFT) + index;
buf : }
buf : 
buf : static int get_command(unsigned long offset)
buf : {
buf : 	return (offset >> MLX5_IB_MMAP_CMD_SHIFT) & MLX5_IB_MMAP_CMD_MASK;
buf : }
buf : 
buf : static int get_arg(unsigned long offset)
buf : {
buf : 	return offset & ((1 << MLX5_IB_MMAP_CMD_SHIFT) - 1);
buf : }
buf : 
buf : static int get_index(unsigned long offset)
buf : {
buf : 	return get_arg(offset);
buf : }
buf : 
buf : static int mlx5_ib_mmap(struct ib_ucontext *ibcontext, struct vm_area_struct *vma)
buf : {
buf : 	struct mlx5_ib_ucontext *context = to_mucontext(ibcontext);
buf : 	struct mlx5_ib_dev *dev = to_mdev(ibcontext->device);
buf : 	struct mlx5_uuar_info *uuari = &context->uuari;
buf : 	unsigned long command;
buf : 	unsigned long idx;
buf : 	phys_addr_t pfn;
buf : 
buf : 	command = get_command(vma->vm_pgoff);
buf : 	switch (command) {
buf : 	case MLX5_IB_MMAP_REGULAR_PAGE:
buf : 		if (vma->vm_end - vma->vm_start != PAGE_SIZE)
if (vma->vm_end - vma->vm_start != PAGE_SIZE) 
buf : 			return -EINVAL;
buf : 
buf : 		idx = get_index(vma->vm_pgoff);
buf : 		pfn = uar_index2pfn(dev, uuari->uars[idx].index);
buf : 		mlx5_ib_dbg(dev, "uar idx 0x%lx, pfn 0x%llx\n", idx,
buf : 			    (unsigned long long)pfn);
buf : 
buf : 		if (idx >= uuari->num_uars)
if (idx >= uuari->num_uars) 
buf : 			return -EINVAL;
buf : 
buf : 		vma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);
buf : 		if (io_remap_pfn_range(vma, vma->vm_start, pfn,
if (io_remap_pfn_range(vma, vma->vm_start, pfn, 
buf : 				       PAGE_SIZE, vma->vm_page_prot))
buf : 			return -EAGAIN;
buf : 
buf : 		mlx5_ib_dbg(dev, "mapped WC at 0x%lx, PA 0x%llx\n",
buf : 			    vma->vm_start,
buf : 			    (unsigned long long)pfn << PAGE_SHIFT);
buf : 		break;
buf : 
buf : 	case MLX5_IB_MMAP_GET_CONTIGUOUS_PAGES:
buf : 		return -ENOSYS;
buf : 
buf : 	default:
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int alloc_pa_mkey(struct mlx5_ib_dev *dev, u32 *key, u32 pdn)
buf : {
buf : 	struct mlx5_create_mkey_mbox_in *in;
buf : 	struct mlx5_mkey_seg *seg;
buf : 	struct mlx5_core_mr mr;
buf : 	int err;
buf : 
buf : 	in = kzalloc(sizeof(*in), GFP_KERNEL);
buf : 	if (!in)
if (!in) 
buf : 		return -ENOMEM;
buf : 
buf : 	seg = &in->seg;
buf : 	seg->flags = MLX5_PERM_LOCAL_READ | MLX5_ACCESS_MODE_PA;
buf : 	seg->flags_pd = cpu_to_be32(pdn | MLX5_MKEY_LEN64);
buf : 	seg->qpn_mkey7_0 = cpu_to_be32(0xffffff << 8);
buf : 	seg->start_addr = 0;
buf : 
buf : 	err = mlx5_core_create_mkey(&dev->mdev, &mr, in, sizeof(*in),
buf : 				    NULL, NULL, NULL);
buf : 	if (err) {
if (err) { 
buf : 		mlx5_ib_warn(dev, "failed to create mkey, %d\n", err);
buf : 		goto err_in;
buf : 	}
buf : 
buf : 	kfree(in);
buf : 	*key = mr.key;
buf : 
buf : 	return 0;
buf : 
buf : err_in:
buf : 	kfree(in);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void free_pa_mkey(struct mlx5_ib_dev *dev, u32 key)
buf : {
buf : 	struct mlx5_core_mr mr;
buf : 	int err;
buf : 
buf : 	memset(&mr, 0, sizeof(mr));
buf : 	mr.key = key;
buf : 	err = mlx5_core_destroy_mkey(&dev->mdev, &mr);
buf : 	if (err)
if (err) 
buf : 		mlx5_ib_warn(dev, "failed to destroy mkey 0x%x\n", key);
buf : }
buf : 
buf : static struct ib_pd *mlx5_ib_alloc_pd(struct ib_device *ibdev,
buf : 				      struct ib_ucontext *context,
buf : 				      struct ib_udata *udata)
buf : {
buf : 	struct mlx5_ib_alloc_pd_resp resp;
buf : 	struct mlx5_ib_pd *pd;
buf : 	int err;
buf : 
buf : 	pd = kmalloc(sizeof(*pd), GFP_KERNEL);
buf : 	if (!pd)
if (!pd) 
buf : 		return ERR_PTR(-ENOMEM);
buf : 
buf : 	err = mlx5_core_alloc_pd(&to_mdev(ibdev)->mdev, &pd->pdn);
buf : 	if (err) {
if (err) { 
buf : 		kfree(pd);
buf : 		return ERR_PTR(err);
buf : 	}
buf : 
buf : 	if (context) {
if (context) { 
buf : 		resp.pdn = pd->pdn;
buf : 		if (ib_copy_to_udata(udata, &resp, sizeof(resp))) {
if (ib_copy_to_udata(udata, &resp, sizeof(resp))) { 
buf : 			mlx5_core_dealloc_pd(&to_mdev(ibdev)->mdev, pd->pdn);
buf : 			kfree(pd);
buf : 			return ERR_PTR(-EFAULT);
buf : 		}
buf : 	} else {
buf : 		err = alloc_pa_mkey(to_mdev(ibdev), &pd->pa_lkey, pd->pdn);
buf : 		if (err) {
if (err) { 
buf : 			mlx5_core_dealloc_pd(&to_mdev(ibdev)->mdev, pd->pdn);
buf : 			kfree(pd);
buf : 			return ERR_PTR(err);
buf : 		}
buf : 	}
buf : 
buf : 	return &pd->ibpd;
buf : }
buf : 
buf : static int mlx5_ib_dealloc_pd(struct ib_pd *pd)
buf : {
buf : 	struct mlx5_ib_dev *mdev = to_mdev(pd->device);
buf : 	struct mlx5_ib_pd *mpd = to_mpd(pd);
buf : 
buf : 	if (!pd->uobject)
if (!pd->uobject) 
buf : 		free_pa_mkey(mdev, mpd->pa_lkey);
buf : 
buf : 	mlx5_core_dealloc_pd(&mdev->mdev, mpd->pdn);
buf : 	kfree(mpd);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int mlx5_ib_mcg_attach(struct ib_qp *ibqp, union ib_gid *gid, u16 lid)
buf : {
buf : 	struct mlx5_ib_dev *dev = to_mdev(ibqp->device);
buf : 	int err;
buf : 
buf : 	err = mlx5_core_attach_mcg(&dev->mdev, gid, ibqp->qp_num);
buf : 	if (err)
if (err) 
buf : 		mlx5_ib_warn(dev, "failed attaching QPN 0x%x, MGID %pI6\n",
buf : 			     ibqp->qp_num, gid->raw);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int mlx5_ib_mcg_detach(struct ib_qp *ibqp, union ib_gid *gid, u16 lid)
buf : {
buf : 	struct mlx5_ib_dev *dev = to_mdev(ibqp->device);
buf : 	int err;
buf : 
buf : 	err = mlx5_core_detach_mcg(&dev->mdev, gid, ibqp->qp_num);
buf : 	if (err)
if (err) 
buf : 		mlx5_ib_warn(dev, "failed detaching QPN 0x%x, MGID %pI6\n",
buf : 			     ibqp->qp_num, gid->raw);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int init_node_data(struct mlx5_ib_dev *dev)
buf : {
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int err = -ENOMEM;
buf : 
buf : 	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id = IB_SMP_ATTR_NODE_DESC;
buf : 
buf : 	err = mlx5_MAD_IFC(dev, 1, 1, 1, NULL, NULL, in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	memcpy(dev->ib_dev.node_desc, out_mad->data, 64);
buf : 
buf : 	in_mad->attr_id = IB_SMP_ATTR_NODE_INFO;
buf : 
buf : 	err = mlx5_MAD_IFC(dev, 1, 1, 1, NULL, NULL, in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	dev->mdev.rev_id = be32_to_cpup((__be32 *)(out_mad->data + 32));
buf : 	memcpy(&dev->ib_dev.node_guid, out_mad->data + 12, 8);
buf : 
buf : out:
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 	return err;
buf : }
buf : 
buf : static ssize_t show_fw_pages(struct device *device, struct device_attribute *attr,
buf : 			     char *buf)
buf : {
buf : 	struct mlx5_ib_dev *dev =
buf : 		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
buf : 
buf : 	return sprintf(buf, "%d\n", dev->mdev.priv.fw_pages);
buf : }
buf : 
buf : static ssize_t show_reg_pages(struct device *device,
buf : 			      struct device_attribute *attr, char *buf)
buf : {
buf : 	struct mlx5_ib_dev *dev =
buf : 		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
buf : 
buf : 	return sprintf(buf, "%d\n", dev->mdev.priv.reg_pages);
buf : }
buf : 
buf : static ssize_t show_hca(struct device *device, struct device_attribute *attr,
buf : 			char *buf)
buf : {
buf : 	struct mlx5_ib_dev *dev =
buf : 		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
buf : 	return sprintf(buf, "MT%d\n", dev->mdev.pdev->device);
buf : }
buf : 
buf : static ssize_t show_fw_ver(struct device *device, struct device_attribute *attr,
buf : 			   char *buf)
buf : {
buf : 	struct mlx5_ib_dev *dev =
buf : 		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
buf : 	return sprintf(buf, "%d.%d.%d\n", fw_rev_maj(&dev->mdev),
buf : 		       fw_rev_min(&dev->mdev), fw_rev_sub(&dev->mdev));
buf : }
buf : 
buf : static ssize_t show_rev(struct device *device, struct device_attribute *attr,
buf : 			char *buf)
buf : {
buf : 	struct mlx5_ib_dev *dev =
buf : 		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
buf : 	return sprintf(buf, "%x\n", dev->mdev.rev_id);
buf : }
buf : 
buf : static ssize_t show_board(struct device *device, struct device_attribute *attr,
buf : 			  char *buf)
buf : {
buf : 	struct mlx5_ib_dev *dev =
buf : 		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
buf : 	return sprintf(buf, "%.*s\n", MLX5_BOARD_ID_LEN,
buf : 		       dev->mdev.board_id);
buf : }
buf : 
buf : static DEVICE_ATTR(hw_rev,   S_IRUGO, show_rev,    NULL);
buf : static DEVICE_ATTR(fw_ver,   S_IRUGO, show_fw_ver, NULL);
buf : static DEVICE_ATTR(hca_type, S_IRUGO, show_hca,    NULL);
buf : static DEVICE_ATTR(board_id, S_IRUGO, show_board,  NULL);
buf : static DEVICE_ATTR(fw_pages, S_IRUGO, show_fw_pages, NULL);
buf : static DEVICE_ATTR(reg_pages, S_IRUGO, show_reg_pages, NULL);
buf : 
buf : static struct device_attribute *mlx5_class_attributes[] = {
buf : 	&dev_attr_hw_rev,
buf : 	&dev_attr_fw_ver,
buf : 	&dev_attr_hca_type,
buf : 	&dev_attr_board_id,
buf : 	&dev_attr_fw_pages,
buf : 	&dev_attr_reg_pages,
buf : };
buf : 
buf : static void mlx5_ib_event(struct mlx5_core_dev *dev, enum mlx5_dev_event event,
buf : 			  void *data)
buf : {
buf : 	struct mlx5_ib_dev *ibdev = container_of(dev, struct mlx5_ib_dev, mdev);
buf : 	struct ib_event ibev;
buf : 	u8 port = 0;
buf : 
buf : 	switch (event) {
buf : 	case MLX5_DEV_EVENT_SYS_ERROR:
buf : 		ibdev->ib_active = false;
buf : 		ibev.event = IB_EVENT_DEVICE_FATAL;
buf : 		break;
buf : 
buf : 	case MLX5_DEV_EVENT_PORT_UP:
buf : 		ibev.event = IB_EVENT_PORT_ACTIVE;
buf : 		port = *(u8 *)data;
buf : 		break;
buf : 
buf : 	case MLX5_DEV_EVENT_PORT_DOWN:
buf : 		ibev.event = IB_EVENT_PORT_ERR;
buf : 		port = *(u8 *)data;
buf : 		break;
buf : 
buf : 	case MLX5_DEV_EVENT_PORT_INITIALIZED:
buf : 		/* not used by ULPs */
buf : 		return;
buf : 
buf : 	case MLX5_DEV_EVENT_LID_CHANGE:
buf : 		ibev.event = IB_EVENT_LID_CHANGE;
buf : 		port = *(u8 *)data;
buf : 		break;
buf : 
buf : 	case MLX5_DEV_EVENT_PKEY_CHANGE:
buf : 		ibev.event = IB_EVENT_PKEY_CHANGE;
buf : 		port = *(u8 *)data;
buf : 		break;
buf : 
buf : 	case MLX5_DEV_EVENT_GUID_CHANGE:
buf : 		ibev.event = IB_EVENT_GID_CHANGE;
buf : 		port = *(u8 *)data;
buf : 		break;
buf : 
buf : 	case MLX5_DEV_EVENT_CLIENT_REREG:
buf : 		ibev.event = IB_EVENT_CLIENT_REREGISTER;
buf : 		port = *(u8 *)data;
buf : 		break;
buf : 	}
buf : 
buf : 	ibev.device	      = &ibdev->ib_dev;
buf : 	ibev.element.port_num = port;
buf : 
buf : 	if (port < 1 || port > ibdev->num_ports) {
if (port < 1 || port > ibdev->num_ports) { 
buf : 		mlx5_ib_warn(ibdev, "warning: event on port %d\n", port);
buf : 		return;
buf : 	}
buf : 
buf : 	if (ibdev->ib_active)
if (ibdev->ib_active) 
buf : 		ib_dispatch_event(&ibev);
buf : }
buf : 
buf : static void get_ext_port_caps(struct mlx5_ib_dev *dev)
buf : {
buf : 	int port;
buf : 
buf : 	for (port = 1; port <= dev->mdev.caps.num_ports; port++)
for (port = 1; port <= dev->mdev.caps.num_ports; port++) 
buf : 		mlx5_query_ext_port_caps(dev, port);
buf : }
buf : 
buf : static int get_port_caps(struct mlx5_ib_dev *dev)
buf : {
buf : 	struct ib_device_attr *dprops = NULL;
buf : 	struct ib_port_attr *pprops = NULL;
buf : 	int err = 0;
buf : 	int port;
buf : 
buf : 	pprops = kmalloc(sizeof(*pprops), GFP_KERNEL);
buf : 	if (!pprops)
if (!pprops) 
buf : 		goto out;
buf : 
buf : 	dprops = kmalloc(sizeof(*dprops), GFP_KERNEL);
buf : 	if (!dprops)
if (!dprops) 
buf : 		goto out;
buf : 
buf : 	err = mlx5_ib_query_device(&dev->ib_dev, dprops);
buf : 	if (err) {
if (err) { 
buf : 		mlx5_ib_warn(dev, "query_device failed %d\n", err);
buf : 		goto out;
buf : 	}
buf : 
buf : 	for (port = 1; port <= dev->mdev.caps.num_ports; port++) {
for (port = 1; port <= dev->mdev.caps.num_ports; port++) { 
buf : 		err = mlx5_ib_query_port(&dev->ib_dev, port, pprops);
buf : 		if (err) {
if (err) { 
buf : 			mlx5_ib_warn(dev, "query_port %d failed %d\n", port, err);
buf : 			break;
buf : 		}
buf : 		dev->mdev.caps.port[port - 1].pkey_table_len = dprops->max_pkeys;
buf : 		dev->mdev.caps.port[port - 1].gid_table_len = pprops->gid_tbl_len;
buf : 		mlx5_ib_dbg(dev, "pkey_table_len %d, gid_table_len %d\n",
buf : 			    dprops->max_pkeys, pprops->gid_tbl_len);
buf : 	}
buf : 
buf : out:
buf : 	kfree(pprops);
buf : 	kfree(dprops);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void destroy_umrc_res(struct mlx5_ib_dev *dev)
buf : {
buf : 	int err;
buf : 
buf : 	err = mlx5_mr_cache_cleanup(dev);
buf : 	if (err)
if (err) 
buf : 		mlx5_ib_warn(dev, "mr cache cleanup failed\n");
buf : 
buf : 	mlx5_ib_destroy_qp(dev->umrc.qp);
buf : 	ib_destroy_cq(dev->umrc.cq);
buf : 	ib_dereg_mr(dev->umrc.mr);
buf : 	ib_dealloc_pd(dev->umrc.pd);
buf : }
buf : 
buf : enum {
buf : 	MAX_UMR_WR = 128,
buf : };
buf : 
buf : static int create_umr_res(struct mlx5_ib_dev *dev)
buf : {
buf : 	struct ib_qp_init_attr *init_attr = NULL;
buf : 	struct ib_qp_attr *attr = NULL;
buf : 	struct ib_pd *pd;
buf : 	struct ib_cq *cq;
buf : 	struct ib_qp *qp;
buf : 	struct ib_mr *mr;
buf : 	int ret;
buf : 
buf : 	attr = kzalloc(sizeof(*attr), GFP_KERNEL);
buf : 	init_attr = kzalloc(sizeof(*init_attr), GFP_KERNEL);
buf : 	if (!attr || !init_attr) {
if (!attr || !init_attr) { 
buf : 		ret = -ENOMEM;
buf : 		goto error_0;
buf : 	}
buf : 
buf : 	pd = ib_alloc_pd(&dev->ib_dev);
buf : 	if (IS_ERR(pd)) {
if (IS_ERR(pd)) { 
buf : 		mlx5_ib_dbg(dev, "Couldn't create PD for sync UMR QP\n");
for sync UMR QP\n"); 
buf : 		ret = PTR_ERR(pd);
buf : 		goto error_0;
buf : 	}
buf : 
buf : 	mr = ib_get_dma_mr(pd,  IB_ACCESS_LOCAL_WRITE);
buf : 	if (IS_ERR(mr)) {
if (IS_ERR(mr)) { 
buf : 		mlx5_ib_dbg(dev, "Couldn't create DMA MR for sync UMR QP\n");
for sync UMR QP\n"); 
buf : 		ret = PTR_ERR(mr);
buf : 		goto error_1;
buf : 	}
buf : 
buf : 	cq = ib_create_cq(&dev->ib_dev, mlx5_umr_cq_handler, NULL, NULL, 128,
buf : 			  0);
buf : 	if (IS_ERR(cq)) {
if (IS_ERR(cq)) { 
buf : 		mlx5_ib_dbg(dev, "Couldn't create CQ for sync UMR QP\n");
for sync UMR QP\n"); 
buf : 		ret = PTR_ERR(cq);
buf : 		goto error_2;
buf : 	}
buf : 	ib_req_notify_cq(cq, IB_CQ_NEXT_COMP);
ify_cq(cq, IB_CQ_NEXT_COMP); 
buf : 
buf : 	init_attr->send_cq = cq;
buf : 	init_attr->recv_cq = cq;
buf : 	init_attr->sq_sig_type = IB_SIGNAL_ALL_WR;
buf : 	init_attr->cap.max_send_wr = MAX_UMR_WR;
buf : 	init_attr->cap.max_send_sge = 1;
buf : 	init_attr->qp_type = MLX5_IB_QPT_REG_UMR;
buf : 	init_attr->port_num = 1;
buf : 	qp = mlx5_ib_create_qp(pd, init_attr, NULL);
buf : 	if (IS_ERR(qp)) {
if (IS_ERR(qp)) { 
buf : 		mlx5_ib_dbg(dev, "Couldn't create sync UMR QP\n");
buf : 		ret = PTR_ERR(qp);
buf : 		goto error_3;
buf : 	}
buf : 	qp->device     = &dev->ib_dev;
buf : 	qp->real_qp    = qp;
buf : 	qp->uobject    = NULL;
buf : 	qp->qp_type    = MLX5_IB_QPT_REG_UMR;
buf : 
buf : 	attr->qp_state = IB_QPS_INIT;
buf : 	attr->port_num = 1;
buf : 	ret = mlx5_ib_modify_qp(qp, attr, IB_QP_STATE | IB_QP_PKEY_INDEX |
ify_qp(qp, attr, IB_QP_STATE | IB_QP_PKEY_INDEX | 
buf : 				IB_QP_PORT, NULL);
buf : 	if (ret) {
if (ret) { 
buf : 		mlx5_ib_dbg(dev, "Couldn't modify UMR QP\n");
buf : 		goto error_4;
buf : 	}
buf : 
buf : 	memset(attr, 0, sizeof(*attr));
buf : 	attr->qp_state = IB_QPS_RTR;
buf : 	attr->path_mtu = IB_MTU_256;
buf : 
buf : 	ret = mlx5_ib_modify_qp(qp, attr, IB_QP_STATE, NULL);
ify_qp(qp, attr, IB_QP_STATE, NULL); 
buf : 	if (ret) {
buf : 		mlx5_ib_dbg(dev, "Couldn't modify umr QP to rtr\n");
ify umr QP to rtr\n"); 
buf : 		goto error_4;
buf : 	}
buf : 
buf : 	memset(attr, 0, sizeof(*attr));
buf : 	attr->qp_state = IB_QPS_RTS;
buf : 	ret = mlx5_ib_modify_qp(qp, attr, IB_QP_STATE, NULL);
ify_qp(qp, attr, IB_QP_STATE, NULL); 
buf : 	if (ret) {
buf : 		mlx5_ib_dbg(dev, "Couldn't modify umr QP to rts\n");
ify umr QP to rts\n"); 
buf : 		goto error_4;
buf : 	}
buf : 
buf : 	dev->umrc.qp = qp;
buf : 	dev->umrc.cq = cq;
buf : 	dev->umrc.mr = mr;
buf : 	dev->umrc.pd = pd;
buf : 
buf : 	sema_init(&dev->umrc.sem, MAX_UMR_WR);
buf : 	ret = mlx5_mr_cache_init(dev);
buf : 	if (ret) {
if (ret) { 
buf : 		mlx5_ib_warn(dev, "mr cache init failed %d\n", ret);
buf : 		goto error_4;
buf : 	}
buf : 
buf : 	kfree(attr);
buf : 	kfree(init_attr);
buf : 
buf : 	return 0;
buf : 
buf : error_4:
buf : 	mlx5_ib_destroy_qp(qp);
buf : 
buf : error_3:
buf : 	ib_destroy_cq(cq);
buf : 
buf : error_2:
buf : 	ib_dereg_mr(mr);
buf : 
buf : error_1:
buf : 	ib_dealloc_pd(pd);
buf : 
buf : error_0:
buf : 	kfree(attr);
buf : 	kfree(init_attr);
buf : 	return ret;
buf : }
buf : 
buf : static int create_dev_resources(struct mlx5_ib_resources *devr)
buf : {
buf : 	struct ib_srq_init_attr attr;
buf : 	struct mlx5_ib_dev *dev;
buf : 	int ret = 0;
buf : 
buf : 	dev = container_of(devr, struct mlx5_ib_dev, devr);
buf : 
buf : 	devr->p0 = mlx5_ib_alloc_pd(&dev->ib_dev, NULL, NULL);
buf : 	if (IS_ERR(devr->p0)) {
if (IS_ERR(devr->p0)) { 
buf : 		ret = PTR_ERR(devr->p0);
buf : 		goto error0;
buf : 	}
buf : 	devr->p0->device  = &dev->ib_dev;
buf : 	devr->p0->uobject = NULL;
buf : 	atomic_set(&devr->p0->usecnt, 0);
buf : 
buf : 	devr->c0 = mlx5_ib_create_cq(&dev->ib_dev, 1, 0, NULL, NULL);
buf : 	if (IS_ERR(devr->c0)) {
if (IS_ERR(devr->c0)) { 
buf : 		ret = PTR_ERR(devr->c0);
buf : 		goto error1;
buf : 	}
buf : 	devr->c0->device        = &dev->ib_dev;
buf : 	devr->c0->uobject       = NULL;
buf : 	devr->c0->comp_handler  = NULL;
buf : 	devr->c0->event_handler = NULL;
buf : 	devr->c0->cq_context    = NULL;
buf : 	atomic_set(&devr->c0->usecnt, 0);
buf : 
buf : 	devr->x0 = mlx5_ib_alloc_xrcd(&dev->ib_dev, NULL, NULL);
buf : 	if (IS_ERR(devr->x0)) {
if (IS_ERR(devr->x0)) { 
buf : 		ret = PTR_ERR(devr->x0);
buf : 		goto error2;
buf : 	}
buf : 	devr->x0->device = &dev->ib_dev;
buf : 	devr->x0->inode = NULL;
buf : 	atomic_set(&devr->x0->usecnt, 0);
buf : 	mutex_init(&devr->x0->tgt_qp_mutex);
buf : 	INIT_LIST_HEAD(&devr->x0->tgt_qp_list);
buf : 
buf : 	devr->x1 = mlx5_ib_alloc_xrcd(&dev->ib_dev, NULL, NULL);
buf : 	if (IS_ERR(devr->x1)) {
if (IS_ERR(devr->x1)) { 
buf : 		ret = PTR_ERR(devr->x1);
buf : 		goto error3;
buf : 	}
buf : 	devr->x1->device = &dev->ib_dev;
buf : 	devr->x1->inode = NULL;
buf : 	atomic_set(&devr->x1->usecnt, 0);
buf : 	mutex_init(&devr->x1->tgt_qp_mutex);
buf : 	INIT_LIST_HEAD(&devr->x1->tgt_qp_list);
buf : 
buf : 	memset(&attr, 0, sizeof(attr));
buf : 	attr.attr.max_sge = 1;
buf : 	attr.attr.max_wr = 1;
buf : 	attr.srq_type = IB_SRQT_XRC;
buf : 	attr.ext.xrc.cq = devr->c0;
buf : 	attr.ext.xrc.xrcd = devr->x0;
buf : 
buf : 	devr->s0 = mlx5_ib_create_srq(devr->p0, &attr, NULL);
buf : 	if (IS_ERR(devr->s0)) {
if (IS_ERR(devr->s0)) { 
buf : 		ret = PTR_ERR(devr->s0);
buf : 		goto error4;
buf : 	}
buf : 	devr->s0->device	= &dev->ib_dev;
buf : 	devr->s0->pd		= devr->p0;
buf : 	devr->s0->uobject       = NULL;
buf : 	devr->s0->event_handler = NULL;
buf : 	devr->s0->srq_context   = NULL;
buf : 	devr->s0->srq_type      = IB_SRQT_XRC;
buf : 	devr->s0->ext.xrc.xrcd	= devr->x0;
buf : 	devr->s0->ext.xrc.cq	= devr->c0;
buf : 	atomic_inc(&devr->s0->ext.xrc.xrcd->usecnt);
buf : 	atomic_inc(&devr->s0->ext.xrc.cq->usecnt);
buf : 	atomic_inc(&devr->p0->usecnt);
buf : 	atomic_set(&devr->s0->usecnt, 0);
buf : 
buf : 	return 0;
buf : 
buf : error4:
buf : 	mlx5_ib_dealloc_xrcd(devr->x1);
buf : error3:
buf : 	mlx5_ib_dealloc_xrcd(devr->x0);
buf : error2:
buf : 	mlx5_ib_destroy_cq(devr->c0);
buf : error1:
buf : 	mlx5_ib_dealloc_pd(devr->p0);
buf : error0:
buf : 	return ret;
buf : }
buf : 
buf : static void destroy_dev_resources(struct mlx5_ib_resources *devr)
buf : {
buf : 	mlx5_ib_destroy_srq(devr->s0);
buf : 	mlx5_ib_dealloc_xrcd(devr->x0);
buf : 	mlx5_ib_dealloc_xrcd(devr->x1);
buf : 	mlx5_ib_destroy_cq(devr->c0);
buf : 	mlx5_ib_dealloc_pd(devr->p0);
buf : }
buf : 
buf : static int init_one(struct pci_dev *pdev,
buf : 		    const struct pci_device_id *id)
buf : {
buf : 	struct mlx5_core_dev *mdev;
buf : 	struct mlx5_ib_dev *dev;
buf : 	int err;
buf : 	int i;
buf : 
buf : 	printk_once(KERN_INFO "%s", mlx5_version);
buf : 
buf : 	dev = (struct mlx5_ib_dev *)ib_alloc_device(sizeof(*dev));
buf : 	if (!dev)
if (!dev) 
buf : 		return -ENOMEM;
buf : 
buf : 	mdev = &dev->mdev;
buf : 	mdev->event = mlx5_ib_event;
buf : 	if (prof_sel >= ARRAY_SIZE(profile)) {
if (prof_sel >= ARRAY_SIZE(profile)) { 
buf : 		pr_warn("selected pofile out of range, selceting default\n");
buf : 		prof_sel = 0;
buf : 	}
buf : 	mdev->profile = &profile[prof_sel];
buf : 	err = mlx5_dev_init(mdev, pdev);
buf : 	if (err)
if (err) 
buf : 		goto err_free;
buf : 
buf : 	err = get_port_caps(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_cleanup;
buf : 
buf : 	get_ext_port_caps(dev);
buf : 
buf : 	err = alloc_comp_eqs(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_cleanup;
buf : 
buf : 	MLX5_INIT_DOORBELL_LOCK(&dev->uar_lock);
buf : 
buf : 	strlcpy(dev->ib_dev.name, "mlx5_%d", IB_DEVICE_NAME_MAX);
buf : 	dev->ib_dev.owner		= THIS_MODULE;
buf : 	dev->ib_dev.node_type		= RDMA_NODE_IB_CA;
buf : 	dev->ib_dev.local_dma_lkey	= mdev->caps.reserved_lkey;
buf : 	dev->num_ports		= mdev->caps.num_ports;
buf : 	dev->ib_dev.phys_port_cnt     = dev->num_ports;
buf : 	dev->ib_dev.num_comp_vectors	= dev->num_comp_vectors;
buf : 	dev->ib_dev.dma_device	= &mdev->pdev->dev;
buf : 
buf : 	dev->ib_dev.uverbs_abi_ver	= MLX5_IB_UVERBS_ABI_VERSION;
buf : 	dev->ib_dev.uverbs_cmd_mask	=
buf : 		(1ull << IB_USER_VERBS_CMD_GET_CONTEXT)		|
buf : 		(1ull << IB_USER_VERBS_CMD_QUERY_DEVICE)	|
buf : 		(1ull << IB_USER_VERBS_CMD_QUERY_PORT)		|
buf : 		(1ull << IB_USER_VERBS_CMD_ALLOC_PD)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DEALLOC_PD)		|
buf : 		(1ull << IB_USER_VERBS_CMD_REG_MR)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DEREG_MR)		|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_COMP_CHANNEL)	|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_CQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_RESIZE_CQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DESTROY_CQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_QP)		|
buf : 		(1ull << IB_USER_VERBS_CMD_MODIFY_QP)		|
buf : 		(1ull << IB_USER_VERBS_CMD_QUERY_QP)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DESTROY_QP)		|
buf : 		(1ull << IB_USER_VERBS_CMD_ATTACH_MCAST)	|
buf : 		(1ull << IB_USER_VERBS_CMD_DETACH_MCAST)	|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_SRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_MODIFY_SRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_QUERY_SRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DESTROY_SRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_XSRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_OPEN_QP);
buf : 
buf : 	dev->ib_dev.query_device	= mlx5_ib_query_device;
buf : 	dev->ib_dev.query_port		= mlx5_ib_query_port;
buf : 	dev->ib_dev.query_gid		= mlx5_ib_query_gid;
buf : 	dev->ib_dev.query_pkey		= mlx5_ib_query_pkey;
buf : 	dev->ib_dev.modify_device	= mlx5_ib_modify_device;
ify_device	= mlx5_ib_modify_device; 
buf : 	dev->ib_dev.modify_port		= mlx5_ib_modify_port;
buf : 	dev->ib_dev.alloc_ucontext	= mlx5_ib_alloc_ucontext;
buf : 	dev->ib_dev.dealloc_ucontext	= mlx5_ib_dealloc_ucontext;
buf : 	dev->ib_dev.mmap		= mlx5_ib_mmap;
buf : 	dev->ib_dev.alloc_pd		= mlx5_ib_alloc_pd;
buf : 	dev->ib_dev.dealloc_pd		= mlx5_ib_dealloc_pd;
buf : 	dev->ib_dev.create_ah		= mlx5_ib_create_ah;
buf : 	dev->ib_dev.query_ah		= mlx5_ib_query_ah;
buf : 	dev->ib_dev.destroy_ah		= mlx5_ib_destroy_ah;
buf : 	dev->ib_dev.create_srq		= mlx5_ib_create_srq;
buf : 	dev->ib_dev.modify_srq		= mlx5_ib_modify_srq;
ify_srq		= mlx5_ib_modify_srq; 
buf : 	dev->ib_dev.query_srq		= mlx5_ib_query_srq;
buf : 	dev->ib_dev.destroy_srq		= mlx5_ib_destroy_srq;
buf : 	dev->ib_dev.post_srq_recv	= mlx5_ib_post_srq_recv;
buf : 	dev->ib_dev.create_qp		= mlx5_ib_create_qp;
buf : 	dev->ib_dev.modify_qp		= mlx5_ib_modify_qp;
ify_qp		= mlx5_ib_modify_qp; 
buf : 	dev->ib_dev.query_qp		= mlx5_ib_query_qp;
buf : 	dev->ib_dev.destroy_qp		= mlx5_ib_destroy_qp;
buf : 	dev->ib_dev.post_send		= mlx5_ib_post_send;
buf : 	dev->ib_dev.post_recv		= mlx5_ib_post_recv;
buf : 	dev->ib_dev.create_cq		= mlx5_ib_create_cq;
buf : 	dev->ib_dev.modify_cq		= mlx5_ib_modify_cq;
ify_cq		= mlx5_ib_modify_cq; 
buf : 	dev->ib_dev.resize_cq		= mlx5_ib_resize_cq;
buf : 	dev->ib_dev.destroy_cq		= mlx5_ib_destroy_cq;
buf : 	dev->ib_dev.poll_cq		= mlx5_ib_poll_cq;
buf : 	dev->ib_dev.req_notify_cq	= mlx5_ib_arm_cq;
ify_cq	= mlx5_ib_arm_cq; 
buf : 	dev->ib_dev.get_dma_mr		= mlx5_ib_get_dma_mr;
buf : 	dev->ib_dev.reg_user_mr		= mlx5_ib_reg_user_mr;
buf : 	dev->ib_dev.dereg_mr		= mlx5_ib_dereg_mr;
buf : 	dev->ib_dev.destroy_mr		= mlx5_ib_destroy_mr;
buf : 	dev->ib_dev.attach_mcast	= mlx5_ib_mcg_attach;
buf : 	dev->ib_dev.detach_mcast	= mlx5_ib_mcg_detach;
buf : 	dev->ib_dev.process_mad		= mlx5_ib_process_mad;
buf : 	dev->ib_dev.create_mr		= mlx5_ib_create_mr;
buf : 	dev->ib_dev.alloc_fast_reg_mr	= mlx5_ib_alloc_fast_reg_mr;
buf : 	dev->ib_dev.alloc_fast_reg_page_list = mlx5_ib_alloc_fast_reg_page_list;
buf : 	dev->ib_dev.free_fast_reg_page_list  = mlx5_ib_free_fast_reg_page_list;
buf : 	dev->ib_dev.check_mr_status	= mlx5_ib_check_mr_status;
buf : 
buf : 	if (mdev->caps.flags & MLX5_DEV_CAP_FLAG_XRC) {
if (mdev->caps.flags & MLX5_DEV_CAP_FLAG_XRC) { 
buf : 		dev->ib_dev.alloc_xrcd = mlx5_ib_alloc_xrcd;
buf : 		dev->ib_dev.dealloc_xrcd = mlx5_ib_dealloc_xrcd;
buf : 		dev->ib_dev.uverbs_cmd_mask |=
buf : 			(1ull << IB_USER_VERBS_CMD_OPEN_XRCD) |
buf : 			(1ull << IB_USER_VERBS_CMD_CLOSE_XRCD);
buf : 	}
buf : 
buf : 	err = init_node_data(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_eqs;
buf : 
buf : 	mutex_init(&dev->cap_mask_mutex);
buf : 	spin_lock_init(&dev->mr_lock);
buf : 
buf : 	err = create_dev_resources(&dev->devr);
buf : 	if (err)
if (err) 
buf : 		goto err_eqs;
buf : 
buf : 	err = ib_register_device(&dev->ib_dev, NULL);
buf : 	if (err)
if (err) 
buf : 		goto err_rsrc;
buf : 
buf : 	err = create_umr_res(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_dev;
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(mlx5_class_attributes); i++) {
for (i = 0; i < ARRAY_SIZE(mlx5_class_attributes); i++) { 
buf : 		err = device_create_file(&dev->ib_dev.dev,
buf : 					 mlx5_class_attributes[i]);
buf : 		if (err)
if (err) 
buf : 			goto err_umrc;
buf : 	}
buf : 
buf : 	dev->ib_active = true;
buf : 
buf : 	return 0;
buf : 
buf : err_umrc:
buf : 	destroy_umrc_res(dev);
buf : 
buf : err_dev:
buf : 	ib_unregister_device(&dev->ib_dev);
buf : 
buf : err_rsrc:
buf : 	destroy_dev_resources(&dev->devr);
buf : 
buf : err_eqs:
buf : 	free_comp_eqs(dev);
buf : 
buf : err_cleanup:
buf : 	mlx5_dev_cleanup(mdev);
buf : 
buf : err_free:
buf : 	ib_dealloc_device((struct ib_device *)dev);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void remove_one(struct pci_dev *pdev)
buf : {
buf : 	struct mlx5_ib_dev *dev = mlx5_pci2ibdev(pdev);
buf : 
buf : 	destroy_umrc_res(dev);
buf : 	ib_unregister_device(&dev->ib_dev);
buf : 	destroy_dev_resources(&dev->devr);
buf : 	free_comp_eqs(dev);
buf : 	mlx5_dev_cleanup(&dev->mdev);
buf : 	ib_dealloc_device(&dev->ib_dev);
buf : }
buf : 
buf : static DEFINE_PCI_DEVICE_TABLE(mlx5_ib_pci_table) = {
buf : 	{ PCI_VDEVICE(MELLANOX, 4113) }, /* MT4113 Connect-IB */
buf : 	{ 0, }
buf : };
buf : 
buf : MODULE_DEVICE_TABLE(pci, mlx5_ib_pci_table);
buf : 
buf : static struct pci_driver mlx5_ib_driver = {
buf : 	.name		= DRIVER_NAME,
buf : 	.id_table	= mlx5_ib_pci_table,
buf : 	.probe		= init_one,
buf : 	.remove		= remove_one
buf : };
buf : 
buf : static int __init mlx5_ib_init(void)
buf : {
buf : 	return pci_register_driver(&mlx5_ib_driver);
buf : }
buf : 
buf : static void __exit mlx5_ib_cleanup(void)
buf : {
buf : 	pci_unregister_driver(&mlx5_ib_driver);
buf : }
buf : 
buf : module_init(mlx5_ib_init);
buf : module_exit(mlx5_ib_cleanup);
file : ./test/kernel/drivers/infiniband/hw/mlx4/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2006, 2007 Cisco Systems, Inc. All rights reserved.
buf :  * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.
buf :  *
buf :  * This software is available to you under a choice of one of two
buf :  * licenses.  You may choose to be licensed under the terms of the GNU
buf :  * General Public License (GPL) Version 2, available from the file
buf :  * COPYING in the main directory of this source tree, or the
buf :  * OpenIB.org BSD license below:
buf :  *
buf :  *     Redistribution and use in source and binary forms, with or
forms, with or 
buf :  *     without modification, are permitted provided that the following
buf :  *     conditions are met:
buf :  *
buf :  *      - Redistributions of source code must retain the above
buf :  *        copyright notice, this list of conditions and the following
buf :  *        disclaimer.
buf :  *
buf :  *      - Redistributions in binary form must reproduce the above
form must reproduce the above 
buf :  *        copyright notice, this list of conditions and the following
buf :  *        disclaimer in the documentation and/or other materials
buf :  *        provided with the distribution.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
buf :  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
buf :  * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
buf :  * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
buf :  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
buf :  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
buf :  * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
buf :  * SOFTWARE.
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/init.h>
buf : #include <linux/slab.h>
buf : #include <linux/errno.h>
buf : #include <linux/netdevice.h>
buf : #include <linux/inetdevice.h>
buf : #include <linux/rtnetlink.h>
buf : #include <linux/if_vlan.h>
if_vlan.h> 
buf : #include <net/ipv6.h>
buf : #include <net/addrconf.h>
buf : 
buf : #include <rdma/ib_smi.h>
buf : #include <rdma/ib_user_verbs.h>
buf : #include <rdma/ib_addr.h>
buf : 
buf : #include <linux/mlx4/driver.h>
buf : #include <linux/mlx4/cmd.h>
buf : #include <linux/mlx4/qp.h>
buf : 
buf : #include "mlx4_ib.h"
buf : #include "user.h"
buf : 
buf : #define DRV_NAME	MLX4_IB_DRV_NAME
buf : #define DRV_VERSION	"2.2-1"
buf : #define DRV_RELDATE	"Feb 2014"
buf : 
buf : #define MLX4_IB_FLOW_MAX_PRIO 0xFFF
buf : #define MLX4_IB_FLOW_QPN_MASK 0xFFFFFF
buf : 
buf : MODULE_AUTHOR("Roland Dreier");
buf : MODULE_DESCRIPTION("Mellanox ConnectX HCA InfiniBand driver");
buf : MODULE_LICENSE("Dual BSD/GPL");
buf : MODULE_VERSION(DRV_VERSION);
buf : 
buf : int mlx4_ib_sm_guid_assign = 1;
buf : module_param_named(sm_guid_assign, mlx4_ib_sm_guid_assign, int, 0444);
buf : MODULE_PARM_DESC(sm_guid_assign, "Enable SM alias_GUID assignment if sm_guid_assign > 0 (Default: 1)");
if sm_guid_assign > 0 (Default: 1)"); 
buf : 
buf : static const char mlx4_ib_version[] =
buf : 	DRV_NAME ": Mellanox ConnectX InfiniBand driver v"
buf : 	DRV_VERSION " (" DRV_RELDATE ")\n";
buf : 
buf : struct update_gid_work {
buf : 	struct work_struct	work;
buf : 	union ib_gid		gids[128];
buf : 	struct mlx4_ib_dev     *dev;
buf : 	int			port;
buf : };
buf : 
buf : static void do_slave_init(struct mlx4_ib_dev *ibdev, int slave, int do_init);
buf : 
buf : static struct workqueue_struct *wq;
buf : 
buf : static void init_query_mad(struct ib_smp *mad)
buf : {
buf : 	mad->base_version  = 1;
buf : 	mad->mgmt_class    = IB_MGMT_CLASS_SUBN_LID_ROUTED;
buf : 	mad->class_version = 1;
buf : 	mad->method	   = IB_MGMT_METHOD_GET;
buf : }
buf : 
buf : static union ib_gid zgid;
buf : 
buf : static int check_flow_steering_support(struct mlx4_dev *dev)
buf : {
buf : 	int eth_num_ports = 0;
buf : 	int ib_num_ports = 0;
buf : 
buf : 	int dmfs = dev->caps.steering_mode == MLX4_STEERING_MODE_DEVICE_MANAGED;
buf : 
buf : 	if (dmfs) {
if (dmfs) { 
buf : 		int i;
buf : 		mlx4_foreach_port(i, dev, MLX4_PORT_TYPE_ETH)
foreach_port(i, dev, MLX4_PORT_TYPE_ETH) 
buf : 			eth_num_ports++;
buf : 		mlx4_foreach_port(i, dev, MLX4_PORT_TYPE_IB)
foreach_port(i, dev, MLX4_PORT_TYPE_IB) 
buf : 			ib_num_ports++;
buf : 		dmfs &= (!ib_num_ports ||
buf : 			 (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_DMFS_IPOIB)) &&
buf : 			(!eth_num_ports ||
buf : 			 (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_FS_EN));
buf : 		if (ib_num_ports && mlx4_is_mfunc(dev)) {
if (ib_num_ports && mlx4_is_mfunc(dev)) { 
buf : 			pr_warn("Device managed flow steering is unavailable for IB port in multifunction env.\n");
for IB port in multifunction env.\n"); 
buf : 			dmfs = 0;
buf : 		}
buf : 	}
buf : 	return dmfs;
buf : }
buf : 
buf : static int mlx4_ib_query_device(struct ib_device *ibdev,
buf : 				struct ib_device_attr *props)
buf : {
buf : 	struct mlx4_ib_dev *dev = to_mdev(ibdev);
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int err = -ENOMEM;
buf : 
buf : 	in_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id = IB_SMP_ATTR_NODE_INFO;
buf : 
buf : 	err = mlx4_MAD_IFC(to_mdev(ibdev), MLX4_MAD_IFC_IGNORE_KEYS,
buf : 			   1, NULL, NULL, in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	memset(props, 0, sizeof *props);
buf : 
buf : 	props->fw_ver = dev->dev->caps.fw_ver;
buf : 	props->device_cap_flags    = IB_DEVICE_CHANGE_PHY_PORT |
buf : 		IB_DEVICE_PORT_ACTIVE_EVENT		|
buf : 		IB_DEVICE_SYS_IMAGE_GUID		|
buf : 		IB_DEVICE_RC_RNR_NAK_GEN		|
buf : 		IB_DEVICE_BLOCK_MULTICAST_LOOPBACK;
buf : 	if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_BAD_PKEY_CNTR)
if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_BAD_PKEY_CNTR) 
buf : 		props->device_cap_flags |= IB_DEVICE_BAD_PKEY_CNTR;
buf : 	if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_BAD_QKEY_CNTR)
if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_BAD_QKEY_CNTR) 
buf : 		props->device_cap_flags |= IB_DEVICE_BAD_QKEY_CNTR;
buf : 	if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_APM)
if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_APM) 
buf : 		props->device_cap_flags |= IB_DEVICE_AUTO_PATH_MIG;
buf : 	if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_UD_AV_PORT)
if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_UD_AV_PORT) 
buf : 		props->device_cap_flags |= IB_DEVICE_UD_AV_PORT_ENFORCE;
buf : 	if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_IPOIB_CSUM)
if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_IPOIB_CSUM) 
buf : 		props->device_cap_flags |= IB_DEVICE_UD_IP_CSUM;
buf : 	if (dev->dev->caps.max_gso_sz && dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_BLH)
if (dev->dev->caps.max_gso_sz && dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_BLH) 
buf : 		props->device_cap_flags |= IB_DEVICE_UD_TSO;
buf : 	if (dev->dev->caps.bmme_flags & MLX4_BMME_FLAG_RESERVED_LKEY)
if (dev->dev->caps.bmme_flags & MLX4_BMME_FLAG_RESERVED_LKEY) 
buf : 		props->device_cap_flags |= IB_DEVICE_LOCAL_DMA_LKEY;
buf : 	if ((dev->dev->caps.bmme_flags & MLX4_BMME_FLAG_LOCAL_INV) &&
if ((dev->dev->caps.bmme_flags & MLX4_BMME_FLAG_LOCAL_INV) && 
buf : 	    (dev->dev->caps.bmme_flags & MLX4_BMME_FLAG_REMOTE_INV) &&
buf : 	    (dev->dev->caps.bmme_flags & MLX4_BMME_FLAG_FAST_REG_WR))
buf : 		props->device_cap_flags |= IB_DEVICE_MEM_MGT_EXTENSIONS;
buf : 	if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_XRC)
if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_XRC) 
buf : 		props->device_cap_flags |= IB_DEVICE_XRC;
buf : 	if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_MEM_WINDOW)
if (dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_MEM_WINDOW) 
buf : 		props->device_cap_flags |= IB_DEVICE_MEM_WINDOW;
buf : 	if (dev->dev->caps.bmme_flags & MLX4_BMME_FLAG_TYPE_2_WIN) {
if (dev->dev->caps.bmme_flags & MLX4_BMME_FLAG_TYPE_2_WIN) { 
buf : 		if (dev->dev->caps.bmme_flags & MLX4_BMME_FLAG_WIN_TYPE_2B)
buf : 			props->device_cap_flags |= IB_DEVICE_MEM_WINDOW_TYPE_2B;
buf : 		else
buf : 			props->device_cap_flags |= IB_DEVICE_MEM_WINDOW_TYPE_2A;
buf : 	if (dev->steering_support ==  MLX4_STEERING_MODE_DEVICE_MANAGED)
if (dev->steering_support ==  MLX4_STEERING_MODE_DEVICE_MANAGED) 
buf : 		props->device_cap_flags |= IB_DEVICE_MANAGED_FLOW_STEERING;
buf : 	}
buf : 
buf : 	props->vendor_id	   = be32_to_cpup((__be32 *) (out_mad->data + 36)) &
buf : 		0xffffff;
buf : 	props->vendor_part_id	   = dev->dev->pdev->device;
buf : 	props->hw_ver		   = be32_to_cpup((__be32 *) (out_mad->data + 32));
buf : 	memcpy(&props->sys_image_guid, out_mad->data +	4, 8);
buf : 
buf : 	props->max_mr_size	   = ~0ull;
buf : 	props->page_size_cap	   = dev->dev->caps.page_size_cap;
buf : 	props->max_qp		   = dev->dev->quotas.qp;
buf : 	props->max_qp_wr	   = dev->dev->caps.max_wqes - MLX4_IB_SQ_MAX_SPARE;
buf : 	props->max_sge		   = min(dev->dev->caps.max_sq_sg,
buf : 					 dev->dev->caps.max_rq_sg);
buf : 	props->max_cq		   = dev->dev->quotas.cq;
buf : 	props->max_cqe		   = dev->dev->caps.max_cqes;
buf : 	props->max_mr		   = dev->dev->quotas.mpt;
buf : 	props->max_pd		   = dev->dev->caps.num_pds - dev->dev->caps.reserved_pds;
buf : 	props->max_qp_rd_atom	   = dev->dev->caps.max_qp_dest_rdma;
buf : 	props->max_qp_init_rd_atom = dev->dev->caps.max_qp_init_rdma;
buf : 	props->max_res_rd_atom	   = props->max_qp_rd_atom * props->max_qp;
buf : 	props->max_srq		   = dev->dev->quotas.srq;
buf : 	props->max_srq_wr	   = dev->dev->caps.max_srq_wqes - 1;
buf : 	props->max_srq_sge	   = dev->dev->caps.max_srq_sge;
buf : 	props->max_fast_reg_page_list_len = MLX4_MAX_FAST_REG_PAGES;
buf : 	props->local_ca_ack_delay  = dev->dev->caps.local_ca_ack_delay;
buf : 	props->atomic_cap	   = dev->dev->caps.flags & MLX4_DEV_CAP_FLAG_ATOMIC ?
buf : 		IB_ATOMIC_HCA : IB_ATOMIC_NONE;
buf : 	props->masked_atomic_cap   = props->atomic_cap;
buf : 	props->max_pkeys	   = dev->dev->caps.pkey_table_len[1];
buf : 	props->max_mcast_grp	   = dev->dev->caps.num_mgms + dev->dev->caps.num_amgms;
buf : 	props->max_mcast_qp_attach = dev->dev->caps.num_qp_per_mgm;
buf : 	props->max_total_mcast_qp_attach = props->max_mcast_qp_attach *
buf : 					   props->max_mcast_grp;
buf : 	props->max_map_per_fmr = dev->dev->caps.max_fmr_maps;
buf : 
buf : out:
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static enum rdma_link_layer
buf : mlx4_ib_port_link_layer(struct ib_device *device, u8 port_num)
buf : {
buf : 	struct mlx4_dev *dev = to_mdev(device)->dev;
buf : 
buf : 	return dev->caps.port_mask[port_num] == MLX4_PORT_TYPE_IB ?
buf : 		IB_LINK_LAYER_INFINIBAND : IB_LINK_LAYER_ETHERNET;
buf : }
buf : 
buf : static int ib_link_query_port(struct ib_device *ibdev, u8 port,
buf : 			      struct ib_port_attr *props, int netw_view)
buf : {
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int ext_active_speed;
buf : 	int mad_ifc_flags = MLX4_MAD_IFC_IGNORE_KEYS;
ifc_flags = MLX4_MAD_IFC_IGNORE_KEYS; 
buf : 	int err = -ENOMEM;
buf : 
buf : 	in_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id  = IB_SMP_ATTR_PORT_INFO;
buf : 	in_mad->attr_mod = cpu_to_be32(port);
buf : 
buf : 	if (mlx4_is_mfunc(to_mdev(ibdev)->dev) && netw_view)
if (mlx4_is_mfunc(to_mdev(ibdev)->dev) && netw_view) 
buf : 		mad_ifc_flags |= MLX4_MAD_IFC_NET_VIEW;
buf : 
buf : 	err = mlx4_MAD_IFC(to_mdev(ibdev), mad_ifc_flags, port, NULL, NULL,
ifc_flags, port, NULL, NULL, 
buf : 				in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 
buf : 	props->lid		= be16_to_cpup((__be16 *) (out_mad->data + 16));
buf : 	props->lmc		= out_mad->data[34] & 0x7;
buf : 	props->sm_lid		= be16_to_cpup((__be16 *) (out_mad->data + 18));
buf : 	props->sm_sl		= out_mad->data[36] & 0xf;
buf : 	props->state		= out_mad->data[32] & 0xf;
buf : 	props->phys_state	= out_mad->data[33] >> 4;
buf : 	props->port_cap_flags	= be32_to_cpup((__be32 *) (out_mad->data + 20));
buf : 	if (netw_view)
if (netw_view) 
buf : 		props->gid_tbl_len = out_mad->data[50];
buf : 	else
buf : 		props->gid_tbl_len = to_mdev(ibdev)->dev->caps.gid_table_len[port];
buf : 	props->max_msg_sz	= to_mdev(ibdev)->dev->caps.max_msg_sz;
buf : 	props->pkey_tbl_len	= to_mdev(ibdev)->dev->caps.pkey_table_len[port];
buf : 	props->bad_pkey_cntr	= be16_to_cpup((__be16 *) (out_mad->data + 46));
buf : 	props->qkey_viol_cntr	= be16_to_cpup((__be16 *) (out_mad->data + 48));
buf : 	props->active_width	= out_mad->data[31] & 0xf;
buf : 	props->active_speed	= out_mad->data[35] >> 4;
buf : 	props->max_mtu		= out_mad->data[41] & 0xf;
buf : 	props->active_mtu	= out_mad->data[36] >> 4;
buf : 	props->subnet_timeout	= out_mad->data[51] & 0x1f;
buf : 	props->max_vl_num	= out_mad->data[37] >> 4;
buf : 	props->init_type_reply	= out_mad->data[41] >> 4;
buf : 
buf : 	/* Check if extended speeds (EDR/FDR/...) are supported */
if extended speeds (EDR/FDR/...) are supported */ 
buf : 	if (props->port_cap_flags & IB_PORT_EXTENDED_SPEEDS_SUP) {
buf : 		ext_active_speed = out_mad->data[62] >> 4;
buf : 
buf : 		switch (ext_active_speed) {
buf : 		case 1:
buf : 			props->active_speed = IB_SPEED_FDR;
buf : 			break;
buf : 		case 2:
buf : 			props->active_speed = IB_SPEED_EDR;
buf : 			break;
buf : 		}
buf : 	}
buf : 
buf : 	/* If reported active speed is QDR, check if is FDR-10 */
if is FDR-10 */ 
buf : 	if (props->active_speed == IB_SPEED_QDR) {
buf : 		init_query_mad(in_mad);
buf : 		in_mad->attr_id = MLX4_ATTR_EXTENDED_PORT_INFO;
buf : 		in_mad->attr_mod = cpu_to_be32(port);
buf : 
buf : 		err = mlx4_MAD_IFC(to_mdev(ibdev), mad_ifc_flags, port,
ifc_flags, port, 
buf : 				   NULL, NULL, in_mad, out_mad);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 
buf : 		/* Checking LinkSpeedActive for FDR-10 */
for FDR-10 */ 
buf : 		if (out_mad->data[15] & 0x1)
buf : 			props->active_speed = IB_SPEED_FDR10;
buf : 	}
buf : 
buf : 	/* Avoid wrong speed value returned by FW if the IB link is down. */
if the IB link is down. */ 
buf : 	if (props->state == IB_PORT_DOWN)
buf : 		 props->active_speed = IB_SPEED_SDR;
buf : 
buf : out:
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 	return err;
buf : }
buf : 
buf : static u8 state_to_phys_state(enum ib_port_state state)
buf : {
buf : 	return state == IB_PORT_ACTIVE ? 5 : 3;
buf : }
buf : 
buf : static int eth_link_query_port(struct ib_device *ibdev, u8 port,
buf : 			       struct ib_port_attr *props, int netw_view)
buf : {
buf : 
buf : 	struct mlx4_ib_dev *mdev = to_mdev(ibdev);
buf : 	struct mlx4_ib_iboe *iboe = &mdev->iboe;
buf : 	struct net_device *ndev;
buf : 	enum ib_mtu tmp;
buf : 	struct mlx4_cmd_mailbox *mailbox;
buf : 	int err = 0;
buf : 
buf : 	mailbox = mlx4_alloc_cmd_mailbox(mdev->dev);
buf : 	if (IS_ERR(mailbox))
if (IS_ERR(mailbox)) 
buf : 		return PTR_ERR(mailbox);
buf : 
buf : 	err = mlx4_cmd_box(mdev->dev, 0, mailbox->dma, port, 0,
buf : 			   MLX4_CMD_QUERY_PORT, MLX4_CMD_TIME_CLASS_B,
buf : 			   MLX4_CMD_WRAPPED);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	props->active_width	=  (((u8 *)mailbox->buf)[5] == 0x40) ?
buf : 						IB_WIDTH_4X : IB_WIDTH_1X;
buf : 	props->active_speed	= IB_SPEED_QDR;
buf : 	props->port_cap_flags	= IB_PORT_CM_SUP | IB_PORT_IP_BASED_GIDS;
buf : 	props->gid_tbl_len	= mdev->dev->caps.gid_table_len[port];
buf : 	props->max_msg_sz	= mdev->dev->caps.max_msg_sz;
buf : 	props->pkey_tbl_len	= 1;
buf : 	props->max_mtu		= IB_MTU_4096;
buf : 	props->max_vl_num	= 2;
buf : 	props->state		= IB_PORT_DOWN;
buf : 	props->phys_state	= state_to_phys_state(props->state);
buf : 	props->active_mtu	= IB_MTU_256;
buf : 	spin_lock(&iboe->lock);
buf : 	ndev = iboe->netdevs[port - 1];
buf : 	if (!ndev)
if (!ndev) 
buf : 		goto out_unlock;
buf : 
buf : 	tmp = iboe_get_mtu(ndev->mtu);
buf : 	props->active_mtu = tmp ? min(props->max_mtu, tmp) : IB_MTU_256;
buf : 
buf : 	props->state		= (netif_running(ndev) && netif_carrier_ok(ndev)) ?
if_running(ndev) && netif_carrier_ok(ndev)) ? 
buf : 					IB_PORT_ACTIVE : IB_PORT_DOWN;
buf : 	props->phys_state	= state_to_phys_state(props->state);
buf : out_unlock:
buf : 	spin_unlock(&iboe->lock);
buf : out:
buf : 	mlx4_free_cmd_mailbox(mdev->dev, mailbox);
buf : 	return err;
buf : }
buf : 
buf : int __mlx4_ib_query_port(struct ib_device *ibdev, u8 port,
buf : 			 struct ib_port_attr *props, int netw_view)
buf : {
buf : 	int err;
buf : 
buf : 	memset(props, 0, sizeof *props);
buf : 
buf : 	err = mlx4_ib_port_link_layer(ibdev, port) == IB_LINK_LAYER_INFINIBAND ?
buf : 		ib_link_query_port(ibdev, port, props, netw_view) :
buf : 				eth_link_query_port(ibdev, port, props, netw_view);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int mlx4_ib_query_port(struct ib_device *ibdev, u8 port,
buf : 			      struct ib_port_attr *props)
buf : {
buf : 	/* returns host view */
buf : 	return __mlx4_ib_query_port(ibdev, port, props, 0);
buf : }
buf : 
buf : int __mlx4_ib_query_gid(struct ib_device *ibdev, u8 port, int index,
buf : 			union ib_gid *gid, int netw_view)
buf : {
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int err = -ENOMEM;
buf : 	struct mlx4_ib_dev *dev = to_mdev(ibdev);
buf : 	int clear = 0;
buf : 	int mad_ifc_flags = MLX4_MAD_IFC_IGNORE_KEYS;
ifc_flags = MLX4_MAD_IFC_IGNORE_KEYS; 
buf : 
buf : 	in_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id  = IB_SMP_ATTR_PORT_INFO;
buf : 	in_mad->attr_mod = cpu_to_be32(port);
buf : 
buf : 	if (mlx4_is_mfunc(dev->dev) && netw_view)
if (mlx4_is_mfunc(dev->dev) && netw_view) 
buf : 		mad_ifc_flags |= MLX4_MAD_IFC_NET_VIEW;
buf : 
buf : 	err = mlx4_MAD_IFC(dev, mad_ifc_flags, port, NULL, NULL, in_mad, out_mad);
ifc_flags, port, NULL, NULL, in_mad, out_mad); 
buf : 	if (err)
buf : 		goto out;
buf : 
buf : 	memcpy(gid->raw, out_mad->data + 8, 8);
buf : 
buf : 	if (mlx4_is_mfunc(dev->dev) && !netw_view) {
if (mlx4_is_mfunc(dev->dev) && !netw_view) { 
buf : 		if (index) {
buf : 			/* For any index > 0, return the null guid */
buf : 			err = 0;
buf : 			clear = 1;
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id  = IB_SMP_ATTR_GUID_INFO;
buf : 	in_mad->attr_mod = cpu_to_be32(index / 8);
buf : 
buf : 	err = mlx4_MAD_IFC(dev, mad_ifc_flags, port,
ifc_flags, port, 
buf : 			   NULL, NULL, in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	memcpy(gid->raw + 8, out_mad->data + (index % 8) * 8, 8);
buf : 
buf : out:
buf : 	if (clear)
if (clear) 
buf : 		memset(gid->raw + 8, 0, 8);
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 	return err;
buf : }
buf : 
buf : static int iboe_query_gid(struct ib_device *ibdev, u8 port, int index,
buf : 			  union ib_gid *gid)
buf : {
buf : 	struct mlx4_ib_dev *dev = to_mdev(ibdev);
buf : 
buf : 	*gid = dev->iboe.gid_table[port - 1][index];
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int mlx4_ib_query_gid(struct ib_device *ibdev, u8 port, int index,
buf : 			     union ib_gid *gid)
buf : {
buf : 	if (rdma_port_get_link_layer(ibdev, port) == IB_LINK_LAYER_INFINIBAND)
if (rdma_port_get_link_layer(ibdev, port) == IB_LINK_LAYER_INFINIBAND) 
buf : 		return __mlx4_ib_query_gid(ibdev, port, index, gid, 0);
buf : 	else
buf : 		return iboe_query_gid(ibdev, port, index, gid);
buf : }
buf : 
buf : int __mlx4_ib_query_pkey(struct ib_device *ibdev, u8 port, u16 index,
buf : 			 u16 *pkey, int netw_view)
buf : {
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int mad_ifc_flags = MLX4_MAD_IFC_IGNORE_KEYS;
ifc_flags = MLX4_MAD_IFC_IGNORE_KEYS; 
buf : 	int err = -ENOMEM;
buf : 
buf : 	in_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id  = IB_SMP_ATTR_PKEY_TABLE;
buf : 	in_mad->attr_mod = cpu_to_be32(index / 32);
buf : 
buf : 	if (mlx4_is_mfunc(to_mdev(ibdev)->dev) && netw_view)
if (mlx4_is_mfunc(to_mdev(ibdev)->dev) && netw_view) 
buf : 		mad_ifc_flags |= MLX4_MAD_IFC_NET_VIEW;
buf : 
buf : 	err = mlx4_MAD_IFC(to_mdev(ibdev), mad_ifc_flags, port, NULL, NULL,
ifc_flags, port, NULL, NULL, 
buf : 			   in_mad, out_mad);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	*pkey = be16_to_cpu(((__be16 *) out_mad->data)[index % 32]);
buf : 
buf : out:
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 	return err;
buf : }
buf : 
buf : static int mlx4_ib_query_pkey(struct ib_device *ibdev, u8 port, u16 index, u16 *pkey)
buf : {
buf : 	return __mlx4_ib_query_pkey(ibdev, port, index, pkey, 0);
buf : }
buf : 
buf : static int mlx4_ib_modify_device(struct ib_device *ibdev, int mask,
ify_device(struct ib_device *ibdev, int mask, 
buf : 				 struct ib_device_modify *props)
buf : {
buf : 	struct mlx4_cmd_mailbox *mailbox;
buf : 	unsigned long flags;
buf : 
buf : 	if (mask & ~IB_DEVICE_MODIFY_NODE_DESC)
if (mask & ~IB_DEVICE_MODIFY_NODE_DESC) 
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	if (!(mask & IB_DEVICE_MODIFY_NODE_DESC))
if (!(mask & IB_DEVICE_MODIFY_NODE_DESC)) 
buf : 		return 0;
buf : 
buf : 	if (mlx4_is_slave(to_mdev(ibdev)->dev))
if (mlx4_is_slave(to_mdev(ibdev)->dev)) 
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	spin_lock_irqsave(&to_mdev(ibdev)->sm_lock, flags);
buf : 	memcpy(ibdev->node_desc, props->node_desc, 64);
buf : 	spin_unlock_irqrestore(&to_mdev(ibdev)->sm_lock, flags);
buf : 
buf : 	/*
buf : 	 * If possible, pass node desc to FW, so it can generate
buf : 	 * a 144 trap.  If cmd fails, just ignore.
buf : 	 */
buf : 	mailbox = mlx4_alloc_cmd_mailbox(to_mdev(ibdev)->dev);
buf : 	if (IS_ERR(mailbox))
if (IS_ERR(mailbox)) 
buf : 		return 0;
buf : 
buf : 	memcpy(mailbox->buf, props->node_desc, 64);
buf : 	mlx4_cmd(to_mdev(ibdev)->dev, mailbox->dma, 1, 0,
buf : 		 MLX4_CMD_SET_NODE, MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);
buf : 
buf : 	mlx4_free_cmd_mailbox(to_mdev(ibdev)->dev, mailbox);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int mlx4_ib_SET_PORT(struct mlx4_ib_dev *dev, u8 port, int reset_qkey_viols,
buf : 			    u32 cap_mask)
buf : {
buf : 	struct mlx4_cmd_mailbox *mailbox;
buf : 	int err;
buf : 
buf : 	mailbox = mlx4_alloc_cmd_mailbox(dev->dev);
buf : 	if (IS_ERR(mailbox))
if (IS_ERR(mailbox)) 
buf : 		return PTR_ERR(mailbox);
buf : 
buf : 	if (dev->dev->flags & MLX4_FLAG_OLD_PORT_CMDS) {
if (dev->dev->flags & MLX4_FLAG_OLD_PORT_CMDS) { 
buf : 		*(u8 *) mailbox->buf	     = !!reset_qkey_viols << 6;
buf : 		((__be32 *) mailbox->buf)[2] = cpu_to_be32(cap_mask);
buf : 	} else {
buf : 		((u8 *) mailbox->buf)[3]     = !!reset_qkey_viols;
buf : 		((__be32 *) mailbox->buf)[1] = cpu_to_be32(cap_mask);
buf : 	}
buf : 
buf : 	err = mlx4_cmd(dev->dev, mailbox->dma, port, 0, MLX4_CMD_SET_PORT,
buf : 		       MLX4_CMD_TIME_CLASS_B, MLX4_CMD_WRAPPED);
buf : 
buf : 	mlx4_free_cmd_mailbox(dev->dev, mailbox);
buf : 	return err;
buf : }
buf : 
buf : static int mlx4_ib_modify_port(struct ib_device *ibdev, u8 port, int mask,
ify_port(struct ib_device *ibdev, u8 port, int mask, 
buf : 			       struct ib_port_modify *props)
buf : {
buf : 	struct mlx4_ib_dev *mdev = to_mdev(ibdev);
buf : 	u8 is_eth = mdev->dev->caps.port_type[port] == MLX4_PORT_TYPE_ETH;
buf : 	struct ib_port_attr attr;
buf : 	u32 cap_mask;
buf : 	int err;
buf : 
buf : 	/* return OK if this is RoCE. CM calls ib_modify_port() regardless
if this is RoCE. CM calls ib_modify_port() regardless 
buf : 	 * of whether port link layer is ETH or IB. For ETH ports, qkey
buf : 	 * violations and port capabilities are not meaningful.
buf : 	 */
buf : 	if (is_eth)
if (is_eth) 
buf : 		return 0;
buf : 
buf : 	mutex_lock(&mdev->cap_mask_mutex);
buf : 
buf : 	err = mlx4_ib_query_port(ibdev, port, &attr);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	cap_mask = (attr.port_cap_flags | props->set_port_cap_mask) &
buf : 		~props->clr_port_cap_mask;
buf : 
buf : 	err = mlx4_ib_SET_PORT(mdev, port,
buf : 			       !!(mask & IB_PORT_RESET_QKEY_CNTR),
buf : 			       cap_mask);
buf : 
buf : out:
buf : 	mutex_unlock(&to_mdev(ibdev)->cap_mask_mutex);
buf : 	return err;
buf : }
buf : 
buf : static struct ib_ucontext *mlx4_ib_alloc_ucontext(struct ib_device *ibdev,
buf : 						  struct ib_udata *udata)
buf : {
buf : 	struct mlx4_ib_dev *dev = to_mdev(ibdev);
buf : 	struct mlx4_ib_ucontext *context;
buf : 	struct mlx4_ib_alloc_ucontext_resp_v3 resp_v3;
buf : 	struct mlx4_ib_alloc_ucontext_resp resp;
buf : 	int err;
buf : 
buf : 	if (!dev->ib_active)
if (!dev->ib_active) 
buf : 		return ERR_PTR(-EAGAIN);
buf : 
buf : 	if (ibdev->uverbs_abi_ver == MLX4_IB_UVERBS_NO_DEV_CAPS_ABI_VERSION) {
if (ibdev->uverbs_abi_ver == MLX4_IB_UVERBS_NO_DEV_CAPS_ABI_VERSION) { 
buf : 		resp_v3.qp_tab_size      = dev->dev->caps.num_qps;
buf : 		resp_v3.bf_reg_size      = dev->dev->caps.bf_reg_size;
buf : 		resp_v3.bf_regs_per_page = dev->dev->caps.bf_regs_per_page;
buf : 	} else {
buf : 		resp.dev_caps	      = dev->dev->caps.userspace_caps;
buf : 		resp.qp_tab_size      = dev->dev->caps.num_qps;
buf : 		resp.bf_reg_size      = dev->dev->caps.bf_reg_size;
buf : 		resp.bf_regs_per_page = dev->dev->caps.bf_regs_per_page;
buf : 		resp.cqe_size	      = dev->dev->caps.cqe_size;
buf : 	}
buf : 
buf : 	context = kmalloc(sizeof *context, GFP_KERNEL);
buf : 	if (!context)
if (!context) 
buf : 		return ERR_PTR(-ENOMEM);
buf : 
buf : 	err = mlx4_uar_alloc(to_mdev(ibdev)->dev, &context->uar);
buf : 	if (err) {
if (err) { 
buf : 		kfree(context);
buf : 		return ERR_PTR(err);
buf : 	}
buf : 
buf : 	INIT_LIST_HEAD(&context->db_page_list);
buf : 	mutex_init(&context->db_page_mutex);
buf : 
buf : 	if (ibdev->uverbs_abi_ver == MLX4_IB_UVERBS_NO_DEV_CAPS_ABI_VERSION)
if (ibdev->uverbs_abi_ver == MLX4_IB_UVERBS_NO_DEV_CAPS_ABI_VERSION) 
buf : 		err = ib_copy_to_udata(udata, &resp_v3, sizeof(resp_v3));
buf : 	else
buf : 		err = ib_copy_to_udata(udata, &resp, sizeof(resp));
buf : 
buf : 	if (err) {
if (err) { 
buf : 		mlx4_uar_free(to_mdev(ibdev)->dev, &context->uar);
buf : 		kfree(context);
buf : 		return ERR_PTR(-EFAULT);
buf : 	}
buf : 
buf : 	return &context->ibucontext;
buf : }
buf : 
buf : static int mlx4_ib_dealloc_ucontext(struct ib_ucontext *ibcontext)
buf : {
buf : 	struct mlx4_ib_ucontext *context = to_mucontext(ibcontext);
buf : 
buf : 	mlx4_uar_free(to_mdev(ibcontext->device)->dev, &context->uar);
buf : 	kfree(context);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int mlx4_ib_mmap(struct ib_ucontext *context, struct vm_area_struct *vma)
buf : {
buf : 	struct mlx4_ib_dev *dev = to_mdev(context->device);
buf : 
buf : 	if (vma->vm_end - vma->vm_start != PAGE_SIZE)
if (vma->vm_end - vma->vm_start != PAGE_SIZE) 
buf : 		return -EINVAL;
buf : 
buf : 	if (vma->vm_pgoff == 0) {
if (vma->vm_pgoff == 0) { 
buf : 		vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
buf : 
buf : 		if (io_remap_pfn_range(vma, vma->vm_start,
if (io_remap_pfn_range(vma, vma->vm_start, 
buf : 				       to_mucontext(context)->uar.pfn,
buf : 				       PAGE_SIZE, vma->vm_page_prot))
buf : 			return -EAGAIN;
buf : 	} else if (vma->vm_pgoff == 1 && dev->dev->caps.bf_reg_size != 0) {
if (vma->vm_pgoff == 1 && dev->dev->caps.bf_reg_size != 0) { 
buf : 		vma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);
buf : 
buf : 		if (io_remap_pfn_range(vma, vma->vm_start,
if (io_remap_pfn_range(vma, vma->vm_start, 
buf : 				       to_mucontext(context)->uar.pfn +
buf : 				       dev->dev->caps.num_uars,
buf : 				       PAGE_SIZE, vma->vm_page_prot))
buf : 			return -EAGAIN;
buf : 	} else
buf : 		return -EINVAL;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static struct ib_pd *mlx4_ib_alloc_pd(struct ib_device *ibdev,
buf : 				      struct ib_ucontext *context,
buf : 				      struct ib_udata *udata)
buf : {
buf : 	struct mlx4_ib_pd *pd;
buf : 	int err;
buf : 
buf : 	pd = kmalloc(sizeof *pd, GFP_KERNEL);
buf : 	if (!pd)
if (!pd) 
buf : 		return ERR_PTR(-ENOMEM);
buf : 
buf : 	err = mlx4_pd_alloc(to_mdev(ibdev)->dev, &pd->pdn);
buf : 	if (err) {
if (err) { 
buf : 		kfree(pd);
buf : 		return ERR_PTR(err);
buf : 	}
buf : 
buf : 	if (context)
if (context) 
buf : 		if (ib_copy_to_udata(udata, &pd->pdn, sizeof (__u32))) {
buf : 			mlx4_pd_free(to_mdev(ibdev)->dev, pd->pdn);
buf : 			kfree(pd);
buf : 			return ERR_PTR(-EFAULT);
buf : 		}
buf : 
buf : 	return &pd->ibpd;
buf : }
buf : 
buf : static int mlx4_ib_dealloc_pd(struct ib_pd *pd)
buf : {
buf : 	mlx4_pd_free(to_mdev(pd->device)->dev, to_mpd(pd)->pdn);
buf : 	kfree(pd);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static struct ib_xrcd *mlx4_ib_alloc_xrcd(struct ib_device *ibdev,
buf : 					  struct ib_ucontext *context,
buf : 					  struct ib_udata *udata)
buf : {
buf : 	struct mlx4_ib_xrcd *xrcd;
buf : 	int err;
buf : 
buf : 	if (!(to_mdev(ibdev)->dev->caps.flags & MLX4_DEV_CAP_FLAG_XRC))
if (!(to_mdev(ibdev)->dev->caps.flags & MLX4_DEV_CAP_FLAG_XRC)) 
buf : 		return ERR_PTR(-ENOSYS);
buf : 
buf : 	xrcd = kmalloc(sizeof *xrcd, GFP_KERNEL);
buf : 	if (!xrcd)
if (!xrcd) 
buf : 		return ERR_PTR(-ENOMEM);
buf : 
buf : 	err = mlx4_xrcd_alloc(to_mdev(ibdev)->dev, &xrcd->xrcdn);
buf : 	if (err)
if (err) 
buf : 		goto err1;
buf : 
buf : 	xrcd->pd = ib_alloc_pd(ibdev);
buf : 	if (IS_ERR(xrcd->pd)) {
if (IS_ERR(xrcd->pd)) { 
buf : 		err = PTR_ERR(xrcd->pd);
buf : 		goto err2;
buf : 	}
buf : 
buf : 	xrcd->cq = ib_create_cq(ibdev, NULL, NULL, xrcd, 1, 0);
buf : 	if (IS_ERR(xrcd->cq)) {
if (IS_ERR(xrcd->cq)) { 
buf : 		err = PTR_ERR(xrcd->cq);
buf : 		goto err3;
buf : 	}
buf : 
buf : 	return &xrcd->ibxrcd;
buf : 
buf : err3:
buf : 	ib_dealloc_pd(xrcd->pd);
buf : err2:
buf : 	mlx4_xrcd_free(to_mdev(ibdev)->dev, xrcd->xrcdn);
buf : err1:
buf : 	kfree(xrcd);
buf : 	return ERR_PTR(err);
buf : }
buf : 
buf : static int mlx4_ib_dealloc_xrcd(struct ib_xrcd *xrcd)
buf : {
buf : 	ib_destroy_cq(to_mxrcd(xrcd)->cq);
buf : 	ib_dealloc_pd(to_mxrcd(xrcd)->pd);
buf : 	mlx4_xrcd_free(to_mdev(xrcd->device)->dev, to_mxrcd(xrcd)->xrcdn);
buf : 	kfree(xrcd);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int add_gid_entry(struct ib_qp *ibqp, union ib_gid *gid)
buf : {
buf : 	struct mlx4_ib_qp *mqp = to_mqp(ibqp);
buf : 	struct mlx4_ib_dev *mdev = to_mdev(ibqp->device);
buf : 	struct mlx4_ib_gid_entry *ge;
buf : 
buf : 	ge = kzalloc(sizeof *ge, GFP_KERNEL);
buf : 	if (!ge)
if (!ge) 
buf : 		return -ENOMEM;
buf : 
buf : 	ge->gid = *gid;
buf : 	if (mlx4_ib_add_mc(mdev, mqp, gid)) {
if (mlx4_ib_add_mc(mdev, mqp, gid)) { 
buf : 		ge->port = mqp->port;
buf : 		ge->added = 1;
buf : 	}
buf : 
buf : 	mutex_lock(&mqp->mutex);
buf : 	list_add_tail(&ge->list, &mqp->gid_list);
buf : 	mutex_unlock(&mqp->mutex);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int mlx4_ib_add_mc(struct mlx4_ib_dev *mdev, struct mlx4_ib_qp *mqp,
buf : 		   union ib_gid *gid)
buf : {
buf : 	struct net_device *ndev;
buf : 	int ret = 0;
buf : 
buf : 	if (!mqp->port)
if (!mqp->port) 
buf : 		return 0;
buf : 
buf : 	spin_lock(&mdev->iboe.lock);
buf : 	ndev = mdev->iboe.netdevs[mqp->port - 1];
buf : 	if (ndev)
if (ndev) 
buf : 		dev_hold(ndev);
buf : 	spin_unlock(&mdev->iboe.lock);
buf : 
buf : 	if (ndev) {
if (ndev) { 
buf : 		ret = 1;
buf : 		dev_put(ndev);
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : 
buf : struct mlx4_ib_steering {
buf : 	struct list_head list;
buf : 	u64 reg_id;
buf : 	union ib_gid gid;
buf : };
buf : 
buf : static int parse_flow_attr(struct mlx4_dev *dev,
buf : 			   u32 qp_num,
buf : 			   union ib_flow_spec *ib_spec,
buf : 			   struct _rule_hw *mlx4_spec)
buf : {
buf : 	enum mlx4_net_trans_rule_id type;
buf : 
buf : 	switch (ib_spec->type) {
buf : 	case IB_FLOW_SPEC_ETH:
buf : 		type = MLX4_NET_TRANS_RULE_ID_ETH;
buf : 		memcpy(mlx4_spec->eth.dst_mac, ib_spec->eth.val.dst_mac,
buf : 		       ETH_ALEN);
buf : 		memcpy(mlx4_spec->eth.dst_mac_msk, ib_spec->eth.mask.dst_mac,
buf : 		       ETH_ALEN);
buf : 		mlx4_spec->eth.vlan_tag = ib_spec->eth.val.vlan_tag;
buf : 		mlx4_spec->eth.vlan_tag_msk = ib_spec->eth.mask.vlan_tag;
buf : 		break;
buf : 	case IB_FLOW_SPEC_IB:
buf : 		type = MLX4_NET_TRANS_RULE_ID_IB;
buf : 		mlx4_spec->ib.l3_qpn =
buf : 			cpu_to_be32(qp_num);
buf : 		mlx4_spec->ib.qpn_mask =
buf : 			cpu_to_be32(MLX4_IB_FLOW_QPN_MASK);
buf : 		break;
buf : 
buf : 
buf : 	case IB_FLOW_SPEC_IPV4:
buf : 		type = MLX4_NET_TRANS_RULE_ID_IPV4;
buf : 		mlx4_spec->ipv4.src_ip = ib_spec->ipv4.val.src_ip;
buf : 		mlx4_spec->ipv4.src_ip_msk = ib_spec->ipv4.mask.src_ip;
buf : 		mlx4_spec->ipv4.dst_ip = ib_spec->ipv4.val.dst_ip;
buf : 		mlx4_spec->ipv4.dst_ip_msk = ib_spec->ipv4.mask.dst_ip;
buf : 		break;
buf : 
buf : 	case IB_FLOW_SPEC_TCP:
buf : 	case IB_FLOW_SPEC_UDP:
buf : 		type = ib_spec->type == IB_FLOW_SPEC_TCP ?
buf : 					MLX4_NET_TRANS_RULE_ID_TCP :
buf : 					MLX4_NET_TRANS_RULE_ID_UDP;
buf : 		mlx4_spec->tcp_udp.dst_port = ib_spec->tcp_udp.val.dst_port;
buf : 		mlx4_spec->tcp_udp.dst_port_msk = ib_spec->tcp_udp.mask.dst_port;
buf : 		mlx4_spec->tcp_udp.src_port = ib_spec->tcp_udp.val.src_port;
buf : 		mlx4_spec->tcp_udp.src_port_msk = ib_spec->tcp_udp.mask.src_port;
buf : 		break;
buf : 
buf : 	default:
buf : 		return -EINVAL;
buf : 	}
buf : 	if (mlx4_map_sw_to_hw_steering_id(dev, type) < 0 ||
if (mlx4_map_sw_to_hw_steering_id(dev, type) < 0 || 
buf : 	    mlx4_hw_rule_sz(dev, type) < 0)
buf : 		return -EINVAL;
buf : 	mlx4_spec->id = cpu_to_be16(mlx4_map_sw_to_hw_steering_id(dev, type));
buf : 	mlx4_spec->size = mlx4_hw_rule_sz(dev, type) >> 2;
buf : 	return mlx4_hw_rule_sz(dev, type);
buf : }
buf : 
buf : struct default_rules {
buf : 	__u32 mandatory_fields[IB_FLOW_SPEC_SUPPORT_LAYERS];
buf : 	__u32 mandatory_not_fields[IB_FLOW_SPEC_SUPPORT_LAYERS];
buf : 	__u32 rules_create_list[IB_FLOW_SPEC_SUPPORT_LAYERS];
buf : 	__u8  link_layer;
buf : };
buf : static const struct default_rules default_table[] = {
buf : 	{
buf : 		.mandatory_fields = {IB_FLOW_SPEC_IPV4},
buf : 		.mandatory_not_fields = {IB_FLOW_SPEC_ETH},
buf : 		.rules_create_list = {IB_FLOW_SPEC_IB},
buf : 		.link_layer = IB_LINK_LAYER_INFINIBAND
buf : 	}
buf : };
buf : 
buf : static int __mlx4_ib_default_rules_match(struct ib_qp *qp,
buf : 					 struct ib_flow_attr *flow_attr)
buf : {
buf : 	int i, j, k;
buf : 	void *ib_flow;
buf : 	const struct default_rules *pdefault_rules = default_table;
buf : 	u8 link_layer = rdma_port_get_link_layer(qp->device, flow_attr->port);
buf : 
buf : 	for (i = 0; i < sizeof(default_table)/sizeof(default_table[0]); i++,
for (i = 0; i < sizeof(default_table)/sizeof(default_table[0]); i++, 
buf : 	     pdefault_rules++) {
buf : 		__u32 field_types[IB_FLOW_SPEC_SUPPORT_LAYERS];
buf : 		memset(&field_types, 0, sizeof(field_types));
buf : 
buf : 		if (link_layer != pdefault_rules->link_layer)
if (link_layer != pdefault_rules->link_layer) 
buf : 			continue;
buf : 
buf : 		ib_flow = flow_attr + 1;
buf : 		/* we assume the specs are sorted */
buf : 		for (j = 0, k = 0; k < IB_FLOW_SPEC_SUPPORT_LAYERS &&
for (j = 0, k = 0; k < IB_FLOW_SPEC_SUPPORT_LAYERS && 
buf : 		     j < flow_attr->num_of_specs; k++) {
buf : 			union ib_flow_spec *current_flow =
buf : 				(union ib_flow_spec *)ib_flow;
buf : 
buf : 			/* same layer but different type */
ifferent type */ 
buf : 			if (((current_flow->type & IB_FLOW_SPEC_LAYER_MASK) ==
buf : 			     (pdefault_rules->mandatory_fields[k] &
buf : 			      IB_FLOW_SPEC_LAYER_MASK)) &&
buf : 			    (current_flow->type !=
buf : 			     pdefault_rules->mandatory_fields[k]))
buf : 				goto out;
buf : 
buf : 			/* same layer, try match next one */
buf : 			if (current_flow->type ==
if (current_flow->type == 
buf : 			    pdefault_rules->mandatory_fields[k]) {
buf : 				j++;
buf : 				ib_flow +=
buf : 					((union ib_flow_spec *)ib_flow)->size;
buf : 			}
buf : 		}
buf : 
buf : 		ib_flow = flow_attr + 1;
buf : 		for (j = 0; j < flow_attr->num_of_specs;
for (j = 0; j < flow_attr->num_of_specs; 
buf : 		     j++, ib_flow += ((union ib_flow_spec *)ib_flow)->size)
buf : 			for (k = 0; k < IB_FLOW_SPEC_SUPPORT_LAYERS; k++)
for (k = 0; k < IB_FLOW_SPEC_SUPPORT_LAYERS; k++) 
buf : 				/* same layer and same type */
buf : 				if (((union ib_flow_spec *)ib_flow)->type ==
if (((union ib_flow_spec *)ib_flow)->type == 
buf : 				    pdefault_rules->mandatory_not_fields[k])
buf : 					goto out;
buf : 
buf : 		return i;
buf : 	}
buf : out:
buf : 	return -1;
buf : }
buf : 
buf : static int __mlx4_ib_create_default_rules(
buf : 		struct mlx4_ib_dev *mdev,
buf : 		struct ib_qp *qp,
buf : 		const struct default_rules *pdefault_rules,
buf : 		struct _rule_hw *mlx4_spec) {
buf : 	int size = 0;
buf : 	int i;
buf : 
buf : 	for (i = 0; i < sizeof(pdefault_rules->rules_create_list)/
for (i = 0; i < sizeof(pdefault_rules->rules_create_list)/ 
buf : 			sizeof(pdefault_rules->rules_create_list[0]); i++) {
buf : 		int ret;
buf : 		union ib_flow_spec ib_spec;
buf : 		switch (pdefault_rules->rules_create_list[i]) {
buf : 		case 0:
buf : 			/* no rule */
buf : 			continue;
buf : 		case IB_FLOW_SPEC_IB:
buf : 			ib_spec.type = IB_FLOW_SPEC_IB;
buf : 			ib_spec.size = sizeof(struct ib_flow_spec_ib);
buf : 
buf : 			break;
buf : 		default:
buf : 			/* invalid rule */
buf : 			return -EINVAL;
buf : 		}
buf : 		/* We must put empty rule, qpn is being ignored */
buf : 		ret = parse_flow_attr(mdev->dev, 0, &ib_spec,
buf : 				      mlx4_spec);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			pr_info("invalid parsing\n");
buf : 			return -EINVAL;
buf : 		}
buf : 
buf : 		mlx4_spec = (void *)mlx4_spec + ret;
buf : 		size += ret;
buf : 	}
buf : 	return size;
buf : }
buf : 
buf : static int __mlx4_ib_create_flow(struct ib_qp *qp, struct ib_flow_attr *flow_attr,
buf : 			  int domain,
buf : 			  enum mlx4_net_trans_promisc_mode flow_type,
buf : 			  u64 *reg_id)
buf : {
buf : 	int ret, i;
buf : 	int size = 0;
buf : 	void *ib_flow;
buf : 	struct mlx4_ib_dev *mdev = to_mdev(qp->device);
buf : 	struct mlx4_cmd_mailbox *mailbox;
buf : 	struct mlx4_net_trans_rule_hw_ctrl *ctrl;
buf : 	int default_flow;
buf : 
buf : 	static const u16 __mlx4_domain[] = {
buf : 		[IB_FLOW_DOMAIN_USER] = MLX4_DOMAIN_UVERBS,
buf : 		[IB_FLOW_DOMAIN_ETHTOOL] = MLX4_DOMAIN_ETHTOOL,
buf : 		[IB_FLOW_DOMAIN_RFS] = MLX4_DOMAIN_RFS,
buf : 		[IB_FLOW_DOMAIN_NIC] = MLX4_DOMAIN_NIC,
buf : 	};
buf : 
buf : 	if (flow_attr->priority > MLX4_IB_FLOW_MAX_PRIO) {
if (flow_attr->priority > MLX4_IB_FLOW_MAX_PRIO) { 
buf : 		pr_err("Invalid priority value %d\n", flow_attr->priority);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	if (domain >= IB_FLOW_DOMAIN_NUM) {
if (domain >= IB_FLOW_DOMAIN_NUM) { 
buf : 		pr_err("Invalid domain value %d\n", domain);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	if (mlx4_map_sw_to_hw_steering_mode(mdev->dev, flow_type) < 0)
if (mlx4_map_sw_to_hw_steering_mode(mdev->dev, flow_type) < 0) 
buf : 		return -EINVAL;
buf : 
buf : 	mailbox = mlx4_alloc_cmd_mailbox(mdev->dev);
buf : 	if (IS_ERR(mailbox))
if (IS_ERR(mailbox)) 
buf : 		return PTR_ERR(mailbox);
buf : 	ctrl = mailbox->buf;
buf : 
buf : 	ctrl->prio = cpu_to_be16(__mlx4_domain[domain] |
buf : 				 flow_attr->priority);
buf : 	ctrl->type = mlx4_map_sw_to_hw_steering_mode(mdev->dev, flow_type);
buf : 	ctrl->port = flow_attr->port;
buf : 	ctrl->qpn = cpu_to_be32(qp->qp_num);
buf : 
buf : 	ib_flow = flow_attr + 1;
buf : 	size += sizeof(struct mlx4_net_trans_rule_hw_ctrl);
buf : 	/* Add default flows */
buf : 	default_flow = __mlx4_ib_default_rules_match(qp, flow_attr);
buf : 	if (default_flow >= 0) {
if (default_flow >= 0) { 
buf : 		ret = __mlx4_ib_create_default_rules(
buf : 				mdev, qp, default_table + default_flow,
buf : 				mailbox->buf + size);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			mlx4_free_cmd_mailbox(mdev->dev, mailbox);
buf : 			return -EINVAL;
buf : 		}
buf : 		size += ret;
buf : 	}
buf : 	for (i = 0; i < flow_attr->num_of_specs; i++) {
for (i = 0; i < flow_attr->num_of_specs; i++) { 
buf : 		ret = parse_flow_attr(mdev->dev, qp->qp_num, ib_flow,
buf : 				      mailbox->buf + size);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			mlx4_free_cmd_mailbox(mdev->dev, mailbox);
buf : 			return -EINVAL;
buf : 		}
buf : 		ib_flow += ((union ib_flow_spec *) ib_flow)->size;
buf : 		size += ret;
buf : 	}
buf : 
buf : 	ret = mlx4_cmd_imm(mdev->dev, mailbox->dma, reg_id, size >> 2, 0,
buf : 			   MLX4_QP_FLOW_STEERING_ATTACH, MLX4_CMD_TIME_CLASS_A,
buf : 			   MLX4_CMD_NATIVE);
buf : 	if (ret == -ENOMEM)
if (ret == -ENOMEM) 
buf : 		pr_err("mcg table is full. Fail to register network rule.\n");
buf : 	else if (ret == -ENXIO)
if (ret == -ENXIO) 
buf : 		pr_err("Device managed flow steering is disabled. Fail to register network rule.\n");
buf : 	else if (ret)
if (ret) 
buf : 		pr_err("Invalid argumant. Fail to register network rule.\n");
buf : 
buf : 	mlx4_free_cmd_mailbox(mdev->dev, mailbox);
buf : 	return ret;
buf : }
buf : 
buf : static int __mlx4_ib_destroy_flow(struct mlx4_dev *dev, u64 reg_id)
buf : {
buf : 	int err;
buf : 	err = mlx4_cmd(dev, reg_id, 0, 0,
buf : 		       MLX4_QP_FLOW_STEERING_DETACH, MLX4_CMD_TIME_CLASS_A,
buf : 		       MLX4_CMD_NATIVE);
buf : 	if (err)
if (err) 
buf : 		pr_err("Fail to detach network rule. registration id = 0x%llx\n",
buf : 		       reg_id);
buf : 	return err;
buf : }
buf : 
buf : static struct ib_flow *mlx4_ib_create_flow(struct ib_qp *qp,
buf : 				    struct ib_flow_attr *flow_attr,
buf : 				    int domain)
buf : {
buf : 	int err = 0, i = 0;
buf : 	struct mlx4_ib_flow *mflow;
buf : 	enum mlx4_net_trans_promisc_mode type[2];
buf : 
buf : 	memset(type, 0, sizeof(type));
buf : 
buf : 	mflow = kzalloc(sizeof(*mflow), GFP_KERNEL);
buf : 	if (!mflow) {
if (!mflow) { 
buf : 		err = -ENOMEM;
buf : 		goto err_free;
buf : 	}
buf : 
buf : 	switch (flow_attr->type) {
buf : 	case IB_FLOW_ATTR_NORMAL:
buf : 		type[0] = MLX4_FS_REGULAR;
buf : 		break;
buf : 
buf : 	case IB_FLOW_ATTR_ALL_DEFAULT:
buf : 		type[0] = MLX4_FS_ALL_DEFAULT;
buf : 		break;
buf : 
buf : 	case IB_FLOW_ATTR_MC_DEFAULT:
buf : 		type[0] = MLX4_FS_MC_DEFAULT;
buf : 		break;
buf : 
buf : 	case IB_FLOW_ATTR_SNIFFER:
buf : 		type[0] = MLX4_FS_UC_SNIFFER;
buf : 		type[1] = MLX4_FS_MC_SNIFFER;
buf : 		break;
buf : 
buf : 	default:
buf : 		err = -EINVAL;
buf : 		goto err_free;
buf : 	}
buf : 
buf : 	while (i < ARRAY_SIZE(type) && type[i]) {
while (i < ARRAY_SIZE(type) && type[i]) { 
buf : 		err = __mlx4_ib_create_flow(qp, flow_attr, domain, type[i],
buf : 					    &mflow->reg_id[i]);
buf : 		if (err)
if (err) 
buf : 			goto err_free;
buf : 		i++;
buf : 	}
buf : 
buf : 	return &mflow->ibflow;
buf : 
buf : err_free:
buf : 	kfree(mflow);
buf : 	return ERR_PTR(err);
buf : }
buf : 
buf : static int mlx4_ib_destroy_flow(struct ib_flow *flow_id)
buf : {
buf : 	int err, ret = 0;
buf : 	int i = 0;
buf : 	struct mlx4_ib_dev *mdev = to_mdev(flow_id->qp->device);
buf : 	struct mlx4_ib_flow *mflow = to_mflow(flow_id);
buf : 
buf : 	while (i < ARRAY_SIZE(mflow->reg_id) && mflow->reg_id[i]) {
while (i < ARRAY_SIZE(mflow->reg_id) && mflow->reg_id[i]) { 
buf : 		err = __mlx4_ib_destroy_flow(mdev->dev, mflow->reg_id[i]);
buf : 		if (err)
if (err) 
buf : 			ret = err;
buf : 		i++;
buf : 	}
buf : 
buf : 	kfree(mflow);
buf : 	return ret;
buf : }
buf : 
buf : static int mlx4_ib_mcg_attach(struct ib_qp *ibqp, union ib_gid *gid, u16 lid)
buf : {
buf : 	int err;
buf : 	struct mlx4_ib_dev *mdev = to_mdev(ibqp->device);
buf : 	struct mlx4_ib_qp *mqp = to_mqp(ibqp);
buf : 	u64 reg_id;
buf : 	struct mlx4_ib_steering *ib_steering = NULL;
buf : 	enum mlx4_protocol prot = (gid->raw[1] == 0x0e) ?
buf : 		MLX4_PROT_IB_IPV4 : MLX4_PROT_IB_IPV6;
buf : 
buf : 	if (mdev->dev->caps.steering_mode ==
if (mdev->dev->caps.steering_mode == 
buf : 	    MLX4_STEERING_MODE_DEVICE_MANAGED) {
buf : 		ib_steering = kmalloc(sizeof(*ib_steering), GFP_KERNEL);
buf : 		if (!ib_steering)
if (!ib_steering) 
buf : 			return -ENOMEM;
buf : 	}
buf : 
buf : 	err = mlx4_multicast_attach(mdev->dev, &mqp->mqp, gid->raw, mqp->port,
buf : 				    !!(mqp->flags &
buf : 				       MLX4_IB_QP_BLOCK_MULTICAST_LOOPBACK),
buf : 				    prot, &reg_id);
buf : 	if (err)
if (err) 
buf : 		goto err_malloc;
buf : 
buf : 	err = add_gid_entry(ibqp, gid);
buf : 	if (err)
if (err) 
buf : 		goto err_add;
buf : 
buf : 	if (ib_steering) {
if (ib_steering) { 
buf : 		memcpy(ib_steering->gid.raw, gid->raw, 16);
buf : 		ib_steering->reg_id = reg_id;
buf : 		mutex_lock(&mqp->mutex);
buf : 		list_add(&ib_steering->list, &mqp->steering_rules);
buf : 		mutex_unlock(&mqp->mutex);
buf : 	}
buf : 	return 0;
buf : 
buf : err_add:
buf : 	mlx4_multicast_detach(mdev->dev, &mqp->mqp, gid->raw,
buf : 			      prot, reg_id);
buf : err_malloc:
buf : 	kfree(ib_steering);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static struct mlx4_ib_gid_entry *find_gid_entry(struct mlx4_ib_qp *qp, u8 *raw)
buf : {
buf : 	struct mlx4_ib_gid_entry *ge;
buf : 	struct mlx4_ib_gid_entry *tmp;
buf : 	struct mlx4_ib_gid_entry *ret = NULL;
buf : 
buf : 	list_for_each_entry_safe(ge, tmp, &qp->gid_list, list) {
for_each_entry_safe(ge, tmp, &qp->gid_list, list) { 
buf : 		if (!memcmp(raw, ge->gid.raw, 16)) {
buf : 			ret = ge;
buf : 			break;
buf : 		}
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int mlx4_ib_mcg_detach(struct ib_qp *ibqp, union ib_gid *gid, u16 lid)
buf : {
buf : 	int err;
buf : 	struct mlx4_ib_dev *mdev = to_mdev(ibqp->device);
buf : 	struct mlx4_ib_qp *mqp = to_mqp(ibqp);
buf : 	struct net_device *ndev;
buf : 	struct mlx4_ib_gid_entry *ge;
buf : 	u64 reg_id = 0;
buf : 	enum mlx4_protocol prot = (gid->raw[1] == 0x0e) ?
buf : 		MLX4_PROT_IB_IPV4 : MLX4_PROT_IB_IPV6;
buf : 
buf : 	if (mdev->dev->caps.steering_mode ==
if (mdev->dev->caps.steering_mode == 
buf : 	    MLX4_STEERING_MODE_DEVICE_MANAGED) {
buf : 		struct mlx4_ib_steering *ib_steering;
buf : 
buf : 		mutex_lock(&mqp->mutex);
buf : 		list_for_each_entry(ib_steering, &mqp->steering_rules, list) {
for_each_entry(ib_steering, &mqp->steering_rules, list) { 
buf : 			if (!memcmp(ib_steering->gid.raw, gid->raw, 16)) {
buf : 				list_del(&ib_steering->list);
buf : 				break;
buf : 			}
buf : 		}
buf : 		mutex_unlock(&mqp->mutex);
buf : 		if (&ib_steering->list == &mqp->steering_rules) {
if (&ib_steering->list == &mqp->steering_rules) { 
buf : 			pr_err("Couldn't find reg_id for mgid. Steering rule is left attached\n");
for mgid. Steering rule is left attached\n"); 
buf : 			return -EINVAL;
buf : 		}
buf : 		reg_id = ib_steering->reg_id;
buf : 		kfree(ib_steering);
buf : 	}
buf : 
buf : 	err = mlx4_multicast_detach(mdev->dev, &mqp->mqp, gid->raw,
buf : 				    prot, reg_id);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	mutex_lock(&mqp->mutex);
buf : 	ge = find_gid_entry(mqp, gid->raw);
buf : 	if (ge) {
if (ge) { 
buf : 		spin_lock(&mdev->iboe.lock);
buf : 		ndev = ge->added ? mdev->iboe.netdevs[ge->port - 1] : NULL;
buf : 		if (ndev)
if (ndev) 
buf : 			dev_hold(ndev);
buf : 		spin_unlock(&mdev->iboe.lock);
buf : 		if (ndev)
if (ndev) 
buf : 			dev_put(ndev);
buf : 		list_del(&ge->list);
buf : 		kfree(ge);
buf : 	} else
buf : 		pr_warn("could not find mgid entry\n");
buf : 
buf : 	mutex_unlock(&mqp->mutex);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int init_node_data(struct mlx4_ib_dev *dev)
buf : {
buf : 	struct ib_smp *in_mad  = NULL;
buf : 	struct ib_smp *out_mad = NULL;
buf : 	int mad_ifc_flags = MLX4_MAD_IFC_IGNORE_KEYS;
ifc_flags = MLX4_MAD_IFC_IGNORE_KEYS; 
buf : 	int err = -ENOMEM;
buf : 
buf : 	in_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);
buf : 	out_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);
buf : 	if (!in_mad || !out_mad)
if (!in_mad || !out_mad) 
buf : 		goto out;
buf : 
buf : 	init_query_mad(in_mad);
buf : 	in_mad->attr_id = IB_SMP_ATTR_NODE_DESC;
buf : 	if (mlx4_is_master(dev->dev))
if (mlx4_is_master(dev->dev)) 
buf : 		mad_ifc_flags |= MLX4_MAD_IFC_NET_VIEW;
buf : 
buf : 	err = mlx4_MAD_IFC(dev, mad_ifc_flags, 1, NULL, NULL, in_mad, out_mad);
ifc_flags, 1, NULL, NULL, in_mad, out_mad); 
buf : 	if (err)
buf : 		goto out;
buf : 
buf : 	memcpy(dev->ib_dev.node_desc, out_mad->data, 64);
buf : 
buf : 	in_mad->attr_id = IB_SMP_ATTR_NODE_INFO;
buf : 
buf : 	err = mlx4_MAD_IFC(dev, mad_ifc_flags, 1, NULL, NULL, in_mad, out_mad);
ifc_flags, 1, NULL, NULL, in_mad, out_mad); 
buf : 	if (err)
buf : 		goto out;
buf : 
buf : 	dev->dev->rev_id = be32_to_cpup((__be32 *) (out_mad->data + 32));
buf : 	memcpy(&dev->ib_dev.node_guid, out_mad->data + 12, 8);
buf : 
buf : out:
buf : 	kfree(in_mad);
buf : 	kfree(out_mad);
buf : 	return err;
buf : }
buf : 
buf : static ssize_t show_hca(struct device *device, struct device_attribute *attr,
buf : 			char *buf)
buf : {
buf : 	struct mlx4_ib_dev *dev =
buf : 		container_of(device, struct mlx4_ib_dev, ib_dev.dev);
buf : 	return sprintf(buf, "MT%d\n", dev->dev->pdev->device);
buf : }
buf : 
buf : static ssize_t show_fw_ver(struct device *device, struct device_attribute *attr,
buf : 			   char *buf)
buf : {
buf : 	struct mlx4_ib_dev *dev =
buf : 		container_of(device, struct mlx4_ib_dev, ib_dev.dev);
buf : 	return sprintf(buf, "%d.%d.%d\n", (int) (dev->dev->caps.fw_ver >> 32),
buf : 		       (int) (dev->dev->caps.fw_ver >> 16) & 0xffff,
buf : 		       (int) dev->dev->caps.fw_ver & 0xffff);
buf : }
buf : 
buf : static ssize_t show_rev(struct device *device, struct device_attribute *attr,
buf : 			char *buf)
buf : {
buf : 	struct mlx4_ib_dev *dev =
buf : 		container_of(device, struct mlx4_ib_dev, ib_dev.dev);
buf : 	return sprintf(buf, "%x\n", dev->dev->rev_id);
buf : }
buf : 
buf : static ssize_t show_board(struct device *device, struct device_attribute *attr,
buf : 			  char *buf)
buf : {
buf : 	struct mlx4_ib_dev *dev =
buf : 		container_of(device, struct mlx4_ib_dev, ib_dev.dev);
buf : 	return sprintf(buf, "%.*s\n", MLX4_BOARD_ID_LEN,
buf : 		       dev->dev->board_id);
buf : }
buf : 
buf : static DEVICE_ATTR(hw_rev,   S_IRUGO, show_rev,    NULL);
buf : static DEVICE_ATTR(fw_ver,   S_IRUGO, show_fw_ver, NULL);
buf : static DEVICE_ATTR(hca_type, S_IRUGO, show_hca,    NULL);
buf : static DEVICE_ATTR(board_id, S_IRUGO, show_board,  NULL);
buf : 
buf : static struct device_attribute *mlx4_class_attributes[] = {
buf : 	&dev_attr_hw_rev,
buf : 	&dev_attr_fw_ver,
buf : 	&dev_attr_hca_type,
buf : 	&dev_attr_board_id
buf : };
buf : 
buf : static void mlx4_addrconf_ifid_eui48(u8 *eui, u16 vlan_id,
ifid_eui48(u8 *eui, u16 vlan_id, 
buf : 				     struct net_device *dev)
buf : {
buf : 	memcpy(eui, dev->dev_addr, 3);
buf : 	memcpy(eui + 5, dev->dev_addr + 3, 3);
buf : 	if (vlan_id < 0x1000) {
if (vlan_id < 0x1000) { 
buf : 		eui[3] = vlan_id >> 8;
buf : 		eui[4] = vlan_id & 0xff;
buf : 	} else {
buf : 		eui[3] = 0xff;
buf : 		eui[4] = 0xfe;
buf : 	}
buf : 	eui[0] ^= 2;
buf : }
buf : 
buf : static void update_gids_task(struct work_struct *work)
buf : {
buf : 	struct update_gid_work *gw = container_of(work, struct update_gid_work, work);
buf : 	struct mlx4_cmd_mailbox *mailbox;
buf : 	union ib_gid *gids;
buf : 	int err;
buf : 	struct mlx4_dev	*dev = gw->dev->dev;
buf : 
buf : 	mailbox = mlx4_alloc_cmd_mailbox(dev);
buf : 	if (IS_ERR(mailbox)) {
if (IS_ERR(mailbox)) { 
buf : 		pr_warn("update gid table failed %ld\n", PTR_ERR(mailbox));
buf : 		return;
buf : 	}
buf : 
buf : 	gids = mailbox->buf;
buf : 	memcpy(gids, gw->gids, sizeof gw->gids);
buf : 
buf : 	err = mlx4_cmd(dev, mailbox->dma, MLX4_SET_PORT_GID_TABLE << 8 | gw->port,
buf : 		       1, MLX4_CMD_SET_PORT, MLX4_CMD_TIME_CLASS_B,
buf : 		       MLX4_CMD_WRAPPED);
buf : 	if (err)
if (err) 
buf : 		pr_warn("set port command failed\n");
buf : 	else
buf : 		mlx4_ib_dispatch_event(gw->dev, gw->port, IB_EVENT_GID_CHANGE);
buf : 
buf : 	mlx4_free_cmd_mailbox(dev, mailbox);
buf : 	kfree(gw);
buf : }
buf : 
buf : static void reset_gids_task(struct work_struct *work)
buf : {
buf : 	struct update_gid_work *gw =
buf : 			container_of(work, struct update_gid_work, work);
buf : 	struct mlx4_cmd_mailbox *mailbox;
buf : 	union ib_gid *gids;
buf : 	int err;
buf : 	struct mlx4_dev	*dev = gw->dev->dev;
buf : 
buf : 	mailbox = mlx4_alloc_cmd_mailbox(dev);
buf : 	if (IS_ERR(mailbox)) {
if (IS_ERR(mailbox)) { 
buf : 		pr_warn("reset gid table failed\n");
buf : 		goto free;
buf : 	}
buf : 
buf : 	gids = mailbox->buf;
buf : 	memcpy(gids, gw->gids, sizeof(gw->gids));
buf : 
buf : 	if (mlx4_ib_port_link_layer(&gw->dev->ib_dev, gw->port) ==
if (mlx4_ib_port_link_layer(&gw->dev->ib_dev, gw->port) == 
buf : 				    IB_LINK_LAYER_ETHERNET) {
buf : 		err = mlx4_cmd(dev, mailbox->dma,
buf : 			       MLX4_SET_PORT_GID_TABLE << 8 | gw->port,
buf : 			       1, MLX4_CMD_SET_PORT,
buf : 			       MLX4_CMD_TIME_CLASS_B,
buf : 			       MLX4_CMD_WRAPPED);
buf : 		if (err)
if (err) 
buf : 			pr_warn(KERN_WARNING
buf : 				"set port %d command failed\n", gw->port);
buf : 	}
buf : 
buf : 	mlx4_free_cmd_mailbox(dev, mailbox);
buf : free:
buf : 	kfree(gw);
buf : }
buf : 
buf : static int update_gid_table(struct mlx4_ib_dev *dev, int port,
buf : 			    union ib_gid *gid, int clear,
buf : 			    int default_gid)
buf : {
buf : 	struct update_gid_work *work;
buf : 	int i;
buf : 	int need_update = 0;
buf : 	int free = -1;
buf : 	int found = -1;
buf : 	int max_gids;
buf : 
buf : 	if (default_gid) {
if (default_gid) { 
buf : 		free = 0;
buf : 	} else {
buf : 		max_gids = dev->dev->caps.gid_table_len[port];
buf : 		for (i = 1; i < max_gids; ++i) {
for (i = 1; i < max_gids; ++i) { 
buf : 			if (!memcmp(&dev->iboe.gid_table[port - 1][i], gid,
buf : 				    sizeof(*gid)))
buf : 				found = i;
buf : 
buf : 			if (clear) {
if (clear) { 
buf : 				if (found >= 0) {
buf : 					need_update = 1;
buf : 					dev->iboe.gid_table[port - 1][found] =
buf : 						zgid;
buf : 					break;
buf : 				}
buf : 			} else {
buf : 				if (found >= 0)
if (found >= 0) 
buf : 					break;
buf : 
buf : 				if (free < 0 &&
if (free < 0 && 
buf : 				    !memcmp(&dev->iboe.gid_table[port - 1][i],
buf : 					    &zgid, sizeof(*gid)))
buf : 					free = i;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	if (found == -1 && !clear && free >= 0) {
if (found == -1 && !clear && free >= 0) { 
buf : 		dev->iboe.gid_table[port - 1][free] = *gid;
buf : 		need_update = 1;
buf : 	}
buf : 
buf : 	if (!need_update)
if (!need_update) 
buf : 		return 0;
buf : 
buf : 	work = kzalloc(sizeof(*work), GFP_ATOMIC);
buf : 	if (!work)
if (!work) 
buf : 		return -ENOMEM;
buf : 
buf : 	memcpy(work->gids, dev->iboe.gid_table[port - 1], sizeof(work->gids));
buf : 	INIT_WORK(&work->work, update_gids_task);
buf : 	work->port = port;
buf : 	work->dev = dev;
buf : 	queue_work(wq, &work->work);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void mlx4_make_default_gid(struct  net_device *dev, union ib_gid *gid)
buf : {
buf : 	gid->global.subnet_prefix = cpu_to_be64(0xfe80000000000000LL);
buf : 	mlx4_addrconf_ifid_eui48(&gid->raw[8], 0xffff, dev);
ifid_eui48(&gid->raw[8], 0xffff, dev); 
buf : }
buf : 
buf : 
buf : static int reset_gid_table(struct mlx4_ib_dev *dev, u8 port)
buf : {
buf : 	struct update_gid_work *work;
buf : 
buf : 	work = kzalloc(sizeof(*work), GFP_ATOMIC);
buf : 	if (!work)
if (!work) 
buf : 		return -ENOMEM;
buf : 
buf : 	memset(dev->iboe.gid_table[port - 1], 0, sizeof(work->gids));
buf : 	memset(work->gids, 0, sizeof(work->gids));
buf : 	INIT_WORK(&work->work, reset_gids_task);
buf : 	work->dev = dev;
buf : 	work->port = port;
buf : 	queue_work(wq, &work->work);
buf : 	return 0;
buf : }
buf : 
buf : static int mlx4_ib_addr_event(int event, struct net_device *event_netdev,
buf : 			      struct mlx4_ib_dev *ibdev, union ib_gid *gid)
buf : {
buf : 	struct mlx4_ib_iboe *iboe;
buf : 	int port = 0;
buf : 	struct net_device *real_dev = rdma_vlan_dev_real_dev(event_netdev) ?
buf : 				rdma_vlan_dev_real_dev(event_netdev) :
buf : 				event_netdev;
buf : 	union ib_gid default_gid;
buf : 
buf : 	mlx4_make_default_gid(real_dev, &default_gid);
buf : 
buf : 	if (!memcmp(gid, &default_gid, sizeof(*gid)))
if (!memcmp(gid, &default_gid, sizeof(*gid))) 
buf : 		return 0;
buf : 
buf : 	if (event != NETDEV_DOWN && event != NETDEV_UP)
if (event != NETDEV_DOWN && event != NETDEV_UP) 
buf : 		return 0;
buf : 
buf : 	if ((real_dev != event_netdev) &&
if ((real_dev != event_netdev) && 
buf : 	    (event == NETDEV_DOWN) &&
buf : 	    rdma_link_local_addr((struct in6_addr *)gid))
buf : 		return 0;
buf : 
buf : 	iboe = &ibdev->iboe;
buf : 	spin_lock(&iboe->lock);
buf : 
buf : 	for (port = 1; port <= ibdev->dev->caps.num_ports; ++port)
for (port = 1; port <= ibdev->dev->caps.num_ports; ++port) 
buf : 		if ((netif_is_bond_master(real_dev) &&
buf : 		     (real_dev == iboe->masters[port - 1])) ||
buf : 		     (!netif_is_bond_master(real_dev) &&
if_is_bond_master(real_dev) && 
buf : 		     (real_dev == iboe->netdevs[port - 1])))
buf : 			update_gid_table(ibdev, port, gid,
buf : 					 event == NETDEV_DOWN, 0);
buf : 
buf : 	spin_unlock(&iboe->lock);
buf : 	return 0;
buf : 
buf : }
buf : 
buf : static u8 mlx4_ib_get_dev_port(struct net_device *dev,
buf : 			       struct mlx4_ib_dev *ibdev)
buf : {
buf : 	u8 port = 0;
buf : 	struct mlx4_ib_iboe *iboe;
buf : 	struct net_device *real_dev = rdma_vlan_dev_real_dev(dev) ?
buf : 				rdma_vlan_dev_real_dev(dev) : dev;
buf : 
buf : 	iboe = &ibdev->iboe;
buf : 
buf : 	for (port = 1; port <= ibdev->dev->caps.num_ports; ++port)
for (port = 1; port <= ibdev->dev->caps.num_ports; ++port) 
buf : 		if ((netif_is_bond_master(real_dev) &&
buf : 		     (real_dev == iboe->masters[port - 1])) ||
buf : 		     (!netif_is_bond_master(real_dev) &&
if_is_bond_master(real_dev) && 
buf : 		     (real_dev == iboe->netdevs[port - 1])))
buf : 			break;
buf : 
buf : 	if ((port == 0) || (port > ibdev->dev->caps.num_ports))
if ((port == 0) || (port > ibdev->dev->caps.num_ports)) 
buf : 		return 0;
buf : 	else
buf : 		return port;
buf : }
buf : 
buf : static int mlx4_ib_inet_event(struct notifier_block *this, unsigned long event,
ifier_block *this, unsigned long event, 
buf : 				void *ptr)
buf : {
buf : 	struct mlx4_ib_dev *ibdev;
buf : 	struct in_ifaddr *ifa = ptr;
ifaddr *ifa = ptr; 
buf : 	union ib_gid gid;
buf : 	struct net_device *event_netdev = ifa->ifa_dev->dev;
ifa->ifa_dev->dev; 
buf : 
buf : 	ipv6_addr_set_v4mapped(ifa->ifa_address, (struct in6_addr *)&gid);
buf : 
buf : 	ibdev = container_of(this, struct mlx4_ib_dev, iboe.nb_inet);
buf : 
buf : 	mlx4_ib_addr_event(event, event_netdev, ibdev, &gid);
buf : 	return NOTIFY_DONE;
buf : }
buf : 
buf : #if IS_ENABLED(CONFIG_IPV6)
if IS_ENABLED(CONFIG_IPV6) 
buf : static int mlx4_ib_inet6_event(struct notifier_block *this, unsigned long event,
buf : 				void *ptr)
buf : {
buf : 	struct mlx4_ib_dev *ibdev;
buf : 	struct inet6_ifaddr *ifa = ptr;
ifaddr *ifa = ptr; 
buf : 	union  ib_gid *gid = (union ib_gid *)&ifa->addr;
buf : 	struct net_device *event_netdev = ifa->idev->dev;
ifa->idev->dev; 
buf : 
buf : 	ibdev = container_of(this, struct mlx4_ib_dev, iboe.nb_inet6);
buf : 
buf : 	mlx4_ib_addr_event(event, event_netdev, ibdev, gid);
buf : 	return NOTIFY_DONE;
buf : }
buf : #endif
if 
buf : 
buf : #define MLX4_IB_INVALID_MAC	((u64)-1)
buf : static void mlx4_ib_update_qps(struct mlx4_ib_dev *ibdev,
buf : 			       struct net_device *dev,
buf : 			       int port)
buf : {
buf : 	u64 new_smac = 0;
buf : 	u64 release_mac = MLX4_IB_INVALID_MAC;
buf : 	struct mlx4_ib_qp *qp;
buf : 
buf : 	read_lock(&dev_base_lock);
buf : 	new_smac = mlx4_mac_to_u64(dev->dev_addr);
buf : 	read_unlock(&dev_base_lock);
buf : 
buf : 	mutex_lock(&ibdev->qp1_proxy_lock[port - 1]);
buf : 	qp = ibdev->qp1_proxy[port - 1];
buf : 	if (qp) {
if (qp) { 
buf : 		int new_smac_index;
buf : 		u64 old_smac = qp->pri.smac;
buf : 		struct mlx4_update_qp_params update_params;
buf : 
buf : 		if (new_smac == old_smac)
if (new_smac == old_smac) 
buf : 			goto unlock;
buf : 
buf : 		new_smac_index = mlx4_register_mac(ibdev->dev, port, new_smac);
buf : 
buf : 		if (new_smac_index < 0)
if (new_smac_index < 0) 
buf : 			goto unlock;
buf : 
buf : 		update_params.smac_index = new_smac_index;
buf : 		if (mlx4_update_qp(ibdev->dev, &qp->mqp, MLX4_UPDATE_QP_SMAC,
if (mlx4_update_qp(ibdev->dev, &qp->mqp, MLX4_UPDATE_QP_SMAC, 
buf : 				   &update_params)) {
buf : 			release_mac = new_smac;
buf : 			goto unlock;
buf : 		}
buf : 
buf : 		qp->pri.smac = new_smac;
buf : 		qp->pri.smac_index = new_smac_index;
buf : 
buf : 		release_mac = old_smac;
buf : 	}
buf : 
buf : unlock:
buf : 	mutex_unlock(&ibdev->qp1_proxy_lock[port - 1]);
buf : 	if (release_mac != MLX4_IB_INVALID_MAC)
if (release_mac != MLX4_IB_INVALID_MAC) 
buf : 		mlx4_unregister_mac(ibdev->dev, port, release_mac);
buf : }
buf : 
buf : static void mlx4_ib_get_dev_addr(struct net_device *dev,
buf : 				 struct mlx4_ib_dev *ibdev, u8 port)
buf : {
buf : 	struct in_device *in_dev;
buf : #if IS_ENABLED(CONFIG_IPV6)
if IS_ENABLED(CONFIG_IPV6) 
buf : 	struct inet6_dev *in6_dev;
buf : 	union ib_gid  *pgid;
buf : 	struct inet6_ifaddr *ifp;
ifaddr *ifp; 
buf : #endif
buf : 	union ib_gid gid;
buf : 
buf : 
buf : 	if ((port == 0) || (port > ibdev->dev->caps.num_ports))
if ((port == 0) || (port > ibdev->dev->caps.num_ports)) 
buf : 		return;
buf : 
buf : 	/* IPv4 gids */
buf : 	in_dev = in_dev_get(dev);
buf : 	if (in_dev) {
if (in_dev) { 
buf : 		for_ifa(in_dev) {
for_ifa(in_dev) { 
buf : 			/*ifa->ifa_address;*/
buf : 			ipv6_addr_set_v4mapped(ifa->ifa_address,
ifa->ifa_address, 
buf : 					       (struct in6_addr *)&gid);
buf : 			update_gid_table(ibdev, port, &gid, 0, 0);
buf : 		}
buf : 		endfor_ifa(in_dev);
ifa(in_dev); 
buf : 		in_dev_put(in_dev);
buf : 	}
buf : #if IS_ENABLED(CONFIG_IPV6)
if IS_ENABLED(CONFIG_IPV6) 
buf : 	/* IPv6 gids */
buf : 	in6_dev = in6_dev_get(dev);
buf : 	if (in6_dev) {
if (in6_dev) { 
buf : 		read_lock_bh(&in6_dev->lock);
buf : 		list_for_each_entry(ifp, &in6_dev->addr_list, if_list) {
ifp, &in6_dev->addr_list, if_list) { 
buf : 			pgid = (union ib_gid *)&ifp->addr;
buf : 			update_gid_table(ibdev, port, pgid, 0, 0);
buf : 		}
buf : 		read_unlock_bh(&in6_dev->lock);
buf : 		in6_dev_put(in6_dev);
buf : 	}
buf : #endif
if 
buf : }
buf : 
buf : static void mlx4_ib_set_default_gid(struct mlx4_ib_dev *ibdev,
buf : 				 struct  net_device *dev, u8 port)
buf : {
buf : 	union ib_gid gid;
buf : 	mlx4_make_default_gid(dev, &gid);
buf : 	update_gid_table(ibdev, port, &gid, 0, 1);
buf : }
buf : 
buf : static int mlx4_ib_init_gid_table(struct mlx4_ib_dev *ibdev)
buf : {
buf : 	struct	net_device *dev;
buf : 	struct mlx4_ib_iboe *iboe = &ibdev->iboe;
buf : 	int i;
buf : 
buf : 	for (i = 1; i <= ibdev->num_ports; ++i)
for (i = 1; i <= ibdev->num_ports; ++i) 
buf : 		if (reset_gid_table(ibdev, i))
buf : 			return -1;
buf : 
buf : 	read_lock(&dev_base_lock);
buf : 	spin_lock(&iboe->lock);
buf : 
buf : 	for_each_netdev(&init_net, dev) {
for_each_netdev(&init_net, dev) { 
buf : 		u8 port = mlx4_ib_get_dev_port(dev, ibdev);
buf : 		if (port)
if (port) 
buf : 			mlx4_ib_get_dev_addr(dev, ibdev, port);
buf : 	}
buf : 
buf : 	spin_unlock(&iboe->lock);
buf : 	read_unlock(&dev_base_lock);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void mlx4_ib_scan_netdevs(struct mlx4_ib_dev *ibdev,
buf : 				 struct net_device *dev,
buf : 				 unsigned long event)
buf : 
buf : {
buf : 	struct mlx4_ib_iboe *iboe;
buf : 	int update_qps_port = -1;
buf : 	int port;
buf : 
buf : 	iboe = &ibdev->iboe;
buf : 
buf : 	spin_lock(&iboe->lock);
buf : 	mlx4_foreach_ib_transport_port(port, ibdev->dev) {
foreach_ib_transport_port(port, ibdev->dev) { 
buf : 		enum ib_port_state	port_state = IB_PORT_NOP;
buf : 		struct net_device *old_master = iboe->masters[port - 1];
buf : 		struct net_device *curr_netdev;
buf : 		struct net_device *curr_master;
buf : 
buf : 		iboe->netdevs[port - 1] =
buf : 			mlx4_get_protocol_dev(ibdev->dev, MLX4_PROT_ETH, port);
buf : 		if (iboe->netdevs[port - 1])
if (iboe->netdevs[port - 1]) 
buf : 			mlx4_ib_set_default_gid(ibdev,
buf : 						iboe->netdevs[port - 1], port);
buf : 		curr_netdev = iboe->netdevs[port - 1];
buf : 
buf : 		if (iboe->netdevs[port - 1] &&
if (iboe->netdevs[port - 1] && 
buf : 		    netif_is_bond_slave(iboe->netdevs[port - 1])) {
buf : 			iboe->masters[port - 1] = netdev_master_upper_dev_get(
buf : 				iboe->netdevs[port - 1]);
buf : 		} else {
buf : 			iboe->masters[port - 1] = NULL;
buf : 		}
buf : 		curr_master = iboe->masters[port - 1];
buf : 
buf : 		if (dev == iboe->netdevs[port - 1] &&
if (dev == iboe->netdevs[port - 1] && 
buf : 		    (event == NETDEV_CHANGEADDR || event == NETDEV_REGISTER ||
buf : 		     event == NETDEV_UP || event == NETDEV_CHANGE))
buf : 			update_qps_port = port;
buf : 
buf : 		if (curr_netdev) {
if (curr_netdev) { 
buf : 			port_state = (netif_running(curr_netdev) && netif_carrier_ok(curr_netdev)) ?
buf : 						IB_PORT_ACTIVE : IB_PORT_DOWN;
buf : 			mlx4_ib_set_default_gid(ibdev, curr_netdev, port);
buf : 		} else {
buf : 			reset_gid_table(ibdev, port);
buf : 		}
buf : 		/* if using bonding/team and a slave port is down, we don't the bond IP
if using bonding/team and a slave port is down, we don't the bond IP 
buf : 		 * based gids in the table since flows that select port by gid may get
buf : 		 * the down port.
buf : 		 */
buf : 		if (curr_master && (port_state == IB_PORT_DOWN)) {
if (curr_master && (port_state == IB_PORT_DOWN)) { 
buf : 			reset_gid_table(ibdev, port);
buf : 			mlx4_ib_set_default_gid(ibdev, curr_netdev, port);
buf : 		}
buf : 		/* if bonding is used it is possible that we add it to masters
if bonding is used it is possible that we add it to masters 
buf : 		 * only after IP address is assigned to the net bonding
buf : 		 * interface.
buf : 		*/
buf : 		if (curr_master && (old_master != curr_master)) {
if (curr_master && (old_master != curr_master)) { 
buf : 			reset_gid_table(ibdev, port);
buf : 			mlx4_ib_set_default_gid(ibdev, curr_netdev, port);
buf : 			mlx4_ib_get_dev_addr(curr_master, ibdev, port);
buf : 		}
buf : 
buf : 		if (!curr_master && (old_master != curr_master)) {
if (!curr_master && (old_master != curr_master)) { 
buf : 			reset_gid_table(ibdev, port);
buf : 			mlx4_ib_set_default_gid(ibdev, curr_netdev, port);
buf : 			mlx4_ib_get_dev_addr(curr_netdev, ibdev, port);
buf : 		}
buf : 	}
buf : 
buf : 	spin_unlock(&iboe->lock);
buf : 
buf : 	if (update_qps_port > 0)
if (update_qps_port > 0) 
buf : 		mlx4_ib_update_qps(ibdev, dev, update_qps_port);
buf : }
buf : 
buf : static int mlx4_ib_netdev_event(struct notifier_block *this,
ifier_block *this, 
buf : 				unsigned long event, void *ptr)
buf : {
buf : 	struct net_device *dev = netdev_notifier_info_to_dev(ptr);
ifier_info_to_dev(ptr); 
buf : 	struct mlx4_ib_dev *ibdev;
buf : 
buf : 	if (!net_eq(dev_net(dev), &init_net))
if (!net_eq(dev_net(dev), &init_net)) 
buf : 		return NOTIFY_DONE;
buf : 
buf : 	ibdev = container_of(this, struct mlx4_ib_dev, iboe.nb);
buf : 	mlx4_ib_scan_netdevs(ibdev, dev, event);
buf : 
buf : 	return NOTIFY_DONE;
buf : }
buf : 
buf : static void init_pkeys(struct mlx4_ib_dev *ibdev)
buf : {
buf : 	int port;
buf : 	int slave;
buf : 	int i;
buf : 
buf : 	if (mlx4_is_master(ibdev->dev)) {
if (mlx4_is_master(ibdev->dev)) { 
buf : 		for (slave = 0; slave <= ibdev->dev->num_vfs; ++slave) {
for (slave = 0; slave <= ibdev->dev->num_vfs; ++slave) { 
buf : 			for (port = 1; port <= ibdev->dev->caps.num_ports; ++port) {
buf : 				for (i = 0;
for (i = 0; 
buf : 				     i < ibdev->dev->phys_caps.pkey_phys_table_len[port];
buf : 				     ++i) {
buf : 					ibdev->pkeys.virt2phys_pkey[slave][port - 1][i] =
buf : 					/* master has the identity virt2phys pkey mapping */
buf : 						(slave == mlx4_master_func_num(ibdev->dev) || !i) ? i :
buf : 							ibdev->dev->phys_caps.pkey_phys_table_len[port] - 1;
buf : 					mlx4_sync_pkey_table(ibdev->dev, slave, port, i,
buf : 							     ibdev->pkeys.virt2phys_pkey[slave][port - 1][i]);
buf : 				}
buf : 			}
buf : 		}
buf : 		/* initialize pkey cache */
buf : 		for (port = 1; port <= ibdev->dev->caps.num_ports; ++port) {
for (port = 1; port <= ibdev->dev->caps.num_ports; ++port) { 
buf : 			for (i = 0;
buf : 			     i < ibdev->dev->phys_caps.pkey_phys_table_len[port];
buf : 			     ++i)
buf : 				ibdev->pkeys.phys_pkey_cache[port-1][i] =
buf : 					(i) ? 0 : 0xFFFF;
buf : 		}
buf : 	}
buf : }
buf : 
buf : static void mlx4_ib_alloc_eqs(struct mlx4_dev *dev, struct mlx4_ib_dev *ibdev)
buf : {
buf : 	char name[80];
buf : 	int eq_per_port = 0;
buf : 	int added_eqs = 0;
buf : 	int total_eqs = 0;
buf : 	int i, j, eq;
buf : 
buf : 	/* Legacy mode or comp_pool is not large enough */
buf : 	if (dev->caps.comp_pool == 0 ||
if (dev->caps.comp_pool == 0 || 
buf : 	    dev->caps.num_ports > dev->caps.comp_pool)
buf : 		return;
buf : 
buf : 	eq_per_port = rounddown_pow_of_two(dev->caps.comp_pool/
buf : 					dev->caps.num_ports);
buf : 
buf : 	/* Init eq table */
buf : 	added_eqs = 0;
buf : 	mlx4_foreach_port(i, dev, MLX4_PORT_TYPE_IB)
foreach_port(i, dev, MLX4_PORT_TYPE_IB) 
buf : 		added_eqs += eq_per_port;
buf : 
buf : 	total_eqs = dev->caps.num_comp_vectors + added_eqs;
buf : 
buf : 	ibdev->eq_table = kzalloc(total_eqs * sizeof(int), GFP_KERNEL);
buf : 	if (!ibdev->eq_table)
if (!ibdev->eq_table) 
buf : 		return;
buf : 
buf : 	ibdev->eq_added = added_eqs;
buf : 
buf : 	eq = 0;
buf : 	mlx4_foreach_port(i, dev, MLX4_PORT_TYPE_IB) {
foreach_port(i, dev, MLX4_PORT_TYPE_IB) { 
buf : 		for (j = 0; j < eq_per_port; j++) {
buf : 			snprintf(name, sizeof(name), "mlx4-ib-%d-%d@%s",
buf : 				 i, j, dev->pdev->bus->name);
buf : 			/* Set IRQ for specific name (per ring) */
ific name (per ring) */ 
buf : 			if (mlx4_assign_eq(dev, name, NULL,
buf : 					   &ibdev->eq_table[eq])) {
buf : 				/* Use legacy (same as mlx4_en driver) */
buf : 				pr_warn("Can't allocate EQ %d; reverting to legacy\n", eq);
buf : 				ibdev->eq_table[eq] =
buf : 					(eq % dev->caps.num_comp_vectors);
buf : 			}
buf : 			eq++;
buf : 		}
buf : 	}
buf : 
buf : 	/* Fill the reset of the vector with legacy EQ */
buf : 	for (i = 0, eq = added_eqs; i < dev->caps.num_comp_vectors; i++)
for (i = 0, eq = added_eqs; i < dev->caps.num_comp_vectors; i++) 
buf : 		ibdev->eq_table[eq++] = i;
buf : 
buf : 	/* Advertise the new number of EQs to clients */
buf : 	ibdev->ib_dev.num_comp_vectors = total_eqs;
buf : }
buf : 
buf : static void mlx4_ib_free_eqs(struct mlx4_dev *dev, struct mlx4_ib_dev *ibdev)
buf : {
buf : 	int i;
buf : 
buf : 	/* no additional eqs were added */
buf : 	if (!ibdev->eq_table)
if (!ibdev->eq_table) 
buf : 		return;
buf : 
buf : 	/* Reset the advertised EQ number */
buf : 	ibdev->ib_dev.num_comp_vectors = dev->caps.num_comp_vectors;
buf : 
buf : 	/* Free only the added eqs */
buf : 	for (i = 0; i < ibdev->eq_added; i++) {
for (i = 0; i < ibdev->eq_added; i++) { 
buf : 		/* Don't free legacy eqs if used */
buf : 		if (ibdev->eq_table[i] <= dev->caps.num_comp_vectors)
if (ibdev->eq_table[i] <= dev->caps.num_comp_vectors) 
buf : 			continue;
buf : 		mlx4_release_eq(dev, ibdev->eq_table[i]);
buf : 	}
buf : 
buf : 	kfree(ibdev->eq_table);
buf : }
buf : 
buf : static void *mlx4_ib_add(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_ib_dev *ibdev;
buf : 	int num_ports = 0;
buf : 	int i, j;
buf : 	int err;
buf : 	struct mlx4_ib_iboe *iboe;
buf : 	int ib_num_ports = 0;
buf : 
buf : 	pr_info_once("%s", mlx4_ib_version);
buf : 
buf : 	num_ports = 0;
buf : 	mlx4_foreach_ib_transport_port(i, dev)
foreach_ib_transport_port(i, dev) 
buf : 		num_ports++;
buf : 
buf : 	/* No point in registering a device with no ports... */
buf : 	if (num_ports == 0)
if (num_ports == 0) 
buf : 		return NULL;
buf : 
buf : 	ibdev = (struct mlx4_ib_dev *) ib_alloc_device(sizeof *ibdev);
buf : 	if (!ibdev) {
if (!ibdev) { 
buf : 		dev_err(&dev->pdev->dev, "Device struct alloc failed\n");
buf : 		return NULL;
buf : 	}
buf : 
buf : 	iboe = &ibdev->iboe;
buf : 
buf : 	if (mlx4_pd_alloc(dev, &ibdev->priv_pdn))
if (mlx4_pd_alloc(dev, &ibdev->priv_pdn)) 
buf : 		goto err_dealloc;
buf : 
buf : 	if (mlx4_uar_alloc(dev, &ibdev->priv_uar))
if (mlx4_uar_alloc(dev, &ibdev->priv_uar)) 
buf : 		goto err_pd;
buf : 
buf : 	ibdev->uar_map = ioremap((phys_addr_t) ibdev->priv_uar.pfn << PAGE_SHIFT,
buf : 				 PAGE_SIZE);
buf : 	if (!ibdev->uar_map)
if (!ibdev->uar_map) 
buf : 		goto err_uar;
buf : 	MLX4_INIT_DOORBELL_LOCK(&ibdev->uar_lock);
buf : 
buf : 	ibdev->dev = dev;
buf : 
buf : 	strlcpy(ibdev->ib_dev.name, "mlx4_%d", IB_DEVICE_NAME_MAX);
buf : 	ibdev->ib_dev.owner		= THIS_MODULE;
buf : 	ibdev->ib_dev.node_type		= RDMA_NODE_IB_CA;
buf : 	ibdev->ib_dev.local_dma_lkey	= dev->caps.reserved_lkey;
buf : 	ibdev->num_ports		= num_ports;
buf : 	ibdev->ib_dev.phys_port_cnt     = ibdev->num_ports;
buf : 	ibdev->ib_dev.num_comp_vectors	= dev->caps.num_comp_vectors;
buf : 	ibdev->ib_dev.dma_device	= &dev->pdev->dev;
buf : 
buf : 	if (dev->caps.userspace_caps)
if (dev->caps.userspace_caps) 
buf : 		ibdev->ib_dev.uverbs_abi_ver = MLX4_IB_UVERBS_ABI_VERSION;
buf : 	else
buf : 		ibdev->ib_dev.uverbs_abi_ver = MLX4_IB_UVERBS_NO_DEV_CAPS_ABI_VERSION;
buf : 
buf : 	ibdev->ib_dev.uverbs_cmd_mask	=
buf : 		(1ull << IB_USER_VERBS_CMD_GET_CONTEXT)		|
buf : 		(1ull << IB_USER_VERBS_CMD_QUERY_DEVICE)	|
buf : 		(1ull << IB_USER_VERBS_CMD_QUERY_PORT)		|
buf : 		(1ull << IB_USER_VERBS_CMD_ALLOC_PD)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DEALLOC_PD)		|
buf : 		(1ull << IB_USER_VERBS_CMD_REG_MR)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DEREG_MR)		|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_COMP_CHANNEL)	|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_CQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_RESIZE_CQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DESTROY_CQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_QP)		|
buf : 		(1ull << IB_USER_VERBS_CMD_MODIFY_QP)		|
buf : 		(1ull << IB_USER_VERBS_CMD_QUERY_QP)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DESTROY_QP)		|
buf : 		(1ull << IB_USER_VERBS_CMD_ATTACH_MCAST)	|
buf : 		(1ull << IB_USER_VERBS_CMD_DETACH_MCAST)	|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_SRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_MODIFY_SRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_QUERY_SRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_DESTROY_SRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_CREATE_XSRQ)		|
buf : 		(1ull << IB_USER_VERBS_CMD_OPEN_QP);
buf : 
buf : 	ibdev->ib_dev.query_device	= mlx4_ib_query_device;
buf : 	ibdev->ib_dev.query_port	= mlx4_ib_query_port;
buf : 	ibdev->ib_dev.get_link_layer	= mlx4_ib_port_link_layer;
buf : 	ibdev->ib_dev.query_gid		= mlx4_ib_query_gid;
buf : 	ibdev->ib_dev.query_pkey	= mlx4_ib_query_pkey;
buf : 	ibdev->ib_dev.modify_device	= mlx4_ib_modify_device;
ify_device	= mlx4_ib_modify_device; 
buf : 	ibdev->ib_dev.modify_port	= mlx4_ib_modify_port;
buf : 	ibdev->ib_dev.alloc_ucontext	= mlx4_ib_alloc_ucontext;
buf : 	ibdev->ib_dev.dealloc_ucontext	= mlx4_ib_dealloc_ucontext;
buf : 	ibdev->ib_dev.mmap		= mlx4_ib_mmap;
buf : 	ibdev->ib_dev.alloc_pd		= mlx4_ib_alloc_pd;
buf : 	ibdev->ib_dev.dealloc_pd	= mlx4_ib_dealloc_pd;
buf : 	ibdev->ib_dev.create_ah		= mlx4_ib_create_ah;
buf : 	ibdev->ib_dev.query_ah		= mlx4_ib_query_ah;
buf : 	ibdev->ib_dev.destroy_ah	= mlx4_ib_destroy_ah;
buf : 	ibdev->ib_dev.create_srq	= mlx4_ib_create_srq;
buf : 	ibdev->ib_dev.modify_srq	= mlx4_ib_modify_srq;
ify_srq	= mlx4_ib_modify_srq; 
buf : 	ibdev->ib_dev.query_srq		= mlx4_ib_query_srq;
buf : 	ibdev->ib_dev.destroy_srq	= mlx4_ib_destroy_srq;
buf : 	ibdev->ib_dev.post_srq_recv	= mlx4_ib_post_srq_recv;
buf : 	ibdev->ib_dev.create_qp		= mlx4_ib_create_qp;
buf : 	ibdev->ib_dev.modify_qp		= mlx4_ib_modify_qp;
ify_qp		= mlx4_ib_modify_qp; 
buf : 	ibdev->ib_dev.query_qp		= mlx4_ib_query_qp;
buf : 	ibdev->ib_dev.destroy_qp	= mlx4_ib_destroy_qp;
buf : 	ibdev->ib_dev.post_send		= mlx4_ib_post_send;
buf : 	ibdev->ib_dev.post_recv		= mlx4_ib_post_recv;
buf : 	ibdev->ib_dev.create_cq		= mlx4_ib_create_cq;
buf : 	ibdev->ib_dev.modify_cq		= mlx4_ib_modify_cq;
ify_cq		= mlx4_ib_modify_cq; 
buf : 	ibdev->ib_dev.resize_cq		= mlx4_ib_resize_cq;
buf : 	ibdev->ib_dev.destroy_cq	= mlx4_ib_destroy_cq;
buf : 	ibdev->ib_dev.poll_cq		= mlx4_ib_poll_cq;
buf : 	ibdev->ib_dev.req_notify_cq	= mlx4_ib_arm_cq;
ify_cq	= mlx4_ib_arm_cq; 
buf : 	ibdev->ib_dev.get_dma_mr	= mlx4_ib_get_dma_mr;
buf : 	ibdev->ib_dev.reg_user_mr	= mlx4_ib_reg_user_mr;
buf : 	ibdev->ib_dev.dereg_mr		= mlx4_ib_dereg_mr;
buf : 	ibdev->ib_dev.alloc_fast_reg_mr = mlx4_ib_alloc_fast_reg_mr;
buf : 	ibdev->ib_dev.alloc_fast_reg_page_list = mlx4_ib_alloc_fast_reg_page_list;
buf : 	ibdev->ib_dev.free_fast_reg_page_list  = mlx4_ib_free_fast_reg_page_list;
buf : 	ibdev->ib_dev.attach_mcast	= mlx4_ib_mcg_attach;
buf : 	ibdev->ib_dev.detach_mcast	= mlx4_ib_mcg_detach;
buf : 	ibdev->ib_dev.process_mad	= mlx4_ib_process_mad;
buf : 
buf : 	if (!mlx4_is_slave(ibdev->dev)) {
if (!mlx4_is_slave(ibdev->dev)) { 
buf : 		ibdev->ib_dev.alloc_fmr		= mlx4_ib_fmr_alloc;
buf : 		ibdev->ib_dev.map_phys_fmr	= mlx4_ib_map_phys_fmr;
buf : 		ibdev->ib_dev.unmap_fmr		= mlx4_ib_unmap_fmr;
buf : 		ibdev->ib_dev.dealloc_fmr	= mlx4_ib_fmr_dealloc;
buf : 	}
buf : 
buf : 	if (dev->caps.flags & MLX4_DEV_CAP_FLAG_MEM_WINDOW ||
if (dev->caps.flags & MLX4_DEV_CAP_FLAG_MEM_WINDOW || 
buf : 	    dev->caps.bmme_flags & MLX4_BMME_FLAG_TYPE_2_WIN) {
buf : 		ibdev->ib_dev.alloc_mw = mlx4_ib_alloc_mw;
buf : 		ibdev->ib_dev.bind_mw = mlx4_ib_bind_mw;
buf : 		ibdev->ib_dev.dealloc_mw = mlx4_ib_dealloc_mw;
buf : 
buf : 		ibdev->ib_dev.uverbs_cmd_mask |=
buf : 			(1ull << IB_USER_VERBS_CMD_ALLOC_MW) |
buf : 			(1ull << IB_USER_VERBS_CMD_DEALLOC_MW);
buf : 	}
buf : 
buf : 	if (dev->caps.flags & MLX4_DEV_CAP_FLAG_XRC) {
if (dev->caps.flags & MLX4_DEV_CAP_FLAG_XRC) { 
buf : 		ibdev->ib_dev.alloc_xrcd = mlx4_ib_alloc_xrcd;
buf : 		ibdev->ib_dev.dealloc_xrcd = mlx4_ib_dealloc_xrcd;
buf : 		ibdev->ib_dev.uverbs_cmd_mask |=
buf : 			(1ull << IB_USER_VERBS_CMD_OPEN_XRCD) |
buf : 			(1ull << IB_USER_VERBS_CMD_CLOSE_XRCD);
buf : 	}
buf : 
buf : 	if (check_flow_steering_support(dev)) {
if (check_flow_steering_support(dev)) { 
buf : 		ibdev->steering_support = MLX4_STEERING_MODE_DEVICE_MANAGED;
buf : 		ibdev->ib_dev.create_flow	= mlx4_ib_create_flow;
buf : 		ibdev->ib_dev.destroy_flow	= mlx4_ib_destroy_flow;
buf : 
buf : 		ibdev->ib_dev.uverbs_ex_cmd_mask	|=
buf : 			(1ull << IB_USER_VERBS_EX_CMD_CREATE_FLOW) |
buf : 			(1ull << IB_USER_VERBS_EX_CMD_DESTROY_FLOW);
buf : 	}
buf : 
buf : 	mlx4_ib_alloc_eqs(dev, ibdev);
buf : 
buf : 	spin_lock_init(&iboe->lock);
buf : 
buf : 	if (init_node_data(ibdev))
if (init_node_data(ibdev)) 
buf : 		goto err_map;
buf : 
buf : 	for (i = 0; i < ibdev->num_ports; ++i) {
for (i = 0; i < ibdev->num_ports; ++i) { 
buf : 		mutex_init(&ibdev->qp1_proxy_lock[i]);
buf : 		if (mlx4_ib_port_link_layer(&ibdev->ib_dev, i + 1) ==
if (mlx4_ib_port_link_layer(&ibdev->ib_dev, i + 1) == 
buf : 						IB_LINK_LAYER_ETHERNET) {
buf : 			err = mlx4_counter_alloc(ibdev->dev, &ibdev->counters[i]);
buf : 			if (err)
if (err) 
buf : 				ibdev->counters[i] = -1;
buf : 		} else {
buf : 			ibdev->counters[i] = -1;
buf : 		}
buf : 	}
buf : 
buf : 	mlx4_foreach_port(i, dev, MLX4_PORT_TYPE_IB)
foreach_port(i, dev, MLX4_PORT_TYPE_IB) 
buf : 		ib_num_ports++;
buf : 
buf : 	spin_lock_init(&ibdev->sm_lock);
buf : 	mutex_init(&ibdev->cap_mask_mutex);
buf : 
buf : 	if (ibdev->steering_support == MLX4_STEERING_MODE_DEVICE_MANAGED &&
if (ibdev->steering_support == MLX4_STEERING_MODE_DEVICE_MANAGED && 
buf : 	    ib_num_ports) {
buf : 		ibdev->steer_qpn_count = MLX4_IB_UC_MAX_NUM_QPS;
buf : 		err = mlx4_qp_reserve_range(dev, ibdev->steer_qpn_count,
buf : 					    MLX4_IB_UC_STEER_QPN_ALIGN,
buf : 					    &ibdev->steer_qpn_base);
buf : 		if (err)
if (err) 
buf : 			goto err_counter;
buf : 
buf : 		ibdev->ib_uc_qpns_bitmap =
buf : 			kmalloc(BITS_TO_LONGS(ibdev->steer_qpn_count) *
buf : 				sizeof(long),
buf : 				GFP_KERNEL);
buf : 		if (!ibdev->ib_uc_qpns_bitmap) {
if (!ibdev->ib_uc_qpns_bitmap) { 
buf : 			dev_err(&dev->pdev->dev, "bit map alloc failed\n");
buf : 			goto err_steer_qp_release;
buf : 		}
buf : 
buf : 		bitmap_zero(ibdev->ib_uc_qpns_bitmap, ibdev->steer_qpn_count);
buf : 
buf : 		err = mlx4_FLOW_STEERING_IB_UC_QP_RANGE(
buf : 				dev, ibdev->steer_qpn_base,
buf : 				ibdev->steer_qpn_base +
buf : 				ibdev->steer_qpn_count - 1);
buf : 		if (err)
if (err) 
buf : 			goto err_steer_free_bitmap;
buf : 	}
buf : 
buf : 	if (ib_register_device(&ibdev->ib_dev, NULL))
if (ib_register_device(&ibdev->ib_dev, NULL)) 
buf : 		goto err_steer_free_bitmap;
buf : 
buf : 	if (mlx4_ib_mad_init(ibdev))
if (mlx4_ib_mad_init(ibdev)) 
buf : 		goto err_reg;
buf : 
buf : 	if (mlx4_ib_init_sriov(ibdev))
if (mlx4_ib_init_sriov(ibdev)) 
buf : 		goto err_mad;
buf : 
buf : 	if (dev->caps.flags & MLX4_DEV_CAP_FLAG_IBOE) {
if (dev->caps.flags & MLX4_DEV_CAP_FLAG_IBOE) { 
buf : 		if (!iboe->nb.notifier_call) {
buf : 			iboe->nb.notifier_call = mlx4_ib_netdev_event;
ifier_call = mlx4_ib_netdev_event; 
buf : 			err = register_netdevice_notifier(&iboe->nb);
buf : 			if (err) {
if (err) { 
buf : 				iboe->nb.notifier_call = NULL;
buf : 				goto err_notif;
if; 
buf : 			}
buf : 		}
buf : 		if (!iboe->nb_inet.notifier_call) {
if (!iboe->nb_inet.notifier_call) { 
buf : 			iboe->nb_inet.notifier_call = mlx4_ib_inet_event;
buf : 			err = register_inetaddr_notifier(&iboe->nb_inet);
ifier(&iboe->nb_inet); 
buf : 			if (err) {
buf : 				iboe->nb_inet.notifier_call = NULL;
ifier_call = NULL; 
buf : 				goto err_notif;
buf : 			}
buf : 		}
buf : #if IS_ENABLED(CONFIG_IPV6)
if IS_ENABLED(CONFIG_IPV6) 
buf : 		if (!iboe->nb_inet6.notifier_call) {
buf : 			iboe->nb_inet6.notifier_call = mlx4_ib_inet6_event;
ifier_call = mlx4_ib_inet6_event; 
buf : 			err = register_inet6addr_notifier(&iboe->nb_inet6);
buf : 			if (err) {
if (err) { 
buf : 				iboe->nb_inet6.notifier_call = NULL;
buf : 				goto err_notif;
if; 
buf : 			}
buf : 		}
buf : #endif
if 
buf : 		for (i = 1 ; i <= ibdev->num_ports ; ++i)
for (i = 1 ; i <= ibdev->num_ports ; ++i) 
buf : 			reset_gid_table(ibdev, i);
buf : 		rtnl_lock();
buf : 		mlx4_ib_scan_netdevs(ibdev, NULL, 0);
buf : 		rtnl_unlock();
buf : 		mlx4_ib_init_gid_table(ibdev);
buf : 	}
buf : 
buf : 	for (j = 0; j < ARRAY_SIZE(mlx4_class_attributes); ++j) {
for (j = 0; j < ARRAY_SIZE(mlx4_class_attributes); ++j) { 
buf : 		if (device_create_file(&ibdev->ib_dev.dev,
buf : 				       mlx4_class_attributes[j]))
buf : 			goto err_notif;
if; 
buf : 	}
buf : 
buf : 	ibdev->ib_active = true;
buf : 
buf : 	if (mlx4_is_mfunc(ibdev->dev))
if (mlx4_is_mfunc(ibdev->dev)) 
buf : 		init_pkeys(ibdev);
buf : 
buf : 	/* create paravirt contexts for any VFs which are active */
for any VFs which are active */ 
buf : 	if (mlx4_is_master(ibdev->dev)) {
buf : 		for (j = 0; j < MLX4_MFUNC_MAX; j++) {
for (j = 0; j < MLX4_MFUNC_MAX; j++) { 
buf : 			if (j == mlx4_master_func_num(ibdev->dev))
buf : 				continue;
buf : 			if (mlx4_is_slave_active(ibdev->dev, j))
if (mlx4_is_slave_active(ibdev->dev, j)) 
buf : 				do_slave_init(ibdev, j, 1);
buf : 		}
buf : 	}
buf : 	return ibdev;
buf : 
buf : err_notif:
if: 
buf : 	if (ibdev->iboe.nb.notifier_call) {
buf : 		if (unregister_netdevice_notifier(&ibdev->iboe.nb))
if (unregister_netdevice_notifier(&ibdev->iboe.nb)) 
buf : 			pr_warn("failure unregistering notifier\n");
buf : 		ibdev->iboe.nb.notifier_call = NULL;
ifier_call = NULL; 
buf : 	}
buf : 	if (ibdev->iboe.nb_inet.notifier_call) {
buf : 		if (unregister_inetaddr_notifier(&ibdev->iboe.nb_inet))
if (unregister_inetaddr_notifier(&ibdev->iboe.nb_inet)) 
buf : 			pr_warn("failure unregistering notifier\n");
buf : 		ibdev->iboe.nb_inet.notifier_call = NULL;
ifier_call = NULL; 
buf : 	}
buf : #if IS_ENABLED(CONFIG_IPV6)
buf : 	if (ibdev->iboe.nb_inet6.notifier_call) {
if (ibdev->iboe.nb_inet6.notifier_call) { 
buf : 		if (unregister_inet6addr_notifier(&ibdev->iboe.nb_inet6))
buf : 			pr_warn("failure unregistering notifier\n");
ifier\n"); 
buf : 		ibdev->iboe.nb_inet6.notifier_call = NULL;
buf : 	}
buf : #endif
if 
buf : 	flush_workqueue(wq);
buf : 
buf : 	mlx4_ib_close_sriov(ibdev);
buf : 
buf : err_mad:
buf : 	mlx4_ib_mad_cleanup(ibdev);
buf : 
buf : err_reg:
buf : 	ib_unregister_device(&ibdev->ib_dev);
buf : 
buf : err_steer_free_bitmap:
buf : 	kfree(ibdev->ib_uc_qpns_bitmap);
buf : 
buf : err_steer_qp_release:
buf : 	if (ibdev->steering_support == MLX4_STEERING_MODE_DEVICE_MANAGED)
if (ibdev->steering_support == MLX4_STEERING_MODE_DEVICE_MANAGED) 
buf : 		mlx4_qp_release_range(dev, ibdev->steer_qpn_base,
buf : 				      ibdev->steer_qpn_count);
buf : err_counter:
buf : 	for (; i; --i)
for (; i; --i) 
buf : 		if (ibdev->counters[i - 1] != -1)
buf : 			mlx4_counter_free(ibdev->dev, ibdev->counters[i - 1]);
buf : 
buf : err_map:
buf : 	iounmap(ibdev->uar_map);
buf : 
buf : err_uar:
buf : 	mlx4_uar_free(dev, &ibdev->priv_uar);
buf : 
buf : err_pd:
buf : 	mlx4_pd_free(dev, ibdev->priv_pdn);
buf : 
buf : err_dealloc:
buf : 	ib_dealloc_device(&ibdev->ib_dev);
buf : 
buf : 	return NULL;
buf : }
buf : 
buf : int mlx4_ib_steer_qp_alloc(struct mlx4_ib_dev *dev, int count, int *qpn)
buf : {
buf : 	int offset;
buf : 
buf : 	WARN_ON(!dev->ib_uc_qpns_bitmap);
buf : 
buf : 	offset = bitmap_find_free_region(dev->ib_uc_qpns_bitmap,
buf : 					 dev->steer_qpn_count,
buf : 					 get_count_order(count));
buf : 	if (offset < 0)
if (offset < 0) 
buf : 		return offset;
buf : 
buf : 	*qpn = dev->steer_qpn_base + offset;
buf : 	return 0;
buf : }
buf : 
buf : void mlx4_ib_steer_qp_free(struct mlx4_ib_dev *dev, u32 qpn, int count)
buf : {
buf : 	if (!qpn ||
if (!qpn || 
buf : 	    dev->steering_support != MLX4_STEERING_MODE_DEVICE_MANAGED)
buf : 		return;
buf : 
buf : 	BUG_ON(qpn < dev->steer_qpn_base);
buf : 
buf : 	bitmap_release_region(dev->ib_uc_qpns_bitmap,
buf : 			      qpn - dev->steer_qpn_base,
buf : 			      get_count_order(count));
buf : }
buf : 
buf : int mlx4_ib_steer_qp_reg(struct mlx4_ib_dev *mdev, struct mlx4_ib_qp *mqp,
buf : 			 int is_attach)
buf : {
buf : 	int err;
buf : 	size_t flow_size;
buf : 	struct ib_flow_attr *flow = NULL;
buf : 	struct ib_flow_spec_ib *ib_spec;
buf : 
buf : 	if (is_attach) {
if (is_attach) { 
buf : 		flow_size = sizeof(struct ib_flow_attr) +
buf : 			    sizeof(struct ib_flow_spec_ib);
buf : 		flow = kzalloc(flow_size, GFP_KERNEL);
buf : 		if (!flow)
if (!flow) 
buf : 			return -ENOMEM;
buf : 		flow->port = mqp->port;
buf : 		flow->num_of_specs = 1;
buf : 		flow->size = flow_size;
buf : 		ib_spec = (struct ib_flow_spec_ib *)(flow + 1);
buf : 		ib_spec->type = IB_FLOW_SPEC_IB;
buf : 		ib_spec->size = sizeof(struct ib_flow_spec_ib);
buf : 		/* Add an empty rule for IB L2 */
for IB L2 */ 
buf : 		memset(&ib_spec->mask, 0, sizeof(ib_spec->mask));
buf : 
buf : 		err = __mlx4_ib_create_flow(&mqp->ibqp, flow,
buf : 					    IB_FLOW_DOMAIN_NIC,
buf : 					    MLX4_FS_REGULAR,
buf : 					    &mqp->reg_id);
buf : 	} else {
buf : 		err = __mlx4_ib_destroy_flow(mdev->dev, mqp->reg_id);
buf : 	}
buf : 	kfree(flow);
buf : 	return err;
buf : }
buf : 
buf : static void mlx4_ib_remove(struct mlx4_dev *dev, void *ibdev_ptr)
buf : {
buf : 	struct mlx4_ib_dev *ibdev = ibdev_ptr;
buf : 	int p;
buf : 
buf : 	mlx4_ib_close_sriov(ibdev);
buf : 	mlx4_ib_mad_cleanup(ibdev);
buf : 	ib_unregister_device(&ibdev->ib_dev);
buf : 	if (ibdev->iboe.nb.notifier_call) {
if (ibdev->iboe.nb.notifier_call) { 
buf : 		if (unregister_netdevice_notifier(&ibdev->iboe.nb))
buf : 			pr_warn("failure unregistering notifier\n");
ifier\n"); 
buf : 		ibdev->iboe.nb.notifier_call = NULL;
buf : 	}
buf : 
buf : 	if (ibdev->steering_support == MLX4_STEERING_MODE_DEVICE_MANAGED) {
if (ibdev->steering_support == MLX4_STEERING_MODE_DEVICE_MANAGED) { 
buf : 		mlx4_qp_release_range(dev, ibdev->steer_qpn_base,
buf : 				      ibdev->steer_qpn_count);
buf : 		kfree(ibdev->ib_uc_qpns_bitmap);
buf : 	}
buf : 
buf : 	if (ibdev->iboe.nb_inet.notifier_call) {
if (ibdev->iboe.nb_inet.notifier_call) { 
buf : 		if (unregister_inetaddr_notifier(&ibdev->iboe.nb_inet))
buf : 			pr_warn("failure unregistering notifier\n");
ifier\n"); 
buf : 		ibdev->iboe.nb_inet.notifier_call = NULL;
buf : 	}
buf : #if IS_ENABLED(CONFIG_IPV6)
if IS_ENABLED(CONFIG_IPV6) 
buf : 	if (ibdev->iboe.nb_inet6.notifier_call) {
buf : 		if (unregister_inet6addr_notifier(&ibdev->iboe.nb_inet6))
if (unregister_inet6addr_notifier(&ibdev->iboe.nb_inet6)) 
buf : 			pr_warn("failure unregistering notifier\n");
buf : 		ibdev->iboe.nb_inet6.notifier_call = NULL;
ifier_call = NULL; 
buf : 	}
buf : #endif
buf : 
buf : 	iounmap(ibdev->uar_map);
buf : 	for (p = 0; p < ibdev->num_ports; ++p)
for (p = 0; p < ibdev->num_ports; ++p) 
buf : 		if (ibdev->counters[p] != -1)
buf : 			mlx4_counter_free(ibdev->dev, ibdev->counters[p]);
buf : 	mlx4_foreach_port(p, dev, MLX4_PORT_TYPE_IB)
foreach_port(p, dev, MLX4_PORT_TYPE_IB) 
buf : 		mlx4_CLOSE_PORT(dev, p);
buf : 
buf : 	mlx4_ib_free_eqs(dev, ibdev);
buf : 
buf : 	mlx4_uar_free(dev, &ibdev->priv_uar);
buf : 	mlx4_pd_free(dev, ibdev->priv_pdn);
buf : 	ib_dealloc_device(&ibdev->ib_dev);
buf : }
buf : 
buf : static void do_slave_init(struct mlx4_ib_dev *ibdev, int slave, int do_init)
buf : {
buf : 	struct mlx4_ib_demux_work **dm = NULL;
buf : 	struct mlx4_dev *dev = ibdev->dev;
buf : 	int i;
buf : 	unsigned long flags;
buf : 	struct mlx4_active_ports actv_ports;
buf : 	unsigned int ports;
buf : 	unsigned int first_port;
buf : 
buf : 	if (!mlx4_is_master(dev))
if (!mlx4_is_master(dev)) 
buf : 		return;
buf : 
buf : 	actv_ports = mlx4_get_active_ports(dev, slave);
buf : 	ports = bitmap_weight(actv_ports.ports, dev->caps.num_ports);
buf : 	first_port = find_first_bit(actv_ports.ports, dev->caps.num_ports);
buf : 
buf : 	dm = kcalloc(ports, sizeof(*dm), GFP_ATOMIC);
buf : 	if (!dm) {
if (!dm) { 
buf : 		pr_err("failed to allocate memory for tunneling qp update\n");
for tunneling qp update\n"); 
buf : 		goto out;
buf : 	}
buf : 
buf : 	for (i = 0; i < ports; i++) {
for (i = 0; i < ports; i++) { 
buf : 		dm[i] = kmalloc(sizeof (struct mlx4_ib_demux_work), GFP_ATOMIC);
buf : 		if (!dm[i]) {
if (!dm[i]) { 
buf : 			pr_err("failed to allocate memory for tunneling qp update work struct\n");
for tunneling qp update work struct\n"); 
buf : 			for (i = 0; i < dev->caps.num_ports; i++) {
buf : 				if (dm[i])
if (dm[i]) 
buf : 					kfree(dm[i]);
buf : 			}
buf : 			goto out;
buf : 		}
buf : 	}
buf : 	/* initialize or tear down tunnel QPs for the slave */
for the slave */ 
buf : 	for (i = 0; i < ports; i++) {
buf : 		INIT_WORK(&dm[i]->work, mlx4_ib_tunnels_update_work);
buf : 		dm[i]->port = first_port + i + 1;
buf : 		dm[i]->slave = slave;
buf : 		dm[i]->do_init = do_init;
buf : 		dm[i]->dev = ibdev;
buf : 		spin_lock_irqsave(&ibdev->sriov.going_down_lock, flags);
buf : 		if (!ibdev->sriov.is_going_down)
if (!ibdev->sriov.is_going_down) 
buf : 			queue_work(ibdev->sriov.demux[i].ud_wq, &dm[i]->work);
buf : 		spin_unlock_irqrestore(&ibdev->sriov.going_down_lock, flags);
buf : 	}
buf : out:
buf : 	kfree(dm);
buf : 	return;
buf : }
buf : 
buf : static void mlx4_ib_event(struct mlx4_dev *dev, void *ibdev_ptr,
buf : 			  enum mlx4_dev_event event, unsigned long param)
buf : {
buf : 	struct ib_event ibev;
buf : 	struct mlx4_ib_dev *ibdev = to_mdev((struct ib_device *) ibdev_ptr);
buf : 	struct mlx4_eqe *eqe = NULL;
buf : 	struct ib_event_work *ew;
buf : 	int p = 0;
buf : 
buf : 	if (event == MLX4_DEV_EVENT_PORT_MGMT_CHANGE)
if (event == MLX4_DEV_EVENT_PORT_MGMT_CHANGE) 
buf : 		eqe = (struct mlx4_eqe *)param;
buf : 	else
buf : 		p = (int) param;
buf : 
buf : 	switch (event) {
buf : 	case MLX4_DEV_EVENT_PORT_UP:
buf : 		if (p > ibdev->num_ports)
if (p > ibdev->num_ports) 
buf : 			return;
buf : 		if (mlx4_is_master(dev) &&
if (mlx4_is_master(dev) && 
buf : 		    rdma_port_get_link_layer(&ibdev->ib_dev, p) ==
buf : 			IB_LINK_LAYER_INFINIBAND) {
buf : 			mlx4_ib_invalidate_all_guid_record(ibdev, p);
buf : 		}
buf : 		ibev.event = IB_EVENT_PORT_ACTIVE;
buf : 		break;
buf : 
buf : 	case MLX4_DEV_EVENT_PORT_DOWN:
buf : 		if (p > ibdev->num_ports)
if (p > ibdev->num_ports) 
buf : 			return;
buf : 		ibev.event = IB_EVENT_PORT_ERR;
buf : 		break;
buf : 
buf : 	case MLX4_DEV_EVENT_CATASTROPHIC_ERROR:
buf : 		ibdev->ib_active = false;
buf : 		ibev.event = IB_EVENT_DEVICE_FATAL;
buf : 		break;
buf : 
buf : 	case MLX4_DEV_EVENT_PORT_MGMT_CHANGE:
buf : 		ew = kmalloc(sizeof *ew, GFP_ATOMIC);
buf : 		if (!ew) {
if (!ew) { 
buf : 			pr_err("failed to allocate memory for events work\n");
for events work\n"); 
buf : 			break;
buf : 		}
buf : 
buf : 		INIT_WORK(&ew->work, handle_port_mgmt_change_event);
buf : 		memcpy(&ew->ib_eqe, eqe, sizeof *eqe);
buf : 		ew->ib_dev = ibdev;
buf : 		/* need to queue only for port owner, which uses GEN_EQE */
for port owner, which uses GEN_EQE */ 
buf : 		if (mlx4_is_master(dev))
buf : 			queue_work(wq, &ew->work);
buf : 		else
buf : 			handle_port_mgmt_change_event(&ew->work);
buf : 		return;
buf : 
buf : 	case MLX4_DEV_EVENT_SLAVE_INIT:
buf : 		/* here, p is the slave id */
buf : 		do_slave_init(ibdev, p, 1);
buf : 		return;
buf : 
buf : 	case MLX4_DEV_EVENT_SLAVE_SHUTDOWN:
buf : 		/* here, p is the slave id */
buf : 		do_slave_init(ibdev, p, 0);
buf : 		return;
buf : 
buf : 	default:
buf : 		return;
buf : 	}
buf : 
buf : 	ibev.device	      = ibdev_ptr;
buf : 	ibev.element.port_num = (u8) p;
buf : 
buf : 	ib_dispatch_event(&ibev);
buf : }
buf : 
buf : static struct mlx4_interface mlx4_ib_interface = {
buf : 	.add		= mlx4_ib_add,
buf : 	.remove		= mlx4_ib_remove,
buf : 	.event		= mlx4_ib_event,
buf : 	.protocol	= MLX4_PROT_IB_IPV6
buf : };
buf : 
buf : static int __init mlx4_ib_init(void)
buf : {
buf : 	int err;
buf : 
buf : 	wq = create_singlethread_workqueue("mlx4_ib");
buf : 	if (!wq)
if (!wq) 
buf : 		return -ENOMEM;
buf : 
buf : 	err = mlx4_ib_mcg_init();
buf : 	if (err)
if (err) 
buf : 		goto clean_wq;
buf : 
buf : 	err = mlx4_register_interface(&mlx4_ib_interface);
buf : 	if (err)
if (err) 
buf : 		goto clean_mcg;
buf : 
buf : 	return 0;
buf : 
buf : clean_mcg:
buf : 	mlx4_ib_mcg_destroy();
buf : 
buf : clean_wq:
buf : 	destroy_workqueue(wq);
buf : 	return err;
buf : }
buf : 
buf : static void __exit mlx4_ib_cleanup(void)
buf : {
buf : 	mlx4_unregister_interface(&mlx4_ib_interface);
buf : 	mlx4_ib_mcg_destroy();
buf : 	destroy_workqueue(wq);
buf : }
buf : 
buf : module_init(mlx4_ib_init);
buf : module_exit(mlx4_ib_cleanup);
file : ./test/kernel/drivers/misc/mei/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  *
buf :  * Intel Management Engine Interface (Intel MEI) Linux driver
buf :  * Copyright (c) 2003-2012, Intel Corporation.
buf :  *
buf :  * This program is free software; you can redistribute it and/or modify it
ify it 
buf :  * under the terms and conditions of the GNU General Public License,
buf :  * version 2, as published by the Free Software Foundation.
buf :  *
buf :  * This program is distributed in the hope it will be useful, but WITHOUT
buf :  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
buf :  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
for 
buf :  * more details.
buf :  *
buf :  */
buf : #include <linux/module.h>
buf : #include <linux/moduleparam.h>
buf : #include <linux/kernel.h>
buf : #include <linux/device.h>
buf : #include <linux/fs.h>
buf : #include <linux/errno.h>
buf : #include <linux/types.h>
buf : #include <linux/fcntl.h>
buf : #include <linux/aio.h>
buf : #include <linux/pci.h>
buf : #include <linux/poll.h>
buf : #include <linux/init.h>
buf : #include <linux/ioctl.h>
buf : #include <linux/cdev.h>
buf : #include <linux/sched.h>
buf : #include <linux/uuid.h>
buf : #include <linux/compat.h>
buf : #include <linux/jiffies.h>
iffies.h> 
buf : #include <linux/interrupt.h>
buf : #include <linux/miscdevice.h>
buf : 
buf : #include <linux/mei.h>
buf : 
buf : #include "mei_dev.h"
buf : #include "client.h"
buf : 
buf : /**
buf :  * mei_open - the open function
buf :  *
buf :  * @inode: pointer to inode structure
buf :  * @file: pointer to file structure
buf :  *
buf :  * returns 0 on success, <0 on error
buf :  */
buf : static int mei_open(struct inode *inode, struct file *file)
buf : {
buf : 	struct miscdevice *misc = file->private_data;
buf : 	struct pci_dev *pdev;
buf : 	struct mei_cl *cl;
buf : 	struct mei_device *dev;
buf : 
buf : 	int err;
buf : 
buf : 	if (!misc->parent)
if (!misc->parent) 
buf : 		return -ENODEV;
buf : 
buf : 	pdev = container_of(misc->parent, struct pci_dev, dev);
buf : 
buf : 	dev = pci_get_drvdata(pdev);
buf : 	if (!dev)
if (!dev) 
buf : 		return -ENODEV;
buf : 
buf : 	mutex_lock(&dev->device_lock);
buf : 
buf : 	cl = NULL;
buf : 
buf : 	err = -ENODEV;
buf : 	if (dev->dev_state != MEI_DEV_ENABLED) {
if (dev->dev_state != MEI_DEV_ENABLED) { 
buf : 		dev_dbg(&dev->pdev->dev, "dev_state != MEI_ENABLED  dev_state = %s\n",
buf : 		    mei_dev_state_str(dev->dev_state));
buf : 		goto err_unlock;
buf : 	}
buf : 
buf : 	err = -ENOMEM;
buf : 	cl = mei_cl_allocate(dev);
buf : 	if (!cl)
if (!cl) 
buf : 		goto err_unlock;
buf : 
buf : 	/* open_handle_count check is handled in the mei_cl_link */
buf : 	err = mei_cl_link(cl, MEI_HOST_CLIENT_ID_ANY);
buf : 	if (err)
if (err) 
buf : 		goto err_unlock;
buf : 
buf : 	file->private_data = cl;
buf : 
buf : 	mutex_unlock(&dev->device_lock);
buf : 
buf : 	return nonseekable_open(inode, file);
buf : 
buf : err_unlock:
buf : 	mutex_unlock(&dev->device_lock);
buf : 	kfree(cl);
buf : 	return err;
buf : }
buf : 
buf : /**
buf :  * mei_release - the release function
buf :  *
buf :  * @inode: pointer to inode structure
buf :  * @file: pointer to file structure
buf :  *
buf :  * returns 0 on success, <0 on error
buf :  */
buf : static int mei_release(struct inode *inode, struct file *file)
buf : {
buf : 	struct mei_cl *cl = file->private_data;
buf : 	struct mei_cl_cb *cb;
buf : 	struct mei_device *dev;
buf : 	int rets = 0;
buf : 
buf : 	if (WARN_ON(!cl || !cl->dev))
if (WARN_ON(!cl || !cl->dev)) 
buf : 		return -ENODEV;
buf : 
buf : 	dev = cl->dev;
buf : 
buf : 	mutex_lock(&dev->device_lock);
buf : 	if (cl == &dev->iamthif_cl) {
if (cl == &dev->iamthif_cl) { 
buf : 		rets = mei_amthif_release(dev, file);
buf : 		goto out;
buf : 	}
buf : 	if (cl->state == MEI_FILE_CONNECTED) {
if (cl->state == MEI_FILE_CONNECTED) { 
buf : 		cl->state = MEI_FILE_DISCONNECTING;
buf : 		cl_dbg(dev, cl, "disconnecting\n");
buf : 		rets = mei_cl_disconnect(cl);
buf : 	}
buf : 	mei_cl_flush_queues(cl);
buf : 	cl_dbg(dev, cl, "removing\n");
buf : 
buf : 	mei_cl_unlink(cl);
buf : 
buf : 
buf : 	/* free read cb */
buf : 	cb = NULL;
buf : 	if (cl->read_cb) {
if (cl->read_cb) { 
buf : 		cb = mei_cl_find_read_cb(cl);
buf : 		/* Remove entry from read list */
buf : 		if (cb)
if (cb) 
buf : 			list_del(&cb->list);
buf : 
buf : 		cb = cl->read_cb;
buf : 		cl->read_cb = NULL;
buf : 	}
buf : 
buf : 	file->private_data = NULL;
buf : 
buf : 	mei_io_cb_free(cb);
buf : 
buf : 	kfree(cl);
buf : out:
buf : 	mutex_unlock(&dev->device_lock);
buf : 	return rets;
buf : }
buf : 
buf : 
buf : /**
buf :  * mei_read - the read function.
buf :  *
buf :  * @file: pointer to file structure
buf :  * @ubuf: pointer to user buffer
buf :  * @length: buffer length
buf :  * @offset: data offset in buffer
buf :  *
buf :  * returns >=0 data length on success , <0 on error
buf :  */
buf : static ssize_t mei_read(struct file *file, char __user *ubuf,
buf : 			size_t length, loff_t *offset)
buf : {
buf : 	struct mei_cl *cl = file->private_data;
buf : 	struct mei_cl_cb *cb_pos = NULL;
buf : 	struct mei_cl_cb *cb = NULL;
buf : 	struct mei_device *dev;
buf : 	int rets;
buf : 	int err;
buf : 
buf : 
buf : 	if (WARN_ON(!cl || !cl->dev))
if (WARN_ON(!cl || !cl->dev)) 
buf : 		return -ENODEV;
buf : 
buf : 	dev = cl->dev;
buf : 
buf : 
buf : 	mutex_lock(&dev->device_lock);
buf : 	if (dev->dev_state != MEI_DEV_ENABLED) {
if (dev->dev_state != MEI_DEV_ENABLED) { 
buf : 		rets = -ENODEV;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (length == 0) {
if (length == 0) { 
buf : 		rets = 0;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (cl == &dev->iamthif_cl) {
if (cl == &dev->iamthif_cl) { 
buf : 		rets = mei_amthif_read(dev, file, ubuf, length, offset);
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (cl->read_cb) {
if (cl->read_cb) { 
buf : 		cb = cl->read_cb;
buf : 		/* read what left */
buf : 		if (cb->buf_idx > *offset)
if (cb->buf_idx > *offset) 
buf : 			goto copy_buffer;
buf : 		/* offset is beyond buf_idx we have no more data return 0 */
buf : 		if (cb->buf_idx > 0 && cb->buf_idx <= *offset) {
if (cb->buf_idx > 0 && cb->buf_idx <= *offset) { 
buf : 			rets = 0;
buf : 			goto free;
buf : 		}
buf : 		/* Offset needs to be cleaned for contiguous reads*/
for contiguous reads*/ 
buf : 		if (cb->buf_idx == 0 && *offset > 0)
buf : 			*offset = 0;
buf : 	} else if (*offset > 0) {
if (*offset > 0) { 
buf : 		*offset = 0;
buf : 	}
buf : 
buf : 	err = mei_cl_read_start(cl, length);
buf : 	if (err && err != -EBUSY) {
if (err && err != -EBUSY) { 
buf : 		dev_dbg(&dev->pdev->dev,
buf : 			"mei start read failure with status = %d\n", err);
buf : 		rets = err;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (MEI_READ_COMPLETE != cl->reading_state &&
if (MEI_READ_COMPLETE != cl->reading_state && 
buf : 			!waitqueue_active(&cl->rx_wait)) {
buf : 		if (file->f_flags & O_NONBLOCK) {
if (file->f_flags & O_NONBLOCK) { 
buf : 			rets = -EAGAIN;
buf : 			goto out;
buf : 		}
buf : 
buf : 		mutex_unlock(&dev->device_lock);
buf : 
buf : 		if (wait_event_interruptible(cl->rx_wait,
if (wait_event_interruptible(cl->rx_wait, 
buf : 				MEI_READ_COMPLETE == cl->reading_state ||
buf : 				mei_cl_is_transitioning(cl))) {
buf : 
buf : 			if (signal_pending(current))
if (signal_pending(current)) 
buf : 				return -EINTR;
buf : 			return -ERESTARTSYS;
buf : 		}
buf : 
buf : 		mutex_lock(&dev->device_lock);
buf : 		if (mei_cl_is_transitioning(cl)) {
if (mei_cl_is_transitioning(cl)) { 
buf : 			rets = -EBUSY;
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : 	cb = cl->read_cb;
buf : 
buf : 	if (!cb) {
if (!cb) { 
buf : 		rets = -ENODEV;
buf : 		goto out;
buf : 	}
buf : 	if (cl->reading_state != MEI_READ_COMPLETE) {
if (cl->reading_state != MEI_READ_COMPLETE) { 
buf : 		rets = 0;
buf : 		goto out;
buf : 	}
buf : 	/* now copy the data to user space */
buf : copy_buffer:
buf : 	dev_dbg(&dev->pdev->dev, "buf.size = %d buf.idx= %ld\n",
buf : 	    cb->response_buffer.size, cb->buf_idx);
buf : 	if (length == 0 || ubuf == NULL || *offset > cb->buf_idx) {
if (length == 0 || ubuf == NULL || *offset > cb->buf_idx) { 
buf : 		rets = -EMSGSIZE;
buf : 		goto free;
buf : 	}
buf : 
buf : 	/* length is being truncated to PAGE_SIZE,
buf : 	 * however buf_idx may point beyond that */
buf : 	length = min_t(size_t, length, cb->buf_idx - *offset);
buf : 
buf : 	if (copy_to_user(ubuf, cb->response_buffer.data + *offset, length)) {
if (copy_to_user(ubuf, cb->response_buffer.data + *offset, length)) { 
buf : 		dev_dbg(&dev->pdev->dev, "failed to copy data to userland\n");
buf : 		rets = -EFAULT;
buf : 		goto free;
buf : 	}
buf : 
buf : 	rets = length;
buf : 	*offset += length;
buf : 	if ((unsigned long)*offset < cb->buf_idx)
if ((unsigned long)*offset < cb->buf_idx) 
buf : 		goto out;
buf : 
buf : free:
buf : 	cb_pos = mei_cl_find_read_cb(cl);
buf : 	/* Remove entry from read list */
buf : 	if (cb_pos)
if (cb_pos) 
buf : 		list_del(&cb_pos->list);
buf : 	mei_io_cb_free(cb);
buf : 	cl->reading_state = MEI_IDLE;
buf : 	cl->read_cb = NULL;
buf : out:
buf : 	dev_dbg(&dev->pdev->dev, "end mei read rets= %d\n", rets);
buf : 	mutex_unlock(&dev->device_lock);
buf : 	return rets;
buf : }
buf : /**
buf :  * mei_write - the write function.
buf :  *
buf :  * @file: pointer to file structure
buf :  * @ubuf: pointer to user buffer
buf :  * @length: buffer length
buf :  * @offset: data offset in buffer
buf :  *
buf :  * returns >=0 data length on success , <0 on error
buf :  */
buf : static ssize_t mei_write(struct file *file, const char __user *ubuf,
buf : 			 size_t length, loff_t *offset)
buf : {
buf : 	struct mei_cl *cl = file->private_data;
buf : 	struct mei_cl_cb *write_cb = NULL;
buf : 	struct mei_device *dev;
buf : 	unsigned long timeout = 0;
buf : 	int rets;
buf : 	int id;
buf : 
buf : 	if (WARN_ON(!cl || !cl->dev))
if (WARN_ON(!cl || !cl->dev)) 
buf : 		return -ENODEV;
buf : 
buf : 	dev = cl->dev;
buf : 
buf : 	mutex_lock(&dev->device_lock);
buf : 
buf : 	if (dev->dev_state != MEI_DEV_ENABLED) {
if (dev->dev_state != MEI_DEV_ENABLED) { 
buf : 		rets = -ENODEV;
buf : 		goto out;
buf : 	}
buf : 
buf : 	id = mei_me_cl_by_id(dev, cl->me_client_id);
buf : 	if (id < 0) {
if (id < 0) { 
buf : 		rets = -ENOTTY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (length == 0) {
if (length == 0) { 
buf : 		rets = 0;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (length > dev->me_clients[id].props.max_msg_length) {
if (length > dev->me_clients[id].props.max_msg_length) { 
buf : 		rets = -EFBIG;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (cl->state != MEI_FILE_CONNECTED) {
if (cl->state != MEI_FILE_CONNECTED) { 
buf : 		dev_err(&dev->pdev->dev, "host client = %d,  is not connected to ME client = %d",
buf : 			cl->host_client_id, cl->me_client_id);
buf : 		rets = -ENODEV;
buf : 		goto out;
buf : 	}
buf : 	if (cl == &dev->iamthif_cl) {
if (cl == &dev->iamthif_cl) { 
buf : 		write_cb = mei_amthif_find_read_list_entry(dev, file);
buf : 
buf : 		if (write_cb) {
if (write_cb) { 
buf : 			timeout = write_cb->read_time +
buf : 				mei_secs_to_jiffies(MEI_IAMTHIF_READ_TIMER);
iffies(MEI_IAMTHIF_READ_TIMER); 
buf : 
buf : 			if (time_after(jiffies, timeout) ||
buf : 			    cl->reading_state == MEI_READ_COMPLETE) {
buf : 				*offset = 0;
buf : 				list_del(&write_cb->list);
buf : 				mei_io_cb_free(write_cb);
buf : 				write_cb = NULL;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	/* free entry used in read */
buf : 	if (cl->reading_state == MEI_READ_COMPLETE) {
if (cl->reading_state == MEI_READ_COMPLETE) { 
buf : 		*offset = 0;
buf : 		write_cb = mei_cl_find_read_cb(cl);
buf : 		if (write_cb) {
if (write_cb) { 
buf : 			list_del(&write_cb->list);
buf : 			mei_io_cb_free(write_cb);
buf : 			write_cb = NULL;
buf : 			cl->reading_state = MEI_IDLE;
buf : 			cl->read_cb = NULL;
buf : 		}
buf : 	} else if (cl->reading_state == MEI_IDLE)
if (cl->reading_state == MEI_IDLE) 
buf : 		*offset = 0;
buf : 
buf : 
buf : 	write_cb = mei_io_cb_init(cl, file);
buf : 	if (!write_cb) {
if (!write_cb) { 
buf : 		dev_err(&dev->pdev->dev, "write cb allocation failed\n");
buf : 		rets = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 	rets = mei_io_cb_alloc_req_buf(write_cb, length);
buf : 	if (rets)
if (rets) 
buf : 		goto out;
buf : 
buf : 	rets = copy_from_user(write_cb->request_buffer.data, ubuf, length);
buf : 	if (rets) {
if (rets) { 
buf : 		dev_dbg(&dev->pdev->dev, "failed to copy data from userland\n");
buf : 		rets = -EFAULT;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (cl == &dev->iamthif_cl) {
if (cl == &dev->iamthif_cl) { 
buf : 		rets = mei_amthif_write(dev, write_cb);
buf : 
buf : 		if (rets) {
if (rets) { 
buf : 			dev_err(&dev->pdev->dev,
buf : 				"amthif write failed with status = %d\n", rets);
if write failed with status = %d\n", rets); 
buf : 			goto out;
buf : 		}
buf : 		mutex_unlock(&dev->device_lock);
buf : 		return length;
buf : 	}
buf : 
buf : 	rets = mei_cl_write(cl, write_cb, false);
buf : out:
buf : 	mutex_unlock(&dev->device_lock);
buf : 	if (rets < 0)
if (rets < 0) 
buf : 		mei_io_cb_free(write_cb);
buf : 	return rets;
buf : }
buf : 
buf : /**
buf :  * mei_ioctl_connect_client - the connect to fw client IOCTL function
buf :  *
buf :  * @dev: the device structure
buf :  * @data: IOCTL connect data, input and output parameters
buf :  * @file: private data of the file object
buf :  *
buf :  * Locking: called under "dev->device_lock" lock
buf :  *
buf :  * returns 0 on success, <0 on failure.
buf :  */
buf : static int mei_ioctl_connect_client(struct file *file,
buf : 			struct mei_connect_client_data *data)
buf : {
buf : 	struct mei_device *dev;
buf : 	struct mei_client *client;
buf : 	struct mei_cl *cl;
buf : 	int i;
buf : 	int rets;
buf : 
buf : 	cl = file->private_data;
buf : 	if (WARN_ON(!cl || !cl->dev))
if (WARN_ON(!cl || !cl->dev)) 
buf : 		return -ENODEV;
buf : 
buf : 	dev = cl->dev;
buf : 
buf : 	if (dev->dev_state != MEI_DEV_ENABLED) {
if (dev->dev_state != MEI_DEV_ENABLED) { 
buf : 		rets = -ENODEV;
buf : 		goto end;
buf : 	}
buf : 
buf : 	if (cl->state != MEI_FILE_INITIALIZING &&
if (cl->state != MEI_FILE_INITIALIZING && 
buf : 	    cl->state != MEI_FILE_DISCONNECTED) {
buf : 		rets = -EBUSY;
buf : 		goto end;
buf : 	}
buf : 
buf : 	/* find ME client we're trying to connect to */
buf : 	i = mei_me_cl_by_uuid(dev, &data->in_client_uuid);
buf : 	if (i < 0 || dev->me_clients[i].props.fixed_address) {
if (i < 0 || dev->me_clients[i].props.fixed_address) { 
buf : 		dev_dbg(&dev->pdev->dev, "Cannot connect to FW Client UUID = %pUl\n",
buf : 				&data->in_client_uuid);
buf : 		rets = -ENOTTY;
buf : 		goto end;
buf : 	}
buf : 
buf : 	cl->me_client_id = dev->me_clients[i].client_id;
buf : 
buf : 	dev_dbg(&dev->pdev->dev, "Connect to FW Client ID = %d\n",
buf : 			cl->me_client_id);
buf : 	dev_dbg(&dev->pdev->dev, "FW Client - Protocol Version = %d\n",
buf : 			dev->me_clients[i].props.protocol_version);
buf : 	dev_dbg(&dev->pdev->dev, "FW Client - Max Msg Len = %d\n",
buf : 			dev->me_clients[i].props.max_msg_length);
buf : 
buf : 	/* if we're connecting to amthif client then we will use the
if we're connecting to amthif client then we will use the 
buf : 	 * existing connection
buf : 	 */
buf : 	if (uuid_le_cmp(data->in_client_uuid, mei_amthif_guid) == 0) {
if (uuid_le_cmp(data->in_client_uuid, mei_amthif_guid) == 0) { 
buf : 		dev_dbg(&dev->pdev->dev, "FW Client is amthi\n");
buf : 		if (dev->iamthif_cl.state != MEI_FILE_CONNECTED) {
if (dev->iamthif_cl.state != MEI_FILE_CONNECTED) { 
buf : 			rets = -ENODEV;
buf : 			goto end;
buf : 		}
buf : 		mei_cl_unlink(cl);
buf : 
buf : 		kfree(cl);
buf : 		cl = NULL;
buf : 		dev->iamthif_open_count++;
if_open_count++; 
buf : 		file->private_data = &dev->iamthif_cl;
buf : 
buf : 		client = &data->out_client_properties;
buf : 		client->max_msg_length =
buf : 			dev->me_clients[i].props.max_msg_length;
buf : 		client->protocol_version =
buf : 			dev->me_clients[i].props.protocol_version;
buf : 		rets = dev->iamthif_cl.status;
if_cl.status; 
buf : 
buf : 		goto end;
buf : 	}
buf : 
buf : 
buf : 	/* prepare the output buffer */
buf : 	client = &data->out_client_properties;
buf : 	client->max_msg_length = dev->me_clients[i].props.max_msg_length;
buf : 	client->protocol_version = dev->me_clients[i].props.protocol_version;
buf : 	dev_dbg(&dev->pdev->dev, "Can connect?\n");
buf : 
buf : 
buf : 	rets = mei_cl_connect(cl, file);
buf : 
buf : end:
buf : 	return rets;
buf : }
buf : 
buf : 
buf : /**
buf :  * mei_ioctl - the IOCTL function
buf :  *
buf :  * @file: pointer to file structure
buf :  * @cmd: ioctl command
buf :  * @data: pointer to mei message structure
buf :  *
buf :  * returns 0 on success , <0 on error
buf :  */
buf : static long mei_ioctl(struct file *file, unsigned int cmd, unsigned long data)
buf : {
buf : 	struct mei_device *dev;
buf : 	struct mei_cl *cl = file->private_data;
buf : 	struct mei_connect_client_data *connect_data = NULL;
buf : 	int rets;
buf : 
buf : 	if (cmd != IOCTL_MEI_CONNECT_CLIENT)
if (cmd != IOCTL_MEI_CONNECT_CLIENT) 
buf : 		return -EINVAL;
buf : 
buf : 	if (WARN_ON(!cl || !cl->dev))
if (WARN_ON(!cl || !cl->dev)) 
buf : 		return -ENODEV;
buf : 
buf : 	dev = cl->dev;
buf : 
buf : 	dev_dbg(&dev->pdev->dev, "IOCTL cmd = 0x%x", cmd);
buf : 
buf : 	mutex_lock(&dev->device_lock);
buf : 	if (dev->dev_state != MEI_DEV_ENABLED) {
if (dev->dev_state != MEI_DEV_ENABLED) { 
buf : 		rets = -ENODEV;
buf : 		goto out;
buf : 	}
buf : 
buf : 	dev_dbg(&dev->pdev->dev, ": IOCTL_MEI_CONNECT_CLIENT.\n");
buf : 
buf : 	connect_data = kzalloc(sizeof(struct mei_connect_client_data),
buf : 							GFP_KERNEL);
buf : 	if (!connect_data) {
if (!connect_data) { 
buf : 		rets = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 	dev_dbg(&dev->pdev->dev, "copy connect data from user\n");
buf : 	if (copy_from_user(connect_data, (char __user *)data,
if (copy_from_user(connect_data, (char __user *)data, 
buf : 				sizeof(struct mei_connect_client_data))) {
buf : 		dev_dbg(&dev->pdev->dev, "failed to copy data from userland\n");
buf : 		rets = -EFAULT;
buf : 		goto out;
buf : 	}
buf : 
buf : 	rets = mei_ioctl_connect_client(file, connect_data);
buf : 
buf : 	/* if all is ok, copying the data back to user. */
if all is ok, copying the data back to user. */ 
buf : 	if (rets)
buf : 		goto out;
buf : 
buf : 	dev_dbg(&dev->pdev->dev, "copy connect data to user\n");
buf : 	if (copy_to_user((char __user *)data, connect_data,
if (copy_to_user((char __user *)data, connect_data, 
buf : 				sizeof(struct mei_connect_client_data))) {
buf : 		dev_dbg(&dev->pdev->dev, "failed to copy data to userland\n");
buf : 		rets = -EFAULT;
buf : 		goto out;
buf : 	}
buf : 
buf : out:
buf : 	kfree(connect_data);
buf : 	mutex_unlock(&dev->device_lock);
buf : 	return rets;
buf : }
buf : 
buf : /**
buf :  * mei_compat_ioctl - the compat IOCTL function
buf :  *
buf :  * @file: pointer to file structure
buf :  * @cmd: ioctl command
buf :  * @data: pointer to mei message structure
buf :  *
buf :  * returns 0 on success , <0 on error
buf :  */
buf : #ifdef CONFIG_COMPAT
ifdef CONFIG_COMPAT 
buf : static long mei_compat_ioctl(struct file *file,
buf : 			unsigned int cmd, unsigned long data)
buf : {
buf : 	return mei_ioctl(file, cmd, (unsigned long)compat_ptr(data));
buf : }
buf : #endif
if 
buf : 
buf : 
buf : /**
buf :  * mei_poll - the poll function
buf :  *
buf :  * @file: pointer to file structure
buf :  * @wait: pointer to poll_table structure
buf :  *
buf :  * returns poll mask
buf :  */
buf : static unsigned int mei_poll(struct file *file, poll_table *wait)
buf : {
buf : 	struct mei_cl *cl = file->private_data;
buf : 	struct mei_device *dev;
buf : 	unsigned int mask = 0;
buf : 
buf : 	if (WARN_ON(!cl || !cl->dev))
if (WARN_ON(!cl || !cl->dev)) 
buf : 		return POLLERR;
buf : 
buf : 	dev = cl->dev;
buf : 
buf : 	mutex_lock(&dev->device_lock);
buf : 
buf : 	if (!mei_cl_is_connected(cl)) {
if (!mei_cl_is_connected(cl)) { 
buf : 		mask = POLLERR;
buf : 		goto out;
buf : 	}
buf : 
buf : 	mutex_unlock(&dev->device_lock);
buf : 
buf : 
buf : 	if (cl == &dev->iamthif_cl)
if (cl == &dev->iamthif_cl) 
buf : 		return mei_amthif_poll(dev, file, wait);
buf : 
buf : 	poll_wait(file, &cl->tx_wait, wait);
buf : 
buf : 	mutex_lock(&dev->device_lock);
buf : 
buf : 	if (!mei_cl_is_connected(cl)) {
if (!mei_cl_is_connected(cl)) { 
buf : 		mask = POLLERR;
buf : 		goto out;
buf : 	}
buf : 
buf : 	mask |= (POLLIN | POLLRDNORM);
buf : 
buf : out:
buf : 	mutex_unlock(&dev->device_lock);
buf : 	return mask;
buf : }
buf : 
buf : /*
buf :  * file operations structure will be used for mei char device.
for mei char device. 
buf :  */
buf : static const struct file_operations mei_fops = {
buf : 	.owner = THIS_MODULE,
buf : 	.read = mei_read,
buf : 	.unlocked_ioctl = mei_ioctl,
buf : #ifdef CONFIG_COMPAT
ifdef CONFIG_COMPAT 
buf : 	.compat_ioctl = mei_compat_ioctl,
buf : #endif
if 
buf : 	.open = mei_open,
buf : 	.release = mei_release,
buf : 	.write = mei_write,
buf : 	.poll = mei_poll,
buf : 	.llseek = no_llseek
buf : };
buf : 
buf : /*
buf :  * Misc Device Struct
buf :  */
buf : static struct miscdevice  mei_misc_device = {
buf : 		.name = "mei",
buf : 		.fops = &mei_fops,
buf : 		.minor = MISC_DYNAMIC_MINOR,
buf : };
buf : 
buf : 
buf : int mei_register(struct mei_device *dev)
buf : {
buf : 	int ret;
buf : 	mei_misc_device.parent = &dev->pdev->dev;
buf : 	ret = misc_register(&mei_misc_device);
buf : 	if (ret)
if (ret) 
buf : 		return ret;
buf : 
buf : 	if (mei_dbgfs_register(dev, mei_misc_device.name))
if (mei_dbgfs_register(dev, mei_misc_device.name)) 
buf : 		dev_err(&dev->pdev->dev, "cannot register debugfs\n");
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL_GPL(mei_register);
buf : 
buf : void mei_deregister(struct mei_device *dev)
buf : {
buf : 	mei_dbgfs_deregister(dev);
buf : 	misc_deregister(&mei_misc_device);
buf : 	mei_misc_device.parent = NULL;
buf : }
buf : EXPORT_SYMBOL_GPL(mei_deregister);
buf : 
buf : static int __init mei_init(void)
buf : {
buf : 	return mei_cl_bus_init();
buf : }
buf : 
buf : static void __exit mei_exit(void)
buf : {
buf : 	mei_cl_bus_exit();
buf : }
buf : 
buf : module_init(mei_init);
buf : module_exit(mei_exit);
buf : 
buf : MODULE_AUTHOR("Intel Corporation");
buf : MODULE_DESCRIPTION("Intel(R) Management Engine Interface");
buf : MODULE_LICENSE("GPL v2");
buf : 
file : ./test/kernel/drivers/nfc/nfcmrvl/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Marvell NFC driver: major functions
buf :  *
buf :  * Copyright (C) 2014, Marvell International Ltd.
buf :  *
buf :  * This software file (the "File") is distributed by Marvell International
buf :  * Ltd. under the terms of the GNU General Public License Version 2, June 1991
buf :  * (the "License").  You may use, redistribute and/or modify this File in
ify this File in 
buf :  * accordance with the terms and conditions of the License, a copy of which
buf :  * is available on the worldwide web at
buf :  * http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
buf :  *
buf :  * THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE
buf :  * IMPLIED WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE
buf :  * ARE EXPRESSLY DISCLAIMED.  The License provides additional details about
buf :  * this warranty disclaimer.
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/nfc.h>
buf : #include <net/nfc/nci.h>
buf : #include <net/nfc/nci_core.h>
buf : #include "nfcmrvl.h"
buf : 
buf : #define VERSION "1.0"
buf : 
buf : static int nfcmrvl_nci_open(struct nci_dev *ndev)
buf : {
buf : 	struct nfcmrvl_private *priv = nci_get_drvdata(ndev);
buf : 	int err;
buf : 
buf : 	if (test_and_set_bit(NFCMRVL_NCI_RUNNING, &priv->flags))
if (test_and_set_bit(NFCMRVL_NCI_RUNNING, &priv->flags)) 
buf : 		return 0;
buf : 
buf : 	err = priv->if_ops->nci_open(priv);
if_ops->nci_open(priv); 
buf : 
buf : 	if (err)
buf : 		clear_bit(NFCMRVL_NCI_RUNNING, &priv->flags);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int nfcmrvl_nci_close(struct nci_dev *ndev)
buf : {
buf : 	struct nfcmrvl_private *priv = nci_get_drvdata(ndev);
buf : 
buf : 	if (!test_and_clear_bit(NFCMRVL_NCI_RUNNING, &priv->flags))
if (!test_and_clear_bit(NFCMRVL_NCI_RUNNING, &priv->flags)) 
buf : 		return 0;
buf : 
buf : 	priv->if_ops->nci_close(priv);
if_ops->nci_close(priv); 
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int nfcmrvl_nci_send(struct nci_dev *ndev, struct sk_buff *skb)
buf : {
buf : 	struct nfcmrvl_private *priv = nci_get_drvdata(ndev);
buf : 
buf : 	nfc_info(priv->dev, "send entry, len %d\n", skb->len);
buf : 
buf : 	skb->dev = (void *)ndev;
buf : 
buf : 	if (!test_bit(NFCMRVL_NCI_RUNNING, &priv->flags))
if (!test_bit(NFCMRVL_NCI_RUNNING, &priv->flags)) 
buf : 		return -EBUSY;
buf : 
buf : 	return priv->if_ops->nci_send(priv, skb);
if_ops->nci_send(priv, skb); 
buf : }
buf : 
buf : static int nfcmrvl_nci_setup(struct nci_dev *ndev)
buf : {
buf : 	__u8 val;
buf : 
buf : 	val = NFCMRVL_GPIO_PIN_NFC_NOT_ALLOWED;
buf : 	nci_set_config(ndev, NFCMRVL_NOT_ALLOWED_ID, 1, &val);
buf : 	val = NFCMRVL_GPIO_PIN_NFC_ACTIVE;
buf : 	nci_set_config(ndev, NFCMRVL_ACTIVE_ID, 1, &val);
buf : 	val = NFCMRVL_EXT_COEX_ENABLE;
buf : 	nci_set_config(ndev, NFCMRVL_EXT_COEX_ID, 1, &val);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static struct nci_ops nfcmrvl_nci_ops = {
buf : 	.open = nfcmrvl_nci_open,
buf : 	.close = nfcmrvl_nci_close,
buf : 	.send = nfcmrvl_nci_send,
buf : 	.setup = nfcmrvl_nci_setup,
buf : };
buf : 
buf : struct nfcmrvl_private *nfcmrvl_nci_register_dev(void *drv_data,
buf : 						 struct nfcmrvl_if_ops *ops,
if_ops *ops, 
buf : 						 struct device *dev)
buf : {
buf : 	struct nfcmrvl_private *priv;
buf : 	int rc;
buf : 	u32 protocols;
buf : 
buf : 	priv = kzalloc(sizeof(*priv), GFP_KERNEL);
buf : 	if (!priv)
if (!priv) 
buf : 		return ERR_PTR(-ENOMEM);
buf : 
buf : 	priv->drv_data = drv_data;
buf : 	priv->if_ops = ops;
if_ops = ops; 
buf : 	priv->dev = dev;
buf : 
buf : 	protocols = NFC_PROTO_JEWEL_MASK
buf : 		| NFC_PROTO_MIFARE_MASK | NFC_PROTO_FELICA_MASK
buf : 		| NFC_PROTO_ISO14443_MASK
buf : 		| NFC_PROTO_ISO14443_B_MASK
buf : 		| NFC_PROTO_NFC_DEP_MASK;
buf : 
buf : 	priv->ndev = nci_allocate_device(&nfcmrvl_nci_ops, protocols, 0, 0);
buf : 	if (!priv->ndev) {
if (!priv->ndev) { 
buf : 		nfc_err(dev, "nci_allocate_device failed");
buf : 		rc = -ENOMEM;
buf : 		goto error;
buf : 	}
buf : 
buf : 	nci_set_drvdata(priv->ndev, priv);
buf : 
buf : 	rc = nci_register_device(priv->ndev);
buf : 	if (rc) {
if (rc) { 
buf : 		nfc_err(dev, "nci_register_device failed %d", rc);
buf : 		nci_free_device(priv->ndev);
buf : 		goto error;
buf : 	}
buf : 
buf : 	nfc_info(dev, "registered with nci successfully\n");
buf : 	return priv;
buf : 
buf : error:
buf : 	kfree(priv);
buf : 	return ERR_PTR(rc);
buf : }
buf : EXPORT_SYMBOL_GPL(nfcmrvl_nci_register_dev);
buf : 
buf : void nfcmrvl_nci_unregister_dev(struct nfcmrvl_private *priv)
buf : {
buf : 	struct nci_dev *ndev = priv->ndev;
buf : 
buf : 	nci_unregister_device(ndev);
buf : 	nci_free_device(ndev);
buf : 	kfree(priv);
buf : }
buf : EXPORT_SYMBOL_GPL(nfcmrvl_nci_unregister_dev);
buf : 
buf : int nfcmrvl_nci_recv_frame(struct nfcmrvl_private *priv, void *data, int count)
buf : {
buf : 	struct sk_buff *skb;
buf : 
buf : 	skb = nci_skb_alloc(priv->ndev, count, GFP_ATOMIC);
buf : 	if (!skb)
if (!skb) 
buf : 		return -ENOMEM;
buf : 
buf : 	memcpy(skb_put(skb, count), data, count);
buf : 	nci_recv_frame(priv->ndev, skb);
buf : 
buf : 	return count;
buf : }
buf : EXPORT_SYMBOL_GPL(nfcmrvl_nci_recv_frame);
buf : 
buf : MODULE_AUTHOR("Marvell International Ltd.");
buf : MODULE_DESCRIPTION("Marvell NFC driver ver " VERSION);
buf : MODULE_VERSION(VERSION);
buf : MODULE_LICENSE("GPL v2");
file : ./test/kernel/drivers/net/wireless/orinoco/main.c 
[ OK ] open : 4 ok... 
buf : /* main.c - (formerly known as dldwd_cs.c, orinoco_cs.c and orinoco.c)
formerly known as dldwd_cs.c, orinoco_cs.c and orinoco.c) 
buf :  *
buf :  * A driver for Hermes or Prism 2 chipset based PCMCIA wireless
buf :  * adaptors, with Lucent/Agere, Intersil or Symbol firmware.
buf :  *
buf :  * Current maintainers (as of 29 September 2003) are:
buf :  *	Pavel Roskin <proski AT gnu.org>
buf :  * and	David Gibson <hermes AT gibson.dropbear.id.au>
buf :  *
buf :  * (C) Copyright David Gibson, IBM Corporation 2001-2003.
buf :  * Copyright (C) 2000 David Gibson, Linuxcare Australia.
buf :  *	With some help from :
buf :  * Copyright (C) 2001 Jean Tourrilhes, HP Labs
buf :  * Copyright (C) 2001 Benjamin Herrenschmidt
buf :  *
buf :  * Based on dummy_cs.c 1.27 2000/06/12 21:27:25
buf :  *
buf :  * Portions based on wvlan_cs.c 1.0.6, Copyright Andreas Neuhaus <andy
buf :  * AT fasta.fh-dortmund.de>
buf :  *      http://www.stud.fh-dortmund.de/~andy/wvlan/
buf :  *
buf :  * The contents of this file are subject to the Mozilla Public License
buf :  * Version 1.1 (the "License"); you may not use this file except in
buf :  * compliance with the License. You may obtain a copy of the License
buf :  * at http://www.mozilla.org/MPL/
buf :  *
buf :  * Software distributed under the License is distributed on an "AS IS"
buf :  * basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See
buf :  * the License for the specific language governing rights and
ific language governing rights and 
buf :  * limitations under the License.
buf :  *
buf :  * The initial developer of the original code is David A. Hinds
buf :  * <dahinds AT users.sourceforge.net>.  Portions created by David
forge.net>.  Portions created by David 
buf :  * A. Hinds are Copyright (C) 1999 David A. Hinds.  All Rights
buf :  * Reserved.
buf :  *
buf :  * Alternatively, the contents of this file may be used under the
buf :  * terms of the GNU General Public License version 2 (the "GPL"), in
buf :  * which case the provisions of the GPL are applicable instead of the
buf :  * above.  If you wish to allow the use of your version of this file
buf :  * only under the terms of the GPL and not to allow others to use your
buf :  * version of this file under the MPL, indicate your decision by
buf :  * deleting the provisions above and replace them with the notice and
buf :  * other provisions required by the GPL.  If you do not delete the
buf :  * provisions above, a recipient may use your version of this file
buf :  * under either the MPL or the GPL.  */
buf : 
buf : /*
buf :  * TODO
buf :  *	o Handle de-encapsulation within network layer, provide 802.11
buf :  *	  headers (patch from Thomas 'Dent' Mirlacher)
buf :  *	o Fix possible races in SPY handling.
buf :  *	o Disconnect wireless extensions from fundamental configuration.
buf :  *	o (maybe) Software WEP support (patch from Stano Meduna).
buf :  *	o (maybe) Use multiple Tx buffers - driver handling queue
buf :  *	  rather than firmware.
buf :  */
buf : 
buf : /* Locking and synchronization:
buf :  *
buf :  * The basic principle is that everything is serialized through a
buf :  * single spinlock, priv->lock.  The lock is used in user, bh and irq
buf :  * context, so when taken outside hardirq context it should always be
buf :  * taken with interrupts disabled.  The lock protects both the
buf :  * hardware and the struct orinoco_private.
buf :  *
buf :  * Another flag, priv->hw_unavailable indicates that the hardware is
buf :  * unavailable for an extended period of time (e.g. suspended, or in
for an extended period of time (e.g. suspended, or in 
buf :  * the middle of a hard reset).  This flag is protected by the
buf :  * spinlock.  All code which touches the hardware should check the
buf :  * flag after taking the lock, and if it is set, give up on whatever
if it is set, give up on whatever 
buf :  * they are doing and drop the lock again.  The orinoco_lock()
buf :  * function handles this (it unlocks and returns -EBUSY if
if 
buf :  * hw_unavailable is non-zero).
buf :  */
buf : 
buf : #define DRIVER_NAME "orinoco"
buf : 
buf : #include <linux/module.h>
buf : #include <linux/kernel.h>
buf : #include <linux/slab.h>
buf : #include <linux/init.h>
buf : #include <linux/delay.h>
buf : #include <linux/device.h>
buf : #include <linux/netdevice.h>
buf : #include <linux/etherdevice.h>
buf : #include <linux/suspend.h>
buf : #include <linux/if_arp.h>
if_arp.h> 
buf : #include <linux/wireless.h>
buf : #include <linux/ieee80211.h>
buf : #include <net/iw_handler.h>
buf : #include <net/cfg80211.h>
buf : 
buf : #include "hermes_rid.h"
buf : #include "hermes_dld.h"
buf : #include "hw.h"
buf : #include "scan.h"
buf : #include "mic.h"
buf : #include "fw.h"
buf : #include "wext.h"
buf : #include "cfg.h"
buf : #include "main.h"
buf : 
buf : #include "orinoco.h"
buf : 
buf : /********************************************************************/
buf : /* Module information                                               */
formation                                               */ 
buf : /********************************************************************/
buf : 
buf : MODULE_AUTHOR("Pavel Roskin <proski@gnu.org> & "
buf : 	      "David Gibson <hermes@gibson.dropbear.id.au>");
buf : MODULE_DESCRIPTION("Driver for Lucent Orinoco, Prism II based "
for Lucent Orinoco, Prism II based " 
buf : 		   "and similar wireless cards");
buf : MODULE_LICENSE("Dual MPL/GPL");
buf : 
buf : /* Level of debugging. Used in the macros in orinoco.h */
buf : #ifdef ORINOCO_DEBUG
ifdef ORINOCO_DEBUG 
buf : int orinoco_debug = ORINOCO_DEBUG;
buf : EXPORT_SYMBOL(orinoco_debug);
buf : module_param(orinoco_debug, int, 0644);
buf : MODULE_PARM_DESC(orinoco_debug, "Debug level");
buf : #endif
if 
buf : 
buf : static bool suppress_linkstatus; /* = 0 */
buf : module_param(suppress_linkstatus, bool, 0644);
buf : MODULE_PARM_DESC(suppress_linkstatus, "Don't log link status changes");
buf : 
buf : static int ignore_disconnect; /* = 0 */
buf : module_param(ignore_disconnect, int, 0644);
buf : MODULE_PARM_DESC(ignore_disconnect,
buf : 		 "Don't report lost link to the network layer");
buf : 
buf : int force_monitor; /* = 0 */
force_monitor; /* = 0 */ 
buf : module_param(force_monitor, int, 0644);
buf : MODULE_PARM_DESC(force_monitor, "Allow monitor mode for all firmware versions");
force_monitor, "Allow monitor mode for all firmware versions"); 
buf : 
buf : /********************************************************************/
buf : /* Internal constants                                               */
buf : /********************************************************************/
buf : 
buf : /* 802.2 LLC/SNAP header used for Ethernet encapsulation over 802.11 */
for Ethernet encapsulation over 802.11 */ 
buf : static const u8 encaps_hdr[] = {0xaa, 0xaa, 0x03, 0x00, 0x00, 0x00};
buf : #define ENCAPS_OVERHEAD		(sizeof(encaps_hdr) + 2)
buf : 
buf : #define ORINOCO_MIN_MTU		256
buf : #define ORINOCO_MAX_MTU		(IEEE80211_MAX_DATA_LEN - ENCAPS_OVERHEAD)
buf : 
buf : #define MAX_IRQLOOPS_PER_IRQ	10
buf : #define MAX_IRQLOOPS_PER_JIFFY	(20000 / HZ)	/* Based on a guestimate of
buf : 						 * how many events the
buf : 						 * device could
buf : 						 * legitimately generate */
buf : 
buf : #define DUMMY_FID		0xFFFF
buf : 
buf : /*#define MAX_MULTICAST(priv)	(priv->firmware_type == FIRMWARE_TYPE_AGERE ? \
buf :   HERMES_MAX_MULTICAST : 0)*/
buf : #define MAX_MULTICAST(priv)	(HERMES_MAX_MULTICAST)
buf : 
buf : #define ORINOCO_INTEN		(HERMES_EV_RX | HERMES_EV_ALLOC \
buf : 				 | HERMES_EV_TX | HERMES_EV_TXEXC \
buf : 				 | HERMES_EV_WTERR | HERMES_EV_INFO \
buf : 				 | HERMES_EV_INFDROP)
buf : 
buf : /********************************************************************/
buf : /* Data types                                                       */
buf : /********************************************************************/
buf : 
buf : /* Beginning of the Tx descriptor, used in TxExc handling */
buf : struct hermes_txexc_data {
buf : 	struct hermes_tx_descriptor desc;
buf : 	__le16 frame_ctl;
buf : 	__le16 duration_id;
buf : 	u8 addr1[ETH_ALEN];
buf : } __packed;
buf : 
buf : /* Rx frame header except compatibility 802.3 header */
buf : struct hermes_rx_descriptor {
buf : 	/* Control */
buf : 	__le16 status;
buf : 	__le32 time;
buf : 	u8 silence;
buf : 	u8 signal;
buf : 	u8 rate;
buf : 	u8 rxflow;
buf : 	__le32 reserved;
buf : 
buf : 	/* 802.11 header */
buf : 	__le16 frame_ctl;
buf : 	__le16 duration_id;
buf : 	u8 addr1[ETH_ALEN];
buf : 	u8 addr2[ETH_ALEN];
buf : 	u8 addr3[ETH_ALEN];
buf : 	__le16 seq_ctl;
buf : 	u8 addr4[ETH_ALEN];
buf : 
buf : 	/* Data length */
buf : 	__le16 data_len;
buf : } __packed;
buf : 
buf : struct orinoco_rx_data {
buf : 	struct hermes_rx_descriptor *desc;
buf : 	struct sk_buff *skb;
buf : 	struct list_head list;
buf : };
buf : 
buf : struct orinoco_scan_data {
buf : 	void *buf;
buf : 	size_t len;
buf : 	int type;
buf : 	struct list_head list;
buf : };
buf : 
buf : /********************************************************************/
buf : /* Function prototypes                                              */
buf : /********************************************************************/
buf : 
buf : static int __orinoco_set_multicast_list(struct net_device *dev);
buf : static int __orinoco_up(struct orinoco_private *priv);
buf : static int __orinoco_down(struct orinoco_private *priv);
buf : static int __orinoco_commit(struct orinoco_private *priv);
buf : 
buf : /********************************************************************/
buf : /* Internal helper functions                                        */
buf : /********************************************************************/
buf : 
buf : void set_port_type(struct orinoco_private *priv)
buf : {
buf : 	switch (priv->iw_mode) {
buf : 	case NL80211_IFTYPE_STATION:
buf : 		priv->port_type = 1;
buf : 		priv->createibss = 0;
buf : 		break;
buf : 	case NL80211_IFTYPE_ADHOC:
buf : 		if (priv->prefer_port3) {
if (priv->prefer_port3) { 
buf : 			priv->port_type = 3;
buf : 			priv->createibss = 0;
buf : 		} else {
buf : 			priv->port_type = priv->ibss_port;
buf : 			priv->createibss = 1;
buf : 		}
buf : 		break;
buf : 	case NL80211_IFTYPE_MONITOR:
buf : 		priv->port_type = 3;
buf : 		priv->createibss = 0;
buf : 		break;
buf : 	default:
buf : 		printk(KERN_ERR "%s: Invalid priv->iw_mode in set_port_type()\n",
buf : 		       priv->ndev->name);
buf : 	}
buf : }
buf : 
buf : /********************************************************************/
buf : /* Device methods                                                   */
buf : /********************************************************************/
buf : 
buf : int orinoco_open(struct net_device *dev)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	unsigned long flags;
buf : 	int err;
buf : 
buf : 	if (orinoco_lock(priv, &flags) != 0)
if (orinoco_lock(priv, &flags) != 0) 
buf : 		return -EBUSY;
buf : 
buf : 	err = __orinoco_up(priv);
buf : 
buf : 	if (!err)
if (!err) 
buf : 		priv->open = 1;
buf : 
buf : 	orinoco_unlock(priv, &flags);
buf : 
buf : 	return err;
buf : }
buf : EXPORT_SYMBOL(orinoco_open);
buf : 
buf : int orinoco_stop(struct net_device *dev)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	int err = 0;
buf : 
buf : 	/* We mustn't use orinoco_lock() here, because we need to be
buf : 	   able to close the interface even if hw_unavailable is set
if hw_unavailable is set 
buf : 	   (e.g. as we're released after a PC Card removal) */
buf : 	orinoco_lock_irq(priv);
buf : 
buf : 	priv->open = 0;
buf : 
buf : 	err = __orinoco_down(priv);
buf : 
buf : 	orinoco_unlock_irq(priv);
buf : 
buf : 	return err;
buf : }
buf : EXPORT_SYMBOL(orinoco_stop);
buf : 
buf : struct net_device_stats *orinoco_get_stats(struct net_device *dev)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 
buf : 	return &priv->stats;
buf : }
buf : EXPORT_SYMBOL(orinoco_get_stats);
buf : 
buf : void orinoco_set_multicast_list(struct net_device *dev)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	unsigned long flags;
buf : 
buf : 	if (orinoco_lock(priv, &flags) != 0) {
if (orinoco_lock(priv, &flags) != 0) { 
buf : 		printk(KERN_DEBUG "%s: orinoco_set_multicast_list() "
buf : 		       "called when hw_unavailable\n", dev->name);
buf : 		return;
buf : 	}
buf : 
buf : 	__orinoco_set_multicast_list(dev);
buf : 	orinoco_unlock(priv, &flags);
buf : }
buf : EXPORT_SYMBOL(orinoco_set_multicast_list);
buf : 
buf : int orinoco_change_mtu(struct net_device *dev, int new_mtu)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 
buf : 	if ((new_mtu < ORINOCO_MIN_MTU) || (new_mtu > ORINOCO_MAX_MTU))
if ((new_mtu < ORINOCO_MIN_MTU) || (new_mtu > ORINOCO_MAX_MTU)) 
buf : 		return -EINVAL;
buf : 
buf : 	/* MTU + encapsulation + header length */
buf : 	if ((new_mtu + ENCAPS_OVERHEAD + sizeof(struct ieee80211_hdr)) >
if ((new_mtu + ENCAPS_OVERHEAD + sizeof(struct ieee80211_hdr)) > 
buf : 	     (priv->nicbuf_size - ETH_HLEN))
buf : 		return -EINVAL;
buf : 
buf : 	dev->mtu = new_mtu;
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL(orinoco_change_mtu);
buf : 
buf : /********************************************************************/
buf : /* Tx path                                                          */
buf : /********************************************************************/
buf : 
buf : /* Add encapsulation and MIC to the existing SKB.
buf :  * The main xmit routine will then send the whole lot to the card.
buf :  * Need 8 bytes headroom
buf :  * Need 8 bytes tailroom
buf :  *
buf :  *                          With encapsulated ethernet II frame
buf :  *                          --------
buf :  *                          803.3 header (14 bytes)
buf :  *                           dst[6]
buf :  * --------                  src[6]
buf :  * 803.3 header (14 bytes)   len[2]
buf :  *  dst[6]                  803.2 header (8 bytes)
buf :  *  src[6]                   encaps[6]
buf :  *  len[2] <- leave alone -> len[2]
buf :  * --------                 -------- <-- 0
buf :  * Payload                  Payload
buf :  * ...                      ...
buf :  *
buf :  * --------                 --------
buf :  *                          MIC (8 bytes)
buf :  *                          --------
buf :  *
buf :  * returns 0 on success, -ENOMEM on error.
buf :  */
buf : int orinoco_process_xmit_skb(struct sk_buff *skb,
buf : 			     struct net_device *dev,
buf : 			     struct orinoco_private *priv,
buf : 			     int *tx_control,
buf : 			     u8 *mic_buf)
buf : {
buf : 	struct orinoco_tkip_key *key;
buf : 	struct ethhdr *eh;
buf : 	int do_mic;
buf : 
buf : 	key = (struct orinoco_tkip_key *) priv->keys[priv->tx_key].key;
buf : 
buf : 	do_mic = ((priv->encode_alg == ORINOCO_ALG_TKIP) &&
buf : 		  (key != NULL));
buf : 
buf : 	if (do_mic)
if (do_mic) 
buf : 		*tx_control |= (priv->tx_key << HERMES_MIC_KEY_ID_SHIFT) |
buf : 			HERMES_TXCTRL_MIC;
buf : 
buf : 	eh = (struct ethhdr *)skb->data;
buf : 
buf : 	/* Encapsulate Ethernet-II frames */
buf : 	if (ntohs(eh->h_proto) > ETH_DATA_LEN) { /* Ethernet-II frame */
if (ntohs(eh->h_proto) > ETH_DATA_LEN) { /* Ethernet-II frame */ 
buf : 		struct header_struct {
buf : 			struct ethhdr eth;	/* 802.3 header */
buf : 			u8 encap[6];		/* 802.2 header */
buf : 		} __packed hdr;
buf : 		int len = skb->len + sizeof(encaps_hdr) - (2 * ETH_ALEN);
buf : 
buf : 		if (skb_headroom(skb) < ENCAPS_OVERHEAD) {
if (skb_headroom(skb) < ENCAPS_OVERHEAD) { 
buf : 			if (net_ratelimit())
buf : 				printk(KERN_ERR
buf : 				       "%s: Not enough headroom for 802.2 headers %d\n",
for 802.2 headers %d\n", 
buf : 				       dev->name, skb_headroom(skb));
buf : 			return -ENOMEM;
buf : 		}
buf : 
buf : 		/* Fill in new header */
buf : 		memcpy(&hdr.eth, eh, 2 * ETH_ALEN);
buf : 		hdr.eth.h_proto = htons(len);
buf : 		memcpy(hdr.encap, encaps_hdr, sizeof(encaps_hdr));
buf : 
buf : 		/* Make room for the new header, and copy it in */
for the new header, and copy it in */ 
buf : 		eh = (struct ethhdr *) skb_push(skb, ENCAPS_OVERHEAD);
buf : 		memcpy(eh, &hdr, sizeof(hdr));
buf : 	}
buf : 
buf : 	/* Calculate Michael MIC */
buf : 	if (do_mic) {
if (do_mic) { 
buf : 		size_t len = skb->len - ETH_HLEN;
buf : 		u8 *mic = &mic_buf[0];
buf : 
buf : 		/* Have to write to an even address, so copy the spare
buf : 		 * byte across */
buf : 		if (skb->len % 2) {
if (skb->len % 2) { 
buf : 			*mic = skb->data[skb->len - 1];
buf : 			mic++;
buf : 		}
buf : 
buf : 		orinoco_mic(priv->tx_tfm_mic, key->tx_mic,
buf : 			    eh->h_dest, eh->h_source, 0 /* priority */,
buf : 			    skb->data + ETH_HLEN,
buf : 			    len, mic);
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL(orinoco_process_xmit_skb);
buf : 
buf : static netdev_tx_t orinoco_xmit(struct sk_buff *skb, struct net_device *dev)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	struct net_device_stats *stats = &priv->stats;
buf : 	struct hermes *hw = &priv->hw;
buf : 	int err = 0;
buf : 	u16 txfid = priv->txfid;
buf : 	int tx_control;
buf : 	unsigned long flags;
buf : 	u8 mic_buf[MICHAEL_MIC_LEN + 1];
buf : 
buf : 	if (!netif_running(dev)) {
if (!netif_running(dev)) { 
buf : 		printk(KERN_ERR "%s: Tx on stopped device!\n",
buf : 		       dev->name);
buf : 		return NETDEV_TX_BUSY;
buf : 	}
buf : 
buf : 	if (netif_queue_stopped(dev)) {
if (netif_queue_stopped(dev)) { 
buf : 		printk(KERN_DEBUG "%s: Tx while transmitter busy!\n",
while transmitter busy!\n", 
buf : 		       dev->name);
buf : 		return NETDEV_TX_BUSY;
buf : 	}
buf : 
buf : 	if (orinoco_lock(priv, &flags) != 0) {
if (orinoco_lock(priv, &flags) != 0) { 
buf : 		printk(KERN_ERR "%s: orinoco_xmit() called while hw_unavailable\n",
while hw_unavailable\n", 
buf : 		       dev->name);
buf : 		return NETDEV_TX_BUSY;
buf : 	}
buf : 
buf : 	if (!netif_carrier_ok(dev) ||
if (!netif_carrier_ok(dev) || 
buf : 	    (priv->iw_mode == NL80211_IFTYPE_MONITOR)) {
buf : 		/* Oops, the firmware hasn't established a connection,
buf : 		   silently drop the packet (this seems to be the
buf : 		   safest approach). */
buf : 		goto drop;
buf : 	}
buf : 
buf : 	/* Check packet length */
buf : 	if (skb->len < ETH_HLEN)
if (skb->len < ETH_HLEN) 
buf : 		goto drop;
buf : 
buf : 	tx_control = HERMES_TXCTRL_TX_OK | HERMES_TXCTRL_TX_EX;
buf : 
buf : 	err = orinoco_process_xmit_skb(skb, dev, priv, &tx_control,
buf : 				       &mic_buf[0]);
buf : 	if (err)
if (err) 
buf : 		goto drop;
buf : 
buf : 	if (priv->has_alt_txcntl) {
if (priv->has_alt_txcntl) { 
buf : 		/* WPA enabled firmwares have tx_cntl at the end of
buf : 		 * the 802.11 header.  So write zeroed descriptor and
buf : 		 * 802.11 header at the same time
buf : 		 */
buf : 		char desc[HERMES_802_3_OFFSET];
buf : 		__le16 *txcntl = (__le16 *) &desc[HERMES_TXCNTL2_OFFSET];
buf : 
buf : 		memset(&desc, 0, sizeof(desc));
buf : 
buf : 		*txcntl = cpu_to_le16(tx_control);
buf : 		err = hw->ops->bap_pwrite(hw, USER_BAP, &desc, sizeof(desc),
buf : 					  txfid, 0);
buf : 		if (err) {
if (err) { 
buf : 			if (net_ratelimit())
buf : 				printk(KERN_ERR "%s: Error %d writing Tx "
buf : 				       "descriptor to BAP\n", dev->name, err);
buf : 			goto busy;
buf : 		}
buf : 	} else {
buf : 		struct hermes_tx_descriptor desc;
buf : 
buf : 		memset(&desc, 0, sizeof(desc));
buf : 
buf : 		desc.tx_control = cpu_to_le16(tx_control);
buf : 		err = hw->ops->bap_pwrite(hw, USER_BAP, &desc, sizeof(desc),
buf : 					  txfid, 0);
buf : 		if (err) {
if (err) { 
buf : 			if (net_ratelimit())
buf : 				printk(KERN_ERR "%s: Error %d writing Tx "
buf : 				       "descriptor to BAP\n", dev->name, err);
buf : 			goto busy;
buf : 		}
buf : 
buf : 		/* Clear the 802.11 header and data length fields - some
buf : 		 * firmwares (e.g. Lucent/Agere 8.xx) appear to get confused
buf : 		 * if this isn't done. */
if this isn't done. */ 
buf : 		hermes_clear_words(hw, HERMES_DATA0,
buf : 				   HERMES_802_3_OFFSET - HERMES_802_11_OFFSET);
buf : 	}
buf : 
buf : 	err = hw->ops->bap_pwrite(hw, USER_BAP, skb->data, skb->len,
buf : 				  txfid, HERMES_802_3_OFFSET);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_ERR "%s: Error %d writing packet to BAP\n",
buf : 		       dev->name, err);
buf : 		goto busy;
buf : 	}
buf : 
buf : 	if (tx_control & HERMES_TXCTRL_MIC) {
if (tx_control & HERMES_TXCTRL_MIC) { 
buf : 		size_t offset = HERMES_802_3_OFFSET + skb->len;
buf : 		size_t len = MICHAEL_MIC_LEN;
buf : 
buf : 		if (offset % 2) {
if (offset % 2) { 
buf : 			offset--;
buf : 			len++;
buf : 		}
buf : 		err = hw->ops->bap_pwrite(hw, USER_BAP, &mic_buf[0], len,
buf : 					  txfid, offset);
buf : 		if (err) {
if (err) { 
buf : 			printk(KERN_ERR "%s: Error %d writing MIC to BAP\n",
buf : 			       dev->name, err);
buf : 			goto busy;
buf : 		}
buf : 	}
buf : 
buf : 	/* Finally, we actually initiate the send */
buf : 	netif_stop_queue(dev);
if_stop_queue(dev); 
buf : 
buf : 	err = hw->ops->cmd_wait(hw, HERMES_CMD_TX | HERMES_CMD_RECL,
buf : 				txfid, NULL);
buf : 	if (err) {
if (err) { 
buf : 		netif_start_queue(dev);
buf : 		if (net_ratelimit())
if (net_ratelimit()) 
buf : 			printk(KERN_ERR "%s: Error %d transmitting packet\n",
buf : 				dev->name, err);
buf : 		goto busy;
buf : 	}
buf : 
buf : 	stats->tx_bytes += HERMES_802_3_OFFSET + skb->len;
buf : 	goto ok;
buf : 
buf :  drop:
buf : 	stats->tx_errors++;
buf : 	stats->tx_dropped++;
buf : 
buf :  ok:
buf : 	orinoco_unlock(priv, &flags);
buf : 	dev_kfree_skb(skb);
buf : 	return NETDEV_TX_OK;
buf : 
buf :  busy:
buf : 	if (err == -EIO)
if (err == -EIO) 
buf : 		schedule_work(&priv->reset_work);
buf : 	orinoco_unlock(priv, &flags);
buf : 	return NETDEV_TX_BUSY;
buf : }
buf : 
buf : static void __orinoco_ev_alloc(struct net_device *dev, struct hermes *hw)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	u16 fid = hermes_read_regn(hw, ALLOCFID);
buf : 
buf : 	if (fid != priv->txfid) {
if (fid != priv->txfid) { 
buf : 		if (fid != DUMMY_FID)
buf : 			printk(KERN_WARNING "%s: Allocate event on unexpected fid (%04X)\n",
buf : 			       dev->name, fid);
buf : 		return;
buf : 	}
buf : 
buf : 	hermes_write_regn(hw, ALLOCFID, DUMMY_FID);
buf : }
buf : 
buf : static void __orinoco_ev_tx(struct net_device *dev, struct hermes *hw)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	struct net_device_stats *stats = &priv->stats;
buf : 
buf : 	stats->tx_packets++;
buf : 
buf : 	netif_wake_queue(dev);
if_wake_queue(dev); 
buf : 
buf : 	hermes_write_regn(hw, TXCOMPLFID, DUMMY_FID);
buf : }
buf : 
buf : static void __orinoco_ev_txexc(struct net_device *dev, struct hermes *hw)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	struct net_device_stats *stats = &priv->stats;
buf : 	u16 fid = hermes_read_regn(hw, TXCOMPLFID);
buf : 	u16 status;
buf : 	struct hermes_txexc_data hdr;
buf : 	int err = 0;
buf : 
buf : 	if (fid == DUMMY_FID)
if (fid == DUMMY_FID) 
buf : 		return; /* Nothing's really happened */
buf : 
buf : 	/* Read part of the frame header - we need status and addr1 */
buf : 	err = hw->ops->bap_pread(hw, IRQ_BAP, &hdr,
buf : 				 sizeof(struct hermes_txexc_data),
buf : 				 fid, 0);
buf : 
buf : 	hermes_write_regn(hw, TXCOMPLFID, DUMMY_FID);
buf : 	stats->tx_errors++;
buf : 
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_WARNING "%s: Unable to read descriptor on Tx error "
buf : 		       "(FID=%04X error %d)\n",
buf : 		       dev->name, fid, err);
buf : 		return;
buf : 	}
buf : 
buf : 	DEBUG(1, "%s: Tx error, err %d (FID=%04X)\n", dev->name,
buf : 	      err, fid);
buf : 
buf : 	/* We produce a TXDROP event only for retry or lifetime
ifetime 
buf : 	 * exceeded, because that's the only status that really mean
buf : 	 * that this particular node went away.
buf : 	 * Other errors means that *we* screwed up. - Jean II */
buf : 	status = le16_to_cpu(hdr.desc.status);
buf : 	if (status & (HERMES_TXSTAT_RETRYERR | HERMES_TXSTAT_AGEDERR)) {
if (status & (HERMES_TXSTAT_RETRYERR | HERMES_TXSTAT_AGEDERR)) { 
buf : 		union iwreq_data	wrqu;
buf : 
buf : 		/* Copy 802.11 dest address.
buf : 		 * We use the 802.11 header because the frame may
buf : 		 * not be 802.3 or may be mangled...
buf : 		 * In Ad-Hoc mode, it will be the node address.
buf : 		 * In managed mode, it will be most likely the AP addr
buf : 		 * User space will figure out how to convert it to
buf : 		 * whatever it needs (IP address or else).
buf : 		 * - Jean II */
buf : 		memcpy(wrqu.addr.sa_data, hdr.addr1, ETH_ALEN);
buf : 		wrqu.addr.sa_family = ARPHRD_ETHER;
buf : 
buf : 		/* Send event to user space */
buf : 		wireless_send_event(dev, IWEVTXDROP, &wrqu, NULL);
buf : 	}
buf : 
buf : 	netif_wake_queue(dev);
if_wake_queue(dev); 
buf : }
buf : 
buf : void orinoco_tx_timeout(struct net_device *dev)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	struct net_device_stats *stats = &priv->stats;
buf : 	struct hermes *hw = &priv->hw;
buf : 
buf : 	printk(KERN_WARNING "%s: Tx timeout! "
buf : 	       "ALLOCFID=%04x, TXCOMPLFID=%04x, EVSTAT=%04x\n",
buf : 	       dev->name, hermes_read_regn(hw, ALLOCFID),
buf : 	       hermes_read_regn(hw, TXCOMPLFID), hermes_read_regn(hw, EVSTAT));
buf : 
buf : 	stats->tx_errors++;
buf : 
buf : 	schedule_work(&priv->reset_work);
buf : }
buf : EXPORT_SYMBOL(orinoco_tx_timeout);
buf : 
buf : /********************************************************************/
buf : /* Rx path (data frames)                                            */
buf : /********************************************************************/
buf : 
buf : /* Does the frame have a SNAP header indicating it should be
buf :  * de-encapsulated to Ethernet-II? */
buf : static inline int is_ethersnap(void *_hdr)
buf : {
buf : 	u8 *hdr = _hdr;
buf : 
buf : 	/* We de-encapsulate all packets which, a) have SNAP headers
buf : 	 * (i.e. SSAP=DSAP=0xaa and CTRL=0x3 in the 802.2 LLC header
buf : 	 * and where b) the OUI of the SNAP header is 00:00:00 or
buf : 	 * 00:00:f8 - we need both because different APs appear to use
ifferent APs appear to use 
buf : 	 * different OUIs for some reason */
for some reason */ 
buf : 	return (memcmp(hdr, &encaps_hdr, 5) == 0)
buf : 		&& ((hdr[5] == 0x00) || (hdr[5] == 0xf8));
buf : }
buf : 
buf : static inline void orinoco_spy_gather(struct net_device *dev, u_char *mac,
buf : 				      int level, int noise)
buf : {
buf : 	struct iw_quality wstats;
buf : 	wstats.level = level - 0x95;
buf : 	wstats.noise = noise - 0x95;
buf : 	wstats.qual = (level > noise) ? (level - noise) : 0;
buf : 	wstats.updated = IW_QUAL_ALL_UPDATED | IW_QUAL_DBM;
buf : 	/* Update spy records */
buf : 	wireless_spy_update(dev, mac, &wstats);
buf : }
buf : 
buf : static void orinoco_stat_gather(struct net_device *dev,
buf : 				struct sk_buff *skb,
buf : 				struct hermes_rx_descriptor *desc)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 
buf : 	/* Using spy support with lots of Rx packets, like in an
buf : 	 * infrastructure (AP), will really slow down everything, because
buf : 	 * the MAC address must be compared to each entry of the spy list.
buf : 	 * If the user really asks for it (set some address in the
for it (set some address in the 
buf : 	 * spy list), we do it, but he will pay the price.
buf : 	 * Note that to get here, you need both WIRELESS_SPY
buf : 	 * compiled in AND some addresses in the list !!!
buf : 	 */
buf : 	/* Note : gcc will optimise the whole section away if
if 
buf : 	 * WIRELESS_SPY is not defined... - Jean II */
buf : 	if (SPY_NUMBER(priv)) {
if (SPY_NUMBER(priv)) { 
buf : 		orinoco_spy_gather(dev, skb_mac_header(skb) + ETH_ALEN,
buf : 				   desc->signal, desc->silence);
buf : 	}
buf : }
buf : 
buf : /*
buf :  * orinoco_rx_monitor - handle received monitor frames.
buf :  *
buf :  * Arguments:
buf :  *	dev		network device
buf :  *	rxfid		received FID
buf :  *	desc		rx descriptor of the frame
buf :  *
buf :  * Call context: interrupt
buf :  */
buf : static void orinoco_rx_monitor(struct net_device *dev, u16 rxfid,
buf : 			       struct hermes_rx_descriptor *desc)
buf : {
buf : 	u32 hdrlen = 30;	/* return full header by default */
buf : 	u32 datalen = 0;
buf : 	u16 fc;
buf : 	int err;
buf : 	int len;
buf : 	struct sk_buff *skb;
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	struct net_device_stats *stats = &priv->stats;
buf : 	struct hermes *hw = &priv->hw;
buf : 
buf : 	len = le16_to_cpu(desc->data_len);
buf : 
buf : 	/* Determine the size of the header and the data */
buf : 	fc = le16_to_cpu(desc->frame_ctl);
buf : 	switch (fc & IEEE80211_FCTL_FTYPE) {
buf : 	case IEEE80211_FTYPE_DATA:
buf : 		if ((fc & IEEE80211_FCTL_TODS)
if ((fc & IEEE80211_FCTL_TODS) 
buf : 		    && (fc & IEEE80211_FCTL_FROMDS))
buf : 			hdrlen = 30;
buf : 		else
buf : 			hdrlen = 24;
buf : 		datalen = len;
buf : 		break;
buf : 	case IEEE80211_FTYPE_MGMT:
buf : 		hdrlen = 24;
buf : 		datalen = len;
buf : 		break;
buf : 	case IEEE80211_FTYPE_CTL:
buf : 		switch (fc & IEEE80211_FCTL_STYPE) {
buf : 		case IEEE80211_STYPE_PSPOLL:
buf : 		case IEEE80211_STYPE_RTS:
buf : 		case IEEE80211_STYPE_CFEND:
buf : 		case IEEE80211_STYPE_CFENDACK:
buf : 			hdrlen = 16;
buf : 			break;
buf : 		case IEEE80211_STYPE_CTS:
buf : 		case IEEE80211_STYPE_ACK:
buf : 			hdrlen = 10;
buf : 			break;
buf : 		}
buf : 		break;
buf : 	default:
buf : 		/* Unknown frame type */
buf : 		break;
buf : 	}
buf : 
buf : 	/* sanity check the length */
buf : 	if (datalen > IEEE80211_MAX_DATA_LEN + 12) {
if (datalen > IEEE80211_MAX_DATA_LEN + 12) { 
buf : 		printk(KERN_DEBUG "%s: oversized monitor frame, "
buf : 		       "data length = %d\n", dev->name, datalen);
buf : 		stats->rx_length_errors++;
buf : 		goto update_stats;
buf : 	}
buf : 
buf : 	skb = dev_alloc_skb(hdrlen + datalen);
buf : 	if (!skb) {
if (!skb) { 
buf : 		printk(KERN_WARNING "%s: Cannot allocate skb for monitor frame\n",
for monitor frame\n", 
buf : 		       dev->name);
buf : 		goto update_stats;
buf : 	}
buf : 
buf : 	/* Copy the 802.11 header to the skb */
buf : 	memcpy(skb_put(skb, hdrlen), &(desc->frame_ctl), hdrlen);
buf : 	skb_reset_mac_header(skb);
buf : 
buf : 	/* If any, copy the data from the card to the skb */
buf : 	if (datalen > 0) {
if (datalen > 0) { 
buf : 		err = hw->ops->bap_pread(hw, IRQ_BAP, skb_put(skb, datalen),
buf : 					 ALIGN(datalen, 2), rxfid,
buf : 					 HERMES_802_2_OFFSET);
buf : 		if (err) {
if (err) { 
buf : 			printk(KERN_ERR "%s: error %d reading monitor frame\n",
buf : 			       dev->name, err);
buf : 			goto drop;
buf : 		}
buf : 	}
buf : 
buf : 	skb->dev = dev;
buf : 	skb->ip_summed = CHECKSUM_NONE;
buf : 	skb->pkt_type = PACKET_OTHERHOST;
buf : 	skb->protocol = cpu_to_be16(ETH_P_802_2);
buf : 
buf : 	stats->rx_packets++;
buf : 	stats->rx_bytes += skb->len;
buf : 
buf : 	netif_rx(skb);
if_rx(skb); 
buf : 	return;
buf : 
buf :  drop:
buf : 	dev_kfree_skb_irq(skb);
buf :  update_stats:
buf : 	stats->rx_errors++;
buf : 	stats->rx_dropped++;
buf : }
buf : 
buf : void __orinoco_ev_rx(struct net_device *dev, struct hermes *hw)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	struct net_device_stats *stats = &priv->stats;
buf : 	struct iw_statistics *wstats = &priv->wstats;
buf : 	struct sk_buff *skb = NULL;
buf : 	u16 rxfid, status;
buf : 	int length;
buf : 	struct hermes_rx_descriptor *desc;
buf : 	struct orinoco_rx_data *rx_data;
buf : 	int err;
buf : 
buf : 	desc = kmalloc(sizeof(*desc), GFP_ATOMIC);
buf : 	if (!desc)
if (!desc) 
buf : 		goto update_stats;
buf : 
buf : 	rxfid = hermes_read_regn(hw, RXFID);
buf : 
buf : 	err = hw->ops->bap_pread(hw, IRQ_BAP, desc, sizeof(*desc),
buf : 				 rxfid, 0);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_ERR "%s: error %d reading Rx descriptor. "
buf : 		       "Frame dropped.\n", dev->name, err);
buf : 		goto update_stats;
buf : 	}
buf : 
buf : 	status = le16_to_cpu(desc->status);
buf : 
buf : 	if (status & HERMES_RXSTAT_BADCRC) {
if (status & HERMES_RXSTAT_BADCRC) { 
buf : 		DEBUG(1, "%s: Bad CRC on Rx. Frame dropped.\n",
buf : 		      dev->name);
buf : 		stats->rx_crc_errors++;
buf : 		goto update_stats;
buf : 	}
buf : 
buf : 	/* Handle frames in monitor mode */
buf : 	if (priv->iw_mode == NL80211_IFTYPE_MONITOR) {
if (priv->iw_mode == NL80211_IFTYPE_MONITOR) { 
buf : 		orinoco_rx_monitor(dev, rxfid, desc);
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (status & HERMES_RXSTAT_UNDECRYPTABLE) {
if (status & HERMES_RXSTAT_UNDECRYPTABLE) { 
buf : 		DEBUG(1, "%s: Undecryptable frame on Rx. Frame dropped.\n",
buf : 		      dev->name);
buf : 		wstats->discard.code++;
buf : 		goto update_stats;
buf : 	}
buf : 
buf : 	length = le16_to_cpu(desc->data_len);
buf : 
buf : 	/* Sanity checks */
buf : 	if (length < 3) { /* No for even an 802.2 LLC header */
if (length < 3) { /* No for even an 802.2 LLC header */ 
buf : 		/* At least on Symbol firmware with PCF we get quite a
buf : 		   lot of these legitimately - Poll frames with no
buf : 		   data. */
buf : 		goto out;
buf : 	}
buf : 	if (length > IEEE80211_MAX_DATA_LEN) {
if (length > IEEE80211_MAX_DATA_LEN) { 
buf : 		printk(KERN_WARNING "%s: Oversized frame received (%d bytes)\n",
buf : 		       dev->name, length);
buf : 		stats->rx_length_errors++;
buf : 		goto update_stats;
buf : 	}
buf : 
buf : 	/* Payload size does not include Michael MIC. Increase payload
buf : 	 * size to read it together with the data. */
buf : 	if (status & HERMES_RXSTAT_MIC)
if (status & HERMES_RXSTAT_MIC) 
buf : 		length += MICHAEL_MIC_LEN;
buf : 
buf : 	/* We need space for the packet data itself, plus an ethernet
for the packet data itself, plus an ethernet 
buf : 	   header, plus 2 bytes so we can align the IP header on a
buf : 	   32bit boundary, plus 1 byte so we can read in odd length
buf : 	   packets from the card, which has an IO granularity of 16
buf : 	   bits */
buf : 	skb = dev_alloc_skb(length + ETH_HLEN + 2 + 1);
buf : 	if (!skb) {
if (!skb) { 
buf : 		printk(KERN_WARNING "%s: Can't allocate skb for Rx\n",
for Rx\n", 
buf : 		       dev->name);
buf : 		goto update_stats;
buf : 	}
buf : 
buf : 	/* We'll prepend the header, so reserve space for it.  The worst
for it.  The worst 
buf : 	   case is no decapsulation, when 802.3 header is prepended and
buf : 	   nothing is removed.  2 is for aligning the IP header.  */
for aligning the IP header.  */ 
buf : 	skb_reserve(skb, ETH_HLEN + 2);
buf : 
buf : 	err = hw->ops->bap_pread(hw, IRQ_BAP, skb_put(skb, length),
buf : 				 ALIGN(length, 2), rxfid,
buf : 				 HERMES_802_2_OFFSET);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_ERR "%s: error %d reading frame. "
buf : 		       "Frame dropped.\n", dev->name, err);
buf : 		goto drop;
buf : 	}
buf : 
buf : 	/* Add desc and skb to rx queue */
buf : 	rx_data = kzalloc(sizeof(*rx_data), GFP_ATOMIC);
buf : 	if (!rx_data)
if (!rx_data) 
buf : 		goto drop;
buf : 
buf : 	rx_data->desc = desc;
buf : 	rx_data->skb = skb;
buf : 	list_add_tail(&rx_data->list, &priv->rx_list);
buf : 	tasklet_schedule(&priv->rx_tasklet);
buf : 
buf : 	return;
buf : 
buf : drop:
buf : 	dev_kfree_skb_irq(skb);
buf : update_stats:
buf : 	stats->rx_errors++;
buf : 	stats->rx_dropped++;
buf : out:
buf : 	kfree(desc);
buf : }
buf : EXPORT_SYMBOL(__orinoco_ev_rx);
buf : 
buf : static void orinoco_rx(struct net_device *dev,
buf : 		       struct hermes_rx_descriptor *desc,
buf : 		       struct sk_buff *skb)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	struct net_device_stats *stats = &priv->stats;
buf : 	u16 status, fc;
buf : 	int length;
buf : 	struct ethhdr *hdr;
buf : 
buf : 	status = le16_to_cpu(desc->status);
buf : 	length = le16_to_cpu(desc->data_len);
buf : 	fc = le16_to_cpu(desc->frame_ctl);
buf : 
buf : 	/* Calculate and check MIC */
buf : 	if (status & HERMES_RXSTAT_MIC) {
if (status & HERMES_RXSTAT_MIC) { 
buf : 		struct orinoco_tkip_key *key;
buf : 		int key_id = ((status & HERMES_RXSTAT_MIC_KEY_ID) >>
buf : 			      HERMES_MIC_KEY_ID_SHIFT);
buf : 		u8 mic[MICHAEL_MIC_LEN];
buf : 		u8 *rxmic;
buf : 		u8 *src = (fc & IEEE80211_FCTL_FROMDS) ?
buf : 			desc->addr3 : desc->addr2;
buf : 
buf : 		/* Extract Michael MIC from payload */
buf : 		rxmic = skb->data + skb->len - MICHAEL_MIC_LEN;
buf : 
buf : 		skb_trim(skb, skb->len - MICHAEL_MIC_LEN);
buf : 		length -= MICHAEL_MIC_LEN;
buf : 
buf : 		key = (struct orinoco_tkip_key *) priv->keys[key_id].key;
buf : 
buf : 		if (!key) {
if (!key) { 
buf : 			printk(KERN_WARNING "%s: Received encrypted frame from "
buf : 			       "%pM using key %i, but key is not installed\n",
buf : 			       dev->name, src, key_id);
buf : 			goto drop;
buf : 		}
buf : 
buf : 		orinoco_mic(priv->rx_tfm_mic, key->rx_mic, desc->addr1, src,
buf : 			    0, /* priority or QoS? */
buf : 			    skb->data, skb->len, &mic[0]);
buf : 
buf : 		if (memcmp(mic, rxmic,
if (memcmp(mic, rxmic, 
buf : 			   MICHAEL_MIC_LEN)) {
buf : 			union iwreq_data wrqu;
buf : 			struct iw_michaelmicfailure wxmic;
buf : 
buf : 			printk(KERN_WARNING "%s: "
buf : 			       "Invalid Michael MIC in data frame from %pM, "
buf : 			       "using key %i\n",
buf : 			       dev->name, src, key_id);
buf : 
buf : 			/* TODO: update stats */
buf : 
buf : 			/* Notify userspace */
ify userspace */ 
buf : 			memset(&wxmic, 0, sizeof(wxmic));
buf : 			wxmic.flags = key_id & IW_MICFAILURE_KEY_ID;
buf : 			wxmic.flags |= (desc->addr1[0] & 1) ?
buf : 				IW_MICFAILURE_GROUP : IW_MICFAILURE_PAIRWISE;
buf : 			wxmic.src_addr.sa_family = ARPHRD_ETHER;
buf : 			memcpy(wxmic.src_addr.sa_data, src, ETH_ALEN);
buf : 
buf : 			(void) orinoco_hw_get_tkip_iv(priv, key_id,
buf : 						      &wxmic.tsc[0]);
buf : 
buf : 			memset(&wrqu, 0, sizeof(wrqu));
buf : 			wrqu.data.length = sizeof(wxmic);
buf : 			wireless_send_event(dev, IWEVMICHAELMICFAILURE, &wrqu,
buf : 					    (char *) &wxmic);
buf : 
buf : 			goto drop;
buf : 		}
buf : 	}
buf : 
buf : 	/* Handle decapsulation
buf : 	 * In most cases, the firmware tell us about SNAP frames.
buf : 	 * For some reason, the SNAP frames sent by LinkSys APs
buf : 	 * are not properly recognised by most firmwares.
buf : 	 * So, check ourselves */
buf : 	if (length >= ENCAPS_OVERHEAD &&
if (length >= ENCAPS_OVERHEAD && 
buf : 	    (((status & HERMES_RXSTAT_MSGTYPE) == HERMES_RXSTAT_1042) ||
buf : 	     ((status & HERMES_RXSTAT_MSGTYPE) == HERMES_RXSTAT_TUNNEL) ||
buf : 	     is_ethersnap(skb->data))) {
buf : 		/* These indicate a SNAP within 802.2 LLC within
buf : 		   802.11 frame which we'll need to de-encapsulate to
buf : 		   the original EthernetII frame. */
buf : 		hdr = (struct ethhdr *)skb_push(skb,
buf : 						ETH_HLEN - ENCAPS_OVERHEAD);
buf : 	} else {
buf : 		/* 802.3 frame - prepend 802.3 header as is */
buf : 		hdr = (struct ethhdr *)skb_push(skb, ETH_HLEN);
buf : 		hdr->h_proto = htons(length);
buf : 	}
buf : 	memcpy(hdr->h_dest, desc->addr1, ETH_ALEN);
buf : 	if (fc & IEEE80211_FCTL_FROMDS)
if (fc & IEEE80211_FCTL_FROMDS) 
buf : 		memcpy(hdr->h_source, desc->addr3, ETH_ALEN);
buf : 	else
buf : 		memcpy(hdr->h_source, desc->addr2, ETH_ALEN);
buf : 
buf : 	skb->protocol = eth_type_trans(skb, dev);
buf : 	skb->ip_summed = CHECKSUM_NONE;
buf : 	if (fc & IEEE80211_FCTL_TODS)
if (fc & IEEE80211_FCTL_TODS) 
buf : 		skb->pkt_type = PACKET_OTHERHOST;
buf : 
buf : 	/* Process the wireless stats if needed */
if needed */ 
buf : 	orinoco_stat_gather(dev, skb, desc);
buf : 
buf : 	/* Pass the packet to the networking stack */
buf : 	netif_rx(skb);
if_rx(skb); 
buf : 	stats->rx_packets++;
buf : 	stats->rx_bytes += length;
buf : 
buf : 	return;
buf : 
buf :  drop:
buf : 	dev_kfree_skb(skb);
buf : 	stats->rx_errors++;
buf : 	stats->rx_dropped++;
buf : }
buf : 
buf : static void orinoco_rx_isr_tasklet(unsigned long data)
buf : {
buf : 	struct orinoco_private *priv = (struct orinoco_private *) data;
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct orinoco_rx_data *rx_data, *temp;
buf : 	struct hermes_rx_descriptor *desc;
buf : 	struct sk_buff *skb;
buf : 	unsigned long flags;
buf : 
buf : 	/* orinoco_rx requires the driver lock, and we also need to
buf : 	 * protect priv->rx_list, so just hold the lock over the
buf : 	 * lot.
buf : 	 *
buf : 	 * If orinoco_lock fails, we've unplugged the card. In this
buf : 	 * case just abort. */
buf : 	if (orinoco_lock(priv, &flags) != 0)
if (orinoco_lock(priv, &flags) != 0) 
buf : 		return;
buf : 
buf : 	/* extract desc and skb from queue */
buf : 	list_for_each_entry_safe(rx_data, temp, &priv->rx_list, list) {
for_each_entry_safe(rx_data, temp, &priv->rx_list, list) { 
buf : 		desc = rx_data->desc;
buf : 		skb = rx_data->skb;
buf : 		list_del(&rx_data->list);
buf : 		kfree(rx_data);
buf : 
buf : 		orinoco_rx(dev, desc, skb);
buf : 
buf : 		kfree(desc);
buf : 	}
buf : 
buf : 	orinoco_unlock(priv, &flags);
buf : }
buf : 
buf : /********************************************************************/
buf : /* Rx path (info frames)                                            */
buf : /********************************************************************/
buf : 
buf : static void print_linkstatus(struct net_device *dev, u16 status)
buf : {
buf : 	char *s;
buf : 
buf : 	if (suppress_linkstatus)
if (suppress_linkstatus) 
buf : 		return;
buf : 
buf : 	switch (status) {
buf : 	case HERMES_LINKSTATUS_NOT_CONNECTED:
buf : 		s = "Not Connected";
buf : 		break;
buf : 	case HERMES_LINKSTATUS_CONNECTED:
buf : 		s = "Connected";
buf : 		break;
buf : 	case HERMES_LINKSTATUS_DISCONNECTED:
buf : 		s = "Disconnected";
buf : 		break;
buf : 	case HERMES_LINKSTATUS_AP_CHANGE:
buf : 		s = "AP Changed";
buf : 		break;
buf : 	case HERMES_LINKSTATUS_AP_OUT_OF_RANGE:
buf : 		s = "AP Out of Range";
buf : 		break;
buf : 	case HERMES_LINKSTATUS_AP_IN_RANGE:
buf : 		s = "AP In Range";
buf : 		break;
buf : 	case HERMES_LINKSTATUS_ASSOC_FAILED:
buf : 		s = "Association Failed";
buf : 		break;
buf : 	default:
buf : 		s = "UNKNOWN";
buf : 	}
buf : 
buf : 	printk(KERN_DEBUG "%s: New link status: %s (%04x)\n",
buf : 	       dev->name, s, status);
buf : }
buf : 
buf : /* Search scan results for requested BSSID, join it if found */
if found */ 
buf : static void orinoco_join_ap(struct work_struct *work)
buf : {
buf : 	struct orinoco_private *priv =
buf : 		container_of(work, struct orinoco_private, join_work);
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct hermes *hw = &priv->hw;
buf : 	int err;
buf : 	unsigned long flags;
buf : 	struct join_req {
buf : 		u8 bssid[ETH_ALEN];
buf : 		__le16 channel;
buf : 	} __packed req;
buf : 	const int atom_len = offsetof(struct prism2_scan_apinfo, atim);
buf : 	struct prism2_scan_apinfo *atom = NULL;
buf : 	int offset = 4;
buf : 	int found = 0;
buf : 	u8 *buf;
buf : 	u16 len;
buf : 
buf : 	/* Allocate buffer for scan results */
for scan results */ 
buf : 	buf = kmalloc(MAX_SCAN_LEN, GFP_KERNEL);
buf : 	if (!buf)
if (!buf) 
buf : 		return;
buf : 
buf : 	if (orinoco_lock(priv, &flags) != 0)
if (orinoco_lock(priv, &flags) != 0) 
buf : 		goto fail_lock;
buf : 
buf : 	/* Sanity checks in case user changed something in the meantime */
buf : 	if (!priv->bssid_fixed)
if (!priv->bssid_fixed) 
buf : 		goto out;
buf : 
buf : 	if (strlen(priv->desired_essid) == 0)
if (strlen(priv->desired_essid) == 0) 
buf : 		goto out;
buf : 
buf : 	/* Read scan results from the firmware */
buf : 	err = hw->ops->read_ltv(hw, USER_BAP,
buf : 				HERMES_RID_SCANRESULTSTABLE,
buf : 				MAX_SCAN_LEN, &len, buf);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_ERR "%s: Cannot read scan results\n",
buf : 		       dev->name);
buf : 		goto out;
buf : 	}
buf : 
buf : 	len = HERMES_RECLEN_TO_BYTES(len);
buf : 
buf : 	/* Go through the scan results looking for the channel of the AP
for the channel of the AP 
buf : 	 * we were requested to join */
buf : 	for (; offset + atom_len <= len; offset += atom_len) {
for (; offset + atom_len <= len; offset += atom_len) { 
buf : 		atom = (struct prism2_scan_apinfo *) (buf + offset);
buf : 		if (memcmp(&atom->bssid, priv->desired_bssid, ETH_ALEN) == 0) {
if (memcmp(&atom->bssid, priv->desired_bssid, ETH_ALEN) == 0) { 
buf : 			found = 1;
buf : 			break;
buf : 		}
buf : 	}
buf : 
buf : 	if (!found) {
if (!found) { 
buf : 		DEBUG(1, "%s: Requested AP not found in scan results\n",
buf : 		      dev->name);
buf : 		goto out;
buf : 	}
buf : 
buf : 	memcpy(req.bssid, priv->desired_bssid, ETH_ALEN);
buf : 	req.channel = atom->channel;	/* both are little-endian */
buf : 	err = HERMES_WRITE_RECORD(hw, USER_BAP, HERMES_RID_CNFJOINREQUEST,
buf : 				  &req);
buf : 	if (err)
if (err) 
buf : 		printk(KERN_ERR "%s: Error issuing join request\n", dev->name);
buf : 
buf :  out:
buf : 	orinoco_unlock(priv, &flags);
buf : 
buf :  fail_lock:
buf : 	kfree(buf);
buf : }
buf : 
buf : /* Send new BSSID to userspace */
buf : static void orinoco_send_bssid_wevent(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct hermes *hw = &priv->hw;
buf : 	union iwreq_data wrqu;
buf : 	int err;
buf : 
buf : 	err = hw->ops->read_ltv(hw, USER_BAP, HERMES_RID_CURRENTBSSID,
buf : 				ETH_ALEN, NULL, wrqu.ap_addr.sa_data);
buf : 	if (err != 0)
if (err != 0) 
buf : 		return;
buf : 
buf : 	wrqu.ap_addr.sa_family = ARPHRD_ETHER;
buf : 
buf : 	/* Send event to user space */
buf : 	wireless_send_event(dev, SIOCGIWAP, &wrqu, NULL);
buf : }
buf : 
buf : static void orinoco_send_assocreqie_wevent(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct hermes *hw = &priv->hw;
buf : 	union iwreq_data wrqu;
buf : 	int err;
buf : 	u8 buf[88];
buf : 	u8 *ie;
buf : 
buf : 	if (!priv->has_wpa)
if (!priv->has_wpa) 
buf : 		return;
buf : 
buf : 	err = hw->ops->read_ltv(hw, USER_BAP, HERMES_RID_CURRENT_ASSOC_REQ_INFO,
buf : 				sizeof(buf), NULL, &buf);
buf : 	if (err != 0)
if (err != 0) 
buf : 		return;
buf : 
buf : 	ie = orinoco_get_wpa_ie(buf, sizeof(buf));
buf : 	if (ie) {
if (ie) { 
buf : 		int rem = sizeof(buf) - (ie - &buf[0]);
buf : 		wrqu.data.length = ie[1] + 2;
buf : 		if (wrqu.data.length > rem)
if (wrqu.data.length > rem) 
buf : 			wrqu.data.length = rem;
buf : 
buf : 		if (wrqu.data.length)
if (wrqu.data.length) 
buf : 			/* Send event to user space */
buf : 			wireless_send_event(dev, IWEVASSOCREQIE, &wrqu, ie);
buf : 	}
buf : }
buf : 
buf : static void orinoco_send_assocrespie_wevent(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct hermes *hw = &priv->hw;
buf : 	union iwreq_data wrqu;
buf : 	int err;
buf : 	u8 buf[88]; /* TODO: verify max size or IW_GENERIC_IE_MAX */
ify max size or IW_GENERIC_IE_MAX */ 
buf : 	u8 *ie;
buf : 
buf : 	if (!priv->has_wpa)
if (!priv->has_wpa) 
buf : 		return;
buf : 
buf : 	err = hw->ops->read_ltv(hw, USER_BAP,
buf : 				HERMES_RID_CURRENT_ASSOC_RESP_INFO,
buf : 				sizeof(buf), NULL, &buf);
buf : 	if (err != 0)
if (err != 0) 
buf : 		return;
buf : 
buf : 	ie = orinoco_get_wpa_ie(buf, sizeof(buf));
buf : 	if (ie) {
if (ie) { 
buf : 		int rem = sizeof(buf) - (ie - &buf[0]);
buf : 		wrqu.data.length = ie[1] + 2;
buf : 		if (wrqu.data.length > rem)
if (wrqu.data.length > rem) 
buf : 			wrqu.data.length = rem;
buf : 
buf : 		if (wrqu.data.length)
if (wrqu.data.length) 
buf : 			/* Send event to user space */
buf : 			wireless_send_event(dev, IWEVASSOCRESPIE, &wrqu, ie);
buf : 	}
buf : }
buf : 
buf : static void orinoco_send_wevents(struct work_struct *work)
buf : {
buf : 	struct orinoco_private *priv =
buf : 		container_of(work, struct orinoco_private, wevent_work);
buf : 	unsigned long flags;
buf : 
buf : 	if (orinoco_lock(priv, &flags) != 0)
if (orinoco_lock(priv, &flags) != 0) 
buf : 		return;
buf : 
buf : 	orinoco_send_assocreqie_wevent(priv);
buf : 	orinoco_send_assocrespie_wevent(priv);
buf : 	orinoco_send_bssid_wevent(priv);
buf : 
buf : 	orinoco_unlock(priv, &flags);
buf : }
buf : 
buf : static void qbuf_scan(struct orinoco_private *priv, void *buf,
buf : 		      int len, int type)
buf : {
buf : 	struct orinoco_scan_data *sd;
buf : 	unsigned long flags;
buf : 
buf : 	sd = kmalloc(sizeof(*sd), GFP_ATOMIC);
buf : 	if (!sd)
if (!sd) 
buf : 		return;
buf : 
buf : 	sd->buf = buf;
buf : 	sd->len = len;
buf : 	sd->type = type;
buf : 
buf : 	spin_lock_irqsave(&priv->scan_lock, flags);
buf : 	list_add_tail(&sd->list, &priv->scan_list);
buf : 	spin_unlock_irqrestore(&priv->scan_lock, flags);
buf : 
buf : 	schedule_work(&priv->process_scan);
buf : }
buf : 
buf : static void qabort_scan(struct orinoco_private *priv)
buf : {
buf : 	struct orinoco_scan_data *sd;
buf : 	unsigned long flags;
buf : 
buf : 	sd = kmalloc(sizeof(*sd), GFP_ATOMIC);
buf : 	if (!sd)
if (!sd) 
buf : 		return;
buf : 
buf : 	sd->len = -1; /* Abort */
buf : 
buf : 	spin_lock_irqsave(&priv->scan_lock, flags);
buf : 	list_add_tail(&sd->list, &priv->scan_list);
buf : 	spin_unlock_irqrestore(&priv->scan_lock, flags);
buf : 
buf : 	schedule_work(&priv->process_scan);
buf : }
buf : 
buf : static void orinoco_process_scan_results(struct work_struct *work)
buf : {
buf : 	struct orinoco_private *priv =
buf : 		container_of(work, struct orinoco_private, process_scan);
buf : 	struct orinoco_scan_data *sd, *temp;
buf : 	unsigned long flags;
buf : 	void *buf;
buf : 	int len;
buf : 	int type;
buf : 
buf : 	spin_lock_irqsave(&priv->scan_lock, flags);
buf : 	list_for_each_entry_safe(sd, temp, &priv->scan_list, list) {
for_each_entry_safe(sd, temp, &priv->scan_list, list) { 
buf : 
buf : 		buf = sd->buf;
buf : 		len = sd->len;
buf : 		type = sd->type;
buf : 
buf : 		list_del(&sd->list);
buf : 		spin_unlock_irqrestore(&priv->scan_lock, flags);
buf : 		kfree(sd);
buf : 
buf : 		if (len > 0) {
if (len > 0) { 
buf : 			if (type == HERMES_INQ_CHANNELINFO)
buf : 				orinoco_add_extscan_result(priv, buf, len);
buf : 			else
buf : 				orinoco_add_hostscan_results(priv, buf, len);
buf : 
buf : 			kfree(buf);
buf : 		} else {
buf : 			/* Either abort or complete the scan */
buf : 			orinoco_scan_done(priv, (len < 0));
buf : 		}
buf : 
buf : 		spin_lock_irqsave(&priv->scan_lock, flags);
buf : 	}
buf : 	spin_unlock_irqrestore(&priv->scan_lock, flags);
buf : }
buf : 
buf : void __orinoco_ev_info(struct net_device *dev, struct hermes *hw)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	u16 infofid;
buf : 	struct {
buf : 		__le16 len;
buf : 		__le16 type;
buf : 	} __packed info;
buf : 	int len, type;
buf : 	int err;
buf : 
buf : 	/* This is an answer to an INQUIRE command that we did earlier,
buf : 	 * or an information "event" generated by the card
formation "event" generated by the card 
buf : 	 * The controller return to us a pseudo frame containing
buf : 	 * the information in question - Jean II */
formation in question - Jean II */ 
buf : 	infofid = hermes_read_regn(hw, INFOFID);
buf : 
buf : 	/* Read the info frame header - don't try too hard */
buf : 	err = hw->ops->bap_pread(hw, IRQ_BAP, &info, sizeof(info),
buf : 				 infofid, 0);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_ERR "%s: error %d reading info frame. "
buf : 		       "Frame dropped.\n", dev->name, err);
buf : 		return;
buf : 	}
buf : 
buf : 	len = HERMES_RECLEN_TO_BYTES(le16_to_cpu(info.len));
buf : 	type = le16_to_cpu(info.type);
buf : 
buf : 	switch (type) {
buf : 	case HERMES_INQ_TALLIES: {
buf : 		struct hermes_tallies_frame tallies;
buf : 		struct iw_statistics *wstats = &priv->wstats;
buf : 
buf : 		if (len > sizeof(tallies)) {
if (len > sizeof(tallies)) { 
buf : 			printk(KERN_WARNING "%s: Tallies frame too long (%d bytes)\n",
buf : 			       dev->name, len);
buf : 			len = sizeof(tallies);
buf : 		}
buf : 
buf : 		err = hw->ops->bap_pread(hw, IRQ_BAP, &tallies, len,
buf : 					 infofid, sizeof(info));
buf : 		if (err)
if (err) 
buf : 			break;
buf : 
buf : 		/* Increment our various counters */
buf : 		/* wstats->discard.nwid - no wrong BSSID stuff */
buf : 		wstats->discard.code +=
buf : 			le16_to_cpu(tallies.RxWEPUndecryptable);
buf : 		if (len == sizeof(tallies))
if (len == sizeof(tallies)) 
buf : 			wstats->discard.code +=
buf : 				le16_to_cpu(tallies.RxDiscards_WEPICVError) +
buf : 				le16_to_cpu(tallies.RxDiscards_WEPExcluded);
buf : 		wstats->discard.misc +=
buf : 			le16_to_cpu(tallies.TxDiscardsWrongSA);
buf : 		wstats->discard.fragment +=
buf : 			le16_to_cpu(tallies.RxMsgInBadMsgFragments);
buf : 		wstats->discard.retries +=
buf : 			le16_to_cpu(tallies.TxRetryLimitExceeded);
buf : 		/* wstats->miss.beacon - no match */
buf : 	}
buf : 	break;
buf : 	case HERMES_INQ_LINKSTATUS: {
buf : 		struct hermes_linkstatus linkstatus;
buf : 		u16 newstatus;
buf : 		int connected;
buf : 
buf : 		if (priv->iw_mode == NL80211_IFTYPE_MONITOR)
if (priv->iw_mode == NL80211_IFTYPE_MONITOR) 
buf : 			break;
buf : 
buf : 		if (len != sizeof(linkstatus)) {
if (len != sizeof(linkstatus)) { 
buf : 			printk(KERN_WARNING "%s: Unexpected size for linkstatus frame (%d bytes)\n",
for linkstatus frame (%d bytes)\n", 
buf : 			       dev->name, len);
buf : 			break;
buf : 		}
buf : 
buf : 		err = hw->ops->bap_pread(hw, IRQ_BAP, &linkstatus, len,
buf : 					 infofid, sizeof(info));
buf : 		if (err)
if (err) 
buf : 			break;
buf : 		newstatus = le16_to_cpu(linkstatus.linkstatus);
buf : 
buf : 		/* Symbol firmware uses "out of range" to signal that
buf : 		 * the hostscan frame can be requested.  */
buf : 		if (newstatus == HERMES_LINKSTATUS_AP_OUT_OF_RANGE &&
if (newstatus == HERMES_LINKSTATUS_AP_OUT_OF_RANGE && 
buf : 		    priv->firmware_type == FIRMWARE_TYPE_SYMBOL &&
buf : 		    priv->has_hostscan && priv->scan_request) {
buf : 			hermes_inquire(hw, HERMES_INQ_HOSTSCAN_SYMBOL);
buf : 			break;
buf : 		}
buf : 
buf : 		connected = (newstatus == HERMES_LINKSTATUS_CONNECTED)
buf : 			|| (newstatus == HERMES_LINKSTATUS_AP_CHANGE)
buf : 			|| (newstatus == HERMES_LINKSTATUS_AP_IN_RANGE);
buf : 
buf : 		if (connected)
if (connected) 
buf : 			netif_carrier_on(dev);
buf : 		else if (!ignore_disconnect)
if (!ignore_disconnect) 
buf : 			netif_carrier_off(dev);
buf : 
buf : 		if (newstatus != priv->last_linkstatus) {
if (newstatus != priv->last_linkstatus) { 
buf : 			priv->last_linkstatus = newstatus;
buf : 			print_linkstatus(dev, newstatus);
buf : 			/* The info frame contains only one word which is the
buf : 			 * status (see hermes.h). The status is pretty boring
buf : 			 * in itself, that's why we export the new BSSID...
buf : 			 * Jean II */
buf : 			schedule_work(&priv->wevent_work);
buf : 		}
buf : 	}
buf : 	break;
buf : 	case HERMES_INQ_SCAN:
buf : 		if (!priv->scan_request && priv->bssid_fixed &&
if (!priv->scan_request && priv->bssid_fixed && 
buf : 		    priv->firmware_type == FIRMWARE_TYPE_INTERSIL) {
buf : 			schedule_work(&priv->join_work);
buf : 			break;
buf : 		}
buf : 		/* fall through */
buf : 	case HERMES_INQ_HOSTSCAN:
buf : 	case HERMES_INQ_HOSTSCAN_SYMBOL: {
buf : 		/* Result of a scanning. Contains information about
formation about 
buf : 		 * cells in the vicinity - Jean II */
buf : 		unsigned char *buf;
buf : 
buf : 		/* Sanity check */
buf : 		if (len > 4096) {
if (len > 4096) { 
buf : 			printk(KERN_WARNING "%s: Scan results too large (%d bytes)\n",
buf : 			       dev->name, len);
buf : 			qabort_scan(priv);
buf : 			break;
buf : 		}
buf : 
buf : 		/* Allocate buffer for results */
for results */ 
buf : 		buf = kmalloc(len, GFP_ATOMIC);
buf : 		if (buf == NULL) {
if (buf == NULL) { 
buf : 			/* No memory, so can't printk()... */
buf : 			qabort_scan(priv);
buf : 			break;
buf : 		}
buf : 
buf : 		/* Read scan data */
buf : 		err = hw->ops->bap_pread(hw, IRQ_BAP, (void *) buf, len,
buf : 					 infofid, sizeof(info));
buf : 		if (err) {
if (err) { 
buf : 			kfree(buf);
buf : 			qabort_scan(priv);
buf : 			break;
buf : 		}
buf : 
buf : #ifdef ORINOCO_DEBUG
ifdef ORINOCO_DEBUG 
buf : 		{
buf : 			int	i;
buf : 			printk(KERN_DEBUG "Scan result [%02X", buf[0]);
buf : 			for (i = 1; i < (len * 2); i++)
for (i = 1; i < (len * 2); i++) 
buf : 				printk(":%02X", buf[i]);
buf : 			printk("]\n");
buf : 		}
buf : #endif	/* ORINOCO_DEBUG */
if	/* ORINOCO_DEBUG */ 
buf : 
buf : 		qbuf_scan(priv, buf, len, type);
buf : 	}
buf : 	break;
buf : 	case HERMES_INQ_CHANNELINFO:
buf : 	{
buf : 		struct agere_ext_scan_info *bss;
buf : 
buf : 		if (!priv->scan_request) {
if (!priv->scan_request) { 
buf : 			printk(KERN_DEBUG "%s: Got chaninfo without scan, "
buf : 			       "len=%d\n", dev->name, len);
buf : 			break;
buf : 		}
buf : 
buf : 		/* An empty result indicates that the scan is complete */
buf : 		if (len == 0) {
if (len == 0) { 
buf : 			qbuf_scan(priv, NULL, len, type);
buf : 			break;
buf : 		}
buf : 
buf : 		/* Sanity check */
buf : 		else if (len < (offsetof(struct agere_ext_scan_info,
if (len < (offsetof(struct agere_ext_scan_info, 
buf : 					   data) + 2)) {
buf : 			/* Drop this result now so we don't have to
buf : 			 * keep checking later */
buf : 			printk(KERN_WARNING
buf : 			       "%s: Ext scan results too short (%d bytes)\n",
buf : 			       dev->name, len);
buf : 			break;
buf : 		}
buf : 
buf : 		bss = kmalloc(len, GFP_ATOMIC);
buf : 		if (bss == NULL)
if (bss == NULL) 
buf : 			break;
buf : 
buf : 		/* Read scan data */
buf : 		err = hw->ops->bap_pread(hw, IRQ_BAP, (void *) bss, len,
buf : 					 infofid, sizeof(info));
buf : 		if (err)
if (err) 
buf : 			kfree(bss);
buf : 		else
buf : 			qbuf_scan(priv, bss, len, type);
buf : 
buf : 		break;
buf : 	}
buf : 	case HERMES_INQ_SEC_STAT_AGERE:
buf : 		/* Security status (Agere specific) */
ific) */ 
buf : 		/* Ignore this frame for now */
for now */ 
buf : 		if (priv->firmware_type == FIRMWARE_TYPE_AGERE)
buf : 			break;
buf : 		/* fall through */
buf : 	default:
buf : 		printk(KERN_DEBUG "%s: Unknown information frame received: "
formation frame received: " 
buf : 		       "type 0x%04x, length %d\n", dev->name, type, len);
buf : 		/* We don't actually do anything about it */
buf : 		break;
buf : 	}
buf : }
buf : EXPORT_SYMBOL(__orinoco_ev_info);
buf : 
buf : static void __orinoco_ev_infdrop(struct net_device *dev, struct hermes *hw)
buf : {
buf : 	if (net_ratelimit())
if (net_ratelimit()) 
buf : 		printk(KERN_DEBUG "%s: Information frame lost.\n", dev->name);
formation frame lost.\n", dev->name); 
buf : }
buf : 
buf : /********************************************************************/
buf : /* Internal hardware control routines                               */
buf : /********************************************************************/
buf : 
buf : static int __orinoco_up(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct hermes *hw = &priv->hw;
buf : 	int err;
buf : 
buf : 	netif_carrier_off(dev); /* just to make sure */
if_carrier_off(dev); /* just to make sure */ 
buf : 
buf : 	err = __orinoco_commit(priv);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_ERR "%s: Error %d configuring card\n",
buf : 		       dev->name, err);
buf : 		return err;
buf : 	}
buf : 
buf : 	/* Fire things up again */
buf : 	hermes_set_irqmask(hw, ORINOCO_INTEN);
buf : 	err = hermes_enable_port(hw, 0);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_ERR "%s: Error %d enabling MAC port\n",
buf : 		       dev->name, err);
buf : 		return err;
buf : 	}
buf : 
buf : 	netif_start_queue(dev);
if_start_queue(dev); 
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int __orinoco_down(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct hermes *hw = &priv->hw;
buf : 	int err;
buf : 
buf : 	netif_stop_queue(dev);
if_stop_queue(dev); 
buf : 
buf : 	if (!priv->hw_unavailable) {
buf : 		if (!priv->broken_disableport) {
if (!priv->broken_disableport) { 
buf : 			err = hermes_disable_port(hw, 0);
buf : 			if (err) {
if (err) { 
buf : 				/* Some firmwares (e.g. Intersil 1.3.x) seem
buf : 				 * to have problems disabling the port, oh
buf : 				 * well, too bad. */
buf : 				printk(KERN_WARNING "%s: Error %d disabling MAC port\n",
buf : 				       dev->name, err);
buf : 				priv->broken_disableport = 1;
buf : 			}
buf : 		}
buf : 		hermes_set_irqmask(hw, 0);
buf : 		hermes_write_regn(hw, EVACK, 0xffff);
buf : 	}
buf : 
buf : 	orinoco_scan_done(priv, true);
buf : 
buf : 	/* firmware will have to reassociate */
buf : 	netif_carrier_off(dev);
if_carrier_off(dev); 
buf : 	priv->last_linkstatus = 0xffff;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int orinoco_reinit_firmware(struct orinoco_private *priv)
buf : {
buf : 	struct hermes *hw = &priv->hw;
buf : 	int err;
buf : 
buf : 	err = hw->ops->init(hw);
buf : 	if (priv->do_fw_download && !err) {
if (priv->do_fw_download && !err) { 
buf : 		err = orinoco_download(priv);
buf : 		if (err)
if (err) 
buf : 			priv->do_fw_download = 0;
buf : 	}
buf : 	if (!err)
if (!err) 
buf : 		err = orinoco_hw_allocate_fid(priv);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int
buf : __orinoco_set_multicast_list(struct net_device *dev)
buf : {
buf : 	struct orinoco_private *priv = ndev_priv(dev);
buf : 	int err = 0;
buf : 	int promisc, mc_count;
buf : 
buf : 	/* The Hermes doesn't seem to have an allmulti mode, so we go
buf : 	 * into promiscuous mode and let the upper levels deal. */
buf : 	if ((dev->flags & IFF_PROMISC) || (dev->flags & IFF_ALLMULTI) ||
if ((dev->flags & IFF_PROMISC) || (dev->flags & IFF_ALLMULTI) || 
buf : 	    (netdev_mc_count(dev) > MAX_MULTICAST(priv))) {
buf : 		promisc = 1;
buf : 		mc_count = 0;
buf : 	} else {
buf : 		promisc = 0;
buf : 		mc_count = netdev_mc_count(dev);
buf : 	}
buf : 
buf : 	err = __orinoco_hw_set_multicast_list(priv, dev, mc_count, promisc);
buf : 
buf : 	return err;
buf : }
buf : 
buf : /* This must be called from user context, without locks held - use
buf :  * schedule_work() */
buf : void orinoco_reset(struct work_struct *work)
buf : {
buf : 	struct orinoco_private *priv =
buf : 		container_of(work, struct orinoco_private, reset_work);
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct hermes *hw = &priv->hw;
buf : 	int err;
buf : 	unsigned long flags;
buf : 
buf : 	if (orinoco_lock(priv, &flags) != 0)
if (orinoco_lock(priv, &flags) != 0) 
buf : 		/* When the hardware becomes available again, whatever
buf : 		 * detects that is responsible for re-initializing
for re-initializing 
buf : 		 * it. So no need for anything further */
buf : 		return;
buf : 
buf : 	netif_stop_queue(dev);
if_stop_queue(dev); 
buf : 
buf : 	/* Shut off interrupts.  Depending on what state the hardware
buf : 	 * is in, this might not work, but we'll try anyway */
buf : 	hermes_set_irqmask(hw, 0);
buf : 	hermes_write_regn(hw, EVACK, 0xffff);
buf : 
buf : 	priv->hw_unavailable++;
buf : 	priv->last_linkstatus = 0xffff; /* firmware will have to reassociate */
buf : 	netif_carrier_off(dev);
if_carrier_off(dev); 
buf : 
buf : 	orinoco_unlock(priv, &flags);
buf : 
buf : 	/* Scanning support: Notify scan cancellation */
ify scan cancellation */ 
buf : 	orinoco_scan_done(priv, true);
buf : 
buf : 	if (priv->hard_reset) {
if (priv->hard_reset) { 
buf : 		err = (*priv->hard_reset)(priv);
buf : 		if (err) {
if (err) { 
buf : 			printk(KERN_ERR "%s: orinoco_reset: Error %d "
buf : 			       "performing hard reset\n", dev->name, err);
forming hard reset\n", dev->name, err); 
buf : 			goto disable;
buf : 		}
buf : 	}
buf : 
buf : 	err = orinoco_reinit_firmware(priv);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_ERR "%s: orinoco_reset: Error %d re-initializing firmware\n",
buf : 		       dev->name, err);
buf : 		goto disable;
buf : 	}
buf : 
buf : 	/* This has to be called from user context */
buf : 	orinoco_lock_irq(priv);
buf : 
buf : 	priv->hw_unavailable--;
buf : 
buf : 	/* priv->open or priv->hw_unavailable might have changed while
while 
buf : 	 * we dropped the lock */
buf : 	if (priv->open && (!priv->hw_unavailable)) {
if (priv->open && (!priv->hw_unavailable)) { 
buf : 		err = __orinoco_up(priv);
buf : 		if (err) {
if (err) { 
buf : 			printk(KERN_ERR "%s: orinoco_reset: Error %d reenabling card\n",
buf : 			       dev->name, err);
buf : 		} else
buf : 			dev->trans_start = jiffies;
iffies; 
buf : 	}
buf : 
buf : 	orinoco_unlock_irq(priv);
buf : 
buf : 	return;
buf :  disable:
buf : 	hermes_set_irqmask(hw, 0);
buf : 	netif_device_detach(dev);
if_device_detach(dev); 
buf : 	printk(KERN_ERR "%s: Device has been disabled!\n", dev->name);
buf : }
buf : 
buf : static int __orinoco_commit(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 	int err = 0;
buf : 
buf : 	/* If we've called commit, we are reconfiguring or bringing the
buf : 	 * interface up. Maintaining countermeasures across this would
buf : 	 * be confusing, so note that we've disabled them. The port will
buf : 	 * be enabled later in orinoco_commit or __orinoco_up. */
buf : 	priv->tkip_cm_active = 0;
buf : 
buf : 	err = orinoco_hw_program_rids(priv);
buf : 
buf : 	/* FIXME: what about netif_tx_lock */
if_tx_lock */ 
buf : 	(void) __orinoco_set_multicast_list(dev);
buf : 
buf : 	return err;
buf : }
buf : 
buf : /* Ensures configuration changes are applied. May result in a reset.
buf :  * The caller should hold priv->lock
buf :  */
buf : int orinoco_commit(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct hermes *hw = &priv->hw;
buf : 	int err;
buf : 
buf : 	if (priv->broken_disableport) {
if (priv->broken_disableport) { 
buf : 		schedule_work(&priv->reset_work);
buf : 		return 0;
buf : 	}
buf : 
buf : 	err = hermes_disable_port(hw, 0);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_WARNING "%s: Unable to disable port "
buf : 		       "while reconfiguring card\n", dev->name);
while reconfiguring card\n", dev->name); 
buf : 		priv->broken_disableport = 1;
buf : 		goto out;
buf : 	}
buf : 
buf : 	err = __orinoco_commit(priv);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_WARNING "%s: Unable to reconfigure card\n",
buf : 		       dev->name);
buf : 		goto out;
buf : 	}
buf : 
buf : 	err = hermes_enable_port(hw, 0);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_WARNING "%s: Unable to enable port while reconfiguring card\n",
while reconfiguring card\n", 
buf : 		       dev->name);
buf : 		goto out;
buf : 	}
buf : 
buf :  out:
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_WARNING "%s: Resetting instead...\n", dev->name);
buf : 		schedule_work(&priv->reset_work);
buf : 		err = 0;
buf : 	}
buf : 	return err;
buf : }
buf : 
buf : /********************************************************************/
buf : /* Interrupt handler                                                */
buf : /********************************************************************/
buf : 
buf : static void __orinoco_ev_tick(struct net_device *dev, struct hermes *hw)
buf : {
buf : 	printk(KERN_DEBUG "%s: TICK\n", dev->name);
buf : }
buf : 
buf : static void __orinoco_ev_wterr(struct net_device *dev, struct hermes *hw)
buf : {
buf : 	/* This seems to happen a fair bit under load, but ignoring it
buf : 	   seems to work fine...*/
buf : 	printk(KERN_DEBUG "%s: MAC controller error (WTERR). Ignoring.\n",
buf : 	       dev->name);
buf : }
buf : 
buf : irqreturn_t orinoco_interrupt(int irq, void *dev_id)
buf : {
buf : 	struct orinoco_private *priv = dev_id;
buf : 	struct net_device *dev = priv->ndev;
buf : 	struct hermes *hw = &priv->hw;
buf : 	int count = MAX_IRQLOOPS_PER_IRQ;
buf : 	u16 evstat, events;
buf : 	/* These are used to detect a runaway interrupt situation.
buf : 	 *
buf : 	 * If we get more than MAX_IRQLOOPS_PER_JIFFY iterations in a jiffy,
iffy, 
buf : 	 * we panic and shut down the hardware
buf : 	 */
buf : 	/* jiffies value the last time we were called */
iffies value the last time we were called */ 
buf : 	static int last_irq_jiffy; /* = 0 */
buf : 	static int loops_this_jiffy; /* = 0 */
iffy; /* = 0 */ 
buf : 	unsigned long flags;
buf : 
buf : 	if (orinoco_lock(priv, &flags) != 0) {
if (orinoco_lock(priv, &flags) != 0) { 
buf : 		/* If hw is unavailable - we don't know if the irq was
buf : 		 * for us or not */
for us or not */ 
buf : 		return IRQ_HANDLED;
buf : 	}
buf : 
buf : 	evstat = hermes_read_regn(hw, EVSTAT);
buf : 	events = evstat & hw->inten;
buf : 	if (!events) {
if (!events) { 
buf : 		orinoco_unlock(priv, &flags);
buf : 		return IRQ_NONE;
buf : 	}
buf : 
buf : 	if (jiffies != last_irq_jiffy)
if (jiffies != last_irq_jiffy) 
buf : 		loops_this_jiffy = 0;
buf : 	last_irq_jiffy = jiffies;
iffy = jiffies; 
buf : 
buf : 	while (events && count--) {
while (events && count--) { 
buf : 		if (++loops_this_jiffy > MAX_IRQLOOPS_PER_JIFFY) {
buf : 			printk(KERN_WARNING "%s: IRQ handler is looping too "
buf : 			       "much! Resetting.\n", dev->name);
buf : 			/* Disable interrupts for now */
for now */ 
buf : 			hermes_set_irqmask(hw, 0);
buf : 			schedule_work(&priv->reset_work);
buf : 			break;
buf : 		}
buf : 
buf : 		/* Check the card hasn't been removed */
buf : 		if (!hermes_present(hw)) {
if (!hermes_present(hw)) { 
buf : 			DEBUG(0, "orinoco_interrupt(): card removed\n");
buf : 			break;
buf : 		}
buf : 
buf : 		if (events & HERMES_EV_TICK)
if (events & HERMES_EV_TICK) 
buf : 			__orinoco_ev_tick(dev, hw);
buf : 		if (events & HERMES_EV_WTERR)
if (events & HERMES_EV_WTERR) 
buf : 			__orinoco_ev_wterr(dev, hw);
buf : 		if (events & HERMES_EV_INFDROP)
if (events & HERMES_EV_INFDROP) 
buf : 			__orinoco_ev_infdrop(dev, hw);
buf : 		if (events & HERMES_EV_INFO)
if (events & HERMES_EV_INFO) 
buf : 			__orinoco_ev_info(dev, hw);
buf : 		if (events & HERMES_EV_RX)
if (events & HERMES_EV_RX) 
buf : 			__orinoco_ev_rx(dev, hw);
buf : 		if (events & HERMES_EV_TXEXC)
if (events & HERMES_EV_TXEXC) 
buf : 			__orinoco_ev_txexc(dev, hw);
buf : 		if (events & HERMES_EV_TX)
if (events & HERMES_EV_TX) 
buf : 			__orinoco_ev_tx(dev, hw);
buf : 		if (events & HERMES_EV_ALLOC)
if (events & HERMES_EV_ALLOC) 
buf : 			__orinoco_ev_alloc(dev, hw);
buf : 
buf : 		hermes_write_regn(hw, EVACK, evstat);
buf : 
buf : 		evstat = hermes_read_regn(hw, EVSTAT);
buf : 		events = evstat & hw->inten;
buf : 	}
buf : 
buf : 	orinoco_unlock(priv, &flags);
buf : 	return IRQ_HANDLED;
buf : }
buf : EXPORT_SYMBOL(orinoco_interrupt);
buf : 
buf : /********************************************************************/
buf : /* Power management                                                 */
buf : /********************************************************************/
buf : #if defined(CONFIG_PM_SLEEP) && !defined(CONFIG_HERMES_CACHE_FW_ON_INIT)
if defined(CONFIG_PM_SLEEP) && !defined(CONFIG_HERMES_CACHE_FW_ON_INIT) 
buf : static int orinoco_pm_notifier(struct notifier_block *notifier,
buf : 			       unsigned long pm_event,
buf : 			       void *unused)
buf : {
buf : 	struct orinoco_private *priv = container_of(notifier,
ifier, 
buf : 						    struct orinoco_private,
buf : 						    pm_notifier);
ifier); 
buf : 
buf : 	/* All we need to do is cache the firmware before suspend, and
fore suspend, and 
buf : 	 * release it when we come out.
buf : 	 *
buf : 	 * Only need to do this if we're downloading firmware. */
if we're downloading firmware. */ 
buf : 	if (!priv->do_fw_download)
buf : 		return NOTIFY_DONE;
buf : 
buf : 	switch (pm_event) {
buf : 	case PM_HIBERNATION_PREPARE:
buf : 	case PM_SUSPEND_PREPARE:
buf : 		orinoco_cache_fw(priv, 0);
buf : 		break;
buf : 
buf : 	case PM_POST_RESTORE:
buf : 		/* Restore from hibernation failed. We need to clean
buf : 		 * up in exactly the same way, so fall through. */
buf : 	case PM_POST_HIBERNATION:
buf : 	case PM_POST_SUSPEND:
buf : 		orinoco_uncache_fw(priv);
buf : 		break;
buf : 
buf : 	case PM_RESTORE_PREPARE:
buf : 	default:
buf : 		break;
buf : 	}
buf : 
buf : 	return NOTIFY_DONE;
buf : }
buf : 
buf : static void orinoco_register_pm_notifier(struct orinoco_private *priv)
ifier(struct orinoco_private *priv) 
buf : {
buf : 	priv->pm_notifier.notifier_call = orinoco_pm_notifier;
buf : 	register_pm_notifier(&priv->pm_notifier);
ifier(&priv->pm_notifier); 
buf : }
buf : 
buf : static void orinoco_unregister_pm_notifier(struct orinoco_private *priv)
buf : {
buf : 	unregister_pm_notifier(&priv->pm_notifier);
ifier(&priv->pm_notifier); 
buf : }
buf : #else /* !PM_SLEEP || HERMES_CACHE_FW_ON_INIT */
buf : #define orinoco_register_pm_notifier(priv) do { } while (0)
ifier(priv) do { } while (0) 
buf : #define orinoco_unregister_pm_notifier(priv) do { } while (0)
while (0) 
buf : #endif
buf : 
buf : /********************************************************************/
buf : /* Initialization                                                   */
buf : /********************************************************************/
buf : 
buf : int orinoco_init(struct orinoco_private *priv)
buf : {
buf : 	struct device *dev = priv->dev;
buf : 	struct wiphy *wiphy = priv_to_wiphy(priv);
buf : 	struct hermes *hw = &priv->hw;
buf : 	int err = 0;
buf : 
buf : 	/* No need to lock, the hw_unavailable flag is already set in
buf : 	 * alloc_orinocodev() */
buf : 	priv->nicbuf_size = IEEE80211_MAX_FRAME_LEN + ETH_HLEN;
buf : 
buf : 	/* Initialize the firmware */
buf : 	err = hw->ops->init(hw);
buf : 	if (err != 0) {
if (err != 0) { 
buf : 		dev_err(dev, "Failed to initialize firmware (err = %d)\n",
buf : 			err);
buf : 		goto out;
buf : 	}
buf : 
buf : 	err = determine_fw_capabilities(priv, wiphy->fw_version,
buf : 					sizeof(wiphy->fw_version),
buf : 					&wiphy->hw_version);
buf : 	if (err != 0) {
if (err != 0) { 
buf : 		dev_err(dev, "Incompatible firmware, aborting\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (priv->do_fw_download) {
if (priv->do_fw_download) { 
buf : #ifdef CONFIG_HERMES_CACHE_FW_ON_INIT
buf : 		orinoco_cache_fw(priv, 0);
buf : #endif
if 
buf : 
buf : 		err = orinoco_download(priv);
buf : 		if (err)
if (err) 
buf : 			priv->do_fw_download = 0;
buf : 
buf : 		/* Check firmware version again */
buf : 		err = determine_fw_capabilities(priv, wiphy->fw_version,
buf : 						sizeof(wiphy->fw_version),
buf : 						&wiphy->hw_version);
buf : 		if (err != 0) {
if (err != 0) { 
buf : 			dev_err(dev, "Incompatible firmware, aborting\n");
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : 	if (priv->has_port3)
if (priv->has_port3) 
buf : 		dev_info(dev, "Ad-hoc demo mode supported\n");
buf : 	if (priv->has_ibss)
if (priv->has_ibss) 
buf : 		dev_info(dev, "IEEE standard IBSS ad-hoc mode supported\n");
buf : 	if (priv->has_wep)
if (priv->has_wep) 
buf : 		dev_info(dev, "WEP supported, %s-bit key\n",
buf : 			 priv->has_big_wep ? "104" : "40");
buf : 	if (priv->has_wpa) {
if (priv->has_wpa) { 
buf : 		dev_info(dev, "WPA-PSK supported\n");
buf : 		if (orinoco_mic_init(priv)) {
if (orinoco_mic_init(priv)) { 
buf : 			dev_err(dev, "Failed to setup MIC crypto algorithm. "
buf : 				"Disabling WPA support\n");
buf : 			priv->has_wpa = 0;
buf : 		}
buf : 	}
buf : 
buf : 	err = orinoco_hw_read_card_settings(priv, wiphy->perm_addr);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	err = orinoco_hw_allocate_fid(priv);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(dev, "Failed to allocate NIC buffer!\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	/* Set up the default configuration */
buf : 	priv->iw_mode = NL80211_IFTYPE_STATION;
buf : 	/* By default use IEEE/IBSS ad-hoc mode if we have it */
if we have it */ 
buf : 	priv->prefer_port3 = priv->has_port3 && (!priv->has_ibss);
buf : 	set_port_type(priv);
buf : 	priv->channel = 0; /* use firmware default */
buf : 
buf : 	priv->promiscuous = 0;
buf : 	priv->encode_alg = ORINOCO_ALG_NONE;
buf : 	priv->tx_key = 0;
buf : 	priv->wpa_enabled = 0;
buf : 	priv->tkip_cm_active = 0;
buf : 	priv->key_mgmt = 0;
buf : 	priv->wpa_ie_len = 0;
buf : 	priv->wpa_ie = NULL;
buf : 
buf : 	if (orinoco_wiphy_register(wiphy)) {
if (orinoco_wiphy_register(wiphy)) { 
buf : 		err = -ENODEV;
buf : 		goto out;
buf : 	}
buf : 
buf : 	/* Make the hardware available, as long as it hasn't been
buf : 	 * removed elsewhere (e.g. by PCMCIA hot unplug) */
buf : 	orinoco_lock_irq(priv);
buf : 	priv->hw_unavailable--;
buf : 	orinoco_unlock_irq(priv);
buf : 
buf : 	dev_dbg(dev, "Ready\n");
buf : 
buf :  out:
buf : 	return err;
buf : }
buf : EXPORT_SYMBOL(orinoco_init);
buf : 
buf : static const struct net_device_ops orinoco_netdev_ops = {
buf : 	.ndo_open		= orinoco_open,
buf : 	.ndo_stop		= orinoco_stop,
buf : 	.ndo_start_xmit		= orinoco_xmit,
buf : 	.ndo_set_rx_mode	= orinoco_set_multicast_list,
buf : 	.ndo_change_mtu		= orinoco_change_mtu,
buf : 	.ndo_set_mac_address	= eth_mac_addr,
buf : 	.ndo_validate_addr	= eth_validate_addr,
buf : 	.ndo_tx_timeout		= orinoco_tx_timeout,
buf : 	.ndo_get_stats		= orinoco_get_stats,
buf : };
buf : 
buf : /* Allocate private data.
buf :  *
buf :  * This driver has a number of structures associated with it
buf :  *  netdev - Net device structure for each network interface
for each network interface 
buf :  *  wiphy - structure associated with wireless phy
buf :  *  wireless_dev (wdev) - structure for each wireless interface
for each wireless interface 
buf :  *  hw - structure for hermes chip info
buf :  *  card - card specific structure for use by the card driver
ific structure for use by the card driver 
buf :  *         (airport, orinoco_cs)
buf :  *  priv - orinoco private data
buf :  *  device - generic linux device structure
buf :  *
buf :  *  +---------+    +---------+
buf :  *  |  wiphy  |    | netdev  |
buf :  *  | +-------+    | +-------+
buf :  *  | | priv  |    | | wdev  |
buf :  *  | | +-----+    +-+-------+
buf :  *  | | | hw  |
buf :  *  | +-+-----+
buf :  *  | | card  |
buf :  *  +-+-------+
buf :  *
buf :  * priv has a link to netdev and device
buf :  * wdev has a link to wiphy
buf :  */
buf : struct orinoco_private
buf : *alloc_orinocodev(int sizeof_card,
buf : 		  struct device *device,
buf : 		  int (*hard_reset)(struct orinoco_private *),
buf : 		  int (*stop_fw)(struct orinoco_private *, int))
buf : {
buf : 	struct orinoco_private *priv;
buf : 	struct wiphy *wiphy;
buf : 
buf : 	/* allocate wiphy
buf : 	 * NOTE: We only support a single virtual interface
buf : 	 *       but this may change when monitor mode is added
buf : 	 */
buf : 	wiphy = wiphy_new(&orinoco_cfg_ops,
buf : 			  sizeof(struct orinoco_private) + sizeof_card);
buf : 	if (!wiphy)
if (!wiphy) 
buf : 		return NULL;
buf : 
buf : 	priv = wiphy_priv(wiphy);
buf : 	priv->dev = device;
buf : 
buf : 	if (sizeof_card)
if (sizeof_card) 
buf : 		priv->card = (void *)((unsigned long)priv
buf : 				      + sizeof(struct orinoco_private));
buf : 	else
buf : 		priv->card = NULL;
buf : 
buf : 	orinoco_wiphy_init(wiphy);
buf : 
buf : #ifdef WIRELESS_SPY
ifdef WIRELESS_SPY 
buf : 	priv->wireless_data.spy_data = &priv->spy_data;
buf : #endif
if 
buf : 
buf : 	/* Set up default callbacks */
buf : 	priv->hard_reset = hard_reset;
buf : 	priv->stop_fw = stop_fw;
buf : 
buf : 	spin_lock_init(&priv->lock);
buf : 	priv->open = 0;
buf : 	priv->hw_unavailable = 1; /* orinoco_init() must clear this
buf : 				   * before anything else touches the
fore anything else touches the 
buf : 				   * hardware */
buf : 	INIT_WORK(&priv->reset_work, orinoco_reset);
buf : 	INIT_WORK(&priv->join_work, orinoco_join_ap);
buf : 	INIT_WORK(&priv->wevent_work, orinoco_send_wevents);
buf : 
buf : 	INIT_LIST_HEAD(&priv->rx_list);
buf : 	tasklet_init(&priv->rx_tasklet, orinoco_rx_isr_tasklet,
buf : 		     (unsigned long) priv);
buf : 
buf : 	spin_lock_init(&priv->scan_lock);
buf : 	INIT_LIST_HEAD(&priv->scan_list);
buf : 	INIT_WORK(&priv->process_scan, orinoco_process_scan_results);
buf : 
buf : 	priv->last_linkstatus = 0xffff;
buf : 
buf : #if defined(CONFIG_HERMES_CACHE_FW_ON_INIT) || defined(CONFIG_PM_SLEEP)
if defined(CONFIG_HERMES_CACHE_FW_ON_INIT) || defined(CONFIG_PM_SLEEP) 
buf : 	priv->cached_pri_fw = NULL;
buf : 	priv->cached_fw = NULL;
buf : #endif
if 
buf : 
buf : 	/* Register PM notifiers */
buf : 	orinoco_register_pm_notifier(priv);
ifier(priv); 
buf : 
buf : 	return priv;
buf : }
buf : EXPORT_SYMBOL(alloc_orinocodev);
buf : 
buf : /* We can only support a single interface. We provide a separate
buf :  * function to set it up to distinguish between hardware
buf :  * initialisation and interface setup.
buf :  *
buf :  * The base_addr and irq parameters are passed on to netdev for use
for use 
buf :  * with SIOCGIFMAP.
buf :  */
buf : int orinoco_if_add(struct orinoco_private *priv,
if_add(struct orinoco_private *priv, 
buf : 		   unsigned long base_addr,
buf : 		   unsigned int irq,
buf : 		   const struct net_device_ops *ops)
buf : {
buf : 	struct wiphy *wiphy = priv_to_wiphy(priv);
buf : 	struct wireless_dev *wdev;
buf : 	struct net_device *dev;
buf : 	int ret;
buf : 
buf : 	dev = alloc_etherdev(sizeof(struct wireless_dev));
buf : 
buf : 	if (!dev)
if (!dev) 
buf : 		return -ENOMEM;
buf : 
buf : 	/* Initialise wireless_dev */
buf : 	wdev = netdev_priv(dev);
buf : 	wdev->wiphy = wiphy;
buf : 	wdev->iftype = NL80211_IFTYPE_STATION;
iftype = NL80211_IFTYPE_STATION; 
buf : 
buf : 	/* Setup / override net_device fields */
buf : 	dev->ieee80211_ptr = wdev;
buf : 	dev->watchdog_timeo = HZ; /* 1 second timeout */
buf : 	dev->wireless_handlers = &orinoco_handler_def;
buf : #ifdef WIRELESS_SPY
ifdef WIRELESS_SPY 
buf : 	dev->wireless_data = &priv->wireless_data;
buf : #endif
if 
buf : 	/* Default to standard ops if not set */
buf : 	if (ops)
if (ops) 
buf : 		dev->netdev_ops = ops;
buf : 	else
buf : 		dev->netdev_ops = &orinoco_netdev_ops;
buf : 
buf : 	/* we use the default eth_mac_addr for setting the MAC addr */
for setting the MAC addr */ 
buf : 
buf : 	/* Reserve space in skb for the SNAP header */
buf : 	dev->needed_headroom = ENCAPS_OVERHEAD;
buf : 
buf : 	netif_carrier_off(dev);
if_carrier_off(dev); 
buf : 
buf : 	memcpy(dev->dev_addr, wiphy->perm_addr, ETH_ALEN);
buf : 
buf : 	dev->base_addr = base_addr;
buf : 	dev->irq = irq;
buf : 
buf : 	SET_NETDEV_DEV(dev, priv->dev);
buf : 	ret = register_netdev(dev);
buf : 	if (ret)
if (ret) 
buf : 		goto fail;
buf : 
buf : 	priv->ndev = dev;
buf : 
buf : 	/* Report what we've done */
buf : 	dev_dbg(priv->dev, "Registerred interface %s.\n", dev->name);
buf : 
buf : 	return 0;
buf : 
buf :  fail:
buf : 	free_netdev(dev);
buf : 	return ret;
buf : }
buf : EXPORT_SYMBOL(orinoco_if_add);
if_add); 
buf : 
buf : void orinoco_if_del(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 
buf : 	unregister_netdev(dev);
buf : 	free_netdev(dev);
buf : }
buf : EXPORT_SYMBOL(orinoco_if_del);
if_del); 
buf : 
buf : void free_orinocodev(struct orinoco_private *priv)
buf : {
buf : 	struct wiphy *wiphy = priv_to_wiphy(priv);
buf : 	struct orinoco_rx_data *rx_data, *temp;
buf : 	struct orinoco_scan_data *sd, *sdtemp;
buf : 
buf : 	wiphy_unregister(wiphy);
buf : 
buf : 	/* If the tasklet is scheduled when we call tasklet_kill it
buf : 	 * will run one final time. However the tasklet will only
buf : 	 * drain priv->rx_list if the hw is still available. */
if the hw is still available. */ 
buf : 	tasklet_kill(&priv->rx_tasklet);
buf : 
buf : 	/* Explicitly drain priv->rx_list */
buf : 	list_for_each_entry_safe(rx_data, temp, &priv->rx_list, list) {
for_each_entry_safe(rx_data, temp, &priv->rx_list, list) { 
buf : 		list_del(&rx_data->list);
buf : 
buf : 		dev_kfree_skb(rx_data->skb);
buf : 		kfree(rx_data->desc);
buf : 		kfree(rx_data);
buf : 	}
buf : 
buf : 	cancel_work_sync(&priv->process_scan);
buf : 	/* Explicitly drain priv->scan_list */
buf : 	list_for_each_entry_safe(sd, sdtemp, &priv->scan_list, list) {
for_each_entry_safe(sd, sdtemp, &priv->scan_list, list) { 
buf : 		list_del(&sd->list);
buf : 
buf : 		if ((sd->len > 0) && sd->buf)
if ((sd->len > 0) && sd->buf) 
buf : 			kfree(sd->buf);
buf : 		kfree(sd);
buf : 	}
buf : 
buf : 	orinoco_unregister_pm_notifier(priv);
ifier(priv); 
buf : 	orinoco_uncache_fw(priv);
buf : 
buf : 	priv->wpa_ie_len = 0;
buf : 	kfree(priv->wpa_ie);
buf : 	orinoco_mic_free(priv);
buf : 	wiphy_free(wiphy);
buf : }
buf : EXPORT_SYMBOL(free_orinocodev);
buf : 
buf : int orinoco_up(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 	unsigned long flags;
buf : 	int err;
buf : 
buf : 	priv->hw.ops->lock_irqsave(&priv->lock, &flags);
buf : 
buf : 	err = orinoco_reinit_firmware(priv);
buf : 	if (err) {
if (err) { 
buf : 		printk(KERN_ERR "%s: Error %d re-initializing firmware\n",
buf : 		       dev->name, err);
buf : 		goto exit;
buf : 	}
buf : 
buf : 	netif_device_attach(dev);
if_device_attach(dev); 
buf : 	priv->hw_unavailable--;
buf : 
buf : 	if (priv->open && !priv->hw_unavailable) {
if (priv->open && !priv->hw_unavailable) { 
buf : 		err = __orinoco_up(priv);
buf : 		if (err)
if (err) 
buf : 			printk(KERN_ERR "%s: Error %d restarting card\n",
buf : 			       dev->name, err);
buf : 	}
buf : 
buf : exit:
buf : 	priv->hw.ops->unlock_irqrestore(&priv->lock, &flags);
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL(orinoco_up);
buf : 
buf : void orinoco_down(struct orinoco_private *priv)
buf : {
buf : 	struct net_device *dev = priv->ndev;
buf : 	unsigned long flags;
buf : 	int err;
buf : 
buf : 	priv->hw.ops->lock_irqsave(&priv->lock, &flags);
buf : 	err = __orinoco_down(priv);
buf : 	if (err)
if (err) 
buf : 		printk(KERN_WARNING "%s: Error %d downing interface\n",
buf : 		       dev->name, err);
buf : 
buf : 	netif_device_detach(dev);
if_device_detach(dev); 
buf : 	priv->hw_unavailable++;
buf : 	priv->hw.ops->unlock_irqrestore(&priv->lock, &flags);
buf : }
buf : EXPORT_SYMBOL(orinoco_down);
buf : 
buf : /********************************************************************/
buf : /* Module initialization                                            */
buf : /********************************************************************/
buf : 
buf : /* Can't be declared "const" or the whole __initdata section will
buf :  * become const */
buf : static char version[] __initdata = DRIVER_NAME " " DRIVER_VERSION
buf : 	" (David Gibson <hermes@gibson.dropbear.id.au>, "
buf : 	"Pavel Roskin <proski@gnu.org>, et al)";
buf : 
buf : static int __init init_orinoco(void)
buf : {
buf : 	printk(KERN_DEBUG "%s\n", version);
buf : 	return 0;
buf : }
buf : 
buf : static void __exit exit_orinoco(void)
buf : {
buf : }
buf : 
buf : module_init(init_orinoco);
buf : module_exit(exit_orinoco);
file : ./test/kernel/drivers/net/wireless/cw1200/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * mac80211 glue code for mac80211 ST-Ericsson CW1200 drivers
for mac80211 ST-Ericsson CW1200 drivers 
buf :  *
buf :  * Copyright (c) 2010, ST-Ericsson
buf :  * Author: Dmitry Tarnyagin <dmitry.tarnyagin@lockless.no>
buf :  *
buf :  * Based on:
buf :  * Copyright (c) 2006, Michael Wu <flamingice@sourmilk.net>
buf :  * Copyright (c) 2007-2009, Christian Lamparter <chunkeey@web.de>
buf :  * Copyright 2008, Johannes Berg <johannes@sipsolutions.net>
buf :  *
buf :  * Based on:
buf :  * - the islsm (softmac prism54) driver, which is:
buf :  *   Copyright 2004-2006 Jean-Baptiste Note <jbnote@gmail.com>, et al.
buf :  * - stlc45xx driver
buf :  *   Copyright (C) 2008 Nokia Corporation and/or its subsidiary(-ies).
buf :  *
buf :  * This program is free software; you can redistribute it and/or modify
ify 
buf :  * it under the terms of the GNU General Public License version 2 as
buf :  * published by the Free Software Foundation.
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/firmware.h>
buf : #include <linux/etherdevice.h>
buf : #include <linux/vmalloc.h>
buf : #include <linux/random.h>
buf : #include <linux/sched.h>
buf : #include <net/mac80211.h>
buf : 
buf : #include "cw1200.h"
buf : #include "txrx.h"
buf : #include "hwbus.h"
buf : #include "fwio.h"
buf : #include "hwio.h"
buf : #include "bh.h"
buf : #include "sta.h"
buf : #include "scan.h"
buf : #include "debug.h"
buf : #include "pm.h"
buf : 
buf : MODULE_AUTHOR("Dmitry Tarnyagin <dmitry.tarnyagin@lockless.no>");
buf : MODULE_DESCRIPTION("Softmac ST-Ericsson CW1200 common code");
buf : MODULE_LICENSE("GPL");
buf : MODULE_ALIAS("cw1200_core");
buf : 
buf : /* Accept MAC address of the form macaddr=0x00,0x80,0xE1,0x30,0x40,0x50 */
form macaddr=0x00,0x80,0xE1,0x30,0x40,0x50 */ 
buf : static u8 cw1200_mac_template[ETH_ALEN] = {0x02, 0x80, 0xe1, 0x00, 0x00, 0x00};
buf : module_param_array_named(macaddr, cw1200_mac_template, byte, NULL, S_IRUGO);
buf : MODULE_PARM_DESC(macaddr, "Override platform_data MAC address");
form_data MAC address"); 
buf : 
buf : static char *cw1200_sdd_path;
buf : module_param(cw1200_sdd_path, charp, 0644);
buf : MODULE_PARM_DESC(cw1200_sdd_path, "Override platform_data SDD file");
form_data SDD file"); 
buf : static int cw1200_refclk;
buf : module_param(cw1200_refclk, int, 0644);
buf : MODULE_PARM_DESC(cw1200_refclk, "Override platform_data reference clock");
form_data reference clock"); 
buf : 
buf : int cw1200_power_mode = wsm_power_mode_quiescent;
buf : module_param(cw1200_power_mode, int, 0644);
buf : MODULE_PARM_DESC(cw1200_power_mode, "WSM power mode.  0 == active, 1 == doze, 2 == quiescent (default)");
buf : 
buf : #define RATETAB_ENT(_rate, _rateid, _flags)		\
buf : 	{						\
buf : 		.bitrate	= (_rate),		\
buf : 		.hw_value	= (_rateid),		\
buf : 		.flags		= (_flags),		\
buf : 	}
buf : 
buf : static struct ieee80211_rate cw1200_rates[] = {
buf : 	RATETAB_ENT(10,  0,   0),
buf : 	RATETAB_ENT(20,  1,   0),
buf : 	RATETAB_ENT(55,  2,   0),
buf : 	RATETAB_ENT(110, 3,   0),
buf : 	RATETAB_ENT(60,  6,  0),
buf : 	RATETAB_ENT(90,  7,  0),
buf : 	RATETAB_ENT(120, 8,  0),
buf : 	RATETAB_ENT(180, 9,  0),
buf : 	RATETAB_ENT(240, 10, 0),
buf : 	RATETAB_ENT(360, 11, 0),
buf : 	RATETAB_ENT(480, 12, 0),
buf : 	RATETAB_ENT(540, 13, 0),
buf : };
buf : 
buf : static struct ieee80211_rate cw1200_mcs_rates[] = {
buf : 	RATETAB_ENT(65,  14, IEEE80211_TX_RC_MCS),
buf : 	RATETAB_ENT(130, 15, IEEE80211_TX_RC_MCS),
buf : 	RATETAB_ENT(195, 16, IEEE80211_TX_RC_MCS),
buf : 	RATETAB_ENT(260, 17, IEEE80211_TX_RC_MCS),
buf : 	RATETAB_ENT(390, 18, IEEE80211_TX_RC_MCS),
buf : 	RATETAB_ENT(520, 19, IEEE80211_TX_RC_MCS),
buf : 	RATETAB_ENT(585, 20, IEEE80211_TX_RC_MCS),
buf : 	RATETAB_ENT(650, 21, IEEE80211_TX_RC_MCS),
buf : };
buf : 
buf : #define cw1200_a_rates		(cw1200_rates + 4)
buf : #define cw1200_a_rates_size	(ARRAY_SIZE(cw1200_rates) - 4)
buf : #define cw1200_g_rates		(cw1200_rates + 0)
buf : #define cw1200_g_rates_size	(ARRAY_SIZE(cw1200_rates))
buf : #define cw1200_n_rates		(cw1200_mcs_rates)
buf : #define cw1200_n_rates_size	(ARRAY_SIZE(cw1200_mcs_rates))
buf : 
buf : 
buf : #define CHAN2G(_channel, _freq, _flags) {			\
buf : 	.band			= IEEE80211_BAND_2GHZ,		\
buf : 	.center_freq		= (_freq),			\
buf : 	.hw_value		= (_channel),			\
buf : 	.flags			= (_flags),			\
buf : 	.max_antenna_gain	= 0,				\
buf : 	.max_power		= 30,				\
buf : }
buf : 
buf : #define CHAN5G(_channel, _flags) {				\
buf : 	.band			= IEEE80211_BAND_5GHZ,		\
buf : 	.center_freq	= 5000 + (5 * (_channel)),		\
buf : 	.hw_value		= (_channel),			\
buf : 	.flags			= (_flags),			\
buf : 	.max_antenna_gain	= 0,				\
buf : 	.max_power		= 30,				\
buf : }
buf : 
buf : static struct ieee80211_channel cw1200_2ghz_chantable[] = {
buf : 	CHAN2G(1, 2412, 0),
buf : 	CHAN2G(2, 2417, 0),
buf : 	CHAN2G(3, 2422, 0),
buf : 	CHAN2G(4, 2427, 0),
buf : 	CHAN2G(5, 2432, 0),
buf : 	CHAN2G(6, 2437, 0),
buf : 	CHAN2G(7, 2442, 0),
buf : 	CHAN2G(8, 2447, 0),
buf : 	CHAN2G(9, 2452, 0),
buf : 	CHAN2G(10, 2457, 0),
buf : 	CHAN2G(11, 2462, 0),
buf : 	CHAN2G(12, 2467, 0),
buf : 	CHAN2G(13, 2472, 0),
buf : 	CHAN2G(14, 2484, 0),
buf : };
buf : 
buf : static struct ieee80211_channel cw1200_5ghz_chantable[] = {
buf : 	CHAN5G(34, 0),		CHAN5G(36, 0),
buf : 	CHAN5G(38, 0),		CHAN5G(40, 0),
buf : 	CHAN5G(42, 0),		CHAN5G(44, 0),
buf : 	CHAN5G(46, 0),		CHAN5G(48, 0),
buf : 	CHAN5G(52, 0),		CHAN5G(56, 0),
buf : 	CHAN5G(60, 0),		CHAN5G(64, 0),
buf : 	CHAN5G(100, 0),		CHAN5G(104, 0),
buf : 	CHAN5G(108, 0),		CHAN5G(112, 0),
buf : 	CHAN5G(116, 0),		CHAN5G(120, 0),
buf : 	CHAN5G(124, 0),		CHAN5G(128, 0),
buf : 	CHAN5G(132, 0),		CHAN5G(136, 0),
buf : 	CHAN5G(140, 0),		CHAN5G(149, 0),
buf : 	CHAN5G(153, 0),		CHAN5G(157, 0),
buf : 	CHAN5G(161, 0),		CHAN5G(165, 0),
buf : 	CHAN5G(184, 0),		CHAN5G(188, 0),
buf : 	CHAN5G(192, 0),		CHAN5G(196, 0),
buf : 	CHAN5G(200, 0),		CHAN5G(204, 0),
buf : 	CHAN5G(208, 0),		CHAN5G(212, 0),
buf : 	CHAN5G(216, 0),
buf : };
buf : 
buf : static struct ieee80211_supported_band cw1200_band_2ghz = {
buf : 	.channels = cw1200_2ghz_chantable,
buf : 	.n_channels = ARRAY_SIZE(cw1200_2ghz_chantable),
buf : 	.bitrates = cw1200_g_rates,
buf : 	.n_bitrates = cw1200_g_rates_size,
buf : 	.ht_cap = {
buf : 		.cap = IEEE80211_HT_CAP_GRN_FLD |
buf : 			(1 << IEEE80211_HT_CAP_RX_STBC_SHIFT) |
buf : 			IEEE80211_HT_CAP_MAX_AMSDU,
buf : 		.ht_supported = 1,
buf : 		.ampdu_factor = IEEE80211_HT_MAX_AMPDU_8K,
buf : 		.ampdu_density = IEEE80211_HT_MPDU_DENSITY_NONE,
buf : 		.mcs = {
buf : 			.rx_mask[0] = 0xFF,
buf : 			.rx_highest = __cpu_to_le16(0x41),
buf : 			.tx_params = IEEE80211_HT_MCS_TX_DEFINED,
buf : 		},
buf : 	},
buf : };
buf : 
buf : static struct ieee80211_supported_band cw1200_band_5ghz = {
buf : 	.channels = cw1200_5ghz_chantable,
buf : 	.n_channels = ARRAY_SIZE(cw1200_5ghz_chantable),
buf : 	.bitrates = cw1200_a_rates,
buf : 	.n_bitrates = cw1200_a_rates_size,
buf : 	.ht_cap = {
buf : 		.cap = IEEE80211_HT_CAP_GRN_FLD |
buf : 			(1 << IEEE80211_HT_CAP_RX_STBC_SHIFT) |
buf : 			IEEE80211_HT_CAP_MAX_AMSDU,
buf : 		.ht_supported = 1,
buf : 		.ampdu_factor = IEEE80211_HT_MAX_AMPDU_8K,
buf : 		.ampdu_density = IEEE80211_HT_MPDU_DENSITY_NONE,
buf : 		.mcs = {
buf : 			.rx_mask[0] = 0xFF,
buf : 			.rx_highest = __cpu_to_le16(0x41),
buf : 			.tx_params = IEEE80211_HT_MCS_TX_DEFINED,
buf : 		},
buf : 	},
buf : };
buf : 
buf : static const unsigned long cw1200_ttl[] = {
buf : 	1 * HZ,	/* VO */
buf : 	2 * HZ,	/* VI */
buf : 	5 * HZ, /* BE */
buf : 	10 * HZ	/* BK */
buf : };
buf : 
buf : static const struct ieee80211_ops cw1200_ops = {
buf : 	.start			= cw1200_start,
buf : 	.stop			= cw1200_stop,
buf : 	.add_interface		= cw1200_add_interface,
buf : 	.remove_interface	= cw1200_remove_interface,
buf : 	.change_interface	= cw1200_change_interface,
buf : 	.tx			= cw1200_tx,
buf : 	.hw_scan		= cw1200_hw_scan,
buf : 	.set_tim		= cw1200_set_tim,
buf : 	.sta_notify		= cw1200_sta_notify,
ify		= cw1200_sta_notify, 
buf : 	.sta_add		= cw1200_sta_add,
buf : 	.sta_remove		= cw1200_sta_remove,
buf : 	.set_key		= cw1200_set_key,
buf : 	.set_rts_threshold	= cw1200_set_rts_threshold,
buf : 	.config			= cw1200_config,
buf : 	.bss_info_changed	= cw1200_bss_info_changed,
buf : 	.prepare_multicast	= cw1200_prepare_multicast,
buf : 	.configure_filter	= cw1200_configure_filter,
buf : 	.conf_tx		= cw1200_conf_tx,
buf : 	.get_stats		= cw1200_get_stats,
buf : 	.ampdu_action		= cw1200_ampdu_action,
buf : 	.flush			= cw1200_flush,
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 	.suspend		= cw1200_wow_suspend,
buf : 	.resume			= cw1200_wow_resume,
buf : #endif
if 
buf : 	/* Intentionally not offloaded:					*/
buf : 	/*.channel_switch	= cw1200_channel_switch,		*/
buf : 	/*.remain_on_channel	= cw1200_remain_on_channel,		*/
buf : 	/*.cancel_remain_on_channel = cw1200_cancel_remain_on_channel,	*/
buf : };
buf : 
buf : static int cw1200_ba_rx_tids = -1;
buf : static int cw1200_ba_tx_tids = -1;
buf : module_param(cw1200_ba_rx_tids, int, 0644);
buf : module_param(cw1200_ba_tx_tids, int, 0644);
buf : MODULE_PARM_DESC(cw1200_ba_rx_tids, "Block ACK RX TIDs");
buf : MODULE_PARM_DESC(cw1200_ba_tx_tids, "Block ACK TX TIDs");
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : static const struct wiphy_wowlan_support cw1200_wowlan_support = {
buf : 	/* Support only for limited wowlan functionalities */
for limited wowlan functionalities */ 
buf : 	.flags = WIPHY_WOWLAN_ANY | WIPHY_WOWLAN_DISCONNECT,
buf : };
buf : #endif
if 
buf : 
buf : 
buf : static struct ieee80211_hw *cw1200_init_common(const u8 *macaddr,
buf : 						const bool have_5ghz)
buf : {
buf : 	int i, band;
buf : 	struct ieee80211_hw *hw;
buf : 	struct cw1200_common *priv;
buf : 
buf : 	hw = ieee80211_alloc_hw(sizeof(struct cw1200_common), &cw1200_ops);
buf : 	if (!hw)
if (!hw) 
buf : 		return NULL;
buf : 
buf : 	priv = hw->priv;
buf : 	priv->hw = hw;
buf : 	priv->hw_type = -1;
buf : 	priv->mode = NL80211_IFTYPE_UNSPECIFIED;
buf : 	priv->rates = cw1200_rates; /* TODO: fetch from FW */
buf : 	priv->mcs_rates = cw1200_n_rates;
buf : 	if (cw1200_ba_rx_tids != -1)
if (cw1200_ba_rx_tids != -1) 
buf : 		priv->ba_rx_tid_mask = cw1200_ba_rx_tids;
buf : 	else
buf : 		priv->ba_rx_tid_mask = 0xFF; /* Enable RX BLKACK for all TIDs */
for all TIDs */ 
buf : 	if (cw1200_ba_tx_tids != -1)
buf : 		priv->ba_tx_tid_mask = cw1200_ba_tx_tids;
buf : 	else
buf : 		priv->ba_tx_tid_mask = 0xff; /* Enable TX BLKACK for all TIDs */
for all TIDs */ 
buf : 
buf : 	hw->flags = IEEE80211_HW_SIGNAL_DBM |
buf : 		    IEEE80211_HW_SUPPORTS_PS |
buf : 		    IEEE80211_HW_SUPPORTS_DYNAMIC_PS |
buf : 		    IEEE80211_HW_REPORTS_TX_ACK_STATUS |
buf : 		    IEEE80211_HW_SUPPORTS_UAPSD |
buf : 		    IEEE80211_HW_CONNECTION_MONITOR |
buf : 		    IEEE80211_HW_AMPDU_AGGREGATION |
buf : 		    IEEE80211_HW_TX_AMPDU_SETUP_IN_HW |
buf : 		    IEEE80211_HW_NEED_DTIM_BEFORE_ASSOC;
buf : 
buf : 	hw->wiphy->interface_modes = BIT(NL80211_IFTYPE_STATION) |
buf : 					  BIT(NL80211_IFTYPE_ADHOC) |
buf : 					  BIT(NL80211_IFTYPE_AP) |
buf : 					  BIT(NL80211_IFTYPE_MESH_POINT) |
buf : 					  BIT(NL80211_IFTYPE_P2P_CLIENT) |
buf : 					  BIT(NL80211_IFTYPE_P2P_GO);
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 	hw->wiphy->wowlan = &cw1200_wowlan_support;
buf : #endif
if 
buf : 
buf : 	hw->wiphy->flags |= WIPHY_FLAG_AP_UAPSD;
buf : 
buf : 	hw->queues = 4;
buf : 
buf : 	priv->rts_threshold = -1;
buf : 
buf : 	hw->max_rates = 8;
buf : 	hw->max_rate_tries = 15;
buf : 	hw->extra_tx_headroom = WSM_TX_EXTRA_HEADROOM +
buf : 		8;  /* TKIP IV */
buf : 
buf : 	hw->sta_data_size = sizeof(struct cw1200_sta_priv);
buf : 
buf : 	hw->wiphy->bands[IEEE80211_BAND_2GHZ] = &cw1200_band_2ghz;
buf : 	if (have_5ghz)
if (have_5ghz) 
buf : 		hw->wiphy->bands[IEEE80211_BAND_5GHZ] = &cw1200_band_5ghz;
buf : 
buf : 	/* Channel params have to be cleared before registering wiphy again */
fore registering wiphy again */ 
buf : 	for (band = 0; band < IEEE80211_NUM_BANDS; band++) {
buf : 		struct ieee80211_supported_band *sband = hw->wiphy->bands[band];
buf : 		if (!sband)
if (!sband) 
buf : 			continue;
buf : 		for (i = 0; i < sband->n_channels; i++) {
for (i = 0; i < sband->n_channels; i++) { 
buf : 			sband->channels[i].flags = 0;
buf : 			sband->channels[i].max_antenna_gain = 0;
buf : 			sband->channels[i].max_power = 30;
buf : 		}
buf : 	}
buf : 
buf : 	hw->wiphy->max_scan_ssids = 2;
buf : 	hw->wiphy->max_scan_ie_len = IEEE80211_MAX_DATA_LEN;
buf : 
buf : 	if (macaddr)
if (macaddr) 
buf : 		SET_IEEE80211_PERM_ADDR(hw, (u8 *)macaddr);
buf : 	else
buf : 		SET_IEEE80211_PERM_ADDR(hw, cw1200_mac_template);
buf : 
buf : 	/* Fix up mac address if necessary */
if necessary */ 
buf : 	if (hw->wiphy->perm_addr[3] == 0 &&
buf : 	    hw->wiphy->perm_addr[4] == 0 &&
buf : 	    hw->wiphy->perm_addr[5] == 0) {
buf : 		get_random_bytes(&hw->wiphy->perm_addr[3], 3);
buf : 	}
buf : 
buf : 	mutex_init(&priv->wsm_cmd_mux);
buf : 	mutex_init(&priv->conf_mutex);
buf : 	priv->workqueue = create_singlethread_workqueue("cw1200_wq");
buf : 	sema_init(&priv->scan.lock, 1);
buf : 	INIT_WORK(&priv->scan.work, cw1200_scan_work);
buf : 	INIT_DELAYED_WORK(&priv->scan.probe_work, cw1200_probe_work);
buf : 	INIT_DELAYED_WORK(&priv->scan.timeout, cw1200_scan_timeout);
buf : 	INIT_DELAYED_WORK(&priv->clear_recent_scan_work,
buf : 			  cw1200_clear_recent_scan_work);
buf : 	INIT_DELAYED_WORK(&priv->join_timeout, cw1200_join_timeout);
buf : 	INIT_WORK(&priv->unjoin_work, cw1200_unjoin_work);
buf : 	INIT_WORK(&priv->join_complete_work, cw1200_join_complete_work);
buf : 	INIT_WORK(&priv->wep_key_work, cw1200_wep_key_work);
buf : 	INIT_WORK(&priv->tx_policy_upload_work, tx_policy_upload_work);
buf : 	spin_lock_init(&priv->event_queue_lock);
buf : 	INIT_LIST_HEAD(&priv->event_queue);
buf : 	INIT_WORK(&priv->event_handler, cw1200_event_handler);
buf : 	INIT_DELAYED_WORK(&priv->bss_loss_work, cw1200_bss_loss_work);
buf : 	INIT_WORK(&priv->bss_params_work, cw1200_bss_params_work);
buf : 	spin_lock_init(&priv->bss_loss_lock);
buf : 	spin_lock_init(&priv->ps_state_lock);
buf : 	INIT_WORK(&priv->set_cts_work, cw1200_set_cts_work);
buf : 	INIT_WORK(&priv->set_tim_work, cw1200_set_tim_work);
buf : 	INIT_WORK(&priv->multicast_start_work, cw1200_multicast_start_work);
buf : 	INIT_WORK(&priv->multicast_stop_work, cw1200_multicast_stop_work);
buf : 	INIT_WORK(&priv->link_id_work, cw1200_link_id_work);
buf : 	INIT_DELAYED_WORK(&priv->link_id_gc_work, cw1200_link_id_gc_work);
buf : 	INIT_WORK(&priv->linkid_reset_work, cw1200_link_id_reset);
buf : 	INIT_WORK(&priv->update_filtering_work, cw1200_update_filtering_work);
buf : 	INIT_WORK(&priv->set_beacon_wakeup_period_work,
buf : 		  cw1200_set_beacon_wakeup_period_work);
buf : 	init_timer(&priv->mcast_timeout);
buf : 	priv->mcast_timeout.data = (unsigned long)priv;
buf : 	priv->mcast_timeout.function = cw1200_mcast_timeout;
buf : 
buf : 	if (cw1200_queue_stats_init(&priv->tx_queue_stats,
if (cw1200_queue_stats_init(&priv->tx_queue_stats, 
buf : 				    CW1200_LINK_ID_MAX,
buf : 				    cw1200_skb_dtor,
buf : 				    priv)) {
buf : 		ieee80211_free_hw(hw);
buf : 		return NULL;
buf : 	}
buf : 
buf : 	for (i = 0; i < 4; ++i) {
for (i = 0; i < 4; ++i) { 
buf : 		if (cw1200_queue_init(&priv->tx_queue[i],
buf : 				      &priv->tx_queue_stats, i, 16,
buf : 				      cw1200_ttl[i])) {
buf : 			for (; i > 0; i--)
for (; i > 0; i--) 
buf : 				cw1200_queue_deinit(&priv->tx_queue[i - 1]);
buf : 			cw1200_queue_stats_deinit(&priv->tx_queue_stats);
buf : 			ieee80211_free_hw(hw);
buf : 			return NULL;
buf : 		}
buf : 	}
buf : 
buf : 	init_waitqueue_head(&priv->channel_switch_done);
buf : 	init_waitqueue_head(&priv->wsm_cmd_wq);
buf : 	init_waitqueue_head(&priv->wsm_startup_done);
buf : 	init_waitqueue_head(&priv->ps_mode_switch_done);
buf : 	wsm_buf_init(&priv->wsm_cmd_buf);
buf : 	spin_lock_init(&priv->wsm_cmd.lock);
buf : 	priv->wsm_cmd.done = 1;
buf : 	tx_policy_init(priv);
buf : 
buf : 	return hw;
buf : }
buf : 
buf : static int cw1200_register_common(struct ieee80211_hw *dev)
buf : {
buf : 	struct cw1200_common *priv = dev->priv;
buf : 	int err;
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 	err = cw1200_pm_init(&priv->pm_state, priv);
buf : 	if (err) {
if (err) { 
buf : 		pr_err("Cannot init PM. (%d).\n",
buf : 		       err);
buf : 		return err;
buf : 	}
buf : #endif
if 
buf : 
buf : 	err = ieee80211_register_hw(dev);
buf : 	if (err) {
if (err) { 
buf : 		pr_err("Cannot register device (%d).\n",
buf : 		       err);
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 		cw1200_pm_deinit(&priv->pm_state);
buf : #endif
if 
buf : 		return err;
buf : 	}
buf : 
buf : 	cw1200_debug_init(priv);
buf : 
buf : 	pr_info("Registered as '%s'\n", wiphy_name(dev->wiphy));
buf : 	return 0;
buf : }
buf : 
buf : static void cw1200_free_common(struct ieee80211_hw *dev)
buf : {
buf : 	ieee80211_free_hw(dev);
buf : }
buf : 
buf : static void cw1200_unregister_common(struct ieee80211_hw *dev)
buf : {
buf : 	struct cw1200_common *priv = dev->priv;
buf : 	int i;
buf : 
buf : 	ieee80211_unregister_hw(dev);
buf : 
buf : 	del_timer_sync(&priv->mcast_timeout);
buf : 	cw1200_unregister_bh(priv);
buf : 
buf : 	cw1200_debug_release(priv);
buf : 
buf : 	mutex_destroy(&priv->conf_mutex);
buf : 
buf : 	wsm_buf_deinit(&priv->wsm_cmd_buf);
buf : 
buf : 	destroy_workqueue(priv->workqueue);
buf : 	priv->workqueue = NULL;
buf : 
buf : 	if (priv->sdd) {
if (priv->sdd) { 
buf : 		release_firmware(priv->sdd);
buf : 		priv->sdd = NULL;
buf : 	}
buf : 
buf : 	for (i = 0; i < 4; ++i)
for (i = 0; i < 4; ++i) 
buf : 		cw1200_queue_deinit(&priv->tx_queue[i]);
buf : 
buf : 	cw1200_queue_stats_deinit(&priv->tx_queue_stats);
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 	cw1200_pm_deinit(&priv->pm_state);
buf : #endif
if 
buf : }
buf : 
buf : /* Clock is in KHz */
buf : u32 cw1200_dpll_from_clk(u16 clk_khz)
buf : {
buf : 	switch (clk_khz) {
buf : 	case 0x32C8: /* 13000 KHz */
buf : 		return 0x1D89D241;
buf : 	case 0x3E80: /* 16000 KHz */
buf : 		return 0x000001E1;
buf : 	case 0x41A0: /* 16800 KHz */
buf : 		return 0x124931C1;
buf : 	case 0x4B00: /* 19200 KHz */
buf : 		return 0x00000191;
buf : 	case 0x5DC0: /* 24000 KHz */
buf : 		return 0x00000141;
buf : 	case 0x6590: /* 26000 KHz */
buf : 		return 0x0EC4F121;
buf : 	case 0x8340: /* 33600 KHz */
buf : 		return 0x092490E1;
buf : 	case 0x9600: /* 38400 KHz */
buf : 		return 0x100010C1;
buf : 	case 0x9C40: /* 40000 KHz */
buf : 		return 0x000000C1;
buf : 	case 0xBB80: /* 48000 KHz */
buf : 		return 0x000000A1;
buf : 	case 0xCB20: /* 52000 KHz */
buf : 		return 0x07627091;
buf : 	default:
buf : 		pr_err("Unknown Refclk freq (0x%04x), using 26000KHz\n",
buf : 		       clk_khz);
buf : 		return 0x0EC4F121;
buf : 	}
buf : }
buf : 
buf : int cw1200_core_probe(const struct hwbus_ops *hwbus_ops,
buf : 		      struct hwbus_priv *hwbus,
buf : 		      struct device *pdev,
buf : 		      struct cw1200_common **core,
buf : 		      int ref_clk, const u8 *macaddr,
buf : 		      const char *sdd_path, bool have_5ghz)
buf : {
buf : 	int err = -EINVAL;
buf : 	struct ieee80211_hw *dev;
buf : 	struct cw1200_common *priv;
buf : 	struct wsm_operational_mode mode = {
buf : 		.power_mode = cw1200_power_mode,
buf : 		.disable_more_flag_usage = true,
buf : 	};
buf : 
buf : 	dev = cw1200_init_common(macaddr, have_5ghz);
buf : 	if (!dev)
if (!dev) 
buf : 		goto err;
buf : 
buf : 	priv = dev->priv;
buf : 	priv->hw_refclk = ref_clk;
buf : 	if (cw1200_refclk)
if (cw1200_refclk) 
buf : 		priv->hw_refclk = cw1200_refclk;
buf : 
buf : 	priv->sdd_path = (char *)sdd_path;
buf : 	if (cw1200_sdd_path)
if (cw1200_sdd_path) 
buf : 		priv->sdd_path = cw1200_sdd_path;
buf : 
buf : 	priv->hwbus_ops = hwbus_ops;
buf : 	priv->hwbus_priv = hwbus;
buf : 	priv->pdev = pdev;
buf : 	SET_IEEE80211_DEV(priv->hw, pdev);
buf : 
buf : 	/* Pass struct cw1200_common back up */
buf : 	*core = priv;
buf : 
buf : 	err = cw1200_register_bh(priv);
buf : 	if (err)
if (err) 
buf : 		goto err1;
buf : 
buf : 	err = cw1200_load_firmware(priv);
buf : 	if (err)
if (err) 
buf : 		goto err2;
buf : 
buf : 	if (wait_event_interruptible_timeout(priv->wsm_startup_done,
if (wait_event_interruptible_timeout(priv->wsm_startup_done, 
buf : 					     priv->firmware_ready,
buf : 					     3*HZ) <= 0) {
buf : 		/* TODO: Need to find how to reset device
buf : 		   in QUEUE mode properly.
buf : 		*/
buf : 		pr_err("Timeout waiting on device startup\n");
buf : 		err = -ETIMEDOUT;
buf : 		goto err2;
buf : 	}
buf : 
buf : 	/* Set low-power mode. */
buf : 	wsm_set_operational_mode(priv, &mode);
buf : 
buf : 	/* Enable multi-TX confirmation */
buf : 	wsm_use_multi_tx_conf(priv, true);
buf : 
buf : 	err = cw1200_register_common(dev);
buf : 	if (err)
if (err) 
buf : 		goto err2;
buf : 
buf : 	return err;
buf : 
buf : err2:
buf : 	cw1200_unregister_bh(priv);
buf : err1:
buf : 	cw1200_free_common(dev);
buf : err:
buf : 	*core = NULL;
buf : 	return err;
buf : }
buf : EXPORT_SYMBOL_GPL(cw1200_core_probe);
buf : 
buf : void cw1200_core_release(struct cw1200_common *self)
buf : {
buf : 	/* Disable device interrupts */
buf : 	self->hwbus_ops->lock(self->hwbus_priv);
buf : 	__cw1200_irq_enable(self, 0);
buf : 	self->hwbus_ops->unlock(self->hwbus_priv);
buf : 
buf : 	/* And then clean up */
buf : 	cw1200_unregister_common(self->hw);
buf : 	cw1200_free_common(self->hw);
buf : 	return;
buf : }
buf : EXPORT_SYMBOL_GPL(cw1200_core_release);
file : ./test/kernel/drivers/net/wireless/libertas/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * This file contains the major functions in WLAN
buf :  * driver. It includes init, exit, open, close and main
buf :  * thread etc..
buf :  */
buf : 
buf : #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
buf : 
buf : #include <linux/module.h>
buf : #include <linux/delay.h>
buf : #include <linux/etherdevice.h>
buf : #include <linux/hardirq.h>
buf : #include <linux/netdevice.h>
buf : #include <linux/if_arp.h>
if_arp.h> 
buf : #include <linux/kthread.h>
buf : #include <linux/kfifo.h>
ifo.h> 
buf : #include <linux/slab.h>
buf : #include <net/cfg80211.h>
buf : 
buf : #include "host.h"
buf : #include "decl.h"
buf : #include "dev.h"
buf : #include "cfg.h"
buf : #include "debugfs.h"
buf : #include "cmd.h"
buf : #include "mesh.h"
buf : 
buf : #define DRIVER_RELEASE_VERSION "323.p0"
buf : const char lbs_driver_version[] = "COMM-USB8388-" DRIVER_RELEASE_VERSION
buf : #ifdef  DEBUG
ifdef  DEBUG 
buf :     "-dbg"
buf : #endif
if 
buf :     "";
buf : 
buf : 
buf : /* Module parameters */
buf : unsigned int lbs_debug;
buf : EXPORT_SYMBOL_GPL(lbs_debug);
buf : module_param_named(libertas_debug, lbs_debug, int, 0644);
buf : 
buf : unsigned int lbs_disablemesh;
buf : EXPORT_SYMBOL_GPL(lbs_disablemesh);
buf : module_param_named(libertas_disablemesh, lbs_disablemesh, int, 0644);
buf : 
buf : 
buf : /*
buf :  * This global structure is used to send the confirm_sleep command as
buf :  * fast as possible down to the firmware.
buf :  */
buf : struct cmd_confirm_sleep confirm_sleep;
buf : 
buf : 
buf : /*
buf :  * the table to keep region code
buf :  */
buf : u16 lbs_region_code_to_index[MRVDRV_MAX_REGION_CODE] =
buf :     { 0x10, 0x20, 0x30, 0x31, 0x32, 0x40 };
buf : 
buf : /*
buf :  * FW rate table.  FW refers to rates by their index in this table, not by the
buf :  * rate value itself.  Values of 0x00 are
buf :  * reserved positions.
buf :  */
buf : static u8 fw_data_rates[MAX_RATES] =
buf :     { 0x02, 0x04, 0x0B, 0x16, 0x00, 0x0C, 0x12,
buf :       0x18, 0x24, 0x30, 0x48, 0x60, 0x6C, 0x00
buf : };
buf : 
buf : /**
buf :  *  lbs_fw_index_to_data_rate - use index to get the data rate
buf :  *
buf :  *  @idx:	The index of data rate
buf :  *  returns:	data rate or 0
buf :  */
buf : u32 lbs_fw_index_to_data_rate(u8 idx)
buf : {
buf : 	if (idx >= sizeof(fw_data_rates))
if (idx >= sizeof(fw_data_rates)) 
buf : 		idx = 0;
buf : 	return fw_data_rates[idx];
buf : }
buf : 
buf : /**
buf :  *  lbs_data_rate_to_fw_index - use rate to get the index
buf :  *
buf :  *  @rate:	data rate
buf :  *  returns:	index or 0
buf :  */
buf : u8 lbs_data_rate_to_fw_index(u32 rate)
buf : {
buf : 	u8 i;
buf : 
buf : 	if (!rate)
if (!rate) 
buf : 		return 0;
buf : 
buf : 	for (i = 0; i < sizeof(fw_data_rates); i++) {
for (i = 0; i < sizeof(fw_data_rates); i++) { 
buf : 		if (rate == fw_data_rates[i])
buf : 			return i;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : int lbs_set_iface_type(struct lbs_private *priv, enum nl80211_iftype type)
iface_type(struct lbs_private *priv, enum nl80211_iftype type) 
buf : {
buf : 	int ret = 0;
buf : 
buf : 	switch (type) {
buf : 	case NL80211_IFTYPE_MONITOR:
buf : 		ret = lbs_set_monitor_mode(priv, 1);
buf : 		break;
buf : 	case NL80211_IFTYPE_STATION:
buf : 		if (priv->wdev->iftype == NL80211_IFTYPE_MONITOR)
if (priv->wdev->iftype == NL80211_IFTYPE_MONITOR) 
buf : 			ret = lbs_set_monitor_mode(priv, 0);
buf : 		if (!ret)
if (!ret) 
buf : 			ret = lbs_set_snmp_mib(priv, SNMP_MIB_OID_BSS_TYPE, 1);
buf : 		break;
buf : 	case NL80211_IFTYPE_ADHOC:
buf : 		if (priv->wdev->iftype == NL80211_IFTYPE_MONITOR)
if (priv->wdev->iftype == NL80211_IFTYPE_MONITOR) 
buf : 			ret = lbs_set_monitor_mode(priv, 0);
buf : 		if (!ret)
if (!ret) 
buf : 			ret = lbs_set_snmp_mib(priv, SNMP_MIB_OID_BSS_TYPE, 2);
buf : 		break;
buf : 	default:
buf : 		ret = -ENOTSUPP;
buf : 	}
buf : 	return ret;
buf : }
buf : 
buf : int lbs_start_iface(struct lbs_private *priv)
iface(struct lbs_private *priv) 
buf : {
buf : 	struct cmd_ds_802_11_mac_address cmd;
buf : 	int ret;
buf : 
buf : 	if (priv->power_restore) {
if (priv->power_restore) { 
buf : 		ret = priv->power_restore(priv);
buf : 		if (ret)
if (ret) 
buf : 			return ret;
buf : 	}
buf : 
buf : 	cmd.hdr.size = cpu_to_le16(sizeof(cmd));
buf : 	cmd.action = cpu_to_le16(CMD_ACT_SET);
buf : 	memcpy(cmd.macadd, priv->current_addr, ETH_ALEN);
buf : 
buf : 	ret = lbs_cmd_with_response(priv, CMD_802_11_MAC_ADDRESS, &cmd);
buf : 	if (ret) {
if (ret) { 
buf : 		lbs_deb_net("set MAC address failed\n");
buf : 		goto err;
buf : 	}
buf : 
buf : 	ret = lbs_set_iface_type(priv, priv->wdev->iftype);
iface_type(priv, priv->wdev->iftype); 
buf : 	if (ret) {
buf : 		lbs_deb_net("set iface type failed\n");
iface type failed\n"); 
buf : 		goto err;
buf : 	}
buf : 
buf : 	ret = lbs_set_11d_domain_info(priv);
buf : 	if (ret) {
if (ret) { 
buf : 		lbs_deb_net("set 11d domain info failed\n");
buf : 		goto err;
buf : 	}
buf : 
buf : 	lbs_update_channel(priv);
buf : 
buf : 	priv->iface_running = true;
iface_running = true; 
buf : 	return 0;
buf : 
buf : err:
buf : 	if (priv->power_save)
if (priv->power_save) 
buf : 		priv->power_save(priv);
buf : 	return ret;
buf : }
buf : 
buf : /**
buf :  *  lbs_dev_open - open the ethX interface
buf :  *
buf :  *  @dev:	A pointer to &net_device structure
buf :  *  returns:	0 or -EBUSY if monitor mode active
if monitor mode active 
buf :  */
buf : static int lbs_dev_open(struct net_device *dev)
buf : {
buf : 	struct lbs_private *priv = dev->ml_priv;
buf : 	int ret = 0;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_NET);
buf : 	if (!priv->iface_running) {
if (!priv->iface_running) { 
buf : 		ret = lbs_start_iface(priv);
buf : 		if (ret)
if (ret) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	spin_lock_irq(&priv->driver_lock);
buf : 
buf : 	netif_carrier_off(dev);
if_carrier_off(dev); 
buf : 
buf : 	if (!priv->tx_pending_len)
buf : 		netif_wake_queue(dev);
if_wake_queue(dev); 
buf : 
buf : 	spin_unlock_irq(&priv->driver_lock);
buf : 
buf : out:
buf : 	lbs_deb_leave_args(LBS_DEB_NET, "ret %d", ret);
buf : 	return ret;
buf : }
buf : 
buf : static bool lbs_command_queue_empty(struct lbs_private *priv)
buf : {
buf : 	unsigned long flags;
buf : 	bool ret;
buf : 	spin_lock_irqsave(&priv->driver_lock, flags);
buf : 	ret = priv->cur_cmd == NULL && list_empty(&priv->cmdpendingq);
buf : 	spin_unlock_irqrestore(&priv->driver_lock, flags);
buf : 	return ret;
buf : }
buf : 
buf : int lbs_stop_iface(struct lbs_private *priv)
iface(struct lbs_private *priv) 
buf : {
buf : 	unsigned long flags;
buf : 	int ret = 0;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_MAIN);
buf : 
buf : 	spin_lock_irqsave(&priv->driver_lock, flags);
buf : 	priv->iface_running = false;
iface_running = false; 
buf : 	kfree_skb(priv->currenttxskb);
buf : 	priv->currenttxskb = NULL;
buf : 	priv->tx_pending_len = 0;
buf : 	spin_unlock_irqrestore(&priv->driver_lock, flags);
buf : 
buf : 	cancel_work_sync(&priv->mcast_work);
buf : 	del_timer_sync(&priv->tx_lockup_timer);
buf : 
buf : 	/* Disable command processing, and wait for all commands to complete */
for all commands to complete */ 
buf : 	lbs_deb_main("waiting for commands to complete\n");
buf : 	wait_event(priv->waitq, lbs_command_queue_empty(priv));
buf : 	lbs_deb_main("all commands completed\n");
buf : 
buf : 	if (priv->power_save)
if (priv->power_save) 
buf : 		ret = priv->power_save(priv);
buf : 
buf : 	lbs_deb_leave(LBS_DEB_MAIN);
buf : 	return ret;
buf : }
buf : 
buf : /**
buf :  *  lbs_eth_stop - close the ethX interface
buf :  *
buf :  *  @dev:	A pointer to &net_device structure
buf :  *  returns:	0
buf :  */
buf : static int lbs_eth_stop(struct net_device *dev)
buf : {
buf : 	struct lbs_private *priv = dev->ml_priv;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_NET);
buf : 
buf : 	if (priv->connect_status == LBS_CONNECTED)
if (priv->connect_status == LBS_CONNECTED) 
buf : 		lbs_disconnect(priv, WLAN_REASON_DEAUTH_LEAVING);
buf : 
buf : 	spin_lock_irq(&priv->driver_lock);
buf : 	netif_stop_queue(dev);
if_stop_queue(dev); 
buf : 	spin_unlock_irq(&priv->driver_lock);
buf : 
buf : 	lbs_update_mcast(priv);
buf : 	cancel_delayed_work_sync(&priv->scan_work);
buf : 	if (priv->scan_req)
if (priv->scan_req) 
buf : 		lbs_scan_done(priv);
buf : 
buf : 	netif_carrier_off(priv->dev);
if_carrier_off(priv->dev); 
buf : 
buf : 	if (!lbs_iface_active(priv))
buf : 		lbs_stop_iface(priv);
iface(priv); 
buf : 
buf : 	lbs_deb_leave(LBS_DEB_NET);
buf : 	return 0;
buf : }
buf : 
buf : void lbs_host_to_card_done(struct lbs_private *priv)
buf : {
buf : 	unsigned long flags;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_THREAD);
buf : 
buf : 	spin_lock_irqsave(&priv->driver_lock, flags);
buf : 	del_timer(&priv->tx_lockup_timer);
buf : 
buf : 	priv->dnld_sent = DNLD_RES_RECEIVED;
buf : 
buf : 	/* Wake main thread if commands are pending */
if commands are pending */ 
buf : 	if (!priv->cur_cmd || priv->tx_pending_len > 0) {
buf : 		if (!priv->wakeup_dev_required)
if (!priv->wakeup_dev_required) 
buf : 			wake_up(&priv->waitq);
buf : 	}
buf : 
buf : 	spin_unlock_irqrestore(&priv->driver_lock, flags);
buf : 	lbs_deb_leave(LBS_DEB_THREAD);
buf : }
buf : EXPORT_SYMBOL_GPL(lbs_host_to_card_done);
buf : 
buf : int lbs_set_mac_address(struct net_device *dev, void *addr)
buf : {
buf : 	int ret = 0;
buf : 	struct lbs_private *priv = dev->ml_priv;
buf : 	struct sockaddr *phwaddr = addr;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_NET);
buf : 
buf : 	/*
buf : 	 * Can only set MAC address when all interfaces are down, to be written
buf : 	 * to the hardware when one of them is brought up.
buf : 	 */
buf : 	if (lbs_iface_active(priv))
if (lbs_iface_active(priv)) 
buf : 		return -EBUSY;
buf : 
buf : 	/* In case it was called from the mesh device */
buf : 	dev = priv->dev;
buf : 
buf : 	memcpy(priv->current_addr, phwaddr->sa_data, ETH_ALEN);
buf : 	memcpy(dev->dev_addr, phwaddr->sa_data, ETH_ALEN);
buf : 	if (priv->mesh_dev)
if (priv->mesh_dev) 
buf : 		memcpy(priv->mesh_dev->dev_addr, phwaddr->sa_data, ETH_ALEN);
buf : 
buf : 	lbs_deb_leave_args(LBS_DEB_NET, "ret %d", ret);
buf : 	return ret;
buf : }
buf : 
buf : 
buf : static inline int mac_in_list(unsigned char *list, int list_len,
buf : 			      unsigned char *mac)
buf : {
buf : 	while (list_len) {
while (list_len) { 
buf : 		if (!memcmp(list, mac, ETH_ALEN))
buf : 			return 1;
buf : 		list += ETH_ALEN;
buf : 		list_len--;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : 
buf : static int lbs_add_mcast_addrs(struct cmd_ds_mac_multicast_adr *cmd,
buf : 			       struct net_device *dev, int nr_addrs)
buf : {
buf : 	int i = nr_addrs;
buf : 	struct netdev_hw_addr *ha;
buf : 	int cnt;
buf : 
buf : 	if ((dev->flags & (IFF_UP|IFF_MULTICAST)) != (IFF_UP|IFF_MULTICAST))
if ((dev->flags & (IFF_UP|IFF_MULTICAST)) != (IFF_UP|IFF_MULTICAST)) 
buf : 		return nr_addrs;
buf : 
buf : 	netif_addr_lock_bh(dev);
if_addr_lock_bh(dev); 
buf : 	cnt = netdev_mc_count(dev);
buf : 	netdev_for_each_mc_addr(ha, dev) {
for_each_mc_addr(ha, dev) { 
buf : 		if (mac_in_list(cmd->maclist, nr_addrs, ha->addr)) {
buf : 			lbs_deb_net("mcast address %s:%pM skipped\n", dev->name,
buf : 				    ha->addr);
buf : 			cnt--;
buf : 			continue;
buf : 		}
buf : 
buf : 		if (i == MRVDRV_MAX_MULTICAST_LIST_SIZE)
if (i == MRVDRV_MAX_MULTICAST_LIST_SIZE) 
buf : 			break;
buf : 		memcpy(&cmd->maclist[6*i], ha->addr, ETH_ALEN);
buf : 		lbs_deb_net("mcast address %s:%pM added to filter\n", dev->name,
buf : 			    ha->addr);
buf : 		i++;
buf : 		cnt--;
buf : 	}
buf : 	netif_addr_unlock_bh(dev);
if_addr_unlock_bh(dev); 
buf : 	if (cnt)
buf : 		return -EOVERFLOW;
buf : 
buf : 	return i;
buf : }
buf : 
buf : void lbs_update_mcast(struct lbs_private *priv)
buf : {
buf : 	struct cmd_ds_mac_multicast_adr mcast_cmd;
buf : 	int dev_flags = 0;
buf : 	int nr_addrs;
buf : 	int old_mac_control = priv->mac_control;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_NET);
buf : 
buf : 	if (netif_running(priv->dev))
if (netif_running(priv->dev)) 
buf : 		dev_flags |= priv->dev->flags;
buf : 	if (priv->mesh_dev && netif_running(priv->mesh_dev))
if (priv->mesh_dev && netif_running(priv->mesh_dev)) 
buf : 		dev_flags |= priv->mesh_dev->flags;
buf : 
buf : 	if (dev_flags & IFF_PROMISC) {
if (dev_flags & IFF_PROMISC) { 
buf : 		priv->mac_control |= CMD_ACT_MAC_PROMISCUOUS_ENABLE;
buf : 		priv->mac_control &= ~(CMD_ACT_MAC_ALL_MULTICAST_ENABLE |
buf : 				       CMD_ACT_MAC_MULTICAST_ENABLE);
buf : 		goto out_set_mac_control;
buf : 	} else if (dev_flags & IFF_ALLMULTI) {
if (dev_flags & IFF_ALLMULTI) { 
buf : 	do_allmulti:
buf : 		priv->mac_control |= CMD_ACT_MAC_ALL_MULTICAST_ENABLE;
buf : 		priv->mac_control &= ~(CMD_ACT_MAC_PROMISCUOUS_ENABLE |
buf : 				       CMD_ACT_MAC_MULTICAST_ENABLE);
buf : 		goto out_set_mac_control;
buf : 	}
buf : 
buf : 	/* Once for priv->dev, again for priv->mesh_dev if it exists */
if it exists */ 
buf : 	nr_addrs = lbs_add_mcast_addrs(&mcast_cmd, priv->dev, 0);
buf : 	if (nr_addrs >= 0 && priv->mesh_dev)
if (nr_addrs >= 0 && priv->mesh_dev) 
buf : 		nr_addrs = lbs_add_mcast_addrs(&mcast_cmd, priv->mesh_dev, nr_addrs);
buf : 	if (nr_addrs < 0)
if (nr_addrs < 0) 
buf : 		goto do_allmulti;
buf : 
buf : 	if (nr_addrs) {
if (nr_addrs) { 
buf : 		int size = offsetof(struct cmd_ds_mac_multicast_adr,
buf : 				    maclist[6*nr_addrs]);
buf : 
buf : 		mcast_cmd.action = cpu_to_le16(CMD_ACT_SET);
buf : 		mcast_cmd.hdr.size = cpu_to_le16(size);
buf : 		mcast_cmd.nr_of_adrs = cpu_to_le16(nr_addrs);
buf : 
buf : 		lbs_cmd_async(priv, CMD_MAC_MULTICAST_ADR, &mcast_cmd.hdr, size);
buf : 
buf : 		priv->mac_control |= CMD_ACT_MAC_MULTICAST_ENABLE;
buf : 	} else
buf : 		priv->mac_control &= ~CMD_ACT_MAC_MULTICAST_ENABLE;
buf : 
buf : 	priv->mac_control &= ~(CMD_ACT_MAC_PROMISCUOUS_ENABLE |
buf : 			       CMD_ACT_MAC_ALL_MULTICAST_ENABLE);
buf :  out_set_mac_control:
buf : 	if (priv->mac_control != old_mac_control)
if (priv->mac_control != old_mac_control) 
buf : 		lbs_set_mac_control(priv);
buf : 
buf : 	lbs_deb_leave(LBS_DEB_NET);
buf : }
buf : 
buf : static void lbs_set_mcast_worker(struct work_struct *work)
buf : {
buf : 	struct lbs_private *priv = container_of(work, struct lbs_private, mcast_work);
buf : 	lbs_update_mcast(priv);
buf : }
buf : 
buf : void lbs_set_multicast_list(struct net_device *dev)
buf : {
buf : 	struct lbs_private *priv = dev->ml_priv;
buf : 
buf : 	schedule_work(&priv->mcast_work);
buf : }
buf : 
buf : /**
buf :  *  lbs_thread - handles the major jobs in the LBS driver.
buf :  *  It handles all events generated by firmware, RX data received
buf :  *  from firmware and TX data sent from kernel.
buf :  *
buf :  *  @data:	A pointer to &lbs_thread structure
buf :  *  returns:	0
buf :  */
buf : static int lbs_thread(void *data)
buf : {
buf : 	struct net_device *dev = data;
buf : 	struct lbs_private *priv = dev->ml_priv;
buf : 	wait_queue_t wait;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_THREAD);
buf : 
buf : 	init_waitqueue_entry(&wait, current);
buf : 
buf : 	for (;;) {
for (;;) { 
buf : 		int shouldsleep;
buf : 		u8 resp_idx;
buf : 
buf : 		lbs_deb_thread("1: currenttxskb %p, dnld_sent %d\n",
buf : 				priv->currenttxskb, priv->dnld_sent);
buf : 
buf : 		add_wait_queue(&priv->waitq, &wait);
buf : 		set_current_state(TASK_INTERRUPTIBLE);
buf : 		spin_lock_irq(&priv->driver_lock);
buf : 
buf : 		if (kthread_should_stop())
if (kthread_should_stop()) 
buf : 			shouldsleep = 0;	/* Bye */
buf : 		else if (priv->surpriseremoved)
if (priv->surpriseremoved) 
buf : 			shouldsleep = 1;	/* We need to wait until we're _told_ to die */
buf : 		else if (priv->psstate == PS_STATE_SLEEP)
if (priv->psstate == PS_STATE_SLEEP) 
buf : 			shouldsleep = 1;	/* Sleep mode. Nothing we can do till it wakes */
buf : 		else if (priv->cmd_timed_out)
if (priv->cmd_timed_out) 
buf : 			shouldsleep = 0;	/* Command timed out. Recover */
buf : 		else if (!priv->fw_ready)
if (!priv->fw_ready) 
buf : 			shouldsleep = 1;	/* Firmware not ready. We're waiting for it */
for it */ 
buf : 		else if (priv->dnld_sent)
buf : 			shouldsleep = 1;	/* Something is en route to the device already */
buf : 		else if (priv->tx_pending_len > 0)
if (priv->tx_pending_len > 0) 
buf : 			shouldsleep = 0;	/* We've a packet to send */
buf : 		else if (priv->resp_len[priv->resp_idx])
if (priv->resp_len[priv->resp_idx]) 
buf : 			shouldsleep = 0;	/* We have a command response */
buf : 		else if (priv->cur_cmd)
if (priv->cur_cmd) 
buf : 			shouldsleep = 1;	/* Can't send a command; one already running */
buf : 		else if (!list_empty(&priv->cmdpendingq) &&
if (!list_empty(&priv->cmdpendingq) && 
buf : 					!(priv->wakeup_dev_required))
buf : 			shouldsleep = 0;	/* We have a command to send */
buf : 		else if (kfifo_len(&priv->event_fifo))
if (kfifo_len(&priv->event_fifo)) 
buf : 			shouldsleep = 0;	/* We have an event to process */
buf : 		else
buf : 			shouldsleep = 1;	/* No command */
buf : 
buf : 		if (shouldsleep) {
if (shouldsleep) { 
buf : 			lbs_deb_thread("sleeping, connect_status %d, "
buf : 				"psmode %d, psstate %d\n",
buf : 				priv->connect_status,
buf : 				priv->psmode, priv->psstate);
buf : 			spin_unlock_irq(&priv->driver_lock);
buf : 			schedule();
buf : 		} else
buf : 			spin_unlock_irq(&priv->driver_lock);
buf : 
buf : 		lbs_deb_thread("2: currenttxskb %p, dnld_send %d\n",
buf : 			       priv->currenttxskb, priv->dnld_sent);
buf : 
buf : 		set_current_state(TASK_RUNNING);
buf : 		remove_wait_queue(&priv->waitq, &wait);
buf : 
buf : 		lbs_deb_thread("3: currenttxskb %p, dnld_sent %d\n",
buf : 			       priv->currenttxskb, priv->dnld_sent);
buf : 
buf : 		if (kthread_should_stop()) {
if (kthread_should_stop()) { 
buf : 			lbs_deb_thread("break from main thread\n");
buf : 			break;
buf : 		}
buf : 
buf : 		if (priv->surpriseremoved) {
if (priv->surpriseremoved) { 
buf : 			lbs_deb_thread("adapter removed; waiting to die...\n");
buf : 			continue;
buf : 		}
buf : 
buf : 		lbs_deb_thread("4: currenttxskb %p, dnld_sent %d\n",
buf : 		       priv->currenttxskb, priv->dnld_sent);
buf : 
buf : 		/* Process any pending command response */
buf : 		spin_lock_irq(&priv->driver_lock);
buf : 		resp_idx = priv->resp_idx;
buf : 		if (priv->resp_len[resp_idx]) {
if (priv->resp_len[resp_idx]) { 
buf : 			spin_unlock_irq(&priv->driver_lock);
buf : 			lbs_process_command_response(priv,
buf : 				priv->resp_buf[resp_idx],
buf : 				priv->resp_len[resp_idx]);
buf : 			spin_lock_irq(&priv->driver_lock);
buf : 			priv->resp_len[resp_idx] = 0;
buf : 		}
buf : 		spin_unlock_irq(&priv->driver_lock);
buf : 
buf : 		/* Process hardware events, e.g. card removed, link lost */
buf : 		spin_lock_irq(&priv->driver_lock);
buf : 		while (kfifo_len(&priv->event_fifo)) {
ifo_len(&priv->event_fifo)) { 
buf : 			u32 event;
buf : 
buf : 			if (kfifo_out(&priv->event_fifo,
if (kfifo_out(&priv->event_fifo, 
buf : 				(unsigned char *) &event, sizeof(event)) !=
buf : 				sizeof(event))
buf : 					break;
buf : 			spin_unlock_irq(&priv->driver_lock);
buf : 			lbs_process_event(priv, event);
buf : 			spin_lock_irq(&priv->driver_lock);
buf : 		}
buf : 		spin_unlock_irq(&priv->driver_lock);
buf : 
buf : 		if (priv->wakeup_dev_required) {
if (priv->wakeup_dev_required) { 
buf : 			lbs_deb_thread("Waking up device...\n");
buf : 			/* Wake up device */
buf : 			if (priv->exit_deep_sleep(priv))
if (priv->exit_deep_sleep(priv)) 
buf : 				lbs_deb_thread("Wakeup device failed\n");
buf : 			continue;
buf : 		}
buf : 
buf : 		/* command timeout stuff */
buf : 		if (priv->cmd_timed_out && priv->cur_cmd) {
if (priv->cmd_timed_out && priv->cur_cmd) { 
buf : 			struct cmd_ctrl_node *cmdnode = priv->cur_cmd;
buf : 
buf : 			netdev_info(dev, "Timeout submitting command 0x%04x\n",
buf : 				    le16_to_cpu(cmdnode->cmdbuf->command));
buf : 			lbs_complete_command(priv, cmdnode, -ETIMEDOUT);
buf : 
buf : 			/* Reset card, but only when it isn't in the process
buf : 			 * of being shutdown anyway. */
buf : 			if (!dev->dismantle && priv->reset_card)
if (!dev->dismantle && priv->reset_card) 
buf : 				priv->reset_card(priv);
buf : 		}
buf : 		priv->cmd_timed_out = 0;
buf : 
buf : 		if (!priv->fw_ready)
if (!priv->fw_ready) 
buf : 			continue;
buf : 
buf : 		/* Check if we need to confirm Sleep Request received previously */
if we need to confirm Sleep Request received previously */ 
buf : 		if (priv->psstate == PS_STATE_PRE_SLEEP &&
buf : 		    !priv->dnld_sent && !priv->cur_cmd) {
buf : 			if (priv->connect_status == LBS_CONNECTED) {
if (priv->connect_status == LBS_CONNECTED) { 
buf : 				lbs_deb_thread("pre-sleep, currenttxskb %p, "
buf : 					"dnld_sent %d, cur_cmd %p\n",
buf : 					priv->currenttxskb, priv->dnld_sent,
buf : 					priv->cur_cmd);
buf : 
buf : 				lbs_ps_confirm_sleep(priv);
buf : 			} else {
buf : 				/* workaround for firmware sending
for firmware sending 
buf : 				 * deauth/linkloss event immediately
buf : 				 * after sleep request; remove this
buf : 				 * after firmware fixes it
buf : 				 */
buf : 				priv->psstate = PS_STATE_AWAKE;
buf : 				netdev_alert(dev,
buf : 					     "ignore PS_SleepConfirm in non-connected state\n");
buf : 			}
buf : 		}
buf : 
buf : 		/* The PS state is changed during processing of Sleep Request
buf : 		 * event above
buf : 		 */
buf : 		if ((priv->psstate == PS_STATE_SLEEP) ||
if ((priv->psstate == PS_STATE_SLEEP) || 
buf : 		    (priv->psstate == PS_STATE_PRE_SLEEP))
buf : 			continue;
buf : 
buf : 		if (priv->is_deep_sleep)
if (priv->is_deep_sleep) 
buf : 			continue;
buf : 
buf : 		/* Execute the next command */
buf : 		if (!priv->dnld_sent && !priv->cur_cmd)
if (!priv->dnld_sent && !priv->cur_cmd) 
buf : 			lbs_execute_next_command(priv);
buf : 
buf : 		spin_lock_irq(&priv->driver_lock);
buf : 		if (!priv->dnld_sent && priv->tx_pending_len > 0) {
if (!priv->dnld_sent && priv->tx_pending_len > 0) { 
buf : 			int ret = priv->hw_host_to_card(priv, MVMS_DAT,
buf : 							priv->tx_pending_buf,
buf : 							priv->tx_pending_len);
buf : 			if (ret) {
if (ret) { 
buf : 				lbs_deb_tx("host_to_card failed %d\n", ret);
buf : 				priv->dnld_sent = DNLD_RES_RECEIVED;
buf : 			} else {
buf : 				mod_timer(&priv->tx_lockup_timer,
buf : 					  jiffies + (HZ * 5));
iffies + (HZ * 5)); 
buf : 			}
buf : 			priv->tx_pending_len = 0;
buf : 			if (!priv->currenttxskb) {
if (!priv->currenttxskb) { 
buf : 				/* We can wake the queues immediately if we aren't
buf : 				   waiting for TX feedback */
for TX feedback */ 
buf : 				if (priv->connect_status == LBS_CONNECTED)
buf : 					netif_wake_queue(priv->dev);
if_wake_queue(priv->dev); 
buf : 				if (priv->mesh_dev &&
buf : 				    netif_running(priv->mesh_dev))
if_running(priv->mesh_dev)) 
buf : 					netif_wake_queue(priv->mesh_dev);
buf : 			}
buf : 		}
buf : 		spin_unlock_irq(&priv->driver_lock);
buf : 	}
buf : 
buf : 	del_timer(&priv->command_timer);
buf : 	del_timer(&priv->tx_lockup_timer);
buf : 	del_timer(&priv->auto_deepsleep_timer);
buf : 
buf : 	lbs_deb_leave(LBS_DEB_THREAD);
buf : 	return 0;
buf : }
buf : 
buf : /**
buf :  * lbs_setup_firmware - gets the HW spec from the firmware and sets
buf :  *        some basic parameters
buf :  *
buf :  *  @priv:	A pointer to &struct lbs_private structure
buf :  *  returns:	0 or -1
buf :  */
buf : static int lbs_setup_firmware(struct lbs_private *priv)
buf : {
buf : 	int ret = -1;
buf : 	s16 curlevel = 0, minlevel = 0, maxlevel = 0;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_FW);
buf : 
buf : 	/* Read MAC address from firmware */
buf : 	memset(priv->current_addr, 0xff, ETH_ALEN);
buf : 	ret = lbs_update_hw_spec(priv);
buf : 	if (ret)
if (ret) 
buf : 		goto done;
buf : 
buf : 	/* Read power levels if available */
if available */ 
buf : 	ret = lbs_get_tx_power(priv, &curlevel, &minlevel, &maxlevel);
buf : 	if (ret == 0) {
if (ret == 0) { 
buf : 		priv->txpower_cur = curlevel;
buf : 		priv->txpower_min = minlevel;
buf : 		priv->txpower_max = maxlevel;
buf : 	}
buf : 
buf : 	/* Send cmd to FW to enable 11D function */
buf : 	ret = lbs_set_snmp_mib(priv, SNMP_MIB_OID_11D_ENABLE, 1);
buf : 	if (ret)
if (ret) 
buf : 		goto done;
buf : 
buf : 	ret = lbs_set_mac_control_sync(priv);
buf : done:
buf : 	lbs_deb_leave_args(LBS_DEB_FW, "ret %d", ret);
buf : 	return ret;
buf : }
buf : 
buf : int lbs_suspend(struct lbs_private *priv)
buf : {
buf : 	int ret;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_FW);
buf : 
buf : 	if (priv->is_deep_sleep) {
if (priv->is_deep_sleep) { 
buf : 		ret = lbs_set_deep_sleep(priv, 0);
buf : 		if (ret) {
if (ret) { 
buf : 			netdev_err(priv->dev,
buf : 				   "deep sleep cancellation failed: %d\n", ret);
buf : 			return ret;
buf : 		}
buf : 		priv->deep_sleep_required = 1;
buf : 	}
buf : 
buf : 	ret = lbs_set_host_sleep(priv, 1);
buf : 
buf : 	netif_device_detach(priv->dev);
if_device_detach(priv->dev); 
buf : 	if (priv->mesh_dev)
buf : 		netif_device_detach(priv->mesh_dev);
if_device_detach(priv->mesh_dev); 
buf : 
buf : 	lbs_deb_leave_args(LBS_DEB_FW, "ret %d", ret);
buf : 	return ret;
buf : }
buf : EXPORT_SYMBOL_GPL(lbs_suspend);
buf : 
buf : int lbs_resume(struct lbs_private *priv)
buf : {
buf : 	int ret;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_FW);
buf : 
buf : 	ret = lbs_set_host_sleep(priv, 0);
buf : 
buf : 	netif_device_attach(priv->dev);
if_device_attach(priv->dev); 
buf : 	if (priv->mesh_dev)
buf : 		netif_device_attach(priv->mesh_dev);
if_device_attach(priv->mesh_dev); 
buf : 
buf : 	if (priv->deep_sleep_required) {
buf : 		priv->deep_sleep_required = 0;
buf : 		ret = lbs_set_deep_sleep(priv, 1);
buf : 		if (ret)
if (ret) 
buf : 			netdev_err(priv->dev,
buf : 				   "deep sleep activation failed: %d\n", ret);
buf : 	}
buf : 
buf : 	if (priv->setup_fw_on_resume)
if (priv->setup_fw_on_resume) 
buf : 		ret = lbs_setup_firmware(priv);
buf : 
buf : 	lbs_deb_leave_args(LBS_DEB_FW, "ret %d", ret);
buf : 	return ret;
buf : }
buf : EXPORT_SYMBOL_GPL(lbs_resume);
buf : 
buf : /**
buf :  * lbs_cmd_timeout_handler - handles the timeout of command sending.
buf :  * It will re-send the same command again.
buf :  *
buf :  * @data: &struct lbs_private pointer
buf :  */
buf : static void lbs_cmd_timeout_handler(unsigned long data)
buf : {
buf : 	struct lbs_private *priv = (struct lbs_private *)data;
buf : 	unsigned long flags;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_CMD);
buf : 	spin_lock_irqsave(&priv->driver_lock, flags);
buf : 
buf : 	if (!priv->cur_cmd)
if (!priv->cur_cmd) 
buf : 		goto out;
buf : 
buf : 	netdev_info(priv->dev, "command 0x%04x timed out\n",
buf : 		    le16_to_cpu(priv->cur_cmd->cmdbuf->command));
buf : 
buf : 	priv->cmd_timed_out = 1;
buf : 
buf : 	/*
buf : 	 * If the device didn't even acknowledge the command, reset the state
buf : 	 * so that we don't block all future commands due to this one timeout.
buf : 	 */
buf : 	if (priv->dnld_sent == DNLD_CMD_SENT)
if (priv->dnld_sent == DNLD_CMD_SENT) 
buf : 		priv->dnld_sent = DNLD_RES_RECEIVED;
buf : 
buf : 	wake_up(&priv->waitq);
buf : out:
buf : 	spin_unlock_irqrestore(&priv->driver_lock, flags);
buf : 	lbs_deb_leave(LBS_DEB_CMD);
buf : }
buf : 
buf : /**
buf :  * lbs_tx_lockup_handler - handles the timeout of the passing of TX frames
buf :  * to the hardware. This is known to frequently happen with SD8686 when
buf :  * waking up after a Wake-on-WLAN-triggered resume.
buf :  *
buf :  * @data: &struct lbs_private pointer
buf :  */
buf : static void lbs_tx_lockup_handler(unsigned long data)
buf : {
buf : 	struct lbs_private *priv = (struct lbs_private *)data;
buf : 	unsigned long flags;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_TX);
buf : 	spin_lock_irqsave(&priv->driver_lock, flags);
buf : 
buf : 	netdev_info(priv->dev, "TX lockup detected\n");
buf : 	if (priv->reset_card)
if (priv->reset_card) 
buf : 		priv->reset_card(priv);
buf : 
buf : 	priv->dnld_sent = DNLD_RES_RECEIVED;
buf : 	wake_up_interruptible(&priv->waitq);
buf : 
buf : 	spin_unlock_irqrestore(&priv->driver_lock, flags);
buf : 	lbs_deb_leave(LBS_DEB_TX);
buf : }
buf : 
buf : /**
buf :  * auto_deepsleep_timer_fn - put the device back to deep sleep mode when
buf :  * timer expires and no activity (command, event, data etc.) is detected.
buf :  * @data:	&struct lbs_private pointer
buf :  * returns:	N/A
buf :  */
buf : static void auto_deepsleep_timer_fn(unsigned long data)
buf : {
buf : 	struct lbs_private *priv = (struct lbs_private *)data;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_CMD);
buf : 
buf : 	if (priv->is_activity_detected) {
if (priv->is_activity_detected) { 
buf : 		priv->is_activity_detected = 0;
buf : 	} else {
buf : 		if (priv->is_auto_deep_sleep_enabled &&
if (priv->is_auto_deep_sleep_enabled && 
buf : 		    (!priv->wakeup_dev_required) &&
buf : 		    (priv->connect_status != LBS_CONNECTED)) {
buf : 			struct cmd_header cmd;
buf : 
buf : 			lbs_deb_main("Entering auto deep sleep mode...\n");
buf : 			memset(&cmd, 0, sizeof(cmd));
buf : 			cmd.size = cpu_to_le16(sizeof(cmd));
buf : 			lbs_cmd_async(priv, CMD_802_11_DEEP_SLEEP, &cmd,
buf : 					sizeof(cmd));
buf : 		}
buf : 	}
buf : 	mod_timer(&priv->auto_deepsleep_timer , jiffies +
iffies + 
buf : 				(priv->auto_deep_sleep_timeout * HZ)/1000);
buf : 	lbs_deb_leave(LBS_DEB_CMD);
buf : }
buf : 
buf : int lbs_enter_auto_deep_sleep(struct lbs_private *priv)
buf : {
buf : 	lbs_deb_enter(LBS_DEB_SDIO);
buf : 
buf : 	priv->is_auto_deep_sleep_enabled = 1;
buf : 	if (priv->is_deep_sleep)
if (priv->is_deep_sleep) 
buf : 		priv->wakeup_dev_required = 1;
buf : 	mod_timer(&priv->auto_deepsleep_timer ,
buf : 			jiffies + (priv->auto_deep_sleep_timeout * HZ)/1000);
iffies + (priv->auto_deep_sleep_timeout * HZ)/1000); 
buf : 
buf : 	lbs_deb_leave(LBS_DEB_SDIO);
buf : 	return 0;
buf : }
buf : 
buf : int lbs_exit_auto_deep_sleep(struct lbs_private *priv)
buf : {
buf : 	lbs_deb_enter(LBS_DEB_SDIO);
buf : 
buf : 	priv->is_auto_deep_sleep_enabled = 0;
buf : 	priv->auto_deep_sleep_timeout = 0;
buf : 	del_timer(&priv->auto_deepsleep_timer);
buf : 
buf : 	lbs_deb_leave(LBS_DEB_SDIO);
buf : 	return 0;
buf : }
buf : 
buf : static int lbs_init_adapter(struct lbs_private *priv)
buf : {
buf : 	int ret;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_MAIN);
buf : 
buf : 	memset(priv->current_addr, 0xff, ETH_ALEN);
buf : 
buf : 	priv->connect_status = LBS_DISCONNECTED;
buf : 	priv->channel = DEFAULT_AD_HOC_CHANNEL;
buf : 	priv->mac_control = CMD_ACT_MAC_RX_ON | CMD_ACT_MAC_TX_ON;
buf : 	priv->radio_on = 1;
buf : 	priv->psmode = LBS802_11POWERMODECAM;
buf : 	priv->psstate = PS_STATE_FULL_POWER;
buf : 	priv->is_deep_sleep = 0;
buf : 	priv->is_auto_deep_sleep_enabled = 0;
buf : 	priv->deep_sleep_required = 0;
buf : 	priv->wakeup_dev_required = 0;
buf : 	init_waitqueue_head(&priv->ds_awake_q);
buf : 	init_waitqueue_head(&priv->scan_q);
buf : 	priv->authtype_auto = 1;
buf : 	priv->is_host_sleep_configured = 0;
buf : 	priv->is_host_sleep_activated = 0;
buf : 	init_waitqueue_head(&priv->host_sleep_q);
buf : 	init_waitqueue_head(&priv->fw_waitq);
buf : 	mutex_init(&priv->lock);
buf : 
buf : 	setup_timer(&priv->command_timer, lbs_cmd_timeout_handler,
buf : 		(unsigned long)priv);
buf : 	setup_timer(&priv->tx_lockup_timer, lbs_tx_lockup_handler,
buf : 		(unsigned long)priv);
buf : 	setup_timer(&priv->auto_deepsleep_timer, auto_deepsleep_timer_fn,
buf : 			(unsigned long)priv);
buf : 
buf : 	INIT_LIST_HEAD(&priv->cmdfreeq);
buf : 	INIT_LIST_HEAD(&priv->cmdpendingq);
buf : 
buf : 	spin_lock_init(&priv->driver_lock);
buf : 
buf : 	/* Allocate the command buffers */
buf : 	if (lbs_allocate_cmd_buffer(priv)) {
if (lbs_allocate_cmd_buffer(priv)) { 
buf : 		pr_err("Out of memory allocating command buffers\n");
buf : 		ret = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 	priv->resp_idx = 0;
buf : 	priv->resp_len[0] = priv->resp_len[1] = 0;
buf : 
buf : 	/* Create the event FIFO */
buf : 	ret = kfifo_alloc(&priv->event_fifo, sizeof(u32) * 16, GFP_KERNEL);
ifo_alloc(&priv->event_fifo, sizeof(u32) * 16, GFP_KERNEL); 
buf : 	if (ret) {
buf : 		pr_err("Out of memory allocating event FIFO buffer\n");
buf : 		goto out;
buf : 	}
buf : 
buf : out:
buf : 	lbs_deb_leave_args(LBS_DEB_MAIN, "ret %d", ret);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void lbs_free_adapter(struct lbs_private *priv)
buf : {
buf : 	lbs_deb_enter(LBS_DEB_MAIN);
buf : 
buf : 	lbs_free_cmd_buffer(priv);
buf : 	kfifo_free(&priv->event_fifo);
ifo_free(&priv->event_fifo); 
buf : 	del_timer(&priv->command_timer);
buf : 	del_timer(&priv->tx_lockup_timer);
buf : 	del_timer(&priv->auto_deepsleep_timer);
buf : 
buf : 	lbs_deb_leave(LBS_DEB_MAIN);
buf : }
buf : 
buf : static const struct net_device_ops lbs_netdev_ops = {
buf : 	.ndo_open 		= lbs_dev_open,
buf : 	.ndo_stop		= lbs_eth_stop,
buf : 	.ndo_start_xmit		= lbs_hard_start_xmit,
buf : 	.ndo_set_mac_address	= lbs_set_mac_address,
buf : 	.ndo_set_rx_mode	= lbs_set_multicast_list,
buf : 	.ndo_change_mtu		= eth_change_mtu,
buf : 	.ndo_validate_addr	= eth_validate_addr,
buf : };
buf : 
buf : /**
buf :  * lbs_add_card - adds the card. It will probe the
buf :  * card, allocate the lbs_priv and initialize the device.
buf :  *
buf :  * @card:	A pointer to card
buf :  * @dmdev:	A pointer to &struct device
buf :  * returns:	A pointer to &struct lbs_private structure
buf :  */
buf : struct lbs_private *lbs_add_card(void *card, struct device *dmdev)
buf : {
buf : 	struct net_device *dev;
buf : 	struct wireless_dev *wdev;
buf : 	struct lbs_private *priv = NULL;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_MAIN);
buf : 
buf : 	/* Allocate an Ethernet device and register it */
buf : 	wdev = lbs_cfg_alloc(dmdev);
buf : 	if (IS_ERR(wdev)) {
if (IS_ERR(wdev)) { 
buf : 		pr_err("cfg80211 init failed\n");
buf : 		goto done;
buf : 	}
buf : 
buf : 	wdev->iftype = NL80211_IFTYPE_STATION;
iftype = NL80211_IFTYPE_STATION; 
buf : 	priv = wdev_priv(wdev);
buf : 	priv->wdev = wdev;
buf : 
buf : 	if (lbs_init_adapter(priv)) {
if (lbs_init_adapter(priv)) { 
buf : 		pr_err("failed to initialize adapter structure\n");
buf : 		goto err_wdev;
buf : 	}
buf : 
buf : 	dev = alloc_netdev(0, "wlan%d", ether_setup);
buf : 	if (!dev) {
if (!dev) { 
buf : 		dev_err(dmdev, "no memory for network device instance\n");
for network device instance\n"); 
buf : 		goto err_adapter;
buf : 	}
buf : 
buf : 	dev->ieee80211_ptr = wdev;
buf : 	dev->ml_priv = priv;
buf : 	SET_NETDEV_DEV(dev, dmdev);
buf : 	wdev->netdev = dev;
buf : 	priv->dev = dev;
buf : 
buf :  	dev->netdev_ops = &lbs_netdev_ops;
buf : 	dev->watchdog_timeo = 5 * HZ;
buf : 	dev->ethtool_ops = &lbs_ethtool_ops;
buf : 	dev->flags |= IFF_BROADCAST | IFF_MULTICAST;
buf : 
buf : 	priv->card = card;
buf : 
buf : 	strcpy(dev->name, "wlan%d");
buf : 
buf : 	lbs_deb_thread("Starting main thread...\n");
buf : 	init_waitqueue_head(&priv->waitq);
buf : 	priv->main_thread = kthread_run(lbs_thread, dev, "lbs_main");
buf : 	if (IS_ERR(priv->main_thread)) {
if (IS_ERR(priv->main_thread)) { 
buf : 		lbs_deb_thread("Error creating main thread.\n");
buf : 		goto err_ndev;
buf : 	}
buf : 
buf : 	priv->work_thread = create_singlethread_workqueue("lbs_worker");
buf : 	INIT_WORK(&priv->mcast_work, lbs_set_mcast_worker);
buf : 
buf : 	priv->wol_criteria = EHS_REMOVE_WAKEUP;
buf : 	priv->wol_gpio = 0xff;
buf : 	priv->wol_gap = 20;
buf : 	priv->ehs_remove_supported = true;
buf : 
buf : 	goto done;
buf : 
buf :  err_ndev:
buf : 	free_netdev(dev);
buf : 
buf :  err_adapter:
buf : 	lbs_free_adapter(priv);
buf : 
buf :  err_wdev:
buf : 	lbs_cfg_free(priv);
buf : 
buf : 	priv = NULL;
buf : 
buf : done:
buf : 	lbs_deb_leave_args(LBS_DEB_MAIN, "priv %p", priv);
buf : 	return priv;
buf : }
buf : EXPORT_SYMBOL_GPL(lbs_add_card);
buf : 
buf : 
buf : void lbs_remove_card(struct lbs_private *priv)
buf : {
buf : 	struct net_device *dev = priv->dev;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_MAIN);
buf : 
buf : 	lbs_remove_mesh(priv);
buf : 
buf : 	if (priv->wiphy_registered)
if (priv->wiphy_registered) 
buf : 		lbs_scan_deinit(priv);
buf : 
buf : 	lbs_wait_for_firmware_load(priv);
for_firmware_load(priv); 
buf : 
buf : 	/* worker thread destruction blocks on the in-flight command which
buf : 	 * should have been cleared already in lbs_stop_card().
buf : 	 */
buf : 	lbs_deb_main("destroying worker thread\n");
buf : 	destroy_workqueue(priv->work_thread);
buf : 	lbs_deb_main("done destroying worker thread\n");
buf : 
buf : 	if (priv->psmode == LBS802_11POWERMODEMAX_PSP) {
if (priv->psmode == LBS802_11POWERMODEMAX_PSP) { 
buf : 		priv->psmode = LBS802_11POWERMODECAM;
buf : 		lbs_set_ps_mode(priv, PS_MODE_ACTION_EXIT_PS, true);
buf : 	}
buf : 
buf : 	if (priv->is_deep_sleep) {
if (priv->is_deep_sleep) { 
buf : 		priv->is_deep_sleep = 0;
buf : 		wake_up_interruptible(&priv->ds_awake_q);
buf : 	}
buf : 
buf : 	priv->is_host_sleep_configured = 0;
buf : 	priv->is_host_sleep_activated = 0;
buf : 	wake_up_interruptible(&priv->host_sleep_q);
buf : 
buf : 	/* Stop the thread servicing the interrupts */
buf : 	priv->surpriseremoved = 1;
buf : 	kthread_stop(priv->main_thread);
buf : 
buf : 	lbs_free_adapter(priv);
buf : 	lbs_cfg_free(priv);
buf : 	free_netdev(dev);
buf : 
buf : 	lbs_deb_leave(LBS_DEB_MAIN);
buf : }
buf : EXPORT_SYMBOL_GPL(lbs_remove_card);
buf : 
buf : 
buf : int lbs_rtap_supported(struct lbs_private *priv)
buf : {
buf : 	if (MRVL_FW_MAJOR_REV(priv->fwrelease) == MRVL_FW_V5)
if (MRVL_FW_MAJOR_REV(priv->fwrelease) == MRVL_FW_V5) 
buf : 		return 1;
buf : 
buf : 	/* newer firmware use a capability mask */
buf : 	return ((MRVL_FW_MAJOR_REV(priv->fwrelease) >= MRVL_FW_V10) &&
buf : 		(priv->fwcapinfo & MESH_CAPINFO_ENABLE_MASK));
buf : }
buf : 
buf : 
buf : int lbs_start_card(struct lbs_private *priv)
buf : {
buf : 	struct net_device *dev = priv->dev;
buf : 	int ret = -1;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_MAIN);
buf : 
buf : 	/* poke the firmware */
buf : 	ret = lbs_setup_firmware(priv);
buf : 	if (ret)
if (ret) 
buf : 		goto done;
buf : 
buf : 	if (!lbs_disablemesh)
if (!lbs_disablemesh) 
buf : 		lbs_init_mesh(priv);
buf : 	else
buf : 		pr_info("%s: mesh disabled\n", dev->name);
buf : 
buf : 	if (lbs_cfg_register(priv)) {
if (lbs_cfg_register(priv)) { 
buf : 		pr_err("cannot register device\n");
buf : 		goto done;
buf : 	}
buf : 
buf : 	if (lbs_mesh_activated(priv))
if (lbs_mesh_activated(priv)) 
buf : 		lbs_start_mesh(priv);
buf : 
buf : 	lbs_debugfs_init_one(priv, dev);
buf : 
buf : 	netdev_info(dev, "Marvell WLAN 802.11 adapter\n");
buf : 
buf : 	ret = 0;
buf : 
buf : done:
buf : 	lbs_deb_leave_args(LBS_DEB_MAIN, "ret %d", ret);
buf : 	return ret;
buf : }
buf : EXPORT_SYMBOL_GPL(lbs_start_card);
buf : 
buf : 
buf : void lbs_stop_card(struct lbs_private *priv)
buf : {
buf : 	struct net_device *dev;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_MAIN);
buf : 
buf : 	if (!priv)
if (!priv) 
buf : 		goto out;
buf : 	dev = priv->dev;
buf : 
buf : 	/* If the netdev isn't registered, it means that lbs_start_card() was
buf : 	 * never called so we have nothing to do here. */
buf : 	if (dev->reg_state != NETREG_REGISTERED)
if (dev->reg_state != NETREG_REGISTERED) 
buf : 		goto out;
buf : 
buf : 	netif_stop_queue(dev);
if_stop_queue(dev); 
buf : 	netif_carrier_off(dev);
buf : 
buf : 	lbs_debugfs_remove_one(priv);
buf : 	lbs_deinit_mesh(priv);
buf : 	unregister_netdev(dev);
buf : 
buf : out:
buf : 	lbs_deb_leave(LBS_DEB_MAIN);
buf : }
buf : EXPORT_SYMBOL_GPL(lbs_stop_card);
buf : 
buf : 
buf : void lbs_queue_event(struct lbs_private *priv, u32 event)
buf : {
buf : 	unsigned long flags;
buf : 
buf : 	lbs_deb_enter(LBS_DEB_THREAD);
buf : 	spin_lock_irqsave(&priv->driver_lock, flags);
buf : 
buf : 	if (priv->psstate == PS_STATE_SLEEP)
if (priv->psstate == PS_STATE_SLEEP) 
buf : 		priv->psstate = PS_STATE_AWAKE;
buf : 
buf : 	kfifo_in(&priv->event_fifo, (unsigned char *) &event, sizeof(u32));
ifo_in(&priv->event_fifo, (unsigned char *) &event, sizeof(u32)); 
buf : 
buf : 	wake_up(&priv->waitq);
buf : 
buf : 	spin_unlock_irqrestore(&priv->driver_lock, flags);
buf : 	lbs_deb_leave(LBS_DEB_THREAD);
buf : }
buf : EXPORT_SYMBOL_GPL(lbs_queue_event);
buf : 
buf : void lbs_notify_command_response(struct lbs_private *priv, u8 resp_idx)
ify_command_response(struct lbs_private *priv, u8 resp_idx) 
buf : {
buf : 	lbs_deb_enter(LBS_DEB_THREAD);
buf : 
buf : 	if (priv->psstate == PS_STATE_SLEEP)
if (priv->psstate == PS_STATE_SLEEP) 
buf : 		priv->psstate = PS_STATE_AWAKE;
buf : 
buf : 	/* Swap buffers by flipping the response index */
buf : 	BUG_ON(resp_idx > 1);
buf : 	priv->resp_idx = resp_idx;
buf : 
buf : 	wake_up(&priv->waitq);
buf : 
buf : 	lbs_deb_leave(LBS_DEB_THREAD);
buf : }
buf : EXPORT_SYMBOL_GPL(lbs_notify_command_response);
ify_command_response); 
buf : 
buf : static int __init lbs_init_module(void)
buf : {
buf : 	lbs_deb_enter(LBS_DEB_MAIN);
buf : 	memset(&confirm_sleep, 0, sizeof(confirm_sleep));
buf : 	confirm_sleep.hdr.command = cpu_to_le16(CMD_802_11_PS_MODE);
buf : 	confirm_sleep.hdr.size = cpu_to_le16(sizeof(confirm_sleep));
buf : 	confirm_sleep.action = cpu_to_le16(PS_MODE_ACTION_SLEEP_CONFIRMED);
buf : 	lbs_debugfs_init();
buf : 	lbs_deb_leave(LBS_DEB_MAIN);
buf : 	return 0;
buf : }
buf : 
buf : static void __exit lbs_exit_module(void)
buf : {
buf : 	lbs_deb_enter(LBS_DEB_MAIN);
buf : 	lbs_debugfs_remove();
buf : 	lbs_deb_leave(LBS_DEB_MAIN);
buf : }
buf : 
buf : module_init(lbs_init_module);
buf : module_exit(lbs_exit_module);
buf : 
buf : MODULE_DESCRIPTION("Libertas WLAN Driver Library");
buf : MODULE_AUTHOR("Marvell International Ltd.");
buf : MODULE_LICENSE("GPL");
file : ./test/kernel/drivers/net/wireless/brcm80211/brcmsmac/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2010 Broadcom Corporation
buf :  * Copyright (c) 2013 Hauke Mehrtens <hauke@hauke-m.de>
buf :  *
buf :  * Permission to use, copy, modify, and/or distribute this software for any
ify, and/or distribute this software for any 
buf :  * purpose with or without fee is hereby granted, provided that the above
buf :  * copyright notice and this permission notice appear in all copies.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
buf :  * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
buf :  * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
buf :  * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
buf :  * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
buf :  * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
buf :  * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
buf :  */
buf : 
buf : #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
buf : 
buf : #include <linux/pci_ids.h>
buf : #include <linux/if_ether.h>
if_ether.h> 
buf : #include <net/cfg80211.h>
buf : #include <net/mac80211.h>
buf : #include <brcm_hw_ids.h>
buf : #include <aiutils.h>
buf : #include <chipcommon.h>
buf : #include "rate.h"
buf : #include "scb.h"
buf : #include "phy/phy_hal.h"
buf : #include "channel.h"
buf : #include "antsel.h"
buf : #include "stf.h"
buf : #include "ampdu.h"
buf : #include "mac80211_if.h"
if.h" 
buf : #include "ucode_loader.h"
buf : #include "main.h"
buf : #include "soc.h"
buf : #include "dma.h"
buf : #include "debug.h"
buf : #include "brcms_trace_events.h"
buf : 
buf : /* watchdog timer, in unit of ms */
buf : #define TIMER_INTERVAL_WATCHDOG		1000
buf : /* radio monitor timer, in unit of ms */
buf : #define TIMER_INTERVAL_RADIOCHK		800
buf : 
buf : /* beacon interval, in unit of 1024TU */
buf : #define BEACON_INTERVAL_DEFAULT		100
buf : 
buf : /* n-mode support capability */
buf : /* 2x2 includes both 1x1 & 2x2 devices
buf :  * reserved #define 2 for future when we want to separate 1x1 & 2x2 and
for future when we want to separate 1x1 & 2x2 and 
buf :  * control it independently
buf :  */
buf : #define WL_11N_2x2			1
buf : #define WL_11N_3x3			3
buf : #define WL_11N_4x4			4
buf : 
buf : #define EDCF_ACI_MASK			0x60
buf : #define EDCF_ACI_SHIFT			5
buf : #define EDCF_ECWMIN_MASK		0x0f
buf : #define EDCF_ECWMAX_SHIFT		4
buf : #define EDCF_AIFSN_MASK			0x0f
buf : #define EDCF_AIFSN_MAX			15
buf : #define EDCF_ECWMAX_MASK		0xf0
buf : 
buf : #define EDCF_AC_BE_TXOP_STA		0x0000
buf : #define EDCF_AC_BK_TXOP_STA		0x0000
buf : #define EDCF_AC_VO_ACI_STA		0x62
buf : #define EDCF_AC_VO_ECW_STA		0x32
buf : #define EDCF_AC_VI_ACI_STA		0x42
buf : #define EDCF_AC_VI_ECW_STA		0x43
buf : #define EDCF_AC_BK_ECW_STA		0xA4
buf : #define EDCF_AC_VI_TXOP_STA		0x005e
buf : #define EDCF_AC_VO_TXOP_STA		0x002f
buf : #define EDCF_AC_BE_ACI_STA		0x03
buf : #define EDCF_AC_BE_ECW_STA		0xA4
buf : #define EDCF_AC_BK_ACI_STA		0x27
buf : #define EDCF_AC_VO_TXOP_AP		0x002f
buf : 
buf : #define EDCF_TXOP2USEC(txop)		((txop) << 5)
buf : #define EDCF_ECW2CW(exp)		((1 << (exp)) - 1)
buf : 
buf : #define APHY_SYMBOL_TIME		4
buf : #define APHY_PREAMBLE_TIME		16
buf : #define APHY_SIGNAL_TIME		4
buf : #define APHY_SIFS_TIME			16
buf : #define APHY_SERVICE_NBITS		16
buf : #define APHY_TAIL_NBITS			6
buf : #define BPHY_SIFS_TIME			10
buf : #define BPHY_PLCP_SHORT_TIME		96
buf : 
buf : #define PREN_PREAMBLE			24
buf : #define PREN_MM_EXT			12
buf : #define PREN_PREAMBLE_EXT		4
buf : 
buf : #define DOT11_MAC_HDR_LEN		24
buf : #define DOT11_ACK_LEN			10
buf : #define DOT11_BA_LEN			4
buf : #define DOT11_OFDM_SIGNAL_EXTENSION	6
buf : #define DOT11_MIN_FRAG_LEN		256
buf : #define DOT11_RTS_LEN			16
buf : #define DOT11_CTS_LEN			10
buf : #define DOT11_BA_BITMAP_LEN		128
buf : #define DOT11_MAXNUMFRAGS		16
buf : #define DOT11_MAX_FRAG_LEN		2346
buf : 
buf : #define BPHY_PLCP_TIME			192
buf : #define RIFS_11N_TIME			2
buf : 
buf : /* length of the BCN template area */
buf : #define BCN_TMPL_LEN			512
buf : 
buf : /* brcms_bss_info flag bit values */
buf : #define BRCMS_BSS_HT			0x0020	/* BSS is HT (MIMO) capable */
buf : 
buf : /* chip rx buffer offset */
buf : #define BRCMS_HWRXOFF			38
buf : 
buf : /* rfdisable delay timer 500 ms, runs of ALP clock */
buf : #define RFDISABLE_DEFAULT		10000000
buf : 
buf : #define BRCMS_TEMPSENSE_PERIOD		10	/* 10 second timeout */
buf : 
buf : /* synthpu_dly times in us */
buf : #define SYNTHPU_DLY_APHY_US		3700
buf : #define SYNTHPU_DLY_BPHY_US		1050
buf : #define SYNTHPU_DLY_NPHY_US		2048
buf : #define SYNTHPU_DLY_LPPHY_US		300
buf : 
buf : #define ANTCNT				10	/* vanilla M_MAX_ANTCNT val */
buf : 
buf : /* Per-AC retry limit register definitions; uses defs.h bitfield macros */
buf : #define EDCF_SHORT_S			0
buf : #define EDCF_SFB_S			4
buf : #define EDCF_LONG_S			8
buf : #define EDCF_LFB_S			12
buf : #define EDCF_SHORT_M			BITFIELD_MASK(4)
buf : #define EDCF_SFB_M			BITFIELD_MASK(4)
buf : #define EDCF_LONG_M			BITFIELD_MASK(4)
buf : #define EDCF_LFB_M			BITFIELD_MASK(4)
buf : 
buf : #define RETRY_SHORT_DEF			7	/* Default Short retry Limit */
buf : #define RETRY_SHORT_MAX			255	/* Maximum Short retry Limit */
buf : #define RETRY_LONG_DEF			4	/* Default Long retry count */
buf : #define RETRY_SHORT_FB			3	/* Short count for fb rate */
for fb rate */ 
buf : #define RETRY_LONG_FB			2	/* Long count for fb rate */
buf : 
buf : #define APHY_CWMIN			15
buf : #define PHY_CWMAX			1023
buf : 
buf : #define EDCF_AIFSN_MIN			1
buf : 
buf : #define FRAGNUM_MASK			0xF
buf : 
buf : #define APHY_SLOT_TIME			9
buf : #define BPHY_SLOT_TIME			20
buf : 
buf : #define WL_SPURAVOID_OFF		0
buf : #define WL_SPURAVOID_ON1		1
buf : #define WL_SPURAVOID_ON2		2
buf : 
buf : /* invalid core flags, use the saved coreflags */
buf : #define BRCMS_USE_COREFLAGS		0xffffffff
buf : 
buf : /* values for PLCPHdr_override */
for PLCPHdr_override */ 
buf : #define BRCMS_PLCP_AUTO			-1
buf : #define BRCMS_PLCP_SHORT		0
buf : #define BRCMS_PLCP_LONG			1
buf : 
buf : /* values for g_protection_override and n_protection_override */
for g_protection_override and n_protection_override */ 
buf : #define BRCMS_PROTECTION_AUTO		-1
buf : #define BRCMS_PROTECTION_OFF		0
buf : #define BRCMS_PROTECTION_ON		1
buf : #define BRCMS_PROTECTION_MMHDR_ONLY	2
buf : #define BRCMS_PROTECTION_CTS_ONLY	3
buf : 
buf : /* values for g_protection_control and n_protection_control */
for g_protection_control and n_protection_control */ 
buf : #define BRCMS_PROTECTION_CTL_OFF	0
buf : #define BRCMS_PROTECTION_CTL_LOCAL	1
buf : #define BRCMS_PROTECTION_CTL_OVERLAP	2
buf : 
buf : /* values for n_protection */
for n_protection */ 
buf : #define BRCMS_N_PROTECTION_OFF		0
buf : #define BRCMS_N_PROTECTION_OPTIONAL	1
buf : #define BRCMS_N_PROTECTION_20IN40	2
buf : #define BRCMS_N_PROTECTION_MIXEDMODE	3
buf : 
buf : /* values for band specific 40MHz capabilities */
ific 40MHz capabilities */ 
buf : #define BRCMS_N_BW_20ALL		0
buf : #define BRCMS_N_BW_40ALL		1
buf : #define BRCMS_N_BW_20IN2G_40IN5G	2
buf : 
buf : /* bitflags for SGI support (sgi_rx iovar) */
for SGI support (sgi_rx iovar) */ 
buf : #define BRCMS_N_SGI_20			0x01
buf : #define BRCMS_N_SGI_40			0x02
buf : 
buf : /* defines used by the nrate iovar */
buf : /* MSC in use,indicates b0-6 holds an mcs */
buf : #define NRATE_MCS_INUSE			0x00000080
buf : /* rate/mcs value */
buf : #define NRATE_RATE_MASK			0x0000007f
buf : /* stf mode mask: siso, cdd, stbc, sdm */
buf : #define NRATE_STF_MASK			0x0000ff00
buf : /* stf mode shift */
ift */ 
buf : #define NRATE_STF_SHIFT			8
buf : /* bit indicate to override mcs only */
buf : #define NRATE_OVERRIDE_MCS_ONLY		0x40000000
buf : #define NRATE_SGI_MASK			0x00800000	/* sgi mode */
buf : #define NRATE_SGI_SHIFT			23		/* sgi mode */
buf : #define NRATE_LDPC_CODING		0x00400000	/* adv coding in use */
buf : #define NRATE_LDPC_SHIFT		22		/* ldpc shift */
ift */ 
buf : 
buf : #define NRATE_STF_SISO			0		/* stf mode SISO */
buf : #define NRATE_STF_CDD			1		/* stf mode CDD */
buf : #define NRATE_STF_STBC			2		/* stf mode STBC */
buf : #define NRATE_STF_SDM			3		/* stf mode SDM */
buf : 
buf : #define MAX_DMA_SEGS			4
buf : 
buf : /* # of entries in Tx FIFO */
buf : #define NTXD				64
buf : /* Max # of entries in Rx FIFO based on 4kb page size */
buf : #define NRXD				256
buf : 
buf : /* Amount of headroom to leave in Tx FIFO */
buf : #define TX_HEADROOM			4
buf : 
buf : /* try to keep this # rbufs posted to the chip */
buf : #define NRXBUFPOST			32
buf : 
buf : /* max # frames to process in brcms_c_recv() */
buf : #define RXBND				8
buf : /* max # tx status to process in wlc_txstatus() */
buf : #define TXSBND				8
buf : 
buf : /* brcmu_format_flags() bit description structure */
format_flags() bit description structure */ 
buf : struct brcms_c_bit_desc {
buf : 	u32 bit;
buf : 	const char *name;
buf : };
buf : 
buf : /*
buf :  * The following table lists the buffer memory allocated to xmt fifos in HW.
ifos in HW. 
buf :  * the size is in units of 256bytes(one block), total size is HW dependent
buf :  * ucode has default fifo partition, sw can overwrite if necessary
ifo partition, sw can overwrite if necessary 
buf :  *
buf :  * This is documented in twiki under the topic UcodeTxFifo. Please ensure
buf :  * the twiki is updated before making changes.
fore making changes. 
buf :  */
buf : 
buf : /* Starting corerev for the fifo size table */
ifo size table */ 
buf : #define XMTFIFOTBL_STARTREV	17
buf : 
buf : struct d11init {
buf : 	__le16 addr;
buf : 	__le16 size;
buf : 	__le32 value;
buf : };
buf : 
buf : struct edcf_acparam {
buf : 	u8 ACI;
buf : 	u8 ECW;
buf : 	u16 TXOP;
buf : } __packed;
buf : 
buf : /* debug/trace */
buf : uint brcm_msg_level;
buf : 
buf : /* TX FIFO number to WME/802.1E Access Category */
buf : static const u8 wme_fifo2ac[] = {
ifo2ac[] = { 
buf : 	IEEE80211_AC_BK,
buf : 	IEEE80211_AC_BE,
buf : 	IEEE80211_AC_VI,
buf : 	IEEE80211_AC_VO,
buf : 	IEEE80211_AC_BE,
buf : 	IEEE80211_AC_BE
buf : };
buf : 
buf : /* ieee80211 Access Category to TX FIFO number */
buf : static const u8 wme_ac2fifo[] = {
ifo[] = { 
buf : 	TX_AC_VO_FIFO,
buf : 	TX_AC_VI_FIFO,
buf : 	TX_AC_BE_FIFO,
buf : 	TX_AC_BK_FIFO
buf : };
buf : 
buf : static const u16 xmtfifo_sz[][NFIFO] = {
ifo_sz[][NFIFO] = { 
buf : 	/* corerev 17: 5120, 49152, 49152, 5376, 4352, 1280 */
buf : 	{20, 192, 192, 21, 17, 5},
buf : 	/* corerev 18: */
buf : 	{0, 0, 0, 0, 0, 0},
buf : 	/* corerev 19: */
buf : 	{0, 0, 0, 0, 0, 0},
buf : 	/* corerev 20: 5120, 49152, 49152, 5376, 4352, 1280 */
buf : 	{20, 192, 192, 21, 17, 5},
buf : 	/* corerev 21: 2304, 14848, 5632, 3584, 3584, 1280 */
buf : 	{9, 58, 22, 14, 14, 5},
buf : 	/* corerev 22: 5120, 49152, 49152, 5376, 4352, 1280 */
buf : 	{20, 192, 192, 21, 17, 5},
buf : 	/* corerev 23: 5120, 49152, 49152, 5376, 4352, 1280 */
buf : 	{20, 192, 192, 21, 17, 5},
buf : 	/* corerev 24: 2304, 14848, 5632, 3584, 3584, 1280 */
buf : 	{9, 58, 22, 14, 14, 5},
buf : 	/* corerev 25: */
buf : 	{0, 0, 0, 0, 0, 0},
buf : 	/* corerev 26: */
buf : 	{0, 0, 0, 0, 0, 0},
buf : 	/* corerev 27: */
buf : 	{0, 0, 0, 0, 0, 0},
buf : 	/* corerev 28: 2304, 14848, 5632, 3584, 3584, 1280 */
buf : 	{9, 58, 22, 14, 14, 5},
buf : };
buf : 
buf : #ifdef DEBUG
ifdef DEBUG 
buf : static const char * const fifo_names[] = {
buf : 	"AC_BK", "AC_BE", "AC_VI", "AC_VO", "BCMC", "ATIM" };
buf : #else
buf : static const char fifo_names[6][0];
ifo_names[6][0]; 
buf : #endif
buf : 
buf : #ifdef DEBUG
ifdef DEBUG 
buf : /* pointer to most recently allocated wl/wlc */
buf : static struct brcms_c_info *wlc_info_dbg = (struct brcms_c_info *) (NULL);
buf : #endif
if 
buf : 
buf : /* Mapping of ieee80211 AC numbers to tx fifos */
buf : static const u8 ac_to_fifo_mapping[IEEE80211_NUM_ACS] = {
ifo_mapping[IEEE80211_NUM_ACS] = { 
buf : 	[IEEE80211_AC_VO]	= TX_AC_VO_FIFO,
buf : 	[IEEE80211_AC_VI]	= TX_AC_VI_FIFO,
buf : 	[IEEE80211_AC_BE]	= TX_AC_BE_FIFO,
buf : 	[IEEE80211_AC_BK]	= TX_AC_BK_FIFO,
buf : };
buf : 
buf : /* Mapping of tx fifos to ieee80211 AC numbers */
ifos to ieee80211 AC numbers */ 
buf : static const u8 fifo_to_ac_mapping[IEEE80211_NUM_ACS] = {
buf : 	[TX_AC_BK_FIFO]	= IEEE80211_AC_BK,
buf : 	[TX_AC_BE_FIFO]	= IEEE80211_AC_BE,
buf : 	[TX_AC_VI_FIFO]	= IEEE80211_AC_VI,
buf : 	[TX_AC_VO_FIFO]	= IEEE80211_AC_VO,
buf : };
buf : 
buf : static u8 brcms_ac_to_fifo(u8 ac)
ifo(u8 ac) 
buf : {
buf : 	if (ac >= ARRAY_SIZE(ac_to_fifo_mapping))
buf : 		return TX_AC_BE_FIFO;
buf : 	return ac_to_fifo_mapping[ac];
ifo_mapping[ac]; 
buf : }
buf : 
buf : static u8 brcms_fifo_to_ac(u8 fifo)
buf : {
buf : 	if (fifo >= ARRAY_SIZE(fifo_to_ac_mapping))
if (fifo >= ARRAY_SIZE(fifo_to_ac_mapping)) 
buf : 		return IEEE80211_AC_BE;
buf : 	return fifo_to_ac_mapping[fifo];
ifo_to_ac_mapping[fifo]; 
buf : }
buf : 
buf : /* Find basic rate for a given rate */
for a given rate */ 
buf : static u8 brcms_basic_rate(struct brcms_c_info *wlc, u32 rspec)
buf : {
buf : 	if (is_mcs_rate(rspec))
if (is_mcs_rate(rspec)) 
buf : 		return wlc->band->basic_rate[mcs_table[rspec & RSPEC_RATE_MASK]
buf : 		       .leg_ofdm];
buf : 	return wlc->band->basic_rate[rspec & RSPEC_RATE_MASK];
buf : }
buf : 
buf : static u16 frametype(u32 rspec, u8 mimoframe)
buf : {
buf : 	if (is_mcs_rate(rspec))
if (is_mcs_rate(rspec)) 
buf : 		return mimoframe;
buf : 	return is_cck_rate(rspec) ? FT_CCK : FT_OFDM;
buf : }
buf : 
buf : /* currently the best mechanism for determining SIFS is the band in use */
for determining SIFS is the band in use */ 
buf : static u16 get_sifs(struct brcms_band *band)
buf : {
buf : 	return band->bandtype == BRCM_BAND_5G ? APHY_SIFS_TIME :
buf : 				 BPHY_SIFS_TIME;
buf : }
buf : 
buf : /*
buf :  * Detect Card removed.
buf :  * Even checking an sbconfig register read will not false trigger when the core
buf :  * is in reset it breaks CF address mechanism. Accessing gphy phyversion will
buf :  * cause SB error if aphy is in reset on 4306B0-DB. Need a simple accessible
if aphy is in reset on 4306B0-DB. Need a simple accessible 
buf :  * reg with fixed 0/1 pattern (some platforms return all 0).
forms return all 0). 
buf :  * If clocks are present, call the sb routine which will figure out if the
buf :  * device is removed.
buf :  */
buf : static bool brcms_deviceremoved(struct brcms_c_info *wlc)
buf : {
buf : 	u32 macctrl;
buf : 
buf : 	if (!wlc->hw->clk)
if (!wlc->hw->clk) 
buf : 		return ai_deviceremoved(wlc->hw->sih);
buf : 	macctrl = bcma_read32(wlc->hw->d11core,
buf : 			      D11REGOFFS(maccontrol));
buf : 	return (macctrl & (MCTL_PSM_JMP_0 | MCTL_IHR_EN)) != MCTL_IHR_EN;
buf : }
buf : 
buf : /* sum the individual fifo tx pending packet counts */
ifo tx pending packet counts */ 
buf : static int brcms_txpktpendtot(struct brcms_c_info *wlc)
buf : {
buf : 	int i;
buf : 	int pending = 0;
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(wlc->hw->di); i++)
for (i = 0; i < ARRAY_SIZE(wlc->hw->di); i++) 
buf : 		if (wlc->hw->di[i])
buf : 			pending += dma_txpending(wlc->hw->di[i]);
buf : 	return pending;
buf : }
buf : 
buf : static bool brcms_is_mband_unlocked(struct brcms_c_info *wlc)
buf : {
buf : 	return wlc->pub->_nbands > 1 && !wlc->bandlocked;
buf : }
buf : 
buf : static int brcms_chspec_bw(u16 chanspec)
buf : {
buf : 	if (CHSPEC_IS40(chanspec))
if (CHSPEC_IS40(chanspec)) 
buf : 		return BRCMS_40_MHZ;
buf : 	if (CHSPEC_IS20(chanspec))
if (CHSPEC_IS20(chanspec)) 
buf : 		return BRCMS_20_MHZ;
buf : 
buf : 	return BRCMS_10_MHZ;
buf : }
buf : 
buf : static void brcms_c_bsscfg_mfree(struct brcms_bss_cfg *cfg)
buf : {
buf : 	if (cfg == NULL)
if (cfg == NULL) 
buf : 		return;
buf : 
buf : 	kfree(cfg->current_bss);
buf : 	kfree(cfg);
buf : }
buf : 
buf : static void brcms_c_detach_mfree(struct brcms_c_info *wlc)
buf : {
buf : 	if (wlc == NULL)
if (wlc == NULL) 
buf : 		return;
buf : 
buf : 	brcms_c_bsscfg_mfree(wlc->bsscfg);
buf : 	kfree(wlc->pub);
buf : 	kfree(wlc->modulecb);
buf : 	kfree(wlc->default_bss);
buf : 	kfree(wlc->protection);
buf : 	kfree(wlc->stf);
buf : 	kfree(wlc->bandstate[0]);
buf : 	kfree(wlc->corestate->macstat_snapshot);
buf : 	kfree(wlc->corestate);
buf : 	kfree(wlc->hw->bandstate[0]);
buf : 	kfree(wlc->hw);
buf : 	if (wlc->beacon)
if (wlc->beacon) 
buf : 		dev_kfree_skb_any(wlc->beacon);
buf : 	if (wlc->probe_resp)
if (wlc->probe_resp) 
buf : 		dev_kfree_skb_any(wlc->probe_resp);
buf : 
buf : 	/* free the wlc */
buf : 	kfree(wlc);
buf : 	wlc = NULL;
buf : }
buf : 
buf : static struct brcms_bss_cfg *brcms_c_bsscfg_malloc(uint unit)
buf : {
buf : 	struct brcms_bss_cfg *cfg;
buf : 
buf : 	cfg = kzalloc(sizeof(struct brcms_bss_cfg), GFP_ATOMIC);
buf : 	if (cfg == NULL)
if (cfg == NULL) 
buf : 		goto fail;
buf : 
buf : 	cfg->current_bss = kzalloc(sizeof(struct brcms_bss_info), GFP_ATOMIC);
buf : 	if (cfg->current_bss == NULL)
if (cfg->current_bss == NULL) 
buf : 		goto fail;
buf : 
buf : 	return cfg;
buf : 
buf :  fail:
buf : 	brcms_c_bsscfg_mfree(cfg);
buf : 	return NULL;
buf : }
buf : 
buf : static struct brcms_c_info *
buf : brcms_c_attach_malloc(uint unit, uint *err, uint devid)
buf : {
buf : 	struct brcms_c_info *wlc;
buf : 
buf : 	wlc = kzalloc(sizeof(struct brcms_c_info), GFP_ATOMIC);
buf : 	if (wlc == NULL) {
if (wlc == NULL) { 
buf : 		*err = 1002;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	/* allocate struct brcms_c_pub state structure */
buf : 	wlc->pub = kzalloc(sizeof(struct brcms_pub), GFP_ATOMIC);
buf : 	if (wlc->pub == NULL) {
if (wlc->pub == NULL) { 
buf : 		*err = 1003;
buf : 		goto fail;
buf : 	}
buf : 	wlc->pub->wlc = wlc;
buf : 
buf : 	/* allocate struct brcms_hardware state structure */
buf : 
buf : 	wlc->hw = kzalloc(sizeof(struct brcms_hardware), GFP_ATOMIC);
buf : 	if (wlc->hw == NULL) {
if (wlc->hw == NULL) { 
buf : 		*err = 1005;
buf : 		goto fail;
buf : 	}
buf : 	wlc->hw->wlc = wlc;
buf : 
buf : 	wlc->hw->bandstate[0] =
buf : 		kzalloc(sizeof(struct brcms_hw_band) * MAXBANDS, GFP_ATOMIC);
buf : 	if (wlc->hw->bandstate[0] == NULL) {
if (wlc->hw->bandstate[0] == NULL) { 
buf : 		*err = 1006;
buf : 		goto fail;
buf : 	} else {
buf : 		int i;
buf : 
buf : 		for (i = 1; i < MAXBANDS; i++)
for (i = 1; i < MAXBANDS; i++) 
buf : 			wlc->hw->bandstate[i] = (struct brcms_hw_band *)
buf : 			    ((unsigned long)wlc->hw->bandstate[0] +
buf : 			     (sizeof(struct brcms_hw_band) * i));
buf : 	}
buf : 
buf : 	wlc->modulecb =
buf : 		kzalloc(sizeof(struct modulecb) * BRCMS_MAXMODULES, GFP_ATOMIC);
buf : 	if (wlc->modulecb == NULL) {
if (wlc->modulecb == NULL) { 
buf : 		*err = 1009;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	wlc->default_bss = kzalloc(sizeof(struct brcms_bss_info), GFP_ATOMIC);
buf : 	if (wlc->default_bss == NULL) {
if (wlc->default_bss == NULL) { 
buf : 		*err = 1010;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	wlc->bsscfg = brcms_c_bsscfg_malloc(unit);
buf : 	if (wlc->bsscfg == NULL) {
if (wlc->bsscfg == NULL) { 
buf : 		*err = 1011;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	wlc->protection = kzalloc(sizeof(struct brcms_protection),
buf : 				  GFP_ATOMIC);
buf : 	if (wlc->protection == NULL) {
if (wlc->protection == NULL) { 
buf : 		*err = 1016;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	wlc->stf = kzalloc(sizeof(struct brcms_stf), GFP_ATOMIC);
buf : 	if (wlc->stf == NULL) {
if (wlc->stf == NULL) { 
buf : 		*err = 1017;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	wlc->bandstate[0] =
buf : 		kzalloc(sizeof(struct brcms_band)*MAXBANDS, GFP_ATOMIC);
buf : 	if (wlc->bandstate[0] == NULL) {
if (wlc->bandstate[0] == NULL) { 
buf : 		*err = 1025;
buf : 		goto fail;
buf : 	} else {
buf : 		int i;
buf : 
buf : 		for (i = 1; i < MAXBANDS; i++)
for (i = 1; i < MAXBANDS; i++) 
buf : 			wlc->bandstate[i] = (struct brcms_band *)
buf : 				((unsigned long)wlc->bandstate[0]
buf : 				+ (sizeof(struct brcms_band)*i));
buf : 	}
buf : 
buf : 	wlc->corestate = kzalloc(sizeof(struct brcms_core), GFP_ATOMIC);
buf : 	if (wlc->corestate == NULL) {
if (wlc->corestate == NULL) { 
buf : 		*err = 1026;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	wlc->corestate->macstat_snapshot =
buf : 		kzalloc(sizeof(struct macstat), GFP_ATOMIC);
buf : 	if (wlc->corestate->macstat_snapshot == NULL) {
if (wlc->corestate->macstat_snapshot == NULL) { 
buf : 		*err = 1027;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	return wlc;
buf : 
buf :  fail:
buf : 	brcms_c_detach_mfree(wlc);
buf : 	return NULL;
buf : }
buf : 
buf : /*
buf :  * Update the slot timing for standard 11b/g (20us slots)
for standard 11b/g (20us slots) 
buf :  * or shortslot 11g (9us slots)
buf :  * The PSM needs to be suspended for this call.
for this call. 
buf :  */
buf : static void brcms_b_update_slot_timing(struct brcms_hardware *wlc_hw,
buf : 					bool shortslot)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 
buf : 	if (shortslot) {
if (shortslot) { 
buf : 		/* 11g short slot: 11a timing */
buf : 		bcma_write16(core, D11REGOFFS(ifs_slot), 0x0207);
ifs_slot), 0x0207); 
buf : 		brcms_b_write_shm(wlc_hw, M_DOT11_SLOT, APHY_SLOT_TIME);
buf : 	} else {
buf : 		/* 11g long slot: 11b timing */
buf : 		bcma_write16(core, D11REGOFFS(ifs_slot), 0x0212);
ifs_slot), 0x0212); 
buf : 		brcms_b_write_shm(wlc_hw, M_DOT11_SLOT, BPHY_SLOT_TIME);
buf : 	}
buf : }
buf : 
buf : /*
buf :  * calculate frame duration of a given rate and length, return
buf :  * time in usec unit
buf :  */
buf : static uint brcms_c_calc_frame_time(struct brcms_c_info *wlc, u32 ratespec,
buf : 				    u8 preamble_type, uint mac_len)
buf : {
buf : 	uint nsyms, dur = 0, Ndps, kNdps;
buf : 	uint rate = rspec2rate(ratespec);
buf : 
buf : 	if (rate == 0) {
if (rate == 0) { 
buf : 		brcms_err(wlc->hw->d11core, "wl%d: WAR: using rate of 1 mbps\n",
buf : 			  wlc->pub->unit);
buf : 		rate = BRCM_RATE_1M;
buf : 	}
buf : 
buf : 	if (is_mcs_rate(ratespec)) {
if (is_mcs_rate(ratespec)) { 
buf : 		uint mcs = ratespec & RSPEC_RATE_MASK;
buf : 		int tot_streams = mcs_2_txstreams(mcs) + rspec_stc(ratespec);
buf : 
buf : 		dur = PREN_PREAMBLE + (tot_streams * PREN_PREAMBLE_EXT);
buf : 		if (preamble_type == BRCMS_MM_PREAMBLE)
if (preamble_type == BRCMS_MM_PREAMBLE) 
buf : 			dur += PREN_MM_EXT;
buf : 		/* 1000Ndbps = kbps * 4 */
buf : 		kNdps = mcs_2_rate(mcs, rspec_is40mhz(ratespec),
buf : 				   rspec_issgi(ratespec)) * 4;
buf : 
buf : 		if (rspec_stc(ratespec) == 0)
if (rspec_stc(ratespec) == 0) 
buf : 			nsyms =
buf : 			    CEIL((APHY_SERVICE_NBITS + 8 * mac_len +
buf : 				  APHY_TAIL_NBITS) * 1000, kNdps);
buf : 		else
buf : 			/* STBC needs to have even number of symbols */
buf : 			nsyms =
buf : 			    2 *
buf : 			    CEIL((APHY_SERVICE_NBITS + 8 * mac_len +
buf : 				  APHY_TAIL_NBITS) * 1000, 2 * kNdps);
buf : 
buf : 		dur += APHY_SYMBOL_TIME * nsyms;
buf : 		if (wlc->band->bandtype == BRCM_BAND_2G)
if (wlc->band->bandtype == BRCM_BAND_2G) 
buf : 			dur += DOT11_OFDM_SIGNAL_EXTENSION;
buf : 	} else if (is_ofdm_rate(rate)) {
if (is_ofdm_rate(rate)) { 
buf : 		dur = APHY_PREAMBLE_TIME;
buf : 		dur += APHY_SIGNAL_TIME;
buf : 		/* Ndbps = Mbps * 4 = rate(500Kbps) * 2 */
buf : 		Ndps = rate * 2;
buf : 		/* NSyms = CEILING((SERVICE + 8*NBytes + TAIL) / Ndbps) */
buf : 		nsyms =
buf : 		    CEIL((APHY_SERVICE_NBITS + 8 * mac_len + APHY_TAIL_NBITS),
buf : 			 Ndps);
buf : 		dur += APHY_SYMBOL_TIME * nsyms;
buf : 		if (wlc->band->bandtype == BRCM_BAND_2G)
if (wlc->band->bandtype == BRCM_BAND_2G) 
buf : 			dur += DOT11_OFDM_SIGNAL_EXTENSION;
buf : 	} else {
buf : 		/*
buf : 		 * calc # bits * 2 so factor of 2 in rate (1/2 mbps)
buf : 		 * will divide out
buf : 		 */
buf : 		mac_len = mac_len * 8 * 2;
buf : 		/* calc ceiling of bits/rate = microseconds of air time */
buf : 		dur = (mac_len + rate - 1) / rate;
buf : 		if (preamble_type & BRCMS_SHORT_PREAMBLE)
if (preamble_type & BRCMS_SHORT_PREAMBLE) 
buf : 			dur += BPHY_PLCP_SHORT_TIME;
buf : 		else
buf : 			dur += BPHY_PLCP_TIME;
buf : 	}
buf : 	return dur;
buf : }
buf : 
buf : static void brcms_c_write_inits(struct brcms_hardware *wlc_hw,
buf : 				const struct d11init *inits)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	int i;
buf : 	uint offset;
buf : 	u16 size;
buf : 	u32 value;
buf : 
buf : 	brcms_dbg_info(wlc_hw->d11core, "wl%d\n", wlc_hw->unit);
buf : 
buf : 	for (i = 0; inits[i].addr != cpu_to_le16(0xffff); i++) {
for (i = 0; inits[i].addr != cpu_to_le16(0xffff); i++) { 
buf : 		size = le16_to_cpu(inits[i].size);
buf : 		offset = le16_to_cpu(inits[i].addr);
buf : 		value = le32_to_cpu(inits[i].value);
buf : 		if (size == 2)
if (size == 2) 
buf : 			bcma_write16(core, offset, value);
buf : 		else if (size == 4)
if (size == 4) 
buf : 			bcma_write32(core, offset, value);
buf : 		else
buf : 			break;
buf : 	}
buf : }
buf : 
buf : static void brcms_c_write_mhf(struct brcms_hardware *wlc_hw, u16 *mhfs)
buf : {
buf : 	u8 idx;
buf : 	u16 addr[] = {
buf : 		M_HOST_FLAGS1, M_HOST_FLAGS2, M_HOST_FLAGS3, M_HOST_FLAGS4,
buf : 		M_HOST_FLAGS5
buf : 	};
buf : 
buf : 	for (idx = 0; idx < MHFMAX; idx++)
for (idx = 0; idx < MHFMAX; idx++) 
buf : 		brcms_b_write_shm(wlc_hw, addr[idx], mhfs[idx]);
buf : }
buf : 
buf : static void brcms_c_ucode_bsinit(struct brcms_hardware *wlc_hw)
buf : {
buf : 	struct brcms_ucode *ucode = &wlc_hw->wlc->wl->ucode;
buf : 
buf : 	/* init microcode host flags */
buf : 	brcms_c_write_mhf(wlc_hw, wlc_hw->band->mhfs);
buf : 
buf : 	/* do band-specific ucode IHR, SHM, and SCR inits */
ific ucode IHR, SHM, and SCR inits */ 
buf : 	if (D11REV_IS(wlc_hw->corerev, 17) || D11REV_IS(wlc_hw->corerev, 23)) {
buf : 		if (BRCMS_ISNPHY(wlc_hw->band))
if (BRCMS_ISNPHY(wlc_hw->band)) 
buf : 			brcms_c_write_inits(wlc_hw, ucode->d11n0bsinitvals16);
buf : 		else
buf : 			brcms_err(wlc_hw->d11core,
buf : 				  "%s: wl%d: unsupported phy in corerev %d\n",
buf : 				  __func__, wlc_hw->unit,
buf : 				  wlc_hw->corerev);
buf : 	} else {
buf : 		if (D11REV_IS(wlc_hw->corerev, 24)) {
if (D11REV_IS(wlc_hw->corerev, 24)) { 
buf : 			if (BRCMS_ISLCNPHY(wlc_hw->band))
buf : 				brcms_c_write_inits(wlc_hw,
buf : 						    ucode->d11lcn0bsinitvals24);
buf : 			else
buf : 				brcms_err(wlc_hw->d11core,
buf : 					  "%s: wl%d: unsupported phy in core rev %d\n",
buf : 					  __func__, wlc_hw->unit,
buf : 					  wlc_hw->corerev);
buf : 		} else {
buf : 			brcms_err(wlc_hw->d11core,
buf : 				  "%s: wl%d: unsupported corerev %d\n",
buf : 				  __func__, wlc_hw->unit, wlc_hw->corerev);
buf : 		}
buf : 	}
buf : }
buf : 
buf : static void brcms_b_core_ioctl(struct brcms_hardware *wlc_hw, u32 m, u32 v)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u32 ioctl = bcma_aread32(core, BCMA_IOCTL) & ~m;
buf : 
buf : 	bcma_awrite32(core, BCMA_IOCTL, ioctl | v);
buf : }
buf : 
buf : static void brcms_b_core_phy_clk(struct brcms_hardware *wlc_hw, bool clk)
buf : {
buf : 	brcms_dbg_info(wlc_hw->d11core, "wl%d: clk %d\n", wlc_hw->unit, clk);
buf : 
buf : 	wlc_hw->phyclk = clk;
buf : 
buf : 	if (OFF == clk) {	/* clear gmode bit, put phy into reset */
if (OFF == clk) {	/* clear gmode bit, put phy into reset */ 
buf : 
buf : 		brcms_b_core_ioctl(wlc_hw, (SICF_PRST | SICF_FGC | SICF_GMODE),
buf : 				   (SICF_PRST | SICF_FGC));
buf : 		udelay(1);
buf : 		brcms_b_core_ioctl(wlc_hw, (SICF_PRST | SICF_FGC), SICF_PRST);
buf : 		udelay(1);
buf : 
buf : 	} else {		/* take phy out of reset */
buf : 
buf : 		brcms_b_core_ioctl(wlc_hw, (SICF_PRST | SICF_FGC), SICF_FGC);
buf : 		udelay(1);
buf : 		brcms_b_core_ioctl(wlc_hw, SICF_FGC, 0);
buf : 		udelay(1);
buf : 
buf : 	}
buf : }
buf : 
buf : /* low-level band switch utility routine */
buf : static void brcms_c_setxband(struct brcms_hardware *wlc_hw, uint bandunit)
buf : {
buf : 	brcms_dbg_mac80211(wlc_hw->d11core, "wl%d: bandunit %d\n", wlc_hw->unit,
buf : 			   bandunit);
buf : 
buf : 	wlc_hw->band = wlc_hw->bandstate[bandunit];
buf : 
buf : 	/*
buf : 	 * BMAC_NOTE:
buf : 	 *   until we eliminate need for wlc->band refs in low level code
for wlc->band refs in low level code 
buf : 	 */
buf : 	wlc_hw->wlc->band = wlc_hw->wlc->bandstate[bandunit];
buf : 
buf : 	/* set gmode core flag */
buf : 	if (wlc_hw->sbclk && !wlc_hw->noreset) {
if (wlc_hw->sbclk && !wlc_hw->noreset) { 
buf : 		u32 gmode = 0;
buf : 
buf : 		if (bandunit == 0)
if (bandunit == 0) 
buf : 			gmode = SICF_GMODE;
buf : 
buf : 		brcms_b_core_ioctl(wlc_hw, SICF_GMODE, gmode);
buf : 	}
buf : }
buf : 
buf : /* switch to new band but leave it inactive */
buf : static u32 brcms_c_setband_inact(struct brcms_c_info *wlc, uint bandunit)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	u32 macintmask;
buf : 	u32 macctrl;
buf : 
buf : 	brcms_dbg_mac80211(wlc_hw->d11core, "wl%d\n", wlc_hw->unit);
buf : 	macctrl = bcma_read32(wlc_hw->d11core,
buf : 			      D11REGOFFS(maccontrol));
buf : 	WARN_ON((macctrl & MCTL_EN_MAC) != 0);
buf : 
buf : 	/* disable interrupts */
buf : 	macintmask = brcms_intrsoff(wlc->wl);
buf : 
buf : 	/* radio off */
buf : 	wlc_phy_switch_radio(wlc_hw->band->pi, OFF);
buf : 
buf : 	brcms_b_core_phy_clk(wlc_hw, OFF);
buf : 
buf : 	brcms_c_setxband(wlc_hw, bandunit);
buf : 
buf : 	return macintmask;
buf : }
buf : 
buf : /* process an individual struct tx_status */
buf : static bool
buf : brcms_c_dotxstatus(struct brcms_c_info *wlc, struct tx_status *txs)
buf : {
buf : 	struct sk_buff *p = NULL;
buf : 	uint queue = NFIFO;
buf : 	struct dma_pub *dma = NULL;
buf : 	struct d11txh *txh = NULL;
buf : 	struct scb *scb = NULL;
buf : 	bool free_pdu;
buf : 	int tx_rts, tx_frame_count, tx_rts_count;
buf : 	uint totlen, supr_status;
buf : 	bool lastframe;
buf : 	struct ieee80211_hdr *h;
buf : 	u16 mcl;
buf : 	struct ieee80211_tx_info *tx_info;
buf : 	struct ieee80211_tx_rate *txrate;
buf : 	int i;
buf : 	bool fatal = true;
buf : 
buf : 	trace_brcms_txstatus(&wlc->hw->d11core->dev, txs->framelen,
buf : 			     txs->frameid, txs->status, txs->lasttxtime,
buf : 			     txs->sequence, txs->phyerr, txs->ackphyrxsh);
buf : 
buf : 	/* discard intermediate indications for ucode with one legitimate case:
for ucode with one legitimate case: 
buf : 	 *   e.g. if "useRTS" is set. ucode did a successful rts/cts exchange,
buf : 	 *   but the subsequent tx of DATA failed. so it will start rts/cts
buf : 	 *   from the beginning (resetting the rts transmission count)
buf : 	 */
buf : 	if (!(txs->status & TX_STATUS_AMPDU)
if (!(txs->status & TX_STATUS_AMPDU) 
buf : 	    && (txs->status & TX_STATUS_INTERMEDIATE)) {
buf : 		brcms_dbg_tx(wlc->hw->d11core, "INTERMEDIATE but not AMPDU\n");
buf : 		fatal = false;
buf : 		goto out;
buf : 	}
buf : 
buf : 	queue = txs->frameid & TXFID_QUEUE_MASK;
buf : 	if (queue >= NFIFO) {
if (queue >= NFIFO) { 
buf : 		brcms_err(wlc->hw->d11core, "queue %u >= NFIFO\n", queue);
buf : 		goto out;
buf : 	}
buf : 
buf : 	dma = wlc->hw->di[queue];
buf : 
buf : 	p = dma_getnexttxp(wlc->hw->di[queue], DMA_RANGE_TRANSMITTED);
buf : 	if (p == NULL) {
if (p == NULL) { 
buf : 		brcms_err(wlc->hw->d11core, "dma_getnexttxp returned null!\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	txh = (struct d11txh *) (p->data);
buf : 	mcl = le16_to_cpu(txh->MacTxControlLow);
buf : 
buf : 	if (txs->phyerr)
if (txs->phyerr) 
buf : 		brcms_dbg_tx(wlc->hw->d11core, "phyerr 0x%x, rate 0x%x\n",
buf : 			     txs->phyerr, txh->MainRates);
buf : 
buf : 	if (txs->frameid != le16_to_cpu(txh->TxFrameID)) {
if (txs->frameid != le16_to_cpu(txh->TxFrameID)) { 
buf : 		brcms_err(wlc->hw->d11core, "frameid != txh->TxFrameID\n");
buf : 		goto out;
buf : 	}
buf : 	tx_info = IEEE80211_SKB_CB(p);
buf : 	h = (struct ieee80211_hdr *)((u8 *) (txh + 1) + D11_PHY_HDR_LEN);
buf : 
buf : 	if (tx_info->rate_driver_data[0])
if (tx_info->rate_driver_data[0]) 
buf : 		scb = &wlc->pri_scb;
buf : 
buf : 	if (tx_info->flags & IEEE80211_TX_CTL_AMPDU) {
if (tx_info->flags & IEEE80211_TX_CTL_AMPDU) { 
buf : 		brcms_c_ampdu_dotxstatus(wlc->ampdu, scb, p, txs);
buf : 		fatal = false;
buf : 		goto out;
buf : 	}
buf : 
buf : 	/*
buf : 	 * brcms_c_ampdu_dotxstatus() will trace tx descriptors for AMPDU
for AMPDU 
buf : 	 * frames; this traces them for the rest.
buf : 	 */
buf : 	trace_brcms_txdesc(&wlc->hw->d11core->dev, txh, sizeof(*txh));
buf : 
buf : 	supr_status = txs->status & TX_STATUS_SUPR_MASK;
buf : 	if (supr_status == TX_STATUS_SUPR_BADCH) {
if (supr_status == TX_STATUS_SUPR_BADCH) { 
buf : 		unsigned xfts = le16_to_cpu(txh->XtraFrameTypes);
buf : 		brcms_dbg_tx(wlc->hw->d11core,
buf : 			     "Pkt tx suppressed, dest chan %u, current %d\n",
buf : 			     (xfts >> XFTS_CHANNEL_SHIFT) & 0xff,
buf : 			     CHSPEC_CHANNEL(wlc->default_bss->chanspec));
buf : 	}
buf : 
buf : 	tx_rts = le16_to_cpu(txh->MacTxControlLow) & TXC_SENDRTS;
buf : 	tx_frame_count =
buf : 	    (txs->status & TX_STATUS_FRM_RTX_MASK) >> TX_STATUS_FRM_RTX_SHIFT;
buf : 	tx_rts_count =
buf : 	    (txs->status & TX_STATUS_RTS_RTX_MASK) >> TX_STATUS_RTS_RTX_SHIFT;
buf : 
buf : 	lastframe = !ieee80211_has_morefrags(h->frame_control);
buf : 
buf : 	if (!lastframe) {
if (!lastframe) { 
buf : 		brcms_err(wlc->hw->d11core, "Not last frame!\n");
buf : 	} else {
buf : 		/*
buf : 		 * Set information to be consumed by Minstrel ht.
formation to be consumed by Minstrel ht. 
buf : 		 *
buf : 		 * The "fallback limit" is the number of tx attempts a given
buf : 		 * MPDU is sent at the "primary" rate. Tx attempts beyond that
buf : 		 * limit are sent at the "secondary" rate.
buf : 		 * A 'short frame' does not exceed RTS treshold.
buf : 		 */
buf : 		u16 sfbl,	/* Short Frame Rate Fallback Limit */
buf : 		    lfbl,	/* Long Frame Rate Fallback Limit */
buf : 		    fbl;
buf : 
buf : 		if (queue < IEEE80211_NUM_ACS) {
if (queue < IEEE80211_NUM_ACS) { 
buf : 			sfbl = GFIELD(wlc->wme_retries[wme_fifo2ac[queue]],
buf : 				      EDCF_SFB);
buf : 			lfbl = GFIELD(wlc->wme_retries[wme_fifo2ac[queue]],
ifo2ac[queue]], 
buf : 				      EDCF_LFB);
buf : 		} else {
buf : 			sfbl = wlc->SFBL;
buf : 			lfbl = wlc->LFBL;
buf : 		}
buf : 
buf : 		txrate = tx_info->status.rates;
buf : 		if (txrate[0].flags & IEEE80211_TX_RC_USE_RTS_CTS)
if (txrate[0].flags & IEEE80211_TX_RC_USE_RTS_CTS) 
buf : 			fbl = lfbl;
buf : 		else
buf : 			fbl = sfbl;
buf : 
buf : 		ieee80211_tx_info_clear_status(tx_info);
buf : 
buf : 		if ((tx_frame_count > fbl) && (txrate[1].idx >= 0)) {
if ((tx_frame_count > fbl) && (txrate[1].idx >= 0)) { 
buf : 			/*
buf : 			 * rate selection requested a fallback rate
buf : 			 * and we used it
buf : 			 */
buf : 			txrate[0].count = fbl;
buf : 			txrate[1].count = tx_frame_count - fbl;
buf : 		} else {
buf : 			/*
buf : 			 * rate selection did not request fallback rate, or
buf : 			 * we didn't need it
buf : 			 */
buf : 			txrate[0].count = tx_frame_count;
buf : 			/*
buf : 			 * rc80211_minstrel.c:minstrel_tx_status() expects
buf : 			 * unused rates to be marked with idx = -1
buf : 			 */
buf : 			txrate[1].idx = -1;
buf : 			txrate[1].count = 0;
buf : 		}
buf : 
buf : 		/* clear the rest of the rates */
buf : 		for (i = 2; i < IEEE80211_TX_MAX_RATES; i++) {
for (i = 2; i < IEEE80211_TX_MAX_RATES; i++) { 
buf : 			txrate[i].idx = -1;
buf : 			txrate[i].count = 0;
buf : 		}
buf : 
buf : 		if (txs->status & TX_STATUS_ACK_RCV)
if (txs->status & TX_STATUS_ACK_RCV) 
buf : 			tx_info->flags |= IEEE80211_TX_STAT_ACK;
buf : 	}
buf : 
buf : 	totlen = p->len;
buf : 	free_pdu = true;
buf : 
buf : 	if (lastframe) {
if (lastframe) { 
buf : 		/* remove PLCP & Broadcom tx descriptor header */
buf : 		skb_pull(p, D11_PHY_HDR_LEN);
buf : 		skb_pull(p, D11_TXH_LEN);
buf : 		ieee80211_tx_status_irqsafe(wlc->pub->ieee_hw, p);
buf : 	} else {
buf : 		brcms_err(wlc->hw->d11core,
buf : 			  "%s: Not last frame => not calling tx_status\n",
buf : 			  __func__);
buf : 	}
buf : 
buf : 	fatal = false;
buf : 
buf :  out:
buf : 	if (fatal) {
if (fatal) { 
buf : 		if (txh)
buf : 			trace_brcms_txdesc(&wlc->hw->d11core->dev, txh,
buf : 					   sizeof(*txh));
buf : 		if (p)
if (p) 
buf : 			brcmu_pkt_buf_free_skb(p);
buf : 	}
buf : 
buf : 	if (dma && queue < NFIFO) {
if (dma && queue < NFIFO) { 
buf : 		u16 ac_queue = brcms_fifo_to_ac(queue);
buf : 		if (dma->txavail > TX_HEADROOM && queue < TX_BCMC_FIFO &&
if (dma->txavail > TX_HEADROOM && queue < TX_BCMC_FIFO && 
buf : 		    ieee80211_queue_stopped(wlc->pub->ieee_hw, ac_queue))
buf : 			ieee80211_wake_queue(wlc->pub->ieee_hw, ac_queue);
buf : 		dma_kick_tx(dma);
buf : 	}
buf : 
buf : 	return fatal;
buf : }
buf : 
buf : /* process tx completion events in BMAC
buf :  * Return true if more tx status need to be processed. false otherwise.
if more tx status need to be processed. false otherwise. 
buf :  */
buf : static bool
buf : brcms_b_txstatus(struct brcms_hardware *wlc_hw, bool bound, bool *fatal)
buf : {
buf : 	struct bcma_device *core;
buf : 	struct tx_status txstatus, *txs;
buf : 	u32 s1, s2;
buf : 	uint n = 0;
buf : 	/*
buf : 	 * Param 'max_tx_num' indicates max. # tx status to process before
fore 
buf : 	 * break out.
buf : 	 */
buf : 	uint max_tx_num = bound ? TXSBND : -1;
buf : 
buf : 	txs = &txstatus;
buf : 	core = wlc_hw->d11core;
buf : 	*fatal = false;
buf : 
buf : 	while (n < max_tx_num) {
while (n < max_tx_num) { 
buf : 		s1 = bcma_read32(core, D11REGOFFS(frmtxstatus));
buf : 		if (s1 == 0xffffffff) {
if (s1 == 0xffffffff) { 
buf : 			brcms_err(core, "wl%d: %s: dead chip\n", wlc_hw->unit,
buf : 				  __func__);
buf : 			*fatal = true;
buf : 			return false;
buf : 		}
buf : 		/* only process when valid */
buf : 		if (!(s1 & TXS_V))
if (!(s1 & TXS_V)) 
buf : 			break;
buf : 
buf : 		s2 = bcma_read32(core, D11REGOFFS(frmtxstatus2));
buf : 		txs->status = s1 & TXS_STATUS_MASK;
buf : 		txs->frameid = (s1 & TXS_FID_MASK) >> TXS_FID_SHIFT;
buf : 		txs->sequence = s2 & TXS_SEQ_MASK;
buf : 		txs->phyerr = (s2 & TXS_PTX_MASK) >> TXS_PTX_SHIFT;
buf : 		txs->lasttxtime = 0;
buf : 
buf : 		*fatal = brcms_c_dotxstatus(wlc_hw->wlc, txs);
buf : 		if (*fatal == true)
if (*fatal == true) 
buf : 			return false;
buf : 		n++;
buf : 	}
buf : 
buf : 	return n >= max_tx_num;
buf : }
buf : 
buf : static void brcms_c_tbtt(struct brcms_c_info *wlc)
buf : {
buf : 	if (wlc->bsscfg->type == BRCMS_TYPE_ADHOC)
if (wlc->bsscfg->type == BRCMS_TYPE_ADHOC) 
buf : 		/*
buf : 		 * DirFrmQ is now valid...defer setting until end
buf : 		 * of ATIM window
buf : 		 */
buf : 		wlc->qvalid |= MCMD_DIRFRMQVAL;
buf : }
buf : 
buf : /* set initial host flags value */
buf : static void
buf : brcms_c_mhfdef(struct brcms_c_info *wlc, u16 *mhfs, u16 mhf2_init)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 
buf : 	memset(mhfs, 0, MHFMAX * sizeof(u16));
buf : 
buf : 	mhfs[MHF2] |= mhf2_init;
buf : 
buf : 	/* prohibit use of slowclock on multifunction boards */
ifunction boards */ 
buf : 	if (wlc_hw->boardflags & BFL_NOPLLDOWN)
buf : 		mhfs[MHF1] |= MHF1_FORCEFASTCLK;
buf : 
buf : 	if (BRCMS_ISNPHY(wlc_hw->band) && NREV_LT(wlc_hw->band->phyrev, 2)) {
if (BRCMS_ISNPHY(wlc_hw->band) && NREV_LT(wlc_hw->band->phyrev, 2)) { 
buf : 		mhfs[MHF2] |= MHF2_NPHY40MHZ_WAR;
buf : 		mhfs[MHF1] |= MHF1_IQSWAP_WAR;
buf : 	}
buf : }
buf : 
buf : static uint
buf : dmareg(uint direction, uint fifonum)
ifonum) 
buf : {
buf : 	if (direction == DMA_TX)
buf : 		return offsetof(struct d11regs, fifo64regs[fifonum].dmaxmt);
ifo64regs[fifonum].dmaxmt); 
buf : 	return offsetof(struct d11regs, fifo64regs[fifonum].dmarcv);
buf : }
buf : 
buf : static bool brcms_b_attach_dmapio(struct brcms_c_info *wlc, uint j, bool wme)
buf : {
buf : 	uint i;
buf : 	char name[8];
buf : 	/*
buf : 	 * ucode host flag 2 needed for pio mode, independent of band and fifo
ifo 
buf : 	 */
buf : 	u16 pio_mhf2 = 0;
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	uint unit = wlc_hw->unit;
buf : 
buf : 	/* name and offsets for dma_attach */
for dma_attach */ 
buf : 	snprintf(name, sizeof(name), "wl%d", unit);
buf : 
buf : 	if (wlc_hw->di[0] == NULL) {	/* Init FIFOs */
if (wlc_hw->di[0] == NULL) {	/* Init FIFOs */ 
buf : 		int dma_attach_err = 0;
buf : 
buf : 		/*
buf : 		 * FIFO 0
buf : 		 * TX: TX_AC_BK_FIFO (TX AC Background data packets)
buf : 		 * RX: RX_FIFO (RX data packets)
buf : 		 */
buf : 		wlc_hw->di[0] = dma_attach(name, wlc,
buf : 					   (wme ? dmareg(DMA_TX, 0) : 0),
buf : 					   dmareg(DMA_RX, 0),
buf : 					   (wme ? NTXD : 0), NRXD,
buf : 					   RXBUFSZ, -1, NRXBUFPOST,
buf : 					   BRCMS_HWRXOFF);
buf : 		dma_attach_err |= (NULL == wlc_hw->di[0]);
buf : 
buf : 		/*
buf : 		 * FIFO 1
buf : 		 * TX: TX_AC_BE_FIFO (TX AC Best-Effort data packets)
fort data packets) 
buf : 		 *   (legacy) TX_DATA_FIFO (TX data packets)
buf : 		 * RX: UNUSED
buf : 		 */
buf : 		wlc_hw->di[1] = dma_attach(name, wlc,
buf : 					   dmareg(DMA_TX, 1), 0,
buf : 					   NTXD, 0, 0, -1, 0, 0);
buf : 		dma_attach_err |= (NULL == wlc_hw->di[1]);
buf : 
buf : 		/*
buf : 		 * FIFO 2
buf : 		 * TX: TX_AC_VI_FIFO (TX AC Video data packets)
buf : 		 * RX: UNUSED
buf : 		 */
buf : 		wlc_hw->di[2] = dma_attach(name, wlc,
buf : 					   dmareg(DMA_TX, 2), 0,
buf : 					   NTXD, 0, 0, -1, 0, 0);
buf : 		dma_attach_err |= (NULL == wlc_hw->di[2]);
buf : 		/*
buf : 		 * FIFO 3
buf : 		 * TX: TX_AC_VO_FIFO (TX AC Voice data packets)
buf : 		 *   (legacy) TX_CTL_FIFO (TX control & mgmt packets)
buf : 		 */
buf : 		wlc_hw->di[3] = dma_attach(name, wlc,
buf : 					   dmareg(DMA_TX, 3),
buf : 					   0, NTXD, 0, 0, -1,
buf : 					   0, 0);
buf : 		dma_attach_err |= (NULL == wlc_hw->di[3]);
buf : /* Cleaner to leave this as if with AP defined */
if with AP defined */ 
buf : 
buf : 		if (dma_attach_err) {
buf : 			brcms_err(wlc_hw->d11core,
buf : 				  "wl%d: wlc_attach: dma_attach failed\n",
buf : 				  unit);
buf : 			return false;
buf : 		}
buf : 
buf : 		/* get pointer to dma engine tx flow control variable */
buf : 		for (i = 0; i < NFIFO; i++)
for (i = 0; i < NFIFO; i++) 
buf : 			if (wlc_hw->di[i])
buf : 				wlc_hw->txavail[i] =
buf : 				    (uint *) dma_getvar(wlc_hw->di[i],
buf : 							"&txavail");
buf : 	}
buf : 
buf : 	/* initial ucode host flags */
buf : 	brcms_c_mhfdef(wlc, wlc_hw->band->mhfs, pio_mhf2);
buf : 
buf : 	return true;
buf : }
buf : 
buf : static void brcms_b_detach_dmapio(struct brcms_hardware *wlc_hw)
buf : {
buf : 	uint j;
buf : 
buf : 	for (j = 0; j < NFIFO; j++) {
for (j = 0; j < NFIFO; j++) { 
buf : 		if (wlc_hw->di[j]) {
buf : 			dma_detach(wlc_hw->di[j]);
buf : 			wlc_hw->di[j] = NULL;
buf : 		}
buf : 	}
buf : }
buf : 
buf : /*
buf :  * Initialize brcms_c_info default values ...
buf :  * may get overrides later in this function
buf :  *  BMAC_NOTES, move low out and resolve the dangling ones
buf :  */
buf : static void brcms_b_info_init(struct brcms_hardware *wlc_hw)
buf : {
buf : 	struct brcms_c_info *wlc = wlc_hw->wlc;
buf : 
buf : 	/* set default sw macintmask value */
buf : 	wlc->defmacintmask = DEF_MACINTMASK;
buf : 
buf : 	/* various 802.11g modes */
buf : 	wlc_hw->shortslot = false;
buf : 
buf : 	wlc_hw->SFBL = RETRY_SHORT_FB;
buf : 	wlc_hw->LFBL = RETRY_LONG_FB;
buf : 
buf : 	/* default mac retry limits */
buf : 	wlc_hw->SRL = RETRY_SHORT_DEF;
buf : 	wlc_hw->LRL = RETRY_LONG_DEF;
buf : 	wlc_hw->chanspec = ch20mhz_chspec(1);
buf : }
buf : 
buf : static void brcms_b_wait_for_wake(struct brcms_hardware *wlc_hw)
for_wake(struct brcms_hardware *wlc_hw) 
buf : {
buf : 	/* delay before first read of ucode state */
buf : 	udelay(40);
buf : 
buf : 	/* wait until ucode is no longer asleep */
buf : 	SPINWAIT((brcms_b_read_shm(wlc_hw, M_UCODE_DBGST) ==
buf : 		  DBGST_ASLEEP), wlc_hw->wlc->fastpwrup_dly);
buf : }
buf : 
buf : /* control chip clock to save power, enable dynamic clock or force fast clock */
force fast clock */ 
buf : static void brcms_b_clkctl_clk(struct brcms_hardware *wlc_hw, enum bcma_clkmode mode)
buf : {
buf : 	if (ai_get_cccaps(wlc_hw->sih) & CC_CAP_PMU) {
if (ai_get_cccaps(wlc_hw->sih) & CC_CAP_PMU) { 
buf : 		/* new chips with PMU, CCS_FORCEHT will distribute the HT clock
buf : 		 * on backplane, but mac core will still run on ALP(not HT) when
buf : 		 * it enters powersave mode, which means the FCA bit may not be
buf : 		 * set. Should wakeup mac if driver wants it to run on HT.
if driver wants it to run on HT. 
buf : 		 */
buf : 
buf : 		if (wlc_hw->clk) {
if (wlc_hw->clk) { 
buf : 			if (mode == BCMA_CLKMODE_FAST) {
buf : 				bcma_set32(wlc_hw->d11core,
buf : 					   D11REGOFFS(clk_ctl_st),
buf : 					   CCS_FORCEHT);
buf : 
buf : 				udelay(64);
buf : 
buf : 				SPINWAIT(
buf : 				    ((bcma_read32(wlc_hw->d11core,
buf : 				      D11REGOFFS(clk_ctl_st)) &
buf : 				      CCS_HTAVAIL) == 0),
buf : 				      PMU_MAX_TRANSITION_DLY);
buf : 				WARN_ON(!(bcma_read32(wlc_hw->d11core,
buf : 					D11REGOFFS(clk_ctl_st)) &
buf : 					CCS_HTAVAIL));
buf : 			} else {
buf : 				if ((ai_get_pmurev(wlc_hw->sih) == 0) &&
if ((ai_get_pmurev(wlc_hw->sih) == 0) && 
buf : 				    (bcma_read32(wlc_hw->d11core,
buf : 					D11REGOFFS(clk_ctl_st)) &
buf : 					(CCS_FORCEHT | CCS_HTAREQ)))
buf : 					SPINWAIT(
buf : 					    ((bcma_read32(wlc_hw->d11core,
buf : 					      offsetof(struct d11regs,
buf : 						       clk_ctl_st)) &
buf : 					      CCS_HTAVAIL) == 0),
buf : 					      PMU_MAX_TRANSITION_DLY);
buf : 				bcma_mask32(wlc_hw->d11core,
buf : 					D11REGOFFS(clk_ctl_st),
buf : 					~CCS_FORCEHT);
buf : 			}
buf : 		}
buf : 		wlc_hw->forcefastclk = (mode == BCMA_CLKMODE_FAST);
forcefastclk = (mode == BCMA_CLKMODE_FAST); 
buf : 	} else {
buf : 
buf : 		/* old chips w/o PMU, force HT through cc,
force HT through cc, 
buf : 		 * then use FCA to verify mac is running fast clock
buf : 		 */
buf : 
buf : 		wlc_hw->forcefastclk = ai_clkctl_cc(wlc_hw->sih, mode);
forcefastclk = ai_clkctl_cc(wlc_hw->sih, mode); 
buf : 
buf : 		/* check fast clock is available (if core is not in reset) */
buf : 		if (wlc_hw->forcefastclk && wlc_hw->clk)
if (wlc_hw->forcefastclk && wlc_hw->clk) 
buf : 			WARN_ON(!(bcma_aread32(wlc_hw->d11core, BCMA_IOST) &
buf : 				  SISF_FCLKA));
buf : 
buf : 		/*
buf : 		 * keep the ucode wake bit on if forcefastclk is on since we
if forcefastclk is on since we 
buf : 		 * do not want ucode to put us back to slow clock when it dozes
buf : 		 * for PM mode. Code below matches the wake override bit with
for PM mode. Code below matches the wake override bit with 
buf : 		 * current forcefastclk state. Only setting bit in wake_override
buf : 		 * instead of waking ucode immediately since old code had this
buf : 		 * behavior. Older code set wlc->forcefastclk but only had the
forcefastclk but only had the 
buf : 		 * wake happen if the wakup_ucode work (protected by an up
buf : 		 * check) was executed just below.
buf : 		 */
buf : 		if (wlc_hw->forcefastclk)
if (wlc_hw->forcefastclk) 
buf : 			mboolset(wlc_hw->wake_override,
buf : 				 BRCMS_WAKE_OVERRIDE_FORCEFAST);
buf : 		else
buf : 			mboolclr(wlc_hw->wake_override,
buf : 				 BRCMS_WAKE_OVERRIDE_FORCEFAST);
buf : 	}
buf : }
buf : 
buf : /* set or clear ucode host flag bits
buf :  * it has an optimization for no-change write
for no-change write 
buf :  * it only writes through shared memory when the core has clock;
buf :  * pre-CLK changes should use wlc_write_mhf to get around the optimization
buf :  *
buf :  *
buf :  * bands values are: BRCM_BAND_AUTO <--- Current band only
buf :  *                   BRCM_BAND_5G   <--- 5G band only
buf :  *                   BRCM_BAND_2G   <--- 2G band only
buf :  *                   BRCM_BAND_ALL  <--- All bands
buf :  */
buf : void
buf : brcms_b_mhf(struct brcms_hardware *wlc_hw, u8 idx, u16 mask, u16 val,
buf : 	     int bands)
buf : {
buf : 	u16 save;
buf : 	u16 addr[MHFMAX] = {
buf : 		M_HOST_FLAGS1, M_HOST_FLAGS2, M_HOST_FLAGS3, M_HOST_FLAGS4,
buf : 		M_HOST_FLAGS5
buf : 	};
buf : 	struct brcms_hw_band *band;
buf : 
buf : 	if ((val & ~mask) || idx >= MHFMAX)
if ((val & ~mask) || idx >= MHFMAX) 
buf : 		return; /* error condition */
buf : 
buf : 	switch (bands) {
buf : 		/* Current band only or all bands,
buf : 		 * then set the band to current band
buf : 		 */
buf : 	case BRCM_BAND_AUTO:
buf : 	case BRCM_BAND_ALL:
buf : 		band = wlc_hw->band;
buf : 		break;
buf : 	case BRCM_BAND_5G:
buf : 		band = wlc_hw->bandstate[BAND_5G_INDEX];
buf : 		break;
buf : 	case BRCM_BAND_2G:
buf : 		band = wlc_hw->bandstate[BAND_2G_INDEX];
buf : 		break;
buf : 	default:
buf : 		band = NULL;	/* error condition */
buf : 	}
buf : 
buf : 	if (band) {
if (band) { 
buf : 		save = band->mhfs[idx];
buf : 		band->mhfs[idx] = (band->mhfs[idx] & ~mask) | val;
buf : 
buf : 		/* optimization: only write through if changed, and
if changed, and 
buf : 		 * changed band is the current band
buf : 		 */
buf : 		if (wlc_hw->clk && (band->mhfs[idx] != save)
if (wlc_hw->clk && (band->mhfs[idx] != save) 
buf : 		    && (band == wlc_hw->band))
buf : 			brcms_b_write_shm(wlc_hw, addr[idx],
buf : 					   (u16) band->mhfs[idx]);
buf : 	}
buf : 
buf : 	if (bands == BRCM_BAND_ALL) {
if (bands == BRCM_BAND_ALL) { 
buf : 		wlc_hw->bandstate[0]->mhfs[idx] =
buf : 		    (wlc_hw->bandstate[0]->mhfs[idx] & ~mask) | val;
buf : 		wlc_hw->bandstate[1]->mhfs[idx] =
buf : 		    (wlc_hw->bandstate[1]->mhfs[idx] & ~mask) | val;
buf : 	}
buf : }
buf : 
buf : /* set the maccontrol register to desired reset state and
buf :  * initialize the sw cache of the register
buf :  */
buf : static void brcms_c_mctrl_reset(struct brcms_hardware *wlc_hw)
buf : {
buf : 	/* IHR accesses are always enabled, PSM disabled, HPS off and WAKE on */
buf : 	wlc_hw->maccontrol = 0;
buf : 	wlc_hw->suspended_fifos = 0;
ifos = 0; 
buf : 	wlc_hw->wake_override = 0;
buf : 	wlc_hw->mute_override = 0;
buf : 	brcms_b_mctrl(wlc_hw, ~0, MCTL_IHR_EN | MCTL_WAKE);
buf : }
buf : 
buf : /*
buf :  * write the software state of maccontrol and
buf :  * overrides to the maccontrol register
buf :  */
buf : static void brcms_c_mctrl_write(struct brcms_hardware *wlc_hw)
buf : {
buf : 	u32 maccontrol = wlc_hw->maccontrol;
buf : 
buf : 	/* OR in the wake bit if overridden */
if overridden */ 
buf : 	if (wlc_hw->wake_override)
buf : 		maccontrol |= MCTL_WAKE;
buf : 
buf : 	/* set AP and INFRA bits for mute if needed */
if needed */ 
buf : 	if (wlc_hw->mute_override) {
buf : 		maccontrol &= ~(MCTL_AP);
buf : 		maccontrol |= MCTL_INFRA;
buf : 	}
buf : 
buf : 	bcma_write32(wlc_hw->d11core, D11REGOFFS(maccontrol),
buf : 		     maccontrol);
buf : }
buf : 
buf : /* set or clear maccontrol bits */
buf : void brcms_b_mctrl(struct brcms_hardware *wlc_hw, u32 mask, u32 val)
buf : {
buf : 	u32 maccontrol;
buf : 	u32 new_maccontrol;
buf : 
buf : 	if (val & ~mask)
if (val & ~mask) 
buf : 		return; /* error condition */
buf : 	maccontrol = wlc_hw->maccontrol;
buf : 	new_maccontrol = (maccontrol & ~mask) | val;
buf : 
buf : 	/* if the new maccontrol value is the same as the old, nothing to do */
if the new maccontrol value is the same as the old, nothing to do */ 
buf : 	if (new_maccontrol == maccontrol)
buf : 		return;
buf : 
buf : 	/* something changed, cache the new value */
buf : 	wlc_hw->maccontrol = new_maccontrol;
buf : 
buf : 	/* write the new values with overrides applied */
buf : 	brcms_c_mctrl_write(wlc_hw);
buf : }
buf : 
buf : void brcms_c_ucode_wake_override_set(struct brcms_hardware *wlc_hw,
buf : 				 u32 override_bit)
buf : {
buf : 	if (wlc_hw->wake_override || (wlc_hw->maccontrol & MCTL_WAKE)) {
if (wlc_hw->wake_override || (wlc_hw->maccontrol & MCTL_WAKE)) { 
buf : 		mboolset(wlc_hw->wake_override, override_bit);
buf : 		return;
buf : 	}
buf : 
buf : 	mboolset(wlc_hw->wake_override, override_bit);
buf : 
buf : 	brcms_c_mctrl_write(wlc_hw);
buf : 	brcms_b_wait_for_wake(wlc_hw);
for_wake(wlc_hw); 
buf : }
buf : 
buf : void brcms_c_ucode_wake_override_clear(struct brcms_hardware *wlc_hw,
buf : 				   u32 override_bit)
buf : {
buf : 	mboolclr(wlc_hw->wake_override, override_bit);
buf : 
buf : 	if (wlc_hw->wake_override || (wlc_hw->maccontrol & MCTL_WAKE))
if (wlc_hw->wake_override || (wlc_hw->maccontrol & MCTL_WAKE)) 
buf : 		return;
buf : 
buf : 	brcms_c_mctrl_write(wlc_hw);
buf : }
buf : 
buf : /* When driver needs ucode to stop beaconing, it has to make sure that
buf :  * MCTL_AP is clear and MCTL_INFRA is set
buf :  * Mode           MCTL_AP        MCTL_INFRA
buf :  * AP                1              1
buf :  * STA               0              1 <--- This will ensure no beacons
buf :  * IBSS              0              0
buf :  */
buf : static void brcms_c_ucode_mute_override_set(struct brcms_hardware *wlc_hw)
buf : {
buf : 	wlc_hw->mute_override = 1;
buf : 
buf : 	/* if maccontrol already has AP == 0 and INFRA == 1 without this
if maccontrol already has AP == 0 and INFRA == 1 without this 
buf : 	 * override, then there is no change to write
buf : 	 */
buf : 	if ((wlc_hw->maccontrol & (MCTL_AP | MCTL_INFRA)) == MCTL_INFRA)
if ((wlc_hw->maccontrol & (MCTL_AP | MCTL_INFRA)) == MCTL_INFRA) 
buf : 		return;
buf : 
buf : 	brcms_c_mctrl_write(wlc_hw);
buf : }
buf : 
buf : /* Clear the override on AP and INFRA bits */
buf : static void brcms_c_ucode_mute_override_clear(struct brcms_hardware *wlc_hw)
buf : {
buf : 	if (wlc_hw->mute_override == 0)
if (wlc_hw->mute_override == 0) 
buf : 		return;
buf : 
buf : 	wlc_hw->mute_override = 0;
buf : 
buf : 	/* if maccontrol already has AP == 0 and INFRA == 1 without this
if maccontrol already has AP == 0 and INFRA == 1 without this 
buf : 	 * override, then there is no change to write
buf : 	 */
buf : 	if ((wlc_hw->maccontrol & (MCTL_AP | MCTL_INFRA)) == MCTL_INFRA)
if ((wlc_hw->maccontrol & (MCTL_AP | MCTL_INFRA)) == MCTL_INFRA) 
buf : 		return;
buf : 
buf : 	brcms_c_mctrl_write(wlc_hw);
buf : }
buf : 
buf : /*
buf :  * Write a MAC address to the given match reg offset in the RXE match engine.
buf :  */
buf : static void
buf : brcms_b_set_addrmatch(struct brcms_hardware *wlc_hw, int match_reg_offset,
buf : 		       const u8 *addr)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u16 mac_l;
buf : 	u16 mac_m;
buf : 	u16 mac_h;
buf : 
buf : 	brcms_dbg_rx(core, "wl%d: brcms_b_set_addrmatch\n", wlc_hw->unit);
buf : 
buf : 	mac_l = addr[0] | (addr[1] << 8);
buf : 	mac_m = addr[2] | (addr[3] << 8);
buf : 	mac_h = addr[4] | (addr[5] << 8);
buf : 
buf : 	/* enter the MAC addr into the RXE match registers */
buf : 	bcma_write16(core, D11REGOFFS(rcm_ctl),
buf : 		     RCM_INC_DATA | match_reg_offset);
buf : 	bcma_write16(core, D11REGOFFS(rcm_mat_data), mac_l);
buf : 	bcma_write16(core, D11REGOFFS(rcm_mat_data), mac_m);
buf : 	bcma_write16(core, D11REGOFFS(rcm_mat_data), mac_h);
buf : }
buf : 
buf : void
buf : brcms_b_write_template_ram(struct brcms_hardware *wlc_hw, int offset, int len,
buf : 			    void *buf)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u32 word;
buf : 	__le32 word_le;
buf : 	__be32 word_be;
buf : 	bool be_bit;
buf : 	brcms_dbg_info(core, "wl%d\n", wlc_hw->unit);
buf : 
buf : 	bcma_write32(core, D11REGOFFS(tplatewrptr), offset);
buf : 
buf : 	/* if MCTL_BIGEND bit set in mac control register,
if MCTL_BIGEND bit set in mac control register, 
buf : 	 * the chip swaps data in fifo, as well as data in
buf : 	 * template ram
buf : 	 */
buf : 	be_bit = (bcma_read32(core, D11REGOFFS(maccontrol)) & MCTL_BIGEND) != 0;
buf : 
buf : 	while (len > 0) {
while (len > 0) { 
buf : 		memcpy(&word, buf, sizeof(u32));
buf : 
buf : 		if (be_bit) {
if (be_bit) { 
buf : 			word_be = cpu_to_be32(word);
buf : 			word = *(u32 *)&word_be;
buf : 		} else {
buf : 			word_le = cpu_to_le32(word);
buf : 			word = *(u32 *)&word_le;
buf : 		}
buf : 
buf : 		bcma_write32(core, D11REGOFFS(tplatewrdata), word);
buf : 
buf : 		buf = (u8 *) buf + sizeof(u32);
buf : 		len -= sizeof(u32);
buf : 	}
buf : }
buf : 
buf : static void brcms_b_set_cwmin(struct brcms_hardware *wlc_hw, u16 newmin)
buf : {
buf : 	wlc_hw->band->CWmin = newmin;
buf : 
buf : 	bcma_write32(wlc_hw->d11core, D11REGOFFS(objaddr),
buf : 		     OBJADDR_SCR_SEL | S_DOT11_CWMIN);
buf : 	(void)bcma_read32(wlc_hw->d11core, D11REGOFFS(objaddr));
buf : 	bcma_write32(wlc_hw->d11core, D11REGOFFS(objdata), newmin);
buf : }
buf : 
buf : static void brcms_b_set_cwmax(struct brcms_hardware *wlc_hw, u16 newmax)
buf : {
buf : 	wlc_hw->band->CWmax = newmax;
buf : 
buf : 	bcma_write32(wlc_hw->d11core, D11REGOFFS(objaddr),
buf : 		     OBJADDR_SCR_SEL | S_DOT11_CWMAX);
buf : 	(void)bcma_read32(wlc_hw->d11core, D11REGOFFS(objaddr));
buf : 	bcma_write32(wlc_hw->d11core, D11REGOFFS(objdata), newmax);
buf : }
buf : 
buf : void brcms_b_bw_set(struct brcms_hardware *wlc_hw, u16 bw)
buf : {
buf : 	bool fastclk;
buf : 
buf : 	/* request FAST clock if not on */
if not on */ 
buf : 	fastclk = wlc_hw->forcefastclk;
forcefastclk; 
buf : 	if (!fastclk)
buf : 		brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_FAST);
buf : 
buf : 	wlc_phy_bw_state_set(wlc_hw->band->pi, bw);
buf : 
buf : 	brcms_b_phy_reset(wlc_hw);
buf : 	wlc_phy_init(wlc_hw->band->pi, wlc_phy_chanspec_get(wlc_hw->band->pi));
buf : 
buf : 	/* restore the clk */
buf : 	if (!fastclk)
if (!fastclk) 
buf : 		brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_DYNAMIC);
buf : }
buf : 
buf : static void brcms_b_upd_synthpu(struct brcms_hardware *wlc_hw)
buf : {
buf : 	u16 v;
buf : 	struct brcms_c_info *wlc = wlc_hw->wlc;
buf : 	/* update SYNTHPU_DLY */
buf : 
buf : 	if (BRCMS_ISLCNPHY(wlc->band))
if (BRCMS_ISLCNPHY(wlc->band)) 
buf : 		v = SYNTHPU_DLY_LPPHY_US;
buf : 	else if (BRCMS_ISNPHY(wlc->band) && (NREV_GE(wlc->band->phyrev, 3)))
if (BRCMS_ISNPHY(wlc->band) && (NREV_GE(wlc->band->phyrev, 3))) 
buf : 		v = SYNTHPU_DLY_NPHY_US;
buf : 	else
buf : 		v = SYNTHPU_DLY_BPHY_US;
buf : 
buf : 	brcms_b_write_shm(wlc_hw, M_SYNTHPU_DLY, v);
buf : }
buf : 
buf : static void brcms_c_ucode_txant_set(struct brcms_hardware *wlc_hw)
buf : {
buf : 	u16 phyctl;
buf : 	u16 phytxant = wlc_hw->bmac_phytxant;
buf : 	u16 mask = PHY_TXC_ANT_MASK;
buf : 
buf : 	/* set the Probe Response frame phy control word */
buf : 	phyctl = brcms_b_read_shm(wlc_hw, M_CTXPRS_BLK + C_CTX_PCTLWD_POS);
buf : 	phyctl = (phyctl & ~mask) | phytxant;
buf : 	brcms_b_write_shm(wlc_hw, M_CTXPRS_BLK + C_CTX_PCTLWD_POS, phyctl);
buf : 
buf : 	/* set the Response (ACK/CTS) frame phy control word */
buf : 	phyctl = brcms_b_read_shm(wlc_hw, M_RSP_PCTLWD);
buf : 	phyctl = (phyctl & ~mask) | phytxant;
buf : 	brcms_b_write_shm(wlc_hw, M_RSP_PCTLWD, phyctl);
buf : }
buf : 
buf : static u16 brcms_b_ofdm_ratetable_offset(struct brcms_hardware *wlc_hw,
buf : 					 u8 rate)
buf : {
buf : 	uint i;
buf : 	u8 plcp_rate = 0;
buf : 	struct plcp_signal_rate_lookup {
buf : 		u8 rate;
buf : 		u8 signal_rate;
buf : 	};
buf : 	/* OFDM RATE sub-field of PLCP SIGNAL field, per 802.11 sec 17.3.4.1 */
buf : 	const struct plcp_signal_rate_lookup rate_lookup[] = {
buf : 		{BRCM_RATE_6M, 0xB},
buf : 		{BRCM_RATE_9M, 0xF},
buf : 		{BRCM_RATE_12M, 0xA},
buf : 		{BRCM_RATE_18M, 0xE},
buf : 		{BRCM_RATE_24M, 0x9},
buf : 		{BRCM_RATE_36M, 0xD},
buf : 		{BRCM_RATE_48M, 0x8},
buf : 		{BRCM_RATE_54M, 0xC}
buf : 	};
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(rate_lookup); i++) {
for (i = 0; i < ARRAY_SIZE(rate_lookup); i++) { 
buf : 		if (rate == rate_lookup[i].rate) {
buf : 			plcp_rate = rate_lookup[i].signal_rate;
buf : 			break;
buf : 		}
buf : 	}
buf : 
buf : 	/* Find the SHM pointer to the rate table entry by looking in the
buf : 	 * Direct-map Table
buf : 	 */
buf : 	return 2 * brcms_b_read_shm(wlc_hw, M_RT_DIRMAP_A + (plcp_rate * 2));
buf : }
buf : 
buf : static void brcms_upd_ofdm_pctl1_table(struct brcms_hardware *wlc_hw)
buf : {
buf : 	u8 rate;
buf : 	u8 rates[8] = {
buf : 		BRCM_RATE_6M, BRCM_RATE_9M, BRCM_RATE_12M, BRCM_RATE_18M,
buf : 		BRCM_RATE_24M, BRCM_RATE_36M, BRCM_RATE_48M, BRCM_RATE_54M
buf : 	};
buf : 	u16 entry_ptr;
buf : 	u16 pctl1;
buf : 	uint i;
buf : 
buf : 	if (!BRCMS_PHY_11N_CAP(wlc_hw->band))
if (!BRCMS_PHY_11N_CAP(wlc_hw->band)) 
buf : 		return;
buf : 
buf : 	/* walk the phy rate table and update the entries */
buf : 	for (i = 0; i < ARRAY_SIZE(rates); i++) {
for (i = 0; i < ARRAY_SIZE(rates); i++) { 
buf : 		rate = rates[i];
buf : 
buf : 		entry_ptr = brcms_b_ofdm_ratetable_offset(wlc_hw, rate);
buf : 
buf : 		/* read the SHM Rate Table entry OFDM PCTL1 values */
buf : 		pctl1 =
buf : 		    brcms_b_read_shm(wlc_hw, entry_ptr + M_RT_OFDM_PCTL1_POS);
buf : 
buf : 		/* modify the value */
ify the value */ 
buf : 		pctl1 &= ~PHY_TXC1_MODE_MASK;
buf : 		pctl1 |= (wlc_hw->hw_stf_ss_opmode << PHY_TXC1_MODE_SHIFT);
buf : 
buf : 		/* Update the SHM Rate Table entry OFDM PCTL1 values */
buf : 		brcms_b_write_shm(wlc_hw, entry_ptr + M_RT_OFDM_PCTL1_POS,
buf : 				   pctl1);
buf : 	}
buf : }
buf : 
buf : /* band-specific init */
ific init */ 
buf : static void brcms_b_bsinit(struct brcms_c_info *wlc, u16 chanspec)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 
buf : 	brcms_dbg_mac80211(wlc_hw->d11core, "wl%d: bandunit %d\n", wlc_hw->unit,
buf : 			   wlc_hw->band->bandunit);
buf : 
buf : 	brcms_c_ucode_bsinit(wlc_hw);
buf : 
buf : 	wlc_phy_init(wlc_hw->band->pi, chanspec);
buf : 
buf : 	brcms_c_ucode_txant_set(wlc_hw);
buf : 
buf : 	/*
buf : 	 * cwmin is band-specific, update hardware
ific, update hardware 
buf : 	 * with value for current band
for current band 
buf : 	 */
buf : 	brcms_b_set_cwmin(wlc_hw, wlc_hw->band->CWmin);
buf : 	brcms_b_set_cwmax(wlc_hw, wlc_hw->band->CWmax);
buf : 
buf : 	brcms_b_update_slot_timing(wlc_hw,
buf : 				   wlc_hw->band->bandtype == BRCM_BAND_5G ?
buf : 				   true : wlc_hw->shortslot);
buf : 
buf : 	/* write phytype and phyvers */
buf : 	brcms_b_write_shm(wlc_hw, M_PHYTYPE, (u16) wlc_hw->band->phytype);
buf : 	brcms_b_write_shm(wlc_hw, M_PHYVER, (u16) wlc_hw->band->phyrev);
buf : 
buf : 	/*
buf : 	 * initialize the txphyctl1 rate table since
buf : 	 * shmem is shared between bands
buf : 	 */
buf : 	brcms_upd_ofdm_pctl1_table(wlc_hw);
buf : 
buf : 	brcms_b_upd_synthpu(wlc_hw);
buf : }
buf : 
buf : /* Perform a soft reset of the PHY PLL */
form a soft reset of the PHY PLL */ 
buf : void brcms_b_core_phypll_reset(struct brcms_hardware *wlc_hw)
buf : {
buf : 	ai_cc_reg(wlc_hw->sih, offsetof(struct chipcregs, chipcontrol_addr),
buf : 		  ~0, 0);
buf : 	udelay(1);
buf : 	ai_cc_reg(wlc_hw->sih, offsetof(struct chipcregs, chipcontrol_data),
buf : 		  0x4, 0);
buf : 	udelay(1);
buf : 	ai_cc_reg(wlc_hw->sih, offsetof(struct chipcregs, chipcontrol_data),
buf : 		  0x4, 4);
buf : 	udelay(1);
buf : 	ai_cc_reg(wlc_hw->sih, offsetof(struct chipcregs, chipcontrol_data),
buf : 		  0x4, 0);
buf : 	udelay(1);
buf : }
buf : 
buf : /* light way to turn on phy clock without reset for NPHY only
for NPHY only 
buf :  *  refer to brcms_b_core_phy_clk for full version
buf :  */
buf : void brcms_b_phyclk_fgc(struct brcms_hardware *wlc_hw, bool clk)
buf : {
buf : 	/* support(necessary for NPHY and HYPHY) only */
for NPHY and HYPHY) only */ 
buf : 	if (!BRCMS_ISNPHY(wlc_hw->band))
buf : 		return;
buf : 
buf : 	if (ON == clk)
if (ON == clk) 
buf : 		brcms_b_core_ioctl(wlc_hw, SICF_FGC, SICF_FGC);
buf : 	else
buf : 		brcms_b_core_ioctl(wlc_hw, SICF_FGC, 0);
buf : 
buf : }
buf : 
buf : void brcms_b_macphyclk_set(struct brcms_hardware *wlc_hw, bool clk)
buf : {
buf : 	if (ON == clk)
if (ON == clk) 
buf : 		brcms_b_core_ioctl(wlc_hw, SICF_MPCLKE, SICF_MPCLKE);
buf : 	else
buf : 		brcms_b_core_ioctl(wlc_hw, SICF_MPCLKE, 0);
buf : }
buf : 
buf : void brcms_b_phy_reset(struct brcms_hardware *wlc_hw)
buf : {
buf : 	struct brcms_phy_pub *pih = wlc_hw->band->pi;
buf : 	u32 phy_bw_clkbits;
buf : 	bool phy_in_reset = false;
buf : 
buf : 	brcms_dbg_info(wlc_hw->d11core, "wl%d: reset phy\n", wlc_hw->unit);
buf : 
buf : 	if (pih == NULL)
if (pih == NULL) 
buf : 		return;
buf : 
buf : 	phy_bw_clkbits = wlc_phy_clk_bwbits(wlc_hw->band->pi);
buf : 
buf : 	/* Specific reset sequence required for NPHY rev 3 and 4 */
ific reset sequence required for NPHY rev 3 and 4 */ 
buf : 	if (BRCMS_ISNPHY(wlc_hw->band) && NREV_GE(wlc_hw->band->phyrev, 3) &&
buf : 	    NREV_LE(wlc_hw->band->phyrev, 4)) {
buf : 		/* Set the PHY bandwidth */
buf : 		brcms_b_core_ioctl(wlc_hw, SICF_BWMASK, phy_bw_clkbits);
buf : 
buf : 		udelay(1);
buf : 
buf : 		/* Perform a soft reset of the PHY PLL */
form a soft reset of the PHY PLL */ 
buf : 		brcms_b_core_phypll_reset(wlc_hw);
buf : 
buf : 		/* reset the PHY */
buf : 		brcms_b_core_ioctl(wlc_hw, (SICF_PRST | SICF_PCLKE),
buf : 				   (SICF_PRST | SICF_PCLKE));
buf : 		phy_in_reset = true;
buf : 	} else {
buf : 		brcms_b_core_ioctl(wlc_hw,
buf : 				   (SICF_PRST | SICF_PCLKE | SICF_BWMASK),
buf : 				   (SICF_PRST | SICF_PCLKE | phy_bw_clkbits));
buf : 	}
buf : 
buf : 	udelay(2);
buf : 	brcms_b_core_phy_clk(wlc_hw, ON);
buf : 
buf : 	if (pih)
if (pih) 
buf : 		wlc_phy_anacore(pih, ON);
buf : }
buf : 
buf : /* switch to and initialize new band */
buf : static void brcms_b_setband(struct brcms_hardware *wlc_hw, uint bandunit,
buf : 			    u16 chanspec) {
buf : 	struct brcms_c_info *wlc = wlc_hw->wlc;
buf : 	u32 macintmask;
buf : 
buf : 	/* Enable the d11 core before accessing it */
fore accessing it */ 
buf : 	if (!bcma_core_is_enabled(wlc_hw->d11core)) {
buf : 		bcma_core_enable(wlc_hw->d11core, 0);
buf : 		brcms_c_mctrl_reset(wlc_hw);
buf : 	}
buf : 
buf : 	macintmask = brcms_c_setband_inact(wlc, bandunit);
buf : 
buf : 	if (!wlc_hw->up)
if (!wlc_hw->up) 
buf : 		return;
buf : 
buf : 	brcms_b_core_phy_clk(wlc_hw, ON);
buf : 
buf : 	/* band-specific initializations */
ific initializations */ 
buf : 	brcms_b_bsinit(wlc, chanspec);
buf : 
buf : 	/*
buf : 	 * If there are any pending software interrupt bits,
buf : 	 * then replace these with a harmless nonzero value
buf : 	 * so brcms_c_dpc() will re-enable interrupts when done.
buf : 	 */
buf : 	if (wlc->macintstatus)
if (wlc->macintstatus) 
buf : 		wlc->macintstatus = MI_DMAINT;
buf : 
buf : 	/* restore macintmask */
buf : 	brcms_intrsrestore(wlc->wl, macintmask);
buf : 
buf : 	/* ucode should still be suspended.. */
buf : 	WARN_ON((bcma_read32(wlc_hw->d11core, D11REGOFFS(maccontrol)) &
buf : 		 MCTL_EN_MAC) != 0);
buf : }
buf : 
buf : static bool brcms_c_isgoodchip(struct brcms_hardware *wlc_hw)
buf : {
buf : 
buf : 	/* reject unsupported corerev */
buf : 	if (!CONF_HAS(D11CONF, wlc_hw->corerev)) {
if (!CONF_HAS(D11CONF, wlc_hw->corerev)) { 
buf : 		wiphy_err(wlc_hw->wlc->wiphy, "unsupported core rev %d\n",
buf : 			  wlc_hw->corerev);
buf : 		return false;
buf : 	}
buf : 
buf : 	return true;
buf : }
buf : 
buf : /* Validate some board info parameters */
buf : static bool brcms_c_validboardtype(struct brcms_hardware *wlc_hw)
buf : {
buf : 	uint boardrev = wlc_hw->boardrev;
buf : 
buf : 	/* 4 bits each for board type, major, minor, and tiny version */
for board type, major, minor, and tiny version */ 
buf : 	uint brt = (boardrev & 0xf000) >> 12;
buf : 	uint b0 = (boardrev & 0xf00) >> 8;
buf : 	uint b1 = (boardrev & 0xf0) >> 4;
buf : 	uint b2 = boardrev & 0xf;
buf : 
buf : 	/* voards from other vendors are always considered valid */
buf : 	if (ai_get_boardvendor(wlc_hw->sih) != PCI_VENDOR_ID_BROADCOM)
if (ai_get_boardvendor(wlc_hw->sih) != PCI_VENDOR_ID_BROADCOM) 
buf : 		return true;
buf : 
buf : 	/* do some boardrev sanity checks when boardvendor is Broadcom */
buf : 	if (boardrev == 0)
if (boardrev == 0) 
buf : 		return false;
buf : 
buf : 	if (boardrev <= 0xff)
if (boardrev <= 0xff) 
buf : 		return true;
buf : 
buf : 	if ((brt > 2) || (brt == 0) || (b0 > 9) || (b0 == 0) || (b1 > 9)
if ((brt > 2) || (brt == 0) || (b0 > 9) || (b0 == 0) || (b1 > 9) 
buf : 		|| (b2 > 9))
buf : 		return false;
buf : 
buf : 	return true;
buf : }
buf : 
buf : static void brcms_c_get_macaddr(struct brcms_hardware *wlc_hw, u8 etheraddr[ETH_ALEN])
buf : {
buf : 	struct ssb_sprom *sprom = &wlc_hw->d11core->bus->sprom;
buf : 
buf : 	/* If macaddr exists, use it (Sromrev4, CIS, ...). */
buf : 	if (!is_zero_ether_addr(sprom->il0mac)) {
if (!is_zero_ether_addr(sprom->il0mac)) { 
buf : 		memcpy(etheraddr, sprom->il0mac, ETH_ALEN);
buf : 		return;
buf : 	}
buf : 
buf : 	if (wlc_hw->_nbands > 1)
if (wlc_hw->_nbands > 1) 
buf : 		memcpy(etheraddr, sprom->et1mac, ETH_ALEN);
buf : 	else
buf : 		memcpy(etheraddr, sprom->il0mac, ETH_ALEN);
buf : }
buf : 
buf : /* power both the pll and external oscillator on/off */
buf : static void brcms_b_xtal(struct brcms_hardware *wlc_hw, bool want)
buf : {
buf : 	brcms_dbg_info(wlc_hw->d11core, "wl%d: want %d\n", wlc_hw->unit, want);
buf : 
buf : 	/*
buf : 	 * dont power down if plldown is false or
if plldown is false or 
buf : 	 * we must poll hw radio disable
buf : 	 */
buf : 	if (!want && wlc_hw->pllreq)
if (!want && wlc_hw->pllreq) 
buf : 		return;
buf : 
buf : 	wlc_hw->sbclk = want;
buf : 	if (!wlc_hw->sbclk) {
if (!wlc_hw->sbclk) { 
buf : 		wlc_hw->clk = false;
buf : 		if (wlc_hw->band && wlc_hw->band->pi)
if (wlc_hw->band && wlc_hw->band->pi) 
buf : 			wlc_phy_hw_clk_state_upd(wlc_hw->band->pi, false);
buf : 	}
buf : }
buf : 
buf : /*
buf :  * Return true if radio is disabled, otherwise false.
if radio is disabled, otherwise false. 
buf :  * hw radio disable signal is an external pin, users activate it asynchronously
buf :  * this function could be called when driver is down and w/o clock
buf :  * it operates on different registers depending on corerev and boardflag.
ifferent registers depending on corerev and boardflag. 
buf :  */
buf : static bool brcms_b_radio_read_hwdisabled(struct brcms_hardware *wlc_hw)
buf : {
buf : 	bool v, clk, xtal;
buf : 	u32 flags = 0;
buf : 
buf : 	xtal = wlc_hw->sbclk;
buf : 	if (!xtal)
if (!xtal) 
buf : 		brcms_b_xtal(wlc_hw, ON);
buf : 
buf : 	/* may need to take core out of reset first */
buf : 	clk = wlc_hw->clk;
buf : 	if (!clk) {
if (!clk) { 
buf : 		/*
buf : 		 * mac no longer enables phyclk automatically when driver
buf : 		 * accesses phyreg throughput mac. This can be skipped since
buf : 		 * only mac reg is accessed below
buf : 		 */
buf : 		if (D11REV_GE(wlc_hw->corerev, 18))
if (D11REV_GE(wlc_hw->corerev, 18)) 
buf : 			flags |= SICF_PCLKE;
buf : 
buf : 		/*
buf : 		 * TODO: test suspend/resume
buf : 		 *
buf : 		 * AI chip doesn't restore bar0win2 on
buf : 		 * hibernation/resume, need sw fixup
buf : 		 */
buf : 
buf : 		bcma_core_enable(wlc_hw->d11core, flags);
buf : 		brcms_c_mctrl_reset(wlc_hw);
buf : 	}
buf : 
buf : 	v = ((bcma_read32(wlc_hw->d11core,
buf : 			  D11REGOFFS(phydebug)) & PDBG_RFD) != 0);
buf : 
buf : 	/* put core back into reset */
buf : 	if (!clk)
if (!clk) 
buf : 		bcma_core_disable(wlc_hw->d11core, 0);
buf : 
buf : 	if (!xtal)
if (!xtal) 
buf : 		brcms_b_xtal(wlc_hw, OFF);
buf : 
buf : 	return v;
buf : }
buf : 
buf : static bool wlc_dma_rxreset(struct brcms_hardware *wlc_hw, uint fifo)
ifo) 
buf : {
buf : 	struct dma_pub *di = wlc_hw->di[fifo];
buf : 	return dma_rxreset(di);
buf : }
buf : 
buf : /* d11 core reset
buf :  *   ensure fask clock during reset
buf :  *   reset dma
buf :  *   reset d11(out of reset)
buf :  *   reset phy(out of reset)
buf :  *   clear software macintstatus for fresh new start
for fresh new start 
buf :  * one testing hack wlc_hw->noreset will bypass the d11/phy reset
buf :  */
buf : void brcms_b_corereset(struct brcms_hardware *wlc_hw, u32 flags)
buf : {
buf : 	uint i;
buf : 	bool fastclk;
buf : 
buf : 	if (flags == BRCMS_USE_COREFLAGS)
if (flags == BRCMS_USE_COREFLAGS) 
buf : 		flags = (wlc_hw->band->pi ? wlc_hw->band->core_flags : 0);
buf : 
buf : 	brcms_dbg_info(wlc_hw->d11core, "wl%d: core reset\n", wlc_hw->unit);
buf : 
buf : 	/* request FAST clock if not on  */
if not on  */ 
buf : 	fastclk = wlc_hw->forcefastclk;
forcefastclk; 
buf : 	if (!fastclk)
buf : 		brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_FAST);
buf : 
buf : 	/* reset the dma engines except first time thru */
buf : 	if (bcma_core_is_enabled(wlc_hw->d11core)) {
if (bcma_core_is_enabled(wlc_hw->d11core)) { 
buf : 		for (i = 0; i < NFIFO; i++)
for (i = 0; i < NFIFO; i++) 
buf : 			if ((wlc_hw->di[i]) && (!dma_txreset(wlc_hw->di[i])))
buf : 				brcms_err(wlc_hw->d11core, "wl%d: %s: "
buf : 					  "dma_txreset[%d]: cannot stop dma\n",
buf : 					   wlc_hw->unit, __func__, i);
buf : 
buf : 		if ((wlc_hw->di[RX_FIFO])
if ((wlc_hw->di[RX_FIFO]) 
buf : 		    && (!wlc_dma_rxreset(wlc_hw, RX_FIFO)))
buf : 			brcms_err(wlc_hw->d11core, "wl%d: %s: dma_rxreset"
buf : 				  "[%d]: cannot stop dma\n",
buf : 				  wlc_hw->unit, __func__, RX_FIFO);
buf : 	}
buf : 	/* if noreset, just stop the psm and return */
if noreset, just stop the psm and return */ 
buf : 	if (wlc_hw->noreset) {
buf : 		wlc_hw->wlc->macintstatus = 0;	/* skip wl_dpc after down */
buf : 		brcms_b_mctrl(wlc_hw, MCTL_PSM_RUN | MCTL_EN_MAC, 0);
buf : 		return;
buf : 	}
buf : 
buf : 	/*
buf : 	 * mac no longer enables phyclk automatically when driver accesses
buf : 	 * phyreg throughput mac, AND phy_reset is skipped at early stage when
buf : 	 * band->pi is invalid. need to enable PHY CLK
buf : 	 */
buf : 	if (D11REV_GE(wlc_hw->corerev, 18))
if (D11REV_GE(wlc_hw->corerev, 18)) 
buf : 		flags |= SICF_PCLKE;
buf : 
buf : 	/*
buf : 	 * reset the core
buf : 	 * In chips with PMU, the fastclk request goes through d11 core
buf : 	 * reg 0x1e0, which is cleared by the core_reset. have to re-request it.
buf : 	 *
buf : 	 * This adds some delay and we can optimize it by also requesting
buf : 	 * fastclk through chipcommon during this period if necessary. But
if necessary. But 
buf : 	 * that has to work coordinate with other driver like mips/arm since
buf : 	 * they may touch chipcommon as well.
buf : 	 */
buf : 	wlc_hw->clk = false;
buf : 	bcma_core_enable(wlc_hw->d11core, flags);
buf : 	wlc_hw->clk = true;
buf : 	if (wlc_hw->band && wlc_hw->band->pi)
if (wlc_hw->band && wlc_hw->band->pi) 
buf : 		wlc_phy_hw_clk_state_upd(wlc_hw->band->pi, true);
buf : 
buf : 	brcms_c_mctrl_reset(wlc_hw);
buf : 
buf : 	if (ai_get_cccaps(wlc_hw->sih) & CC_CAP_PMU)
if (ai_get_cccaps(wlc_hw->sih) & CC_CAP_PMU) 
buf : 		brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_FAST);
buf : 
buf : 	brcms_b_phy_reset(wlc_hw);
buf : 
buf : 	/* turn on PHY_PLL */
buf : 	brcms_b_core_phypll_ctl(wlc_hw, true);
buf : 
buf : 	/* clear sw intstatus */
buf : 	wlc_hw->wlc->macintstatus = 0;
buf : 
buf : 	/* restore the clk setting */
buf : 	if (!fastclk)
if (!fastclk) 
buf : 		brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_DYNAMIC);
buf : }
buf : 
buf : /* txfifo sizes needs to be modified(increased) since the newer cores
ifo sizes needs to be modified(increased) since the newer cores 
buf :  * have more memory.
buf :  */
buf : static void brcms_b_corerev_fifofixup(struct brcms_hardware *wlc_hw)
ifofixup(struct brcms_hardware *wlc_hw) 
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u16 fifo_nu;
ifo_nu; 
buf : 	u16 txfifo_startblk = TXFIFO_START_BLK, txfifo_endblk;
buf : 	u16 txfifo_def, txfifo_def1;
ifo_def, txfifo_def1; 
buf : 	u16 txfifo_cmd;
buf : 
buf : 	/* tx fifos start at TXFIFO_START_BLK from the Base address */
ifos start at TXFIFO_START_BLK from the Base address */ 
buf : 	txfifo_startblk = TXFIFO_START_BLK;
buf : 
buf : 	/* sequence of operations:  reset fifo, set fifo size, reset fifo */
ifo, set fifo size, reset fifo */ 
buf : 	for (fifo_nu = 0; fifo_nu < NFIFO; fifo_nu++) {
for (fifo_nu = 0; fifo_nu < NFIFO; fifo_nu++) { 
buf : 
buf : 		txfifo_endblk = txfifo_startblk + wlc_hw->xmtfifo_sz[fifo_nu];
buf : 		txfifo_def = (txfifo_startblk & 0xff) |
ifo_def = (txfifo_startblk & 0xff) | 
buf : 		    (((txfifo_endblk - 1) & 0xff) << TXFIFO_FIFOTOP_SHIFT);
buf : 		txfifo_def1 = ((txfifo_startblk >> 8) & 0x1) |
ifo_def1 = ((txfifo_startblk >> 8) & 0x1) | 
buf : 		    ((((txfifo_endblk -
buf : 			1) >> 8) & 0x1) << TXFIFO_FIFOTOP_SHIFT);
buf : 		txfifo_cmd =
ifo_cmd = 
buf : 		    TXFIFOCMD_RESET_MASK | (fifo_nu << TXFIFOCMD_FIFOSEL_SHIFT);
buf : 
buf : 		bcma_write16(core, D11REGOFFS(xmtfifocmd), txfifo_cmd);
ifocmd), txfifo_cmd); 
buf : 		bcma_write16(core, D11REGOFFS(xmtfifodef), txfifo_def);
buf : 		bcma_write16(core, D11REGOFFS(xmtfifodef1), txfifo_def1);
ifodef1), txfifo_def1); 
buf : 
buf : 		bcma_write16(core, D11REGOFFS(xmtfifocmd), txfifo_cmd);
buf : 
buf : 		txfifo_startblk += wlc_hw->xmtfifo_sz[fifo_nu];
ifo_startblk += wlc_hw->xmtfifo_sz[fifo_nu]; 
buf : 	}
buf : 	/*
buf : 	 * need to propagate to shm location to be in sync since ucode/hw won't
buf : 	 * do this
buf : 	 */
buf : 	brcms_b_write_shm(wlc_hw, M_FIFOSIZE0,
buf : 			   wlc_hw->xmtfifo_sz[TX_AC_BE_FIFO]);
ifo_sz[TX_AC_BE_FIFO]); 
buf : 	brcms_b_write_shm(wlc_hw, M_FIFOSIZE1,
buf : 			   wlc_hw->xmtfifo_sz[TX_AC_VI_FIFO]);
ifo_sz[TX_AC_VI_FIFO]); 
buf : 	brcms_b_write_shm(wlc_hw, M_FIFOSIZE2,
buf : 			   ((wlc_hw->xmtfifo_sz[TX_AC_VO_FIFO] << 8) | wlc_hw->
ifo_sz[TX_AC_VO_FIFO] << 8) | wlc_hw-> 
buf : 			    xmtfifo_sz[TX_AC_BK_FIFO]));
buf : 	brcms_b_write_shm(wlc_hw, M_FIFOSIZE3,
buf : 			   ((wlc_hw->xmtfifo_sz[TX_ATIM_FIFO] << 8) | wlc_hw->
ifo_sz[TX_ATIM_FIFO] << 8) | wlc_hw-> 
buf : 			    xmtfifo_sz[TX_BCMC_FIFO]));
buf : }
buf : 
buf : /* This function is used for changing the tsf frac register
for changing the tsf frac register 
buf :  * If spur avoidance mode is off, the mac freq will be 80/120/160Mhz
buf :  * If spur avoidance mode is on1, the mac freq will be 82/123/164Mhz
buf :  * If spur avoidance mode is on2, the mac freq will be 84/126/168Mhz
buf :  * HTPHY Formula is 2^26/freq(MHz) e.g.
buf :  * For spuron2 - 126MHz -> 2^26/126 = 532610.0
buf :  *  - 532610 = 0x82082 => tsf_clk_frac_h = 0x8, tsf_clk_frac_l = 0x2082
buf :  * For spuron: 123MHz -> 2^26/123    = 545600.5
buf :  *  - 545601 = 0x85341 => tsf_clk_frac_h = 0x8, tsf_clk_frac_l = 0x5341
buf :  * For spur off: 120MHz -> 2^26/120    = 559240.5
buf :  *  - 559241 = 0x88889 => tsf_clk_frac_h = 0x8, tsf_clk_frac_l = 0x8889
buf :  */
buf : 
buf : void brcms_b_switch_macfreq(struct brcms_hardware *wlc_hw, u8 spurmode)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 
buf : 	if ((ai_get_chip_id(wlc_hw->sih) == BCMA_CHIP_ID_BCM43224) ||
if ((ai_get_chip_id(wlc_hw->sih) == BCMA_CHIP_ID_BCM43224) || 
buf : 	    (ai_get_chip_id(wlc_hw->sih) == BCMA_CHIP_ID_BCM43225)) {
buf : 		if (spurmode == WL_SPURAVOID_ON2) {	/* 126Mhz */
if (spurmode == WL_SPURAVOID_ON2) {	/* 126Mhz */ 
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_l), 0x2082);
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_h), 0x8);
buf : 		} else if (spurmode == WL_SPURAVOID_ON1) {	/* 123Mhz */
if (spurmode == WL_SPURAVOID_ON1) {	/* 123Mhz */ 
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_l), 0x5341);
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_h), 0x8);
buf : 		} else {	/* 120Mhz */
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_l), 0x8889);
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_h), 0x8);
buf : 		}
buf : 	} else if (BRCMS_ISLCNPHY(wlc_hw->band)) {
if (BRCMS_ISLCNPHY(wlc_hw->band)) { 
buf : 		if (spurmode == WL_SPURAVOID_ON1) {	/* 82Mhz */
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_l), 0x7CE0);
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_h), 0xC);
buf : 		} else {	/* 80Mhz */
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_l), 0xCCCD);
buf : 			bcma_write16(core, D11REGOFFS(tsf_clk_frac_h), 0xC);
buf : 		}
buf : 	}
buf : }
buf : 
buf : void brcms_c_start_station(struct brcms_c_info *wlc, u8 *addr)
buf : {
buf : 	memcpy(wlc->pub->cur_etheraddr, addr, sizeof(wlc->pub->cur_etheraddr));
buf : 	wlc->bsscfg->type = BRCMS_TYPE_STATION;
buf : }
buf : 
buf : void brcms_c_start_ap(struct brcms_c_info *wlc, u8 *addr, const u8 *bssid,
buf : 		      u8 *ssid, size_t ssid_len)
buf : {
buf : 	brcms_c_set_ssid(wlc, ssid, ssid_len);
buf : 
buf : 	memcpy(wlc->pub->cur_etheraddr, addr, sizeof(wlc->pub->cur_etheraddr));
buf : 	memcpy(wlc->bsscfg->BSSID, bssid, sizeof(wlc->bsscfg->BSSID));
buf : 	wlc->bsscfg->type = BRCMS_TYPE_AP;
buf : 
buf : 	brcms_b_mctrl(wlc->hw, MCTL_AP | MCTL_INFRA, MCTL_AP | MCTL_INFRA);
buf : }
buf : 
buf : void brcms_c_start_adhoc(struct brcms_c_info *wlc, u8 *addr)
buf : {
buf : 	memcpy(wlc->pub->cur_etheraddr, addr, sizeof(wlc->pub->cur_etheraddr));
buf : 	wlc->bsscfg->type = BRCMS_TYPE_ADHOC;
buf : 
buf : 	brcms_b_mctrl(wlc->hw, MCTL_AP | MCTL_INFRA, 0);
buf : }
buf : 
buf : /* Initialize GPIOs that are controlled by D11 core */
buf : static void brcms_c_gpio_init(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	u32 gc, gm;
buf : 
buf : 	/* use GPIO select 0 to get all gpio signals from the gpio out reg */
buf : 	brcms_b_mctrl(wlc_hw, MCTL_GPOUT_SEL_MASK, 0);
buf : 
buf : 	/*
buf : 	 * Common GPIO setup:
buf : 	 *      G0 = LED 0 = WLAN Activity
buf : 	 *      G1 = LED 1 = WLAN 2.4 GHz Radio State
buf : 	 *      G2 = LED 2 = WLAN 5 GHz Radio State
buf : 	 *      G4 = radio disable input (HI enabled, LO disabled)
buf : 	 */
buf : 
buf : 	gc = gm = 0;
buf : 
buf : 	/* Allocate GPIOs for mimo antenna diversity feature */
for mimo antenna diversity feature */ 
buf : 	if (wlc_hw->antsel_type == ANTSEL_2x3) {
buf : 		/* Enable antenna diversity, use 2x3 mode */
buf : 		brcms_b_mhf(wlc_hw, MHF3, MHF3_ANTSEL_EN,
buf : 			     MHF3_ANTSEL_EN, BRCM_BAND_ALL);
buf : 		brcms_b_mhf(wlc_hw, MHF3, MHF3_ANTSEL_MODE,
buf : 			     MHF3_ANTSEL_MODE, BRCM_BAND_ALL);
buf : 
buf : 		/* init superswitch control */
buf : 		wlc_phy_antsel_init(wlc_hw->band->pi, false);
buf : 
buf : 	} else if (wlc_hw->antsel_type == ANTSEL_2x4) {
if (wlc_hw->antsel_type == ANTSEL_2x4) { 
buf : 		gm |= gc |= (BOARD_GPIO_12 | BOARD_GPIO_13);
buf : 		/*
buf : 		 * The board itself is powered by these GPIOs
buf : 		 * (when not sending pattern) so set them high
buf : 		 */
buf : 		bcma_set16(wlc_hw->d11core, D11REGOFFS(psm_gpio_oe),
buf : 			   (BOARD_GPIO_12 | BOARD_GPIO_13));
buf : 		bcma_set16(wlc_hw->d11core, D11REGOFFS(psm_gpio_out),
buf : 			   (BOARD_GPIO_12 | BOARD_GPIO_13));
buf : 
buf : 		/* Enable antenna diversity, use 2x4 mode */
buf : 		brcms_b_mhf(wlc_hw, MHF3, MHF3_ANTSEL_EN,
buf : 			     MHF3_ANTSEL_EN, BRCM_BAND_ALL);
buf : 		brcms_b_mhf(wlc_hw, MHF3, MHF3_ANTSEL_MODE, 0,
buf : 			     BRCM_BAND_ALL);
buf : 
buf : 		/* Configure the desired clock to be 4Mhz */
buf : 		brcms_b_write_shm(wlc_hw, M_ANTSEL_CLKDIV,
buf : 				   ANTSEL_CLKDIV_4MHZ);
buf : 	}
buf : 
buf : 	/*
buf : 	 * gpio 9 controls the PA. ucode is responsible
buf : 	 * for wiggling out and oe
for wiggling out and oe 
buf : 	 */
buf : 	if (wlc_hw->boardflags & BFL_PACTRL)
if (wlc_hw->boardflags & BFL_PACTRL) 
buf : 		gm |= gc |= BOARD_GPIO_PACTRL;
buf : 
buf : 	/* apply to gpiocontrol register */
buf : 	bcma_chipco_gpio_control(&wlc_hw->d11core->bus->drv_cc, gm, gc);
buf : }
buf : 
buf : static void brcms_ucode_write(struct brcms_hardware *wlc_hw,
buf : 			      const __le32 ucode[], const size_t nbytes)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	uint i;
buf : 	uint count;
buf : 
buf : 	brcms_dbg_info(wlc_hw->d11core, "wl%d\n", wlc_hw->unit);
buf : 
buf : 	count = (nbytes / sizeof(u32));
buf : 
buf : 	bcma_write32(core, D11REGOFFS(objaddr),
buf : 		     OBJADDR_AUTO_INC | OBJADDR_UCM_SEL);
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	for (i = 0; i < count; i++)
for (i = 0; i < count; i++) 
buf : 		bcma_write32(core, D11REGOFFS(objdata), le32_to_cpu(ucode[i]));
buf : 
buf : }
buf : 
buf : static void brcms_ucode_download(struct brcms_hardware *wlc_hw)
buf : {
buf : 	struct brcms_c_info *wlc;
buf : 	struct brcms_ucode *ucode = &wlc_hw->wlc->wl->ucode;
buf : 
buf : 	wlc = wlc_hw->wlc;
buf : 
buf : 	if (wlc_hw->ucode_loaded)
if (wlc_hw->ucode_loaded) 
buf : 		return;
buf : 
buf : 	if (D11REV_IS(wlc_hw->corerev, 17) || D11REV_IS(wlc_hw->corerev, 23)) {
if (D11REV_IS(wlc_hw->corerev, 17) || D11REV_IS(wlc_hw->corerev, 23)) { 
buf : 		if (BRCMS_ISNPHY(wlc_hw->band)) {
buf : 			brcms_ucode_write(wlc_hw, ucode->bcm43xx_16_mimo,
buf : 					  ucode->bcm43xx_16_mimosz);
buf : 			wlc_hw->ucode_loaded = true;
buf : 		} else
buf : 			brcms_err(wlc_hw->d11core,
buf : 				  "%s: wl%d: unsupported phy in corerev %d\n",
buf : 				  __func__, wlc_hw->unit, wlc_hw->corerev);
buf : 	} else if (D11REV_IS(wlc_hw->corerev, 24)) {
if (D11REV_IS(wlc_hw->corerev, 24)) { 
buf : 		if (BRCMS_ISLCNPHY(wlc_hw->band)) {
buf : 			brcms_ucode_write(wlc_hw, ucode->bcm43xx_24_lcn,
buf : 					  ucode->bcm43xx_24_lcnsz);
buf : 			wlc_hw->ucode_loaded = true;
buf : 		} else {
buf : 			brcms_err(wlc_hw->d11core,
buf : 				  "%s: wl%d: unsupported phy in corerev %d\n",
buf : 				  __func__, wlc_hw->unit, wlc_hw->corerev);
buf : 		}
buf : 	}
buf : }
buf : 
buf : void brcms_b_txant_set(struct brcms_hardware *wlc_hw, u16 phytxant)
buf : {
buf : 	/* update sw state */
buf : 	wlc_hw->bmac_phytxant = phytxant;
buf : 
buf : 	/* push to ucode if up */
if up */ 
buf : 	if (!wlc_hw->up)
buf : 		return;
buf : 	brcms_c_ucode_txant_set(wlc_hw);
buf : 
buf : }
buf : 
buf : u16 brcms_b_get_txant(struct brcms_hardware *wlc_hw)
buf : {
buf : 	return (u16) wlc_hw->wlc->stf->txant;
buf : }
buf : 
buf : void brcms_b_antsel_type_set(struct brcms_hardware *wlc_hw, u8 antsel_type)
buf : {
buf : 	wlc_hw->antsel_type = antsel_type;
buf : 
buf : 	/* Update the antsel type for phy module to use */
for phy module to use */ 
buf : 	wlc_phy_antsel_type_set(wlc_hw->band->pi, antsel_type);
buf : }
buf : 
buf : static void brcms_b_fifoerrors(struct brcms_hardware *wlc_hw)
ifoerrors(struct brcms_hardware *wlc_hw) 
buf : {
buf : 	bool fatal = false;
buf : 	uint unit;
buf : 	uint intstatus, idx;
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 
buf : 	unit = wlc_hw->unit;
buf : 
buf : 	for (idx = 0; idx < NFIFO; idx++) {
for (idx = 0; idx < NFIFO; idx++) { 
buf : 		/* read intstatus register and ignore any non-error bits */
buf : 		intstatus =
buf : 			bcma_read32(core,
buf : 				    D11REGOFFS(intctrlregs[idx].intstatus)) &
buf : 			I_ERRORS;
buf : 		if (!intstatus)
if (!intstatus) 
buf : 			continue;
buf : 
buf : 		brcms_dbg_int(core, "wl%d: intstatus%d 0x%x\n",
buf : 			      unit, idx, intstatus);
buf : 
buf : 		if (intstatus & I_RO) {
if (intstatus & I_RO) { 
buf : 			brcms_err(core, "wl%d: fifo %d: receive fifo "
buf : 				  "overflow\n", unit, idx);
buf : 			fatal = true;
buf : 		}
buf : 
buf : 		if (intstatus & I_PC) {
if (intstatus & I_PC) { 
buf : 			brcms_err(core, "wl%d: fifo %d: descriptor error\n",
buf : 				  unit, idx);
buf : 			fatal = true;
buf : 		}
buf : 
buf : 		if (intstatus & I_PD) {
if (intstatus & I_PD) { 
buf : 			brcms_err(core, "wl%d: fifo %d: data error\n", unit,
buf : 				  idx);
buf : 			fatal = true;
buf : 		}
buf : 
buf : 		if (intstatus & I_DE) {
if (intstatus & I_DE) { 
buf : 			brcms_err(core, "wl%d: fifo %d: descriptor protocol "
buf : 				  "error\n", unit, idx);
buf : 			fatal = true;
buf : 		}
buf : 
buf : 		if (intstatus & I_RU)
if (intstatus & I_RU) 
buf : 			brcms_err(core, "wl%d: fifo %d: receive descriptor "
buf : 				  "underflow\n", idx, unit);
buf : 
buf : 		if (intstatus & I_XU) {
if (intstatus & I_XU) { 
buf : 			brcms_err(core, "wl%d: fifo %d: transmit fifo "
buf : 				  "underflow\n", idx, unit);
buf : 			fatal = true;
buf : 		}
buf : 
buf : 		if (fatal) {
if (fatal) { 
buf : 			brcms_fatal_error(wlc_hw->wlc->wl); /* big hammer */
buf : 			break;
buf : 		} else
buf : 			bcma_write32(core,
buf : 				     D11REGOFFS(intctrlregs[idx].intstatus),
buf : 				     intstatus);
buf : 	}
buf : }
buf : 
buf : void brcms_c_intrson(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	wlc->macintmask = wlc->defmacintmask;
buf : 	bcma_write32(wlc_hw->d11core, D11REGOFFS(macintmask), wlc->macintmask);
buf : }
buf : 
buf : u32 brcms_c_intrsoff(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	u32 macintmask;
buf : 
buf : 	if (!wlc_hw->clk)
if (!wlc_hw->clk) 
buf : 		return 0;
buf : 
buf : 	macintmask = wlc->macintmask;	/* isr can still happen */
buf : 
buf : 	bcma_write32(wlc_hw->d11core, D11REGOFFS(macintmask), 0);
buf : 	(void)bcma_read32(wlc_hw->d11core, D11REGOFFS(macintmask));
buf : 	udelay(1);		/* ensure int line is no longer driven */
buf : 	wlc->macintmask = 0;
buf : 
buf : 	/* return previous macintmask; resolve race between us and our isr */
buf : 	return wlc->macintstatus ? 0 : macintmask;
buf : }
buf : 
buf : void brcms_c_intrsrestore(struct brcms_c_info *wlc, u32 macintmask)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	if (!wlc_hw->clk)
if (!wlc_hw->clk) 
buf : 		return;
buf : 
buf : 	wlc->macintmask = macintmask;
buf : 	bcma_write32(wlc_hw->d11core, D11REGOFFS(macintmask), wlc->macintmask);
buf : }
buf : 
buf : /* assumes that the d11 MAC is enabled */
buf : static void brcms_b_tx_fifo_suspend(struct brcms_hardware *wlc_hw,
ifo_suspend(struct brcms_hardware *wlc_hw, 
buf : 				    uint tx_fifo)
buf : {
buf : 	u8 fifo = 1 << tx_fifo;
ifo = 1 << tx_fifo; 
buf : 
buf : 	/* Two clients of this code, 11h Quiet period and scanning. */
buf : 
buf : 	/* only suspend if not already suspended */
if not already suspended */ 
buf : 	if ((wlc_hw->suspended_fifos & fifo) == fifo)
buf : 		return;
buf : 
buf : 	/* force the core awake only if not already */
if not already */ 
buf : 	if (wlc_hw->suspended_fifos == 0)
buf : 		brcms_c_ucode_wake_override_set(wlc_hw,
buf : 						BRCMS_WAKE_OVERRIDE_TXFIFO);
buf : 
buf : 	wlc_hw->suspended_fifos |= fifo;
ifos |= fifo; 
buf : 
buf : 	if (wlc_hw->di[tx_fifo]) {
buf : 		/*
buf : 		 * Suspending AMPDU transmissions in the middle can cause
buf : 		 * underflow which may result in mismatch between ucode and
buf : 		 * driver so suspend the mac before suspending the FIFO
fore suspending the FIFO 
buf : 		 */
buf : 		if (BRCMS_PHY_11N_CAP(wlc_hw->band))
if (BRCMS_PHY_11N_CAP(wlc_hw->band)) 
buf : 			brcms_c_suspend_mac_and_wait(wlc_hw->wlc);
buf : 
buf : 		dma_txsuspend(wlc_hw->di[tx_fifo]);
ifo]); 
buf : 
buf : 		if (BRCMS_PHY_11N_CAP(wlc_hw->band))
buf : 			brcms_c_enable_mac(wlc_hw->wlc);
buf : 	}
buf : }
buf : 
buf : static void brcms_b_tx_fifo_resume(struct brcms_hardware *wlc_hw,
ifo_resume(struct brcms_hardware *wlc_hw, 
buf : 				   uint tx_fifo)
buf : {
buf : 	/* BMAC_NOTE: BRCMS_TX_FIFO_ENAB is done in brcms_c_dpc() for DMA case
for DMA case 
buf : 	 * but need to be done here for PIO otherwise the watchdog will catch
buf : 	 * the inconsistency and fire
buf : 	 */
buf : 	/* Two clients of this code, 11h Quiet period and scanning. */
buf : 	if (wlc_hw->di[tx_fifo])
if (wlc_hw->di[tx_fifo]) 
buf : 		dma_txresume(wlc_hw->di[tx_fifo]);
buf : 
buf : 	/* allow core to sleep again */
buf : 	if (wlc_hw->suspended_fifos == 0)
if (wlc_hw->suspended_fifos == 0) 
buf : 		return;
buf : 	else {
buf : 		wlc_hw->suspended_fifos &= ~(1 << tx_fifo);
ifos &= ~(1 << tx_fifo); 
buf : 		if (wlc_hw->suspended_fifos == 0)
buf : 			brcms_c_ucode_wake_override_clear(wlc_hw,
buf : 						BRCMS_WAKE_OVERRIDE_TXFIFO);
buf : 	}
buf : }
buf : 
buf : /* precondition: requires the mac core to be enabled */
buf : static void brcms_b_mute(struct brcms_hardware *wlc_hw, bool mute_tx)
buf : {
buf : 	static const u8 null_ether_addr[ETH_ALEN] = {0, 0, 0, 0, 0, 0};
buf : 	u8 *ethaddr = wlc_hw->wlc->pub->cur_etheraddr;
buf : 
buf : 	if (mute_tx) {
if (mute_tx) { 
buf : 		/* suspend tx fifos */
buf : 		brcms_b_tx_fifo_suspend(wlc_hw, TX_DATA_FIFO);
ifo_suspend(wlc_hw, TX_DATA_FIFO); 
buf : 		brcms_b_tx_fifo_suspend(wlc_hw, TX_CTL_FIFO);
buf : 		brcms_b_tx_fifo_suspend(wlc_hw, TX_AC_BK_FIFO);
ifo_suspend(wlc_hw, TX_AC_BK_FIFO); 
buf : 		brcms_b_tx_fifo_suspend(wlc_hw, TX_AC_VI_FIFO);
buf : 
buf : 		/* zero the address match register so we do not send ACKs */
buf : 		brcms_b_set_addrmatch(wlc_hw, RCM_MAC_OFFSET, null_ether_addr);
buf : 	} else {
buf : 		/* resume tx fifos */
ifos */ 
buf : 		brcms_b_tx_fifo_resume(wlc_hw, TX_DATA_FIFO);
buf : 		brcms_b_tx_fifo_resume(wlc_hw, TX_CTL_FIFO);
ifo_resume(wlc_hw, TX_CTL_FIFO); 
buf : 		brcms_b_tx_fifo_resume(wlc_hw, TX_AC_BK_FIFO);
buf : 		brcms_b_tx_fifo_resume(wlc_hw, TX_AC_VI_FIFO);
ifo_resume(wlc_hw, TX_AC_VI_FIFO); 
buf : 
buf : 		/* Restore address */
buf : 		brcms_b_set_addrmatch(wlc_hw, RCM_MAC_OFFSET, ethaddr);
buf : 	}
buf : 
buf : 	wlc_phy_mute_upd(wlc_hw->band->pi, mute_tx, 0);
buf : 
buf : 	if (mute_tx)
if (mute_tx) 
buf : 		brcms_c_ucode_mute_override_set(wlc_hw);
buf : 	else
buf : 		brcms_c_ucode_mute_override_clear(wlc_hw);
buf : }
buf : 
buf : void
buf : brcms_c_mute(struct brcms_c_info *wlc, bool mute_tx)
buf : {
buf : 	brcms_b_mute(wlc->hw, mute_tx);
buf : }
buf : 
buf : /*
buf :  * Read and clear macintmask and macintstatus and intstatus registers.
buf :  * This routine should be called with interrupts off
buf :  * Return:
buf :  *   -1 if brcms_deviceremoved(wlc) evaluates to true;
if brcms_deviceremoved(wlc) evaluates to true; 
buf :  *   0 if the interrupt is not for us, or we are in some special cases;
for us, or we are in some special cases; 
buf :  *   device interrupt status bits otherwise.
buf :  */
buf : static inline u32 wlc_intstatus(struct brcms_c_info *wlc, bool in_isr)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u32 macintstatus, mask;
buf : 
buf : 	/* macintstatus includes a DMA interrupt summary bit */
buf : 	macintstatus = bcma_read32(core, D11REGOFFS(macintstatus));
buf : 	mask = in_isr ? wlc->macintmask : wlc->defmacintmask;
buf : 
buf : 	trace_brcms_macintstatus(&core->dev, in_isr, macintstatus, mask);
buf : 
buf : 	/* detect cardbus removed, in power down(suspend) and in reset */
buf : 	if (brcms_deviceremoved(wlc))
if (brcms_deviceremoved(wlc)) 
buf : 		return -1;
buf : 
buf : 	/* brcms_deviceremoved() succeeds even when the core is still resetting,
buf : 	 * handle that case here.
buf : 	 */
buf : 	if (macintstatus == 0xffffffff)
if (macintstatus == 0xffffffff) 
buf : 		return 0;
buf : 
buf : 	/* defer unsolicited interrupts */
buf : 	macintstatus &= mask;
buf : 
buf : 	/* if not for us */
if not for us */ 
buf : 	if (macintstatus == 0)
buf : 		return 0;
buf : 
buf : 	/* turn off the interrupts */
buf : 	bcma_write32(core, D11REGOFFS(macintmask), 0);
buf : 	(void)bcma_read32(core, D11REGOFFS(macintmask));
buf : 	wlc->macintmask = 0;
buf : 
buf : 	/* clear device interrupts */
buf : 	bcma_write32(core, D11REGOFFS(macintstatus), macintstatus);
buf : 
buf : 	/* MI_DMAINT is indication of non-zero intstatus */
buf : 	if (macintstatus & MI_DMAINT)
if (macintstatus & MI_DMAINT) 
buf : 		/*
buf : 		 * only fifo interrupt enabled is I_RI in
ifo interrupt enabled is I_RI in 
buf : 		 * RX_FIFO. If MI_DMAINT is set, assume it
buf : 		 * is set and clear the interrupt.
buf : 		 */
buf : 		bcma_write32(core, D11REGOFFS(intctrlregs[RX_FIFO].intstatus),
buf : 			     DEF_RXINTMASK);
buf : 
buf : 	return macintstatus;
buf : }
buf : 
buf : /* Update wlc->macintstatus and wlc->intstatus[]. */
buf : /* Return true if they are updated successfully. false otherwise */
if they are updated successfully. false otherwise */ 
buf : bool brcms_c_intrsupd(struct brcms_c_info *wlc)
buf : {
buf : 	u32 macintstatus;
buf : 
buf : 	/* read and clear macintstatus and intstatus registers */
buf : 	macintstatus = wlc_intstatus(wlc, false);
buf : 
buf : 	/* device is removed */
buf : 	if (macintstatus == 0xffffffff)
if (macintstatus == 0xffffffff) 
buf : 		return false;
buf : 
buf : 	/* update interrupt status in software */
buf : 	wlc->macintstatus |= macintstatus;
buf : 
buf : 	return true;
buf : }
buf : 
buf : /*
buf :  * First-level interrupt processing.
buf :  * Return true if this was our interrupt
if this was our interrupt 
buf :  * and if further brcms_c_dpc() processing is required,
buf :  * false otherwise.
buf :  */
buf : bool brcms_c_isr(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	u32 macintstatus;
buf : 
buf : 	if (!wlc_hw->up || !wlc->macintmask)
if (!wlc_hw->up || !wlc->macintmask) 
buf : 		return false;
buf : 
buf : 	/* read and clear macintstatus and intstatus registers */
buf : 	macintstatus = wlc_intstatus(wlc, true);
buf : 
buf : 	if (macintstatus == 0xffffffff) {
if (macintstatus == 0xffffffff) { 
buf : 		brcms_err(wlc_hw->d11core,
buf : 			  "DEVICEREMOVED detected in the ISR code path\n");
buf : 		return false;
buf : 	}
buf : 
buf : 	/* it is not for us */
for us */ 
buf : 	if (macintstatus == 0)
buf : 		return false;
buf : 
buf : 	/* save interrupt status bits */
buf : 	wlc->macintstatus = macintstatus;
buf : 
buf : 	return true;
buf : 
buf : }
buf : 
buf : void brcms_c_suspend_mac_and_wait(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u32 mc, mi;
buf : 
buf : 	brcms_dbg_mac80211(core, "wl%d: bandunit %d\n", wlc_hw->unit,
buf : 			   wlc_hw->band->bandunit);
buf : 
buf : 	/*
buf : 	 * Track overlapping suspend requests
buf : 	 */
buf : 	wlc_hw->mac_suspend_depth++;
buf : 	if (wlc_hw->mac_suspend_depth > 1)
if (wlc_hw->mac_suspend_depth > 1) 
buf : 		return;
buf : 
buf : 	/* force the core awake */
force the core awake */ 
buf : 	brcms_c_ucode_wake_override_set(wlc_hw, BRCMS_WAKE_OVERRIDE_MACSUSPEND);
buf : 
buf : 	mc = bcma_read32(core, D11REGOFFS(maccontrol));
buf : 
buf : 	if (mc == 0xffffffff) {
if (mc == 0xffffffff) { 
buf : 		brcms_err(core, "wl%d: %s: dead chip\n", wlc_hw->unit,
buf : 			  __func__);
buf : 		brcms_down(wlc->wl);
buf : 		return;
buf : 	}
buf : 	WARN_ON(mc & MCTL_PSM_JMP_0);
buf : 	WARN_ON(!(mc & MCTL_PSM_RUN));
buf : 	WARN_ON(!(mc & MCTL_EN_MAC));
buf : 
buf : 	mi = bcma_read32(core, D11REGOFFS(macintstatus));
buf : 	if (mi == 0xffffffff) {
if (mi == 0xffffffff) { 
buf : 		brcms_err(core, "wl%d: %s: dead chip\n", wlc_hw->unit,
buf : 			  __func__);
buf : 		brcms_down(wlc->wl);
buf : 		return;
buf : 	}
buf : 	WARN_ON(mi & MI_MACSSPNDD);
buf : 
buf : 	brcms_b_mctrl(wlc_hw, MCTL_EN_MAC, 0);
buf : 
buf : 	SPINWAIT(!(bcma_read32(core, D11REGOFFS(macintstatus)) & MI_MACSSPNDD),
buf : 		 BRCMS_MAX_MAC_SUSPEND);
buf : 
buf : 	if (!(bcma_read32(core, D11REGOFFS(macintstatus)) & MI_MACSSPNDD)) {
if (!(bcma_read32(core, D11REGOFFS(macintstatus)) & MI_MACSSPNDD)) { 
buf : 		brcms_err(core, "wl%d: wlc_suspend_mac_and_wait: waited %d uS"
buf : 			  " and MI_MACSSPNDD is still not on.\n",
buf : 			  wlc_hw->unit, BRCMS_MAX_MAC_SUSPEND);
buf : 		brcms_err(core, "wl%d: psmdebug 0x%08x, phydebug 0x%08x, "
buf : 			  "psm_brc 0x%04x\n", wlc_hw->unit,
buf : 			  bcma_read32(core, D11REGOFFS(psmdebug)),
buf : 			  bcma_read32(core, D11REGOFFS(phydebug)),
buf : 			  bcma_read16(core, D11REGOFFS(psm_brc)));
buf : 	}
buf : 
buf : 	mc = bcma_read32(core, D11REGOFFS(maccontrol));
buf : 	if (mc == 0xffffffff) {
if (mc == 0xffffffff) { 
buf : 		brcms_err(core, "wl%d: %s: dead chip\n", wlc_hw->unit,
buf : 			  __func__);
buf : 		brcms_down(wlc->wl);
buf : 		return;
buf : 	}
buf : 	WARN_ON(mc & MCTL_PSM_JMP_0);
buf : 	WARN_ON(!(mc & MCTL_PSM_RUN));
buf : 	WARN_ON(mc & MCTL_EN_MAC);
buf : }
buf : 
buf : void brcms_c_enable_mac(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u32 mc, mi;
buf : 
buf : 	brcms_dbg_mac80211(core, "wl%d: bandunit %d\n", wlc_hw->unit,
buf : 			   wlc->band->bandunit);
buf : 
buf : 	/*
buf : 	 * Track overlapping suspend requests
buf : 	 */
buf : 	wlc_hw->mac_suspend_depth--;
buf : 	if (wlc_hw->mac_suspend_depth > 0)
if (wlc_hw->mac_suspend_depth > 0) 
buf : 		return;
buf : 
buf : 	mc = bcma_read32(core, D11REGOFFS(maccontrol));
buf : 	WARN_ON(mc & MCTL_PSM_JMP_0);
buf : 	WARN_ON(mc & MCTL_EN_MAC);
buf : 	WARN_ON(!(mc & MCTL_PSM_RUN));
buf : 
buf : 	brcms_b_mctrl(wlc_hw, MCTL_EN_MAC, MCTL_EN_MAC);
buf : 	bcma_write32(core, D11REGOFFS(macintstatus), MI_MACSSPNDD);
buf : 
buf : 	mc = bcma_read32(core, D11REGOFFS(maccontrol));
buf : 	WARN_ON(mc & MCTL_PSM_JMP_0);
buf : 	WARN_ON(!(mc & MCTL_EN_MAC));
buf : 	WARN_ON(!(mc & MCTL_PSM_RUN));
buf : 
buf : 	mi = bcma_read32(core, D11REGOFFS(macintstatus));
buf : 	WARN_ON(mi & MI_MACSSPNDD);
buf : 
buf : 	brcms_c_ucode_wake_override_clear(wlc_hw,
buf : 					  BRCMS_WAKE_OVERRIDE_MACSUSPEND);
buf : }
buf : 
buf : void brcms_b_band_stf_ss_set(struct brcms_hardware *wlc_hw, u8 stf_mode)
buf : {
buf : 	wlc_hw->hw_stf_ss_opmode = stf_mode;
buf : 
buf : 	if (wlc_hw->clk)
if (wlc_hw->clk) 
buf : 		brcms_upd_ofdm_pctl1_table(wlc_hw);
buf : }
buf : 
buf : static bool brcms_b_validate_chip_access(struct brcms_hardware *wlc_hw)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u32 w, val;
buf : 	struct wiphy *wiphy = wlc_hw->wlc->wiphy;
buf : 
buf : 	/* Validate dchip register access */
buf : 
buf : 	bcma_write32(core, D11REGOFFS(objaddr), OBJADDR_SHM_SEL | 0);
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	w = bcma_read32(core, D11REGOFFS(objdata));
buf : 
buf : 	/* Can we write and read back a 32bit register? */
buf : 	bcma_write32(core, D11REGOFFS(objaddr), OBJADDR_SHM_SEL | 0);
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	bcma_write32(core, D11REGOFFS(objdata), (u32) 0xaa5555aa);
buf : 
buf : 	bcma_write32(core, D11REGOFFS(objaddr), OBJADDR_SHM_SEL | 0);
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	val = bcma_read32(core, D11REGOFFS(objdata));
buf : 	if (val != (u32) 0xaa5555aa) {
if (val != (u32) 0xaa5555aa) { 
buf : 		wiphy_err(wiphy, "wl%d: validate_chip_access: SHM = 0x%x, "
buf : 			  "expected 0xaa5555aa\n", wlc_hw->unit, val);
buf : 		return false;
buf : 	}
buf : 
buf : 	bcma_write32(core, D11REGOFFS(objaddr), OBJADDR_SHM_SEL | 0);
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	bcma_write32(core, D11REGOFFS(objdata), (u32) 0x55aaaa55);
buf : 
buf : 	bcma_write32(core, D11REGOFFS(objaddr), OBJADDR_SHM_SEL | 0);
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	val = bcma_read32(core, D11REGOFFS(objdata));
buf : 	if (val != (u32) 0x55aaaa55) {
if (val != (u32) 0x55aaaa55) { 
buf : 		wiphy_err(wiphy, "wl%d: validate_chip_access: SHM = 0x%x, "
buf : 			  "expected 0x55aaaa55\n", wlc_hw->unit, val);
buf : 		return false;
buf : 	}
buf : 
buf : 	bcma_write32(core, D11REGOFFS(objaddr), OBJADDR_SHM_SEL | 0);
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	bcma_write32(core, D11REGOFFS(objdata), w);
buf : 
buf : 	/* clear CFPStart */
buf : 	bcma_write32(core, D11REGOFFS(tsf_cfpstart), 0);
buf : 
buf : 	w = bcma_read32(core, D11REGOFFS(maccontrol));
buf : 	if ((w != (MCTL_IHR_EN | MCTL_WAKE)) &&
if ((w != (MCTL_IHR_EN | MCTL_WAKE)) && 
buf : 	    (w != (MCTL_IHR_EN | MCTL_GMODE | MCTL_WAKE))) {
buf : 		wiphy_err(wiphy, "wl%d: validate_chip_access: maccontrol = "
buf : 			  "0x%x, expected 0x%x or 0x%x\n", wlc_hw->unit, w,
buf : 			  (MCTL_IHR_EN | MCTL_WAKE),
buf : 			  (MCTL_IHR_EN | MCTL_GMODE | MCTL_WAKE));
buf : 		return false;
buf : 	}
buf : 
buf : 	return true;
buf : }
buf : 
buf : #define PHYPLL_WAIT_US	100000
buf : 
buf : void brcms_b_core_phypll_ctl(struct brcms_hardware *wlc_hw, bool on)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u32 tmp;
buf : 
buf : 	brcms_dbg_info(core, "wl%d\n", wlc_hw->unit);
buf : 
buf : 	tmp = 0;
buf : 
buf : 	if (on) {
if (on) { 
buf : 		if ((ai_get_chip_id(wlc_hw->sih) == BCMA_CHIP_ID_BCM4313)) {
buf : 			bcma_set32(core, D11REGOFFS(clk_ctl_st),
buf : 				   CCS_ERSRC_REQ_HT |
buf : 				   CCS_ERSRC_REQ_D11PLL |
buf : 				   CCS_ERSRC_REQ_PHYPLL);
buf : 			SPINWAIT((bcma_read32(core, D11REGOFFS(clk_ctl_st)) &
buf : 				  CCS_ERSRC_AVAIL_HT) != CCS_ERSRC_AVAIL_HT,
buf : 				 PHYPLL_WAIT_US);
buf : 
buf : 			tmp = bcma_read32(core, D11REGOFFS(clk_ctl_st));
buf : 			if ((tmp & CCS_ERSRC_AVAIL_HT) != CCS_ERSRC_AVAIL_HT)
if ((tmp & CCS_ERSRC_AVAIL_HT) != CCS_ERSRC_AVAIL_HT) 
buf : 				brcms_err(core, "%s: turn on PHY PLL failed\n",
buf : 					  __func__);
buf : 		} else {
buf : 			bcma_set32(core, D11REGOFFS(clk_ctl_st),
buf : 				   tmp | CCS_ERSRC_REQ_D11PLL |
buf : 				   CCS_ERSRC_REQ_PHYPLL);
buf : 			SPINWAIT((bcma_read32(core, D11REGOFFS(clk_ctl_st)) &
buf : 				  (CCS_ERSRC_AVAIL_D11PLL |
buf : 				   CCS_ERSRC_AVAIL_PHYPLL)) !=
buf : 				 (CCS_ERSRC_AVAIL_D11PLL |
buf : 				  CCS_ERSRC_AVAIL_PHYPLL), PHYPLL_WAIT_US);
buf : 
buf : 			tmp = bcma_read32(core, D11REGOFFS(clk_ctl_st));
buf : 			if ((tmp &
if ((tmp & 
buf : 			     (CCS_ERSRC_AVAIL_D11PLL | CCS_ERSRC_AVAIL_PHYPLL))
buf : 			    !=
buf : 			    (CCS_ERSRC_AVAIL_D11PLL | CCS_ERSRC_AVAIL_PHYPLL))
buf : 				brcms_err(core, "%s: turn on PHY PLL failed\n",
buf : 					  __func__);
buf : 		}
buf : 	} else {
buf : 		/*
buf : 		 * Since the PLL may be shared, other cores can still
buf : 		 * be requesting it; so we'll deassert the request but
buf : 		 * not wait for status to comply.
for status to comply. 
buf : 		 */
buf : 		bcma_mask32(core, D11REGOFFS(clk_ctl_st),
buf : 			    ~CCS_ERSRC_REQ_PHYPLL);
buf : 		(void)bcma_read32(core, D11REGOFFS(clk_ctl_st));
buf : 	}
buf : }
buf : 
buf : static void brcms_c_coredisable(struct brcms_hardware *wlc_hw)
buf : {
buf : 	bool dev_gone;
buf : 
buf : 	brcms_dbg_info(wlc_hw->d11core, "wl%d: disable core\n", wlc_hw->unit);
buf : 
buf : 	dev_gone = brcms_deviceremoved(wlc_hw->wlc);
buf : 
buf : 	if (dev_gone)
if (dev_gone) 
buf : 		return;
buf : 
buf : 	if (wlc_hw->noreset)
if (wlc_hw->noreset) 
buf : 		return;
buf : 
buf : 	/* radio off */
buf : 	wlc_phy_switch_radio(wlc_hw->band->pi, OFF);
buf : 
buf : 	/* turn off analog core */
buf : 	wlc_phy_anacore(wlc_hw->band->pi, OFF);
buf : 
buf : 	/* turn off PHYPLL to save power */
buf : 	brcms_b_core_phypll_ctl(wlc_hw, false);
buf : 
buf : 	wlc_hw->clk = false;
buf : 	bcma_core_disable(wlc_hw->d11core, 0);
buf : 	wlc_phy_hw_clk_state_upd(wlc_hw->band->pi, false);
buf : }
buf : 
buf : static void brcms_c_flushqueues(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	uint i;
buf : 
buf : 	/* free any posted tx packets */
buf : 	for (i = 0; i < NFIFO; i++) {
for (i = 0; i < NFIFO; i++) { 
buf : 		if (wlc_hw->di[i]) {
buf : 			dma_txreclaim(wlc_hw->di[i], DMA_RANGE_ALL);
buf : 			if (i < TX_BCMC_FIFO)
if (i < TX_BCMC_FIFO) 
buf : 				ieee80211_wake_queue(wlc->pub->ieee_hw,
buf : 						     brcms_fifo_to_ac(i));
ifo_to_ac(i)); 
buf : 		}
buf : 	}
buf : 
buf : 	/* free any posted rx packets */
buf : 	dma_rxreclaim(wlc_hw->di[RX_FIFO]);
buf : }
buf : 
buf : static u16
buf : brcms_b_read_objmem(struct brcms_hardware *wlc_hw, uint offset, u32 sel)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u16 objoff = D11REGOFFS(objdata);
buf : 
buf : 	bcma_write32(core, D11REGOFFS(objaddr), sel | (offset >> 2));
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	if (offset & 2)
if (offset & 2) 
buf : 		objoff += 2;
buf : 
buf : 	return bcma_read16(core, objoff);
buf : }
buf : 
buf : static void
buf : brcms_b_write_objmem(struct brcms_hardware *wlc_hw, uint offset, u16 v,
buf : 		     u32 sel)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u16 objoff = D11REGOFFS(objdata);
buf : 
buf : 	bcma_write32(core, D11REGOFFS(objaddr), sel | (offset >> 2));
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	if (offset & 2)
if (offset & 2) 
buf : 		objoff += 2;
buf : 
buf : 	bcma_wflush16(core, objoff, v);
buf : }
buf : 
buf : /*
buf :  * Read a single u16 from shared memory.
buf :  * SHM 'offset' needs to be an even address
buf :  */
buf : u16 brcms_b_read_shm(struct brcms_hardware *wlc_hw, uint offset)
buf : {
buf : 	return brcms_b_read_objmem(wlc_hw, offset, OBJADDR_SHM_SEL);
buf : }
buf : 
buf : /*
buf :  * Write a single u16 to shared memory.
buf :  * SHM 'offset' needs to be an even address
buf :  */
buf : void brcms_b_write_shm(struct brcms_hardware *wlc_hw, uint offset, u16 v)
buf : {
buf : 	brcms_b_write_objmem(wlc_hw, offset, v, OBJADDR_SHM_SEL);
buf : }
buf : 
buf : /*
buf :  * Copy a buffer to shared memory of specified type .
ified type . 
buf :  * SHM 'offset' needs to be an even address and
buf :  * Buffer length 'len' must be an even number of bytes
buf :  * 'sel' selects the type of memory
buf :  */
buf : void
buf : brcms_b_copyto_objmem(struct brcms_hardware *wlc_hw, uint offset,
buf : 		      const void *buf, int len, u32 sel)
buf : {
buf : 	u16 v;
buf : 	const u8 *p = (const u8 *)buf;
buf : 	int i;
buf : 
buf : 	if (len <= 0 || (offset & 1) || (len & 1))
if (len <= 0 || (offset & 1) || (len & 1)) 
buf : 		return;
buf : 
buf : 	for (i = 0; i < len; i += 2) {
for (i = 0; i < len; i += 2) { 
buf : 		v = p[i] | (p[i + 1] << 8);
buf : 		brcms_b_write_objmem(wlc_hw, offset + i, v, sel);
buf : 	}
buf : }
buf : 
buf : /*
buf :  * Copy a piece of shared memory of specified type to a buffer .
ified type to a buffer . 
buf :  * SHM 'offset' needs to be an even address and
buf :  * Buffer length 'len' must be an even number of bytes
buf :  * 'sel' selects the type of memory
buf :  */
buf : void
buf : brcms_b_copyfrom_objmem(struct brcms_hardware *wlc_hw, uint offset, void *buf,
buf : 			 int len, u32 sel)
buf : {
buf : 	u16 v;
buf : 	u8 *p = (u8 *) buf;
buf : 	int i;
buf : 
buf : 	if (len <= 0 || (offset & 1) || (len & 1))
if (len <= 0 || (offset & 1) || (len & 1)) 
buf : 		return;
buf : 
buf : 	for (i = 0; i < len; i += 2) {
for (i = 0; i < len; i += 2) { 
buf : 		v = brcms_b_read_objmem(wlc_hw, offset + i, sel);
buf : 		p[i] = v & 0xFF;
buf : 		p[i + 1] = (v >> 8) & 0xFF;
buf : 	}
buf : }
buf : 
buf : /* Copy a buffer to shared memory.
buf :  * SHM 'offset' needs to be an even address and
buf :  * Buffer length 'len' must be an even number of bytes
buf :  */
buf : static void brcms_c_copyto_shm(struct brcms_c_info *wlc, uint offset,
buf : 			const void *buf, int len)
buf : {
buf : 	brcms_b_copyto_objmem(wlc->hw, offset, buf, len, OBJADDR_SHM_SEL);
buf : }
buf : 
buf : static void brcms_b_retrylimit_upd(struct brcms_hardware *wlc_hw,
buf : 				   u16 SRL, u16 LRL)
buf : {
buf : 	wlc_hw->SRL = SRL;
buf : 	wlc_hw->LRL = LRL;
buf : 
buf : 	/* write retry limit to SCR, shouldn't need to suspend */
buf : 	if (wlc_hw->up) {
if (wlc_hw->up) { 
buf : 		bcma_write32(wlc_hw->d11core, D11REGOFFS(objaddr),
buf : 			     OBJADDR_SCR_SEL | S_DOT11_SRC_LMT);
buf : 		(void)bcma_read32(wlc_hw->d11core, D11REGOFFS(objaddr));
buf : 		bcma_write32(wlc_hw->d11core, D11REGOFFS(objdata), wlc_hw->SRL);
buf : 		bcma_write32(wlc_hw->d11core, D11REGOFFS(objaddr),
buf : 			     OBJADDR_SCR_SEL | S_DOT11_LRC_LMT);
buf : 		(void)bcma_read32(wlc_hw->d11core, D11REGOFFS(objaddr));
buf : 		bcma_write32(wlc_hw->d11core, D11REGOFFS(objdata), wlc_hw->LRL);
buf : 	}
buf : }
buf : 
buf : static void brcms_b_pllreq(struct brcms_hardware *wlc_hw, bool set, u32 req_bit)
buf : {
buf : 	if (set) {
if (set) { 
buf : 		if (mboolisset(wlc_hw->pllreq, req_bit))
buf : 			return;
buf : 
buf : 		mboolset(wlc_hw->pllreq, req_bit);
buf : 
buf : 		if (mboolisset(wlc_hw->pllreq, BRCMS_PLLREQ_FLIP)) {
if (mboolisset(wlc_hw->pllreq, BRCMS_PLLREQ_FLIP)) { 
buf : 			if (!wlc_hw->sbclk)
buf : 				brcms_b_xtal(wlc_hw, ON);
buf : 		}
buf : 	} else {
buf : 		if (!mboolisset(wlc_hw->pllreq, req_bit))
if (!mboolisset(wlc_hw->pllreq, req_bit)) 
buf : 			return;
buf : 
buf : 		mboolclr(wlc_hw->pllreq, req_bit);
buf : 
buf : 		if (mboolisset(wlc_hw->pllreq, BRCMS_PLLREQ_FLIP)) {
if (mboolisset(wlc_hw->pllreq, BRCMS_PLLREQ_FLIP)) { 
buf : 			if (wlc_hw->sbclk)
buf : 				brcms_b_xtal(wlc_hw, OFF);
buf : 		}
buf : 	}
buf : }
buf : 
buf : static void brcms_b_antsel_set(struct brcms_hardware *wlc_hw, u32 antsel_avail)
buf : {
buf : 	wlc_hw->antsel_avail = antsel_avail;
buf : }
buf : 
buf : /*
buf :  * conditions under which the PM bit should be set in outgoing frames
buf :  * and STAY_AWAKE is meaningful
buf :  */
buf : static bool brcms_c_ps_allowed(struct brcms_c_info *wlc)
buf : {
buf : 	/* not supporting PS so always return false for now */
for now */ 
buf : 	return false;
buf : }
buf : 
buf : static void brcms_c_statsupd(struct brcms_c_info *wlc)
buf : {
buf : 	int i;
buf : 	struct macstat macstats;
buf : #ifdef DEBUG
ifdef DEBUG 
buf : 	u16 delta;
buf : 	u16 rxf0ovfl;
buf : 	u16 txfunfl[NFIFO];
buf : #endif				/* DEBUG */
if				/* DEBUG */ 
buf : 
buf : 	/* if driver down, make no sense to update stats */
buf : 	if (!wlc->pub->up)
if (!wlc->pub->up) 
buf : 		return;
buf : 
buf : #ifdef DEBUG
ifdef DEBUG 
buf : 	/* save last rx fifo 0 overflow count */
buf : 	rxf0ovfl = wlc->core->macstat_snapshot->rxf0ovfl;
buf : 
buf : 	/* save last tx fifo  underflow count */
ifo  underflow count */ 
buf : 	for (i = 0; i < NFIFO; i++)
for (i = 0; i < NFIFO; i++) 
buf : 		txfunfl[i] = wlc->core->macstat_snapshot->txfunfl[i];
buf : #endif				/* DEBUG */
if				/* DEBUG */ 
buf : 
buf : 	/* Read mac stats from contiguous shared memory */
buf : 	brcms_b_copyfrom_objmem(wlc->hw, M_UCODE_MACSTAT, &macstats,
buf : 				sizeof(struct macstat), OBJADDR_SHM_SEL);
buf : 
buf : #ifdef DEBUG
ifdef DEBUG 
buf : 	/* check for rx fifo 0 overflow */
for rx fifo 0 overflow */ 
buf : 	delta = (u16) (wlc->core->macstat_snapshot->rxf0ovfl - rxf0ovfl);
buf : 	if (delta)
if (delta) 
buf : 		brcms_err(wlc->hw->d11core, "wl%d: %u rx fifo 0 overflows!\n",
buf : 			  wlc->pub->unit, delta);
buf : 
buf : 	/* check for tx fifo underflows */
ifo underflows */ 
buf : 	for (i = 0; i < NFIFO; i++) {
for (i = 0; i < NFIFO; i++) { 
buf : 		delta =
buf : 		    (u16) (wlc->core->macstat_snapshot->txfunfl[i] -
buf : 			      txfunfl[i]);
buf : 		if (delta)
if (delta) 
buf : 			brcms_err(wlc->hw->d11core,
buf : 				  "wl%d: %u tx fifo %d underflows!\n",
ifo %d underflows!\n", 
buf : 				  wlc->pub->unit, delta, i);
buf : 	}
buf : #endif				/* DEBUG */
if				/* DEBUG */ 
buf : 
buf : 	/* merge counters from dma module */
buf : 	for (i = 0; i < NFIFO; i++) {
for (i = 0; i < NFIFO; i++) { 
buf : 		if (wlc->hw->di[i])
buf : 			dma_counterreset(wlc->hw->di[i]);
buf : 	}
buf : }
buf : 
buf : static void brcms_b_reset(struct brcms_hardware *wlc_hw)
buf : {
buf : 	/* reset the core */
buf : 	if (!brcms_deviceremoved(wlc_hw->wlc))
if (!brcms_deviceremoved(wlc_hw->wlc)) 
buf : 		brcms_b_corereset(wlc_hw, BRCMS_USE_COREFLAGS);
buf : 
buf : 	/* purge the dma rings */
buf : 	brcms_c_flushqueues(wlc_hw->wlc);
buf : }
buf : 
buf : void brcms_c_reset(struct brcms_c_info *wlc)
buf : {
buf : 	brcms_dbg_info(wlc->hw->d11core, "wl%d\n", wlc->pub->unit);
buf : 
buf : 	/* slurp up hw mac counters before core reset */
fore core reset */ 
buf : 	brcms_c_statsupd(wlc);
buf : 
buf : 	/* reset our snapshot of macstat counters */
buf : 	memset(wlc->core->macstat_snapshot, 0, sizeof(struct macstat));
buf : 
buf : 	brcms_b_reset(wlc->hw);
buf : }
buf : 
buf : void brcms_c_init_scb(struct scb *scb)
buf : {
buf : 	int i;
buf : 
buf : 	memset(scb, 0, sizeof(struct scb));
buf : 	scb->flags = SCB_WMECAP | SCB_HTCAP;
buf : 	for (i = 0; i < NUMPRIO; i++) {
for (i = 0; i < NUMPRIO; i++) { 
buf : 		scb->seqnum[i] = 0;
buf : 		scb->seqctl[i] = 0xFFFF;
buf : 	}
buf : 
buf : 	scb->seqctl_nonqos = 0xFFFF;
buf : 	scb->magic = SCB_MAGIC;
buf : }
buf : 
buf : /* d11 core init
buf :  *   reset PSM
buf :  *   download ucode/PCM
buf :  *   let ucode run to suspended
buf :  *   download ucode inits
buf :  *   config other core registers
buf :  *   init dma
buf :  */
buf : static void brcms_b_coreinit(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 	u32 sflags;
buf : 	u32 bcnint_us;
buf : 	uint i = 0;
buf : 	bool fifosz_fixup = false;
ifosz_fixup = false; 
buf : 	int err = 0;
buf : 	u16 buf[NFIFO];
buf : 	struct brcms_ucode *ucode = &wlc_hw->wlc->wl->ucode;
buf : 
buf : 	brcms_dbg_info(core, "wl%d: core init\n", wlc_hw->unit);
buf : 
buf : 	/* reset PSM */
buf : 	brcms_b_mctrl(wlc_hw, ~0, (MCTL_IHR_EN | MCTL_PSM_JMP_0 | MCTL_WAKE));
buf : 
buf : 	brcms_ucode_download(wlc_hw);
buf : 	/*
buf : 	 * FIFOSZ fixup. driver wants to controls the fifo allocation.
ifo allocation. 
buf : 	 */
buf : 	fifosz_fixup = true;
ifosz_fixup = true; 
buf : 
buf : 	/* let the PSM run to the suspended state, set mode to BSS STA */
buf : 	bcma_write32(core, D11REGOFFS(macintstatus), -1);
buf : 	brcms_b_mctrl(wlc_hw, ~0,
buf : 		       (MCTL_IHR_EN | MCTL_INFRA | MCTL_PSM_RUN | MCTL_WAKE));
buf : 
buf : 	/* wait for ucode to self-suspend after auto-init */
for ucode to self-suspend after auto-init */ 
buf : 	SPINWAIT(((bcma_read32(core, D11REGOFFS(macintstatus)) &
buf : 		   MI_MACSSPNDD) == 0), 1000 * 1000);
buf : 	if ((bcma_read32(core, D11REGOFFS(macintstatus)) & MI_MACSSPNDD) == 0)
if ((bcma_read32(core, D11REGOFFS(macintstatus)) & MI_MACSSPNDD) == 0) 
buf : 		brcms_err(core, "wl%d: wlc_coreinit: ucode did not self-"
buf : 			  "suspend!\n", wlc_hw->unit);
buf : 
buf : 	brcms_c_gpio_init(wlc);
buf : 
buf : 	sflags = bcma_aread32(core, BCMA_IOST);
buf : 
buf : 	if (D11REV_IS(wlc_hw->corerev, 17) || D11REV_IS(wlc_hw->corerev, 23)) {
if (D11REV_IS(wlc_hw->corerev, 17) || D11REV_IS(wlc_hw->corerev, 23)) { 
buf : 		if (BRCMS_ISNPHY(wlc_hw->band))
buf : 			brcms_c_write_inits(wlc_hw, ucode->d11n0initvals16);
buf : 		else
buf : 			brcms_err(core, "%s: wl%d: unsupported phy in corerev"
buf : 				  " %d\n", __func__, wlc_hw->unit,
buf : 				  wlc_hw->corerev);
buf : 	} else if (D11REV_IS(wlc_hw->corerev, 24)) {
if (D11REV_IS(wlc_hw->corerev, 24)) { 
buf : 		if (BRCMS_ISLCNPHY(wlc_hw->band))
buf : 			brcms_c_write_inits(wlc_hw, ucode->d11lcn0initvals24);
buf : 		else
buf : 			brcms_err(core, "%s: wl%d: unsupported phy in corerev"
buf : 				  " %d\n", __func__, wlc_hw->unit,
buf : 				  wlc_hw->corerev);
buf : 	} else {
buf : 		brcms_err(core, "%s: wl%d: unsupported corerev %d\n",
buf : 			  __func__, wlc_hw->unit, wlc_hw->corerev);
buf : 	}
buf : 
buf : 	/* For old ucode, txfifo sizes needs to be modified(increased) */
ifo sizes needs to be modified(increased) */ 
buf : 	if (fifosz_fixup)
buf : 		brcms_b_corerev_fifofixup(wlc_hw);
ifofixup(wlc_hw); 
buf : 
buf : 	/* check txfifo allocations match between ucode and driver */
buf : 	buf[TX_AC_BE_FIFO] = brcms_b_read_shm(wlc_hw, M_FIFOSIZE0);
buf : 	if (buf[TX_AC_BE_FIFO] != wlc_hw->xmtfifo_sz[TX_AC_BE_FIFO]) {
if (buf[TX_AC_BE_FIFO] != wlc_hw->xmtfifo_sz[TX_AC_BE_FIFO]) { 
buf : 		i = TX_AC_BE_FIFO;
buf : 		err = -1;
buf : 	}
buf : 	buf[TX_AC_VI_FIFO] = brcms_b_read_shm(wlc_hw, M_FIFOSIZE1);
buf : 	if (buf[TX_AC_VI_FIFO] != wlc_hw->xmtfifo_sz[TX_AC_VI_FIFO]) {
if (buf[TX_AC_VI_FIFO] != wlc_hw->xmtfifo_sz[TX_AC_VI_FIFO]) { 
buf : 		i = TX_AC_VI_FIFO;
buf : 		err = -1;
buf : 	}
buf : 	buf[TX_AC_BK_FIFO] = brcms_b_read_shm(wlc_hw, M_FIFOSIZE2);
buf : 	buf[TX_AC_VO_FIFO] = (buf[TX_AC_BK_FIFO] >> 8) & 0xff;
buf : 	buf[TX_AC_BK_FIFO] &= 0xff;
buf : 	if (buf[TX_AC_BK_FIFO] != wlc_hw->xmtfifo_sz[TX_AC_BK_FIFO]) {
if (buf[TX_AC_BK_FIFO] != wlc_hw->xmtfifo_sz[TX_AC_BK_FIFO]) { 
buf : 		i = TX_AC_BK_FIFO;
buf : 		err = -1;
buf : 	}
buf : 	if (buf[TX_AC_VO_FIFO] != wlc_hw->xmtfifo_sz[TX_AC_VO_FIFO]) {
if (buf[TX_AC_VO_FIFO] != wlc_hw->xmtfifo_sz[TX_AC_VO_FIFO]) { 
buf : 		i = TX_AC_VO_FIFO;
buf : 		err = -1;
buf : 	}
buf : 	buf[TX_BCMC_FIFO] = brcms_b_read_shm(wlc_hw, M_FIFOSIZE3);
buf : 	buf[TX_ATIM_FIFO] = (buf[TX_BCMC_FIFO] >> 8) & 0xff;
buf : 	buf[TX_BCMC_FIFO] &= 0xff;
buf : 	if (buf[TX_BCMC_FIFO] != wlc_hw->xmtfifo_sz[TX_BCMC_FIFO]) {
if (buf[TX_BCMC_FIFO] != wlc_hw->xmtfifo_sz[TX_BCMC_FIFO]) { 
buf : 		i = TX_BCMC_FIFO;
buf : 		err = -1;
buf : 	}
buf : 	if (buf[TX_ATIM_FIFO] != wlc_hw->xmtfifo_sz[TX_ATIM_FIFO]) {
if (buf[TX_ATIM_FIFO] != wlc_hw->xmtfifo_sz[TX_ATIM_FIFO]) { 
buf : 		i = TX_ATIM_FIFO;
buf : 		err = -1;
buf : 	}
buf : 	if (err != 0)
if (err != 0) 
buf : 		brcms_err(core, "wlc_coreinit: txfifo mismatch: ucode size %d"
buf : 			  " driver size %d index %d\n", buf[i],
buf : 			  wlc_hw->xmtfifo_sz[i], i);
ifo_sz[i], i); 
buf : 
buf : 	/* make sure we can still talk to the mac */
buf : 	WARN_ON(bcma_read32(core, D11REGOFFS(maccontrol)) == 0xffffffff);
buf : 
buf : 	/* band-specific inits done by wlc_bsinit() */
ific inits done by wlc_bsinit() */ 
buf : 
buf : 	/* Set up frame burst size and antenna swap threshold init values */
buf : 	brcms_b_write_shm(wlc_hw, M_MBURST_SIZE, MAXTXFRAMEBURST);
buf : 	brcms_b_write_shm(wlc_hw, M_MAX_ANTCNT, ANTCNT);
buf : 
buf : 	/* enable one rx interrupt per received frame */
buf : 	bcma_write32(core, D11REGOFFS(intrcvlazy[0]), (1 << IRL_FC_SHIFT));
buf : 
buf : 	/* set the station mode (BSS STA) */
buf : 	brcms_b_mctrl(wlc_hw,
buf : 		       (MCTL_INFRA | MCTL_DISCARD_PMQ | MCTL_AP),
buf : 		       (MCTL_INFRA | MCTL_DISCARD_PMQ));
buf : 
buf : 	/* set up Beacon interval */
buf : 	bcnint_us = 0x8000 << 10;
buf : 	bcma_write32(core, D11REGOFFS(tsf_cfprep),
buf : 		     (bcnint_us << CFPREP_CBI_SHIFT));
buf : 	bcma_write32(core, D11REGOFFS(tsf_cfpstart), bcnint_us);
buf : 	bcma_write32(core, D11REGOFFS(macintstatus), MI_GP1);
buf : 
buf : 	/* write interrupt mask */
buf : 	bcma_write32(core, D11REGOFFS(intctrlregs[RX_FIFO].intmask),
buf : 		     DEF_RXINTMASK);
buf : 
buf : 	/* allow the MAC to control the PHY clock (dynamic on/off) */
buf : 	brcms_b_macphyclk_set(wlc_hw, ON);
buf : 
buf : 	/* program dynamic clock control fast powerup delay register */
buf : 	wlc->fastpwrup_dly = ai_clkctl_fast_pwrup_delay(wlc_hw->sih);
buf : 	bcma_write16(core, D11REGOFFS(scc_fastpwrup_dly), wlc->fastpwrup_dly);
buf : 
buf : 	/* tell the ucode the corerev */
buf : 	brcms_b_write_shm(wlc_hw, M_MACHW_VER, (u16) wlc_hw->corerev);
buf : 
buf : 	/* tell the ucode MAC capabilities */
buf : 	brcms_b_write_shm(wlc_hw, M_MACHW_CAP_L,
buf : 			   (u16) (wlc_hw->machwcap & 0xffff));
buf : 	brcms_b_write_shm(wlc_hw, M_MACHW_CAP_H,
buf : 			   (u16) ((wlc_hw->
buf : 				      machwcap >> 16) & 0xffff));
buf : 
buf : 	/* write retry limits to SCR, this done after PSM init */
buf : 	bcma_write32(core, D11REGOFFS(objaddr),
buf : 		     OBJADDR_SCR_SEL | S_DOT11_SRC_LMT);
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	bcma_write32(core, D11REGOFFS(objdata), wlc_hw->SRL);
buf : 	bcma_write32(core, D11REGOFFS(objaddr),
buf : 		     OBJADDR_SCR_SEL | S_DOT11_LRC_LMT);
buf : 	(void)bcma_read32(core, D11REGOFFS(objaddr));
buf : 	bcma_write32(core, D11REGOFFS(objdata), wlc_hw->LRL);
buf : 
buf : 	/* write rate fallback retry limits */
buf : 	brcms_b_write_shm(wlc_hw, M_SFRMTXCNTFBRTHSD, wlc_hw->SFBL);
buf : 	brcms_b_write_shm(wlc_hw, M_LFRMTXCNTFBRTHSD, wlc_hw->LFBL);
buf : 
buf : 	bcma_mask16(core, D11REGOFFS(ifs_ctl), 0x0FFF);
ifs_ctl), 0x0FFF); 
buf : 	bcma_write16(core, D11REGOFFS(ifs_aifsn), EDCF_AIFSN_MIN);
buf : 
buf : 	/* init the tx dma engines */
buf : 	for (i = 0; i < NFIFO; i++) {
for (i = 0; i < NFIFO; i++) { 
buf : 		if (wlc_hw->di[i])
buf : 			dma_txinit(wlc_hw->di[i]);
buf : 	}
buf : 
buf : 	/* init the rx dma engine(s) and post receive buffers */
buf : 	dma_rxinit(wlc_hw->di[RX_FIFO]);
buf : 	dma_rxfill(wlc_hw->di[RX_FIFO]);
buf : }
buf : 
buf : void
buf : static brcms_b_init(struct brcms_hardware *wlc_hw, u16 chanspec) {
buf : 	u32 macintmask;
buf : 	bool fastclk;
buf : 	struct brcms_c_info *wlc = wlc_hw->wlc;
buf : 
buf : 	/* request FAST clock if not on */
if not on */ 
buf : 	fastclk = wlc_hw->forcefastclk;
forcefastclk; 
buf : 	if (!fastclk)
buf : 		brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_FAST);
buf : 
buf : 	/* disable interrupts */
buf : 	macintmask = brcms_intrsoff(wlc->wl);
buf : 
buf : 	/* set up the specified band and chanspec */
ified band and chanspec */ 
buf : 	brcms_c_setxband(wlc_hw, chspec_bandunit(chanspec));
buf : 	wlc_phy_chanspec_radio_set(wlc_hw->band->pi, chanspec);
buf : 
buf : 	/* do one-time phy inits and calibration */
buf : 	wlc_phy_cal_init(wlc_hw->band->pi);
buf : 
buf : 	/* core-specific initialization */
ific initialization */ 
buf : 	brcms_b_coreinit(wlc);
buf : 
buf : 	/* band-specific inits */
ific inits */ 
buf : 	brcms_b_bsinit(wlc, chanspec);
buf : 
buf : 	/* restore macintmask */
buf : 	brcms_intrsrestore(wlc->wl, macintmask);
buf : 
buf : 	/* seed wake_override with BRCMS_WAKE_OVERRIDE_MACSUSPEND since the mac
buf : 	 * is suspended and brcms_c_enable_mac() will clear this override bit.
buf : 	 */
buf : 	mboolset(wlc_hw->wake_override, BRCMS_WAKE_OVERRIDE_MACSUSPEND);
buf : 
buf : 	/*
buf : 	 * initialize mac_suspend_depth to 1 to match ucode
buf : 	 * initial suspended state
buf : 	 */
buf : 	wlc_hw->mac_suspend_depth = 1;
buf : 
buf : 	/* restore the clk */
buf : 	if (!fastclk)
if (!fastclk) 
buf : 		brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_DYNAMIC);
buf : }
buf : 
buf : static void brcms_c_set_phy_chanspec(struct brcms_c_info *wlc,
buf : 				     u16 chanspec)
buf : {
buf : 	/* Save our copy of the chanspec */
buf : 	wlc->chanspec = chanspec;
buf : 
buf : 	/* Set the chanspec and power limits for this locale */
for this locale */ 
buf : 	brcms_c_channel_set_chanspec(wlc->cmi, chanspec, BRCMS_TXPWR_MAX);
buf : 
buf : 	if (wlc->stf->ss_algosel_auto)
if (wlc->stf->ss_algosel_auto) 
buf : 		brcms_c_stf_ss_algo_channel_get(wlc, &wlc->stf->ss_algo_channel,
buf : 					    chanspec);
buf : 
buf : 	brcms_c_stf_ss_update(wlc, wlc->band);
buf : }
buf : 
buf : static void
buf : brcms_default_rateset(struct brcms_c_info *wlc, struct brcms_c_rateset *rs)
buf : {
buf : 	brcms_c_rateset_default(rs, NULL, wlc->band->phytype,
buf : 		wlc->band->bandtype, false, BRCMS_RATE_MASK_FULL,
buf : 		(bool) (wlc->pub->_n_enab & SUPPORT_11N),
buf : 		brcms_chspec_bw(wlc->default_bss->chanspec),
buf : 		wlc->stf->txstreams);
buf : }
buf : 
buf : /* derive wlc->band->basic_rate[] table from 'rateset' */
buf : static void brcms_c_rate_lookup_init(struct brcms_c_info *wlc,
buf : 			      struct brcms_c_rateset *rateset)
buf : {
buf : 	u8 rate;
buf : 	u8 mandatory;
buf : 	u8 cck_basic = 0;
buf : 	u8 ofdm_basic = 0;
buf : 	u8 *br = wlc->band->basic_rate;
buf : 	uint i;
buf : 
buf : 	/* incoming rates are in 500kbps units as in 802.11 Supported Rates */
buf : 	memset(br, 0, BRCM_MAXRATE + 1);
buf : 
buf : 	/* For each basic rate in the rates list, make an entry in the
buf : 	 * best basic lookup.
buf : 	 */
buf : 	for (i = 0; i < rateset->count; i++) {
for (i = 0; i < rateset->count; i++) { 
buf : 		/* only make an entry for a basic rate */
buf : 		if (!(rateset->rates[i] & BRCMS_RATE_FLAG))
if (!(rateset->rates[i] & BRCMS_RATE_FLAG)) 
buf : 			continue;
buf : 
buf : 		/* mask off basic bit */
buf : 		rate = (rateset->rates[i] & BRCMS_RATE_MASK);
buf : 
buf : 		if (rate > BRCM_MAXRATE) {
if (rate > BRCM_MAXRATE) { 
buf : 			brcms_err(wlc->hw->d11core, "brcms_c_rate_lookup_init: "
buf : 				  "invalid rate 0x%X in rate set\n",
buf : 				  rateset->rates[i]);
buf : 			continue;
buf : 		}
buf : 
buf : 		br[rate] = rate;
buf : 	}
buf : 
buf : 	/* The rate lookup table now has non-zero entries for each
for each 
buf : 	 * basic rate, equal to the basic rate: br[basicN] = basicN
buf : 	 *
buf : 	 * To look up the best basic rate corresponding to any
buf : 	 * particular rate, code can use the basic_rate table
buf : 	 * like this
buf : 	 *
buf : 	 * basic_rate = wlc->band->basic_rate[tx_rate]
buf : 	 *
buf : 	 * Make sure there is a best basic rate entry for
for 
buf : 	 * every rate by walking up the table from low rates
buf : 	 * to high, filling in holes in the lookup table
buf : 	 */
buf : 
buf : 	for (i = 0; i < wlc->band->hw_rateset.count; i++) {
for (i = 0; i < wlc->band->hw_rateset.count; i++) { 
buf : 		rate = wlc->band->hw_rateset.rates[i];
buf : 
buf : 		if (br[rate] != 0) {
if (br[rate] != 0) { 
buf : 			/* This rate is a basic rate.
buf : 			 * Keep track of the best basic rate so far by
buf : 			 * modulation type.
buf : 			 */
buf : 			if (is_ofdm_rate(rate))
if (is_ofdm_rate(rate)) 
buf : 				ofdm_basic = rate;
buf : 			else
buf : 				cck_basic = rate;
buf : 
buf : 			continue;
buf : 		}
buf : 
buf : 		/* This rate is not a basic rate so figure out the
buf : 		 * best basic rate less than this rate and fill in
buf : 		 * the hole in the table
buf : 		 */
buf : 
buf : 		br[rate] = is_ofdm_rate(rate) ? ofdm_basic : cck_basic;
buf : 
buf : 		if (br[rate] != 0)
if (br[rate] != 0) 
buf : 			continue;
buf : 
buf : 		if (is_ofdm_rate(rate)) {
if (is_ofdm_rate(rate)) { 
buf : 			/*
buf : 			 * In 11g and 11a, the OFDM mandatory rates
buf : 			 * are 6, 12, and 24 Mbps
buf : 			 */
buf : 			if (rate >= BRCM_RATE_24M)
if (rate >= BRCM_RATE_24M) 
buf : 				mandatory = BRCM_RATE_24M;
buf : 			else if (rate >= BRCM_RATE_12M)
if (rate >= BRCM_RATE_12M) 
buf : 				mandatory = BRCM_RATE_12M;
buf : 			else
buf : 				mandatory = BRCM_RATE_6M;
buf : 		} else {
buf : 			/* In 11b, all CCK rates are mandatory 1 - 11 Mbps */
buf : 			mandatory = rate;
buf : 		}
buf : 
buf : 		br[rate] = mandatory;
buf : 	}
buf : }
buf : 
buf : static void brcms_c_bandinit_ordered(struct brcms_c_info *wlc,
buf : 				     u16 chanspec)
buf : {
buf : 	struct brcms_c_rateset default_rateset;
buf : 	uint parkband;
buf : 	uint i, band_order[2];
buf : 
buf : 	/*
buf : 	 * We might have been bandlocked during down and the chip
buf : 	 * power-cycled (hibernate). Figure out the right band to park on
buf : 	 */
buf : 	if (wlc->bandlocked || wlc->pub->_nbands == 1) {
if (wlc->bandlocked || wlc->pub->_nbands == 1) { 
buf : 		/* updated in brcms_c_bandlock() */
buf : 		parkband = wlc->band->bandunit;
buf : 		band_order[0] = band_order[1] = parkband;
buf : 	} else {
buf : 		/* park on the band of the specified chanspec */
ified chanspec */ 
buf : 		parkband = chspec_bandunit(chanspec);
buf : 
buf : 		/* order so that parkband initialize last */
buf : 		band_order[0] = parkband ^ 1;
buf : 		band_order[1] = parkband;
buf : 	}
buf : 
buf : 	/* make each band operational, software state init */
buf : 	for (i = 0; i < wlc->pub->_nbands; i++) {
for (i = 0; i < wlc->pub->_nbands; i++) { 
buf : 		uint j = band_order[i];
buf : 
buf : 		wlc->band = wlc->bandstate[j];
buf : 
buf : 		brcms_default_rateset(wlc, &default_rateset);
buf : 
buf : 		/* fill in hw_rate */
buf : 		brcms_c_rateset_filter(&default_rateset, &wlc->band->hw_rateset,
buf : 				   false, BRCMS_RATES_CCK_OFDM, BRCMS_RATE_MASK,
buf : 				   (bool) (wlc->pub->_n_enab & SUPPORT_11N));
buf : 
buf : 		/* init basic rate lookup */
buf : 		brcms_c_rate_lookup_init(wlc, &default_rateset);
buf : 	}
buf : 
buf : 	/* sync up phy/radio chanspec */
buf : 	brcms_c_set_phy_chanspec(wlc, chanspec);
buf : }
buf : 
buf : /*
buf :  * Set or clear filtering related maccontrol bits based on
buf :  * specified filter flags
ified filter flags 
buf :  */
buf : void brcms_c_mac_promisc(struct brcms_c_info *wlc, uint filter_flags)
buf : {
buf : 	u32 promisc_bits = 0;
buf : 
buf : 	wlc->filter_flags = filter_flags;
buf : 
buf : 	if (filter_flags & (FIF_PROMISC_IN_BSS | FIF_OTHER_BSS))
if (filter_flags & (FIF_PROMISC_IN_BSS | FIF_OTHER_BSS)) 
buf : 		promisc_bits |= MCTL_PROMISC;
buf : 
buf : 	if (filter_flags & FIF_BCN_PRBRESP_PROMISC)
if (filter_flags & FIF_BCN_PRBRESP_PROMISC) 
buf : 		promisc_bits |= MCTL_BCNS_PROMISC;
buf : 
buf : 	if (filter_flags & FIF_FCSFAIL)
if (filter_flags & FIF_FCSFAIL) 
buf : 		promisc_bits |= MCTL_KEEPBADFCS;
buf : 
buf : 	if (filter_flags & (FIF_CONTROL | FIF_PSPOLL))
if (filter_flags & (FIF_CONTROL | FIF_PSPOLL)) 
buf : 		promisc_bits |= MCTL_KEEPCONTROL;
buf : 
buf : 	brcms_b_mctrl(wlc->hw,
buf : 		MCTL_PROMISC | MCTL_BCNS_PROMISC |
buf : 		MCTL_KEEPCONTROL | MCTL_KEEPBADFCS,
buf : 		promisc_bits);
buf : }
buf : 
buf : /*
buf :  * ucode, hwmac update
buf :  *    Channel dependent updates for ucode and hw
for ucode and hw 
buf :  */
buf : static void brcms_c_ucode_mac_upd(struct brcms_c_info *wlc)
buf : {
buf : 	/* enable or disable any active IBSSs depending on whether or not
buf : 	 * we are on the home channel
buf : 	 */
buf : 	if (wlc->home_chanspec == wlc_phy_chanspec_get(wlc->band->pi)) {
if (wlc->home_chanspec == wlc_phy_chanspec_get(wlc->band->pi)) { 
buf : 		if (wlc->pub->associated) {
buf : 			/*
buf : 			 * BMAC_NOTE: This is something that should be fixed
buf : 			 * in ucode inits. I think that the ucode inits set
buf : 			 * up the bcn templates and shm values with a bogus
buf : 			 * beacon. This should not be done in the inits. If
buf : 			 * ucode needs to set up a beacon for testing, the
for testing, the 
buf : 			 * test routines should write it down, not expect the
buf : 			 * inits to populate a bogus beacon.
buf : 			 */
buf : 			if (BRCMS_PHY_11N_CAP(wlc->band))
if (BRCMS_PHY_11N_CAP(wlc->band)) 
buf : 				brcms_b_write_shm(wlc->hw,
buf : 						M_BCN_TXTSF_OFFSET, 0);
buf : 		}
buf : 	} else {
buf : 		/* disable an active IBSS if we are not on the home channel */
if we are not on the home channel */ 
buf : 	}
buf : }
buf : 
buf : static void brcms_c_write_rate_shm(struct brcms_c_info *wlc, u8 rate,
buf : 				   u8 basic_rate)
buf : {
buf : 	u8 phy_rate, index;
buf : 	u8 basic_phy_rate, basic_index;
buf : 	u16 dir_table, basic_table;
buf : 	u16 basic_ptr;
buf : 
buf : 	/* Shared memory address for the table we are reading */
for the table we are reading */ 
buf : 	dir_table = is_ofdm_rate(basic_rate) ? M_RT_DIRMAP_A : M_RT_DIRMAP_B;
buf : 
buf : 	/* Shared memory address for the table we are writing */
for the table we are writing */ 
buf : 	basic_table = is_ofdm_rate(rate) ? M_RT_BBRSMAP_A : M_RT_BBRSMAP_B;
buf : 
buf : 	/*
buf : 	 * for a given rate, the LS-nibble of the PLCP SIGNAL field is
for a given rate, the LS-nibble of the PLCP SIGNAL field is 
buf : 	 * the index into the rate table.
buf : 	 */
buf : 	phy_rate = rate_info[rate] & BRCMS_RATE_MASK;
buf : 	basic_phy_rate = rate_info[basic_rate] & BRCMS_RATE_MASK;
buf : 	index = phy_rate & 0xf;
buf : 	basic_index = basic_phy_rate & 0xf;
buf : 
buf : 	/* Find the SHM pointer to the ACK rate entry by looking in the
buf : 	 * Direct-map Table
buf : 	 */
buf : 	basic_ptr = brcms_b_read_shm(wlc->hw, (dir_table + basic_index * 2));
buf : 
buf : 	/* Update the SHM BSS-basic-rate-set mapping table with the pointer
buf : 	 * to the correct basic rate for the given incoming rate
for the given incoming rate 
buf : 	 */
buf : 	brcms_b_write_shm(wlc->hw, (basic_table + index * 2), basic_ptr);
buf : }
buf : 
buf : static const struct brcms_c_rateset *
buf : brcms_c_rateset_get_hwrs(struct brcms_c_info *wlc)
buf : {
buf : 	const struct brcms_c_rateset *rs_dflt;
buf : 
buf : 	if (BRCMS_PHY_11N_CAP(wlc->band)) {
if (BRCMS_PHY_11N_CAP(wlc->band)) { 
buf : 		if (wlc->band->bandtype == BRCM_BAND_5G)
buf : 			rs_dflt = &ofdm_mimo_rates;
buf : 		else
buf : 			rs_dflt = &cck_ofdm_mimo_rates;
buf : 	} else if (wlc->band->gmode)
if (wlc->band->gmode) 
buf : 		rs_dflt = &cck_ofdm_rates;
buf : 	else
buf : 		rs_dflt = &cck_rates;
buf : 
buf : 	return rs_dflt;
buf : }
buf : 
buf : static void brcms_c_set_ratetable(struct brcms_c_info *wlc)
buf : {
buf : 	const struct brcms_c_rateset *rs_dflt;
buf : 	struct brcms_c_rateset rs;
buf : 	u8 rate, basic_rate;
buf : 	uint i;
buf : 
buf : 	rs_dflt = brcms_c_rateset_get_hwrs(wlc);
buf : 
buf : 	brcms_c_rateset_copy(rs_dflt, &rs);
buf : 	brcms_c_rateset_mcs_upd(&rs, wlc->stf->txstreams);
buf : 
buf : 	/* walk the phy rate table and update SHM basic rate lookup table */
buf : 	for (i = 0; i < rs.count; i++) {
for (i = 0; i < rs.count; i++) { 
buf : 		rate = rs.rates[i] & BRCMS_RATE_MASK;
buf : 
buf : 		/* for a given rate brcms_basic_rate returns the rate at
for a given rate brcms_basic_rate returns the rate at 
buf : 		 * which a response ACK/CTS should be sent.
buf : 		 */
buf : 		basic_rate = brcms_basic_rate(wlc, rate);
buf : 		if (basic_rate == 0)
if (basic_rate == 0) 
buf : 			/* This should only happen if we are using a
buf : 			 * restricted rateset.
buf : 			 */
buf : 			basic_rate = rs.rates[0] & BRCMS_RATE_MASK;
buf : 
buf : 		brcms_c_write_rate_shm(wlc, rate, basic_rate);
buf : 	}
buf : }
buf : 
buf : /* band-specific init */
ific init */ 
buf : static void brcms_c_bsinit(struct brcms_c_info *wlc)
buf : {
buf : 	brcms_dbg_info(wlc->hw->d11core, "wl%d: bandunit %d\n",
buf : 		       wlc->pub->unit, wlc->band->bandunit);
buf : 
buf : 	/* write ucode ACK/CTS rate table */
buf : 	brcms_c_set_ratetable(wlc);
buf : 
buf : 	/* update some band specific mac configuration */
ific mac configuration */ 
buf : 	brcms_c_ucode_mac_upd(wlc);
buf : 
buf : 	/* init antenna selection */
buf : 	brcms_c_antsel_init(wlc->asi);
buf : 
buf : }
buf : 
buf : /* formula:  IDLE_BUSY_RATIO_X_16 = (100-duty_cycle)/duty_cycle*16 */
formula:  IDLE_BUSY_RATIO_X_16 = (100-duty_cycle)/duty_cycle*16 */ 
buf : static int
buf : brcms_c_duty_cycle_set(struct brcms_c_info *wlc, int duty_cycle, bool isOFDM,
buf : 		   bool writeToShm)
buf : {
buf : 	int idle_busy_ratio_x_16 = 0;
buf : 	uint offset =
buf : 	    isOFDM ? M_TX_IDLE_BUSY_RATIO_X_16_OFDM :
buf : 	    M_TX_IDLE_BUSY_RATIO_X_16_CCK;
buf : 	if (duty_cycle > 100 || duty_cycle < 0) {
if (duty_cycle > 100 || duty_cycle < 0) { 
buf : 		brcms_err(wlc->hw->d11core,
buf : 			  "wl%d:  duty cycle value off limit\n",
buf : 			  wlc->pub->unit);
buf : 		return -EINVAL;
buf : 	}
buf : 	if (duty_cycle)
if (duty_cycle) 
buf : 		idle_busy_ratio_x_16 = (100 - duty_cycle) * 16 / duty_cycle;
buf : 	/* Only write to shared memory  when wl is up */
buf : 	if (writeToShm)
if (writeToShm) 
buf : 		brcms_b_write_shm(wlc->hw, offset, (u16) idle_busy_ratio_x_16);
buf : 
buf : 	if (isOFDM)
if (isOFDM) 
buf : 		wlc->tx_duty_cycle_ofdm = (u16) duty_cycle;
buf : 	else
buf : 		wlc->tx_duty_cycle_cck = (u16) duty_cycle;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /* push sw hps and wake state through hardware */
buf : static void brcms_c_set_ps_ctrl(struct brcms_c_info *wlc)
buf : {
buf : 	u32 v1, v2;
buf : 	bool hps;
buf : 	bool awake_before;
fore; 
buf : 
buf : 	hps = brcms_c_ps_allowed(wlc);
buf : 
buf : 	brcms_dbg_mac80211(wlc->hw->d11core, "wl%d: hps %d\n", wlc->pub->unit,
buf : 			   hps);
buf : 
buf : 	v1 = bcma_read32(wlc->hw->d11core, D11REGOFFS(maccontrol));
buf : 	v2 = MCTL_WAKE;
buf : 	if (hps)
if (hps) 
buf : 		v2 |= MCTL_HPS;
buf : 
buf : 	brcms_b_mctrl(wlc->hw, MCTL_WAKE | MCTL_HPS, v2);
buf : 
buf : 	awake_before = ((v1 & MCTL_WAKE) || ((v1 & MCTL_HPS) == 0));
fore = ((v1 & MCTL_WAKE) || ((v1 & MCTL_HPS) == 0)); 
buf : 
buf : 	if (!awake_before)
buf : 		brcms_b_wait_for_wake(wlc->hw);
for_wake(wlc->hw); 
buf : }
buf : 
buf : /*
buf :  * Write this BSS config's MAC address to core.
buf :  * Updates RXE match engine.
buf :  */
buf : static int brcms_c_set_mac(struct brcms_bss_cfg *bsscfg)
buf : {
buf : 	int err = 0;
buf : 	struct brcms_c_info *wlc = bsscfg->wlc;
buf : 
buf : 	/* enter the MAC addr into the RXE match registers */
buf : 	brcms_c_set_addrmatch(wlc, RCM_MAC_OFFSET, wlc->pub->cur_etheraddr);
buf : 
buf : 	brcms_c_ampdu_macaddr_upd(wlc);
buf : 
buf : 	return err;
buf : }
buf : 
buf : /* Write the BSS config's BSSID address to core (set_bssid in d11procs.tcl).
buf :  * Updates RXE match engine.
buf :  */
buf : static void brcms_c_set_bssid(struct brcms_bss_cfg *bsscfg)
buf : {
buf : 	/* we need to update BSSID in RXE match registers */
buf : 	brcms_c_set_addrmatch(bsscfg->wlc, RCM_BSSID_OFFSET, bsscfg->BSSID);
buf : }
buf : 
buf : void brcms_c_set_ssid(struct brcms_c_info *wlc, u8 *ssid, size_t ssid_len)
buf : {
buf : 	u8 len = min_t(u8, sizeof(wlc->bsscfg->SSID), ssid_len);
buf : 	memset(wlc->bsscfg->SSID, 0, sizeof(wlc->bsscfg->SSID));
buf : 
buf : 	memcpy(wlc->bsscfg->SSID, ssid, len);
buf : 	wlc->bsscfg->SSID_len = len;
buf : }
buf : 
buf : static void brcms_b_set_shortslot(struct brcms_hardware *wlc_hw, bool shortslot)
buf : {
buf : 	wlc_hw->shortslot = shortslot;
buf : 
buf : 	if (wlc_hw->band->bandtype == BRCM_BAND_2G && wlc_hw->up) {
if (wlc_hw->band->bandtype == BRCM_BAND_2G && wlc_hw->up) { 
buf : 		brcms_c_suspend_mac_and_wait(wlc_hw->wlc);
buf : 		brcms_b_update_slot_timing(wlc_hw, shortslot);
buf : 		brcms_c_enable_mac(wlc_hw->wlc);
buf : 	}
buf : }
buf : 
buf : /*
buf :  * Suspend the the MAC and update the slot timing
buf :  * for standard 11b/g (20us slots) or shortslot 11g (9us slots).
for standard 11b/g (20us slots) or shortslot 11g (9us slots). 
buf :  */
buf : static void brcms_c_switch_shortslot(struct brcms_c_info *wlc, bool shortslot)
buf : {
buf : 	/* use the override if it is set */
if it is set */ 
buf : 	if (wlc->shortslot_override != BRCMS_SHORTSLOT_AUTO)
buf : 		shortslot = (wlc->shortslot_override == BRCMS_SHORTSLOT_ON);
buf : 
buf : 	if (wlc->shortslot == shortslot)
if (wlc->shortslot == shortslot) 
buf : 		return;
buf : 
buf : 	wlc->shortslot = shortslot;
buf : 
buf : 	brcms_b_set_shortslot(wlc->hw, shortslot);
buf : }
buf : 
buf : static void brcms_c_set_home_chanspec(struct brcms_c_info *wlc, u16 chanspec)
buf : {
buf : 	if (wlc->home_chanspec != chanspec) {
if (wlc->home_chanspec != chanspec) { 
buf : 		wlc->home_chanspec = chanspec;
buf : 
buf : 		if (wlc->pub->associated)
if (wlc->pub->associated) 
buf : 			wlc->bsscfg->current_bss->chanspec = chanspec;
buf : 	}
buf : }
buf : 
buf : void
buf : brcms_b_set_chanspec(struct brcms_hardware *wlc_hw, u16 chanspec,
buf : 		      bool mute_tx, struct txpwr_limits *txpwr)
buf : {
buf : 	uint bandunit;
buf : 
buf : 	brcms_dbg_mac80211(wlc_hw->d11core, "wl%d: 0x%x\n", wlc_hw->unit,
buf : 			   chanspec);
buf : 
buf : 	wlc_hw->chanspec = chanspec;
buf : 
buf : 	/* Switch bands if necessary */
if necessary */ 
buf : 	if (wlc_hw->_nbands > 1) {
buf : 		bandunit = chspec_bandunit(chanspec);
buf : 		if (wlc_hw->band->bandunit != bandunit) {
if (wlc_hw->band->bandunit != bandunit) { 
buf : 			/* brcms_b_setband disables other bandunit,
buf : 			 *  use light band switch if not up yet
if not up yet 
buf : 			 */
buf : 			if (wlc_hw->up) {
if (wlc_hw->up) { 
buf : 				wlc_phy_chanspec_radio_set(wlc_hw->
buf : 							   bandstate[bandunit]->
buf : 							   pi, chanspec);
buf : 				brcms_b_setband(wlc_hw, bandunit, chanspec);
buf : 			} else {
buf : 				brcms_c_setxband(wlc_hw, bandunit);
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	wlc_phy_initcal_enable(wlc_hw->band->pi, !mute_tx);
buf : 
buf : 	if (!wlc_hw->up) {
if (!wlc_hw->up) { 
buf : 		if (wlc_hw->clk)
buf : 			wlc_phy_txpower_limit_set(wlc_hw->band->pi, txpwr,
buf : 						  chanspec);
buf : 		wlc_phy_chanspec_radio_set(wlc_hw->band->pi, chanspec);
buf : 	} else {
buf : 		wlc_phy_chanspec_set(wlc_hw->band->pi, chanspec);
buf : 		wlc_phy_txpower_limit_set(wlc_hw->band->pi, txpwr, chanspec);
buf : 
buf : 		/* Update muting of the channel */
buf : 		brcms_b_mute(wlc_hw, mute_tx);
buf : 	}
buf : }
buf : 
buf : /* switch to and initialize new band */
buf : static void brcms_c_setband(struct brcms_c_info *wlc,
buf : 					   uint bandunit)
buf : {
buf : 	wlc->band = wlc->bandstate[bandunit];
buf : 
buf : 	if (!wlc->pub->up)
if (!wlc->pub->up) 
buf : 		return;
buf : 
buf : 	/* wait for at least one beacon before entering sleeping state */
for at least one beacon before entering sleeping state */ 
buf : 	brcms_c_set_ps_ctrl(wlc);
buf : 
buf : 	/* band-specific initializations */
ific initializations */ 
buf : 	brcms_c_bsinit(wlc);
buf : }
buf : 
buf : static void brcms_c_set_chanspec(struct brcms_c_info *wlc, u16 chanspec)
buf : {
buf : 	uint bandunit;
buf : 	bool switchband = false;
buf : 	u16 old_chanspec = wlc->chanspec;
buf : 
buf : 	if (!brcms_c_valid_chanspec_db(wlc->cmi, chanspec)) {
if (!brcms_c_valid_chanspec_db(wlc->cmi, chanspec)) { 
buf : 		brcms_err(wlc->hw->d11core, "wl%d: %s: Bad channel %d\n",
buf : 			  wlc->pub->unit, __func__, CHSPEC_CHANNEL(chanspec));
buf : 		return;
buf : 	}
buf : 
buf : 	/* Switch bands if necessary */
if necessary */ 
buf : 	if (wlc->pub->_nbands > 1) {
buf : 		bandunit = chspec_bandunit(chanspec);
buf : 		if (wlc->band->bandunit != bandunit || wlc->bandinit_pending) {
if (wlc->band->bandunit != bandunit || wlc->bandinit_pending) { 
buf : 			switchband = true;
buf : 			if (wlc->bandlocked) {
if (wlc->bandlocked) { 
buf : 				brcms_err(wlc->hw->d11core,
buf : 					  "wl%d: %s: chspec %d band is locked!\n",
buf : 					  wlc->pub->unit, __func__,
buf : 					  CHSPEC_CHANNEL(chanspec));
buf : 				return;
buf : 			}
buf : 			/*
buf : 			 * should the setband call come after the
buf : 			 * brcms_b_chanspec() ? if the setband updates
if the setband updates 
buf : 			 * (brcms_c_bsinit) use low level calls to inspect and
buf : 			 * set state, the state inspected may be from the wrong
buf : 			 * band, or the following brcms_b_set_chanspec() may
buf : 			 * undo the work.
buf : 			 */
buf : 			brcms_c_setband(wlc, bandunit);
buf : 		}
buf : 	}
buf : 
buf : 	/* sync up phy/radio chanspec */
buf : 	brcms_c_set_phy_chanspec(wlc, chanspec);
buf : 
buf : 	/* init antenna selection */
buf : 	if (brcms_chspec_bw(old_chanspec) != brcms_chspec_bw(chanspec)) {
if (brcms_chspec_bw(old_chanspec) != brcms_chspec_bw(chanspec)) { 
buf : 		brcms_c_antsel_init(wlc->asi);
buf : 
buf : 		/* Fix the hardware rateset based on bw.
buf : 		 * Mainly add MCS32 for 40Mhz, remove MCS 32 for 20Mhz
for 40Mhz, remove MCS 32 for 20Mhz 
buf : 		 */
buf : 		brcms_c_rateset_bw_mcs_filter(&wlc->band->hw_rateset,
buf : 			wlc->band->mimo_cap_40 ? brcms_chspec_bw(chanspec) : 0);
buf : 	}
buf : 
buf : 	/* update some mac configuration since chanspec changed */
buf : 	brcms_c_ucode_mac_upd(wlc);
buf : }
buf : 
buf : /*
buf :  * This function changes the phytxctl for beacon based on current
for beacon based on current 
buf :  * beacon ratespec AND txant setting as per this table:
buf :  *  ratespec     CCK		ant = wlc->stf->txant
buf :  *		OFDM		ant = 3
buf :  */
buf : void brcms_c_beacon_phytxctl_txant_upd(struct brcms_c_info *wlc,
buf : 				       u32 bcn_rspec)
buf : {
buf : 	u16 phyctl;
buf : 	u16 phytxant = wlc->stf->phytxant;
buf : 	u16 mask = PHY_TXC_ANT_MASK;
buf : 
buf : 	/* for non-siso rates or default setting, use the available chains */
for non-siso rates or default setting, use the available chains */ 
buf : 	if (BRCMS_PHY_11N_CAP(wlc->band))
buf : 		phytxant = brcms_c_stf_phytxchain_sel(wlc, bcn_rspec);
buf : 
buf : 	phyctl = brcms_b_read_shm(wlc->hw, M_BCN_PCTLWD);
buf : 	phyctl = (phyctl & ~mask) | phytxant;
buf : 	brcms_b_write_shm(wlc->hw, M_BCN_PCTLWD, phyctl);
buf : }
buf : 
buf : /*
buf :  * centralized protection config change function to simplify debugging, no
ify debugging, no 
buf :  * consistency checking this should be called only on changes to avoid overhead
buf :  * in periodic function
buf :  */
buf : void brcms_c_protection_upd(struct brcms_c_info *wlc, uint idx, int val)
buf : {
buf : 	/*
buf : 	 * Cannot use brcms_dbg_* here because this function is called
buf : 	 * before wlc is sufficiently initialized.
fore wlc is sufficiently initialized. 
buf : 	 */
buf : 	BCMMSG(wlc->wiphy, "idx %d, val %d\n", idx, val);
buf : 
buf : 	switch (idx) {
buf : 	case BRCMS_PROT_G_SPEC:
buf : 		wlc->protection->_g = (bool) val;
buf : 		break;
buf : 	case BRCMS_PROT_G_OVR:
buf : 		wlc->protection->g_override = (s8) val;
buf : 		break;
buf : 	case BRCMS_PROT_G_USER:
buf : 		wlc->protection->gmode_user = (u8) val;
buf : 		break;
buf : 	case BRCMS_PROT_OVERLAP:
buf : 		wlc->protection->overlap = (s8) val;
buf : 		break;
buf : 	case BRCMS_PROT_N_USER:
buf : 		wlc->protection->nmode_user = (s8) val;
buf : 		break;
buf : 	case BRCMS_PROT_N_CFG:
buf : 		wlc->protection->n_cfg = (s8) val;
buf : 		break;
buf : 	case BRCMS_PROT_N_CFG_OVR:
buf : 		wlc->protection->n_cfg_override = (s8) val;
buf : 		break;
buf : 	case BRCMS_PROT_N_NONGF:
buf : 		wlc->protection->nongf = (bool) val;
buf : 		break;
buf : 	case BRCMS_PROT_N_NONGF_OVR:
buf : 		wlc->protection->nongf_override = (s8) val;
buf : 		break;
buf : 	case BRCMS_PROT_N_PAM_OVR:
buf : 		wlc->protection->n_pam_override = (s8) val;
buf : 		break;
buf : 	case BRCMS_PROT_N_OBSS:
buf : 		wlc->protection->n_obss = (bool) val;
buf : 		break;
buf : 
buf : 	default:
buf : 		break;
buf : 	}
buf : 
buf : }
buf : 
buf : static void brcms_c_ht_update_sgi_rx(struct brcms_c_info *wlc, int val)
buf : {
buf : 	if (wlc->pub->up) {
if (wlc->pub->up) { 
buf : 		brcms_c_update_beacon(wlc);
buf : 		brcms_c_update_probe_resp(wlc, true);
buf : 	}
buf : }
buf : 
buf : static void brcms_c_ht_update_ldpc(struct brcms_c_info *wlc, s8 val)
buf : {
buf : 	wlc->stf->ldpc = val;
buf : 
buf : 	if (wlc->pub->up) {
if (wlc->pub->up) { 
buf : 		brcms_c_update_beacon(wlc);
buf : 		brcms_c_update_probe_resp(wlc, true);
buf : 		wlc_phy_ldpc_override_set(wlc->band->pi, (val ? true : false));
buf : 	}
buf : }
buf : 
buf : void brcms_c_wme_setparams(struct brcms_c_info *wlc, u16 aci,
buf : 		       const struct ieee80211_tx_queue_params *params,
buf : 		       bool suspend)
buf : {
buf : 	int i;
buf : 	struct shm_acparams acp_shm;
buf : 	u16 *shm_entry;
buf : 
buf : 	/* Only apply params if the core is out of reset and has clocks */
if the core is out of reset and has clocks */ 
buf : 	if (!wlc->clk) {
buf : 		brcms_err(wlc->hw->d11core, "wl%d: %s : no-clock\n",
buf : 			  wlc->pub->unit, __func__);
buf : 		return;
buf : 	}
buf : 
buf : 	memset(&acp_shm, 0, sizeof(struct shm_acparams));
buf : 	/* fill in shm ac params struct */
buf : 	acp_shm.txop = params->txop;
buf : 	/* convert from units of 32us to us for ucode */
for ucode */ 
buf : 	wlc->edcf_txop[aci & 0x3] = acp_shm.txop =
buf : 	    EDCF_TXOP2USEC(acp_shm.txop);
buf : 	acp_shm.aifs = (params->aifs & EDCF_AIFSN_MASK);
ifs = (params->aifs & EDCF_AIFSN_MASK); 
buf : 
buf : 	if (aci == IEEE80211_AC_VI && acp_shm.txop == 0
buf : 	    && acp_shm.aifs < EDCF_AIFSN_MAX)
ifs < EDCF_AIFSN_MAX) 
buf : 		acp_shm.aifs++;
buf : 
buf : 	if (acp_shm.aifs < EDCF_AIFSN_MIN
if (acp_shm.aifs < EDCF_AIFSN_MIN 
buf : 	    || acp_shm.aifs > EDCF_AIFSN_MAX) {
buf : 		brcms_err(wlc->hw->d11core, "wl%d: edcf_setparams: bad "
buf : 			  "aifs %d\n", wlc->pub->unit, acp_shm.aifs);
ifs %d\n", wlc->pub->unit, acp_shm.aifs); 
buf : 	} else {
buf : 		acp_shm.cwmin = params->cw_min;
buf : 		acp_shm.cwmax = params->cw_max;
buf : 		acp_shm.cwcur = acp_shm.cwmin;
buf : 		acp_shm.bslots =
buf : 			bcma_read16(wlc->hw->d11core, D11REGOFFS(tsf_random)) &
buf : 			acp_shm.cwcur;
buf : 		acp_shm.reggap = acp_shm.bslots + acp_shm.aifs;
ifs; 
buf : 		/* Indicate the new params to the ucode */
buf : 		acp_shm.status = brcms_b_read_shm(wlc->hw, (M_EDCF_QINFO +
buf : 						  wme_ac2fifo[aci] *
ifo[aci] * 
buf : 						  M_EDCF_QLEN +
buf : 						  M_EDCF_STATUS_OFF));
buf : 		acp_shm.status |= WME_STATUS_NEWAC;
buf : 
buf : 		/* Fill in shm acparam table */
buf : 		shm_entry = (u16 *) &acp_shm;
buf : 		for (i = 0; i < (int)sizeof(struct shm_acparams); i += 2)
for (i = 0; i < (int)sizeof(struct shm_acparams); i += 2) 
buf : 			brcms_b_write_shm(wlc->hw,
buf : 					  M_EDCF_QINFO +
buf : 					  wme_ac2fifo[aci] * M_EDCF_QLEN + i,
ifo[aci] * M_EDCF_QLEN + i, 
buf : 					  *shm_entry++);
buf : 	}
buf : 
buf : 	if (suspend)
if (suspend) 
buf : 		brcms_c_suspend_mac_and_wait(wlc);
buf : 
buf : 	brcms_c_update_beacon(wlc);
buf : 	brcms_c_update_probe_resp(wlc, false);
buf : 
buf : 	if (suspend)
if (suspend) 
buf : 		brcms_c_enable_mac(wlc);
buf : }
buf : 
buf : static void brcms_c_edcf_setparams(struct brcms_c_info *wlc, bool suspend)
buf : {
buf : 	u16 aci;
buf : 	int i_ac;
buf : 	struct ieee80211_tx_queue_params txq_pars;
buf : 	static const struct edcf_acparam default_edcf_acparams[] = {
buf : 		 {EDCF_AC_BE_ACI_STA, EDCF_AC_BE_ECW_STA, EDCF_AC_BE_TXOP_STA},
buf : 		 {EDCF_AC_BK_ACI_STA, EDCF_AC_BK_ECW_STA, EDCF_AC_BK_TXOP_STA},
buf : 		 {EDCF_AC_VI_ACI_STA, EDCF_AC_VI_ECW_STA, EDCF_AC_VI_TXOP_STA},
buf : 		 {EDCF_AC_VO_ACI_STA, EDCF_AC_VO_ECW_STA, EDCF_AC_VO_TXOP_STA}
buf : 	}; /* ucode needs these parameters during its initialization */
buf : 	const struct edcf_acparam *edcf_acp = &default_edcf_acparams[0];
buf : 
buf : 	for (i_ac = 0; i_ac < IEEE80211_NUM_ACS; i_ac++, edcf_acp++) {
for (i_ac = 0; i_ac < IEEE80211_NUM_ACS; i_ac++, edcf_acp++) { 
buf : 		/* find out which ac this set of params applies to */
buf : 		aci = (edcf_acp->ACI & EDCF_ACI_MASK) >> EDCF_ACI_SHIFT;
buf : 
buf : 		/* fill in shm ac params struct */
buf : 		txq_pars.txop = edcf_acp->TXOP;
buf : 		txq_pars.aifs = edcf_acp->ACI;
ifs = edcf_acp->ACI; 
buf : 
buf : 		/* CWmin = 2^(ECWmin) - 1 */
buf : 		txq_pars.cw_min = EDCF_ECW2CW(edcf_acp->ECW & EDCF_ECWMIN_MASK);
buf : 		/* CWmax = 2^(ECWmax) - 1 */
buf : 		txq_pars.cw_max = EDCF_ECW2CW((edcf_acp->ECW & EDCF_ECWMAX_MASK)
buf : 					    >> EDCF_ECWMAX_SHIFT);
buf : 		brcms_c_wme_setparams(wlc, aci, &txq_pars, suspend);
buf : 	}
buf : 
buf : 	if (suspend) {
if (suspend) { 
buf : 		brcms_c_suspend_mac_and_wait(wlc);
buf : 		brcms_c_enable_mac(wlc);
buf : 	}
buf : }
buf : 
buf : static void brcms_c_radio_monitor_start(struct brcms_c_info *wlc)
buf : {
buf : 	/* Don't start the timer if HWRADIO feature is disabled */
if HWRADIO feature is disabled */ 
buf : 	if (wlc->radio_monitor)
buf : 		return;
buf : 
buf : 	wlc->radio_monitor = true;
buf : 	brcms_b_pllreq(wlc->hw, true, BRCMS_PLLREQ_RADIO_MON);
buf : 	brcms_add_timer(wlc->radio_timer, TIMER_INTERVAL_RADIOCHK, true);
buf : }
buf : 
buf : static bool brcms_c_radio_monitor_stop(struct brcms_c_info *wlc)
buf : {
buf : 	if (!wlc->radio_monitor)
if (!wlc->radio_monitor) 
buf : 		return true;
buf : 
buf : 	wlc->radio_monitor = false;
buf : 	brcms_b_pllreq(wlc->hw, false, BRCMS_PLLREQ_RADIO_MON);
buf : 	return brcms_del_timer(wlc->radio_timer);
buf : }
buf : 
buf : /* read hwdisable state and propagate to wlc flag */
buf : static void brcms_c_radio_hwdisable_upd(struct brcms_c_info *wlc)
buf : {
buf : 	if (wlc->pub->hw_off)
if (wlc->pub->hw_off) 
buf : 		return;
buf : 
buf : 	if (brcms_b_radio_read_hwdisabled(wlc->hw))
if (brcms_b_radio_read_hwdisabled(wlc->hw)) 
buf : 		mboolset(wlc->pub->radio_disabled, WL_RADIO_HW_DISABLE);
buf : 	else
buf : 		mboolclr(wlc->pub->radio_disabled, WL_RADIO_HW_DISABLE);
buf : }
buf : 
buf : /* update hwradio status and return it */
buf : bool brcms_c_check_radio_disabled(struct brcms_c_info *wlc)
buf : {
buf : 	brcms_c_radio_hwdisable_upd(wlc);
buf : 
buf : 	return mboolisset(wlc->pub->radio_disabled, WL_RADIO_HW_DISABLE) ?
buf : 			true : false;
buf : }
buf : 
buf : /* periodical query hw radio button while driver is "down" */
while driver is "down" */ 
buf : static void brcms_c_radio_timer(void *arg)
buf : {
buf : 	struct brcms_c_info *wlc = (struct brcms_c_info *) arg;
buf : 
buf : 	if (brcms_deviceremoved(wlc)) {
if (brcms_deviceremoved(wlc)) { 
buf : 		brcms_err(wlc->hw->d11core, "wl%d: %s: dead chip\n",
buf : 			  wlc->pub->unit, __func__);
buf : 		brcms_down(wlc->wl);
buf : 		return;
buf : 	}
buf : 
buf : 	brcms_c_radio_hwdisable_upd(wlc);
buf : }
buf : 
buf : /* common low-level watchdog code */
buf : static void brcms_b_watchdog(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 
buf : 	if (!wlc_hw->up)
if (!wlc_hw->up) 
buf : 		return;
buf : 
buf : 	/* increment second count */
buf : 	wlc_hw->now++;
buf : 
buf : 	/* Check for FIFO error interrupts */
for FIFO error interrupts */ 
buf : 	brcms_b_fifoerrors(wlc_hw);
buf : 
buf : 	/* make sure RX dma has buffers */
buf : 	dma_rxfill(wlc->hw->di[RX_FIFO]);
buf : 
buf : 	wlc_phy_watchdog(wlc_hw->band->pi);
buf : }
buf : 
buf : /* common watchdog code */
buf : static void brcms_c_watchdog(struct brcms_c_info *wlc)
buf : {
buf : 	brcms_dbg_info(wlc->hw->d11core, "wl%d\n", wlc->pub->unit);
buf : 
buf : 	if (!wlc->pub->up)
if (!wlc->pub->up) 
buf : 		return;
buf : 
buf : 	if (brcms_deviceremoved(wlc)) {
if (brcms_deviceremoved(wlc)) { 
buf : 		brcms_err(wlc->hw->d11core, "wl%d: %s: dead chip\n",
buf : 			  wlc->pub->unit, __func__);
buf : 		brcms_down(wlc->wl);
buf : 		return;
buf : 	}
buf : 
buf : 	/* increment second count */
buf : 	wlc->pub->now++;
buf : 
buf : 	brcms_c_radio_hwdisable_upd(wlc);
buf : 	/* if radio is disable, driver may be down, quit here */
if radio is disable, driver may be down, quit here */ 
buf : 	if (wlc->pub->radio_disabled)
buf : 		return;
buf : 
buf : 	brcms_b_watchdog(wlc);
buf : 
buf : 	/*
buf : 	 * occasionally sample mac stat counters to
buf : 	 * detect 16-bit counter wrap
buf : 	 */
buf : 	if ((wlc->pub->now % SW_TIMER_MAC_STAT_UPD) == 0)
if ((wlc->pub->now % SW_TIMER_MAC_STAT_UPD) == 0) 
buf : 		brcms_c_statsupd(wlc);
buf : 
buf : 	if (BRCMS_ISNPHY(wlc->band) &&
if (BRCMS_ISNPHY(wlc->band) && 
buf : 	    ((wlc->pub->now - wlc->tempsense_lasttime) >=
buf : 	     BRCMS_TEMPSENSE_PERIOD)) {
buf : 		wlc->tempsense_lasttime = wlc->pub->now;
buf : 		brcms_c_tempsense_upd(wlc);
buf : 	}
buf : }
buf : 
buf : static void brcms_c_watchdog_by_timer(void *arg)
buf : {
buf : 	struct brcms_c_info *wlc = (struct brcms_c_info *) arg;
buf : 
buf : 	brcms_c_watchdog(wlc);
buf : }
buf : 
buf : static bool brcms_c_timers_init(struct brcms_c_info *wlc, int unit)
buf : {
buf : 	wlc->wdtimer = brcms_init_timer(wlc->wl, brcms_c_watchdog_by_timer,
buf : 		wlc, "watchdog");
buf : 	if (!wlc->wdtimer) {
if (!wlc->wdtimer) { 
buf : 		wiphy_err(wlc->wiphy, "wl%d:  wl_init_timer for wdtimer "
for wdtimer " 
buf : 			  "failed\n", unit);
buf : 		goto fail;
buf : 	}
buf : 
buf : 	wlc->radio_timer = brcms_init_timer(wlc->wl, brcms_c_radio_timer,
buf : 		wlc, "radio");
buf : 	if (!wlc->radio_timer) {
if (!wlc->radio_timer) { 
buf : 		wiphy_err(wlc->wiphy, "wl%d:  wl_init_timer for radio_timer "
for radio_timer " 
buf : 			  "failed\n", unit);
buf : 		goto fail;
buf : 	}
buf : 
buf : 	return true;
buf : 
buf :  fail:
buf : 	return false;
buf : }
buf : 
buf : /*
buf :  * Initialize brcms_c_info default values ...
buf :  * may get overrides later in this function
buf :  */
buf : static void brcms_c_info_init(struct brcms_c_info *wlc, int unit)
buf : {
buf : 	int i;
buf : 
buf : 	/* Save our copy of the chanspec */
buf : 	wlc->chanspec = ch20mhz_chspec(1);
buf : 
buf : 	/* various 802.11g modes */
buf : 	wlc->shortslot = false;
buf : 	wlc->shortslot_override = BRCMS_SHORTSLOT_AUTO;
buf : 
buf : 	brcms_c_protection_upd(wlc, BRCMS_PROT_G_OVR, BRCMS_PROTECTION_AUTO);
buf : 	brcms_c_protection_upd(wlc, BRCMS_PROT_G_SPEC, false);
buf : 
buf : 	brcms_c_protection_upd(wlc, BRCMS_PROT_N_CFG_OVR,
buf : 			       BRCMS_PROTECTION_AUTO);
buf : 	brcms_c_protection_upd(wlc, BRCMS_PROT_N_CFG, BRCMS_N_PROTECTION_OFF);
buf : 	brcms_c_protection_upd(wlc, BRCMS_PROT_N_NONGF_OVR,
buf : 			       BRCMS_PROTECTION_AUTO);
buf : 	brcms_c_protection_upd(wlc, BRCMS_PROT_N_NONGF, false);
buf : 	brcms_c_protection_upd(wlc, BRCMS_PROT_N_PAM_OVR, AUTO);
buf : 
buf : 	brcms_c_protection_upd(wlc, BRCMS_PROT_OVERLAP,
buf : 			       BRCMS_PROTECTION_CTL_OVERLAP);
buf : 
buf : 	/* 802.11g draft 4.0 NonERP elt advertisement */
buf : 	wlc->include_legacy_erp = true;
buf : 
buf : 	wlc->stf->ant_rx_ovr = ANT_RX_DIV_DEF;
buf : 	wlc->stf->txant = ANT_TX_DEF;
buf : 
buf : 	wlc->prb_resp_timeout = BRCMS_PRB_RESP_TIMEOUT;
buf : 
buf : 	wlc->usr_fragthresh = DOT11_DEFAULT_FRAG_LEN;
buf : 	for (i = 0; i < NFIFO; i++)
for (i = 0; i < NFIFO; i++) 
buf : 		wlc->fragthresh[i] = DOT11_DEFAULT_FRAG_LEN;
buf : 	wlc->RTSThresh = DOT11_DEFAULT_RTS_LEN;
buf : 
buf : 	/* default rate fallback retry limits */
buf : 	wlc->SFBL = RETRY_SHORT_FB;
buf : 	wlc->LFBL = RETRY_LONG_FB;
buf : 
buf : 	/* default mac retry limits */
buf : 	wlc->SRL = RETRY_SHORT_DEF;
buf : 	wlc->LRL = RETRY_LONG_DEF;
buf : 
buf : 	/* WME QoS mode is Auto by default */
buf : 	wlc->pub->_ampdu = AMPDU_AGG_HOST;
buf : }
buf : 
buf : static uint brcms_c_attach_module(struct brcms_c_info *wlc)
buf : {
buf : 	uint err = 0;
buf : 	uint unit;
buf : 	unit = wlc->pub->unit;
buf : 
buf : 	wlc->asi = brcms_c_antsel_attach(wlc);
buf : 	if (wlc->asi == NULL) {
if (wlc->asi == NULL) { 
buf : 		wiphy_err(wlc->wiphy, "wl%d: attach: antsel_attach "
buf : 			  "failed\n", unit);
buf : 		err = 44;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	wlc->ampdu = brcms_c_ampdu_attach(wlc);
buf : 	if (wlc->ampdu == NULL) {
if (wlc->ampdu == NULL) { 
buf : 		wiphy_err(wlc->wiphy, "wl%d: attach: ampdu_attach "
buf : 			  "failed\n", unit);
buf : 		err = 50;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	if ((brcms_c_stf_attach(wlc) != 0)) {
if ((brcms_c_stf_attach(wlc) != 0)) { 
buf : 		wiphy_err(wlc->wiphy, "wl%d: attach: stf_attach "
buf : 			  "failed\n", unit);
buf : 		err = 68;
buf : 		goto fail;
buf : 	}
buf :  fail:
buf : 	return err;
buf : }
buf : 
buf : struct brcms_pub *brcms_c_pub(struct brcms_c_info *wlc)
buf : {
buf : 	return wlc->pub;
buf : }
buf : 
buf : /* low level attach
buf :  *    run backplane attach, init nvram
buf :  *    run phy attach
buf :  *    initialize software state for each core and band
for each core and band 
buf :  *    put the whole chip in reset(driver down state), no clock
buf :  */
buf : static int brcms_b_attach(struct brcms_c_info *wlc, struct bcma_device *core,
buf : 			  uint unit, bool piomode)
buf : {
buf : 	struct brcms_hardware *wlc_hw;
buf : 	uint err = 0;
buf : 	uint j;
buf : 	bool wme = false;
buf : 	struct shared_phy_params sha_params;
buf : 	struct wiphy *wiphy = wlc->wiphy;
buf : 	struct pci_dev *pcidev = core->bus->host_pci;
buf : 	struct ssb_sprom *sprom = &core->bus->sprom;
buf : 
buf : 	if (core->bus->hosttype == BCMA_HOSTTYPE_PCI)
if (core->bus->hosttype == BCMA_HOSTTYPE_PCI) 
buf : 		brcms_dbg_info(core, "wl%d: vendor 0x%x device 0x%x\n", unit,
buf : 			       pcidev->vendor,
buf : 			       pcidev->device);
buf : 	else
buf : 		brcms_dbg_info(core, "wl%d: vendor 0x%x device 0x%x\n", unit,
buf : 			       core->bus->boardinfo.vendor,
buf : 			       core->bus->boardinfo.type);
buf : 
buf : 	wme = true;
buf : 
buf : 	wlc_hw = wlc->hw;
buf : 	wlc_hw->wlc = wlc;
buf : 	wlc_hw->unit = unit;
buf : 	wlc_hw->band = wlc_hw->bandstate[0];
buf : 	wlc_hw->_piomode = piomode;
buf : 
buf : 	/* populate struct brcms_hardware with default values  */
buf : 	brcms_b_info_init(wlc_hw);
buf : 
buf : 	/*
buf : 	 * Do the hardware portion of the attach. Also initialize software
buf : 	 * state that depends on the particular hardware we are running.
buf : 	 */
buf : 	wlc_hw->sih = ai_attach(core->bus);
buf : 	if (wlc_hw->sih == NULL) {
if (wlc_hw->sih == NULL) { 
buf : 		wiphy_err(wiphy, "wl%d: brcms_b_attach: si_attach failed\n",
buf : 			  unit);
buf : 		err = 11;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	/* verify again the device is supported */
ify again the device is supported */ 
buf : 	if (!brcms_c_chipmatch(core)) {
buf : 		wiphy_err(wiphy, "wl%d: brcms_b_attach: Unsupported device\n",
buf : 			 unit);
buf : 		err = 12;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	if (core->bus->hosttype == BCMA_HOSTTYPE_PCI) {
if (core->bus->hosttype == BCMA_HOSTTYPE_PCI) { 
buf : 		wlc_hw->vendorid = pcidev->vendor;
buf : 		wlc_hw->deviceid = pcidev->device;
buf : 	} else {
buf : 		wlc_hw->vendorid = core->bus->boardinfo.vendor;
buf : 		wlc_hw->deviceid = core->bus->boardinfo.type;
buf : 	}
buf : 
buf : 	wlc_hw->d11core = core;
buf : 	wlc_hw->corerev = core->id.rev;
buf : 
buf : 	/* validate chip, chiprev and corerev */
buf : 	if (!brcms_c_isgoodchip(wlc_hw)) {
if (!brcms_c_isgoodchip(wlc_hw)) { 
buf : 		err = 13;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	/* initialize power control registers */
buf : 	ai_clkctl_init(wlc_hw->sih);
buf : 
buf : 	/* request fastclock and force fastclock for the rest of attach
force fastclock for the rest of attach 
buf : 	 * bring the d11 core out of reset.
buf : 	 *   For PMU chips, the first wlc_clkctl_clk is no-op since core-clk
buf : 	 *   is still false; But it will be called again inside wlc_corereset,
buf : 	 *   after d11 is out of reset.
buf : 	 */
buf : 	brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_FAST);
buf : 	brcms_b_corereset(wlc_hw, BRCMS_USE_COREFLAGS);
buf : 
buf : 	if (!brcms_b_validate_chip_access(wlc_hw)) {
if (!brcms_b_validate_chip_access(wlc_hw)) { 
buf : 		wiphy_err(wiphy, "wl%d: brcms_b_attach: validate_chip_access "
buf : 			"failed\n", unit);
buf : 		err = 14;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	/* get the board rev, used just below */
buf : 	j = sprom->board_rev;
buf : 	/* promote srom boardrev of 0xFF to 1 */
buf : 	if (j == BOARDREV_PROMOTABLE)
if (j == BOARDREV_PROMOTABLE) 
buf : 		j = BOARDREV_PROMOTED;
buf : 	wlc_hw->boardrev = (u16) j;
buf : 	if (!brcms_c_validboardtype(wlc_hw)) {
if (!brcms_c_validboardtype(wlc_hw)) { 
buf : 		wiphy_err(wiphy, "wl%d: brcms_b_attach: Unsupported Broadcom "
buf : 			  "board type (0x%x)" " or revision level (0x%x)\n",
buf : 			  unit, ai_get_boardtype(wlc_hw->sih),
buf : 			  wlc_hw->boardrev);
buf : 		err = 15;
buf : 		goto fail;
buf : 	}
buf : 	wlc_hw->sromrev = sprom->revision;
buf : 	wlc_hw->boardflags = sprom->boardflags_lo + (sprom->boardflags_hi << 16);
buf : 	wlc_hw->boardflags2 = sprom->boardflags2_lo + (sprom->boardflags2_hi << 16);
buf : 
buf : 	if (wlc_hw->boardflags & BFL_NOPLLDOWN)
if (wlc_hw->boardflags & BFL_NOPLLDOWN) 
buf : 		brcms_b_pllreq(wlc_hw, true, BRCMS_PLLREQ_SHARED);
buf : 
buf : 	/* check device id(srom, nvram etc.) to set bands */
buf : 	if (wlc_hw->deviceid == BCM43224_D11N_ID ||
if (wlc_hw->deviceid == BCM43224_D11N_ID || 
buf : 	    wlc_hw->deviceid == BCM43224_D11N_ID_VEN1 ||
buf : 	    wlc_hw->deviceid == BCM43224_CHIP_ID)
buf : 		/* Dualband boards */
buf : 		wlc_hw->_nbands = 2;
buf : 	else
buf : 		wlc_hw->_nbands = 1;
buf : 
buf : 	if ((ai_get_chip_id(wlc_hw->sih) == BCMA_CHIP_ID_BCM43225))
if ((ai_get_chip_id(wlc_hw->sih) == BCMA_CHIP_ID_BCM43225)) 
buf : 		wlc_hw->_nbands = 1;
buf : 
buf : 	/* BMAC_NOTE: remove init of pub values when brcms_c_attach()
buf : 	 * unconditionally does the init of these values
buf : 	 */
buf : 	wlc->vendorid = wlc_hw->vendorid;
buf : 	wlc->deviceid = wlc_hw->deviceid;
buf : 	wlc->pub->sih = wlc_hw->sih;
buf : 	wlc->pub->corerev = wlc_hw->corerev;
buf : 	wlc->pub->sromrev = wlc_hw->sromrev;
buf : 	wlc->pub->boardrev = wlc_hw->boardrev;
buf : 	wlc->pub->boardflags = wlc_hw->boardflags;
buf : 	wlc->pub->boardflags2 = wlc_hw->boardflags2;
buf : 	wlc->pub->_nbands = wlc_hw->_nbands;
buf : 
buf : 	wlc_hw->physhim = wlc_phy_shim_attach(wlc_hw, wlc->wl, wlc);
buf : 
buf : 	if (wlc_hw->physhim == NULL) {
if (wlc_hw->physhim == NULL) { 
buf : 		wiphy_err(wiphy, "wl%d: brcms_b_attach: wlc_phy_shim_attach "
buf : 			"failed\n", unit);
buf : 		err = 25;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	/* pass all the parameters to wlc_phy_shared_attach in one struct */
buf : 	sha_params.sih = wlc_hw->sih;
buf : 	sha_params.physhim = wlc_hw->physhim;
buf : 	sha_params.unit = unit;
buf : 	sha_params.corerev = wlc_hw->corerev;
buf : 	sha_params.vid = wlc_hw->vendorid;
buf : 	sha_params.did = wlc_hw->deviceid;
buf : 	sha_params.chip = ai_get_chip_id(wlc_hw->sih);
buf : 	sha_params.chiprev = ai_get_chiprev(wlc_hw->sih);
buf : 	sha_params.chippkg = ai_get_chippkg(wlc_hw->sih);
buf : 	sha_params.sromrev = wlc_hw->sromrev;
buf : 	sha_params.boardtype = ai_get_boardtype(wlc_hw->sih);
buf : 	sha_params.boardrev = wlc_hw->boardrev;
buf : 	sha_params.boardflags = wlc_hw->boardflags;
buf : 	sha_params.boardflags2 = wlc_hw->boardflags2;
buf : 
buf : 	/* alloc and save pointer to shared phy state area */
buf : 	wlc_hw->phy_sh = wlc_phy_shared_attach(&sha_params);
buf : 	if (!wlc_hw->phy_sh) {
if (!wlc_hw->phy_sh) { 
buf : 		err = 16;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	/* initialize software state for each core and band */
for each core and band */ 
buf : 	for (j = 0; j < wlc_hw->_nbands; j++) {
buf : 		/*
buf : 		 * band0 is always 2.4Ghz
buf : 		 * band1, if present, is 5Ghz
if present, is 5Ghz 
buf : 		 */
buf : 
buf : 		brcms_c_setxband(wlc_hw, j);
buf : 
buf : 		wlc_hw->band->bandunit = j;
buf : 		wlc_hw->band->bandtype = j ? BRCM_BAND_5G : BRCM_BAND_2G;
buf : 		wlc->band->bandunit = j;
buf : 		wlc->band->bandtype = j ? BRCM_BAND_5G : BRCM_BAND_2G;
buf : 		wlc->core->coreidx = core->core_index;
buf : 
buf : 		wlc_hw->machwcap = bcma_read32(core, D11REGOFFS(machwcap));
buf : 		wlc_hw->machwcap_backup = wlc_hw->machwcap;
buf : 
buf : 		/* init tx fifo size */
ifo size */ 
buf : 		WARN_ON((wlc_hw->corerev - XMTFIFOTBL_STARTREV) < 0 ||
buf : 			(wlc_hw->corerev - XMTFIFOTBL_STARTREV) >
buf : 				ARRAY_SIZE(xmtfifo_sz));
ifo_sz)); 
buf : 		wlc_hw->xmtfifo_sz =
buf : 		    xmtfifo_sz[(wlc_hw->corerev - XMTFIFOTBL_STARTREV)];
ifo_sz[(wlc_hw->corerev - XMTFIFOTBL_STARTREV)]; 
buf : 		WARN_ON(!wlc_hw->xmtfifo_sz[0]);
buf : 
buf : 		/* Get a phy for this band */
for this band */ 
buf : 		wlc_hw->band->pi =
buf : 			wlc_phy_attach(wlc_hw->phy_sh, core,
buf : 				       wlc_hw->band->bandtype,
buf : 				       wlc->wiphy);
buf : 		if (wlc_hw->band->pi == NULL) {
if (wlc_hw->band->pi == NULL) { 
buf : 			wiphy_err(wiphy, "wl%d: brcms_b_attach: wlc_phy_"
buf : 				  "attach failed\n", unit);
buf : 			err = 17;
buf : 			goto fail;
buf : 		}
buf : 
buf : 		wlc_phy_machwcap_set(wlc_hw->band->pi, wlc_hw->machwcap);
buf : 
buf : 		wlc_phy_get_phyversion(wlc_hw->band->pi, &wlc_hw->band->phytype,
buf : 				       &wlc_hw->band->phyrev,
buf : 				       &wlc_hw->band->radioid,
buf : 				       &wlc_hw->band->radiorev);
buf : 		wlc_hw->band->abgphy_encore =
buf : 		    wlc_phy_get_encore(wlc_hw->band->pi);
buf : 		wlc->band->abgphy_encore = wlc_phy_get_encore(wlc_hw->band->pi);
buf : 		wlc_hw->band->core_flags =
buf : 		    wlc_phy_get_coreflags(wlc_hw->band->pi);
buf : 
buf : 		/* verify good phy_type & supported phy revision */
ify good phy_type & supported phy revision */ 
buf : 		if (BRCMS_ISNPHY(wlc_hw->band)) {
buf : 			if (NCONF_HAS(wlc_hw->band->phyrev))
if (NCONF_HAS(wlc_hw->band->phyrev)) 
buf : 				goto good_phy;
buf : 			else
buf : 				goto bad_phy;
buf : 		} else if (BRCMS_ISLCNPHY(wlc_hw->band)) {
if (BRCMS_ISLCNPHY(wlc_hw->band)) { 
buf : 			if (LCNCONF_HAS(wlc_hw->band->phyrev))
buf : 				goto good_phy;
buf : 			else
buf : 				goto bad_phy;
buf : 		} else {
buf :  bad_phy:
buf : 			wiphy_err(wiphy, "wl%d: brcms_b_attach: unsupported "
buf : 				  "phy type/rev (%d/%d)\n", unit,
buf : 				  wlc_hw->band->phytype, wlc_hw->band->phyrev);
buf : 			err = 18;
buf : 			goto fail;
buf : 		}
buf : 
buf :  good_phy:
buf : 		/*
buf : 		 * BMAC_NOTE: wlc->band->pi should not be set below and should
buf : 		 * be done in the high level attach. However we can not make
buf : 		 * that change until all low level access is changed to
buf : 		 * wlc_hw->band->pi. Instead do the wlc->band->pi init below,
buf : 		 * keeping wlc_hw->band->pi as well for incremental update of
for incremental update of 
buf : 		 * low level fns, and cut over low only init when all fns
buf : 		 * updated.
buf : 		 */
buf : 		wlc->band->pi = wlc_hw->band->pi;
buf : 		wlc->band->phytype = wlc_hw->band->phytype;
buf : 		wlc->band->phyrev = wlc_hw->band->phyrev;
buf : 		wlc->band->radioid = wlc_hw->band->radioid;
buf : 		wlc->band->radiorev = wlc_hw->band->radiorev;
buf : 		brcms_dbg_info(core, "wl%d: phy %u/%u radio %x/%u\n", unit,
buf : 			       wlc->band->phytype, wlc->band->phyrev,
buf : 			       wlc->band->radioid, wlc->band->radiorev);
buf : 		/* default contention windows size limits */
buf : 		wlc_hw->band->CWmin = APHY_CWMIN;
buf : 		wlc_hw->band->CWmax = PHY_CWMAX;
buf : 
buf : 		if (!brcms_b_attach_dmapio(wlc, j, wme)) {
if (!brcms_b_attach_dmapio(wlc, j, wme)) { 
buf : 			err = 19;
buf : 			goto fail;
buf : 		}
buf : 	}
buf : 
buf : 	/* disable core to match driver "down" state */
buf : 	brcms_c_coredisable(wlc_hw);
buf : 
buf : 	/* Match driver "down" state */
buf : 	bcma_core_pci_down(wlc_hw->d11core->bus);
buf : 
buf : 	/* turn off pll and xtal to match driver "down" state */
buf : 	brcms_b_xtal(wlc_hw, OFF);
buf : 
buf : 	/* *******************************************************************
buf : 	 * The hardware is in the DOWN state at this point. D11 core
buf : 	 * or cores are in reset with clocks off, and the board PLLs
buf : 	 * are off if possible.
if possible. 
buf : 	 *
buf : 	 * Beyond this point, wlc->sbclk == false and chip registers
buf : 	 * should not be touched.
buf : 	 *********************************************************************
buf : 	 */
buf : 
buf : 	/* init etheraddr state variables */
buf : 	brcms_c_get_macaddr(wlc_hw, wlc_hw->etheraddr);
buf : 
buf : 	if (is_broadcast_ether_addr(wlc_hw->etheraddr) ||
if (is_broadcast_ether_addr(wlc_hw->etheraddr) || 
buf : 	    is_zero_ether_addr(wlc_hw->etheraddr)) {
buf : 		wiphy_err(wiphy, "wl%d: brcms_b_attach: bad macaddr\n",
buf : 			  unit);
buf : 		err = 22;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	brcms_dbg_info(wlc_hw->d11core, "deviceid 0x%x nbands %d board 0x%x\n",
buf : 		       wlc_hw->deviceid, wlc_hw->_nbands,
buf : 		       ai_get_boardtype(wlc_hw->sih));
buf : 
buf : 	return err;
buf : 
buf :  fail:
buf : 	wiphy_err(wiphy, "wl%d: brcms_b_attach: failed with err %d\n", unit,
buf : 		  err);
buf : 	return err;
buf : }
buf : 
buf : static void brcms_c_attach_antgain_init(struct brcms_c_info *wlc)
buf : {
buf : 	uint unit;
buf : 	unit = wlc->pub->unit;
buf : 
buf : 	if ((wlc->band->antgain == -1) && (wlc->pub->sromrev == 1)) {
if ((wlc->band->antgain == -1) && (wlc->pub->sromrev == 1)) { 
buf : 		/* default antenna gain for srom rev 1 is 2 dBm (8 qdbm) */
for srom rev 1 is 2 dBm (8 qdbm) */ 
buf : 		wlc->band->antgain = 8;
buf : 	} else if (wlc->band->antgain == -1) {
if (wlc->band->antgain == -1) { 
buf : 		wiphy_err(wlc->wiphy, "wl%d: %s: Invalid antennas available in"
buf : 			  " srom, using 2dB\n", unit, __func__);
buf : 		wlc->band->antgain = 8;
buf : 	} else {
buf : 		s8 gain, fract;
buf : 		/* Older sroms specified gain in whole dbm only.  In order
ified gain in whole dbm only.  In order 
buf : 		 * be able to specify qdbm granularity and remain backward
buf : 		 * compatible the whole dbms are now encoded in only
buf : 		 * low 6 bits and remaining qdbms are encoded in the hi 2 bits.
buf : 		 * 6 bit signed number ranges from -32 - 31.
buf : 		 *
buf : 		 * Examples:
buf : 		 * 0x1 = 1 db,
buf : 		 * 0xc1 = 1.75 db (1 + 3 quarters),
buf : 		 * 0x3f = -1 (-1 + 0 quarters),
buf : 		 * 0x7f = -.75 (-1 + 1 quarters) = -3 qdbm.
buf : 		 * 0xbf = -.50 (-1 + 2 quarters) = -2 qdbm.
buf : 		 */
buf : 		gain = wlc->band->antgain & 0x3f;
buf : 		gain <<= 2;	/* Sign extend */
buf : 		gain >>= 2;
buf : 		fract = (wlc->band->antgain & 0xc0) >> 6;
buf : 		wlc->band->antgain = 4 * gain + fract;
buf : 	}
buf : }
buf : 
buf : static bool brcms_c_attach_stf_ant_init(struct brcms_c_info *wlc)
buf : {
buf : 	int aa;
buf : 	uint unit;
buf : 	int bandtype;
buf : 	struct ssb_sprom *sprom = &wlc->hw->d11core->bus->sprom;
buf : 
buf : 	unit = wlc->pub->unit;
buf : 	bandtype = wlc->band->bandtype;
buf : 
buf : 	/* get antennas available */
buf : 	if (bandtype == BRCM_BAND_5G)
if (bandtype == BRCM_BAND_5G) 
buf : 		aa = sprom->ant_available_a;
buf : 	else
buf : 		aa = sprom->ant_available_bg;
buf : 
buf : 	if ((aa < 1) || (aa > 15)) {
if ((aa < 1) || (aa > 15)) { 
buf : 		wiphy_err(wlc->wiphy, "wl%d: %s: Invalid antennas available in"
buf : 			  " srom (0x%x), using 3\n", unit, __func__, aa);
buf : 		aa = 3;
buf : 	}
buf : 
buf : 	/* reset the defaults if we have a single antenna */
if we have a single antenna */ 
buf : 	if (aa == 1) {
buf : 		wlc->stf->ant_rx_ovr = ANT_RX_DIV_FORCE_0;
buf : 		wlc->stf->txant = ANT_TX_FORCE_0;
buf : 	} else if (aa == 2) {
if (aa == 2) { 
buf : 		wlc->stf->ant_rx_ovr = ANT_RX_DIV_FORCE_1;
buf : 		wlc->stf->txant = ANT_TX_FORCE_1;
buf : 	} else {
buf : 	}
buf : 
buf : 	/* Compute Antenna Gain */
buf : 	if (bandtype == BRCM_BAND_5G)
if (bandtype == BRCM_BAND_5G) 
buf : 		wlc->band->antgain = sprom->antenna_gain.a1;
buf : 	else
buf : 		wlc->band->antgain = sprom->antenna_gain.a0;
buf : 
buf : 	brcms_c_attach_antgain_init(wlc);
buf : 
buf : 	return true;
buf : }
buf : 
buf : static void brcms_c_bss_default_init(struct brcms_c_info *wlc)
buf : {
buf : 	u16 chanspec;
buf : 	struct brcms_band *band;
buf : 	struct brcms_bss_info *bi = wlc->default_bss;
buf : 
buf : 	/* init default and target BSS with some sane initial values */
buf : 	memset(bi, 0, sizeof(*bi));
buf : 	bi->beacon_period = BEACON_INTERVAL_DEFAULT;
buf : 
buf : 	/* fill the default channel as the first valid channel
buf : 	 * starting from the 2G channels
buf : 	 */
buf : 	chanspec = ch20mhz_chspec(1);
buf : 	wlc->home_chanspec = bi->chanspec = chanspec;
buf : 
buf : 	/* find the band of our default channel */
buf : 	band = wlc->band;
buf : 	if (wlc->pub->_nbands > 1 &&
if (wlc->pub->_nbands > 1 && 
buf : 	    band->bandunit != chspec_bandunit(chanspec))
buf : 		band = wlc->bandstate[OTHERBANDUNIT(wlc)];
buf : 
buf : 	/* init bss rates to the band specific default rate set */
ific default rate set */ 
buf : 	brcms_c_rateset_default(&bi->rateset, NULL, band->phytype,
buf : 		band->bandtype, false, BRCMS_RATE_MASK_FULL,
buf : 		(bool) (wlc->pub->_n_enab & SUPPORT_11N),
buf : 		brcms_chspec_bw(chanspec), wlc->stf->txstreams);
buf : 
buf : 	if (wlc->pub->_n_enab & SUPPORT_11N)
if (wlc->pub->_n_enab & SUPPORT_11N) 
buf : 		bi->flags |= BRCMS_BSS_HT;
buf : }
buf : 
buf : static void brcms_c_update_mimo_band_bwcap(struct brcms_c_info *wlc, u8 bwcap)
buf : {
buf : 	uint i;
buf : 	struct brcms_band *band;
buf : 
buf : 	for (i = 0; i < wlc->pub->_nbands; i++) {
for (i = 0; i < wlc->pub->_nbands; i++) { 
buf : 		band = wlc->bandstate[i];
buf : 		if (band->bandtype == BRCM_BAND_5G) {
if (band->bandtype == BRCM_BAND_5G) { 
buf : 			if ((bwcap == BRCMS_N_BW_40ALL)
buf : 			    || (bwcap == BRCMS_N_BW_20IN2G_40IN5G))
buf : 				band->mimo_cap_40 = true;
buf : 			else
buf : 				band->mimo_cap_40 = false;
buf : 		} else {
buf : 			if (bwcap == BRCMS_N_BW_40ALL)
if (bwcap == BRCMS_N_BW_40ALL) 
buf : 				band->mimo_cap_40 = true;
buf : 			else
buf : 				band->mimo_cap_40 = false;
buf : 		}
buf : 	}
buf : }
buf : 
buf : static void brcms_c_timers_deinit(struct brcms_c_info *wlc)
buf : {
buf : 	/* free timer state */
buf : 	if (wlc->wdtimer) {
if (wlc->wdtimer) { 
buf : 		brcms_free_timer(wlc->wdtimer);
buf : 		wlc->wdtimer = NULL;
buf : 	}
buf : 	if (wlc->radio_timer) {
if (wlc->radio_timer) { 
buf : 		brcms_free_timer(wlc->radio_timer);
buf : 		wlc->radio_timer = NULL;
buf : 	}
buf : }
buf : 
buf : static void brcms_c_detach_module(struct brcms_c_info *wlc)
buf : {
buf : 	if (wlc->asi) {
if (wlc->asi) { 
buf : 		brcms_c_antsel_detach(wlc->asi);
buf : 		wlc->asi = NULL;
buf : 	}
buf : 
buf : 	if (wlc->ampdu) {
if (wlc->ampdu) { 
buf : 		brcms_c_ampdu_detach(wlc->ampdu);
buf : 		wlc->ampdu = NULL;
buf : 	}
buf : 
buf : 	brcms_c_stf_detach(wlc);
buf : }
buf : 
buf : /*
buf :  * low level detach
buf :  */
buf : static void brcms_b_detach(struct brcms_c_info *wlc)
buf : {
buf : 	uint i;
buf : 	struct brcms_hw_band *band;
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 
buf : 	brcms_b_detach_dmapio(wlc_hw);
buf : 
buf : 	band = wlc_hw->band;
buf : 	for (i = 0; i < wlc_hw->_nbands; i++) {
for (i = 0; i < wlc_hw->_nbands; i++) { 
buf : 		if (band->pi) {
buf : 			/* Detach this band's phy */
buf : 			wlc_phy_detach(band->pi);
buf : 			band->pi = NULL;
buf : 		}
buf : 		band = wlc_hw->bandstate[OTHERBANDUNIT(wlc)];
buf : 	}
buf : 
buf : 	/* Free shared phy state */
buf : 	kfree(wlc_hw->phy_sh);
buf : 
buf : 	wlc_phy_shim_detach(wlc_hw->physhim);
buf : 
buf : 	if (wlc_hw->sih) {
if (wlc_hw->sih) { 
buf : 		ai_detach(wlc_hw->sih);
buf : 		wlc_hw->sih = NULL;
buf : 	}
buf : }
buf : 
buf : /*
buf :  * Return a count of the number of driver callbacks still pending.
buf :  *
buf :  * General policy is that brcms_c_detach can only dealloc/free software states.
buf :  * It can NOT touch hardware registers since the d11core may be in reset and
buf :  * clock may not be available.
buf :  * One exception is sb register access, which is possible if crystal is turned
if crystal is turned 
buf :  * on after "down" state, driver should avoid software timer with the exception
buf :  * of radio_monitor.
buf :  */
buf : uint brcms_c_detach(struct brcms_c_info *wlc)
buf : {
buf : 	uint callbacks;
buf : 
buf : 	if (wlc == NULL)
if (wlc == NULL) 
buf : 		return 0;
buf : 
buf : 	brcms_b_detach(wlc);
buf : 
buf : 	/* delete software timers */
buf : 	callbacks = 0;
buf : 	if (!brcms_c_radio_monitor_stop(wlc))
if (!brcms_c_radio_monitor_stop(wlc)) 
buf : 		callbacks++;
buf : 
buf : 	brcms_c_channel_mgr_detach(wlc->cmi);
buf : 
buf : 	brcms_c_timers_deinit(wlc);
buf : 
buf : 	brcms_c_detach_module(wlc);
buf : 
buf : 	brcms_c_detach_mfree(wlc);
buf : 	return callbacks;
buf : }
buf : 
buf : /* update state that depends on the current value of "ap" */
buf : static void brcms_c_ap_upd(struct brcms_c_info *wlc)
buf : {
buf : 	/* STA-BSS; short capable */
buf : 	wlc->PLCPHdr_override = BRCMS_PLCP_SHORT;
buf : }
buf : 
buf : /* Initialize just the hardware when coming out of POR or S3/S5 system states */
buf : static void brcms_b_hw_up(struct brcms_hardware *wlc_hw)
buf : {
buf : 	if (wlc_hw->wlc->pub->hw_up)
if (wlc_hw->wlc->pub->hw_up) 
buf : 		return;
buf : 
buf : 	brcms_dbg_info(wlc_hw->d11core, "wl%d\n", wlc_hw->unit);
buf : 
buf : 	/*
buf : 	 * Enable pll and xtal, initialize the power control registers,
buf : 	 * and force fastclock for the remainder of brcms_c_up().
force fastclock for the remainder of brcms_c_up(). 
buf : 	 */
buf : 	brcms_b_xtal(wlc_hw, ON);
buf : 	ai_clkctl_init(wlc_hw->sih);
buf : 	brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_FAST);
buf : 
buf : 	/*
buf : 	 * TODO: test suspend/resume
buf : 	 *
buf : 	 * AI chip doesn't restore bar0win2 on
buf : 	 * hibernation/resume, need sw fixup
buf : 	 */
buf : 
buf : 	/*
buf : 	 * Inform phy that a POR reset has occurred so
form phy that a POR reset has occurred so 
buf : 	 * it does a complete phy init
buf : 	 */
buf : 	wlc_phy_por_inform(wlc_hw->band->pi);
form(wlc_hw->band->pi); 
buf : 
buf : 	wlc_hw->ucode_loaded = false;
buf : 	wlc_hw->wlc->pub->hw_up = true;
buf : 
buf : 	if ((wlc_hw->boardflags & BFL_FEM)
if ((wlc_hw->boardflags & BFL_FEM) 
buf : 	    && (ai_get_chip_id(wlc_hw->sih) == BCMA_CHIP_ID_BCM4313)) {
buf : 		if (!
if (! 
buf : 		    (wlc_hw->boardrev >= 0x1250
buf : 		     && (wlc_hw->boardflags & BFL_FEM_BT)))
buf : 			ai_epa_4313war(wlc_hw->sih);
buf : 	}
buf : }
buf : 
buf : static int brcms_b_up_prep(struct brcms_hardware *wlc_hw)
buf : {
buf : 	brcms_dbg_info(wlc_hw->d11core, "wl%d\n", wlc_hw->unit);
buf : 
buf : 	/*
buf : 	 * Enable pll and xtal, initialize the power control registers,
buf : 	 * and force fastclock for the remainder of brcms_c_up().
force fastclock for the remainder of brcms_c_up(). 
buf : 	 */
buf : 	brcms_b_xtal(wlc_hw, ON);
buf : 	ai_clkctl_init(wlc_hw->sih);
buf : 	brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_FAST);
buf : 
buf : 	/*
buf : 	 * Configure pci/pcmcia here instead of in brcms_c_attach()
buf : 	 * to allow mfg hotswap:  down, hotswap (chip power cycle), up.
buf : 	 */
buf : 	bcma_core_pci_irq_ctl(&wlc_hw->d11core->bus->drv_pci[0], wlc_hw->d11core,
buf : 			      true);
buf : 
buf : 	/*
buf : 	 * Need to read the hwradio status here to cover the case where the
buf : 	 * system is loaded with the hw radio disabled. We do not want to
buf : 	 * bring the driver up in this case.
buf : 	 */
buf : 	if (brcms_b_radio_read_hwdisabled(wlc_hw)) {
if (brcms_b_radio_read_hwdisabled(wlc_hw)) { 
buf : 		/* put SB PCI in down state again */
buf : 		bcma_core_pci_down(wlc_hw->d11core->bus);
buf : 		brcms_b_xtal(wlc_hw, OFF);
buf : 		return -ENOMEDIUM;
buf : 	}
buf : 
buf : 	bcma_core_pci_up(wlc_hw->d11core->bus);
buf : 
buf : 	/* reset the d11 core */
buf : 	brcms_b_corereset(wlc_hw, BRCMS_USE_COREFLAGS);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int brcms_b_up_finish(struct brcms_hardware *wlc_hw)
buf : {
buf : 	wlc_hw->up = true;
buf : 	wlc_phy_hw_state_upd(wlc_hw->band->pi, true);
buf : 
buf : 	/* FULLY enable dynamic power control and d11 core interrupt */
buf : 	brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_DYNAMIC);
buf : 	brcms_intrson(wlc_hw->wlc->wl);
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * Write WME tunable parameters for retransmit/max rate
for retransmit/max rate 
buf :  * from wlc struct to ucode
buf :  */
buf : static void brcms_c_wme_retries_write(struct brcms_c_info *wlc)
buf : {
buf : 	int ac;
buf : 
buf : 	/* Need clock to do this */
buf : 	if (!wlc->clk)
if (!wlc->clk) 
buf : 		return;
buf : 
buf : 	for (ac = 0; ac < IEEE80211_NUM_ACS; ac++)
for (ac = 0; ac < IEEE80211_NUM_ACS; ac++) 
buf : 		brcms_b_write_shm(wlc->hw, M_AC_TXLMT_ADDR(ac),
buf : 				  wlc->wme_retries[ac]);
buf : }
buf : 
buf : /* make interface operational */
buf : int brcms_c_up(struct brcms_c_info *wlc)
buf : {
buf : 	struct ieee80211_channel *ch;
buf : 
buf : 	brcms_dbg_info(wlc->hw->d11core, "wl%d\n", wlc->pub->unit);
buf : 
buf : 	/* HW is turned off so don't try to access it */
buf : 	if (wlc->pub->hw_off || brcms_deviceremoved(wlc))
if (wlc->pub->hw_off || brcms_deviceremoved(wlc)) 
buf : 		return -ENOMEDIUM;
buf : 
buf : 	if (!wlc->pub->hw_up) {
if (!wlc->pub->hw_up) { 
buf : 		brcms_b_hw_up(wlc->hw);
buf : 		wlc->pub->hw_up = true;
buf : 	}
buf : 
buf : 	if ((wlc->pub->boardflags & BFL_FEM)
if ((wlc->pub->boardflags & BFL_FEM) 
buf : 	    && (ai_get_chip_id(wlc->hw->sih) == BCMA_CHIP_ID_BCM4313)) {
buf : 		if (wlc->pub->boardrev >= 0x1250
if (wlc->pub->boardrev >= 0x1250 
buf : 		    && (wlc->pub->boardflags & BFL_FEM_BT))
buf : 			brcms_b_mhf(wlc->hw, MHF5, MHF5_4313_GPIOCTRL,
buf : 				MHF5_4313_GPIOCTRL, BRCM_BAND_ALL);
buf : 		else
buf : 			brcms_b_mhf(wlc->hw, MHF4, MHF4_EXTPA_ENABLE,
buf : 				    MHF4_EXTPA_ENABLE, BRCM_BAND_ALL);
buf : 	}
buf : 
buf : 	/*
buf : 	 * Need to read the hwradio status here to cover the case where the
buf : 	 * system is loaded with the hw radio disabled. We do not want to bring
buf : 	 * the driver up in this case. If radio is disabled, abort up, lower
buf : 	 * power, start radio timer and return 0(for NDIS) don't call
for NDIS) don't call 
buf : 	 * radio_update to avoid looping brcms_c_up.
buf : 	 *
buf : 	 * brcms_b_up_prep() returns either 0 or -BCME_RADIOOFF only
buf : 	 */
buf : 	if (!wlc->pub->radio_disabled) {
if (!wlc->pub->radio_disabled) { 
buf : 		int status = brcms_b_up_prep(wlc->hw);
buf : 		if (status == -ENOMEDIUM) {
if (status == -ENOMEDIUM) { 
buf : 			if (!mboolisset
buf : 			    (wlc->pub->radio_disabled, WL_RADIO_HW_DISABLE)) {
buf : 				struct brcms_bss_cfg *bsscfg = wlc->bsscfg;
buf : 				mboolset(wlc->pub->radio_disabled,
buf : 					 WL_RADIO_HW_DISABLE);
buf : 				if (bsscfg->type == BRCMS_TYPE_STATION ||
if (bsscfg->type == BRCMS_TYPE_STATION || 
buf : 				    bsscfg->type == BRCMS_TYPE_ADHOC)
buf : 					brcms_err(wlc->hw->d11core,
buf : 						  "wl%d: up: rfdisable -> "
buf : 						  "bsscfg_disable()\n",
buf : 						   wlc->pub->unit);
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	if (wlc->pub->radio_disabled) {
if (wlc->pub->radio_disabled) { 
buf : 		brcms_c_radio_monitor_start(wlc);
buf : 		return 0;
buf : 	}
buf : 
buf : 	/* brcms_b_up_prep has done brcms_c_corereset(). so clk is on, set it */
buf : 	wlc->clk = true;
buf : 
buf : 	brcms_c_radio_monitor_stop(wlc);
buf : 
buf : 	/* Set EDCF hostflags */
buf : 	brcms_b_mhf(wlc->hw, MHF1, MHF1_EDCF, MHF1_EDCF, BRCM_BAND_ALL);
buf : 
buf : 	brcms_init(wlc->wl);
buf : 	wlc->pub->up = true;
buf : 
buf : 	if (wlc->bandinit_pending) {
if (wlc->bandinit_pending) { 
buf : 		ch = wlc->pub->ieee_hw->conf.chandef.chan;
buf : 		brcms_c_suspend_mac_and_wait(wlc);
buf : 		brcms_c_set_chanspec(wlc, ch20mhz_chspec(ch->hw_value));
buf : 		wlc->bandinit_pending = false;
buf : 		brcms_c_enable_mac(wlc);
buf : 	}
buf : 
buf : 	brcms_b_up_finish(wlc->hw);
buf : 
buf : 	/* Program the TX wme params with the current settings */
buf : 	brcms_c_wme_retries_write(wlc);
buf : 
buf : 	/* start one second watchdog timer */
buf : 	brcms_add_timer(wlc->wdtimer, TIMER_INTERVAL_WATCHDOG, true);
buf : 	wlc->WDarmed = true;
buf : 
buf : 	/* ensure antenna config is up to date */
buf : 	brcms_c_stf_phy_txant_upd(wlc);
buf : 	/* ensure LDPC config is in sync */
buf : 	brcms_c_ht_update_ldpc(wlc, wlc->stf->ldpc);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static uint brcms_c_down_del_timer(struct brcms_c_info *wlc)
buf : {
buf : 	uint callbacks = 0;
buf : 
buf : 	return callbacks;
buf : }
buf : 
buf : static int brcms_b_bmac_down_prep(struct brcms_hardware *wlc_hw)
buf : {
buf : 	bool dev_gone;
buf : 	uint callbacks = 0;
buf : 
buf : 	if (!wlc_hw->up)
if (!wlc_hw->up) 
buf : 		return callbacks;
buf : 
buf : 	dev_gone = brcms_deviceremoved(wlc_hw->wlc);
buf : 
buf : 	/* disable interrupts */
buf : 	if (dev_gone)
if (dev_gone) 
buf : 		wlc_hw->wlc->macintmask = 0;
buf : 	else {
buf : 		/* now disable interrupts */
buf : 		brcms_intrsoff(wlc_hw->wlc->wl);
buf : 
buf : 		/* ensure we're running on the pll clock again */
buf : 		brcms_b_clkctl_clk(wlc_hw, BCMA_CLKMODE_FAST);
buf : 	}
buf : 	/* down phy at the last of this stage */
buf : 	callbacks += wlc_phy_down(wlc_hw->band->pi);
buf : 
buf : 	return callbacks;
buf : }
buf : 
buf : static int brcms_b_down_finish(struct brcms_hardware *wlc_hw)
buf : {
buf : 	uint callbacks = 0;
buf : 	bool dev_gone;
buf : 
buf : 	if (!wlc_hw->up)
if (!wlc_hw->up) 
buf : 		return callbacks;
buf : 
buf : 	wlc_hw->up = false;
buf : 	wlc_phy_hw_state_upd(wlc_hw->band->pi, false);
buf : 
buf : 	dev_gone = brcms_deviceremoved(wlc_hw->wlc);
buf : 
buf : 	if (dev_gone) {
if (dev_gone) { 
buf : 		wlc_hw->sbclk = false;
buf : 		wlc_hw->clk = false;
buf : 		wlc_phy_hw_clk_state_upd(wlc_hw->band->pi, false);
buf : 
buf : 		/* reclaim any posted packets */
buf : 		brcms_c_flushqueues(wlc_hw->wlc);
buf : 	} else {
buf : 
buf : 		/* Reset and disable the core */
buf : 		if (bcma_core_is_enabled(wlc_hw->d11core)) {
if (bcma_core_is_enabled(wlc_hw->d11core)) { 
buf : 			if (bcma_read32(wlc_hw->d11core,
buf : 					D11REGOFFS(maccontrol)) & MCTL_EN_MAC)
buf : 				brcms_c_suspend_mac_and_wait(wlc_hw->wlc);
buf : 			callbacks += brcms_reset(wlc_hw->wlc->wl);
buf : 			brcms_c_coredisable(wlc_hw);
buf : 		}
buf : 
buf : 		/* turn off primary xtal and pll */
buf : 		if (!wlc_hw->noreset) {
if (!wlc_hw->noreset) { 
buf : 			bcma_core_pci_down(wlc_hw->d11core->bus);
buf : 			brcms_b_xtal(wlc_hw, OFF);
buf : 		}
buf : 	}
buf : 
buf : 	return callbacks;
buf : }
buf : 
buf : /*
buf :  * Mark the interface nonoperational, stop the software mechanisms,
buf :  * disable the hardware, free any transient buffer state.
buf :  * Return a count of the number of driver callbacks still pending.
buf :  */
buf : uint brcms_c_down(struct brcms_c_info *wlc)
buf : {
buf : 
buf : 	uint callbacks = 0;
buf : 	int i;
buf : 	bool dev_gone = false;
buf : 
buf : 	brcms_dbg_info(wlc->hw->d11core, "wl%d\n", wlc->pub->unit);
buf : 
buf : 	/* check if we are already in the going down path */
if we are already in the going down path */ 
buf : 	if (wlc->going_down) {
buf : 		brcms_err(wlc->hw->d11core,
buf : 			  "wl%d: %s: Driver going down so return\n",
buf : 			  wlc->pub->unit, __func__);
buf : 		return 0;
buf : 	}
buf : 	if (!wlc->pub->up)
if (!wlc->pub->up) 
buf : 		return callbacks;
buf : 
buf : 	wlc->going_down = true;
buf : 
buf : 	callbacks += brcms_b_bmac_down_prep(wlc->hw);
buf : 
buf : 	dev_gone = brcms_deviceremoved(wlc);
buf : 
buf : 	/* Call any registered down handlers */
buf : 	for (i = 0; i < BRCMS_MAXMODULES; i++) {
for (i = 0; i < BRCMS_MAXMODULES; i++) { 
buf : 		if (wlc->modulecb[i].down_fn)
buf : 			callbacks +=
buf : 			    wlc->modulecb[i].down_fn(wlc->modulecb[i].hdl);
buf : 	}
buf : 
buf : 	/* cancel the watchdog timer */
buf : 	if (wlc->WDarmed) {
if (wlc->WDarmed) { 
buf : 		if (!brcms_del_timer(wlc->wdtimer))
buf : 			callbacks++;
buf : 		wlc->WDarmed = false;
buf : 	}
buf : 	/* cancel all other timers */
buf : 	callbacks += brcms_c_down_del_timer(wlc);
buf : 
buf : 	wlc->pub->up = false;
buf : 
buf : 	wlc_phy_mute_upd(wlc->band->pi, false, PHY_MUTE_ALL);
buf : 
buf : 	callbacks += brcms_b_down_finish(wlc->hw);
buf : 
buf : 	/* brcms_b_down_finish has done brcms_c_coredisable(). so clk is off */
buf : 	wlc->clk = false;
buf : 
buf : 	wlc->going_down = false;
buf : 	return callbacks;
buf : }
buf : 
buf : /* Set the current gmode configuration */
buf : int brcms_c_set_gmode(struct brcms_c_info *wlc, u8 gmode, bool config)
buf : {
buf : 	int ret = 0;
buf : 	uint i;
buf : 	struct brcms_c_rateset rs;
buf : 	/* Default to 54g Auto */
buf : 	/* Advertise and use shortslot (-1/0/1 Auto/Off/On) */
buf : 	s8 shortslot = BRCMS_SHORTSLOT_AUTO;
buf : 	bool shortslot_restrict = false; /* Restrict association to stations
buf : 					  * that support shortslot
buf : 					  */
buf : 	bool ofdm_basic = false;	/* Make 6, 12, and 24 basic rates */
buf : 	/* Advertise and use short preambles (-1/0/1 Auto/Off/On) */
buf : 	int preamble = BRCMS_PLCP_LONG;
buf : 	bool preamble_restrict = false;	/* Restrict association to stations
buf : 					 * that support short preambles
buf : 					 */
buf : 	struct brcms_band *band;
buf : 
buf : 	/* if N-support is enabled, allow Gmode set as long as requested
if N-support is enabled, allow Gmode set as long as requested 
buf : 	 * Gmode is not GMODE_LEGACY_B
buf : 	 */
buf : 	if ((wlc->pub->_n_enab & SUPPORT_11N) && gmode == GMODE_LEGACY_B)
if ((wlc->pub->_n_enab & SUPPORT_11N) && gmode == GMODE_LEGACY_B) 
buf : 		return -ENOTSUPP;
buf : 
buf : 	/* verify that we are dealing with 2G band and grab the band pointer */
ify that we are dealing with 2G band and grab the band pointer */ 
buf : 	if (wlc->band->bandtype == BRCM_BAND_2G)
buf : 		band = wlc->band;
buf : 	else if ((wlc->pub->_nbands > 1) &&
if ((wlc->pub->_nbands > 1) && 
buf : 		 (wlc->bandstate[OTHERBANDUNIT(wlc)]->bandtype == BRCM_BAND_2G))
buf : 		band = wlc->bandstate[OTHERBANDUNIT(wlc)];
buf : 	else
buf : 		return -EINVAL;
buf : 
buf : 	/* update configuration value */
buf : 	if (config)
if (config) 
buf : 		brcms_c_protection_upd(wlc, BRCMS_PROT_G_USER, gmode);
buf : 
buf : 	/* Clear rateset override */
buf : 	memset(&rs, 0, sizeof(rs));
buf : 
buf : 	switch (gmode) {
buf : 	case GMODE_LEGACY_B:
buf : 		shortslot = BRCMS_SHORTSLOT_OFF;
buf : 		brcms_c_rateset_copy(&gphy_legacy_rates, &rs);
buf : 
buf : 		break;
buf : 
buf : 	case GMODE_LRS:
buf : 		break;
buf : 
buf : 	case GMODE_AUTO:
buf : 		/* Accept defaults */
buf : 		break;
buf : 
buf : 	case GMODE_ONLY:
buf : 		ofdm_basic = true;
buf : 		preamble = BRCMS_PLCP_SHORT;
buf : 		preamble_restrict = true;
buf : 		break;
buf : 
buf : 	case GMODE_PERFORMANCE:
buf : 		shortslot = BRCMS_SHORTSLOT_ON;
buf : 		shortslot_restrict = true;
buf : 		ofdm_basic = true;
buf : 		preamble = BRCMS_PLCP_SHORT;
buf : 		preamble_restrict = true;
buf : 		break;
buf : 
buf : 	default:
buf : 		/* Error */
buf : 		brcms_err(wlc->hw->d11core, "wl%d: %s: invalid gmode %d\n",
buf : 			  wlc->pub->unit, __func__, gmode);
buf : 		return -ENOTSUPP;
buf : 	}
buf : 
buf : 	band->gmode = gmode;
buf : 
buf : 	wlc->shortslot_override = shortslot;
buf : 
buf : 	/* Use the default 11g rateset */
buf : 	if (!rs.count)
if (!rs.count) 
buf : 		brcms_c_rateset_copy(&cck_ofdm_rates, &rs);
buf : 
buf : 	if (ofdm_basic) {
if (ofdm_basic) { 
buf : 		for (i = 0; i < rs.count; i++) {
for (i = 0; i < rs.count; i++) { 
buf : 			if (rs.rates[i] == BRCM_RATE_6M
buf : 			    || rs.rates[i] == BRCM_RATE_12M
buf : 			    || rs.rates[i] == BRCM_RATE_24M)
buf : 				rs.rates[i] |= BRCMS_RATE_FLAG;
buf : 		}
buf : 	}
buf : 
buf : 	/* Set default bss rateset */
buf : 	wlc->default_bss->rateset.count = rs.count;
buf : 	memcpy(wlc->default_bss->rateset.rates, rs.rates,
buf : 	       sizeof(wlc->default_bss->rateset.rates));
buf : 
buf : 	return ret;
buf : }
buf : 
buf : int brcms_c_set_nmode(struct brcms_c_info *wlc)
buf : {
buf : 	uint i;
buf : 	s32 nmode = AUTO;
buf : 
buf : 	if (wlc->stf->txstreams == WL_11N_3x3)
if (wlc->stf->txstreams == WL_11N_3x3) 
buf : 		nmode = WL_11N_3x3;
buf : 	else
buf : 		nmode = WL_11N_2x2;
buf : 
buf : 	/* force GMODE_AUTO if NMODE is ON */
if NMODE is ON */ 
buf : 	brcms_c_set_gmode(wlc, GMODE_AUTO, true);
buf : 	if (nmode == WL_11N_3x3)
if (nmode == WL_11N_3x3) 
buf : 		wlc->pub->_n_enab = SUPPORT_HT;
buf : 	else
buf : 		wlc->pub->_n_enab = SUPPORT_11N;
buf : 	wlc->default_bss->flags |= BRCMS_BSS_HT;
buf : 	/* add the mcs rates to the default and hw ratesets */
buf : 	brcms_c_rateset_mcs_build(&wlc->default_bss->rateset,
buf : 			      wlc->stf->txstreams);
buf : 	for (i = 0; i < wlc->pub->_nbands; i++)
for (i = 0; i < wlc->pub->_nbands; i++) 
buf : 		memcpy(wlc->bandstate[i]->hw_rateset.mcs,
buf : 		       wlc->default_bss->rateset.mcs, MCSSET_LEN);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int
buf : brcms_c_set_internal_rateset(struct brcms_c_info *wlc,
buf : 			     struct brcms_c_rateset *rs_arg)
buf : {
buf : 	struct brcms_c_rateset rs, new;
buf : 	uint bandunit;
buf : 
buf : 	memcpy(&rs, rs_arg, sizeof(struct brcms_c_rateset));
buf : 
buf : 	/* check for bad count value */
for bad count value */ 
buf : 	if ((rs.count == 0) || (rs.count > BRCMS_NUMRATES))
buf : 		return -EINVAL;
buf : 
buf : 	/* try the current band */
buf : 	bandunit = wlc->band->bandunit;
buf : 	memcpy(&new, &rs, sizeof(struct brcms_c_rateset));
buf : 	if (brcms_c_rate_hwrs_filter_sort_validate
if (brcms_c_rate_hwrs_filter_sort_validate 
buf : 	    (&new, &wlc->bandstate[bandunit]->hw_rateset, true,
buf : 	     wlc->stf->txstreams))
buf : 		goto good;
buf : 
buf : 	/* try the other band */
buf : 	if (brcms_is_mband_unlocked(wlc)) {
if (brcms_is_mband_unlocked(wlc)) { 
buf : 		bandunit = OTHERBANDUNIT(wlc);
buf : 		memcpy(&new, &rs, sizeof(struct brcms_c_rateset));
buf : 		if (brcms_c_rate_hwrs_filter_sort_validate(&new,
if (brcms_c_rate_hwrs_filter_sort_validate(&new, 
buf : 						       &wlc->
buf : 						       bandstate[bandunit]->
buf : 						       hw_rateset, true,
buf : 						       wlc->stf->txstreams))
buf : 			goto good;
buf : 	}
buf : 
buf : 	return -EBADE;
buf : 
buf :  good:
buf : 	/* apply new rateset */
buf : 	memcpy(&wlc->default_bss->rateset, &new,
buf : 	       sizeof(struct brcms_c_rateset));
buf : 	memcpy(&wlc->bandstate[bandunit]->defrateset, &new,
buf : 	       sizeof(struct brcms_c_rateset));
buf : 	return 0;
buf : }
buf : 
buf : static void brcms_c_ofdm_rateset_war(struct brcms_c_info *wlc)
buf : {
buf : 	u8 r;
buf : 	bool war = false;
buf : 
buf : 	if (wlc->pub->associated)
if (wlc->pub->associated) 
buf : 		r = wlc->bsscfg->current_bss->rateset.rates[0];
buf : 	else
buf : 		r = wlc->default_bss->rateset.rates[0];
buf : 
buf : 	wlc_phy_ofdm_rateset_war(wlc->band->pi, war);
buf : }
buf : 
buf : int brcms_c_set_channel(struct brcms_c_info *wlc, u16 channel)
buf : {
buf : 	u16 chspec = ch20mhz_chspec(channel);
buf : 
buf : 	if (channel < 0 || channel > MAXCHANNEL)
if (channel < 0 || channel > MAXCHANNEL) 
buf : 		return -EINVAL;
buf : 
buf : 	if (!brcms_c_valid_chanspec_db(wlc->cmi, chspec))
if (!brcms_c_valid_chanspec_db(wlc->cmi, chspec)) 
buf : 		return -EINVAL;
buf : 
buf : 
buf : 	if (!wlc->pub->up && brcms_is_mband_unlocked(wlc)) {
if (!wlc->pub->up && brcms_is_mband_unlocked(wlc)) { 
buf : 		if (wlc->band->bandunit != chspec_bandunit(chspec))
buf : 			wlc->bandinit_pending = true;
buf : 		else
buf : 			wlc->bandinit_pending = false;
buf : 	}
buf : 
buf : 	wlc->default_bss->chanspec = chspec;
buf : 	/* brcms_c_BSSinit() will sanitize the rateset before
fore 
buf : 	 * using it.. */
buf : 	if (wlc->pub->up && (wlc_phy_chanspec_get(wlc->band->pi) != chspec)) {
if (wlc->pub->up && (wlc_phy_chanspec_get(wlc->band->pi) != chspec)) { 
buf : 		brcms_c_set_home_chanspec(wlc, chspec);
buf : 		brcms_c_suspend_mac_and_wait(wlc);
buf : 		brcms_c_set_chanspec(wlc, chspec);
buf : 		brcms_c_enable_mac(wlc);
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : int brcms_c_set_rate_limit(struct brcms_c_info *wlc, u16 srl, u16 lrl)
buf : {
buf : 	int ac;
buf : 
buf : 	if (srl < 1 || srl > RETRY_SHORT_MAX ||
if (srl < 1 || srl > RETRY_SHORT_MAX || 
buf : 	    lrl < 1 || lrl > RETRY_SHORT_MAX)
buf : 		return -EINVAL;
buf : 
buf : 	wlc->SRL = srl;
buf : 	wlc->LRL = lrl;
buf : 
buf : 	brcms_b_retrylimit_upd(wlc->hw, wlc->SRL, wlc->LRL);
buf : 
buf : 	for (ac = 0; ac < IEEE80211_NUM_ACS; ac++) {
for (ac = 0; ac < IEEE80211_NUM_ACS; ac++) { 
buf : 		wlc->wme_retries[ac] =	SFIELD(wlc->wme_retries[ac],
buf : 					       EDCF_SHORT,  wlc->SRL);
buf : 		wlc->wme_retries[ac] =	SFIELD(wlc->wme_retries[ac],
buf : 					       EDCF_LONG, wlc->LRL);
buf : 	}
buf : 	brcms_c_wme_retries_write(wlc);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : void brcms_c_get_current_rateset(struct brcms_c_info *wlc,
buf : 				 struct brcm_rateset *currs)
buf : {
buf : 	struct brcms_c_rateset *rs;
buf : 
buf : 	if (wlc->pub->associated)
if (wlc->pub->associated) 
buf : 		rs = &wlc->bsscfg->current_bss->rateset;
buf : 	else
buf : 		rs = &wlc->default_bss->rateset;
buf : 
buf : 	/* Copy only legacy rateset section */
buf : 	currs->count = rs->count;
buf : 	memcpy(&currs->rates, &rs->rates, rs->count);
buf : }
buf : 
buf : int brcms_c_set_rateset(struct brcms_c_info *wlc, struct brcm_rateset *rs)
buf : {
buf : 	struct brcms_c_rateset internal_rs;
buf : 	int bcmerror;
buf : 
buf : 	if (rs->count > BRCMS_NUMRATES)
if (rs->count > BRCMS_NUMRATES) 
buf : 		return -ENOBUFS;
buf : 
buf : 	memset(&internal_rs, 0, sizeof(internal_rs));
buf : 
buf : 	/* Copy only legacy rateset section */
buf : 	internal_rs.count = rs->count;
buf : 	memcpy(&internal_rs.rates, &rs->rates, internal_rs.count);
buf : 
buf : 	/* merge rateset coming in with the current mcsset */
buf : 	if (wlc->pub->_n_enab & SUPPORT_11N) {
if (wlc->pub->_n_enab & SUPPORT_11N) { 
buf : 		struct brcms_bss_info *mcsset_bss;
buf : 		if (wlc->pub->associated)
if (wlc->pub->associated) 
buf : 			mcsset_bss = wlc->bsscfg->current_bss;
buf : 		else
buf : 			mcsset_bss = wlc->default_bss;
buf : 		memcpy(internal_rs.mcs, &mcsset_bss->rateset.mcs[0],
buf : 		       MCSSET_LEN);
buf : 	}
buf : 
buf : 	bcmerror = brcms_c_set_internal_rateset(wlc, &internal_rs);
buf : 	if (!bcmerror)
if (!bcmerror) 
buf : 		brcms_c_ofdm_rateset_war(wlc);
buf : 
buf : 	return bcmerror;
buf : }
buf : 
buf : static void brcms_c_time_lock(struct brcms_c_info *wlc)
buf : {
buf : 	bcma_set32(wlc->hw->d11core, D11REGOFFS(maccontrol), MCTL_TBTTHOLD);
buf : 	/* Commit the write */
buf : 	bcma_read32(wlc->hw->d11core, D11REGOFFS(maccontrol));
buf : }
buf : 
buf : static void brcms_c_time_unlock(struct brcms_c_info *wlc)
buf : {
buf : 	bcma_mask32(wlc->hw->d11core, D11REGOFFS(maccontrol), ~MCTL_TBTTHOLD);
buf : 	/* Commit the write */
buf : 	bcma_read32(wlc->hw->d11core, D11REGOFFS(maccontrol));
buf : }
buf : 
buf : int brcms_c_set_beacon_period(struct brcms_c_info *wlc, u16 period)
buf : {
buf : 	u32 bcnint_us;
buf : 
buf : 	if (period == 0)
if (period == 0) 
buf : 		return -EINVAL;
buf : 
buf : 	wlc->default_bss->beacon_period = period;
buf : 
buf : 	bcnint_us = period << 10;
buf : 	brcms_c_time_lock(wlc);
buf : 	bcma_write32(wlc->hw->d11core, D11REGOFFS(tsf_cfprep),
buf : 		     (bcnint_us << CFPREP_CBI_SHIFT));
buf : 	bcma_write32(wlc->hw->d11core, D11REGOFFS(tsf_cfpstart), bcnint_us);
buf : 	brcms_c_time_unlock(wlc);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : u16 brcms_c_get_phy_type(struct brcms_c_info *wlc, int phyidx)
buf : {
buf : 	return wlc->band->phytype;
buf : }
buf : 
buf : void brcms_c_set_shortslot_override(struct brcms_c_info *wlc, s8 sslot_override)
buf : {
buf : 	wlc->shortslot_override = sslot_override;
buf : 
buf : 	/*
buf : 	 * shortslot is an 11g feature, so no more work if we are
if we are 
buf : 	 * currently on the 5G band
buf : 	 */
buf : 	if (wlc->band->bandtype == BRCM_BAND_5G)
if (wlc->band->bandtype == BRCM_BAND_5G) 
buf : 		return;
buf : 
buf : 	if (wlc->pub->up && wlc->pub->associated) {
if (wlc->pub->up && wlc->pub->associated) { 
buf : 		/* let watchdog or beacon processing update shortslot */
buf : 	} else if (wlc->pub->up) {
if (wlc->pub->up) { 
buf : 		/* unassociated shortslot is off */
buf : 		brcms_c_switch_shortslot(wlc, false);
buf : 	} else {
buf : 		/* driver is down, so just update the brcms_c_info
buf : 		 * value */
buf : 		if (wlc->shortslot_override == BRCMS_SHORTSLOT_AUTO)
if (wlc->shortslot_override == BRCMS_SHORTSLOT_AUTO) 
buf : 			wlc->shortslot = false;
buf : 		else
buf : 			wlc->shortslot =
buf : 			    (wlc->shortslot_override ==
buf : 			     BRCMS_SHORTSLOT_ON);
buf : 	}
buf : }
buf : 
buf : /*
buf :  * register watchdog and down handlers.
buf :  */
buf : int brcms_c_module_register(struct brcms_pub *pub,
buf : 			    const char *name, struct brcms_info *hdl,
buf : 			    int (*d_fn)(void *handle))
buf : {
buf : 	struct brcms_c_info *wlc = (struct brcms_c_info *) pub->wlc;
buf : 	int i;
buf : 
buf : 	/* find an empty entry and just add, no duplication check! */
buf : 	for (i = 0; i < BRCMS_MAXMODULES; i++) {
for (i = 0; i < BRCMS_MAXMODULES; i++) { 
buf : 		if (wlc->modulecb[i].name[0] == '\0') {
buf : 			strncpy(wlc->modulecb[i].name, name,
buf : 				sizeof(wlc->modulecb[i].name) - 1);
buf : 			wlc->modulecb[i].hdl = hdl;
buf : 			wlc->modulecb[i].down_fn = d_fn;
buf : 			return 0;
buf : 		}
buf : 	}
buf : 
buf : 	return -ENOSR;
buf : }
buf : 
buf : /* unregister module callbacks */
buf : int brcms_c_module_unregister(struct brcms_pub *pub, const char *name,
buf : 			      struct brcms_info *hdl)
buf : {
buf : 	struct brcms_c_info *wlc = (struct brcms_c_info *) pub->wlc;
buf : 	int i;
buf : 
buf : 	if (wlc == NULL)
if (wlc == NULL) 
buf : 		return -ENODATA;
buf : 
buf : 	for (i = 0; i < BRCMS_MAXMODULES; i++) {
for (i = 0; i < BRCMS_MAXMODULES; i++) { 
buf : 		if (!strcmp(wlc->modulecb[i].name, name) &&
buf : 		    (wlc->modulecb[i].hdl == hdl)) {
buf : 			memset(&wlc->modulecb[i], 0, sizeof(wlc->modulecb[i]));
buf : 			return 0;
buf : 		}
buf : 	}
buf : 
buf : 	/* table not found! */
buf : 	return -ENODATA;
buf : }
buf : 
buf : static bool brcms_c_chipmatch_pci(struct bcma_device *core)
buf : {
buf : 	struct pci_dev *pcidev = core->bus->host_pci;
buf : 	u16 vendor = pcidev->vendor;
buf : 	u16 device = pcidev->device;
buf : 
buf : 	if (vendor != PCI_VENDOR_ID_BROADCOM) {
if (vendor != PCI_VENDOR_ID_BROADCOM) { 
buf : 		pr_err("unknown vendor id %04x\n", vendor);
buf : 		return false;
buf : 	}
buf : 
buf : 	if (device == BCM43224_D11N_ID_VEN1 || device == BCM43224_CHIP_ID)
if (device == BCM43224_D11N_ID_VEN1 || device == BCM43224_CHIP_ID) 
buf : 		return true;
buf : 	if ((device == BCM43224_D11N_ID) || (device == BCM43225_D11N2G_ID))
if ((device == BCM43224_D11N_ID) || (device == BCM43225_D11N2G_ID)) 
buf : 		return true;
buf : 	if (device == BCM4313_D11N2G_ID || device == BCM4313_CHIP_ID)
if (device == BCM4313_D11N2G_ID || device == BCM4313_CHIP_ID) 
buf : 		return true;
buf : 	if ((device == BCM43236_D11N_ID) || (device == BCM43236_D11N2G_ID))
if ((device == BCM43236_D11N_ID) || (device == BCM43236_D11N2G_ID)) 
buf : 		return true;
buf : 
buf : 	pr_err("unknown device id %04x\n", device);
buf : 	return false;
buf : }
buf : 
buf : static bool brcms_c_chipmatch_soc(struct bcma_device *core)
buf : {
buf : 	struct bcma_chipinfo *chipinfo = &core->bus->chipinfo;
buf : 
buf : 	if (chipinfo->id == BCMA_CHIP_ID_BCM4716)
if (chipinfo->id == BCMA_CHIP_ID_BCM4716) 
buf : 		return true;
buf : 
buf : 	pr_err("unknown chip id %04x\n", chipinfo->id);
buf : 	return false;
buf : }
buf : 
buf : bool brcms_c_chipmatch(struct bcma_device *core)
buf : {
buf : 	switch (core->bus->hosttype) {
buf : 	case BCMA_HOSTTYPE_PCI:
buf : 		return brcms_c_chipmatch_pci(core);
buf : 	case BCMA_HOSTTYPE_SOC:
buf : 		return brcms_c_chipmatch_soc(core);
buf : 	default:
buf : 		pr_err("unknown host type: %i\n", core->bus->hosttype);
buf : 		return false;
buf : 	}
buf : }
buf : 
buf : u16 brcms_b_rate_shm_offset(struct brcms_hardware *wlc_hw, u8 rate)
buf : {
buf : 	u16 table_ptr;
buf : 	u8 phy_rate, index;
buf : 
buf : 	/* get the phy specific rate encoding for the PLCP SIGNAL field */
ific rate encoding for the PLCP SIGNAL field */ 
buf : 	if (is_ofdm_rate(rate))
buf : 		table_ptr = M_RT_DIRMAP_A;
buf : 	else
buf : 		table_ptr = M_RT_DIRMAP_B;
buf : 
buf : 	/* for a given rate, the LS-nibble of the PLCP SIGNAL field is
for a given rate, the LS-nibble of the PLCP SIGNAL field is 
buf : 	 * the index into the rate table.
buf : 	 */
buf : 	phy_rate = rate_info[rate] & BRCMS_RATE_MASK;
buf : 	index = phy_rate & 0xf;
buf : 
buf : 	/* Find the SHM pointer to the rate table entry by looking in the
buf : 	 * Direct-map Table
buf : 	 */
buf : 	return 2 * brcms_b_read_shm(wlc_hw, table_ptr + (index * 2));
buf : }
buf : 
buf : /*
buf :  * bcmc_fid_generate:
buf :  * Generate frame ID for a BCMC packet.  The frag field is not used
for a BCMC packet.  The frag field is not used 
buf :  * for MC frames so is used as part of the sequence number.
buf :  */
buf : static inline u16
buf : bcmc_fid_generate(struct brcms_c_info *wlc, struct brcms_bss_cfg *bsscfg,
buf : 		  struct d11txh *txh)
buf : {
buf : 	u16 frameid;
buf : 
buf : 	frameid = le16_to_cpu(txh->TxFrameID) & ~(TXFID_SEQ_MASK |
buf : 						  TXFID_QUEUE_MASK);
buf : 	frameid |=
buf : 	    (((wlc->
buf : 	       mc_fid_counter++) << TXFID_SEQ_SHIFT) & TXFID_SEQ_MASK) |
buf : 	    TX_BCMC_FIFO;
buf : 
buf : 	return frameid;
buf : }
buf : 
buf : static uint
buf : brcms_c_calc_ack_time(struct brcms_c_info *wlc, u32 rspec,
buf : 		      u8 preamble_type)
buf : {
buf : 	uint dur = 0;
buf : 
buf : 	/*
buf : 	 * Spec 9.6: ack rate is the highest rate in BSSBasicRateSet that
buf : 	 * is less than or equal to the rate of the immediately previous
buf : 	 * frame in the FES
buf : 	 */
buf : 	rspec = brcms_basic_rate(wlc, rspec);
buf : 	/* ACK frame len == 14 == 2(fc) + 2(dur) + 6(ra) + 4(fcs) */
buf : 	dur =
buf : 	    brcms_c_calc_frame_time(wlc, rspec, preamble_type,
buf : 				(DOT11_ACK_LEN + FCS_LEN));
buf : 	return dur;
buf : }
buf : 
buf : static uint
buf : brcms_c_calc_cts_time(struct brcms_c_info *wlc, u32 rspec,
buf : 		      u8 preamble_type)
buf : {
buf : 	return brcms_c_calc_ack_time(wlc, rspec, preamble_type);
buf : }
buf : 
buf : static uint
buf : brcms_c_calc_ba_time(struct brcms_c_info *wlc, u32 rspec,
buf : 		     u8 preamble_type)
buf : {
buf : 	/*
buf : 	 * Spec 9.6: ack rate is the highest rate in BSSBasicRateSet that
buf : 	 * is less than or equal to the rate of the immediately previous
buf : 	 * frame in the FES
buf : 	 */
buf : 	rspec = brcms_basic_rate(wlc, rspec);
buf : 	/* BA len == 32 == 16(ctl hdr) + 4(ba len) + 8(bitmap) + 4(fcs) */
buf : 	return brcms_c_calc_frame_time(wlc, rspec, preamble_type,
buf : 				   (DOT11_BA_LEN + DOT11_BA_BITMAP_LEN +
buf : 				    FCS_LEN));
buf : }
buf : 
buf : /* brcms_c_compute_frame_dur()
buf :  *
buf :  * Calculate the 802.11 MAC header DUR field for MPDU
for MPDU 
buf :  * DUR for a single frame = 1 SIFS + 1 ACK
buf :  * DUR for a frame with following frags = 3 SIFS + 2 ACK + next frag time
for a frame with following frags = 3 SIFS + 2 ACK + next frag time 
buf :  *
buf :  * rate			MPDU rate in unit of 500kbps
buf :  * next_frag_len	next MPDU length in bytes
buf :  * preamble_type	use short/GF or long/MM PLCP header
buf :  */
buf : static u16
buf : brcms_c_compute_frame_dur(struct brcms_c_info *wlc, u32 rate,
buf : 		      u8 preamble_type, uint next_frag_len)
buf : {
buf : 	u16 dur, sifs;
ifs; 
buf : 
buf : 	sifs = get_sifs(wlc->band);
buf : 
buf : 	dur = sifs;
ifs; 
buf : 	dur += (u16) brcms_c_calc_ack_time(wlc, rate, preamble_type);
buf : 
buf : 	if (next_frag_len) {
if (next_frag_len) { 
buf : 		/* Double the current DUR to get 2 SIFS + 2 ACKs */
buf : 		dur *= 2;
buf : 		/* add another SIFS and the frag time */
buf : 		dur += sifs;
ifs; 
buf : 		dur +=
buf : 		    (u16) brcms_c_calc_frame_time(wlc, rate, preamble_type,
buf : 						 next_frag_len);
buf : 	}
buf : 	return dur;
buf : }
buf : 
buf : /* The opposite of brcms_c_calc_frame_time */
buf : static uint
buf : brcms_c_calc_frame_len(struct brcms_c_info *wlc, u32 ratespec,
buf : 		   u8 preamble_type, uint dur)
buf : {
buf : 	uint nsyms, mac_len, Ndps, kNdps;
buf : 	uint rate = rspec2rate(ratespec);
buf : 
buf : 	if (is_mcs_rate(ratespec)) {
if (is_mcs_rate(ratespec)) { 
buf : 		uint mcs = ratespec & RSPEC_RATE_MASK;
buf : 		int tot_streams = mcs_2_txstreams(mcs) + rspec_stc(ratespec);
buf : 		dur -= PREN_PREAMBLE + (tot_streams * PREN_PREAMBLE_EXT);
buf : 		/* payload calculation matches that of regular ofdm */
buf : 		if (wlc->band->bandtype == BRCM_BAND_2G)
if (wlc->band->bandtype == BRCM_BAND_2G) 
buf : 			dur -= DOT11_OFDM_SIGNAL_EXTENSION;
buf : 		/* kNdbps = kbps * 4 */
buf : 		kNdps =	mcs_2_rate(mcs, rspec_is40mhz(ratespec),
buf : 				   rspec_issgi(ratespec)) * 4;
buf : 		nsyms = dur / APHY_SYMBOL_TIME;
buf : 		mac_len =
buf : 		    ((nsyms * kNdps) -
buf : 		     ((APHY_SERVICE_NBITS + APHY_TAIL_NBITS) * 1000)) / 8000;
buf : 	} else if (is_ofdm_rate(ratespec)) {
if (is_ofdm_rate(ratespec)) { 
buf : 		dur -= APHY_PREAMBLE_TIME;
buf : 		dur -= APHY_SIGNAL_TIME;
buf : 		/* Ndbps = Mbps * 4 = rate(500Kbps) * 2 */
buf : 		Ndps = rate * 2;
buf : 		nsyms = dur / APHY_SYMBOL_TIME;
buf : 		mac_len =
buf : 		    ((nsyms * Ndps) -
buf : 		     (APHY_SERVICE_NBITS + APHY_TAIL_NBITS)) / 8;
buf : 	} else {
buf : 		if (preamble_type & BRCMS_SHORT_PREAMBLE)
if (preamble_type & BRCMS_SHORT_PREAMBLE) 
buf : 			dur -= BPHY_PLCP_SHORT_TIME;
buf : 		else
buf : 			dur -= BPHY_PLCP_TIME;
buf : 		mac_len = dur * rate;
buf : 		/* divide out factor of 2 in rate (1/2 mbps) */
buf : 		mac_len = mac_len / 8 / 2;
buf : 	}
buf : 	return mac_len;
buf : }
buf : 
buf : /*
buf :  * Return true if the specified rate is supported by the specified band.
if the specified rate is supported by the specified band. 
buf :  * BRCM_BAND_AUTO indicates the current band.
buf :  */
buf : static bool brcms_c_valid_rate(struct brcms_c_info *wlc, u32 rspec, int band,
buf : 		    bool verbose)
buf : {
buf : 	struct brcms_c_rateset *hw_rateset;
buf : 	uint i;
buf : 
buf : 	if ((band == BRCM_BAND_AUTO) || (band == wlc->band->bandtype))
if ((band == BRCM_BAND_AUTO) || (band == wlc->band->bandtype)) 
buf : 		hw_rateset = &wlc->band->hw_rateset;
buf : 	else if (wlc->pub->_nbands > 1)
if (wlc->pub->_nbands > 1) 
buf : 		hw_rateset = &wlc->bandstate[OTHERBANDUNIT(wlc)]->hw_rateset;
buf : 	else
buf : 		/* other band specified and we are a single band device */
ified and we are a single band device */ 
buf : 		return false;
buf : 
buf : 	/* check if this is a mimo rate */
if this is a mimo rate */ 
buf : 	if (is_mcs_rate(rspec)) {
buf : 		if ((rspec & RSPEC_RATE_MASK) >= MCS_TABLE_SIZE)
if ((rspec & RSPEC_RATE_MASK) >= MCS_TABLE_SIZE) 
buf : 			goto error;
buf : 
buf : 		return isset(hw_rateset->mcs, (rspec & RSPEC_RATE_MASK));
buf : 	}
buf : 
buf : 	for (i = 0; i < hw_rateset->count; i++)
for (i = 0; i < hw_rateset->count; i++) 
buf : 		if (hw_rateset->rates[i] == rspec2rate(rspec))
buf : 			return true;
buf :  error:
buf : 	if (verbose)
if (verbose) 
buf : 		brcms_err(wlc->hw->d11core, "wl%d: valid_rate: rate spec 0x%x "
buf : 			  "not in hw_rateset\n", wlc->pub->unit, rspec);
buf : 
buf : 	return false;
buf : }
buf : 
buf : static u32
buf : mac80211_wlc_set_nrate(struct brcms_c_info *wlc, struct brcms_band *cur_band,
buf : 		       u32 int_val)
buf : {
buf : 	struct bcma_device *core = wlc->hw->d11core;
buf : 	u8 stf = (int_val & NRATE_STF_MASK) >> NRATE_STF_SHIFT;
buf : 	u8 rate = int_val & NRATE_RATE_MASK;
buf : 	u32 rspec;
buf : 	bool ismcs = ((int_val & NRATE_MCS_INUSE) == NRATE_MCS_INUSE);
buf : 	bool issgi = ((int_val & NRATE_SGI_MASK) >> NRATE_SGI_SHIFT);
buf : 	bool override_mcs_only = ((int_val & NRATE_OVERRIDE_MCS_ONLY)
buf : 				  == NRATE_OVERRIDE_MCS_ONLY);
buf : 	int bcmerror = 0;
buf : 
buf : 	if (!ismcs)
if (!ismcs) 
buf : 		return (u32) rate;
buf : 
buf : 	/* validate the combination of rate/mcs/stf is allowed */
buf : 	if ((wlc->pub->_n_enab & SUPPORT_11N) && ismcs) {
if ((wlc->pub->_n_enab & SUPPORT_11N) && ismcs) { 
buf : 		/* mcs only allowed when nmode */
buf : 		if (stf > PHY_TXC1_MODE_SDM) {
if (stf > PHY_TXC1_MODE_SDM) { 
buf : 			brcms_err(core, "wl%d: %s: Invalid stf\n",
buf : 				  wlc->pub->unit, __func__);
buf : 			bcmerror = -EINVAL;
buf : 			goto done;
buf : 		}
buf : 
buf : 		/* mcs 32 is a special case, DUP mode 40 only */
buf : 		if (rate == 32) {
if (rate == 32) { 
buf : 			if (!CHSPEC_IS40(wlc->home_chanspec) ||
buf : 			    ((stf != PHY_TXC1_MODE_SISO)
buf : 			     && (stf != PHY_TXC1_MODE_CDD))) {
buf : 				brcms_err(core, "wl%d: %s: Invalid mcs 32\n",
buf : 					  wlc->pub->unit, __func__);
buf : 				bcmerror = -EINVAL;
buf : 				goto done;
buf : 			}
buf : 			/* mcs > 7 must use stf SDM */
buf : 		} else if (rate > HIGHEST_SINGLE_STREAM_MCS) {
if (rate > HIGHEST_SINGLE_STREAM_MCS) { 
buf : 			/* mcs > 7 must use stf SDM */
buf : 			if (stf != PHY_TXC1_MODE_SDM) {
if (stf != PHY_TXC1_MODE_SDM) { 
buf : 				brcms_dbg_mac80211(core, "wl%d: enabling "
buf : 						   "SDM mode for mcs %d\n",
for mcs %d\n", 
buf : 						   wlc->pub->unit, rate);
buf : 				stf = PHY_TXC1_MODE_SDM;
buf : 			}
buf : 		} else {
buf : 			/*
buf : 			 * MCS 0-7 may use SISO, CDD, and for
for 
buf : 			 * phy_rev >= 3 STBC
buf : 			 */
buf : 			if ((stf > PHY_TXC1_MODE_STBC) ||
if ((stf > PHY_TXC1_MODE_STBC) || 
buf : 			    (!BRCMS_STBC_CAP_PHY(wlc)
buf : 			     && (stf == PHY_TXC1_MODE_STBC))) {
buf : 				brcms_err(core, "wl%d: %s: Invalid STBC\n",
buf : 					  wlc->pub->unit, __func__);
buf : 				bcmerror = -EINVAL;
buf : 				goto done;
buf : 			}
buf : 		}
buf : 	} else if (is_ofdm_rate(rate)) {
if (is_ofdm_rate(rate)) { 
buf : 		if ((stf != PHY_TXC1_MODE_CDD) && (stf != PHY_TXC1_MODE_SISO)) {
buf : 			brcms_err(core, "wl%d: %s: Invalid OFDM\n",
buf : 				  wlc->pub->unit, __func__);
buf : 			bcmerror = -EINVAL;
buf : 			goto done;
buf : 		}
buf : 	} else if (is_cck_rate(rate)) {
if (is_cck_rate(rate)) { 
buf : 		if ((cur_band->bandtype != BRCM_BAND_2G)
buf : 		    || (stf != PHY_TXC1_MODE_SISO)) {
buf : 			brcms_err(core, "wl%d: %s: Invalid CCK\n",
buf : 				  wlc->pub->unit, __func__);
buf : 			bcmerror = -EINVAL;
buf : 			goto done;
buf : 		}
buf : 	} else {
buf : 		brcms_err(core, "wl%d: %s: Unknown rate type\n",
buf : 			  wlc->pub->unit, __func__);
buf : 		bcmerror = -EINVAL;
buf : 		goto done;
buf : 	}
buf : 	/* make sure multiple antennae are available for non-siso rates */
for non-siso rates */ 
buf : 	if ((stf != PHY_TXC1_MODE_SISO) && (wlc->stf->txstreams == 1)) {
buf : 		brcms_err(core, "wl%d: %s: SISO antenna but !SISO "
buf : 			  "request\n", wlc->pub->unit, __func__);
buf : 		bcmerror = -EINVAL;
buf : 		goto done;
buf : 	}
buf : 
buf : 	rspec = rate;
buf : 	if (ismcs) {
if (ismcs) { 
buf : 		rspec |= RSPEC_MIMORATE;
buf : 		/* For STBC populate the STC field of the ratespec */
buf : 		if (stf == PHY_TXC1_MODE_STBC) {
if (stf == PHY_TXC1_MODE_STBC) { 
buf : 			u8 stc;
buf : 			stc = 1;	/* Nss for single stream is always 1 */
for single stream is always 1 */ 
buf : 			rspec |= (stc << RSPEC_STC_SHIFT);
buf : 		}
buf : 	}
buf : 
buf : 	rspec |= (stf << RSPEC_STF_SHIFT);
buf : 
buf : 	if (override_mcs_only)
if (override_mcs_only) 
buf : 		rspec |= RSPEC_OVERRIDE_MCS_ONLY;
buf : 
buf : 	if (issgi)
if (issgi) 
buf : 		rspec |= RSPEC_SHORT_GI;
buf : 
buf : 	if ((rate != 0)
if ((rate != 0) 
buf : 	    && !brcms_c_valid_rate(wlc, rspec, cur_band->bandtype, true))
buf : 		return rate;
buf : 
buf : 	return rspec;
buf : done:
buf : 	return rate;
buf : }
buf : 
buf : /*
buf :  * Compute PLCP, but only requires actual rate and length of pkt.
buf :  * Rate is given in the driver standard multiple of 500 kbps.
buf :  * le is set for 11 Mbps rate if necessary.
if necessary. 
buf :  * Broken out for PRQ.
for PRQ. 
buf :  */
buf : 
buf : static void brcms_c_cck_plcp_set(struct brcms_c_info *wlc, int rate_500,
buf : 			     uint length, u8 *plcp)
buf : {
buf : 	u16 usec = 0;
buf : 	u8 le = 0;
buf : 
buf : 	switch (rate_500) {
buf : 	case BRCM_RATE_1M:
buf : 		usec = length << 3;
buf : 		break;
buf : 	case BRCM_RATE_2M:
buf : 		usec = length << 2;
buf : 		break;
buf : 	case BRCM_RATE_5M5:
buf : 		usec = (length << 4) / 11;
buf : 		if ((length << 4) - (usec * 11) > 0)
if ((length << 4) - (usec * 11) > 0) 
buf : 			usec++;
buf : 		break;
buf : 	case BRCM_RATE_11M:
buf : 		usec = (length << 3) / 11;
buf : 		if ((length << 3) - (usec * 11) > 0) {
if ((length << 3) - (usec * 11) > 0) { 
buf : 			usec++;
buf : 			if ((usec * 11) - (length << 3) >= 8)
if ((usec * 11) - (length << 3) >= 8) 
buf : 				le = D11B_PLCP_SIGNAL_LE;
buf : 		}
buf : 		break;
buf : 
buf : 	default:
buf : 		brcms_err(wlc->hw->d11core,
buf : 			  "brcms_c_cck_plcp_set: unsupported rate %d\n",
buf : 			  rate_500);
buf : 		rate_500 = BRCM_RATE_1M;
buf : 		usec = length << 3;
buf : 		break;
buf : 	}
buf : 	/* PLCP signal byte */
buf : 	plcp[0] = rate_500 * 5;	/* r (500kbps) * 5 == r (100kbps) */
buf : 	/* PLCP service byte */
buf : 	plcp[1] = (u8) (le | D11B_PLCP_SIGNAL_LOCKED);
buf : 	/* PLCP length u16, little endian */
buf : 	plcp[2] = usec & 0xff;
buf : 	plcp[3] = (usec >> 8) & 0xff;
buf : 	/* PLCP CRC16 */
buf : 	plcp[4] = 0;
buf : 	plcp[5] = 0;
buf : }
buf : 
buf : /* Rate: 802.11 rate code, length: PSDU length in octets */
buf : static void brcms_c_compute_mimo_plcp(u32 rspec, uint length, u8 *plcp)
buf : {
buf : 	u8 mcs = (u8) (rspec & RSPEC_RATE_MASK);
buf : 	plcp[0] = mcs;
buf : 	if (rspec_is40mhz(rspec) || (mcs == 32))
if (rspec_is40mhz(rspec) || (mcs == 32)) 
buf : 		plcp[0] |= MIMO_PLCP_40MHZ;
buf : 	BRCMS_SET_MIMO_PLCP_LEN(plcp, length);
buf : 	plcp[3] = rspec_mimoplcp3(rspec); /* rspec already holds this byte */
buf : 	plcp[3] |= 0x7; /* set smoothing, not sounding ppdu & reserved */
buf : 	plcp[4] = 0; /* number of extension spatial streams bit 0 & 1 */
buf : 	plcp[5] = 0;
buf : }
buf : 
buf : /* Rate: 802.11 rate code, length: PSDU length in octets */
buf : static void
buf : brcms_c_compute_ofdm_plcp(u32 rspec, u32 length, u8 *plcp)
buf : {
buf : 	u8 rate_signal;
buf : 	u32 tmp = 0;
buf : 	int rate = rspec2rate(rspec);
buf : 
buf : 	/*
buf : 	 * encode rate per 802.11a-1999 sec 17.3.4.1, with lsb
buf : 	 * transmitted first
buf : 	 */
buf : 	rate_signal = rate_info[rate] & BRCMS_RATE_MASK;
buf : 	memset(plcp, 0, D11_PHY_HDR_LEN);
buf : 	D11A_PHY_HDR_SRATE((struct ofdm_phy_hdr *) plcp, rate_signal);
buf : 
buf : 	tmp = (length & 0xfff) << 5;
buf : 	plcp[2] |= (tmp >> 16) & 0xff;
buf : 	plcp[1] |= (tmp >> 8) & 0xff;
buf : 	plcp[0] |= tmp & 0xff;
buf : }
buf : 
buf : /* Rate: 802.11 rate code, length: PSDU length in octets */
buf : static void brcms_c_compute_cck_plcp(struct brcms_c_info *wlc, u32 rspec,
buf : 				 uint length, u8 *plcp)
buf : {
buf : 	int rate = rspec2rate(rspec);
buf : 
buf : 	brcms_c_cck_plcp_set(wlc, rate, length, plcp);
buf : }
buf : 
buf : static void
buf : brcms_c_compute_plcp(struct brcms_c_info *wlc, u32 rspec,
buf : 		     uint length, u8 *plcp)
buf : {
buf : 	if (is_mcs_rate(rspec))
if (is_mcs_rate(rspec)) 
buf : 		brcms_c_compute_mimo_plcp(rspec, length, plcp);
buf : 	else if (is_ofdm_rate(rspec))
if (is_ofdm_rate(rspec)) 
buf : 		brcms_c_compute_ofdm_plcp(rspec, length, plcp);
buf : 	else
buf : 		brcms_c_compute_cck_plcp(wlc, rspec, length, plcp);
buf : }
buf : 
buf : /* brcms_c_compute_rtscts_dur()
buf :  *
buf :  * Calculate the 802.11 MAC header DUR field for an RTS or CTS frame
for an RTS or CTS frame 
buf :  * DUR for normal RTS/CTS w/ frame = 3 SIFS + 1 CTS + next frame time + 1 ACK
buf :  * DUR for CTS-TO-SELF w/ frame    = 2 SIFS         + next frame time + 1 ACK
for CTS-TO-SELF w/ frame    = 2 SIFS         + next frame time + 1 ACK 
buf :  *
buf :  * cts			cts-to-self or rts/cts
buf :  * rts_rate		rts or cts rate in unit of 500kbps
buf :  * rate			next MPDU rate in unit of 500kbps
buf :  * frame_len		next MPDU frame length in bytes
buf :  */
buf : u16
buf : brcms_c_compute_rtscts_dur(struct brcms_c_info *wlc, bool cts_only,
buf : 			   u32 rts_rate,
buf : 			   u32 frame_rate, u8 rts_preamble_type,
buf : 			   u8 frame_preamble_type, uint frame_len, bool ba)
buf : {
buf : 	u16 dur, sifs;
ifs; 
buf : 
buf : 	sifs = get_sifs(wlc->band);
buf : 
buf : 	if (!cts_only) {
if (!cts_only) { 
buf : 		/* RTS/CTS */
buf : 		dur = 3 * sifs;
ifs; 
buf : 		dur +=
buf : 		    (u16) brcms_c_calc_cts_time(wlc, rts_rate,
buf : 					       rts_preamble_type);
buf : 	} else {
buf : 		/* CTS-TO-SELF */
buf : 		dur = 2 * sifs;
ifs; 
buf : 	}
buf : 
buf : 	dur +=
buf : 	    (u16) brcms_c_calc_frame_time(wlc, frame_rate, frame_preamble_type,
buf : 					 frame_len);
buf : 	if (ba)
if (ba) 
buf : 		dur +=
buf : 		    (u16) brcms_c_calc_ba_time(wlc, frame_rate,
buf : 					      BRCMS_SHORT_PREAMBLE);
buf : 	else
buf : 		dur +=
buf : 		    (u16) brcms_c_calc_ack_time(wlc, frame_rate,
buf : 					       frame_preamble_type);
buf : 	return dur;
buf : }
buf : 
buf : static u16 brcms_c_phytxctl1_calc(struct brcms_c_info *wlc, u32 rspec)
buf : {
buf : 	u16 phyctl1 = 0;
buf : 	u16 bw;
buf : 
buf : 	if (BRCMS_ISLCNPHY(wlc->band)) {
if (BRCMS_ISLCNPHY(wlc->band)) { 
buf : 		bw = PHY_TXC1_BW_20MHZ;
buf : 	} else {
buf : 		bw = rspec_get_bw(rspec);
buf : 		/* 10Mhz is not supported yet */
buf : 		if (bw < PHY_TXC1_BW_20MHZ) {
if (bw < PHY_TXC1_BW_20MHZ) { 
buf : 			brcms_err(wlc->hw->d11core, "phytxctl1_calc: bw %d is "
buf : 				  "not supported yet, set to 20L\n", bw);
buf : 			bw = PHY_TXC1_BW_20MHZ;
buf : 		}
buf : 	}
buf : 
buf : 	if (is_mcs_rate(rspec)) {
if (is_mcs_rate(rspec)) { 
buf : 		uint mcs = rspec & RSPEC_RATE_MASK;
buf : 
buf : 		/* bw, stf, coding-type is part of rspec_phytxbyte2 returns */
buf : 		phyctl1 = rspec_phytxbyte2(rspec);
buf : 		/* set the upper byte of phyctl1 */
buf : 		phyctl1 |= (mcs_table[mcs].tx_phy_ctl3 << 8);
buf : 	} else if (is_cck_rate(rspec) && !BRCMS_ISLCNPHY(wlc->band)
if (is_cck_rate(rspec) && !BRCMS_ISLCNPHY(wlc->band) 
buf : 		   && !BRCMS_ISSSLPNPHY(wlc->band)) {
buf : 		/*
buf : 		 * In CCK mode LPPHY overloads OFDM Modulation bits with CCK
buf : 		 * Data Rate. Eventually MIMOPHY would also be converted to
buf : 		 * this format
format 
buf : 		 */
buf : 		/* 0 = 1Mbps; 1 = 2Mbps; 2 = 5.5Mbps; 3 = 11Mbps */
buf : 		phyctl1 = (bw | (rspec_stf(rspec) << PHY_TXC1_MODE_SHIFT));
buf : 	} else {		/* legacy OFDM/CCK */
buf : 		s16 phycfg;
buf : 		/* get the phyctl byte from rate phycfg table */
buf : 		phycfg = brcms_c_rate_legacy_phyctl(rspec2rate(rspec));
buf : 		if (phycfg == -1) {
if (phycfg == -1) { 
buf : 			brcms_err(wlc->hw->d11core, "phytxctl1_calc: wrong "
buf : 				  "legacy OFDM/CCK rate\n");
buf : 			phycfg = 0;
buf : 		}
buf : 		/* set the upper byte of phyctl1 */
buf : 		phyctl1 =
buf : 		    (bw | (phycfg << 8) |
buf : 		     (rspec_stf(rspec) << PHY_TXC1_MODE_SHIFT));
buf : 	}
buf : 	return phyctl1;
buf : }
buf : 
buf : /*
buf :  * Add struct d11txh, struct cck_phy_hdr.
buf :  *
buf :  * 'p' data must start with 802.11 MAC header
buf :  * 'p' must allow enough bytes of local headers to be "pushed" onto the packet
buf :  *
buf :  * headroom == D11_PHY_HDR_LEN + D11_TXH_LEN (D11_TXH_LEN is now 104 bytes)
buf :  *
buf :  */
buf : static u16
buf : brcms_c_d11hdrs_mac80211(struct brcms_c_info *wlc, struct ieee80211_hw *hw,
buf : 		     struct sk_buff *p, struct scb *scb, uint frag,
buf : 		     uint nfrags, uint queue, uint next_frag_len)
buf : {
buf : 	struct ieee80211_hdr *h;
buf : 	struct d11txh *txh;
buf : 	u8 *plcp, plcp_fallback[D11_PHY_HDR_LEN];
buf : 	int len, phylen, rts_phylen;
buf : 	u16 mch, phyctl, xfts, mainrates;
buf : 	u16 seq = 0, mcl = 0, status = 0, frameid = 0;
buf : 	u32 rspec[2] = { BRCM_RATE_1M, BRCM_RATE_1M };
buf : 	u32 rts_rspec[2] = { BRCM_RATE_1M, BRCM_RATE_1M };
buf : 	bool use_rts = false;
buf : 	bool use_cts = false;
buf : 	bool use_rifs = false;
ifs = false; 
buf : 	bool short_preamble[2] = { false, false };
buf : 	u8 preamble_type[2] = { BRCMS_LONG_PREAMBLE, BRCMS_LONG_PREAMBLE };
buf : 	u8 rts_preamble_type[2] = { BRCMS_LONG_PREAMBLE, BRCMS_LONG_PREAMBLE };
buf : 	u8 *rts_plcp, rts_plcp_fallback[D11_PHY_HDR_LEN];
buf : 	struct ieee80211_rts *rts = NULL;
buf : 	bool qos;
buf : 	uint ac;
buf : 	bool hwtkmic = false;
buf : 	u16 mimo_ctlchbw = PHY_TXC1_BW_20MHZ;
buf : #define ANTCFG_NONE 0xFF
buf : 	u8 antcfg = ANTCFG_NONE;
buf : 	u8 fbantcfg = ANTCFG_NONE;
buf : 	uint phyctl1_stf = 0;
buf : 	u16 durid = 0;
buf : 	struct ieee80211_tx_rate *txrate[2];
buf : 	int k;
buf : 	struct ieee80211_tx_info *tx_info;
buf : 	bool is_mcs;
buf : 	u16 mimo_txbw;
buf : 	u8 mimo_preamble_type;
buf : 
buf : 	/* locate 802.11 MAC header */
buf : 	h = (struct ieee80211_hdr *)(p->data);
buf : 	qos = ieee80211_is_data_qos(h->frame_control);
buf : 
buf : 	/* compute length of frame in bytes for use in PLCP computations */
for use in PLCP computations */ 
buf : 	len = p->len;
buf : 	phylen = len + FCS_LEN;
buf : 
buf : 	/* Get tx_info */
buf : 	tx_info = IEEE80211_SKB_CB(p);
buf : 
buf : 	/* add PLCP */
buf : 	plcp = skb_push(p, D11_PHY_HDR_LEN);
buf : 
buf : 	/* add Broadcom tx descriptor header */
buf : 	txh = (struct d11txh *) skb_push(p, D11_TXH_LEN);
buf : 	memset(txh, 0, D11_TXH_LEN);
buf : 
buf : 	/* setup frameid */
buf : 	if (tx_info->flags & IEEE80211_TX_CTL_ASSIGN_SEQ) {
if (tx_info->flags & IEEE80211_TX_CTL_ASSIGN_SEQ) { 
buf : 		/* non-AP STA should never use BCMC queue */
buf : 		if (queue == TX_BCMC_FIFO) {
if (queue == TX_BCMC_FIFO) { 
buf : 			brcms_err(wlc->hw->d11core,
buf : 				  "wl%d: %s: ASSERT queue == TX_BCMC!\n",
buf : 				  wlc->pub->unit, __func__);
buf : 			frameid = bcmc_fid_generate(wlc, NULL, txh);
buf : 		} else {
buf : 			/* Increment the counter for first fragment */
for first fragment */ 
buf : 			if (tx_info->flags & IEEE80211_TX_CTL_FIRST_FRAGMENT)
buf : 				scb->seqnum[p->priority]++;
buf : 
buf : 			/* extract fragment number from frame first */
buf : 			seq = le16_to_cpu(h->seq_ctrl) & FRAGNUM_MASK;
buf : 			seq |= (scb->seqnum[p->priority] << SEQNUM_SHIFT);
buf : 			h->seq_ctrl = cpu_to_le16(seq);
buf : 
buf : 			frameid = ((seq << TXFID_SEQ_SHIFT) & TXFID_SEQ_MASK) |
buf : 			    (queue & TXFID_QUEUE_MASK);
buf : 		}
buf : 	}
buf : 	frameid |= queue & TXFID_QUEUE_MASK;
buf : 
buf : 	/* set the ignpmq bit for all pkts tx'd in PS mode and for beacons */
for all pkts tx'd in PS mode and for beacons */ 
buf : 	if (ieee80211_is_beacon(h->frame_control))
buf : 		mcl |= TXC_IGNOREPMQ;
buf : 
buf : 	txrate[0] = tx_info->control.rates;
buf : 	txrate[1] = txrate[0] + 1;
buf : 
buf : 	/*
buf : 	 * if rate control algorithm didn't give us a fallback
if rate control algorithm didn't give us a fallback 
buf : 	 * rate, use the primary rate
buf : 	 */
buf : 	if (txrate[1]->idx < 0)
if (txrate[1]->idx < 0) 
buf : 		txrate[1] = txrate[0];
buf : 
buf : 	for (k = 0; k < hw->max_rates; k++) {
for (k = 0; k < hw->max_rates; k++) { 
buf : 		is_mcs = txrate[k]->flags & IEEE80211_TX_RC_MCS ? true : false;
buf : 		if (!is_mcs) {
if (!is_mcs) { 
buf : 			if ((txrate[k]->idx >= 0)
buf : 			    && (txrate[k]->idx <
buf : 				hw->wiphy->bands[tx_info->band]->n_bitrates)) {
buf : 				rspec[k] =
buf : 				    hw->wiphy->bands[tx_info->band]->
buf : 				    bitrates[txrate[k]->idx].hw_value;
buf : 				short_preamble[k] =
buf : 				    txrate[k]->
buf : 				    flags & IEEE80211_TX_RC_USE_SHORT_PREAMBLE ?
buf : 				    true : false;
buf : 			} else {
buf : 				rspec[k] = BRCM_RATE_1M;
buf : 			}
buf : 		} else {
buf : 			rspec[k] = mac80211_wlc_set_nrate(wlc, wlc->band,
buf : 					NRATE_MCS_INUSE | txrate[k]->idx);
buf : 		}
buf : 
buf : 		/*
buf : 		 * Currently only support same setting for primay and
for primay and 
buf : 		 * fallback rates. Unify flags for each rate into a
buf : 		 * single value for the frame
for the frame 
buf : 		 */
buf : 		use_rts |=
buf : 		    txrate[k]->
buf : 		    flags & IEEE80211_TX_RC_USE_RTS_CTS ? true : false;
buf : 		use_cts |=
buf : 		    txrate[k]->
buf : 		    flags & IEEE80211_TX_RC_USE_CTS_PROTECT ? true : false;
buf : 
buf : 
buf : 		/*
buf : 		 * (1) RATE:
buf : 		 *   determine and validate primary rate
buf : 		 *   and fallback rates
buf : 		 */
buf : 		if (!rspec_active(rspec[k])) {
if (!rspec_active(rspec[k])) { 
buf : 			rspec[k] = BRCM_RATE_1M;
buf : 		} else {
buf : 			if (!is_multicast_ether_addr(h->addr1)) {
if (!is_multicast_ether_addr(h->addr1)) { 
buf : 				/* set tx antenna config */
buf : 				brcms_c_antsel_antcfg_get(wlc->asi, false,
buf : 					false, 0, 0, &antcfg, &fbantcfg);
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	phyctl1_stf = wlc->stf->ss_opmode;
buf : 
buf : 	if (wlc->pub->_n_enab & SUPPORT_11N) {
if (wlc->pub->_n_enab & SUPPORT_11N) { 
buf : 		for (k = 0; k < hw->max_rates; k++) {
for (k = 0; k < hw->max_rates; k++) { 
buf : 			/*
buf : 			 * apply siso/cdd to single stream mcs's or ofdm
buf : 			 * if rspec is auto selected
if rspec is auto selected 
buf : 			 */
buf : 			if (((is_mcs_rate(rspec[k]) &&
if (((is_mcs_rate(rspec[k]) && 
buf : 			      is_single_stream(rspec[k] & RSPEC_RATE_MASK)) ||
buf : 			     is_ofdm_rate(rspec[k]))
buf : 			    && ((rspec[k] & RSPEC_OVERRIDE_MCS_ONLY)
buf : 				|| !(rspec[k] & RSPEC_OVERRIDE))) {
buf : 				rspec[k] &= ~(RSPEC_STF_MASK | RSPEC_STC_MASK);
buf : 
buf : 				/* For SISO MCS use STBC if possible */
if possible */ 
buf : 				if (is_mcs_rate(rspec[k])
buf : 				    && BRCMS_STF_SS_STBC_TX(wlc, scb)) {
buf : 					u8 stc;
buf : 
buf : 					/* Nss for single stream is always 1 */
for single stream is always 1 */ 
buf : 					stc = 1;
buf : 					rspec[k] |= (PHY_TXC1_MODE_STBC <<
buf : 							RSPEC_STF_SHIFT) |
buf : 						    (stc << RSPEC_STC_SHIFT);
buf : 				} else
buf : 					rspec[k] |=
buf : 					    (phyctl1_stf << RSPEC_STF_SHIFT);
buf : 			}
buf : 
buf : 			/*
buf : 			 * Is the phy configured to use 40MHZ frames? If
buf : 			 * so then pick the desired txbw
buf : 			 */
buf : 			if (brcms_chspec_bw(wlc->chanspec) == BRCMS_40_MHZ) {
if (brcms_chspec_bw(wlc->chanspec) == BRCMS_40_MHZ) { 
buf : 				/* default txbw is 20in40 SB */
buf : 				mimo_ctlchbw = mimo_txbw =
buf : 				   CHSPEC_SB_UPPER(wlc_phy_chanspec_get(
buf : 								 wlc->band->pi))
buf : 				   ? PHY_TXC1_BW_20MHZ_UP : PHY_TXC1_BW_20MHZ;
buf : 
buf : 				if (is_mcs_rate(rspec[k])) {
if (is_mcs_rate(rspec[k])) { 
buf : 					/* mcs 32 must be 40b/w DUP */
buf : 					if ((rspec[k] & RSPEC_RATE_MASK)
if ((rspec[k] & RSPEC_RATE_MASK) 
buf : 					    == 32) {
buf : 						mimo_txbw =
buf : 						    PHY_TXC1_BW_40MHZ_DUP;
buf : 						/* use override */
buf : 					} else if (wlc->mimo_40txbw != AUTO)
if (wlc->mimo_40txbw != AUTO) 
buf : 						mimo_txbw = wlc->mimo_40txbw;
buf : 					/* else check if dst is using 40 Mhz */
if dst is using 40 Mhz */ 
buf : 					else if (scb->flags & SCB_IS40)
buf : 						mimo_txbw = PHY_TXC1_BW_40MHZ;
buf : 				} else if (is_ofdm_rate(rspec[k])) {
if (is_ofdm_rate(rspec[k])) { 
buf : 					if (wlc->ofdm_40txbw != AUTO)
buf : 						mimo_txbw = wlc->ofdm_40txbw;
buf : 				} else if (wlc->cck_40txbw != AUTO) {
if (wlc->cck_40txbw != AUTO) { 
buf : 					mimo_txbw = wlc->cck_40txbw;
buf : 				}
buf : 			} else {
buf : 				/*
buf : 				 * mcs32 is 40 b/w only.
buf : 				 * This is possible for probe packets on
for probe packets on 
buf : 				 * a STA during SCAN
buf : 				 */
buf : 				if ((rspec[k] & RSPEC_RATE_MASK) == 32)
if ((rspec[k] & RSPEC_RATE_MASK) == 32) 
buf : 					/* mcs 0 */
buf : 					rspec[k] = RSPEC_MIMORATE;
buf : 
buf : 				mimo_txbw = PHY_TXC1_BW_20MHZ;
buf : 			}
buf : 
buf : 			/* Set channel width */
buf : 			rspec[k] &= ~RSPEC_BW_MASK;
buf : 			if ((k == 0) || ((k > 0) && is_mcs_rate(rspec[k])))
if ((k == 0) || ((k > 0) && is_mcs_rate(rspec[k]))) 
buf : 				rspec[k] |= (mimo_txbw << RSPEC_BW_SHIFT);
buf : 			else
buf : 				rspec[k] |= (mimo_ctlchbw << RSPEC_BW_SHIFT);
buf : 
buf : 			/* Disable short GI, not supported yet */
buf : 			rspec[k] &= ~RSPEC_SHORT_GI;
buf : 
buf : 			mimo_preamble_type = BRCMS_MM_PREAMBLE;
buf : 			if (txrate[k]->flags & IEEE80211_TX_RC_GREEN_FIELD)
if (txrate[k]->flags & IEEE80211_TX_RC_GREEN_FIELD) 
buf : 				mimo_preamble_type = BRCMS_GF_PREAMBLE;
buf : 
buf : 			if ((txrate[k]->flags & IEEE80211_TX_RC_MCS)
if ((txrate[k]->flags & IEEE80211_TX_RC_MCS) 
buf : 			    && (!is_mcs_rate(rspec[k]))) {
buf : 				brcms_warn(wlc->hw->d11core,
buf : 					   "wl%d: %s: IEEE80211_TX_RC_MCS != is_mcs_rate(rspec)\n",
buf : 					   wlc->pub->unit, __func__);
buf : 			}
buf : 
buf : 			if (is_mcs_rate(rspec[k])) {
if (is_mcs_rate(rspec[k])) { 
buf : 				preamble_type[k] = mimo_preamble_type;
buf : 
buf : 				/*
buf : 				 * if SGI is selected, then forced mm
if SGI is selected, then forced mm 
buf : 				 * for single stream
for single stream 
buf : 				 */
buf : 				if ((rspec[k] & RSPEC_SHORT_GI)
if ((rspec[k] & RSPEC_SHORT_GI) 
buf : 				    && is_single_stream(rspec[k] &
buf : 							RSPEC_RATE_MASK))
buf : 					preamble_type[k] = BRCMS_MM_PREAMBLE;
buf : 			}
buf : 
buf : 			/* should be better conditionalized */
buf : 			if (!is_mcs_rate(rspec[0])
if (!is_mcs_rate(rspec[0]) 
buf : 			    && (tx_info->control.rates[0].
buf : 				flags & IEEE80211_TX_RC_USE_SHORT_PREAMBLE))
buf : 				preamble_type[k] = BRCMS_SHORT_PREAMBLE;
buf : 		}
buf : 	} else {
buf : 		for (k = 0; k < hw->max_rates; k++) {
for (k = 0; k < hw->max_rates; k++) { 
buf : 			/* Set ctrlchbw as 20Mhz */
buf : 			rspec[k] &= ~RSPEC_BW_MASK;
buf : 			rspec[k] |= (PHY_TXC1_BW_20MHZ << RSPEC_BW_SHIFT);
buf : 
buf : 			/* for nphy, stf of ofdm frames must follow policies */
for nphy, stf of ofdm frames must follow policies */ 
buf : 			if (BRCMS_ISNPHY(wlc->band) && is_ofdm_rate(rspec[k])) {
buf : 				rspec[k] &= ~RSPEC_STF_MASK;
buf : 				rspec[k] |= phyctl1_stf << RSPEC_STF_SHIFT;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	/* Reset these for use with AMPDU's */
for use with AMPDU's */ 
buf : 	txrate[0]->count = 0;
buf : 	txrate[1]->count = 0;
buf : 
buf : 	/* (2) PROTECTION, may change rspec */
buf : 	if ((ieee80211_is_data(h->frame_control) ||
if ((ieee80211_is_data(h->frame_control) || 
buf : 	    ieee80211_is_mgmt(h->frame_control)) &&
buf : 	    (phylen > wlc->RTSThresh) && !is_multicast_ether_addr(h->addr1))
buf : 		use_rts = true;
buf : 
buf : 	/* (3) PLCP: determine PLCP header and MAC duration,
buf : 	 * fill struct d11txh */
buf : 	brcms_c_compute_plcp(wlc, rspec[0], phylen, plcp);
buf : 	brcms_c_compute_plcp(wlc, rspec[1], phylen, plcp_fallback);
buf : 	memcpy(&txh->FragPLCPFallback,
buf : 	       plcp_fallback, sizeof(txh->FragPLCPFallback));
buf : 
buf : 	/* Length field now put in CCK FBR CRC field */
buf : 	if (is_cck_rate(rspec[1])) {
if (is_cck_rate(rspec[1])) { 
buf : 		txh->FragPLCPFallback[4] = phylen & 0xff;
buf : 		txh->FragPLCPFallback[5] = (phylen & 0xff00) >> 8;
buf : 	}
buf : 
buf : 	/* MIMO-RATE: need validation ?? */
buf : 	mainrates = is_ofdm_rate(rspec[0]) ?
buf : 			D11A_PHY_HDR_GRATE((struct ofdm_phy_hdr *) plcp) :
buf : 			plcp[0];
buf : 
buf : 	/* DUR field for main rate */
for main rate */ 
buf : 	if (!ieee80211_is_pspoll(h->frame_control) &&
buf : 	    !is_multicast_ether_addr(h->addr1) && !use_rifs) {
ifs) { 
buf : 		durid =
buf : 		    brcms_c_compute_frame_dur(wlc, rspec[0], preamble_type[0],
buf : 					  next_frag_len);
buf : 		h->duration_id = cpu_to_le16(durid);
buf : 	} else if (use_rifs) {
if (use_rifs) { 
buf : 		/* NAV protect to end of next max packet size */
buf : 		durid =
buf : 		    (u16) brcms_c_calc_frame_time(wlc, rspec[0],
buf : 						 preamble_type[0],
buf : 						 DOT11_MAX_FRAG_LEN);
buf : 		durid += RIFS_11N_TIME;
buf : 		h->duration_id = cpu_to_le16(durid);
buf : 	}
buf : 
buf : 	/* DUR field for fallback rate */
for fallback rate */ 
buf : 	if (ieee80211_is_pspoll(h->frame_control))
buf : 		txh->FragDurFallback = h->duration_id;
buf : 	else if (is_multicast_ether_addr(h->addr1) || use_rifs)
if (is_multicast_ether_addr(h->addr1) || use_rifs) 
buf : 		txh->FragDurFallback = 0;
buf : 	else {
buf : 		durid = brcms_c_compute_frame_dur(wlc, rspec[1],
buf : 					      preamble_type[1], next_frag_len);
buf : 		txh->FragDurFallback = cpu_to_le16(durid);
buf : 	}
buf : 
buf : 	/* (4) MAC-HDR: MacTxControlLow */
buf : 	if (frag == 0)
if (frag == 0) 
buf : 		mcl |= TXC_STARTMSDU;
buf : 
buf : 	if (!is_multicast_ether_addr(h->addr1))
if (!is_multicast_ether_addr(h->addr1)) 
buf : 		mcl |= TXC_IMMEDACK;
buf : 
buf : 	if (wlc->band->bandtype == BRCM_BAND_5G)
if (wlc->band->bandtype == BRCM_BAND_5G) 
buf : 		mcl |= TXC_FREQBAND_5G;
buf : 
buf : 	if (CHSPEC_IS40(wlc_phy_chanspec_get(wlc->band->pi)))
if (CHSPEC_IS40(wlc_phy_chanspec_get(wlc->band->pi))) 
buf : 		mcl |= TXC_BW_40;
buf : 
buf : 	/* set AMIC bit if using hardware TKIP MIC */
if using hardware TKIP MIC */ 
buf : 	if (hwtkmic)
buf : 		mcl |= TXC_AMIC;
buf : 
buf : 	txh->MacTxControlLow = cpu_to_le16(mcl);
buf : 
buf : 	/* MacTxControlHigh */
buf : 	mch = 0;
buf : 
buf : 	/* Set fallback rate preamble type */
buf : 	if ((preamble_type[1] == BRCMS_SHORT_PREAMBLE) ||
if ((preamble_type[1] == BRCMS_SHORT_PREAMBLE) || 
buf : 	    (preamble_type[1] == BRCMS_GF_PREAMBLE)) {
buf : 		if (rspec2rate(rspec[1]) != BRCM_RATE_1M)
if (rspec2rate(rspec[1]) != BRCM_RATE_1M) 
buf : 			mch |= TXC_PREAMBLE_DATA_FB_SHORT;
buf : 	}
buf : 
buf : 	/* MacFrameControl */
buf : 	memcpy(&txh->MacFrameControl, &h->frame_control, sizeof(u16));
buf : 	txh->TxFesTimeNormal = cpu_to_le16(0);
buf : 
buf : 	txh->TxFesTimeFallback = cpu_to_le16(0);
buf : 
buf : 	/* TxFrameRA */
buf : 	memcpy(&txh->TxFrameRA, &h->addr1, ETH_ALEN);
buf : 
buf : 	/* TxFrameID */
buf : 	txh->TxFrameID = cpu_to_le16(frameid);
buf : 
buf : 	/*
buf : 	 * TxStatus, Note the case of recreating the first frag of a suppressed
buf : 	 * frame then we may need to reset the retry cnt's via the status reg
buf : 	 */
buf : 	txh->TxStatus = cpu_to_le16(status);
buf : 
buf : 	/*
buf : 	 * extra fields for ucode AMPDU aggregation, the new fields are added to
for ucode AMPDU aggregation, the new fields are added to 
buf : 	 * the END of previous structure so that it's compatible in driver.
buf : 	 */
buf : 	txh->MaxNMpdus = cpu_to_le16(0);
buf : 	txh->MaxABytes_MRT = cpu_to_le16(0);
buf : 	txh->MaxABytes_FBR = cpu_to_le16(0);
buf : 	txh->MinMBytes = cpu_to_le16(0);
buf : 
buf : 	/* (5) RTS/CTS: determine RTS/CTS PLCP header and MAC duration,
buf : 	 * furnish struct d11txh */
buf : 	/* RTS PLCP header and RTS frame */
buf : 	if (use_rts || use_cts) {
if (use_rts || use_cts) { 
buf : 		if (use_rts && use_cts)
buf : 			use_cts = false;
buf : 
buf : 		for (k = 0; k < 2; k++) {
for (k = 0; k < 2; k++) { 
buf : 			rts_rspec[k] = brcms_c_rspec_to_rts_rspec(wlc, rspec[k],
buf : 							      false,
buf : 							      mimo_ctlchbw);
buf : 		}
buf : 
buf : 		if (!is_ofdm_rate(rts_rspec[0]) &&
if (!is_ofdm_rate(rts_rspec[0]) && 
buf : 		    !((rspec2rate(rts_rspec[0]) == BRCM_RATE_1M) ||
buf : 		      (wlc->PLCPHdr_override == BRCMS_PLCP_LONG))) {
buf : 			rts_preamble_type[0] = BRCMS_SHORT_PREAMBLE;
buf : 			mch |= TXC_PREAMBLE_RTS_MAIN_SHORT;
buf : 		}
buf : 
buf : 		if (!is_ofdm_rate(rts_rspec[1]) &&
if (!is_ofdm_rate(rts_rspec[1]) && 
buf : 		    !((rspec2rate(rts_rspec[1]) == BRCM_RATE_1M) ||
buf : 		      (wlc->PLCPHdr_override == BRCMS_PLCP_LONG))) {
buf : 			rts_preamble_type[1] = BRCMS_SHORT_PREAMBLE;
buf : 			mch |= TXC_PREAMBLE_RTS_FB_SHORT;
buf : 		}
buf : 
buf : 		/* RTS/CTS additions to MacTxControlLow */
buf : 		if (use_cts) {
if (use_cts) { 
buf : 			txh->MacTxControlLow |= cpu_to_le16(TXC_SENDCTS);
buf : 		} else {
buf : 			txh->MacTxControlLow |= cpu_to_le16(TXC_SENDRTS);
buf : 			txh->MacTxControlLow |= cpu_to_le16(TXC_LONGFRAME);
buf : 		}
buf : 
buf : 		/* RTS PLCP header */
buf : 		rts_plcp = txh->RTSPhyHeader;
buf : 		if (use_cts)
if (use_cts) 
buf : 			rts_phylen = DOT11_CTS_LEN + FCS_LEN;
buf : 		else
buf : 			rts_phylen = DOT11_RTS_LEN + FCS_LEN;
buf : 
buf : 		brcms_c_compute_plcp(wlc, rts_rspec[0], rts_phylen, rts_plcp);
buf : 
buf : 		/* fallback rate version of RTS PLCP header */
buf : 		brcms_c_compute_plcp(wlc, rts_rspec[1], rts_phylen,
buf : 				 rts_plcp_fallback);
buf : 		memcpy(&txh->RTSPLCPFallback, rts_plcp_fallback,
buf : 		       sizeof(txh->RTSPLCPFallback));
buf : 
buf : 		/* RTS frame fields... */
buf : 		rts = (struct ieee80211_rts *)&txh->rts_frame;
buf : 
buf : 		durid = brcms_c_compute_rtscts_dur(wlc, use_cts, rts_rspec[0],
buf : 					       rspec[0], rts_preamble_type[0],
buf : 					       preamble_type[0], phylen, false);
buf : 		rts->duration = cpu_to_le16(durid);
buf : 		/* fallback rate version of RTS DUR field */
buf : 		durid = brcms_c_compute_rtscts_dur(wlc, use_cts,
buf : 					       rts_rspec[1], rspec[1],
buf : 					       rts_preamble_type[1],
buf : 					       preamble_type[1], phylen, false);
buf : 		txh->RTSDurFallback = cpu_to_le16(durid);
buf : 
buf : 		if (use_cts) {
if (use_cts) { 
buf : 			rts->frame_control = cpu_to_le16(IEEE80211_FTYPE_CTL |
buf : 							 IEEE80211_STYPE_CTS);
buf : 
buf : 			memcpy(&rts->ra, &h->addr2, ETH_ALEN);
buf : 		} else {
buf : 			rts->frame_control = cpu_to_le16(IEEE80211_FTYPE_CTL |
buf : 							 IEEE80211_STYPE_RTS);
buf : 
buf : 			memcpy(&rts->ra, &h->addr1, 2 * ETH_ALEN);
buf : 		}
buf : 
buf : 		/* mainrate
buf : 		 *    low 8 bits: main frag rate/mcs,
buf : 		 *    high 8 bits: rts/cts rate/mcs
buf : 		 */
buf : 		mainrates |= (is_ofdm_rate(rts_rspec[0]) ?
buf : 				D11A_PHY_HDR_GRATE(
buf : 					(struct ofdm_phy_hdr *) rts_plcp) :
buf : 				rts_plcp[0]) << 8;
buf : 	} else {
buf : 		memset(txh->RTSPhyHeader, 0, D11_PHY_HDR_LEN);
buf : 		memset(&txh->rts_frame, 0, sizeof(struct ieee80211_rts));
buf : 		memset(txh->RTSPLCPFallback, 0, sizeof(txh->RTSPLCPFallback));
buf : 		txh->RTSDurFallback = 0;
buf : 	}
buf : 
buf : #ifdef SUPPORT_40MHZ
ifdef SUPPORT_40MHZ 
buf : 	/* add null delimiter count */
buf : 	if ((tx_info->flags & IEEE80211_TX_CTL_AMPDU) && is_mcs_rate(rspec))
if ((tx_info->flags & IEEE80211_TX_CTL_AMPDU) && is_mcs_rate(rspec)) 
buf : 		txh->RTSPLCPFallback[AMPDU_FBR_NULL_DELIM] =
buf : 		   brcm_c_ampdu_null_delim_cnt(wlc->ampdu, scb, rspec, phylen);
buf : 
buf : #endif
if 
buf : 
buf : 	/*
buf : 	 * Now that RTS/RTS FB preamble types are updated, write
buf : 	 * the final value
buf : 	 */
buf : 	txh->MacTxControlHigh = cpu_to_le16(mch);
buf : 
buf : 	/*
buf : 	 * MainRates (both the rts and frag plcp rates have
buf : 	 * been calculated now)
buf : 	 */
buf : 	txh->MainRates = cpu_to_le16(mainrates);
buf : 
buf : 	/* XtraFrameTypes */
buf : 	xfts = frametype(rspec[1], wlc->mimoft);
buf : 	xfts |= (frametype(rts_rspec[0], wlc->mimoft) << XFTS_RTS_FT_SHIFT);
buf : 	xfts |= (frametype(rts_rspec[1], wlc->mimoft) << XFTS_FBRRTS_FT_SHIFT);
buf : 	xfts |= CHSPEC_CHANNEL(wlc_phy_chanspec_get(wlc->band->pi)) <<
buf : 							     XFTS_CHANNEL_SHIFT;
buf : 	txh->XtraFrameTypes = cpu_to_le16(xfts);
buf : 
buf : 	/* PhyTxControlWord */
buf : 	phyctl = frametype(rspec[0], wlc->mimoft);
buf : 	if ((preamble_type[0] == BRCMS_SHORT_PREAMBLE) ||
if ((preamble_type[0] == BRCMS_SHORT_PREAMBLE) || 
buf : 	    (preamble_type[0] == BRCMS_GF_PREAMBLE)) {
buf : 		if (rspec2rate(rspec[0]) != BRCM_RATE_1M)
if (rspec2rate(rspec[0]) != BRCM_RATE_1M) 
buf : 			phyctl |= PHY_TXC_SHORT_HDR;
buf : 	}
buf : 
buf : 	/* phytxant is properly bit shifted */
ifted */ 
buf : 	phyctl |= brcms_c_stf_d11hdrs_phyctl_txant(wlc, rspec[0]);
buf : 	txh->PhyTxControlWord = cpu_to_le16(phyctl);
buf : 
buf : 	/* PhyTxControlWord_1 */
buf : 	if (BRCMS_PHY_11N_CAP(wlc->band)) {
if (BRCMS_PHY_11N_CAP(wlc->band)) { 
buf : 		u16 phyctl1 = 0;
buf : 
buf : 		phyctl1 = brcms_c_phytxctl1_calc(wlc, rspec[0]);
buf : 		txh->PhyTxControlWord_1 = cpu_to_le16(phyctl1);
buf : 		phyctl1 = brcms_c_phytxctl1_calc(wlc, rspec[1]);
buf : 		txh->PhyTxControlWord_1_Fbr = cpu_to_le16(phyctl1);
buf : 
buf : 		if (use_rts || use_cts) {
if (use_rts || use_cts) { 
buf : 			phyctl1 = brcms_c_phytxctl1_calc(wlc, rts_rspec[0]);
buf : 			txh->PhyTxControlWord_1_Rts = cpu_to_le16(phyctl1);
buf : 			phyctl1 = brcms_c_phytxctl1_calc(wlc, rts_rspec[1]);
buf : 			txh->PhyTxControlWord_1_FbrRts = cpu_to_le16(phyctl1);
buf : 		}
buf : 
buf : 		/*
buf : 		 * For mcs frames, if mixedmode(overloaded with long preamble)
if mixedmode(overloaded with long preamble) 
buf : 		 * is going to be set, fill in non-zero MModeLen and/or
buf : 		 * MModeFbrLen it will be unnecessary if they are separated
if they are separated 
buf : 		 */
buf : 		if (is_mcs_rate(rspec[0]) &&
if (is_mcs_rate(rspec[0]) && 
buf : 		    (preamble_type[0] == BRCMS_MM_PREAMBLE)) {
buf : 			u16 mmodelen =
buf : 			    brcms_c_calc_lsig_len(wlc, rspec[0], phylen);
buf : 			txh->MModeLen = cpu_to_le16(mmodelen);
buf : 		}
buf : 
buf : 		if (is_mcs_rate(rspec[1]) &&
if (is_mcs_rate(rspec[1]) && 
buf : 		    (preamble_type[1] == BRCMS_MM_PREAMBLE)) {
buf : 			u16 mmodefbrlen =
buf : 			    brcms_c_calc_lsig_len(wlc, rspec[1], phylen);
buf : 			txh->MModeFbrLen = cpu_to_le16(mmodefbrlen);
buf : 		}
buf : 	}
buf : 
buf : 	ac = skb_get_queue_mapping(p);
buf : 	if ((scb->flags & SCB_WMECAP) && qos && wlc->edcf_txop[ac]) {
if ((scb->flags & SCB_WMECAP) && qos && wlc->edcf_txop[ac]) { 
buf : 		uint frag_dur, dur, dur_fallback;
buf : 
buf : 		/* WME: Update TXOP threshold */
buf : 		if (!(tx_info->flags & IEEE80211_TX_CTL_AMPDU) && frag == 0) {
if (!(tx_info->flags & IEEE80211_TX_CTL_AMPDU) && frag == 0) { 
buf : 			frag_dur =
buf : 			    brcms_c_calc_frame_time(wlc, rspec[0],
buf : 					preamble_type[0], phylen);
buf : 
buf : 			if (rts) {
if (rts) { 
buf : 				/* 1 RTS or CTS-to-self frame */
buf : 				dur =
buf : 				    brcms_c_calc_cts_time(wlc, rts_rspec[0],
buf : 						      rts_preamble_type[0]);
buf : 				dur_fallback =
buf : 				    brcms_c_calc_cts_time(wlc, rts_rspec[1],
buf : 						      rts_preamble_type[1]);
buf : 				/* (SIFS + CTS) + SIFS + frame + SIFS + ACK */
buf : 				dur += le16_to_cpu(rts->duration);
buf : 				dur_fallback +=
buf : 					le16_to_cpu(txh->RTSDurFallback);
buf : 			} else if (use_rifs) {
if (use_rifs) { 
buf : 				dur = frag_dur;
buf : 				dur_fallback = 0;
buf : 			} else {
buf : 				/* frame + SIFS + ACK */
buf : 				dur = frag_dur;
buf : 				dur +=
buf : 				    brcms_c_compute_frame_dur(wlc, rspec[0],
buf : 							  preamble_type[0], 0);
buf : 
buf : 				dur_fallback =
buf : 				    brcms_c_calc_frame_time(wlc, rspec[1],
buf : 							preamble_type[1],
buf : 							phylen);
buf : 				dur_fallback +=
buf : 				    brcms_c_compute_frame_dur(wlc, rspec[1],
buf : 							  preamble_type[1], 0);
buf : 			}
buf : 			/* NEED to set TxFesTimeNormal (hard) */
buf : 			txh->TxFesTimeNormal = cpu_to_le16((u16) dur);
buf : 			/*
buf : 			 * NEED to set fallback rate version of
buf : 			 * TxFesTimeNormal (hard)
buf : 			 */
buf : 			txh->TxFesTimeFallback =
buf : 				cpu_to_le16((u16) dur_fallback);
buf : 
buf : 			/*
buf : 			 * update txop byte threshold (txop minus intraframe
buf : 			 * overhead)
buf : 			 */
buf : 			if (wlc->edcf_txop[ac] >= (dur - frag_dur)) {
if (wlc->edcf_txop[ac] >= (dur - frag_dur)) { 
buf : 				uint newfragthresh;
buf : 
buf : 				newfragthresh =
buf : 				    brcms_c_calc_frame_len(wlc,
buf : 					rspec[0], preamble_type[0],
buf : 					(wlc->edcf_txop[ac] -
buf : 						(dur - frag_dur)));
buf : 				/* range bound the fragthreshold */
buf : 				if (newfragthresh < DOT11_MIN_FRAG_LEN)
if (newfragthresh < DOT11_MIN_FRAG_LEN) 
buf : 					newfragthresh =
buf : 					    DOT11_MIN_FRAG_LEN;
buf : 				else if (newfragthresh >
if (newfragthresh > 
buf : 					 wlc->usr_fragthresh)
buf : 					newfragthresh =
buf : 					    wlc->usr_fragthresh;
buf : 				/* update the fragthresh and do txc update */
buf : 				if (wlc->fragthresh[queue] !=
if (wlc->fragthresh[queue] != 
buf : 				    (u16) newfragthresh)
buf : 					wlc->fragthresh[queue] =
buf : 					    (u16) newfragthresh;
buf : 			} else {
buf : 				brcms_warn(wlc->hw->d11core,
buf : 					   "wl%d: %s txop invalid for rate %d\n",
for rate %d\n", 
buf : 					   wlc->pub->unit, fifo_names[queue],
buf : 					   rspec2rate(rspec[0]));
buf : 			}
buf : 
buf : 			if (dur > wlc->edcf_txop[ac])
if (dur > wlc->edcf_txop[ac]) 
buf : 				brcms_warn(wlc->hw->d11core,
buf : 					   "wl%d: %s: %s txop exceeded phylen %d/%d dur %d/%d\n",
buf : 					   wlc->pub->unit, __func__,
buf : 					   fifo_names[queue],
ifo_names[queue], 
buf : 					   phylen, wlc->fragthresh[queue],
buf : 					   dur, wlc->edcf_txop[ac]);
buf : 		}
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int brcms_c_tx(struct brcms_c_info *wlc, struct sk_buff *skb)
buf : {
buf : 	struct dma_pub *dma;
buf : 	int fifo, ret = -ENOSPC;
ifo, ret = -ENOSPC; 
buf : 	struct d11txh *txh;
buf : 	u16 frameid = INVALIDFID;
buf : 
buf : 	fifo = brcms_ac_to_fifo(skb_get_queue_mapping(skb));
ifo = brcms_ac_to_fifo(skb_get_queue_mapping(skb)); 
buf : 	dma = wlc->hw->di[fifo];
buf : 	txh = (struct d11txh *)(skb->data);
buf : 
buf : 	if (dma->txavail == 0) {
if (dma->txavail == 0) { 
buf : 		/*
buf : 		 * We sometimes get a frame from mac80211 after stopping
buf : 		 * the queues. This only ever seems to be a single frame
buf : 		 * and is seems likely to be a race. TX_HEADROOM should
buf : 		 * ensure that we have enough space to handle these stray
buf : 		 * packets, so warn if there isn't. If we're out of space
if there isn't. If we're out of space 
buf : 		 * in the tx ring and the tx queue isn't stopped then
buf : 		 * we've really got a bug; warn loudly if that happens.
if that happens. 
buf : 		 */
buf : 		brcms_warn(wlc->hw->d11core,
buf : 			   "Received frame for tx with no space in DMA ring\n");
for tx with no space in DMA ring\n"); 
buf : 		WARN_ON(!ieee80211_queue_stopped(wlc->pub->ieee_hw,
buf : 						 skb_get_queue_mapping(skb)));
buf : 		return -ENOSPC;
buf : 	}
buf : 
buf : 	/* When a BC/MC frame is being committed to the BCMC fifo
ifo 
buf : 	 * via DMA (NOT PIO), update ucode or BSS info as appropriate.
buf : 	 */
buf : 	if (fifo == TX_BCMC_FIFO)
if (fifo == TX_BCMC_FIFO) 
buf : 		frameid = le16_to_cpu(txh->TxFrameID);
buf : 
buf : 	/* Commit BCMC sequence number in the SHM frame ID location */
buf : 	if (frameid != INVALIDFID) {
if (frameid != INVALIDFID) { 
buf : 		/*
buf : 		 * To inform the ucode of the last mcast frame posted
form the ucode of the last mcast frame posted 
buf : 		 * so that it can clear moredata bit
buf : 		 */
buf : 		brcms_b_write_shm(wlc->hw, M_BCMC_FID, frameid);
buf : 	}
buf : 
buf : 	ret = brcms_c_txfifo(wlc, fifo, skb);
ifo(wlc, fifo, skb); 
buf : 	/*
buf : 	 * The only reason for brcms_c_txfifo to fail is because
ifo to fail is because 
buf : 	 * there weren't any DMA descriptors, but we've already
buf : 	 * checked for that. So if it does fail yell loudly.
if it does fail yell loudly. 
buf : 	 */
buf : 	WARN_ON_ONCE(ret);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : bool brcms_c_sendpkt_mac80211(struct brcms_c_info *wlc, struct sk_buff *sdu,
buf : 			      struct ieee80211_hw *hw)
buf : {
buf : 	uint fifo;
ifo; 
buf : 	struct scb *scb = &wlc->pri_scb;
buf : 
buf : 	fifo = brcms_ac_to_fifo(skb_get_queue_mapping(sdu));
ifo = brcms_ac_to_fifo(skb_get_queue_mapping(sdu)); 
buf : 	brcms_c_d11hdrs_mac80211(wlc, hw, sdu, scb, 0, 1, fifo, 0);
buf : 	if (!brcms_c_tx(wlc, sdu))
if (!brcms_c_tx(wlc, sdu)) 
buf : 		return true;
buf : 
buf : 	/* packet discarded */
buf : 	dev_kfree_skb_any(sdu);
buf : 	return false;
buf : }
buf : 
buf : int
buf : brcms_c_txfifo(struct brcms_c_info *wlc, uint fifo, struct sk_buff *p)
ifo(struct brcms_c_info *wlc, uint fifo, struct sk_buff *p) 
buf : {
buf : 	struct dma_pub *dma = wlc->hw->di[fifo];
buf : 	int ret;
buf : 	u16 queue;
buf : 
buf : 	ret = dma_txfast(wlc, dma, p);
buf : 	if (ret	< 0)
if (ret	< 0) 
buf : 		wiphy_err(wlc->wiphy, "txfifo: fatal, toss frames !!!\n");
buf : 
buf : 	/*
buf : 	 * Stop queue if DMA ring is full. Reserve some free descriptors,
if DMA ring is full. Reserve some free descriptors, 
buf : 	 * as we sometimes receive a frame from mac80211 after the queues
buf : 	 * are stopped.
buf : 	 */
buf : 	queue = skb_get_queue_mapping(p);
buf : 	if (dma->txavail <= TX_HEADROOM && fifo < TX_BCMC_FIFO &&
if (dma->txavail <= TX_HEADROOM && fifo < TX_BCMC_FIFO && 
buf : 	    !ieee80211_queue_stopped(wlc->pub->ieee_hw, queue))
buf : 		ieee80211_stop_queue(wlc->pub->ieee_hw, queue);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : u32
buf : brcms_c_rspec_to_rts_rspec(struct brcms_c_info *wlc, u32 rspec,
buf : 			   bool use_rspec, u16 mimo_ctlchbw)
buf : {
buf : 	u32 rts_rspec = 0;
buf : 
buf : 	if (use_rspec)
if (use_rspec) 
buf : 		/* use frame rate as rts rate */
buf : 		rts_rspec = rspec;
buf : 	else if (wlc->band->gmode && wlc->protection->_g && !is_cck_rate(rspec))
if (wlc->band->gmode && wlc->protection->_g && !is_cck_rate(rspec)) 
buf : 		/* Use 11Mbps as the g protection RTS target rate and fallback.
buf : 		 * Use the brcms_basic_rate() lookup to find the best basic rate
buf : 		 * under the target in case 11 Mbps is not Basic.
buf : 		 * 6 and 9 Mbps are not usually selected by rate selection, but
buf : 		 * even if the OFDM rate we are protecting is 6 or 9 Mbps, 11
if the OFDM rate we are protecting is 6 or 9 Mbps, 11 
buf : 		 * is more robust.
buf : 		 */
buf : 		rts_rspec = brcms_basic_rate(wlc, BRCM_RATE_11M);
buf : 	else
buf : 		/* calculate RTS rate and fallback rate based on the frame rate
buf : 		 * RTS must be sent at a basic rate since it is a
buf : 		 * control frame, sec 9.6 of 802.11 spec
buf : 		 */
buf : 		rts_rspec = brcms_basic_rate(wlc, rspec);
buf : 
buf : 	if (BRCMS_PHY_11N_CAP(wlc->band)) {
if (BRCMS_PHY_11N_CAP(wlc->band)) { 
buf : 		/* set rts txbw to correct side band */
buf : 		rts_rspec &= ~RSPEC_BW_MASK;
buf : 
buf : 		/*
buf : 		 * if rspec/rspec_fallback is 40MHz, then send RTS on both
if rspec/rspec_fallback is 40MHz, then send RTS on both 
buf : 		 * 20MHz channel (DUP), otherwise send RTS on control channel
buf : 		 */
buf : 		if (rspec_is40mhz(rspec) && !is_cck_rate(rts_rspec))
if (rspec_is40mhz(rspec) && !is_cck_rate(rts_rspec)) 
buf : 			rts_rspec |= (PHY_TXC1_BW_40MHZ_DUP << RSPEC_BW_SHIFT);
buf : 		else
buf : 			rts_rspec |= (mimo_ctlchbw << RSPEC_BW_SHIFT);
buf : 
buf : 		/* pick siso/cdd as default for ofdm */
for ofdm */ 
buf : 		if (is_ofdm_rate(rts_rspec)) {
buf : 			rts_rspec &= ~RSPEC_STF_MASK;
buf : 			rts_rspec |= (wlc->stf->ss_opmode << RSPEC_STF_SHIFT);
buf : 		}
buf : 	}
buf : 	return rts_rspec;
buf : }
buf : 
buf : /* Update beacon listen interval in shared memory */
buf : static void brcms_c_bcn_li_upd(struct brcms_c_info *wlc)
buf : {
buf : 	/* wake up every DTIM is the default */
buf : 	if (wlc->bcn_li_dtim == 1)
if (wlc->bcn_li_dtim == 1) 
buf : 		brcms_b_write_shm(wlc->hw, M_BCN_LI, 0);
buf : 	else
buf : 		brcms_b_write_shm(wlc->hw, M_BCN_LI,
buf : 			      (wlc->bcn_li_dtim << 8) | wlc->bcn_li_bcn);
buf : }
buf : 
buf : static void
buf : brcms_b_read_tsf(struct brcms_hardware *wlc_hw, u32 *tsf_l_ptr,
buf : 		  u32 *tsf_h_ptr)
buf : {
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 
buf : 	/* read the tsf timer low, then high to get an atomic read */
buf : 	*tsf_l_ptr = bcma_read32(core, D11REGOFFS(tsf_timerlow));
buf : 	*tsf_h_ptr = bcma_read32(core, D11REGOFFS(tsf_timerhigh));
buf : }
buf : 
buf : /*
buf :  * recover 64bit TSF value from the 16bit TSF value in the rx header
buf :  * given the assumption that the TSF passed in header is within 65ms
buf :  * of the current tsf.
buf :  *
buf :  * 6       5       4       4       3       2       1
buf :  * 3.......6.......8.......0.......2.......4.......6.......8......0
buf :  * |<---------- tsf_h ----------->||<--- tsf_l -->||<-RxTSFTime ->|
buf :  *
buf :  * The RxTSFTime are the lowest 16 bits and provided by the ucode. The
buf :  * tsf_l is filled in by brcms_b_recv, which is done earlier in the
buf :  * receive call sequence after rx interrupt. Only the higher 16 bits
buf :  * are used. Finally, the tsf_h is read from the tsf register.
buf :  */
buf : static u64 brcms_c_recover_tsf64(struct brcms_c_info *wlc,
buf : 				 struct d11rxhdr *rxh)
buf : {
buf : 	u32 tsf_h, tsf_l;
buf : 	u16 rx_tsf_0_15, rx_tsf_16_31;
buf : 
buf : 	brcms_b_read_tsf(wlc->hw, &tsf_l, &tsf_h);
buf : 
buf : 	rx_tsf_16_31 = (u16)(tsf_l >> 16);
buf : 	rx_tsf_0_15 = rxh->RxTSFTime;
buf : 
buf : 	/*
buf : 	 * a greater tsf time indicates the low 16 bits of
buf : 	 * tsf_l wrapped, so decrement the high 16 bits.
buf : 	 */
buf : 	if ((u16)tsf_l < rx_tsf_0_15) {
if ((u16)tsf_l < rx_tsf_0_15) { 
buf : 		rx_tsf_16_31 -= 1;
buf : 		if (rx_tsf_16_31 == 0xffff)
if (rx_tsf_16_31 == 0xffff) 
buf : 			tsf_h -= 1;
buf : 	}
buf : 
buf : 	return ((u64)tsf_h << 32) | (((u32)rx_tsf_16_31 << 16) + rx_tsf_0_15);
buf : }
buf : 
buf : static void
buf : prep_mac80211_status(struct brcms_c_info *wlc, struct d11rxhdr *rxh,
buf : 		     struct sk_buff *p,
buf : 		     struct ieee80211_rx_status *rx_status)
buf : {
buf : 	int channel;
buf : 	u32 rspec;
buf : 	unsigned char *plcp;
buf : 
buf : 	/* fill in TSF and flag its presence */
buf : 	rx_status->mactime = brcms_c_recover_tsf64(wlc, rxh);
buf : 	rx_status->flag |= RX_FLAG_MACTIME_START;
buf : 
buf : 	channel = BRCMS_CHAN_CHANNEL(rxh->RxChan);
buf : 
buf : 	rx_status->band =
buf : 		channel > 14 ? IEEE80211_BAND_5GHZ : IEEE80211_BAND_2GHZ;
buf : 	rx_status->freq =
buf : 		ieee80211_channel_to_frequency(channel, rx_status->band);
buf : 
buf : 	rx_status->signal = wlc_phy_rssi_compute(wlc->hw->band->pi, rxh);
buf : 
buf : 	/* noise */
buf : 	/* qual */
buf : 	rx_status->antenna =
buf : 		(rxh->PhyRxStatus_0 & PRXS0_RXANT_UPSUBBAND) ? 1 : 0;
buf : 
buf : 	plcp = p->data;
buf : 
buf : 	rspec = brcms_c_compute_rspec(rxh, plcp);
buf : 	if (is_mcs_rate(rspec)) {
if (is_mcs_rate(rspec)) { 
buf : 		rx_status->rate_idx = rspec & RSPEC_RATE_MASK;
buf : 		rx_status->flag |= RX_FLAG_HT;
buf : 		if (rspec_is40mhz(rspec))
if (rspec_is40mhz(rspec)) 
buf : 			rx_status->flag |= RX_FLAG_40MHZ;
buf : 	} else {
buf : 		switch (rspec2rate(rspec)) {
buf : 		case BRCM_RATE_1M:
buf : 			rx_status->rate_idx = 0;
buf : 			break;
buf : 		case BRCM_RATE_2M:
buf : 			rx_status->rate_idx = 1;
buf : 			break;
buf : 		case BRCM_RATE_5M5:
buf : 			rx_status->rate_idx = 2;
buf : 			break;
buf : 		case BRCM_RATE_11M:
buf : 			rx_status->rate_idx = 3;
buf : 			break;
buf : 		case BRCM_RATE_6M:
buf : 			rx_status->rate_idx = 4;
buf : 			break;
buf : 		case BRCM_RATE_9M:
buf : 			rx_status->rate_idx = 5;
buf : 			break;
buf : 		case BRCM_RATE_12M:
buf : 			rx_status->rate_idx = 6;
buf : 			break;
buf : 		case BRCM_RATE_18M:
buf : 			rx_status->rate_idx = 7;
buf : 			break;
buf : 		case BRCM_RATE_24M:
buf : 			rx_status->rate_idx = 8;
buf : 			break;
buf : 		case BRCM_RATE_36M:
buf : 			rx_status->rate_idx = 9;
buf : 			break;
buf : 		case BRCM_RATE_48M:
buf : 			rx_status->rate_idx = 10;
buf : 			break;
buf : 		case BRCM_RATE_54M:
buf : 			rx_status->rate_idx = 11;
buf : 			break;
buf : 		default:
buf : 			brcms_err(wlc->hw->d11core,
buf : 				  "%s: Unknown rate\n", __func__);
buf : 		}
buf : 
buf : 		/*
buf : 		 * For 5GHz, we should decrease the index as it is
buf : 		 * a subset of the 2.4G rates. See bitrates field
buf : 		 * of brcms_band_5GHz_nphy (in mac80211_if.c).
if.c). 
buf : 		 */
buf : 		if (rx_status->band == IEEE80211_BAND_5GHZ)
if (rx_status->band == IEEE80211_BAND_5GHZ) 
buf : 			rx_status->rate_idx -= BRCMS_LEGACY_5G_RATE_OFFSET;
buf : 
buf : 		/* Determine short preamble and rate_idx */
buf : 		if (is_cck_rate(rspec)) {
if (is_cck_rate(rspec)) { 
buf : 			if (rxh->PhyRxStatus_0 & PRXS0_SHORTH)
buf : 				rx_status->flag |= RX_FLAG_SHORTPRE;
buf : 		} else if (is_ofdm_rate(rspec)) {
if (is_ofdm_rate(rspec)) { 
buf : 			rx_status->flag |= RX_FLAG_SHORTPRE;
buf : 		} else {
buf : 			brcms_err(wlc->hw->d11core, "%s: Unknown modulation\n",
buf : 				  __func__);
buf : 		}
buf : 	}
buf : 
buf : 	if (plcp3_issgi(plcp[3]))
if (plcp3_issgi(plcp[3])) 
buf : 		rx_status->flag |= RX_FLAG_SHORT_GI;
buf : 
buf : 	if (rxh->RxStatus1 & RXS_DECERR) {
if (rxh->RxStatus1 & RXS_DECERR) { 
buf : 		rx_status->flag |= RX_FLAG_FAILED_PLCP_CRC;
buf : 		brcms_err(wlc->hw->d11core, "%s:  RX_FLAG_FAILED_PLCP_CRC\n",
buf : 			  __func__);
buf : 	}
buf : 	if (rxh->RxStatus1 & RXS_FCSERR) {
if (rxh->RxStatus1 & RXS_FCSERR) { 
buf : 		rx_status->flag |= RX_FLAG_FAILED_FCS_CRC;
buf : 		brcms_err(wlc->hw->d11core, "%s:  RX_FLAG_FAILED_FCS_CRC\n",
buf : 			  __func__);
buf : 	}
buf : }
buf : 
buf : static void
buf : brcms_c_recvctl(struct brcms_c_info *wlc, struct d11rxhdr *rxh,
buf : 		struct sk_buff *p)
buf : {
buf : 	int len_mpdu;
buf : 	struct ieee80211_rx_status rx_status;
buf : 	struct ieee80211_hdr *hdr;
buf : 
buf : 	memset(&rx_status, 0, sizeof(rx_status));
buf : 	prep_mac80211_status(wlc, rxh, p, &rx_status);
buf : 
buf : 	/* mac header+body length, exclude CRC and plcp header */
buf : 	len_mpdu = p->len - D11_PHY_HDR_LEN - FCS_LEN;
buf : 	skb_pull(p, D11_PHY_HDR_LEN);
buf : 	__skb_trim(p, len_mpdu);
buf : 
buf : 	/* unmute transmit */
buf : 	if (wlc->hw->suspended_fifos) {
if (wlc->hw->suspended_fifos) { 
buf : 		hdr = (struct ieee80211_hdr *)p->data;
buf : 		if (ieee80211_is_beacon(hdr->frame_control))
if (ieee80211_is_beacon(hdr->frame_control)) 
buf : 			brcms_b_mute(wlc->hw, false);
buf : 	}
buf : 
buf : 	memcpy(IEEE80211_SKB_RXCB(p), &rx_status, sizeof(rx_status));
buf : 	ieee80211_rx_irqsafe(wlc->pub->ieee_hw, p);
buf : }
buf : 
buf : /* calculate frame duration for Mixed-mode L-SIG spoofing, return
for Mixed-mode L-SIG spoofing, return 
buf :  * number of bytes goes in the length field
buf :  *
buf :  * Formula given by HT PHY Spec v 1.13
buf :  *   len = 3(nsyms + nstream + 3) - 3
buf :  */
buf : u16
buf : brcms_c_calc_lsig_len(struct brcms_c_info *wlc, u32 ratespec,
buf : 		      uint mac_len)
buf : {
buf : 	uint nsyms, len = 0, kNdps;
buf : 
buf : 	if (is_mcs_rate(ratespec)) {
if (is_mcs_rate(ratespec)) { 
buf : 		uint mcs = ratespec & RSPEC_RATE_MASK;
buf : 		int tot_streams = (mcs_2_txstreams(mcs) + 1) +
buf : 				  rspec_stc(ratespec);
buf : 
buf : 		/*
buf : 		 * the payload duration calculation matches that
buf : 		 * of regular ofdm
buf : 		 */
buf : 		/* 1000Ndbps = kbps * 4 */
buf : 		kNdps = mcs_2_rate(mcs, rspec_is40mhz(ratespec),
buf : 				   rspec_issgi(ratespec)) * 4;
buf : 
buf : 		if (rspec_stc(ratespec) == 0)
if (rspec_stc(ratespec) == 0) 
buf : 			nsyms =
buf : 			    CEIL((APHY_SERVICE_NBITS + 8 * mac_len +
buf : 				  APHY_TAIL_NBITS) * 1000, kNdps);
buf : 		else
buf : 			/* STBC needs to have even number of symbols */
buf : 			nsyms =
buf : 			    2 *
buf : 			    CEIL((APHY_SERVICE_NBITS + 8 * mac_len +
buf : 				  APHY_TAIL_NBITS) * 1000, 2 * kNdps);
buf : 
buf : 		/* (+3) account for HT-SIG(2) and HT-STF(1) */
for HT-SIG(2) and HT-STF(1) */ 
buf : 		nsyms += (tot_streams + 3);
buf : 		/*
buf : 		 * 3 bytes/symbol @ legacy 6Mbps rate
buf : 		 * (-3) excluding service bits and tail bits
buf : 		 */
buf : 		len = (3 * nsyms) - 3;
buf : 	}
buf : 
buf : 	return (u16) len;
buf : }
buf : 
buf : static void
buf : brcms_c_mod_prb_rsp_rate_table(struct brcms_c_info *wlc, uint frame_len)
buf : {
buf : 	const struct brcms_c_rateset *rs_dflt;
buf : 	struct brcms_c_rateset rs;
buf : 	u8 rate;
buf : 	u16 entry_ptr;
buf : 	u8 plcp[D11_PHY_HDR_LEN];
buf : 	u16 dur, sifs;
ifs; 
buf : 	uint i;
buf : 
buf : 	sifs = get_sifs(wlc->band);
ifs = get_sifs(wlc->band); 
buf : 
buf : 	rs_dflt = brcms_c_rateset_get_hwrs(wlc);
buf : 
buf : 	brcms_c_rateset_copy(rs_dflt, &rs);
buf : 	brcms_c_rateset_mcs_upd(&rs, wlc->stf->txstreams);
buf : 
buf : 	/*
buf : 	 * walk the phy rate table and update MAC core SHM
buf : 	 * basic rate table entries
buf : 	 */
buf : 	for (i = 0; i < rs.count; i++) {
for (i = 0; i < rs.count; i++) { 
buf : 		rate = rs.rates[i] & BRCMS_RATE_MASK;
buf : 
buf : 		entry_ptr = brcms_b_rate_shm_offset(wlc->hw, rate);
buf : 
buf : 		/* Calculate the Probe Response PLCP for the given rate */
for the given rate */ 
buf : 		brcms_c_compute_plcp(wlc, rate, frame_len, plcp);
buf : 
buf : 		/*
buf : 		 * Calculate the duration of the Probe Response
buf : 		 * frame plus SIFS for the MAC
for the MAC 
buf : 		 */
buf : 		dur = (u16) brcms_c_calc_frame_time(wlc, rate,
buf : 						BRCMS_LONG_PREAMBLE, frame_len);
buf : 		dur += sifs;
ifs; 
buf : 
buf : 		/* Update the SHM Rate Table entry Probe Response values */
buf : 		brcms_b_write_shm(wlc->hw, entry_ptr + M_RT_PRS_PLCP_POS,
buf : 			      (u16) (plcp[0] + (plcp[1] << 8)));
buf : 		brcms_b_write_shm(wlc->hw, entry_ptr + M_RT_PRS_PLCP_POS + 2,
buf : 			      (u16) (plcp[2] + (plcp[3] << 8)));
buf : 		brcms_b_write_shm(wlc->hw, entry_ptr + M_RT_PRS_DUR_POS, dur);
buf : 	}
buf : }
buf : 
buf : int brcms_c_get_header_len(void)
buf : {
buf : 	return TXOFF;
buf : }
buf : 
buf : static void brcms_c_beacon_write(struct brcms_c_info *wlc,
buf : 				 struct sk_buff *beacon, u16 tim_offset,
buf : 				 u16 dtim_period, bool bcn0, bool bcn1)
buf : {
buf : 	size_t len;
buf : 	struct ieee80211_tx_info *tx_info;
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	struct ieee80211_hw *ieee_hw = brcms_c_pub(wlc)->ieee_hw;
buf : 
buf : 	/* Get tx_info */
buf : 	tx_info = IEEE80211_SKB_CB(beacon);
buf : 
buf : 	len = min_t(size_t, beacon->len, BCN_TMPL_LEN);
buf : 	wlc->bcn_rspec = ieee80211_get_tx_rate(ieee_hw, tx_info)->hw_value;
buf : 
buf : 	brcms_c_compute_plcp(wlc, wlc->bcn_rspec,
buf : 			     len + FCS_LEN - D11_PHY_HDR_LEN, beacon->data);
buf : 
buf : 	/* "Regular" and 16 MBSS but not for 4 MBSS */
for 4 MBSS */ 
buf : 	/* Update the phytxctl for the beacon based on the rspec */
buf : 	brcms_c_beacon_phytxctl_txant_upd(wlc, wlc->bcn_rspec);
buf : 
buf : 	if (bcn0) {
if (bcn0) { 
buf : 		/* write the probe response into the template region */
buf : 		brcms_b_write_template_ram(wlc_hw, T_BCN0_TPL_BASE,
buf : 					    (len + 3) & ~3, beacon->data);
buf : 
buf : 		/* write beacon length to SCR */
buf : 		brcms_b_write_shm(wlc_hw, M_BCN0_FRM_BYTESZ, (u16) len);
buf : 	}
buf : 	if (bcn1) {
if (bcn1) { 
buf : 		/* write the probe response into the template region */
buf : 		brcms_b_write_template_ram(wlc_hw, T_BCN1_TPL_BASE,
buf : 					    (len + 3) & ~3, beacon->data);
buf : 
buf : 		/* write beacon length to SCR */
buf : 		brcms_b_write_shm(wlc_hw, M_BCN1_FRM_BYTESZ, (u16) len);
buf : 	}
buf : 
buf : 	if (tim_offset != 0) {
if (tim_offset != 0) { 
buf : 		brcms_b_write_shm(wlc_hw, M_TIMBPOS_INBEACON,
buf : 				  tim_offset + D11B_PHY_HDR_LEN);
buf : 		brcms_b_write_shm(wlc_hw, M_DOT11_DTIMPERIOD, dtim_period);
buf : 	} else {
buf : 		brcms_b_write_shm(wlc_hw, M_TIMBPOS_INBEACON,
buf : 				  len + D11B_PHY_HDR_LEN);
buf : 		brcms_b_write_shm(wlc_hw, M_DOT11_DTIMPERIOD, 0);
buf : 	}
buf : }
buf : 
buf : static void brcms_c_update_beacon_hw(struct brcms_c_info *wlc,
buf : 				     struct sk_buff *beacon, u16 tim_offset,
buf : 				     u16 dtim_period)
buf : {
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 
buf : 	/* Hardware beaconing for this config */
for this config */ 
buf : 	u32 both_valid = MCMD_BCN0VLD | MCMD_BCN1VLD;
buf : 
buf : 	/* Check if both templates are in use, if so sched. an interrupt
if both templates are in use, if so sched. an interrupt 
buf : 	 *      that will call back into this routine
buf : 	 */
buf : 	if ((bcma_read32(core, D11REGOFFS(maccommand)) & both_valid) == both_valid)
if ((bcma_read32(core, D11REGOFFS(maccommand)) & both_valid) == both_valid) 
buf : 		/* clear any previous status */
buf : 		bcma_write32(core, D11REGOFFS(macintstatus), MI_BCNTPL);
buf : 
buf : 	if (wlc->beacon_template_virgin) {
if (wlc->beacon_template_virgin) { 
buf : 		wlc->beacon_template_virgin = false;
buf : 		brcms_c_beacon_write(wlc, beacon, tim_offset, dtim_period, true,
buf : 				     true);
buf : 		/* mark beacon0 valid */
buf : 		bcma_set32(core, D11REGOFFS(maccommand), MCMD_BCN0VLD);
buf : 		return;
buf : 	}
buf : 
buf : 	/* Check that after scheduling the interrupt both of the
buf : 	 *      templates are still busy. if not clear the int. & remask
if not clear the int. & remask 
buf : 	 */
buf : 	if ((bcma_read32(core, D11REGOFFS(maccommand)) & both_valid) == both_valid) {
if ((bcma_read32(core, D11REGOFFS(maccommand)) & both_valid) == both_valid) { 
buf : 		wlc->defmacintmask |= MI_BCNTPL;
buf : 		return;
buf : 	}
buf : 
buf : 	if (!(bcma_read32(core, D11REGOFFS(maccommand)) & MCMD_BCN0VLD)) {
if (!(bcma_read32(core, D11REGOFFS(maccommand)) & MCMD_BCN0VLD)) { 
buf : 		brcms_c_beacon_write(wlc, beacon, tim_offset, dtim_period, true,
buf : 				     false);
buf : 		/* mark beacon0 valid */
buf : 		bcma_set32(core, D11REGOFFS(maccommand), MCMD_BCN0VLD);
buf : 		return;
buf : 	}
buf : 	if (!(bcma_read32(core, D11REGOFFS(maccommand)) & MCMD_BCN1VLD)) {
if (!(bcma_read32(core, D11REGOFFS(maccommand)) & MCMD_BCN1VLD)) { 
buf : 		brcms_c_beacon_write(wlc, beacon, tim_offset, dtim_period,
buf : 				     false, true);
buf : 		/* mark beacon0 valid */
buf : 		bcma_set32(core, D11REGOFFS(maccommand), MCMD_BCN1VLD);
buf : 		return;
buf : 	}
buf : 	return;
buf : }
buf : 
buf : /*
buf :  * Update all beacons for the system.
for the system. 
buf :  */
buf : void brcms_c_update_beacon(struct brcms_c_info *wlc)
buf : {
buf : 	struct brcms_bss_cfg *bsscfg = wlc->bsscfg;
buf : 
buf : 	if (wlc->pub->up && (bsscfg->type == BRCMS_TYPE_AP ||
if (wlc->pub->up && (bsscfg->type == BRCMS_TYPE_AP || 
buf : 			     bsscfg->type == BRCMS_TYPE_ADHOC)) {
buf : 		/* Clear the soft intmask */
buf : 		wlc->defmacintmask &= ~MI_BCNTPL;
buf : 		if (!wlc->beacon)
if (!wlc->beacon) 
buf : 			return;
buf : 		brcms_c_update_beacon_hw(wlc, wlc->beacon,
buf : 					 wlc->beacon_tim_offset,
buf : 					 wlc->beacon_dtim_period);
buf : 	}
buf : }
buf : 
buf : void brcms_c_set_new_beacon(struct brcms_c_info *wlc, struct sk_buff *beacon,
buf : 			    u16 tim_offset, u16 dtim_period)
buf : {
buf : 	if (!beacon)
if (!beacon) 
buf : 		return;
buf : 	if (wlc->beacon)
if (wlc->beacon) 
buf : 		dev_kfree_skb_any(wlc->beacon);
buf : 	wlc->beacon = beacon;
buf : 
buf : 	/* add PLCP */
buf : 	skb_push(wlc->beacon, D11_PHY_HDR_LEN);
buf : 	wlc->beacon_tim_offset = tim_offset;
buf : 	wlc->beacon_dtim_period = dtim_period;
buf : 	brcms_c_update_beacon(wlc);
buf : }
buf : 
buf : void brcms_c_set_new_probe_resp(struct brcms_c_info *wlc,
buf : 				struct sk_buff *probe_resp)
buf : {
buf : 	if (!probe_resp)
if (!probe_resp) 
buf : 		return;
buf : 	if (wlc->probe_resp)
if (wlc->probe_resp) 
buf : 		dev_kfree_skb_any(wlc->probe_resp);
buf : 	wlc->probe_resp = probe_resp;
buf : 
buf : 	/* add PLCP */
buf : 	skb_push(wlc->probe_resp, D11_PHY_HDR_LEN);
buf : 	brcms_c_update_probe_resp(wlc, false);
buf : }
buf : 
buf : void brcms_c_enable_probe_resp(struct brcms_c_info *wlc, bool enable)
buf : {
buf : 	/*
buf : 	 * prevent ucode from sending probe responses by setting the timeout
buf : 	 * to 1, it can not send it in that time frame.
buf : 	 */
buf : 	wlc->prb_resp_timeout = enable ? BRCMS_PRB_RESP_TIMEOUT : 1;
buf : 	brcms_b_write_shm(wlc->hw, M_PRS_MAXTIME, wlc->prb_resp_timeout);
buf : 	/* TODO: if (enable) => also deactivate receiving of probe request */
if (enable) => also deactivate receiving of probe request */ 
buf : }
buf : 
buf : /* Write ssid into shared memory */
buf : static void
buf : brcms_c_shm_ssid_upd(struct brcms_c_info *wlc, struct brcms_bss_cfg *cfg)
buf : {
buf : 	u8 *ssidptr = cfg->SSID;
buf : 	u16 base = M_SSID;
buf : 	u8 ssidbuf[IEEE80211_MAX_SSID_LEN];
buf : 
buf : 	/* padding the ssid with zero and copy it into shm */
buf : 	memset(ssidbuf, 0, IEEE80211_MAX_SSID_LEN);
buf : 	memcpy(ssidbuf, ssidptr, cfg->SSID_len);
buf : 
buf : 	brcms_c_copyto_shm(wlc, base, ssidbuf, IEEE80211_MAX_SSID_LEN);
buf : 	brcms_b_write_shm(wlc->hw, M_SSIDLEN, (u16) cfg->SSID_len);
buf : }
buf : 
buf : static void
buf : brcms_c_bss_update_probe_resp(struct brcms_c_info *wlc,
buf : 			      struct brcms_bss_cfg *cfg,
buf : 			      struct sk_buff *probe_resp,
buf : 			      bool suspend)
buf : {
buf : 	int len;
buf : 
buf : 	len = min_t(size_t, probe_resp->len, BCN_TMPL_LEN);
buf : 
buf : 	if (suspend)
if (suspend) 
buf : 		brcms_c_suspend_mac_and_wait(wlc);
buf : 
buf : 	/* write the probe response into the template region */
buf : 	brcms_b_write_template_ram(wlc->hw, T_PRS_TPL_BASE,
buf : 				    (len + 3) & ~3, probe_resp->data);
buf : 
buf : 	/* write the length of the probe response frame (+PLCP/-FCS) */
buf : 	brcms_b_write_shm(wlc->hw, M_PRB_RESP_FRM_LEN, (u16) len);
buf : 
buf : 	/* write the SSID and SSID length */
buf : 	brcms_c_shm_ssid_upd(wlc, cfg);
buf : 
buf : 	/*
buf : 	 * Write PLCP headers and durations for probe response frames
for probe response frames 
buf : 	 * at all rates. Use the actual frame length covered by the
buf : 	 * PLCP header for the call to brcms_c_mod_prb_rsp_rate_table()
for the call to brcms_c_mod_prb_rsp_rate_table() 
buf : 	 * by subtracting the PLCP len and adding the FCS.
buf : 	 */
buf : 	brcms_c_mod_prb_rsp_rate_table(wlc,
buf : 				      (u16)len + FCS_LEN - D11_PHY_HDR_LEN);
buf : 
buf : 	if (suspend)
if (suspend) 
buf : 		brcms_c_enable_mac(wlc);
buf : }
buf : 
buf : void brcms_c_update_probe_resp(struct brcms_c_info *wlc, bool suspend)
buf : {
buf : 	struct brcms_bss_cfg *bsscfg = wlc->bsscfg;
buf : 
buf : 	/* update AP or IBSS probe responses */
buf : 	if (wlc->pub->up && (bsscfg->type == BRCMS_TYPE_AP ||
if (wlc->pub->up && (bsscfg->type == BRCMS_TYPE_AP || 
buf : 			     bsscfg->type == BRCMS_TYPE_ADHOC)) {
buf : 		if (!wlc->probe_resp)
if (!wlc->probe_resp) 
buf : 			return;
buf : 		brcms_c_bss_update_probe_resp(wlc, bsscfg, wlc->probe_resp,
buf : 					      suspend);
buf : 	}
buf : }
buf : 
buf : int brcms_b_xmtfifo_sz_get(struct brcms_hardware *wlc_hw, uint fifo,
ifo_sz_get(struct brcms_hardware *wlc_hw, uint fifo, 
buf : 			   uint *blocks)
buf : {
buf : 	if (fifo >= NFIFO)
if (fifo >= NFIFO) 
buf : 		return -EINVAL;
buf : 
buf : 	*blocks = wlc_hw->xmtfifo_sz[fifo];
ifo_sz[fifo]; 
buf : 
buf : 	return 0;
buf : }
buf : 
buf : void
buf : brcms_c_set_addrmatch(struct brcms_c_info *wlc, int match_reg_offset,
buf : 		  const u8 *addr)
buf : {
buf : 	brcms_b_set_addrmatch(wlc->hw, match_reg_offset, addr);
buf : 	if (match_reg_offset == RCM_BSSID_OFFSET)
if (match_reg_offset == RCM_BSSID_OFFSET) 
buf : 		memcpy(wlc->bsscfg->BSSID, addr, ETH_ALEN);
buf : }
buf : 
buf : /*
buf :  * Flag 'scan in progress' to withhold dynamic phy calibration
buf :  */
buf : void brcms_c_scan_start(struct brcms_c_info *wlc)
buf : {
buf : 	wlc_phy_hold_upd(wlc->band->pi, PHY_HOLD_FOR_SCAN, true);
buf : }
buf : 
buf : void brcms_c_scan_stop(struct brcms_c_info *wlc)
buf : {
buf : 	wlc_phy_hold_upd(wlc->band->pi, PHY_HOLD_FOR_SCAN, false);
buf : }
buf : 
buf : void brcms_c_associate_upd(struct brcms_c_info *wlc, bool state)
buf : {
buf : 	wlc->pub->associated = state;
buf : }
buf : 
buf : /*
buf :  * When a remote STA/AP is removed by Mac80211, or when it can no longer accept
buf :  * AMPDU traffic, packets pending in hardware have to be invalidated so that
buf :  * when later on hardware releases them, they can be handled appropriately.
buf :  */
buf : void brcms_c_inval_dma_pkts(struct brcms_hardware *hw,
buf : 			       struct ieee80211_sta *sta,
buf : 			       void (*dma_callback_fn))
buf : {
buf : 	struct dma_pub *dmah;
buf : 	int i;
buf : 	for (i = 0; i < NFIFO; i++) {
for (i = 0; i < NFIFO; i++) { 
buf : 		dmah = hw->di[i];
buf : 		if (dmah != NULL)
if (dmah != NULL) 
buf : 			dma_walk_packets(dmah, dma_callback_fn, sta);
buf : 	}
buf : }
buf : 
buf : int brcms_c_get_curband(struct brcms_c_info *wlc)
buf : {
buf : 	return wlc->band->bandunit;
buf : }
buf : 
buf : bool brcms_c_tx_flush_completed(struct brcms_c_info *wlc)
buf : {
buf : 	int i;
buf : 
buf : 	/* Kick DMA to send any pending AMPDU */
buf : 	for (i = 0; i < ARRAY_SIZE(wlc->hw->di); i++)
for (i = 0; i < ARRAY_SIZE(wlc->hw->di); i++) 
buf : 		if (wlc->hw->di[i])
buf : 			dma_kick_tx(wlc->hw->di[i]);
buf : 
buf : 	return !brcms_txpktpendtot(wlc);
buf : }
buf : 
buf : void brcms_c_set_beacon_listen_interval(struct brcms_c_info *wlc, u8 interval)
buf : {
buf : 	wlc->bcn_li_bcn = interval;
buf : 	if (wlc->pub->up)
if (wlc->pub->up) 
buf : 		brcms_c_bcn_li_upd(wlc);
buf : }
buf : 
buf : u64 brcms_c_tsf_get(struct brcms_c_info *wlc)
buf : {
buf : 	u32 tsf_h, tsf_l;
buf : 	u64 tsf;
buf : 
buf : 	brcms_b_read_tsf(wlc->hw, &tsf_l, &tsf_h);
buf : 
buf : 	tsf = tsf_h;
buf : 	tsf <<= 32;
buf : 	tsf |= tsf_l;
buf : 
buf : 	return tsf;
buf : }
buf : 
buf : void brcms_c_tsf_set(struct brcms_c_info *wlc, u64 tsf)
buf : {
buf : 	u32 tsf_h, tsf_l;
buf : 
buf : 	brcms_c_time_lock(wlc);
buf : 
buf : 	tsf_l = tsf;
buf : 	tsf_h = (tsf >> 32);
buf : 
buf : 	/* read the tsf timer low, then high to get an atomic read */
buf : 	bcma_write32(wlc->hw->d11core, D11REGOFFS(tsf_timerlow), tsf_l);
buf : 	bcma_write32(wlc->hw->d11core, D11REGOFFS(tsf_timerhigh), tsf_h);
buf : 
buf : 	brcms_c_time_unlock(wlc);
buf : }
buf : 
buf : int brcms_c_set_tx_power(struct brcms_c_info *wlc, int txpwr)
buf : {
buf : 	uint qdbm;
buf : 
buf : 	/* Remove override bit and clip to max qdbm value */
buf : 	qdbm = min_t(uint, txpwr * BRCMS_TXPWR_DB_FACTOR, 0xff);
buf : 	return wlc_phy_txpower_set(wlc->band->pi, qdbm, false);
buf : }
buf : 
buf : int brcms_c_get_tx_power(struct brcms_c_info *wlc)
buf : {
buf : 	uint qdbm;
buf : 	bool override;
buf : 
buf : 	wlc_phy_txpower_get(wlc->band->pi, &qdbm, &override);
buf : 
buf : 	/* Return qdbm units */
buf : 	return (int)(qdbm / BRCMS_TXPWR_DB_FACTOR);
buf : }
buf : 
buf : /* Process received frames */
buf : /*
buf :  * Return true if more frames need to be processed. false otherwise.
if more frames need to be processed. false otherwise. 
buf :  * Param 'bound' indicates max. # frames to process before break out.
fore break out. 
buf :  */
buf : static void brcms_c_recv(struct brcms_c_info *wlc, struct sk_buff *p)
buf : {
buf : 	struct d11rxhdr *rxh;
buf : 	struct ieee80211_hdr *h;
buf : 	uint len;
buf : 	bool is_amsdu;
buf : 
buf : 	/* frame starts with rxhdr */
buf : 	rxh = (struct d11rxhdr *) (p->data);
buf : 
buf : 	/* strip off rxhdr */
buf : 	skb_pull(p, BRCMS_HWRXOFF);
buf : 
buf : 	/* MAC inserts 2 pad bytes for a4 headers or QoS or A-MSDU subframes */
for a4 headers or QoS or A-MSDU subframes */ 
buf : 	if (rxh->RxStatus1 & RXS_PBPRES) {
buf : 		if (p->len < 2) {
if (p->len < 2) { 
buf : 			brcms_err(wlc->hw->d11core,
buf : 				  "wl%d: recv: rcvd runt of len %d\n",
buf : 				  wlc->pub->unit, p->len);
buf : 			goto toss;
buf : 		}
buf : 		skb_pull(p, 2);
buf : 	}
buf : 
buf : 	h = (struct ieee80211_hdr *)(p->data + D11_PHY_HDR_LEN);
buf : 	len = p->len;
buf : 
buf : 	if (rxh->RxStatus1 & RXS_FCSERR) {
if (rxh->RxStatus1 & RXS_FCSERR) { 
buf : 		if (!(wlc->filter_flags & FIF_FCSFAIL))
buf : 			goto toss;
buf : 	}
buf : 
buf : 	/* check received pkt has at least frame control field */
buf : 	if (len < D11_PHY_HDR_LEN + sizeof(h->frame_control))
if (len < D11_PHY_HDR_LEN + sizeof(h->frame_control)) 
buf : 		goto toss;
buf : 
buf : 	/* not supporting A-MSDU */
buf : 	is_amsdu = rxh->RxStatus2 & RXS_AMSDU_MASK;
buf : 	if (is_amsdu)
if (is_amsdu) 
buf : 		goto toss;
buf : 
buf : 	brcms_c_recvctl(wlc, rxh, p);
buf : 	return;
buf : 
buf :  toss:
buf : 	brcmu_pkt_buf_free_skb(p);
buf : }
buf : 
buf : /* Process received frames */
buf : /*
buf :  * Return true if more frames need to be processed. false otherwise.
if more frames need to be processed. false otherwise. 
buf :  * Param 'bound' indicates max. # frames to process before break out.
fore break out. 
buf :  */
buf : static bool
buf : brcms_b_recv(struct brcms_hardware *wlc_hw, uint fifo, bool bound)
ifo, bool bound) 
buf : {
buf : 	struct sk_buff *p;
buf : 	struct sk_buff *next = NULL;
buf : 	struct sk_buff_head recv_frames;
buf : 
buf : 	uint n = 0;
buf : 	uint bound_limit = bound ? RXBND : -1;
buf : 	bool morepending = false;
buf : 
buf : 	skb_queue_head_init(&recv_frames);
buf : 
buf : 	/* gather received frames */
buf : 	do {
buf : 		/* !give others some time to run! */
buf : 		if (n >= bound_limit)
if (n >= bound_limit) 
buf : 			break;
buf : 
buf : 		morepending = dma_rx(wlc_hw->di[fifo], &recv_frames);
ifo], &recv_frames); 
buf : 		n++;
buf : 	} while (morepending);
while (morepending); 
buf : 
buf : 	/* post more rbufs */
buf : 	dma_rxfill(wlc_hw->di[fifo]);
ifo]); 
buf : 
buf : 	/* process each frame */
buf : 	skb_queue_walk_safe(&recv_frames, p, next) {
buf : 		struct d11rxhdr_le *rxh_le;
buf : 		struct d11rxhdr *rxh;
buf : 
buf : 		skb_unlink(p, &recv_frames);
buf : 		rxh_le = (struct d11rxhdr_le *)p->data;
buf : 		rxh = (struct d11rxhdr *)p->data;
buf : 
buf : 		/* fixup rx header endianness */
buf : 		rxh->RxFrameSize = le16_to_cpu(rxh_le->RxFrameSize);
buf : 		rxh->PhyRxStatus_0 = le16_to_cpu(rxh_le->PhyRxStatus_0);
buf : 		rxh->PhyRxStatus_1 = le16_to_cpu(rxh_le->PhyRxStatus_1);
buf : 		rxh->PhyRxStatus_2 = le16_to_cpu(rxh_le->PhyRxStatus_2);
buf : 		rxh->PhyRxStatus_3 = le16_to_cpu(rxh_le->PhyRxStatus_3);
buf : 		rxh->PhyRxStatus_4 = le16_to_cpu(rxh_le->PhyRxStatus_4);
buf : 		rxh->PhyRxStatus_5 = le16_to_cpu(rxh_le->PhyRxStatus_5);
buf : 		rxh->RxStatus1 = le16_to_cpu(rxh_le->RxStatus1);
buf : 		rxh->RxStatus2 = le16_to_cpu(rxh_le->RxStatus2);
buf : 		rxh->RxTSFTime = le16_to_cpu(rxh_le->RxTSFTime);
buf : 		rxh->RxChan = le16_to_cpu(rxh_le->RxChan);
buf : 
buf : 		brcms_c_recv(wlc_hw->wlc, p);
buf : 	}
buf : 
buf : 	return morepending;
buf : }
buf : 
buf : /* second-level interrupt processing
buf :  *   Return true if another dpc needs to be re-scheduled. false otherwise.
if another dpc needs to be re-scheduled. false otherwise. 
buf :  *   Param 'bounded' indicates if applicable loops should be bounded.
buf :  */
buf : bool brcms_c_dpc(struct brcms_c_info *wlc, bool bounded)
buf : {
buf : 	u32 macintstatus;
buf : 	struct brcms_hardware *wlc_hw = wlc->hw;
buf : 	struct bcma_device *core = wlc_hw->d11core;
buf : 
buf : 	if (brcms_deviceremoved(wlc)) {
if (brcms_deviceremoved(wlc)) { 
buf : 		brcms_err(core, "wl%d: %s: dead chip\n", wlc_hw->unit,
buf : 			  __func__);
buf : 		brcms_down(wlc->wl);
buf : 		return false;
buf : 	}
buf : 
buf : 	/* grab and clear the saved software intstatus bits */
buf : 	macintstatus = wlc->macintstatus;
buf : 	wlc->macintstatus = 0;
buf : 
buf : 	brcms_dbg_int(core, "wl%d: macintstatus 0x%x\n",
buf : 		      wlc_hw->unit, macintstatus);
buf : 
buf : 	WARN_ON(macintstatus & MI_PRQ); /* PRQ Interrupt in non-MBSS */
buf : 
buf : 	/* tx status */
buf : 	if (macintstatus & MI_TFS) {
if (macintstatus & MI_TFS) { 
buf : 		bool fatal;
buf : 		if (brcms_b_txstatus(wlc->hw, bounded, &fatal))
if (brcms_b_txstatus(wlc->hw, bounded, &fatal)) 
buf : 			wlc->macintstatus |= MI_TFS;
buf : 		if (fatal) {
if (fatal) { 
buf : 			brcms_err(core, "MI_TFS: fatal\n");
buf : 			goto fatal;
buf : 		}
buf : 	}
buf : 
buf : 	if (macintstatus & (MI_TBTT | MI_DTIM_TBTT))
if (macintstatus & (MI_TBTT | MI_DTIM_TBTT)) 
buf : 		brcms_c_tbtt(wlc);
buf : 
buf : 	/* ATIM window end */
buf : 	if (macintstatus & MI_ATIMWINEND) {
if (macintstatus & MI_ATIMWINEND) { 
buf : 		brcms_dbg_info(core, "end of ATIM window\n");
buf : 		bcma_set32(core, D11REGOFFS(maccommand), wlc->qvalid);
buf : 		wlc->qvalid = 0;
buf : 	}
buf : 
buf : 	/*
buf : 	 * received data or control frame, MI_DMAINT is
buf : 	 * indication of RX_FIFO interrupt
buf : 	 */
buf : 	if (macintstatus & MI_DMAINT)
if (macintstatus & MI_DMAINT) 
buf : 		if (brcms_b_recv(wlc_hw, RX_FIFO, bounded))
buf : 			wlc->macintstatus |= MI_DMAINT;
buf : 
buf : 	/* noise sample collected */
buf : 	if (macintstatus & MI_BG_NOISE)
if (macintstatus & MI_BG_NOISE) 
buf : 		wlc_phy_noise_sample_intr(wlc_hw->band->pi);
buf : 
buf : 	if (macintstatus & MI_GP0) {
if (macintstatus & MI_GP0) { 
buf : 		brcms_err(core, "wl%d: PSM microcode watchdog fired at %d "
buf : 			  "(seconds). Resetting.\n", wlc_hw->unit, wlc_hw->now);
buf : 
buf : 		printk_once("%s : PSM Watchdog, chipid 0x%x, chiprev 0x%x\n",
buf : 			    __func__, ai_get_chip_id(wlc_hw->sih),
buf : 			    ai_get_chiprev(wlc_hw->sih));
buf : 		brcms_fatal_error(wlc_hw->wlc->wl);
buf : 	}
buf : 
buf : 	/* gptimer timeout */
buf : 	if (macintstatus & MI_TO)
if (macintstatus & MI_TO) 
buf : 		bcma_write32(core, D11REGOFFS(gptimer), 0);
buf : 
buf : 	if (macintstatus & MI_RFDISABLE) {
if (macintstatus & MI_RFDISABLE) { 
buf : 		brcms_dbg_info(core, "wl%d: BMAC Detected a change on the"
buf : 			       " RF Disable Input\n", wlc_hw->unit);
buf : 		brcms_rfkill_set_hw_state(wlc->wl);
buf : 	}
buf : 
buf : 	/* BCN template is available */
buf : 	if (macintstatus & MI_BCNTPL)
if (macintstatus & MI_BCNTPL) 
buf : 		brcms_c_update_beacon(wlc);
buf : 
buf : 	/* it isn't done and needs to be resched if macintstatus is non-zero */
if macintstatus is non-zero */ 
buf : 	return wlc->macintstatus != 0;
buf : 
buf :  fatal:
buf : 	brcms_fatal_error(wlc_hw->wlc->wl);
buf : 	return wlc->macintstatus != 0;
buf : }
buf : 
buf : void brcms_c_init(struct brcms_c_info *wlc, bool mute_tx)
buf : {
buf : 	struct bcma_device *core = wlc->hw->d11core;
buf : 	struct ieee80211_channel *ch = wlc->pub->ieee_hw->conf.chandef.chan;
buf : 	u16 chanspec;
buf : 
buf : 	brcms_dbg_info(core, "wl%d\n", wlc->pub->unit);
buf : 
buf : 	chanspec = ch20mhz_chspec(ch->hw_value);
buf : 
buf : 	brcms_b_init(wlc->hw, chanspec);
buf : 
buf : 	/* update beacon listen interval */
buf : 	brcms_c_bcn_li_upd(wlc);
buf : 
buf : 	/* write ethernet address to core */
buf : 	brcms_c_set_mac(wlc->bsscfg);
buf : 	brcms_c_set_bssid(wlc->bsscfg);
buf : 
buf : 	/* Update tsf_cfprep if associated and up */
if associated and up */ 
buf : 	if (wlc->pub->associated && wlc->pub->up) {
buf : 		u32 bi;
buf : 
buf : 		/* get beacon period and convert to uS */
buf : 		bi = wlc->bsscfg->current_bss->beacon_period << 10;
buf : 		/*
buf : 		 * update since init path would reset
buf : 		 * to default value
buf : 		 */
buf : 		bcma_write32(core, D11REGOFFS(tsf_cfprep),
buf : 			     bi << CFPREP_CBI_SHIFT);
buf : 
buf : 		/* Update maccontrol PM related bits */
buf : 		brcms_c_set_ps_ctrl(wlc);
buf : 	}
buf : 
buf : 	brcms_c_bandinit_ordered(wlc, chanspec);
buf : 
buf : 	/* init probe response timeout */
buf : 	brcms_b_write_shm(wlc->hw, M_PRS_MAXTIME, wlc->prb_resp_timeout);
buf : 
buf : 	/* init max burst txop (framebursting) */
buf : 	brcms_b_write_shm(wlc->hw, M_MBURST_TXOP,
buf : 		      (wlc->
buf : 		       _rifs ? (EDCF_AC_VO_TXOP_AP << 5) : MAXFRAMEBURST_TXOP));
ifs ? (EDCF_AC_VO_TXOP_AP << 5) : MAXFRAMEBURST_TXOP)); 
buf : 
buf : 	/* initialize maximum allowed duty cycle */
buf : 	brcms_c_duty_cycle_set(wlc, wlc->tx_duty_cycle_ofdm, true, true);
buf : 	brcms_c_duty_cycle_set(wlc, wlc->tx_duty_cycle_cck, false, true);
buf : 
buf : 	/*
buf : 	 * Update some shared memory locations related to
buf : 	 * max AMPDU size allowed to received
buf : 	 */
buf : 	brcms_c_ampdu_shm_upd(wlc->ampdu);
buf : 
buf : 	/* band-specific inits */
ific inits */ 
buf : 	brcms_c_bsinit(wlc);
buf : 
buf : 	/* Enable EDCF mode (while the MAC is suspended) */
while the MAC is suspended) */ 
buf : 	bcma_set16(core, D11REGOFFS(ifs_ctl), IFS_USEEDCF);
buf : 	brcms_c_edcf_setparams(wlc, false);
buf : 
buf : 	/* read the ucode version if we have not yet done so */
if we have not yet done so */ 
buf : 	if (wlc->ucode_rev == 0) {
buf : 		u16 rev;
buf : 		u16 patch;
buf : 
buf : 		rev = brcms_b_read_shm(wlc->hw, M_BOM_REV_MAJOR);
buf : 		patch = brcms_b_read_shm(wlc->hw, M_BOM_REV_MINOR);
buf : 		wlc->ucode_rev = (rev << NBITS(u16)) | patch;
buf : 		snprintf(wlc->wiphy->fw_version,
buf : 			 sizeof(wlc->wiphy->fw_version), "%u.%u", rev, patch);
buf : 	}
buf : 
buf : 	/* ..now really unleash hell (allow the MAC out of suspend) */
buf : 	brcms_c_enable_mac(wlc);
buf : 
buf : 	/* suspend the tx fifos and mute the phy for preism cac time */
ifos and mute the phy for preism cac time */ 
buf : 	if (mute_tx)
buf : 		brcms_b_mute(wlc->hw, true);
buf : 
buf : 	/* enable the RF Disable Delay timer */
buf : 	bcma_write32(core, D11REGOFFS(rfdisabledly), RFDISABLE_DEFAULT);
buf : 
buf : 	/*
buf : 	 * Initialize WME parameters; if they haven't been set by some other
if they haven't been set by some other 
buf : 	 * mechanism (IOVar, etc) then read them from the hardware.
buf : 	 */
buf : 	if (GFIELD(wlc->wme_retries[0], EDCF_SHORT) == 0) {
if (GFIELD(wlc->wme_retries[0], EDCF_SHORT) == 0) { 
buf : 		/* Uninitialized; read from HW */
buf : 		int ac;
buf : 
buf : 		for (ac = 0; ac < IEEE80211_NUM_ACS; ac++)
for (ac = 0; ac < IEEE80211_NUM_ACS; ac++) 
buf : 			wlc->wme_retries[ac] =
buf : 			    brcms_b_read_shm(wlc->hw, M_AC_TXLMT_ADDR(ac));
buf : 	}
buf : }
buf : 
buf : /*
buf :  * The common driver entry routine. Error codes should be unique
buf :  */
buf : struct brcms_c_info *
buf : brcms_c_attach(struct brcms_info *wl, struct bcma_device *core, uint unit,
buf : 	       bool piomode, uint *perr)
buf : {
buf : 	struct brcms_c_info *wlc;
buf : 	uint err = 0;
buf : 	uint i, j;
buf : 	struct brcms_pub *pub;
buf : 
buf : 	/* allocate struct brcms_c_info state and its substructures */
buf : 	wlc = brcms_c_attach_malloc(unit, &err, 0);
buf : 	if (wlc == NULL)
if (wlc == NULL) 
buf : 		goto fail;
buf : 	wlc->wiphy = wl->wiphy;
buf : 	pub = wlc->pub;
buf : 
buf : #if defined(DEBUG)
if defined(DEBUG) 
buf : 	wlc_info_dbg = wlc;
buf : #endif
if 
buf : 
buf : 	wlc->band = wlc->bandstate[0];
buf : 	wlc->core = wlc->corestate;
buf : 	wlc->wl = wl;
buf : 	pub->unit = unit;
buf : 	pub->_piomode = piomode;
buf : 	wlc->bandinit_pending = false;
buf : 	wlc->beacon_template_virgin = true;
buf : 
buf : 	/* populate struct brcms_c_info with default values  */
buf : 	brcms_c_info_init(wlc, unit);
buf : 
buf : 	/* update sta/ap related parameters */
buf : 	brcms_c_ap_upd(wlc);
buf : 
buf : 	/*
buf : 	 * low level attach steps(all hw accesses go
buf : 	 * inside, no more in rest of the attach)
buf : 	 */
buf : 	err = brcms_b_attach(wlc, core, unit, piomode);
buf : 	if (err)
if (err) 
buf : 		goto fail;
buf : 
buf : 	brcms_c_protection_upd(wlc, BRCMS_PROT_N_PAM_OVR, OFF);
buf : 
buf : 	pub->phy_11ncapable = BRCMS_PHY_11N_CAP(wlc->band);
buf : 
buf : 	/* disable allowed duty cycle */
buf : 	wlc->tx_duty_cycle_ofdm = 0;
buf : 	wlc->tx_duty_cycle_cck = 0;
buf : 
buf : 	brcms_c_stf_phy_chain_calc(wlc);
buf : 
buf : 	/* txchain 1: txant 0, txchain 2: txant 1 */
buf : 	if (BRCMS_ISNPHY(wlc->band) && (wlc->stf->txstreams == 1))
if (BRCMS_ISNPHY(wlc->band) && (wlc->stf->txstreams == 1)) 
buf : 		wlc->stf->txant = wlc->stf->hw_txchain - 1;
buf : 
buf : 	/* push to BMAC driver */
buf : 	wlc_phy_stf_chain_init(wlc->band->pi, wlc->stf->hw_txchain,
buf : 			       wlc->stf->hw_rxchain);
buf : 
buf : 	/* pull up some info resulting from the low attach */
buf : 	for (i = 0; i < NFIFO; i++)
for (i = 0; i < NFIFO; i++) 
buf : 		wlc->core->txavail[i] = wlc->hw->txavail[i];
buf : 
buf : 	memcpy(&wlc->perm_etheraddr, &wlc->hw->etheraddr, ETH_ALEN);
buf : 	memcpy(&pub->cur_etheraddr, &wlc->hw->etheraddr, ETH_ALEN);
buf : 
buf : 	for (j = 0; j < wlc->pub->_nbands; j++) {
for (j = 0; j < wlc->pub->_nbands; j++) { 
buf : 		wlc->band = wlc->bandstate[j];
buf : 
buf : 		if (!brcms_c_attach_stf_ant_init(wlc)) {
if (!brcms_c_attach_stf_ant_init(wlc)) { 
buf : 			err = 24;
buf : 			goto fail;
buf : 		}
buf : 
buf : 		/* default contention windows size limits */
buf : 		wlc->band->CWmin = APHY_CWMIN;
buf : 		wlc->band->CWmax = PHY_CWMAX;
buf : 
buf : 		/* init gmode value */
buf : 		if (wlc->band->bandtype == BRCM_BAND_2G) {
if (wlc->band->bandtype == BRCM_BAND_2G) { 
buf : 			wlc->band->gmode = GMODE_AUTO;
buf : 			brcms_c_protection_upd(wlc, BRCMS_PROT_G_USER,
buf : 					   wlc->band->gmode);
buf : 		}
buf : 
buf : 		/* init _n_enab supported mode */
buf : 		if (BRCMS_PHY_11N_CAP(wlc->band)) {
if (BRCMS_PHY_11N_CAP(wlc->band)) { 
buf : 			pub->_n_enab = SUPPORT_11N;
buf : 			brcms_c_protection_upd(wlc, BRCMS_PROT_N_USER,
buf : 						   ((pub->_n_enab ==
buf : 						     SUPPORT_11N) ? WL_11N_2x2 :
buf : 						    WL_11N_3x3));
buf : 		}
buf : 
buf : 		/* init per-band default rateset, depend on band->gmode */
buf : 		brcms_default_rateset(wlc, &wlc->band->defrateset);
buf : 
buf : 		/* fill in hw_rateset */
buf : 		brcms_c_rateset_filter(&wlc->band->defrateset,
buf : 				   &wlc->band->hw_rateset, false,
buf : 				   BRCMS_RATES_CCK_OFDM, BRCMS_RATE_MASK,
buf : 				   (bool) (wlc->pub->_n_enab & SUPPORT_11N));
buf : 	}
buf : 
buf : 	/*
buf : 	 * update antenna config due to
buf : 	 * wlc->stf->txant/txchain/ant_rx_ovr change
buf : 	 */
buf : 	brcms_c_stf_phy_txant_upd(wlc);
buf : 
buf : 	/* attach each modules */
buf : 	err = brcms_c_attach_module(wlc);
buf : 	if (err != 0)
if (err != 0) 
buf : 		goto fail;
buf : 
buf : 	if (!brcms_c_timers_init(wlc, unit)) {
if (!brcms_c_timers_init(wlc, unit)) { 
buf : 		wiphy_err(wl->wiphy, "wl%d: %s: init_timer failed\n", unit,
buf : 			  __func__);
buf : 		err = 32;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	/* depend on rateset, gmode */
buf : 	wlc->cmi = brcms_c_channel_mgr_attach(wlc);
buf : 	if (!wlc->cmi) {
if (!wlc->cmi) { 
buf : 		wiphy_err(wl->wiphy, "wl%d: %s: channel_mgr_attach failed"
buf : 			  "\n", unit, __func__);
buf : 		err = 33;
buf : 		goto fail;
buf : 	}
buf : 
buf : 	/* init default when all parameters are ready, i.e. ->rateset */
buf : 	brcms_c_bss_default_init(wlc);
buf : 
buf : 	/*
buf : 	 * Complete the wlc default state initializations..
buf : 	 */
buf : 
buf : 	wlc->bsscfg->wlc = wlc;
buf : 
buf : 	wlc->mimoft = FT_HT;
buf : 	wlc->mimo_40txbw = AUTO;
buf : 	wlc->ofdm_40txbw = AUTO;
buf : 	wlc->cck_40txbw = AUTO;
buf : 	brcms_c_update_mimo_band_bwcap(wlc, BRCMS_N_BW_20IN2G_40IN5G);
buf : 
buf : 	/* Set default values of SGI */
buf : 	if (BRCMS_SGI_CAP_PHY(wlc)) {
if (BRCMS_SGI_CAP_PHY(wlc)) { 
buf : 		brcms_c_ht_update_sgi_rx(wlc, (BRCMS_N_SGI_20 |
buf : 					       BRCMS_N_SGI_40));
buf : 	} else if (BRCMS_ISSSLPNPHY(wlc->band)) {
if (BRCMS_ISSSLPNPHY(wlc->band)) { 
buf : 		brcms_c_ht_update_sgi_rx(wlc, (BRCMS_N_SGI_20 |
buf : 					       BRCMS_N_SGI_40));
buf : 	} else {
buf : 		brcms_c_ht_update_sgi_rx(wlc, 0);
buf : 	}
buf : 
buf : 	brcms_b_antsel_set(wlc->hw, wlc->asi->antsel_avail);
buf : 
buf : 	if (perr)
if (perr) 
buf : 		*perr = 0;
buf : 
buf : 	return wlc;
buf : 
buf :  fail:
buf : 	wiphy_err(wl->wiphy, "wl%d: %s: failed with err %d\n",
buf : 		  unit, __func__, err);
buf : 	if (wlc)
if (wlc) 
buf : 		brcms_c_detach(wlc);
buf : 
buf : 	if (perr)
if (perr) 
buf : 		*perr = err;
buf : 	return NULL;
buf : }
file : ./test/kernel/drivers/net/wireless/libertas_tf/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  *  Copyright (C) 2008, cozybit Inc.
buf :  *  Copyright (C) 2003-2006, Marvell International Ltd.
buf :  *
buf :  *  This program is free software; you can redistribute it and/or modify
ify 
buf :  *  it under the terms of the GNU General Public License as published by
buf :  *  the Free Software Foundation; either version 2 of the License, or (at
buf :  *  your option) any later version.
buf :  */
buf : #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
buf : 
buf : #include <linux/hardirq.h>
buf : #include <linux/slab.h>
buf : 
buf : #include <linux/etherdevice.h>
buf : #include <linux/module.h>
buf : #include "libertas_tf.h"
buf : 
buf : #define DRIVER_RELEASE_VERSION "004.p0"
buf : /* thinfirm version: 5.132.X.pX */
buf : #define LBTF_FW_VER_MIN		0x05840300
buf : #define LBTF_FW_VER_MAX		0x0584ffff
buf : #define QOS_CONTROL_LEN		2
buf : 
buf : /* Module parameters */
buf : unsigned int lbtf_debug;
buf : EXPORT_SYMBOL_GPL(lbtf_debug);
buf : module_param_named(libertas_tf_debug, lbtf_debug, int, 0644);
buf : 
buf : static const char lbtf_driver_version[] = "THINFIRM-USB8388-" DRIVER_RELEASE_VERSION
buf : #ifdef DEBUG
ifdef DEBUG 
buf : 	"-dbg"
buf : #endif
if 
buf : 	"";
buf : 
buf : struct workqueue_struct *lbtf_wq;
buf : 
buf : static const struct ieee80211_channel lbtf_channels[] = {
buf : 	{ .center_freq = 2412, .hw_value = 1 },
buf : 	{ .center_freq = 2417, .hw_value = 2 },
buf : 	{ .center_freq = 2422, .hw_value = 3 },
buf : 	{ .center_freq = 2427, .hw_value = 4 },
buf : 	{ .center_freq = 2432, .hw_value = 5 },
buf : 	{ .center_freq = 2437, .hw_value = 6 },
buf : 	{ .center_freq = 2442, .hw_value = 7 },
buf : 	{ .center_freq = 2447, .hw_value = 8 },
buf : 	{ .center_freq = 2452, .hw_value = 9 },
buf : 	{ .center_freq = 2457, .hw_value = 10 },
buf : 	{ .center_freq = 2462, .hw_value = 11 },
buf : 	{ .center_freq = 2467, .hw_value = 12 },
buf : 	{ .center_freq = 2472, .hw_value = 13 },
buf : 	{ .center_freq = 2484, .hw_value = 14 },
buf : };
buf : 
buf : /* This table contains the hardware specific values for the modulation rates. */
ific values for the modulation rates. */ 
buf : static const struct ieee80211_rate lbtf_rates[] = {
buf : 	{ .bitrate = 10,
buf : 	  .hw_value = 0, },
buf : 	{ .bitrate = 20,
buf : 	  .hw_value = 1,
buf : 	  .flags = IEEE80211_RATE_SHORT_PREAMBLE },
buf : 	{ .bitrate = 55,
buf : 	  .hw_value = 2,
buf : 	  .flags = IEEE80211_RATE_SHORT_PREAMBLE },
buf : 	{ .bitrate = 110,
buf : 	  .hw_value = 3,
buf : 	  .flags = IEEE80211_RATE_SHORT_PREAMBLE },
buf : 	{ .bitrate = 60,
buf : 	  .hw_value = 5,
buf : 	  .flags = 0 },
buf : 	{ .bitrate = 90,
buf : 	  .hw_value = 6,
buf : 	  .flags = 0 },
buf : 	{ .bitrate = 120,
buf : 	  .hw_value = 7,
buf : 	  .flags = 0 },
buf : 	{ .bitrate = 180,
buf : 	  .hw_value = 8,
buf : 	  .flags = 0 },
buf : 	{ .bitrate = 240,
buf : 	  .hw_value = 9,
buf : 	  .flags = 0 },
buf : 	{ .bitrate = 360,
buf : 	  .hw_value = 10,
buf : 	  .flags = 0 },
buf : 	{ .bitrate = 480,
buf : 	  .hw_value = 11,
buf : 	  .flags = 0 },
buf : 	{ .bitrate = 540,
buf : 	  .hw_value = 12,
buf : 	  .flags = 0 },
buf : };
buf : 
buf : static void lbtf_cmd_work(struct work_struct *work)
buf : {
buf : 	struct lbtf_private *priv = container_of(work, struct lbtf_private,
buf : 					 cmd_work);
buf : 
buf : 	lbtf_deb_enter(LBTF_DEB_CMD);
buf : 
buf : 	spin_lock_irq(&priv->driver_lock);
buf : 	/* command response? */
buf : 	if (priv->cmd_response_rxed) {
if (priv->cmd_response_rxed) { 
buf : 		priv->cmd_response_rxed = 0;
buf : 		spin_unlock_irq(&priv->driver_lock);
buf : 		lbtf_process_rx_command(priv);
buf : 		spin_lock_irq(&priv->driver_lock);
buf : 	}
buf : 
buf : 	if (priv->cmd_timed_out && priv->cur_cmd) {
if (priv->cmd_timed_out && priv->cur_cmd) { 
buf : 		struct cmd_ctrl_node *cmdnode = priv->cur_cmd;
buf : 
buf : 		if (++priv->nr_retries > 10) {
if (++priv->nr_retries > 10) { 
buf : 			lbtf_complete_command(priv, cmdnode,
buf : 					      -ETIMEDOUT);
buf : 			priv->nr_retries = 0;
buf : 		} else {
buf : 			priv->cur_cmd = NULL;
buf : 
buf : 			/* Stick it back at the _top_ of the pending
buf : 			 * queue for immediate resubmission */
for immediate resubmission */ 
buf : 			list_add(&cmdnode->list, &priv->cmdpendingq);
buf : 		}
buf : 	}
buf : 	priv->cmd_timed_out = 0;
buf : 	spin_unlock_irq(&priv->driver_lock);
buf : 
buf : 	if (!priv->fw_ready) {
if (!priv->fw_ready) { 
buf : 		lbtf_deb_leave_args(LBTF_DEB_CMD, "fw not ready");
buf : 		return;
buf : 	}
buf : 
buf : 	/* Execute the next command */
buf : 	if (!priv->cur_cmd)
if (!priv->cur_cmd) 
buf : 		lbtf_execute_next_command(priv);
buf : 
buf : 	lbtf_deb_leave(LBTF_DEB_CMD);
buf : }
buf : 
buf : /**
buf :  *  lbtf_setup_firmware: initialize firmware.
buf :  *
buf :  *  @priv    A pointer to struct lbtf_private structure
buf :  *
buf :  *  Returns: 0 on success.
buf :  */
buf : static int lbtf_setup_firmware(struct lbtf_private *priv)
buf : {
buf : 	int ret = -1;
buf : 
buf : 	lbtf_deb_enter(LBTF_DEB_FW);
buf : 	/*
buf : 	 * Read priv address from HW
buf : 	 */
buf : 	memset(priv->current_addr, 0xff, ETH_ALEN);
buf : 	ret = lbtf_update_hw_spec(priv);
buf : 	if (ret) {
if (ret) { 
buf : 		ret = -1;
buf : 		goto done;
buf : 	}
buf : 
buf : 	lbtf_set_mac_control(priv);
buf : 	lbtf_set_radio_control(priv);
buf : 
buf : 	ret = 0;
buf : done:
buf : 	lbtf_deb_leave_args(LBTF_DEB_FW, "ret: %d", ret);
buf : 	return ret;
buf : }
buf : 
buf : /**
buf :  *  This function handles the timeout of command sending.
buf :  *  It will re-send the same command again.
buf :  */
buf : static void command_timer_fn(unsigned long data)
buf : {
buf : 	struct lbtf_private *priv = (struct lbtf_private *)data;
buf : 	unsigned long flags;
buf : 	lbtf_deb_enter(LBTF_DEB_CMD);
buf : 
buf : 	spin_lock_irqsave(&priv->driver_lock, flags);
buf : 
buf : 	if (!priv->cur_cmd) {
if (!priv->cur_cmd) { 
buf : 		printk(KERN_DEBUG "libertastf: command timer expired; "
buf : 				  "no pending command\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	printk(KERN_DEBUG "libertas: command %x timed out\n",
buf : 		le16_to_cpu(priv->cur_cmd->cmdbuf->command));
buf : 
buf : 	priv->cmd_timed_out = 1;
buf : 	queue_work(lbtf_wq, &priv->cmd_work);
buf : out:
buf : 	spin_unlock_irqrestore(&priv->driver_lock, flags);
buf : 	lbtf_deb_leave(LBTF_DEB_CMD);
buf : }
buf : 
buf : static int lbtf_init_adapter(struct lbtf_private *priv)
buf : {
buf : 	lbtf_deb_enter(LBTF_DEB_MAIN);
buf : 	memset(priv->current_addr, 0xff, ETH_ALEN);
buf : 	mutex_init(&priv->lock);
buf : 
buf : 	priv->vif = NULL;
if = NULL; 
buf : 	setup_timer(&priv->command_timer, command_timer_fn,
buf : 		(unsigned long)priv);
buf : 
buf : 	INIT_LIST_HEAD(&priv->cmdfreeq);
buf : 	INIT_LIST_HEAD(&priv->cmdpendingq);
buf : 
buf : 	spin_lock_init(&priv->driver_lock);
buf : 
buf : 	/* Allocate the command buffers */
buf : 	if (lbtf_allocate_cmd_buffer(priv))
if (lbtf_allocate_cmd_buffer(priv)) 
buf : 		return -1;
buf : 
buf : 	lbtf_deb_leave(LBTF_DEB_MAIN);
buf : 	return 0;
buf : }
buf : 
buf : static void lbtf_free_adapter(struct lbtf_private *priv)
buf : {
buf : 	lbtf_deb_enter(LBTF_DEB_MAIN);
buf : 	lbtf_free_cmd_buffer(priv);
buf : 	del_timer(&priv->command_timer);
buf : 	lbtf_deb_leave(LBTF_DEB_MAIN);
buf : }
buf : 
buf : static void lbtf_op_tx(struct ieee80211_hw *hw,
buf : 		       struct ieee80211_tx_control *control,
buf : 		       struct sk_buff *skb)
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 
buf : 	priv->skb_to_tx = skb;
buf : 	queue_work(lbtf_wq, &priv->tx_work);
buf : 	/*
buf : 	 * queue will be restarted when we receive transmission feedback if
if 
buf : 	 * there are no buffered multicast frames to send
buf : 	 */
buf : 	ieee80211_stop_queues(priv->hw);
buf : }
buf : 
buf : static void lbtf_tx_work(struct work_struct *work)
buf : {
buf : 	struct lbtf_private *priv = container_of(work, struct lbtf_private,
buf : 					 tx_work);
buf : 	unsigned int len;
buf : 	struct ieee80211_tx_info *info;
buf : 	struct txpd *txpd;
buf : 	struct sk_buff *skb = NULL;
buf : 	int err;
buf : 
buf : 	lbtf_deb_enter(LBTF_DEB_MACOPS | LBTF_DEB_TX);
buf : 
buf : 	if ((priv->vif->type == NL80211_IFTYPE_AP) &&
if ((priv->vif->type == NL80211_IFTYPE_AP) && 
buf : 	    (!skb_queue_empty(&priv->bc_ps_buf)))
buf : 		skb = skb_dequeue(&priv->bc_ps_buf);
buf : 	else if (priv->skb_to_tx) {
if (priv->skb_to_tx) { 
buf : 		skb = priv->skb_to_tx;
buf : 		priv->skb_to_tx = NULL;
buf : 	} else {
buf : 		lbtf_deb_leave(LBTF_DEB_MACOPS | LBTF_DEB_TX);
buf : 		return;
buf : 	}
buf : 
buf : 	len = skb->len;
buf : 	info  = IEEE80211_SKB_CB(skb);
buf : 	txpd = (struct txpd *)  skb_push(skb, sizeof(struct txpd));
buf : 
buf : 	if (priv->surpriseremoved) {
if (priv->surpriseremoved) { 
buf : 		dev_kfree_skb_any(skb);
buf : 		lbtf_deb_leave(LBTF_DEB_MACOPS | LBTF_DEB_TX);
buf : 		return;
buf : 	}
buf : 
buf : 	memset(txpd, 0, sizeof(struct txpd));
buf : 	/* Activate per-packet rate selection */
buf : 	txpd->tx_control |= cpu_to_le32(MRVL_PER_PACKET_RATE |
buf : 			     ieee80211_get_tx_rate(priv->hw, info)->hw_value);
buf : 
buf : 	/* copy destination address from 802.11 header */
buf : 	memcpy(txpd->tx_dest_addr_high, skb->data + sizeof(struct txpd) + 4,
buf : 		ETH_ALEN);
buf : 	txpd->tx_packet_length = cpu_to_le16(len);
buf : 	txpd->tx_packet_location = cpu_to_le32(sizeof(struct txpd));
buf : 	lbtf_deb_hex(LBTF_DEB_TX, "TX Data", skb->data, min_t(unsigned int, skb->len, 100));
buf : 	BUG_ON(priv->tx_skb);
buf : 	spin_lock_irq(&priv->driver_lock);
buf : 	priv->tx_skb = skb;
buf : 	err = priv->hw_host_to_card(priv, MVMS_DAT, skb->data, skb->len);
buf : 	spin_unlock_irq(&priv->driver_lock);
buf : 	if (err) {
if (err) { 
buf : 		dev_kfree_skb_any(skb);
buf : 		priv->tx_skb = NULL;
buf : 		pr_err("TX error: %d", err);
buf : 	}
buf : 	lbtf_deb_leave(LBTF_DEB_MACOPS | LBTF_DEB_TX);
buf : }
buf : 
buf : static int lbtf_op_start(struct ieee80211_hw *hw)
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 	void *card = priv->card;
buf : 	int ret = -1;
buf : 
buf : 	lbtf_deb_enter(LBTF_DEB_MACOPS);
buf : 
buf : 	if (!priv->fw_ready)
if (!priv->fw_ready) 
buf : 		/* Upload firmware */
buf : 		if (priv->hw_prog_firmware(card))
if (priv->hw_prog_firmware(card)) 
buf : 			goto err_prog_firmware;
buf : 
buf : 	/* poke the firmware */
buf : 	priv->capability = WLAN_CAPABILITY_SHORT_PREAMBLE;
buf : 	priv->radioon = RADIO_ON;
buf : 	priv->mac_control = CMD_ACT_MAC_RX_ON | CMD_ACT_MAC_TX_ON;
buf : 	ret = lbtf_setup_firmware(priv);
buf : 	if (ret)
if (ret) 
buf : 		goto err_prog_firmware;
buf : 
buf : 	if ((priv->fwrelease < LBTF_FW_VER_MIN) ||
if ((priv->fwrelease < LBTF_FW_VER_MIN) || 
buf : 	    (priv->fwrelease > LBTF_FW_VER_MAX)) {
buf : 		ret = -1;
buf : 		goto err_prog_firmware;
buf : 	}
buf : 
buf : 	printk(KERN_INFO "libertastf: Marvell WLAN 802.11 thinfirm adapter\n");
buf : 	lbtf_deb_leave(LBTF_DEB_MACOPS);
buf : 	return 0;
buf : 
buf : err_prog_firmware:
buf : 	priv->hw_reset_device(card);
buf : 	lbtf_deb_leave_args(LBTF_DEB_MACOPS, "error programing fw; ret=%d", ret);
buf : 	return ret;
buf : }
buf : 
buf : static void lbtf_op_stop(struct ieee80211_hw *hw)
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 	unsigned long flags;
buf : 	struct sk_buff *skb;
buf : 
buf : 	struct cmd_ctrl_node *cmdnode;
buf : 
buf : 	lbtf_deb_enter(LBTF_DEB_MACOPS);
buf : 
buf : 	/* Flush pending command nodes */
buf : 	spin_lock_irqsave(&priv->driver_lock, flags);
buf : 	list_for_each_entry(cmdnode, &priv->cmdpendingq, list) {
for_each_entry(cmdnode, &priv->cmdpendingq, list) { 
buf : 		cmdnode->result = -ENOENT;
buf : 		cmdnode->cmdwaitqwoken = 1;
buf : 		wake_up_interruptible(&cmdnode->cmdwait_q);
buf : 	}
buf : 
buf : 	spin_unlock_irqrestore(&priv->driver_lock, flags);
buf : 	cancel_work_sync(&priv->cmd_work);
buf : 	cancel_work_sync(&priv->tx_work);
buf : 	while ((skb = skb_dequeue(&priv->bc_ps_buf)))
while ((skb = skb_dequeue(&priv->bc_ps_buf))) 
buf : 		dev_kfree_skb_any(skb);
buf : 	priv->radioon = RADIO_OFF;
buf : 	lbtf_set_radio_control(priv);
buf : 
buf : 	lbtf_deb_leave(LBTF_DEB_MACOPS);
buf : }
buf : 
buf : static int lbtf_op_add_interface(struct ieee80211_hw *hw,
buf : 			struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 	lbtf_deb_enter(LBTF_DEB_MACOPS);
buf : 	if (priv->vif != NULL)
if (priv->vif != NULL) 
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	priv->vif = vif;
if = vif; 
buf : 	switch (vif->type) {
buf : 	case NL80211_IFTYPE_MESH_POINT:
buf : 	case NL80211_IFTYPE_AP:
buf : 		lbtf_set_mode(priv, LBTF_AP_MODE);
buf : 		break;
buf : 	case NL80211_IFTYPE_STATION:
buf : 		lbtf_set_mode(priv, LBTF_STA_MODE);
buf : 		break;
buf : 	default:
buf : 		priv->vif = NULL;
if = NULL; 
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 	lbtf_set_mac_address(priv, (u8 *) vif->addr);
if->addr); 
buf : 	lbtf_deb_leave(LBTF_DEB_MACOPS);
buf : 	return 0;
buf : }
buf : 
buf : static void lbtf_op_remove_interface(struct ieee80211_hw *hw,
buf : 			struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 	lbtf_deb_enter(LBTF_DEB_MACOPS);
buf : 
buf : 	if (priv->vif->type == NL80211_IFTYPE_AP ||
if (priv->vif->type == NL80211_IFTYPE_AP || 
buf : 	    priv->vif->type == NL80211_IFTYPE_MESH_POINT)
buf : 		lbtf_beacon_ctrl(priv, 0, 0);
buf : 	lbtf_set_mode(priv, LBTF_PASSIVE_MODE);
buf : 	lbtf_set_bssid(priv, 0, NULL);
buf : 	priv->vif = NULL;
if = NULL; 
buf : 	lbtf_deb_leave(LBTF_DEB_MACOPS);
buf : }
buf : 
buf : static int lbtf_op_config(struct ieee80211_hw *hw, u32 changed)
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 	lbtf_deb_enter(LBTF_DEB_MACOPS);
buf : 
buf : 	if (conf->chandef.chan->center_freq != priv->cur_freq) {
if (conf->chandef.chan->center_freq != priv->cur_freq) { 
buf : 		priv->cur_freq = conf->chandef.chan->center_freq;
buf : 		lbtf_set_channel(priv, conf->chandef.chan->hw_value);
buf : 	}
buf : 	lbtf_deb_leave(LBTF_DEB_MACOPS);
buf : 	return 0;
buf : }
buf : 
buf : static u64 lbtf_op_prepare_multicast(struct ieee80211_hw *hw,
buf : 				     struct netdev_hw_addr_list *mc_list)
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 	int i;
buf : 	struct netdev_hw_addr *ha;
buf : 	int mc_count = netdev_hw_addr_list_count(mc_list);
buf : 
buf : 	if (!mc_count || mc_count > MRVDRV_MAX_MULTICAST_LIST_SIZE)
if (!mc_count || mc_count > MRVDRV_MAX_MULTICAST_LIST_SIZE) 
buf : 		return mc_count;
buf : 
buf : 	priv->nr_of_multicastmacaddr = mc_count;
buf : 	i = 0;
buf : 	netdev_hw_addr_list_for_each(ha, mc_list)
for_each(ha, mc_list) 
buf : 		memcpy(&priv->multicastlist[i++], ha->addr, ETH_ALEN);
buf : 
buf : 	return mc_count;
buf : }
buf : 
buf : #define SUPPORTED_FIF_FLAGS  (FIF_PROMISC_IN_BSS | FIF_ALLMULTI)
buf : static void lbtf_op_configure_filter(struct ieee80211_hw *hw,
buf : 			unsigned int changed_flags,
buf : 			unsigned int *new_flags,
buf : 			u64 multicast)
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 	int old_mac_control = priv->mac_control;
buf : 
buf : 	lbtf_deb_enter(LBTF_DEB_MACOPS);
buf : 
buf : 	changed_flags &= SUPPORTED_FIF_FLAGS;
buf : 	*new_flags &= SUPPORTED_FIF_FLAGS;
buf : 
buf : 	if (!changed_flags) {
if (!changed_flags) { 
buf : 		lbtf_deb_leave(LBTF_DEB_MACOPS);
buf : 		return;
buf : 	}
buf : 
buf : 	if (*new_flags & (FIF_PROMISC_IN_BSS))
if (*new_flags & (FIF_PROMISC_IN_BSS)) 
buf : 		priv->mac_control |= CMD_ACT_MAC_PROMISCUOUS_ENABLE;
buf : 	else
buf : 		priv->mac_control &= ~CMD_ACT_MAC_PROMISCUOUS_ENABLE;
buf : 	if (*new_flags & (FIF_ALLMULTI) ||
if (*new_flags & (FIF_ALLMULTI) || 
buf : 	    multicast > MRVDRV_MAX_MULTICAST_LIST_SIZE) {
buf : 		priv->mac_control |= CMD_ACT_MAC_ALL_MULTICAST_ENABLE;
buf : 		priv->mac_control &= ~CMD_ACT_MAC_MULTICAST_ENABLE;
buf : 	} else if (multicast) {
if (multicast) { 
buf : 		priv->mac_control |= CMD_ACT_MAC_MULTICAST_ENABLE;
buf : 		priv->mac_control &= ~CMD_ACT_MAC_ALL_MULTICAST_ENABLE;
buf : 		lbtf_cmd_set_mac_multicast_addr(priv);
buf : 	} else {
buf : 		priv->mac_control &= ~(CMD_ACT_MAC_MULTICAST_ENABLE |
buf : 				       CMD_ACT_MAC_ALL_MULTICAST_ENABLE);
buf : 		if (priv->nr_of_multicastmacaddr) {
if (priv->nr_of_multicastmacaddr) { 
buf : 			priv->nr_of_multicastmacaddr = 0;
buf : 			lbtf_cmd_set_mac_multicast_addr(priv);
buf : 		}
buf : 	}
buf : 
buf : 
buf : 	if (priv->mac_control != old_mac_control)
if (priv->mac_control != old_mac_control) 
buf : 		lbtf_set_mac_control(priv);
buf : 
buf : 	lbtf_deb_leave(LBTF_DEB_MACOPS);
buf : }
buf : 
buf : static void lbtf_op_bss_info_changed(struct ieee80211_hw *hw,
buf : 			struct ieee80211_vif *vif,
if *vif, 
buf : 			struct ieee80211_bss_conf *bss_conf,
buf : 			u32 changes)
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 	struct sk_buff *beacon;
buf : 	lbtf_deb_enter(LBTF_DEB_MACOPS);
buf : 
buf : 	if (changes & (BSS_CHANGED_BEACON | BSS_CHANGED_BEACON_INT)) {
if (changes & (BSS_CHANGED_BEACON | BSS_CHANGED_BEACON_INT)) { 
buf : 		switch (priv->vif->type) {
buf : 		case NL80211_IFTYPE_AP:
buf : 		case NL80211_IFTYPE_MESH_POINT:
buf : 			beacon = ieee80211_beacon_get(hw, vif);
if); 
buf : 			if (beacon) {
buf : 				lbtf_beacon_set(priv, beacon);
buf : 				kfree_skb(beacon);
buf : 				lbtf_beacon_ctrl(priv, 1,
buf : 						 bss_conf->beacon_int);
buf : 			}
buf : 			break;
buf : 		default:
buf : 			break;
buf : 		}
buf : 	}
buf : 
buf : 	if (changes & BSS_CHANGED_BSSID) {
if (changes & BSS_CHANGED_BSSID) { 
buf : 		bool activate = !is_zero_ether_addr(bss_conf->bssid);
buf : 		lbtf_set_bssid(priv, activate, bss_conf->bssid);
buf : 	}
buf : 
buf : 	if (changes & BSS_CHANGED_ERP_PREAMBLE) {
if (changes & BSS_CHANGED_ERP_PREAMBLE) { 
buf : 		if (bss_conf->use_short_preamble)
buf : 			priv->preamble = CMD_TYPE_SHORT_PREAMBLE;
buf : 		else
buf : 			priv->preamble = CMD_TYPE_LONG_PREAMBLE;
buf : 		lbtf_set_radio_control(priv);
buf : 	}
buf : 
buf : 	lbtf_deb_leave(LBTF_DEB_MACOPS);
buf : }
buf : 
buf : static int lbtf_op_get_survey(struct ieee80211_hw *hw, int idx,
buf : 				struct survey_info *survey)
buf : {
buf : 	struct lbtf_private *priv = hw->priv;
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 
buf : 	if (idx != 0)
if (idx != 0) 
buf : 		return -ENOENT;
buf : 
buf : 	survey->channel = conf->chandef.chan;
buf : 	survey->filled = SURVEY_INFO_NOISE_DBM;
buf : 	survey->noise = priv->noise;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static const struct ieee80211_ops lbtf_ops = {
buf : 	.tx			= lbtf_op_tx,
buf : 	.start			= lbtf_op_start,
buf : 	.stop			= lbtf_op_stop,
buf : 	.add_interface		= lbtf_op_add_interface,
buf : 	.remove_interface	= lbtf_op_remove_interface,
buf : 	.config			= lbtf_op_config,
buf : 	.prepare_multicast	= lbtf_op_prepare_multicast,
buf : 	.configure_filter	= lbtf_op_configure_filter,
buf : 	.bss_info_changed	= lbtf_op_bss_info_changed,
buf : 	.get_survey		= lbtf_op_get_survey,
buf : };
buf : 
buf : int lbtf_rx(struct lbtf_private *priv, struct sk_buff *skb)
buf : {
buf : 	struct ieee80211_rx_status stats;
buf : 	struct rxpd *prxpd;
buf : 	int need_padding;
buf : 	unsigned int flags;
buf : 	struct ieee80211_hdr *hdr;
buf : 
buf : 	lbtf_deb_enter(LBTF_DEB_RX);
buf : 
buf : 	prxpd = (struct rxpd *) skb->data;
buf : 
buf : 	memset(&stats, 0, sizeof(stats));
buf : 	if (!(prxpd->status & cpu_to_le16(MRVDRV_RXPD_STATUS_OK)))
if (!(prxpd->status & cpu_to_le16(MRVDRV_RXPD_STATUS_OK))) 
buf : 		stats.flag |= RX_FLAG_FAILED_FCS_CRC;
buf : 	stats.freq = priv->cur_freq;
buf : 	stats.band = IEEE80211_BAND_2GHZ;
buf : 	stats.signal = prxpd->snr;
buf : 	priv->noise = prxpd->nf;
buf : 	/* Marvell rate index has a hole at value 4 */
buf : 	if (prxpd->rx_rate > 4)
if (prxpd->rx_rate > 4) 
buf : 		--prxpd->rx_rate;
buf : 	stats.rate_idx = prxpd->rx_rate;
buf : 	skb_pull(skb, sizeof(struct rxpd));
buf : 
buf : 	hdr = (struct ieee80211_hdr *)skb->data;
buf : 	flags = le32_to_cpu(*(__le32 *)(skb->data + 4));
buf : 
buf : 	need_padding = ieee80211_is_data_qos(hdr->frame_control);
buf : 	need_padding ^= ieee80211_has_a4(hdr->frame_control);
buf : 	need_padding ^= ieee80211_is_data_qos(hdr->frame_control) &&
buf : 			(*ieee80211_get_qos_ctl(hdr) &
buf : 			 IEEE80211_QOS_CTL_A_MSDU_PRESENT);
buf : 
buf : 	if (need_padding) {
if (need_padding) { 
buf : 		memmove(skb->data + 2, skb->data, skb->len);
buf : 		skb_reserve(skb, 2);
buf : 	}
buf : 
buf : 	memcpy(IEEE80211_SKB_RXCB(skb), &stats, sizeof(stats));
buf : 
buf : 	lbtf_deb_rx("rx data: skb->len-sizeof(RxPd) = %d-%zd = %zd\n",
buf : 	       skb->len, sizeof(struct rxpd), skb->len - sizeof(struct rxpd));
buf : 	lbtf_deb_hex(LBTF_DEB_RX, "RX Data", skb->data,
buf : 	             min_t(unsigned int, skb->len, 100));
buf : 
buf : 	ieee80211_rx_irqsafe(priv->hw, skb);
buf : 
buf : 	lbtf_deb_leave(LBTF_DEB_RX);
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL_GPL(lbtf_rx);
buf : 
buf : /**
buf :  * lbtf_add_card: Add and initialize the card, no fw upload yet.
buf :  *
buf :  *  @card    A pointer to card
buf :  *
buf :  *  Returns: pointer to struct lbtf_priv.
buf :  */
buf : struct lbtf_private *lbtf_add_card(void *card, struct device *dmdev)
buf : {
buf : 	struct ieee80211_hw *hw;
buf : 	struct lbtf_private *priv = NULL;
buf : 
buf : 	lbtf_deb_enter(LBTF_DEB_MAIN);
buf : 
buf : 	hw = ieee80211_alloc_hw(sizeof(struct lbtf_private), &lbtf_ops);
buf : 	if (!hw)
if (!hw) 
buf : 		goto done;
buf : 
buf : 	priv = hw->priv;
buf : 	if (lbtf_init_adapter(priv))
if (lbtf_init_adapter(priv)) 
buf : 		goto err_init_adapter;
buf : 
buf : 	priv->hw = hw;
buf : 	priv->card = card;
buf : 	priv->tx_skb = NULL;
buf : 
buf : 	hw->queues = 1;
buf : 	hw->flags = IEEE80211_HW_HOST_BROADCAST_PS_BUFFERING;
buf : 	hw->extra_tx_headroom = sizeof(struct txpd);
buf : 	memcpy(priv->channels, lbtf_channels, sizeof(lbtf_channels));
buf : 	memcpy(priv->rates, lbtf_rates, sizeof(lbtf_rates));
buf : 	priv->band.n_bitrates = ARRAY_SIZE(lbtf_rates);
buf : 	priv->band.bitrates = priv->rates;
buf : 	priv->band.n_channels = ARRAY_SIZE(lbtf_channels);
buf : 	priv->band.channels = priv->channels;
buf : 	hw->wiphy->bands[IEEE80211_BAND_2GHZ] = &priv->band;
buf : 	hw->wiphy->interface_modes =
buf : 		BIT(NL80211_IFTYPE_STATION) |
buf : 		BIT(NL80211_IFTYPE_ADHOC);
buf : 	skb_queue_head_init(&priv->bc_ps_buf);
buf : 
buf : 	SET_IEEE80211_DEV(hw, dmdev);
buf : 
buf : 	INIT_WORK(&priv->cmd_work, lbtf_cmd_work);
buf : 	INIT_WORK(&priv->tx_work, lbtf_tx_work);
buf : 	if (ieee80211_register_hw(hw))
if (ieee80211_register_hw(hw)) 
buf : 		goto err_init_adapter;
buf : 
buf : 	goto done;
buf : 
buf : err_init_adapter:
buf : 	lbtf_free_adapter(priv);
buf : 	ieee80211_free_hw(hw);
buf : 	priv = NULL;
buf : 
buf : done:
buf : 	lbtf_deb_leave_args(LBTF_DEB_MAIN, "priv %p", priv);
buf : 	return priv;
buf : }
buf : EXPORT_SYMBOL_GPL(lbtf_add_card);
buf : 
buf : 
buf : int lbtf_remove_card(struct lbtf_private *priv)
buf : {
buf : 	struct ieee80211_hw *hw = priv->hw;
buf : 
buf : 	lbtf_deb_enter(LBTF_DEB_MAIN);
buf : 
buf : 	priv->surpriseremoved = 1;
buf : 	del_timer(&priv->command_timer);
buf : 	lbtf_free_adapter(priv);
buf : 	priv->hw = NULL;
buf : 	ieee80211_unregister_hw(hw);
buf : 	ieee80211_free_hw(hw);
buf : 
buf :     lbtf_deb_leave(LBTF_DEB_MAIN);
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL_GPL(lbtf_remove_card);
buf : 
buf : void lbtf_send_tx_feedback(struct lbtf_private *priv, u8 retrycnt, u8 fail)
buf : {
buf : 	struct ieee80211_tx_info *info = IEEE80211_SKB_CB(priv->tx_skb);
buf : 
buf : 	ieee80211_tx_info_clear_status(info);
buf : 	/*
buf : 	 * Commented out, otherwise we never go beyond 1Mbit/s using mac80211
buf : 	 * default pid rc algorithm.
buf : 	 *
buf : 	 * info->status.retry_count = MRVL_DEFAULT_RETRIES - retrycnt;
buf : 	 */
buf : 	if (!(info->flags & IEEE80211_TX_CTL_NO_ACK) && !fail)
if (!(info->flags & IEEE80211_TX_CTL_NO_ACK) && !fail) 
buf : 		info->flags |= IEEE80211_TX_STAT_ACK;
buf : 	skb_pull(priv->tx_skb, sizeof(struct txpd));
buf : 	ieee80211_tx_status_irqsafe(priv->hw, priv->tx_skb);
buf : 	priv->tx_skb = NULL;
buf : 	if (!priv->skb_to_tx && skb_queue_empty(&priv->bc_ps_buf))
if (!priv->skb_to_tx && skb_queue_empty(&priv->bc_ps_buf)) 
buf : 		ieee80211_wake_queues(priv->hw);
buf : 	else
buf : 		queue_work(lbtf_wq, &priv->tx_work);
buf : }
buf : EXPORT_SYMBOL_GPL(lbtf_send_tx_feedback);
buf : 
buf : void lbtf_bcn_sent(struct lbtf_private *priv)
buf : {
buf : 	struct sk_buff *skb = NULL;
buf : 
buf : 	if (priv->vif->type != NL80211_IFTYPE_AP)
if (priv->vif->type != NL80211_IFTYPE_AP) 
buf : 		return;
buf : 
buf : 	if (skb_queue_empty(&priv->bc_ps_buf)) {
if (skb_queue_empty(&priv->bc_ps_buf)) { 
buf : 		bool tx_buff_bc = false;
buf : 
buf : 		while ((skb = ieee80211_get_buffered_bc(priv->hw, priv->vif))) {
if))) { 
buf : 			skb_queue_tail(&priv->bc_ps_buf, skb);
buf : 			tx_buff_bc = true;
buf : 		}
buf : 		if (tx_buff_bc) {
if (tx_buff_bc) { 
buf : 			ieee80211_stop_queues(priv->hw);
buf : 			queue_work(lbtf_wq, &priv->tx_work);
buf : 		}
buf : 	}
buf : 
buf : 	skb = ieee80211_beacon_get(priv->hw, priv->vif);
if); 
buf : 
buf : 	if (skb) {
buf : 		lbtf_beacon_set(priv, skb);
buf : 		kfree_skb(skb);
buf : 	}
buf : }
buf : EXPORT_SYMBOL_GPL(lbtf_bcn_sent);
buf : 
buf : static int __init lbtf_init_module(void)
buf : {
buf : 	lbtf_deb_enter(LBTF_DEB_MAIN);
buf : 	lbtf_wq = create_workqueue("libertastf");
buf : 	if (lbtf_wq == NULL) {
if (lbtf_wq == NULL) { 
buf : 		printk(KERN_ERR "libertastf: couldn't create workqueue\n");
buf : 		return -ENOMEM;
buf : 	}
buf : 	lbtf_deb_leave(LBTF_DEB_MAIN);
buf : 	return 0;
buf : }
buf : 
buf : static void __exit lbtf_exit_module(void)
buf : {
buf : 	lbtf_deb_enter(LBTF_DEB_MAIN);
buf : 	destroy_workqueue(lbtf_wq);
buf : 	lbtf_deb_leave(LBTF_DEB_MAIN);
buf : }
buf : 
buf : module_init(lbtf_init_module);
buf : module_exit(lbtf_exit_module);
buf : 
buf : MODULE_DESCRIPTION("Libertas WLAN Thinfirm Driver Library");
buf : MODULE_AUTHOR("Cozybit Inc.");
buf : MODULE_LICENSE("GPL");
file : ./test/kernel/drivers/net/wireless/ath/carl9170/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Atheros CARL9170 driver
buf :  *
buf :  * mac80211 interaction code
buf :  *
buf :  * Copyright 2008, Johannes Berg <johannes@sipsolutions.net>
buf :  * Copyright 2009, 2010, Christian Lamparter <chunkeey@googlemail.com>
buf :  *
buf :  * This program is free software; you can redistribute it and/or modify
ify 
buf :  * it under the terms of the GNU General Public License as published by
buf :  * the Free Software Foundation; either version 2 of the License, or
buf :  * (at your option) any later version.
buf :  *
buf :  * This program is distributed in the hope that it will be useful,
buf :  * but WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
buf :  * GNU General Public License for more details.
for more details. 
buf :  *
buf :  * You should have received a copy of the GNU General Public License
buf :  * along with this program; see the file COPYING.  If not, see
buf :  * http://www.gnu.org/licenses/.
buf :  *
buf :  * This file incorporates work covered by the following copyright and
buf :  * permission notice:
buf :  *    Copyright (c) 2007-2008 Atheros Communications, Inc.
buf :  *
buf :  *    Permission to use, copy, modify, and/or distribute this software for any
ify, and/or distribute this software for any 
buf :  *    purpose with or without fee is hereby granted, provided that the above
buf :  *    copyright notice and this permission notice appear in all copies.
buf :  *
buf :  *    THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
buf :  *    WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
buf :  *    MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
buf :  *    ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
buf :  *    WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
buf :  *    ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
buf :  *    OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
buf :  */
buf : 
buf : #include <linux/slab.h>
buf : #include <linux/module.h>
buf : #include <linux/etherdevice.h>
buf : #include <linux/random.h>
buf : #include <net/mac80211.h>
buf : #include <net/cfg80211.h>
buf : #include "hw.h"
buf : #include "carl9170.h"
buf : #include "cmd.h"
buf : 
buf : static bool modparam_nohwcrypt;
buf : module_param_named(nohwcrypt, modparam_nohwcrypt, bool, S_IRUGO);
buf : MODULE_PARM_DESC(nohwcrypt, "Disable hardware crypto offload.");
buf : 
buf : int modparam_noht;
buf : module_param_named(noht, modparam_noht, int, S_IRUGO);
buf : MODULE_PARM_DESC(noht, "Disable MPDU aggregation.");
buf : 
buf : #define RATE(_bitrate, _hw_rate, _txpidx, _flags) {	\
buf : 	.bitrate	= (_bitrate),			\
buf : 	.flags		= (_flags),			\
buf : 	.hw_value	= (_hw_rate) | (_txpidx) << 4,	\
buf : }
buf : 
buf : struct ieee80211_rate __carl9170_ratetable[] = {
buf : 	RATE(10, 0, 0, 0),
buf : 	RATE(20, 1, 1, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATE(55, 2, 2, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATE(110, 3, 3, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATE(60, 0xb, 0, 0),
buf : 	RATE(90, 0xf, 0, 0),
buf : 	RATE(120, 0xa, 0, 0),
buf : 	RATE(180, 0xe, 0, 0),
buf : 	RATE(240, 0x9, 0, 0),
buf : 	RATE(360, 0xd, 1, 0),
buf : 	RATE(480, 0x8, 2, 0),
buf : 	RATE(540, 0xc, 3, 0),
buf : };
buf : #undef RATE
buf : 
buf : #define carl9170_g_ratetable	(__carl9170_ratetable + 0)
buf : #define carl9170_g_ratetable_size	12
buf : #define carl9170_a_ratetable	(__carl9170_ratetable + 4)
buf : #define carl9170_a_ratetable_size	8
buf : 
buf : /*
buf :  * NB: The hw_value is used as an index into the carl9170_phy_freq_params
buf :  *     array in phy.c so that we don't have to do frequency lookups!
buf :  */
buf : #define CHAN(_freq, _idx) {		\
buf : 	.center_freq	= (_freq),	\
buf : 	.hw_value	= (_idx),	\
buf : 	.max_power	= 18, /* XXX */	\
buf : }
buf : 
buf : static struct ieee80211_channel carl9170_2ghz_chantable[] = {
buf : 	CHAN(2412,  0),
buf : 	CHAN(2417,  1),
buf : 	CHAN(2422,  2),
buf : 	CHAN(2427,  3),
buf : 	CHAN(2432,  4),
buf : 	CHAN(2437,  5),
buf : 	CHAN(2442,  6),
buf : 	CHAN(2447,  7),
buf : 	CHAN(2452,  8),
buf : 	CHAN(2457,  9),
buf : 	CHAN(2462, 10),
buf : 	CHAN(2467, 11),
buf : 	CHAN(2472, 12),
buf : 	CHAN(2484, 13),
buf : };
buf : 
buf : static struct ieee80211_channel carl9170_5ghz_chantable[] = {
buf : 	CHAN(4920, 14),
buf : 	CHAN(4940, 15),
buf : 	CHAN(4960, 16),
buf : 	CHAN(4980, 17),
buf : 	CHAN(5040, 18),
buf : 	CHAN(5060, 19),
buf : 	CHAN(5080, 20),
buf : 	CHAN(5180, 21),
buf : 	CHAN(5200, 22),
buf : 	CHAN(5220, 23),
buf : 	CHAN(5240, 24),
buf : 	CHAN(5260, 25),
buf : 	CHAN(5280, 26),
buf : 	CHAN(5300, 27),
buf : 	CHAN(5320, 28),
buf : 	CHAN(5500, 29),
buf : 	CHAN(5520, 30),
buf : 	CHAN(5540, 31),
buf : 	CHAN(5560, 32),
buf : 	CHAN(5580, 33),
buf : 	CHAN(5600, 34),
buf : 	CHAN(5620, 35),
buf : 	CHAN(5640, 36),
buf : 	CHAN(5660, 37),
buf : 	CHAN(5680, 38),
buf : 	CHAN(5700, 39),
buf : 	CHAN(5745, 40),
buf : 	CHAN(5765, 41),
buf : 	CHAN(5785, 42),
buf : 	CHAN(5805, 43),
buf : 	CHAN(5825, 44),
buf : 	CHAN(5170, 45),
buf : 	CHAN(5190, 46),
buf : 	CHAN(5210, 47),
buf : 	CHAN(5230, 48),
buf : };
buf : #undef CHAN
buf : 
buf : #define CARL9170_HT_CAP							\
buf : {									\
buf : 	.ht_supported	= true,						\
buf : 	.cap		= IEEE80211_HT_CAP_MAX_AMSDU |			\
buf : 			  IEEE80211_HT_CAP_SUP_WIDTH_20_40 |		\
buf : 			  IEEE80211_HT_CAP_SGI_40 |			\
buf : 			  IEEE80211_HT_CAP_DSSSCCK40 |			\
buf : 			  IEEE80211_HT_CAP_SM_PS,			\
buf : 	.ampdu_factor	= IEEE80211_HT_MAX_AMPDU_64K,			\
buf : 	.ampdu_density	= IEEE80211_HT_MPDU_DENSITY_8,			\
buf : 	.mcs		= {						\
buf : 		.rx_mask = { 0xff, 0xff, 0, 0, 0x1, 0, 0, 0, 0, 0, },	\
buf : 		.rx_highest = cpu_to_le16(300),				\
buf : 		.tx_params = IEEE80211_HT_MCS_TX_DEFINED,		\
buf : 	},								\
buf : }
buf : 
buf : static struct ieee80211_supported_band carl9170_band_2GHz = {
buf : 	.channels	= carl9170_2ghz_chantable,
buf : 	.n_channels	= ARRAY_SIZE(carl9170_2ghz_chantable),
buf : 	.bitrates	= carl9170_g_ratetable,
buf : 	.n_bitrates	= carl9170_g_ratetable_size,
buf : 	.ht_cap		= CARL9170_HT_CAP,
buf : };
buf : 
buf : static struct ieee80211_supported_band carl9170_band_5GHz = {
buf : 	.channels	= carl9170_5ghz_chantable,
buf : 	.n_channels	= ARRAY_SIZE(carl9170_5ghz_chantable),
buf : 	.bitrates	= carl9170_a_ratetable,
buf : 	.n_bitrates	= carl9170_a_ratetable_size,
buf : 	.ht_cap		= CARL9170_HT_CAP,
buf : };
buf : 
buf : static void carl9170_ampdu_gc(struct ar9170 *ar)
buf : {
buf : 	struct carl9170_sta_tid *tid_info;
buf : 	LIST_HEAD(tid_gc);
buf : 
buf : 	rcu_read_lock();
buf : 	list_for_each_entry_rcu(tid_info, &ar->tx_ampdu_list, list) {
for_each_entry_rcu(tid_info, &ar->tx_ampdu_list, list) { 
buf : 		spin_lock_bh(&ar->tx_ampdu_list_lock);
buf : 		if (tid_info->state == CARL9170_TID_STATE_SHUTDOWN) {
if (tid_info->state == CARL9170_TID_STATE_SHUTDOWN) { 
buf : 			tid_info->state = CARL9170_TID_STATE_KILLED;
buf : 			list_del_rcu(&tid_info->list);
buf : 			ar->tx_ampdu_list_len--;
buf : 			list_add_tail(&tid_info->tmp_list, &tid_gc);
buf : 		}
buf : 		spin_unlock_bh(&ar->tx_ampdu_list_lock);
buf : 
buf : 	}
buf : 	rcu_assign_pointer(ar->tx_ampdu_iter, tid_info);
buf : 	rcu_read_unlock();
buf : 
buf : 	synchronize_rcu();
buf : 
buf : 	while (!list_empty(&tid_gc)) {
while (!list_empty(&tid_gc)) { 
buf : 		struct sk_buff *skb;
buf : 		tid_info = list_first_entry(&tid_gc, struct carl9170_sta_tid,
buf : 					    tmp_list);
buf : 
buf : 		while ((skb = __skb_dequeue(&tid_info->queue)))
while ((skb = __skb_dequeue(&tid_info->queue))) 
buf : 			carl9170_tx_status(ar, skb, false);
buf : 
buf : 		list_del_init(&tid_info->tmp_list);
buf : 		kfree(tid_info);
buf : 	}
buf : }
buf : 
buf : static void carl9170_flush(struct ar9170 *ar, bool drop_queued)
buf : {
buf : 	if (drop_queued) {
if (drop_queued) { 
buf : 		int i;
buf : 
buf : 		/*
buf : 		 * We can only drop frames which have not been uploaded
buf : 		 * to the device yet.
buf : 		 */
buf : 
buf : 		for (i = 0; i < ar->hw->queues; i++) {
for (i = 0; i < ar->hw->queues; i++) { 
buf : 			struct sk_buff *skb;
buf : 
buf : 			while ((skb = skb_dequeue(&ar->tx_pending[i]))) {
while ((skb = skb_dequeue(&ar->tx_pending[i]))) { 
buf : 				struct ieee80211_tx_info *info;
buf : 
buf : 				info = IEEE80211_SKB_CB(skb);
buf : 				if (info->flags & IEEE80211_TX_CTL_AMPDU)
if (info->flags & IEEE80211_TX_CTL_AMPDU) 
buf : 					atomic_dec(&ar->tx_ampdu_upload);
buf : 
buf : 				carl9170_tx_status(ar, skb, false);
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	/* Wait for all other outstanding frames to timeout. */
for all other outstanding frames to timeout. */ 
buf : 	if (atomic_read(&ar->tx_total_queued))
buf : 		WARN_ON(wait_for_completion_timeout(&ar->tx_flush, HZ) == 0);
for_completion_timeout(&ar->tx_flush, HZ) == 0); 
buf : }
buf : 
buf : static void carl9170_flush_ba(struct ar9170 *ar)
buf : {
buf : 	struct sk_buff_head free;
buf : 	struct carl9170_sta_tid *tid_info;
buf : 	struct sk_buff *skb;
buf : 
buf : 	__skb_queue_head_init(&free);
buf : 
buf : 	rcu_read_lock();
buf : 	spin_lock_bh(&ar->tx_ampdu_list_lock);
buf : 	list_for_each_entry_rcu(tid_info, &ar->tx_ampdu_list, list) {
for_each_entry_rcu(tid_info, &ar->tx_ampdu_list, list) { 
buf : 		if (tid_info->state > CARL9170_TID_STATE_SUSPEND) {
buf : 			tid_info->state = CARL9170_TID_STATE_SUSPEND;
buf : 
buf : 			spin_lock(&tid_info->lock);
buf : 			while ((skb = __skb_dequeue(&tid_info->queue)))
while ((skb = __skb_dequeue(&tid_info->queue))) 
buf : 				__skb_queue_tail(&free, skb);
buf : 			spin_unlock(&tid_info->lock);
buf : 		}
buf : 	}
buf : 	spin_unlock_bh(&ar->tx_ampdu_list_lock);
buf : 	rcu_read_unlock();
buf : 
buf : 	while ((skb = __skb_dequeue(&free)))
while ((skb = __skb_dequeue(&free))) 
buf : 		carl9170_tx_status(ar, skb, false);
buf : }
buf : 
buf : static void carl9170_zap_queues(struct ar9170 *ar)
buf : {
buf : 	struct carl9170_vif_info *cvif;
if_info *cvif; 
buf : 	unsigned int i;
buf : 
buf : 	carl9170_ampdu_gc(ar);
buf : 
buf : 	carl9170_flush_ba(ar);
buf : 	carl9170_flush(ar, true);
buf : 
buf : 	for (i = 0; i < ar->hw->queues; i++) {
for (i = 0; i < ar->hw->queues; i++) { 
buf : 		spin_lock_bh(&ar->tx_status[i].lock);
buf : 		while (!skb_queue_empty(&ar->tx_status[i])) {
while (!skb_queue_empty(&ar->tx_status[i])) { 
buf : 			struct sk_buff *skb;
buf : 
buf : 			skb = skb_peek(&ar->tx_status[i]);
buf : 			carl9170_tx_get_skb(skb);
buf : 			spin_unlock_bh(&ar->tx_status[i].lock);
buf : 			carl9170_tx_drop(ar, skb);
buf : 			spin_lock_bh(&ar->tx_status[i].lock);
buf : 			carl9170_tx_put_skb(skb);
buf : 		}
buf : 		spin_unlock_bh(&ar->tx_status[i].lock);
buf : 	}
buf : 
buf : 	BUILD_BUG_ON(CARL9170_NUM_TX_LIMIT_SOFT < 1);
buf : 	BUILD_BUG_ON(CARL9170_NUM_TX_LIMIT_HARD < CARL9170_NUM_TX_LIMIT_SOFT);
buf : 	BUILD_BUG_ON(CARL9170_NUM_TX_LIMIT_HARD >= CARL9170_BAW_BITS);
buf : 
buf : 	/* reinitialize queues statistics */
buf : 	memset(&ar->tx_stats, 0, sizeof(ar->tx_stats));
buf : 	for (i = 0; i < ar->hw->queues; i++)
for (i = 0; i < ar->hw->queues; i++) 
buf : 		ar->tx_stats[i].limit = CARL9170_NUM_TX_LIMIT_HARD;
buf : 
buf : 	for (i = 0; i < DIV_ROUND_UP(ar->fw.mem_blocks, BITS_PER_LONG); i++)
for (i = 0; i < DIV_ROUND_UP(ar->fw.mem_blocks, BITS_PER_LONG); i++) 
buf : 		ar->mem_bitmap[i] = 0;
buf : 
buf : 	rcu_read_lock();
buf : 	list_for_each_entry_rcu(cvif, &ar->vif_list, list) {
if, &ar->vif_list, list) { 
buf : 		spin_lock_bh(&ar->beacon_lock);
buf : 		dev_kfree_skb_any(cvif->beacon);
if->beacon); 
buf : 		cvif->beacon = NULL;
buf : 		spin_unlock_bh(&ar->beacon_lock);
buf : 	}
buf : 	rcu_read_unlock();
buf : 
buf : 	atomic_set(&ar->tx_ampdu_upload, 0);
buf : 	atomic_set(&ar->tx_ampdu_scheduler, 0);
buf : 	atomic_set(&ar->tx_total_pending, 0);
buf : 	atomic_set(&ar->tx_total_queued, 0);
buf : 	atomic_set(&ar->mem_free_blocks, ar->fw.mem_blocks);
buf : }
buf : 
buf : #define CARL9170_FILL_QUEUE(queue, ai_fs, cwmin, cwmax, _txop)		\
buf : do {									\
buf : 	queue.aifs = ai_fs;						\
ifs = ai_fs;						\ 
buf : 	queue.cw_min = cwmin;						\
buf : 	queue.cw_max = cwmax;						\
buf : 	queue.txop = _txop;						\
buf : } while (0)
while (0) 
buf : 
buf : static int carl9170_op_start(struct ieee80211_hw *hw)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	int err, i;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 
buf : 	carl9170_zap_queues(ar);
buf : 
buf : 	/* reset QoS defaults */
buf : 	CARL9170_FILL_QUEUE(ar->edcf[AR9170_TXQ_VO], 2, 3,     7, 47);
buf : 	CARL9170_FILL_QUEUE(ar->edcf[AR9170_TXQ_VI], 2, 7,    15, 94);
buf : 	CARL9170_FILL_QUEUE(ar->edcf[AR9170_TXQ_BE], 3, 15, 1023,  0);
buf : 	CARL9170_FILL_QUEUE(ar->edcf[AR9170_TXQ_BK], 7, 15, 1023,  0);
buf : 	CARL9170_FILL_QUEUE(ar->edcf[AR9170_TXQ_SPECIAL], 2, 3, 7, 0);
buf : 
buf : 	ar->current_factor = ar->current_density = -1;
buf : 	/* "The first key is unique." */
buf : 	ar->usedkeys = 1;
buf : 	ar->filter_state = 0;
buf : 	ar->ps.last_action = jiffies;
iffies; 
buf : 	ar->ps.last_slept = jiffies;
buf : 	ar->erp_mode = CARL9170_ERP_AUTO;
buf : 
buf : 	/* Set "disable hw crypto offload" whenever the module parameter
buf : 	 * nohwcrypt is true or if the firmware does not support it.
if the firmware does not support it. 
buf : 	 */
buf : 	ar->disable_offload = modparam_nohwcrypt |
buf : 		ar->fw.disable_offload_fw;
buf : 	ar->rx_software_decryption = ar->disable_offload;
buf : 
buf : 	for (i = 0; i < ar->hw->queues; i++) {
for (i = 0; i < ar->hw->queues; i++) { 
buf : 		ar->queue_stop_timeout[i] = jiffies;
buf : 		ar->max_queue_stop_timeout[i] = 0;
buf : 	}
buf : 
buf : 	atomic_set(&ar->mem_allocs, 0);
buf : 
buf : 	err = carl9170_usb_open(ar);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	err = carl9170_init_mac(ar);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	err = carl9170_set_qos(ar);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	if (ar->fw.rx_filter) {
if (ar->fw.rx_filter) { 
buf : 		err = carl9170_rx_filter(ar, CARL9170_RX_FILTER_OTHER_RA |
buf : 			CARL9170_RX_FILTER_CTL_OTHER | CARL9170_RX_FILTER_BAD);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	err = carl9170_write_reg(ar, AR9170_MAC_REG_DMA_TRIGGER,
buf : 				 AR9170_DMA_TRIGGER_RXQ);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	/* Clear key-cache */
buf : 	for (i = 0; i < AR9170_CAM_MAX_USER + 4; i++) {
for (i = 0; i < AR9170_CAM_MAX_USER + 4; i++) { 
buf : 		err = carl9170_upload_key(ar, i, NULL, AR9170_ENC_ALG_NONE,
buf : 					  0, NULL, 0);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 
buf : 		err = carl9170_upload_key(ar, i, NULL, AR9170_ENC_ALG_NONE,
buf : 					  1, NULL, 0);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 
buf : 		if (i < AR9170_CAM_MAX_USER) {
if (i < AR9170_CAM_MAX_USER) { 
buf : 			err = carl9170_disable_key(ar, i);
buf : 			if (err)
if (err) 
buf : 				goto out;
buf : 		}
buf : 	}
buf : 
buf : 	carl9170_set_state_when(ar, CARL9170_IDLE, CARL9170_STARTED);
buf : 
buf : 	ieee80211_queue_delayed_work(ar->hw, &ar->stat_work,
buf : 		round_jiffies(msecs_to_jiffies(CARL9170_STAT_WORK)));
iffies(msecs_to_jiffies(CARL9170_STAT_WORK))); 
buf : 
buf : 	ieee80211_wake_queues(ar->hw);
buf : 	err = 0;
buf : 
buf : out:
buf : 	mutex_unlock(&ar->mutex);
buf : 	return err;
buf : }
buf : 
buf : static void carl9170_cancel_worker(struct ar9170 *ar)
buf : {
buf : 	cancel_delayed_work_sync(&ar->stat_work);
buf : 	cancel_delayed_work_sync(&ar->tx_janitor);
buf : #ifdef CONFIG_CARL9170_LEDS
ifdef CONFIG_CARL9170_LEDS 
buf : 	cancel_delayed_work_sync(&ar->led_work);
buf : #endif /* CONFIG_CARL9170_LEDS */
if /* CONFIG_CARL9170_LEDS */ 
buf : 	cancel_work_sync(&ar->ps_work);
buf : 	cancel_work_sync(&ar->ping_work);
buf : 	cancel_work_sync(&ar->ampdu_work);
buf : }
buf : 
buf : static void carl9170_op_stop(struct ieee80211_hw *hw)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 
buf : 	carl9170_set_state_when(ar, CARL9170_STARTED, CARL9170_IDLE);
buf : 
buf : 	ieee80211_stop_queues(ar->hw);
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	if (IS_ACCEPTING_CMD(ar)) {
if (IS_ACCEPTING_CMD(ar)) { 
buf : 		RCU_INIT_POINTER(ar->beacon_iter, NULL);
buf : 
buf : 		carl9170_led_set_state(ar, 0);
buf : 
buf : 		/* stop DMA */
buf : 		carl9170_write_reg(ar, AR9170_MAC_REG_DMA_TRIGGER, 0);
buf : 		carl9170_usb_stop(ar);
buf : 	}
buf : 
buf : 	carl9170_zap_queues(ar);
buf : 	mutex_unlock(&ar->mutex);
buf : 
buf : 	carl9170_cancel_worker(ar);
buf : }
buf : 
buf : static void carl9170_restart_work(struct work_struct *work)
buf : {
buf : 	struct ar9170 *ar = container_of(work, struct ar9170,
buf : 					 restart_work);
buf : 	int err = -EIO;
buf : 
buf : 	ar->usedkeys = 0;
buf : 	ar->filter_state = 0;
buf : 	carl9170_cancel_worker(ar);
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	if (!ar->force_usb_reset) {
if (!ar->force_usb_reset) { 
buf : 		err = carl9170_usb_restart(ar);
buf : 		if (net_ratelimit()) {
if (net_ratelimit()) { 
buf : 			if (err)
buf : 				dev_err(&ar->udev->dev, "Failed to restart device (%d).\n", err);
buf : 			else
buf : 				dev_info(&ar->udev->dev, "device restarted successfully.\n");
buf : 		}
buf : 	}
buf : 	carl9170_zap_queues(ar);
buf : 	mutex_unlock(&ar->mutex);
buf : 
buf : 	if (!err && !ar->force_usb_reset) {
if (!err && !ar->force_usb_reset) { 
buf : 		ar->restart_counter++;
buf : 		atomic_set(&ar->pending_restarts, 0);
buf : 
buf : 		ieee80211_restart_hw(ar->hw);
buf : 	} else {
buf : 		/*
buf : 		 * The reset was unsuccessful and the device seems to
buf : 		 * be dead. But there's still one option: a low-level
buf : 		 * usb subsystem reset...
buf : 		 */
buf : 
buf : 		carl9170_usb_reset(ar);
buf : 	}
buf : }
buf : 
buf : void carl9170_restart(struct ar9170 *ar, const enum carl9170_restart_reasons r)
buf : {
buf : 	carl9170_set_state_when(ar, CARL9170_STARTED, CARL9170_IDLE);
buf : 
buf : 	/*
buf : 	 * Sometimes, an error can trigger several different reset events.
ifferent reset events. 
buf : 	 * By ignoring these *surplus* reset events, the device won't be
buf : 	 * killed again, right after it has recovered.
buf : 	 */
buf : 	if (atomic_inc_return(&ar->pending_restarts) > 1) {
if (atomic_inc_return(&ar->pending_restarts) > 1) { 
buf : 		dev_dbg(&ar->udev->dev, "ignoring restart (%d)\n", r);
buf : 		return;
buf : 	}
buf : 
buf : 	ieee80211_stop_queues(ar->hw);
buf : 
buf : 	dev_err(&ar->udev->dev, "restart device (%d)\n", r);
buf : 
buf : 	if (!WARN_ON(r == CARL9170_RR_NO_REASON) ||
if (!WARN_ON(r == CARL9170_RR_NO_REASON) || 
buf : 	    !WARN_ON(r >= __CARL9170_RR_LAST))
buf : 		ar->last_reason = r;
buf : 
buf : 	if (!ar->registered)
if (!ar->registered) 
buf : 		return;
buf : 
buf : 	if (!IS_ACCEPTING_CMD(ar) || ar->needs_full_reset)
if (!IS_ACCEPTING_CMD(ar) || ar->needs_full_reset) 
buf : 		ar->force_usb_reset = true;
force_usb_reset = true; 
buf : 
buf : 	ieee80211_queue_work(ar->hw, &ar->restart_work);
buf : 
buf : 	/*
buf : 	 * At this point, the device instance might have vanished/disabled.
buf : 	 * So, don't put any code which access the ar9170 struct
buf : 	 * without proper protection.
buf : 	 */
buf : }
buf : 
buf : static void carl9170_ping_work(struct work_struct *work)
buf : {
buf : 	struct ar9170 *ar = container_of(work, struct ar9170, ping_work);
buf : 	int err;
buf : 
buf : 	if (!IS_STARTED(ar))
if (!IS_STARTED(ar)) 
buf : 		return;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	err = carl9170_echo_test(ar, 0xdeadbeef);
buf : 	if (err)
if (err) 
buf : 		carl9170_restart(ar, CARL9170_RR_UNRESPONSIVE_DEVICE);
buf : 	mutex_unlock(&ar->mutex);
buf : }
buf : 
buf : static int carl9170_init_interface(struct ar9170 *ar,
buf : 				   struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ath_common *common = &ar->common;
buf : 	int err;
buf : 
buf : 	if (!vif) {
if (!vif) { 
buf : 		WARN_ON_ONCE(IS_STARTED(ar));
buf : 		return 0;
buf : 	}
buf : 
buf : 	memcpy(common->macaddr, vif->addr, ETH_ALEN);
if->addr, ETH_ALEN); 
buf : 
buf : 	/* We have to fall back to software crypto, whenever
buf : 	 * the user choose to participates in an IBSS. HW
buf : 	 * offload for IBSS RSN is not supported by this driver.
for IBSS RSN is not supported by this driver. 
buf : 	 *
buf : 	 * NOTE: If the previous main interface has already
buf : 	 * disabled hw crypto offload, we have to keep this
buf : 	 * previous disable_offload setting as it was.
buf : 	 * Altough ideally, we should notify mac80211 and tell
ify mac80211 and tell 
buf : 	 * it to forget about any HW crypto offload for now.
forget about any HW crypto offload for now. 
buf : 	 */
buf : 	ar->disable_offload |= ((vif->type != NL80211_IFTYPE_STATION) &&
if->type != NL80211_IFTYPE_STATION) && 
buf : 	    (vif->type != NL80211_IFTYPE_AP));
buf : 
buf : 	/* While the driver supports HW offload in a single
buf : 	 * P2P client configuration, it doesn't support HW
buf : 	 * offload in the favourit, concurrent P2P GO+CLIENT
buf : 	 * configuration. Hence, HW offload will always be
buf : 	 * disabled for P2P.
for P2P. 
buf : 	 */
buf : 	ar->disable_offload |= vif->p2p;
if->p2p; 
buf : 
buf : 	ar->rx_software_decryption = ar->disable_offload;
buf : 
buf : 	err = carl9170_set_operating_mode(ar);
buf : 	return err;
buf : }
buf : 
buf : static int carl9170_op_add_interface(struct ieee80211_hw *hw,
buf : 				     struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct carl9170_vif_info *vif_priv = (void *) vif->drv_priv;
buf : 	struct ieee80211_vif *main_vif, *old_main = NULL;
if *main_vif, *old_main = NULL; 
buf : 	struct ar9170 *ar = hw->priv;
buf : 	int vif_id = -1, err = 0;
if_id = -1, err = 0; 
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	rcu_read_lock();
buf : 	if (vif_priv->active) {
if (vif_priv->active) { 
buf : 		/*
buf : 		 * Skip the interface structure initialization,
buf : 		 * if the vif survived the _restart call.
if the vif survived the _restart call. 
buf : 		 */
buf : 		vif_id = vif_priv->id;
if_id = vif_priv->id; 
buf : 		vif_priv->enable_beacon = false;
buf : 
buf : 		spin_lock_bh(&ar->beacon_lock);
buf : 		dev_kfree_skb_any(vif_priv->beacon);
if_priv->beacon); 
buf : 		vif_priv->beacon = NULL;
buf : 		spin_unlock_bh(&ar->beacon_lock);
buf : 
buf : 		goto init;
buf : 	}
buf : 
buf : 	/* Because the AR9170 HW's MAC doesn't provide full support for
for 
buf : 	 * multiple, independent interfaces [of different operation modes].
buf : 	 * We have to select ONE main interface [main mode of HW], but we
buf : 	 * can have multiple slaves [AKA: entry in the ACK-table].
buf : 	 *
buf : 	 * The first (from HEAD/TOP) interface in the ar->vif_list is
if_list is 
buf : 	 * always the main intf. All following intfs in this list
buf : 	 * are considered to be slave intfs.
buf : 	 */
buf : 	main_vif = carl9170_get_main_vif(ar);
if = carl9170_get_main_vif(ar); 
buf : 
buf : 	if (main_vif) {
buf : 		switch (main_vif->type) {
if->type) { 
buf : 		case NL80211_IFTYPE_STATION:
buf : 			if (vif->type == NL80211_IFTYPE_STATION)
if (vif->type == NL80211_IFTYPE_STATION) 
buf : 				break;
buf : 
buf : 			/* P2P GO [master] use-case
buf : 			 * Because the P2P GO station is selected dynamically
buf : 			 * by all participating peers of a WIFI Direct network,
buf : 			 * the driver has be able to change the main interface
buf : 			 * operating mode on the fly.
buf : 			 */
buf : 			if (main_vif->p2p && vif->p2p &&
if (main_vif->p2p && vif->p2p && 
buf : 			    vif->type == NL80211_IFTYPE_AP) {
buf : 				old_main = main_vif;
if; 
buf : 				break;
buf : 			}
buf : 
buf : 			err = -EBUSY;
buf : 			rcu_read_unlock();
buf : 
buf : 			goto unlock;
buf : 
buf : 		case NL80211_IFTYPE_MESH_POINT:
buf : 		case NL80211_IFTYPE_AP:
buf : 			if ((vif->type == NL80211_IFTYPE_STATION) ||
if ((vif->type == NL80211_IFTYPE_STATION) || 
buf : 			    (vif->type == NL80211_IFTYPE_WDS) ||
buf : 			    (vif->type == NL80211_IFTYPE_AP) ||
if->type == NL80211_IFTYPE_AP) || 
buf : 			    (vif->type == NL80211_IFTYPE_MESH_POINT))
buf : 				break;
buf : 
buf : 			err = -EBUSY;
buf : 			rcu_read_unlock();
buf : 			goto unlock;
buf : 
buf : 		default:
buf : 			rcu_read_unlock();
buf : 			goto unlock;
buf : 		}
buf : 	}
buf : 
buf : 	vif_id = bitmap_find_free_region(&ar->vif_bitmap, ar->fw.vif_num, 0);
if_id = bitmap_find_free_region(&ar->vif_bitmap, ar->fw.vif_num, 0); 
buf : 
buf : 	if (vif_id < 0) {
buf : 		rcu_read_unlock();
buf : 
buf : 		err = -ENOSPC;
buf : 		goto unlock;
buf : 	}
buf : 
buf : 	BUG_ON(ar->vif_priv[vif_id].id != vif_id);
if_priv[vif_id].id != vif_id); 
buf : 
buf : 	vif_priv->active = true;
buf : 	vif_priv->id = vif_id;
if_priv->id = vif_id; 
buf : 	vif_priv->enable_beacon = false;
buf : 	ar->vifs++;
ifs++; 
buf : 	if (old_main) {
buf : 		/* We end up in here, if the main interface is being replaced.
if the main interface is being replaced. 
buf : 		 * Put the new main interface at the HEAD of the list and the
buf : 		 * previous inteface will automatically become second in line.
buf : 		 */
buf : 		list_add_rcu(&vif_priv->list, &ar->vif_list);
if_priv->list, &ar->vif_list); 
buf : 	} else {
buf : 		/* Add new inteface. If the list is empty, it will become the
buf : 		 * main inteface, otherwise it will be slave.
buf : 		 */
buf : 		list_add_tail_rcu(&vif_priv->list, &ar->vif_list);
if_priv->list, &ar->vif_list); 
buf : 	}
buf : 	rcu_assign_pointer(ar->vif_priv[vif_id].vif, vif);
buf : 
buf : init:
buf : 	main_vif = carl9170_get_main_vif(ar);
if = carl9170_get_main_vif(ar); 
buf : 
buf : 	if (main_vif == vif) {
buf : 		rcu_assign_pointer(ar->beacon_iter, vif_priv);
if_priv); 
buf : 		rcu_read_unlock();
buf : 
buf : 		if (old_main) {
if (old_main) { 
buf : 			struct carl9170_vif_info *old_main_priv =
buf : 				(void *) old_main->drv_priv;
buf : 			/* downgrade old main intf to slave intf.
buf : 			 * NOTE: We are no longer under rcu_read_lock.
buf : 			 * But we are still holding ar->mutex, so the
buf : 			 * vif data [id, addr] is safe.
if data [id, addr] is safe. 
buf : 			 */
buf : 			err = carl9170_mod_virtual_mac(ar, old_main_priv->id,
buf : 						       old_main->addr);
buf : 			if (err)
if (err) 
buf : 				goto unlock;
buf : 		}
buf : 
buf : 		err = carl9170_init_interface(ar, vif);
if); 
buf : 		if (err)
buf : 			goto unlock;
buf : 	} else {
buf : 		rcu_read_unlock();
buf : 		err = carl9170_mod_virtual_mac(ar, vif_id, vif->addr);
if_id, vif->addr); 
buf : 
buf : 		if (err)
buf : 			goto unlock;
buf : 	}
buf : 
buf : 	if (ar->fw.tx_seq_table) {
if (ar->fw.tx_seq_table) { 
buf : 		err = carl9170_write_reg(ar, ar->fw.tx_seq_table + vif_id * 4,
buf : 					 0);
buf : 		if (err)
if (err) 
buf : 			goto unlock;
buf : 	}
buf : 
buf : unlock:
buf : 	if (err && (vif_id >= 0)) {
if (err && (vif_id >= 0)) { 
buf : 		vif_priv->active = false;
buf : 		bitmap_release_region(&ar->vif_bitmap, vif_id, 0);
if_bitmap, vif_id, 0); 
buf : 		ar->vifs--;
buf : 		RCU_INIT_POINTER(ar->vif_priv[vif_id].vif, NULL);
if_priv[vif_id].vif, NULL); 
buf : 		list_del_rcu(&vif_priv->list);
buf : 		mutex_unlock(&ar->mutex);
buf : 		synchronize_rcu();
buf : 	} else {
buf : 		if (ar->vifs > 1)
if (ar->vifs > 1) 
buf : 			ar->ps.off_override |= PS_OFF_VIF;
buf : 
buf : 		mutex_unlock(&ar->mutex);
buf : 	}
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void carl9170_op_remove_interface(struct ieee80211_hw *hw,
buf : 					 struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct carl9170_vif_info *vif_priv = (void *) vif->drv_priv;
buf : 	struct ieee80211_vif *main_vif;
if *main_vif; 
buf : 	struct ar9170 *ar = hw->priv;
buf : 	unsigned int id;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 
buf : 	if (WARN_ON_ONCE(!vif_priv->active))
if (WARN_ON_ONCE(!vif_priv->active)) 
buf : 		goto unlock;
buf : 
buf : 	ar->vifs--;
ifs--; 
buf : 
buf : 	rcu_read_lock();
buf : 	main_vif = carl9170_get_main_vif(ar);
if = carl9170_get_main_vif(ar); 
buf : 
buf : 	id = vif_priv->id;
buf : 
buf : 	vif_priv->active = false;
if_priv->active = false; 
buf : 	WARN_ON(vif_priv->enable_beacon);
buf : 	vif_priv->enable_beacon = false;
if_priv->enable_beacon = false; 
buf : 	list_del_rcu(&vif_priv->list);
buf : 	RCU_INIT_POINTER(ar->vif_priv[id].vif, NULL);
if_priv[id].vif, NULL); 
buf : 
buf : 	if (vif == main_vif) {
buf : 		rcu_read_unlock();
buf : 
buf : 		if (ar->vifs) {
if (ar->vifs) { 
buf : 			WARN_ON(carl9170_init_interface(ar,
buf : 					carl9170_get_main_vif(ar)));
if(ar))); 
buf : 		} else {
buf : 			carl9170_set_operating_mode(ar);
buf : 		}
buf : 	} else {
buf : 		rcu_read_unlock();
buf : 
buf : 		WARN_ON(carl9170_mod_virtual_mac(ar, id, NULL));
buf : 	}
buf : 
buf : 	carl9170_update_beacon(ar, false);
buf : 	carl9170_flush_cab(ar, id);
buf : 
buf : 	spin_lock_bh(&ar->beacon_lock);
buf : 	dev_kfree_skb_any(vif_priv->beacon);
if_priv->beacon); 
buf : 	vif_priv->beacon = NULL;
buf : 	spin_unlock_bh(&ar->beacon_lock);
buf : 
buf : 	bitmap_release_region(&ar->vif_bitmap, id, 0);
if_bitmap, id, 0); 
buf : 
buf : 	carl9170_set_beacon_timers(ar);
buf : 
buf : 	if (ar->vifs == 1)
if (ar->vifs == 1) 
buf : 		ar->ps.off_override &= ~PS_OFF_VIF;
buf : 
buf : unlock:
buf : 	mutex_unlock(&ar->mutex);
buf : 
buf : 	synchronize_rcu();
buf : }
buf : 
buf : void carl9170_ps_check(struct ar9170 *ar)
buf : {
buf : 	ieee80211_queue_work(ar->hw, &ar->ps_work);
buf : }
buf : 
buf : /* caller must hold ar->mutex */
buf : static int carl9170_ps_update(struct ar9170 *ar)
buf : {
buf : 	bool ps = false;
buf : 	int err = 0;
buf : 
buf : 	if (!ar->ps.off_override)
if (!ar->ps.off_override) 
buf : 		ps = (ar->hw->conf.flags & IEEE80211_CONF_PS);
buf : 
buf : 	if (ps != ar->ps.state) {
if (ps != ar->ps.state) { 
buf : 		err = carl9170_powersave(ar, ps);
buf : 		if (err)
if (err) 
buf : 			return err;
buf : 
buf : 		if (ar->ps.state && !ps) {
if (ar->ps.state && !ps) { 
buf : 			ar->ps.sleep_ms = jiffies_to_msecs(jiffies -
buf : 				ar->ps.last_action);
buf : 		}
buf : 
buf : 		if (ps)
if (ps) 
buf : 			ar->ps.last_slept = jiffies;
buf : 
buf : 		ar->ps.last_action = jiffies;
iffies; 
buf : 		ar->ps.state = ps;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void carl9170_ps_work(struct work_struct *work)
buf : {
buf : 	struct ar9170 *ar = container_of(work, struct ar9170,
buf : 					 ps_work);
buf : 	mutex_lock(&ar->mutex);
buf : 	if (IS_STARTED(ar))
if (IS_STARTED(ar)) 
buf : 		WARN_ON_ONCE(carl9170_ps_update(ar) != 0);
buf : 	mutex_unlock(&ar->mutex);
buf : }
buf : 
buf : static int carl9170_update_survey(struct ar9170 *ar, bool flush, bool noise)
buf : {
buf : 	int err;
buf : 
buf : 	if (noise) {
if (noise) { 
buf : 		err = carl9170_get_noisefloor(ar);
buf : 		if (err)
if (err) 
buf : 			return err;
buf : 	}
buf : 
buf : 	if (ar->fw.hw_counters) {
if (ar->fw.hw_counters) { 
buf : 		err = carl9170_collect_tally(ar);
buf : 		if (err)
if (err) 
buf : 			return err;
buf : 	}
buf : 
buf : 	if (flush)
if (flush) 
buf : 		memset(&ar->tally, 0, sizeof(ar->tally));
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void carl9170_stat_work(struct work_struct *work)
buf : {
buf : 	struct ar9170 *ar = container_of(work, struct ar9170, stat_work.work);
buf : 	int err;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	err = carl9170_update_survey(ar, false, true);
buf : 	mutex_unlock(&ar->mutex);
buf : 
buf : 	if (err)
if (err) 
buf : 		return;
buf : 
buf : 	ieee80211_queue_delayed_work(ar->hw, &ar->stat_work,
buf : 		round_jiffies(msecs_to_jiffies(CARL9170_STAT_WORK)));
iffies(msecs_to_jiffies(CARL9170_STAT_WORK))); 
buf : }
buf : 
buf : static int carl9170_op_config(struct ieee80211_hw *hw, u32 changed)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	int err = 0;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	if (changed & IEEE80211_CONF_CHANGE_LISTEN_INTERVAL) {
if (changed & IEEE80211_CONF_CHANGE_LISTEN_INTERVAL) { 
buf : 		/* TODO */
buf : 		err = 0;
buf : 	}
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_PS) {
if (changed & IEEE80211_CONF_CHANGE_PS) { 
buf : 		err = carl9170_ps_update(ar);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_SMPS) {
if (changed & IEEE80211_CONF_CHANGE_SMPS) { 
buf : 		/* TODO */
buf : 		err = 0;
buf : 	}
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_CHANNEL) {
if (changed & IEEE80211_CONF_CHANGE_CHANNEL) { 
buf : 		enum nl80211_channel_type channel_type =
buf : 			cfg80211_get_chandef_type(&hw->conf.chandef);
buf : 
buf : 		/* adjust slot time for 5 GHz */
for 5 GHz */ 
buf : 		err = carl9170_set_slot_time(ar);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 
buf : 		err = carl9170_update_survey(ar, true, false);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 
buf : 		err = carl9170_set_channel(ar, hw->conf.chandef.chan,
buf : 					   channel_type);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 
buf : 		err = carl9170_update_survey(ar, false, true);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 
buf : 		err = carl9170_set_dyn_sifs_ack(ar);
ifs_ack(ar); 
buf : 		if (err)
buf : 			goto out;
buf : 
buf : 		err = carl9170_set_rts_cts_rate(ar);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_POWER) {
if (changed & IEEE80211_CONF_CHANGE_POWER) { 
buf : 		err = carl9170_set_mac_tpc(ar, ar->hw->conf.chandef.chan);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : out:
buf : 	mutex_unlock(&ar->mutex);
buf : 	return err;
buf : }
buf : 
buf : static u64 carl9170_op_prepare_multicast(struct ieee80211_hw *hw,
buf : 					 struct netdev_hw_addr_list *mc_list)
buf : {
buf : 	struct netdev_hw_addr *ha;
buf : 	u64 mchash;
buf : 
buf : 	/* always get broadcast frames */
buf : 	mchash = 1ULL << (0xff >> 2);
buf : 
buf : 	netdev_hw_addr_list_for_each(ha, mc_list)
for_each(ha, mc_list) 
buf : 		mchash |= 1ULL << (ha->addr[5] >> 2);
buf : 
buf : 	return mchash;
buf : }
buf : 
buf : static void carl9170_op_configure_filter(struct ieee80211_hw *hw,
buf : 					 unsigned int changed_flags,
buf : 					 unsigned int *new_flags,
buf : 					 u64 multicast)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 
buf : 	/* mask supported flags */
buf : 	*new_flags &= FIF_ALLMULTI | ar->rx_filter_caps;
buf : 
buf : 	if (!IS_ACCEPTING_CMD(ar))
if (!IS_ACCEPTING_CMD(ar)) 
buf : 		return;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 
buf : 	ar->filter_state = *new_flags;
buf : 	/*
buf : 	 * We can support more by setting the sniffer bit and
iffer bit and 
buf : 	 * then checking the error flags, later.
buf : 	 */
buf : 
buf : 	if (*new_flags & FIF_ALLMULTI)
if (*new_flags & FIF_ALLMULTI) 
buf : 		multicast = ~0ULL;
buf : 
buf : 	if (multicast != ar->cur_mc_hash)
if (multicast != ar->cur_mc_hash) 
buf : 		WARN_ON(carl9170_update_multicast(ar, multicast));
buf : 
buf : 	if (changed_flags & (FIF_OTHER_BSS | FIF_PROMISC_IN_BSS)) {
if (changed_flags & (FIF_OTHER_BSS | FIF_PROMISC_IN_BSS)) { 
buf : 		ar->sniffer_enabled = !!(*new_flags &
buf : 			(FIF_OTHER_BSS | FIF_PROMISC_IN_BSS));
buf : 
buf : 		WARN_ON(carl9170_set_operating_mode(ar));
buf : 	}
buf : 
buf : 	if (ar->fw.rx_filter && changed_flags & ar->rx_filter_caps) {
if (ar->fw.rx_filter && changed_flags & ar->rx_filter_caps) { 
buf : 		u32 rx_filter = 0;
buf : 
buf : 		if (!ar->fw.ba_filter)
if (!ar->fw.ba_filter) 
buf : 			rx_filter |= CARL9170_RX_FILTER_CTL_OTHER;
buf : 
buf : 		if (!(*new_flags & (FIF_FCSFAIL | FIF_PLCPFAIL)))
if (!(*new_flags & (FIF_FCSFAIL | FIF_PLCPFAIL))) 
buf : 			rx_filter |= CARL9170_RX_FILTER_BAD;
buf : 
buf : 		if (!(*new_flags & FIF_CONTROL))
if (!(*new_flags & FIF_CONTROL)) 
buf : 			rx_filter |= CARL9170_RX_FILTER_CTL_OTHER;
buf : 
buf : 		if (!(*new_flags & FIF_PSPOLL))
if (!(*new_flags & FIF_PSPOLL)) 
buf : 			rx_filter |= CARL9170_RX_FILTER_CTL_PSPOLL;
buf : 
buf : 		if (!(*new_flags & (FIF_OTHER_BSS | FIF_PROMISC_IN_BSS))) {
if (!(*new_flags & (FIF_OTHER_BSS | FIF_PROMISC_IN_BSS))) { 
buf : 			rx_filter |= CARL9170_RX_FILTER_OTHER_RA;
buf : 			rx_filter |= CARL9170_RX_FILTER_DECRY_FAIL;
buf : 		}
buf : 
buf : 		WARN_ON(carl9170_rx_filter(ar, rx_filter));
buf : 	}
buf : 
buf : 	mutex_unlock(&ar->mutex);
buf : }
buf : 
buf : 
buf : static void carl9170_op_bss_info_changed(struct ieee80211_hw *hw,
buf : 					 struct ieee80211_vif *vif,
if *vif, 
buf : 					 struct ieee80211_bss_conf *bss_conf,
buf : 					 u32 changed)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	struct ath_common *common = &ar->common;
buf : 	int err = 0;
buf : 	struct carl9170_vif_info *vif_priv;
if_info *vif_priv; 
buf : 	struct ieee80211_vif *main_vif;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	vif_priv = (void *) vif->drv_priv;
if_priv = (void *) vif->drv_priv; 
buf : 	main_vif = carl9170_get_main_vif(ar);
buf : 	if (WARN_ON(!main_vif))
if (WARN_ON(!main_vif)) 
buf : 		goto out;
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON_ENABLED) {
if (changed & BSS_CHANGED_BEACON_ENABLED) { 
buf : 		struct carl9170_vif_info *iter;
buf : 		int i = 0;
buf : 
buf : 		vif_priv->enable_beacon = bss_conf->enable_beacon;
if_priv->enable_beacon = bss_conf->enable_beacon; 
buf : 		rcu_read_lock();
buf : 		list_for_each_entry_rcu(iter, &ar->vif_list, list) {
if_list, list) { 
buf : 			if (iter->active && iter->enable_beacon)
buf : 				i++;
buf : 
buf : 		}
buf : 		rcu_read_unlock();
buf : 
buf : 		ar->beacon_enabled = i;
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON) {
if (changed & BSS_CHANGED_BEACON) { 
buf : 		err = carl9170_update_beacon(ar, false);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (changed & (BSS_CHANGED_BEACON_ENABLED | BSS_CHANGED_BEACON |
if (changed & (BSS_CHANGED_BEACON_ENABLED | BSS_CHANGED_BEACON | 
buf : 		       BSS_CHANGED_BEACON_INT)) {
buf : 
buf : 		if (main_vif != vif) {
if (main_vif != vif) { 
buf : 			bss_conf->beacon_int = main_vif->bss_conf.beacon_int;
buf : 			bss_conf->dtim_period = main_vif->bss_conf.dtim_period;
if->bss_conf.dtim_period; 
buf : 		}
buf : 
buf : 		/*
buf : 		 * Therefore a hard limit for the broadcast traffic should
fore a hard limit for the broadcast traffic should 
buf : 		 * prevent false alarms.
buf : 		 */
buf : 		if (vif->type != NL80211_IFTYPE_STATION &&
if (vif->type != NL80211_IFTYPE_STATION && 
buf : 		    (bss_conf->beacon_int * bss_conf->dtim_period >=
buf : 		     (CARL9170_QUEUE_STUCK_TIMEOUT / 2))) {
buf : 			err = -EINVAL;
buf : 			goto out;
buf : 		}
buf : 
buf : 		err = carl9170_set_beacon_timers(ar);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_HT) {
if (changed & BSS_CHANGED_HT) { 
buf : 		/* TODO */
buf : 		err = 0;
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (main_vif != vif)
if (main_vif != vif) 
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * The following settings can only be changed by the
buf : 	 * master interface.
buf : 	 */
buf : 
buf : 	if (changed & BSS_CHANGED_BSSID) {
if (changed & BSS_CHANGED_BSSID) { 
buf : 		memcpy(common->curbssid, bss_conf->bssid, ETH_ALEN);
buf : 		err = carl9170_set_operating_mode(ar);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ASSOC) {
if (changed & BSS_CHANGED_ASSOC) { 
buf : 		ar->common.curaid = bss_conf->aid;
buf : 		err = carl9170_set_beacon_timers(ar);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ERP_SLOT) {
if (changed & BSS_CHANGED_ERP_SLOT) { 
buf : 		err = carl9170_set_slot_time(ar);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_BASIC_RATES) {
if (changed & BSS_CHANGED_BASIC_RATES) { 
buf : 		err = carl9170_set_mac_rates(ar);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : out:
buf : 	WARN_ON_ONCE(err && IS_STARTED(ar));
buf : 	mutex_unlock(&ar->mutex);
buf : }
buf : 
buf : static u64 carl9170_op_get_tsf(struct ieee80211_hw *hw,
buf : 			       struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	struct carl9170_tsf_rsp tsf;
buf : 	int err;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	err = carl9170_exec_cmd(ar, CARL9170_CMD_READ_TSF,
buf : 				0, NULL, sizeof(tsf), &tsf);
buf : 	mutex_unlock(&ar->mutex);
buf : 	if (WARN_ON(err))
if (WARN_ON(err)) 
buf : 		return 0;
buf : 
buf : 	return le64_to_cpu(tsf.tsf_64);
buf : }
buf : 
buf : static int carl9170_op_set_key(struct ieee80211_hw *hw, enum set_key_cmd cmd,
buf : 			       struct ieee80211_vif *vif,
if *vif, 
buf : 			       struct ieee80211_sta *sta,
buf : 			       struct ieee80211_key_conf *key)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	int err = 0, i;
buf : 	u8 ktype;
buf : 
buf : 	if (ar->disable_offload || !vif)
if (ar->disable_offload || !vif) 
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	/* Fall back to software encryption whenever the driver is connected
buf : 	 * to more than one network.
buf : 	 *
buf : 	 * This is very unfortunate, because some machines cannot handle
fortunate, because some machines cannot handle 
buf : 	 * the high througput speed in 802.11n networks.
buf : 	 */
buf : 
buf : 	if (!is_main_vif(ar, vif)) {
if (!is_main_vif(ar, vif)) { 
buf : 		mutex_lock(&ar->mutex);
buf : 		goto err_softw;
buf : 	}
buf : 
buf : 	/*
buf : 	 * While the hardware supports *catch-all* key, for offloading
for offloading 
buf : 	 * group-key en-/de-cryption. The way of how the hardware
buf : 	 * decides which keyId maps to which key, remains a mystery...
buf : 	 */
buf : 	if ((vif->type != NL80211_IFTYPE_STATION &&
if ((vif->type != NL80211_IFTYPE_STATION && 
buf : 	     vif->type != NL80211_IFTYPE_ADHOC) &&
buf : 	    !(key->flags & IEEE80211_KEY_FLAG_PAIRWISE))
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	switch (key->cipher) {
buf : 	case WLAN_CIPHER_SUITE_WEP40:
buf : 		ktype = AR9170_ENC_ALG_WEP64;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_WEP104:
buf : 		ktype = AR9170_ENC_ALG_WEP128;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_TKIP:
buf : 		ktype = AR9170_ENC_ALG_TKIP;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_CCMP:
buf : 		ktype = AR9170_ENC_ALG_AESCCMP;
buf : 		key->flags |= IEEE80211_KEY_FLAG_SW_MGMT_TX;
buf : 		break;
buf : 	default:
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	if (cmd == SET_KEY) {
if (cmd == SET_KEY) { 
buf : 		if (!IS_STARTED(ar)) {
buf : 			err = -EOPNOTSUPP;
buf : 			goto out;
buf : 		}
buf : 
buf : 		if (!(key->flags & IEEE80211_KEY_FLAG_PAIRWISE)) {
if (!(key->flags & IEEE80211_KEY_FLAG_PAIRWISE)) { 
buf : 			sta = NULL;
buf : 
buf : 			i = 64 + key->keyidx;
buf : 		} else {
buf : 			for (i = 0; i < 64; i++)
for (i = 0; i < 64; i++) 
buf : 				if (!(ar->usedkeys & BIT(i)))
buf : 					break;
buf : 			if (i == 64)
if (i == 64) 
buf : 				goto err_softw;
buf : 		}
buf : 
buf : 		key->hw_key_idx = i;
buf : 
buf : 		err = carl9170_upload_key(ar, i, sta ? sta->addr : NULL,
buf : 					  ktype, 0, key->key,
buf : 					  min_t(u8, 16, key->keylen));
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 
buf : 		if (key->cipher == WLAN_CIPHER_SUITE_TKIP) {
if (key->cipher == WLAN_CIPHER_SUITE_TKIP) { 
buf : 			err = carl9170_upload_key(ar, i, sta ? sta->addr :
buf : 						  NULL, ktype, 1,
buf : 						  key->key + 16, 16);
buf : 			if (err)
if (err) 
buf : 				goto out;
buf : 
buf : 			/*
buf : 			 * hardware is not capable generating MMIC
buf : 			 * of fragmented frames!
buf : 			 */
buf : 			key->flags |= IEEE80211_KEY_FLAG_GENERATE_MMIC;
buf : 		}
buf : 
buf : 		if (i < 64)
if (i < 64) 
buf : 			ar->usedkeys |= BIT(i);
buf : 
buf : 		key->flags |= IEEE80211_KEY_FLAG_GENERATE_IV;
buf : 	} else {
buf : 		if (!IS_STARTED(ar)) {
if (!IS_STARTED(ar)) { 
buf : 			/* The device is gone... together with the key ;-) */
buf : 			err = 0;
buf : 			goto out;
buf : 		}
buf : 
buf : 		if (key->hw_key_idx < 64) {
if (key->hw_key_idx < 64) { 
buf : 			ar->usedkeys &= ~BIT(key->hw_key_idx);
buf : 		} else {
buf : 			err = carl9170_upload_key(ar, key->hw_key_idx, NULL,
buf : 						  AR9170_ENC_ALG_NONE, 0,
buf : 						  NULL, 0);
buf : 			if (err)
if (err) 
buf : 				goto out;
buf : 
buf : 			if (key->cipher == WLAN_CIPHER_SUITE_TKIP) {
if (key->cipher == WLAN_CIPHER_SUITE_TKIP) { 
buf : 				err = carl9170_upload_key(ar, key->hw_key_idx,
buf : 							  NULL,
buf : 							  AR9170_ENC_ALG_NONE,
buf : 							  1, NULL, 0);
buf : 				if (err)
if (err) 
buf : 					goto out;
buf : 			}
buf : 
buf : 		}
buf : 
buf : 		err = carl9170_disable_key(ar, key->hw_key_idx);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 
buf : out:
buf : 	mutex_unlock(&ar->mutex);
buf : 	return err;
buf : 
buf : err_softw:
buf : 	if (!ar->rx_software_decryption) {
if (!ar->rx_software_decryption) { 
buf : 		ar->rx_software_decryption = true;
buf : 		carl9170_set_operating_mode(ar);
buf : 	}
buf : 	mutex_unlock(&ar->mutex);
buf : 	return -ENOSPC;
buf : }
buf : 
buf : static int carl9170_op_sta_add(struct ieee80211_hw *hw,
buf : 			       struct ieee80211_vif *vif,
if *vif, 
buf : 			       struct ieee80211_sta *sta)
buf : {
buf : 	struct carl9170_sta_info *sta_info = (void *) sta->drv_priv;
buf : 	unsigned int i;
buf : 
buf : 	atomic_set(&sta_info->pending_frames, 0);
buf : 
buf : 	if (sta->ht_cap.ht_supported) {
if (sta->ht_cap.ht_supported) { 
buf : 		if (sta->ht_cap.ampdu_density > 6) {
buf : 			/*
buf : 			 * HW does support 16us AMPDU density.
buf : 			 * No HT-Xmit for station.
for station. 
buf : 			 */
buf : 
buf : 			return 0;
buf : 		}
buf : 
buf : 		for (i = 0; i < ARRAY_SIZE(sta_info->agg); i++)
for (i = 0; i < ARRAY_SIZE(sta_info->agg); i++) 
buf : 			RCU_INIT_POINTER(sta_info->agg[i], NULL);
buf : 
buf : 		sta_info->ampdu_max_len = 1 << (3 + sta->ht_cap.ampdu_factor);
buf : 		sta_info->ht_sta = true;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int carl9170_op_sta_remove(struct ieee80211_hw *hw,
buf : 				struct ieee80211_vif *vif,
if *vif, 
buf : 				struct ieee80211_sta *sta)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	struct carl9170_sta_info *sta_info = (void *) sta->drv_priv;
buf : 	unsigned int i;
buf : 	bool cleanup = false;
buf : 
buf : 	if (sta->ht_cap.ht_supported) {
if (sta->ht_cap.ht_supported) { 
buf : 
buf : 		sta_info->ht_sta = false;
buf : 
buf : 		rcu_read_lock();
buf : 		for (i = 0; i < ARRAY_SIZE(sta_info->agg); i++) {
for (i = 0; i < ARRAY_SIZE(sta_info->agg); i++) { 
buf : 			struct carl9170_sta_tid *tid_info;
buf : 
buf : 			tid_info = rcu_dereference(sta_info->agg[i]);
buf : 			RCU_INIT_POINTER(sta_info->agg[i], NULL);
buf : 
buf : 			if (!tid_info)
if (!tid_info) 
buf : 				continue;
buf : 
buf : 			spin_lock_bh(&ar->tx_ampdu_list_lock);
buf : 			if (tid_info->state > CARL9170_TID_STATE_SHUTDOWN)
if (tid_info->state > CARL9170_TID_STATE_SHUTDOWN) 
buf : 				tid_info->state = CARL9170_TID_STATE_SHUTDOWN;
buf : 			spin_unlock_bh(&ar->tx_ampdu_list_lock);
buf : 			cleanup = true;
buf : 		}
buf : 		rcu_read_unlock();
buf : 
buf : 		if (cleanup)
if (cleanup) 
buf : 			carl9170_ampdu_gc(ar);
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int carl9170_op_conf_tx(struct ieee80211_hw *hw,
buf : 			       struct ieee80211_vif *vif, u16 queue,
if *vif, u16 queue, 
buf : 			       const struct ieee80211_tx_queue_params *param)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	int ret;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	if (queue < ar->hw->queues) {
if (queue < ar->hw->queues) { 
buf : 		memcpy(&ar->edcf[ar9170_qmap[queue]], param, sizeof(*param));
buf : 		ret = carl9170_set_qos(ar);
buf : 	} else {
buf : 		ret = -EINVAL;
buf : 	}
buf : 
buf : 	mutex_unlock(&ar->mutex);
buf : 	return ret;
buf : }
buf : 
buf : static void carl9170_ampdu_work(struct work_struct *work)
buf : {
buf : 	struct ar9170 *ar = container_of(work, struct ar9170,
buf : 					 ampdu_work);
buf : 
buf : 	if (!IS_STARTED(ar))
if (!IS_STARTED(ar)) 
buf : 		return;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	carl9170_ampdu_gc(ar);
buf : 	mutex_unlock(&ar->mutex);
buf : }
buf : 
buf : static int carl9170_op_ampdu_action(struct ieee80211_hw *hw,
buf : 				    struct ieee80211_vif *vif,
if *vif, 
buf : 				    enum ieee80211_ampdu_mlme_action action,
buf : 				    struct ieee80211_sta *sta,
buf : 				    u16 tid, u16 *ssn, u8 buf_size)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	struct carl9170_sta_info *sta_info = (void *) sta->drv_priv;
buf : 	struct carl9170_sta_tid *tid_info;
buf : 
buf : 	if (modparam_noht)
if (modparam_noht) 
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	switch (action) {
buf : 	case IEEE80211_AMPDU_TX_START:
buf : 		if (!sta_info->ht_sta)
if (!sta_info->ht_sta) 
buf : 			return -EOPNOTSUPP;
buf : 
buf : 		rcu_read_lock();
buf : 		if (rcu_dereference(sta_info->agg[tid])) {
if (rcu_dereference(sta_info->agg[tid])) { 
buf : 			rcu_read_unlock();
buf : 			return -EBUSY;
buf : 		}
buf : 
buf : 		tid_info = kzalloc(sizeof(struct carl9170_sta_tid),
buf : 				   GFP_ATOMIC);
buf : 		if (!tid_info) {
if (!tid_info) { 
buf : 			rcu_read_unlock();
buf : 			return -ENOMEM;
buf : 		}
buf : 
buf : 		tid_info->hsn = tid_info->bsn = tid_info->snx = (*ssn);
buf : 		tid_info->state = CARL9170_TID_STATE_PROGRESS;
buf : 		tid_info->tid = tid;
buf : 		tid_info->max = sta_info->ampdu_max_len;
buf : 		tid_info->sta = sta;
buf : 		tid_info->vif = vif;
if = vif; 
buf : 
buf : 		INIT_LIST_HEAD(&tid_info->list);
buf : 		INIT_LIST_HEAD(&tid_info->tmp_list);
buf : 		skb_queue_head_init(&tid_info->queue);
buf : 		spin_lock_init(&tid_info->lock);
buf : 
buf : 		spin_lock_bh(&ar->tx_ampdu_list_lock);
buf : 		ar->tx_ampdu_list_len++;
buf : 		list_add_tail_rcu(&tid_info->list, &ar->tx_ampdu_list);
buf : 		rcu_assign_pointer(sta_info->agg[tid], tid_info);
buf : 		spin_unlock_bh(&ar->tx_ampdu_list_lock);
buf : 		rcu_read_unlock();
buf : 
buf : 		ieee80211_start_tx_ba_cb_irqsafe(vif, sta->addr, tid);
if, sta->addr, tid); 
buf : 		break;
buf : 
buf : 	case IEEE80211_AMPDU_TX_STOP_CONT:
buf : 	case IEEE80211_AMPDU_TX_STOP_FLUSH:
buf : 	case IEEE80211_AMPDU_TX_STOP_FLUSH_CONT:
buf : 		rcu_read_lock();
buf : 		tid_info = rcu_dereference(sta_info->agg[tid]);
buf : 		if (tid_info) {
if (tid_info) { 
buf : 			spin_lock_bh(&ar->tx_ampdu_list_lock);
buf : 			if (tid_info->state > CARL9170_TID_STATE_SHUTDOWN)
if (tid_info->state > CARL9170_TID_STATE_SHUTDOWN) 
buf : 				tid_info->state = CARL9170_TID_STATE_SHUTDOWN;
buf : 			spin_unlock_bh(&ar->tx_ampdu_list_lock);
buf : 		}
buf : 
buf : 		RCU_INIT_POINTER(sta_info->agg[tid], NULL);
buf : 		rcu_read_unlock();
buf : 
buf : 		ieee80211_stop_tx_ba_cb_irqsafe(vif, sta->addr, tid);
if, sta->addr, tid); 
buf : 		ieee80211_queue_work(ar->hw, &ar->ampdu_work);
buf : 		break;
buf : 
buf : 	case IEEE80211_AMPDU_TX_OPERATIONAL:
buf : 		rcu_read_lock();
buf : 		tid_info = rcu_dereference(sta_info->agg[tid]);
buf : 
buf : 		sta_info->stats[tid].clear = true;
buf : 		sta_info->stats[tid].req = false;
buf : 
buf : 		if (tid_info) {
if (tid_info) { 
buf : 			bitmap_zero(tid_info->bitmap, CARL9170_BAW_SIZE);
buf : 			tid_info->state = CARL9170_TID_STATE_IDLE;
buf : 		}
buf : 		rcu_read_unlock();
buf : 
buf : 		if (WARN_ON_ONCE(!tid_info))
if (WARN_ON_ONCE(!tid_info)) 
buf : 			return -EFAULT;
buf : 
buf : 		break;
buf : 
buf : 	case IEEE80211_AMPDU_RX_START:
buf : 	case IEEE80211_AMPDU_RX_STOP:
buf : 		/* Handled by hardware */
buf : 		break;
buf : 
buf : 	default:
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : #ifdef CONFIG_CARL9170_WPC
ifdef CONFIG_CARL9170_WPC 
buf : static int carl9170_register_wps_button(struct ar9170 *ar)
buf : {
buf : 	struct input_dev *input;
buf : 	int err;
buf : 
buf : 	if (!(ar->features & CARL9170_WPS_BUTTON))
if (!(ar->features & CARL9170_WPS_BUTTON)) 
buf : 		return 0;
buf : 
buf : 	input = input_allocate_device();
buf : 	if (!input)
if (!input) 
buf : 		return -ENOMEM;
buf : 
buf : 	snprintf(ar->wps.name, sizeof(ar->wps.name), "%s WPS Button",
buf : 		 wiphy_name(ar->hw->wiphy));
buf : 
buf : 	snprintf(ar->wps.phys, sizeof(ar->wps.phys),
buf : 		 "ieee80211/%s/input0", wiphy_name(ar->hw->wiphy));
buf : 
buf : 	input->name = ar->wps.name;
buf : 	input->phys = ar->wps.phys;
buf : 	input->id.bustype = BUS_USB;
buf : 	input->dev.parent = &ar->hw->wiphy->dev;
buf : 
buf : 	input_set_capability(input, EV_KEY, KEY_WPS_BUTTON);
buf : 
buf : 	err = input_register_device(input);
buf : 	if (err) {
if (err) { 
buf : 		input_free_device(input);
buf : 		return err;
buf : 	}
buf : 
buf : 	ar->wps.pbc = input;
buf : 	return 0;
buf : }
buf : #endif /* CONFIG_CARL9170_WPC */
if /* CONFIG_CARL9170_WPC */ 
buf : 
buf : #ifdef CONFIG_CARL9170_HWRNG
buf : static int carl9170_rng_get(struct ar9170 *ar)
buf : {
buf : 
buf : #define RW	(CARL9170_MAX_CMD_PAYLOAD_LEN / sizeof(u32))
buf : #define RB	(CARL9170_MAX_CMD_PAYLOAD_LEN)
buf : 
buf : 	static const __le32 rng_load[RW] = {
buf : 		[0 ... (RW - 1)] = cpu_to_le32(AR9170_RAND_REG_NUM)};
buf : 
buf : 	u32 buf[RW];
buf : 
buf : 	unsigned int i, off = 0, transfer, count;
buf : 	int err;
buf : 
buf : 	BUILD_BUG_ON(RB > CARL9170_MAX_CMD_PAYLOAD_LEN);
buf : 
buf : 	if (!IS_ACCEPTING_CMD(ar) || !ar->rng.initialized)
if (!IS_ACCEPTING_CMD(ar) || !ar->rng.initialized) 
buf : 		return -EAGAIN;
buf : 
buf : 	count = ARRAY_SIZE(ar->rng.cache);
buf : 	while (count) {
while (count) { 
buf : 		err = carl9170_exec_cmd(ar, CARL9170_CMD_RREG,
buf : 					RB, (u8 *) rng_load,
buf : 					RB, (u8 *) buf);
buf : 		if (err)
if (err) 
buf : 			return err;
buf : 
buf : 		transfer = min_t(unsigned int, count, RW);
buf : 		for (i = 0; i < transfer; i++)
for (i = 0; i < transfer; i++) 
buf : 			ar->rng.cache[off + i] = buf[i];
buf : 
buf : 		off += transfer;
buf : 		count -= transfer;
buf : 	}
buf : 
buf : 	ar->rng.cache_idx = 0;
buf : 
buf : #undef RW
buf : #undef RB
buf : 	return 0;
buf : }
buf : 
buf : static int carl9170_rng_read(struct hwrng *rng, u32 *data)
buf : {
buf : 	struct ar9170 *ar = (struct ar9170 *)rng->priv;
buf : 	int ret = -EIO;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	if (ar->rng.cache_idx >= ARRAY_SIZE(ar->rng.cache)) {
if (ar->rng.cache_idx >= ARRAY_SIZE(ar->rng.cache)) { 
buf : 		ret = carl9170_rng_get(ar);
buf : 		if (ret) {
if (ret) { 
buf : 			mutex_unlock(&ar->mutex);
buf : 			return ret;
buf : 		}
buf : 	}
buf : 
buf : 	*data = ar->rng.cache[ar->rng.cache_idx++];
buf : 	mutex_unlock(&ar->mutex);
buf : 
buf : 	return sizeof(u16);
buf : }
buf : 
buf : static void carl9170_unregister_hwrng(struct ar9170 *ar)
buf : {
buf : 	if (ar->rng.initialized) {
if (ar->rng.initialized) { 
buf : 		hwrng_unregister(&ar->rng.rng);
buf : 		ar->rng.initialized = false;
buf : 	}
buf : }
buf : 
buf : static int carl9170_register_hwrng(struct ar9170 *ar)
buf : {
buf : 	int err;
buf : 
buf : 	snprintf(ar->rng.name, ARRAY_SIZE(ar->rng.name),
buf : 		 "%s_%s", KBUILD_MODNAME, wiphy_name(ar->hw->wiphy));
buf : 	ar->rng.rng.name = ar->rng.name;
buf : 	ar->rng.rng.data_read = carl9170_rng_read;
buf : 	ar->rng.rng.priv = (unsigned long)ar;
buf : 
buf : 	if (WARN_ON(ar->rng.initialized))
if (WARN_ON(ar->rng.initialized)) 
buf : 		return -EALREADY;
buf : 
buf : 	err = hwrng_register(&ar->rng.rng);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&ar->udev->dev, "Failed to register the random "
buf : 			"number generator (%d)\n", err);
buf : 		return err;
buf : 	}
buf : 
buf : 	ar->rng.initialized = true;
buf : 
buf : 	err = carl9170_rng_get(ar);
buf : 	if (err) {
if (err) { 
buf : 		carl9170_unregister_hwrng(ar);
buf : 		return err;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : #endif /* CONFIG_CARL9170_HWRNG */
if /* CONFIG_CARL9170_HWRNG */ 
buf : 
buf : static int carl9170_op_get_survey(struct ieee80211_hw *hw, int idx,
buf : 				struct survey_info *survey)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	struct ieee80211_channel *chan;
buf : 	struct ieee80211_supported_band *band;
buf : 	int err, b, i;
buf : 
buf : 	chan = ar->channel;
buf : 	if (!chan)
if (!chan) 
buf : 		return -ENODEV;
buf : 
buf : 	if (idx == chan->hw_value) {
if (idx == chan->hw_value) { 
buf : 		mutex_lock(&ar->mutex);
buf : 		err = carl9170_update_survey(ar, false, true);
buf : 		mutex_unlock(&ar->mutex);
buf : 		if (err)
if (err) 
buf : 			return err;
buf : 	}
buf : 
buf : 	for (b = 0; b < IEEE80211_NUM_BANDS; b++) {
for (b = 0; b < IEEE80211_NUM_BANDS; b++) { 
buf : 		band = ar->hw->wiphy->bands[b];
buf : 
buf : 		if (!band)
if (!band) 
buf : 			continue;
buf : 
buf : 		for (i = 0; i < band->n_channels; i++) {
for (i = 0; i < band->n_channels; i++) { 
buf : 			if (band->channels[i].hw_value == idx) {
buf : 				chan = &band->channels[i];
buf : 				goto found;
buf : 			}
buf : 		}
buf : 	}
buf : 	return -ENOENT;
buf : 
buf : found:
buf : 	memcpy(survey, &ar->survey[idx], sizeof(*survey));
buf : 
buf : 	survey->channel = chan;
buf : 	survey->filled = SURVEY_INFO_NOISE_DBM;
buf : 
buf : 	if (ar->channel == chan)
if (ar->channel == chan) 
buf : 		survey->filled |= SURVEY_INFO_IN_USE;
buf : 
buf : 	if (ar->fw.hw_counters) {
if (ar->fw.hw_counters) { 
buf : 		survey->filled |= SURVEY_INFO_CHANNEL_TIME |
buf : 				  SURVEY_INFO_CHANNEL_TIME_BUSY |
buf : 				  SURVEY_INFO_CHANNEL_TIME_TX;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void carl9170_op_flush(struct ieee80211_hw *hw,
buf : 			      struct ieee80211_vif *vif,
if *vif, 
buf : 			      u32 queues, bool drop)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 	unsigned int vid;
buf : 
buf : 	mutex_lock(&ar->mutex);
buf : 	for_each_set_bit(vid, &ar->vif_bitmap, ar->fw.vif_num)
if_bitmap, ar->fw.vif_num) 
buf : 		carl9170_flush_cab(ar, vid);
buf : 
buf : 	carl9170_flush(ar, drop);
buf : 	mutex_unlock(&ar->mutex);
buf : }
buf : 
buf : static int carl9170_op_get_stats(struct ieee80211_hw *hw,
buf : 				 struct ieee80211_low_level_stats *stats)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 
buf : 	memset(stats, 0, sizeof(*stats));
buf : 	stats->dot11ACKFailureCount = ar->tx_ack_failures;
buf : 	stats->dot11FCSErrorCount = ar->tx_fcs_errors;
buf : 	return 0;
buf : }
buf : 
buf : static void carl9170_op_sta_notify(struct ieee80211_hw *hw,
ify(struct ieee80211_hw *hw, 
buf : 				   struct ieee80211_vif *vif,
buf : 				   enum sta_notify_cmd cmd,
ify_cmd cmd, 
buf : 				   struct ieee80211_sta *sta)
buf : {
buf : 	struct carl9170_sta_info *sta_info = (void *) sta->drv_priv;
buf : 
buf : 	switch (cmd) {
buf : 	case STA_NOTIFY_SLEEP:
buf : 		sta_info->sleeping = true;
buf : 		if (atomic_read(&sta_info->pending_frames))
if (atomic_read(&sta_info->pending_frames)) 
buf : 			ieee80211_sta_block_awake(hw, sta, true);
buf : 		break;
buf : 
buf : 	case STA_NOTIFY_AWAKE:
buf : 		sta_info->sleeping = false;
buf : 		break;
buf : 	}
buf : }
buf : 
buf : static bool carl9170_tx_frames_pending(struct ieee80211_hw *hw)
buf : {
buf : 	struct ar9170 *ar = hw->priv;
buf : 
buf : 	return !!atomic_read(&ar->tx_total_queued);
buf : }
buf : 
buf : static const struct ieee80211_ops carl9170_ops = {
buf : 	.start			= carl9170_op_start,
buf : 	.stop			= carl9170_op_stop,
buf : 	.tx			= carl9170_op_tx,
buf : 	.flush			= carl9170_op_flush,
buf : 	.add_interface		= carl9170_op_add_interface,
buf : 	.remove_interface	= carl9170_op_remove_interface,
buf : 	.config			= carl9170_op_config,
buf : 	.prepare_multicast	= carl9170_op_prepare_multicast,
buf : 	.configure_filter	= carl9170_op_configure_filter,
buf : 	.conf_tx		= carl9170_op_conf_tx,
buf : 	.bss_info_changed	= carl9170_op_bss_info_changed,
buf : 	.get_tsf		= carl9170_op_get_tsf,
buf : 	.set_key		= carl9170_op_set_key,
buf : 	.sta_add		= carl9170_op_sta_add,
buf : 	.sta_remove		= carl9170_op_sta_remove,
buf : 	.sta_notify		= carl9170_op_sta_notify,
ify		= carl9170_op_sta_notify, 
buf : 	.get_survey		= carl9170_op_get_survey,
buf : 	.get_stats		= carl9170_op_get_stats,
buf : 	.ampdu_action		= carl9170_op_ampdu_action,
buf : 	.tx_frames_pending	= carl9170_tx_frames_pending,
buf : };
buf : 
buf : void *carl9170_alloc(size_t priv_size)
buf : {
buf : 	struct ieee80211_hw *hw;
buf : 	struct ar9170 *ar;
buf : 	struct sk_buff *skb;
buf : 	int i;
buf : 
buf : 	/*
buf : 	 * this buffer is used for rx stream reconstruction.
for rx stream reconstruction. 
buf : 	 * Under heavy load this device (or the transport layer?)
buf : 	 * tends to split the streams into separate rx descriptors.
buf : 	 */
buf : 
buf : 	skb = __dev_alloc_skb(AR9170_RX_STREAM_MAX_SIZE, GFP_KERNEL);
buf : 	if (!skb)
if (!skb) 
buf : 		goto err_nomem;
buf : 
buf : 	hw = ieee80211_alloc_hw(priv_size, &carl9170_ops);
buf : 	if (!hw)
if (!hw) 
buf : 		goto err_nomem;
buf : 
buf : 	ar = hw->priv;
buf : 	ar->hw = hw;
buf : 	ar->rx_failover = skb;
buf : 
buf : 	memset(&ar->rx_plcp, 0, sizeof(struct ar9170_rx_head));
buf : 	ar->rx_has_plcp = false;
buf : 
buf : 	/*
buf : 	 * Here's a hidden pitfall!
buf : 	 *
buf : 	 * All 4 AC queues work perfectly well under _legacy_ operation.
buf : 	 * However as soon as aggregation is enabled, the traffic flow
buf : 	 * gets very bumpy. Therefore we have to _switch_ to a
fore we have to _switch_ to a 
buf : 	 * software AC with a single HW queue.
buf : 	 */
buf : 	hw->queues = __AR9170_NUM_TXQ;
buf : 
buf : 	mutex_init(&ar->mutex);
buf : 	spin_lock_init(&ar->beacon_lock);
buf : 	spin_lock_init(&ar->cmd_lock);
buf : 	spin_lock_init(&ar->tx_stats_lock);
buf : 	spin_lock_init(&ar->tx_ampdu_list_lock);
buf : 	spin_lock_init(&ar->mem_lock);
buf : 	spin_lock_init(&ar->state_lock);
buf : 	atomic_set(&ar->pending_restarts, 0);
buf : 	ar->vifs = 0;
ifs = 0; 
buf : 	for (i = 0; i < ar->hw->queues; i++) {
for (i = 0; i < ar->hw->queues; i++) { 
buf : 		skb_queue_head_init(&ar->tx_status[i]);
buf : 		skb_queue_head_init(&ar->tx_pending[i]);
buf : 
buf : 		INIT_LIST_HEAD(&ar->bar_list[i]);
buf : 		spin_lock_init(&ar->bar_list_lock[i]);
buf : 	}
buf : 	INIT_WORK(&ar->ps_work, carl9170_ps_work);
buf : 	INIT_WORK(&ar->ping_work, carl9170_ping_work);
buf : 	INIT_WORK(&ar->restart_work, carl9170_restart_work);
buf : 	INIT_WORK(&ar->ampdu_work, carl9170_ampdu_work);
buf : 	INIT_DELAYED_WORK(&ar->stat_work, carl9170_stat_work);
buf : 	INIT_DELAYED_WORK(&ar->tx_janitor, carl9170_tx_janitor);
buf : 	INIT_LIST_HEAD(&ar->tx_ampdu_list);
buf : 	rcu_assign_pointer(ar->tx_ampdu_iter,
buf : 			   (struct carl9170_sta_tid *) &ar->tx_ampdu_list);
buf : 
buf : 	bitmap_zero(&ar->vif_bitmap, ar->fw.vif_num);
if_bitmap, ar->fw.vif_num); 
buf : 	INIT_LIST_HEAD(&ar->vif_list);
buf : 	init_completion(&ar->tx_flush);
buf : 
buf : 	/* firmware decides which modes we support */
buf : 	hw->wiphy->interface_modes = 0;
buf : 
buf : 	hw->flags |= IEEE80211_HW_RX_INCLUDES_FCS |
buf : 		     IEEE80211_HW_MFP_CAPABLE |
buf : 		     IEEE80211_HW_REPORTS_TX_ACK_STATUS |
buf : 		     IEEE80211_HW_SUPPORTS_PS |
buf : 		     IEEE80211_HW_PS_NULLFUNC_STACK |
buf : 		     IEEE80211_HW_NEED_DTIM_BEFORE_ASSOC |
buf : 		     IEEE80211_HW_SUPPORTS_RC_TABLE |
buf : 		     IEEE80211_HW_SIGNAL_DBM |
buf : 		     IEEE80211_HW_SUPPORTS_HT_CCK_RATES;
buf : 
buf : 	if (!modparam_noht) {
if (!modparam_noht) { 
buf : 		/*
buf : 		 * see the comment above, why we allow the user
buf : 		 * to disable HT by a module parameter.
buf : 		 */
buf : 		hw->flags |= IEEE80211_HW_AMPDU_AGGREGATION;
buf : 	}
buf : 
buf : 	hw->extra_tx_headroom = sizeof(struct _carl9170_tx_superframe);
buf : 	hw->sta_data_size = sizeof(struct carl9170_sta_info);
buf : 	hw->vif_data_size = sizeof(struct carl9170_vif_info);
if_data_size = sizeof(struct carl9170_vif_info); 
buf : 
buf : 	hw->max_rates = CARL9170_TX_MAX_RATES;
buf : 	hw->max_rate_tries = CARL9170_TX_USER_RATE_TRIES;
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(ar->noise); i++)
for (i = 0; i < ARRAY_SIZE(ar->noise); i++) 
buf : 		ar->noise[i] = -95; /* ATH_DEFAULT_NOISE_FLOOR */
buf : 
buf : 	return ar;
buf : 
buf : err_nomem:
buf : 	kfree_skb(skb);
buf : 	return ERR_PTR(-ENOMEM);
buf : }
buf : 
buf : static int carl9170_read_eeprom(struct ar9170 *ar)
buf : {
buf : #define RW	8	/* number of words to read at once */
buf : #define RB	(sizeof(u32) * RW)
buf : 	u8 *eeprom = (void *)&ar->eeprom;
buf : 	__le32 offsets[RW];
buf : 	int i, j, err;
buf : 
buf : 	BUILD_BUG_ON(sizeof(ar->eeprom) & 3);
buf : 
buf : 	BUILD_BUG_ON(RB > CARL9170_MAX_CMD_LEN - 4);
buf : #ifndef __CHECKER__
ifndef __CHECKER__ 
buf : 	/* don't want to handle trailing remains */
buf : 	BUILD_BUG_ON(sizeof(ar->eeprom) % RB);
buf : #endif
if 
buf : 
buf : 	for (i = 0; i < sizeof(ar->eeprom) / RB; i++) {
for (i = 0; i < sizeof(ar->eeprom) / RB; i++) { 
buf : 		for (j = 0; j < RW; j++)
buf : 			offsets[j] = cpu_to_le32(AR9170_EEPROM_START +
buf : 						 RB * i + 4 * j);
buf : 
buf : 		err = carl9170_exec_cmd(ar, CARL9170_CMD_RREG,
buf : 					RB, (u8 *) &offsets,
buf : 					RB, eeprom + RB * i);
buf : 		if (err)
if (err) 
buf : 			return err;
buf : 	}
buf : 
buf : #undef RW
buf : #undef RB
buf : 	return 0;
buf : }
buf : 
buf : static int carl9170_parse_eeprom(struct ar9170 *ar)
buf : {
buf : 	struct ath_regulatory *regulatory = &ar->common.regulatory;
buf : 	unsigned int rx_streams, tx_streams, tx_params = 0;
buf : 	int bands = 0;
buf : 	int chans = 0;
buf : 
buf : 	if (ar->eeprom.length == cpu_to_le16(0xffff))
if (ar->eeprom.length == cpu_to_le16(0xffff)) 
buf : 		return -ENODATA;
buf : 
buf : 	rx_streams = hweight8(ar->eeprom.rx_mask);
buf : 	tx_streams = hweight8(ar->eeprom.tx_mask);
buf : 
buf : 	if (rx_streams != tx_streams) {
if (rx_streams != tx_streams) { 
buf : 		tx_params = IEEE80211_HT_MCS_TX_RX_DIFF;
buf : 
buf : 		WARN_ON(!(tx_streams >= 1 && tx_streams <=
buf : 			IEEE80211_HT_MCS_TX_MAX_STREAMS));
buf : 
buf : 		tx_params = (tx_streams - 1) <<
buf : 			    IEEE80211_HT_MCS_TX_MAX_STREAMS_SHIFT;
buf : 
buf : 		carl9170_band_2GHz.ht_cap.mcs.tx_params |= tx_params;
buf : 		carl9170_band_5GHz.ht_cap.mcs.tx_params |= tx_params;
buf : 	}
buf : 
buf : 	if (ar->eeprom.operating_flags & AR9170_OPFLAG_2GHZ) {
if (ar->eeprom.operating_flags & AR9170_OPFLAG_2GHZ) { 
buf : 		ar->hw->wiphy->bands[IEEE80211_BAND_2GHZ] =
buf : 			&carl9170_band_2GHz;
buf : 		chans += carl9170_band_2GHz.n_channels;
buf : 		bands++;
buf : 	}
buf : 	if (ar->eeprom.operating_flags & AR9170_OPFLAG_5GHZ) {
if (ar->eeprom.operating_flags & AR9170_OPFLAG_5GHZ) { 
buf : 		ar->hw->wiphy->bands[IEEE80211_BAND_5GHZ] =
buf : 			&carl9170_band_5GHz;
buf : 		chans += carl9170_band_5GHz.n_channels;
buf : 		bands++;
buf : 	}
buf : 
buf : 	if (!bands)
if (!bands) 
buf : 		return -EINVAL;
buf : 
buf : 	ar->survey = kzalloc(sizeof(struct survey_info) * chans, GFP_KERNEL);
buf : 	if (!ar->survey)
if (!ar->survey) 
buf : 		return -ENOMEM;
buf : 	ar->num_channels = chans;
buf : 
buf : 	regulatory->current_rd = le16_to_cpu(ar->eeprom.reg_domain[0]);
buf : 
buf : 	/* second part of wiphy init */
buf : 	SET_IEEE80211_PERM_ADDR(ar->hw, ar->eeprom.mac_address);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void carl9170_reg_notifier(struct wiphy *wiphy,
ifier(struct wiphy *wiphy, 
buf : 				  struct regulatory_request *request)
buf : {
buf : 	struct ieee80211_hw *hw = wiphy_to_ieee80211_hw(wiphy);
buf : 	struct ar9170 *ar = hw->priv;
buf : 
buf : 	ath_reg_notifier_apply(wiphy, request, &ar->common.regulatory);
ifier_apply(wiphy, request, &ar->common.regulatory); 
buf : }
buf : 
buf : int carl9170_register(struct ar9170 *ar)
buf : {
buf : 	struct ath_regulatory *regulatory = &ar->common.regulatory;
buf : 	int err = 0, i;
buf : 
buf : 	if (WARN_ON(ar->mem_bitmap))
if (WARN_ON(ar->mem_bitmap)) 
buf : 		return -EINVAL;
buf : 
buf : 	ar->mem_bitmap = kzalloc(roundup(ar->fw.mem_blocks, BITS_PER_LONG) *
buf : 				 sizeof(unsigned long), GFP_KERNEL);
buf : 
buf : 	if (!ar->mem_bitmap)
if (!ar->mem_bitmap) 
buf : 		return -ENOMEM;
buf : 
buf : 	/* try to read EEPROM, init MAC addr */
buf : 	err = carl9170_read_eeprom(ar);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	err = carl9170_parse_eeprom(ar);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	err = ath_regd_init(regulatory, ar->hw->wiphy,
buf : 			    carl9170_reg_notifier);
ifier); 
buf : 	if (err)
buf : 		return err;
buf : 
buf : 	if (modparam_noht) {
if (modparam_noht) { 
buf : 		carl9170_band_2GHz.ht_cap.ht_supported = false;
buf : 		carl9170_band_5GHz.ht_cap.ht_supported = false;
buf : 	}
buf : 
buf : 	for (i = 0; i < ar->fw.vif_num; i++) {
if_num; i++) { 
buf : 		ar->vif_priv[i].id = i;
buf : 		ar->vif_priv[i].vif = NULL;
if_priv[i].vif = NULL; 
buf : 	}
buf : 
buf : 	err = ieee80211_register_hw(ar->hw);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	/* mac80211 interface is now registered */
buf : 	ar->registered = true;
buf : 
buf : 	if (!ath_is_world_regd(regulatory))
if (!ath_is_world_regd(regulatory)) 
buf : 		regulatory_hint(ar->hw->wiphy, regulatory->alpha2);
buf : 
buf : #ifdef CONFIG_CARL9170_DEBUGFS
ifdef CONFIG_CARL9170_DEBUGFS 
buf : 	carl9170_debugfs_register(ar);
buf : #endif /* CONFIG_CARL9170_DEBUGFS */
if /* CONFIG_CARL9170_DEBUGFS */ 
buf : 
buf : 	err = carl9170_led_init(ar);
buf : 	if (err)
if (err) 
buf : 		goto err_unreg;
buf : 
buf : #ifdef CONFIG_CARL9170_LEDS
ifdef CONFIG_CARL9170_LEDS 
buf : 	err = carl9170_led_register(ar);
buf : 	if (err)
if (err) 
buf : 		goto err_unreg;
buf : #endif /* CONFIG_CARL9170_LEDS */
if /* CONFIG_CARL9170_LEDS */ 
buf : 
buf : #ifdef CONFIG_CARL9170_WPC
buf : 	err = carl9170_register_wps_button(ar);
buf : 	if (err)
if (err) 
buf : 		goto err_unreg;
buf : #endif /* CONFIG_CARL9170_WPC */
if /* CONFIG_CARL9170_WPC */ 
buf : 
buf : #ifdef CONFIG_CARL9170_HWRNG
buf : 	err = carl9170_register_hwrng(ar);
buf : 	if (err)
if (err) 
buf : 		goto err_unreg;
buf : #endif /* CONFIG_CARL9170_HWRNG */
if /* CONFIG_CARL9170_HWRNG */ 
buf : 
buf : 	dev_info(&ar->udev->dev, "Atheros AR9170 is registered as '%s'\n",
buf : 		 wiphy_name(ar->hw->wiphy));
buf : 
buf : 	return 0;
buf : 
buf : err_unreg:
buf : 	carl9170_unregister(ar);
buf : 	return err;
buf : }
buf : 
buf : void carl9170_unregister(struct ar9170 *ar)
buf : {
buf : 	if (!ar->registered)
if (!ar->registered) 
buf : 		return;
buf : 
buf : 	ar->registered = false;
buf : 
buf : #ifdef CONFIG_CARL9170_LEDS
ifdef CONFIG_CARL9170_LEDS 
buf : 	carl9170_led_unregister(ar);
buf : #endif /* CONFIG_CARL9170_LEDS */
if /* CONFIG_CARL9170_LEDS */ 
buf : 
buf : #ifdef CONFIG_CARL9170_DEBUGFS
buf : 	carl9170_debugfs_unregister(ar);
buf : #endif /* CONFIG_CARL9170_DEBUGFS */
if /* CONFIG_CARL9170_DEBUGFS */ 
buf : 
buf : #ifdef CONFIG_CARL9170_WPC
buf : 	if (ar->wps.pbc) {
if (ar->wps.pbc) { 
buf : 		input_unregister_device(ar->wps.pbc);
buf : 		ar->wps.pbc = NULL;
buf : 	}
buf : #endif /* CONFIG_CARL9170_WPC */
if /* CONFIG_CARL9170_WPC */ 
buf : 
buf : #ifdef CONFIG_CARL9170_HWRNG
buf : 	carl9170_unregister_hwrng(ar);
buf : #endif /* CONFIG_CARL9170_HWRNG */
if /* CONFIG_CARL9170_HWRNG */ 
buf : 
buf : 	carl9170_cancel_worker(ar);
buf : 	cancel_work_sync(&ar->restart_work);
buf : 
buf : 	ieee80211_unregister_hw(ar->hw);
buf : }
buf : 
buf : void carl9170_free(struct ar9170 *ar)
buf : {
buf : 	WARN_ON(ar->registered);
buf : 	WARN_ON(IS_INITIALIZED(ar));
buf : 
buf : 	kfree_skb(ar->rx_failover);
buf : 	ar->rx_failover = NULL;
buf : 
buf : 	kfree(ar->mem_bitmap);
buf : 	ar->mem_bitmap = NULL;
buf : 
buf : 	kfree(ar->survey);
buf : 	ar->survey = NULL;
buf : 
buf : 	mutex_destroy(&ar->mutex);
buf : 
buf : 	ieee80211_free_hw(ar->hw);
buf : }
file : ./test/kernel/drivers/net/wireless/ath/ath9k/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2008-2011 Atheros Communications Inc.
buf :  *
buf :  * Permission to use, copy, modify, and/or distribute this software for any
ify, and/or distribute this software for any 
buf :  * purpose with or without fee is hereby granted, provided that the above
buf :  * copyright notice and this permission notice appear in all copies.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
buf :  * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
buf :  * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
buf :  * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
buf :  * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
buf :  * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
buf :  * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
buf :  */
buf : 
buf : #include <linux/nl80211.h>
buf : #include <linux/delay.h>
buf : #include "ath9k.h"
buf : #include "btcoex.h"
buf : 
buf : static void ath9k_set_assoc_state(struct ath_softc *sc,
buf : 				  struct ieee80211_vif *vif);
if *vif); 
buf : 
buf : u8 ath9k_parse_mpdudensity(u8 mpdudensity)
buf : {
buf : 	/*
buf : 	 * 802.11n D2.0 defined values for "Minimum MPDU Start Spacing":
for "Minimum MPDU Start Spacing": 
buf : 	 *   0 for no restriction
buf : 	 *   1 for 1/4 us
for 1/4 us 
buf : 	 *   2 for 1/2 us
buf : 	 *   3 for 1 us
for 1 us 
buf : 	 *   4 for 2 us
buf : 	 *   5 for 4 us
for 4 us 
buf : 	 *   6 for 8 us
buf : 	 *   7 for 16 us
for 16 us 
buf : 	 */
buf : 	switch (mpdudensity) {
buf : 	case 0:
buf : 		return 0;
buf : 	case 1:
buf : 	case 2:
buf : 	case 3:
buf : 		/* Our lower layer calculations limit our precision to
buf : 		   1 microsecond */
buf : 		return 1;
buf : 	case 4:
buf : 		return 2;
buf : 	case 5:
buf : 		return 4;
buf : 	case 6:
buf : 		return 8;
buf : 	case 7:
buf : 		return 16;
buf : 	default:
buf : 		return 0;
buf : 	}
buf : }
buf : 
buf : static bool ath9k_has_pending_frames(struct ath_softc *sc, struct ath_txq *txq)
buf : {
buf : 	bool pending = false;
buf : 
buf : 	spin_lock_bh(&txq->axq_lock);
buf : 
buf : 	if (txq->axq_depth || !list_empty(&txq->axq_acq))
if (txq->axq_depth || !list_empty(&txq->axq_acq)) 
buf : 		pending = true;
buf : 
buf : 	spin_unlock_bh(&txq->axq_lock);
buf : 	return pending;
buf : }
buf : 
buf : static bool ath9k_setpower(struct ath_softc *sc, enum ath9k_power_mode mode)
buf : {
buf : 	unsigned long flags;
buf : 	bool ret;
buf : 
buf : 	spin_lock_irqsave(&sc->sc_pm_lock, flags);
buf : 	ret = ath9k_hw_setpower(sc->sc_ah, mode);
buf : 	spin_unlock_irqrestore(&sc->sc_pm_lock, flags);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : void ath_ps_full_sleep(unsigned long data)
buf : {
buf : 	struct ath_softc *sc = (struct ath_softc *) data;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	bool reset;
buf : 
buf : 	spin_lock(&common->cc_lock);
buf : 	ath_hw_cycle_counters_update(common);
buf : 	spin_unlock(&common->cc_lock);
buf : 
buf : 	ath9k_hw_setrxabort(sc->sc_ah, 1);
buf : 	ath9k_hw_stopdmarecv(sc->sc_ah, &reset);
buf : 
buf : 	ath9k_hw_setpower(sc->sc_ah, ATH9K_PM_FULL_SLEEP);
buf : }
buf : 
buf : void ath9k_ps_wakeup(struct ath_softc *sc)
buf : {
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	unsigned long flags;
buf : 	enum ath9k_power_mode power_mode;
buf : 
buf : 	spin_lock_irqsave(&sc->sc_pm_lock, flags);
buf : 	if (++sc->ps_usecount != 1)
if (++sc->ps_usecount != 1) 
buf : 		goto unlock;
buf : 
buf : 	del_timer_sync(&sc->sleep_timer);
buf : 	power_mode = sc->sc_ah->power_mode;
buf : 	ath9k_hw_setpower(sc->sc_ah, ATH9K_PM_AWAKE);
buf : 
buf : 	/*
buf : 	 * While the hardware is asleep, the cycle counters contain no
buf : 	 * useful data. Better clear them now so that they don't mess up
buf : 	 * survey data results.
buf : 	 */
buf : 	if (power_mode != ATH9K_PM_AWAKE) {
if (power_mode != ATH9K_PM_AWAKE) { 
buf : 		spin_lock(&common->cc_lock);
buf : 		ath_hw_cycle_counters_update(common);
buf : 		memset(&common->cc_survey, 0, sizeof(common->cc_survey));
buf : 		memset(&common->cc_ani, 0, sizeof(common->cc_ani));
buf : 		spin_unlock(&common->cc_lock);
buf : 	}
buf : 
buf :  unlock:
buf : 	spin_unlock_irqrestore(&sc->sc_pm_lock, flags);
buf : }
buf : 
buf : void ath9k_ps_restore(struct ath_softc *sc)
buf : {
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	enum ath9k_power_mode mode;
buf : 	unsigned long flags;
buf : 
buf : 	spin_lock_irqsave(&sc->sc_pm_lock, flags);
buf : 	if (--sc->ps_usecount != 0)
if (--sc->ps_usecount != 0) 
buf : 		goto unlock;
buf : 
buf : 	if (sc->ps_idle) {
if (sc->ps_idle) { 
buf : 		mod_timer(&sc->sleep_timer, jiffies + HZ / 10);
buf : 		goto unlock;
buf : 	}
buf : 
buf : 	if (sc->ps_enabled &&
if (sc->ps_enabled && 
buf : 		   !(sc->ps_flags & (PS_WAIT_FOR_BEACON |
buf : 				     PS_WAIT_FOR_CAB |
buf : 				     PS_WAIT_FOR_PSPOLL_DATA |
buf : 				     PS_WAIT_FOR_TX_ACK |
buf : 				     PS_WAIT_FOR_ANI))) {
buf : 		mode = ATH9K_PM_NETWORK_SLEEP;
buf : 		if (ath9k_hw_btcoex_is_enabled(sc->sc_ah))
if (ath9k_hw_btcoex_is_enabled(sc->sc_ah)) 
buf : 			ath9k_btcoex_stop_gen_timer(sc);
buf : 	} else {
buf : 		goto unlock;
buf : 	}
buf : 
buf : 	spin_lock(&common->cc_lock);
buf : 	ath_hw_cycle_counters_update(common);
buf : 	spin_unlock(&common->cc_lock);
buf : 
buf : 	ath9k_hw_setpower(sc->sc_ah, mode);
buf : 
buf :  unlock:
buf : 	spin_unlock_irqrestore(&sc->sc_pm_lock, flags);
buf : }
buf : 
buf : static void __ath_cancel_work(struct ath_softc *sc)
buf : {
buf : 	cancel_work_sync(&sc->paprd_work);
buf : 	cancel_delayed_work_sync(&sc->tx_complete_work);
buf : 	cancel_delayed_work_sync(&sc->hw_pll_work);
buf : 
buf : #ifdef CONFIG_ATH9K_BTCOEX_SUPPORT
ifdef CONFIG_ATH9K_BTCOEX_SUPPORT 
buf : 	if (ath9k_hw_mci_is_enabled(sc->sc_ah))
buf : 		cancel_work_sync(&sc->mci_work);
buf : #endif
if 
buf : }
buf : 
buf : void ath_cancel_work(struct ath_softc *sc)
buf : {
buf : 	__ath_cancel_work(sc);
buf : 	cancel_work_sync(&sc->hw_reset_work);
buf : }
buf : 
buf : void ath_restart_work(struct ath_softc *sc)
buf : {
buf : 	ieee80211_queue_delayed_work(sc->hw, &sc->tx_complete_work, 0);
buf : 
buf : 	if (AR_SREV_9340(sc->sc_ah) || AR_SREV_9330(sc->sc_ah))
if (AR_SREV_9340(sc->sc_ah) || AR_SREV_9330(sc->sc_ah)) 
buf : 		ieee80211_queue_delayed_work(sc->hw, &sc->hw_pll_work,
buf : 				     msecs_to_jiffies(ATH_PLL_WORK_INTERVAL));
iffies(ATH_PLL_WORK_INTERVAL)); 
buf : 
buf : 	ath_start_ani(sc);
buf : }
buf : 
buf : static bool ath_prepare_reset(struct ath_softc *sc)
buf : {
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	bool ret = true;
buf : 
buf : 	ieee80211_stop_queues(sc->hw);
buf : 	ath_stop_ani(sc);
buf : 	ath9k_hw_disable_interrupts(ah);
buf : 
buf : 	if (!ath_drain_all_txq(sc))
if (!ath_drain_all_txq(sc)) 
buf : 		ret = false;
buf : 
buf : 	if (!ath_stoprecv(sc))
if (!ath_stoprecv(sc)) 
buf : 		ret = false;
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static bool ath_complete_reset(struct ath_softc *sc, bool start)
buf : {
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	unsigned long flags;
buf : 	int i;
buf : 
buf : 	if (ath_startrecv(sc) != 0) {
if (ath_startrecv(sc) != 0) { 
buf : 		ath_err(common, "Unable to restart recv logic\n");
buf : 		return false;
buf : 	}
buf : 
buf : 	ath9k_cmn_update_txpow(ah, sc->curtxpow,
buf : 			       sc->config.txpowlimit, &sc->curtxpow);
buf : 
buf : 	clear_bit(ATH_OP_HW_RESET, &common->op_flags);
buf : 	ath9k_hw_set_interrupts(ah);
buf : 	ath9k_hw_enable_interrupts(ah);
buf : 
buf : 	if (!(sc->hw->conf.flags & IEEE80211_CONF_OFFCHANNEL) && start) {
if (!(sc->hw->conf.flags & IEEE80211_CONF_OFFCHANNEL) && start) { 
buf : 		if (!test_bit(ATH_OP_BEACONS, &common->op_flags))
buf : 			goto work;
buf : 
buf : 		if (ah->opmode == NL80211_IFTYPE_STATION &&
if (ah->opmode == NL80211_IFTYPE_STATION && 
buf : 		    test_bit(ATH_OP_PRIM_STA_VIF, &common->op_flags)) {
buf : 			spin_lock_irqsave(&sc->sc_pm_lock, flags);
buf : 			sc->ps_flags |= PS_BEACON_SYNC | PS_WAIT_FOR_BEACON;
buf : 			spin_unlock_irqrestore(&sc->sc_pm_lock, flags);
buf : 		} else {
buf : 			ath9k_set_beacon(sc);
buf : 		}
buf : 	work:
buf : 		ath_restart_work(sc);
buf : 
buf : 		for (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {
for (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) { 
buf : 			if (!ATH_TXQ_SETUP(sc, i))
buf : 				continue;
buf : 
buf : 			spin_lock_bh(&sc->tx.txq[i].axq_lock);
buf : 			ath_txq_schedule(sc, &sc->tx.txq[i]);
buf : 			spin_unlock_bh(&sc->tx.txq[i].axq_lock);
buf : 		}
buf : 	}
buf : 
buf : 	sc->gtt_cnt = 0;
buf : 	ieee80211_wake_queues(sc->hw);
buf : 
buf : 	ath9k_p2p_ps_timer(sc);
buf : 
buf : 	return true;
buf : }
buf : 
buf : static int ath_reset_internal(struct ath_softc *sc, struct ath9k_channel *hchan)
buf : {
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	struct ath9k_hw_cal_data *caldata = NULL;
buf : 	bool fastcc = true;
buf : 	int r;
buf : 
buf : 	__ath_cancel_work(sc);
buf : 
buf : 	tasklet_disable(&sc->intr_tq);
buf : 	spin_lock_bh(&sc->sc_pcu_lock);
buf : 
buf : 	if (!(sc->hw->conf.flags & IEEE80211_CONF_OFFCHANNEL)) {
if (!(sc->hw->conf.flags & IEEE80211_CONF_OFFCHANNEL)) { 
buf : 		fastcc = false;
buf : 		caldata = &sc->caldata;
buf : 	}
buf : 
buf : 	if (!hchan) {
if (!hchan) { 
buf : 		fastcc = false;
buf : 		hchan = ah->curchan;
buf : 	}
buf : 
buf : 	if (!ath_prepare_reset(sc))
if (!ath_prepare_reset(sc)) 
buf : 		fastcc = false;
buf : 
buf : 	ath_dbg(common, CONFIG, "Reset to %u MHz, HT40: %d fastcc: %d\n",
buf : 		hchan->channel, IS_CHAN_HT40(hchan), fastcc);
buf : 
buf : 	r = ath9k_hw_reset(ah, hchan, caldata, fastcc);
buf : 	if (r) {
if (r) { 
buf : 		ath_err(common,
buf : 			"Unable to reset channel, reset status %d\n", r);
buf : 
buf : 		ath9k_hw_enable_interrupts(ah);
buf : 		ath9k_queue_reset(sc, RESET_TYPE_BB_HANG);
buf : 
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (ath9k_hw_mci_is_enabled(sc->sc_ah) &&
if (ath9k_hw_mci_is_enabled(sc->sc_ah) && 
buf : 	    (sc->hw->conf.flags & IEEE80211_CONF_OFFCHANNEL))
buf : 		ath9k_mci_set_txpower(sc, true, false);
buf : 
buf : 	if (!ath_complete_reset(sc, true))
if (!ath_complete_reset(sc, true)) 
buf : 		r = -EIO;
buf : 
buf : out:
buf : 	spin_unlock_bh(&sc->sc_pcu_lock);
buf : 	tasklet_enable(&sc->intr_tq);
buf : 
buf : 	return r;
buf : }
buf : 
buf : 
buf : /*
buf :  * Set/change channels.  If the channel is really being changed, it's done
buf :  * by reseting the chip.  To accomplish this we must first cleanup any pending
buf :  * DMA, then restart stuff.
buf : */
buf : static int ath_set_channel(struct ath_softc *sc, struct cfg80211_chan_def *chandef)
buf : {
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	struct ieee80211_hw *hw = sc->hw;
buf : 	struct ath9k_channel *hchan;
buf : 	struct ieee80211_channel *chan = chandef->chan;
buf : 	bool offchannel;
buf : 	int pos = chan->hw_value;
buf : 	int old_pos = -1;
buf : 	int r;
buf : 
buf : 	if (test_bit(ATH_OP_INVALID, &common->op_flags))
if (test_bit(ATH_OP_INVALID, &common->op_flags)) 
buf : 		return -EIO;
buf : 
buf : 	offchannel = !!(hw->conf.flags & IEEE80211_CONF_OFFCHANNEL);
buf : 
buf : 	if (ah->curchan)
if (ah->curchan) 
buf : 		old_pos = ah->curchan - &ah->channels[0];
buf : 
buf : 	ath_dbg(common, CONFIG, "Set channel: %d MHz width: %d\n",
buf : 		chan->center_freq, chandef->width);
buf : 
buf : 	/* update survey stats for the old channel before switching */
for the old channel before switching */ 
buf : 	spin_lock_bh(&common->cc_lock);
buf : 	ath_update_survey_stats(sc);
buf : 	spin_unlock_bh(&common->cc_lock);
buf : 
buf : 	ath9k_cmn_get_channel(hw, ah, chandef);
buf : 
buf : 	/*
buf : 	 * If the operating channel changes, change the survey in-use flags
buf : 	 * along with it.
buf : 	 * Reset the survey data for the new channel, unless we're switching
for the new channel, unless we're switching 
buf : 	 * back to the operating channel from an off-channel operation.
buf : 	 */
buf : 	if (!offchannel && sc->cur_survey != &sc->survey[pos]) {
if (!offchannel && sc->cur_survey != &sc->survey[pos]) { 
buf : 		if (sc->cur_survey)
buf : 			sc->cur_survey->filled &= ~SURVEY_INFO_IN_USE;
buf : 
buf : 		sc->cur_survey = &sc->survey[pos];
buf : 
buf : 		memset(sc->cur_survey, 0, sizeof(struct survey_info));
buf : 		sc->cur_survey->filled |= SURVEY_INFO_IN_USE;
buf : 	} else if (!(sc->survey[pos].filled & SURVEY_INFO_IN_USE)) {
if (!(sc->survey[pos].filled & SURVEY_INFO_IN_USE)) { 
buf : 		memset(&sc->survey[pos], 0, sizeof(struct survey_info));
buf : 	}
buf : 
buf : 	hchan = &sc->sc_ah->channels[pos];
buf : 	r = ath_reset_internal(sc, hchan);
buf : 	if (r)
if (r) 
buf : 		return r;
buf : 
buf : 	/*
buf : 	 * The most recent snapshot of channel->noisefloor for the old
for the old 
buf : 	 * channel is only available after the hardware reset. Copy it to
buf : 	 * the survey stats now.
buf : 	 */
buf : 	if (old_pos >= 0)
if (old_pos >= 0) 
buf : 		ath_update_survey_nf(sc, old_pos);
buf : 
buf : 	/*
buf : 	 * Enable radar pulse detection if on a DFS channel. Spectral
if on a DFS channel. Spectral 
buf : 	 * scanning and radar detection can not be used concurrently.
buf : 	 */
buf : 	if (hw->conf.radar_enabled) {
if (hw->conf.radar_enabled) { 
buf : 		u32 rxfilter;
buf : 
buf : 		/* set HW specific DFS configuration */
ific DFS configuration */ 
buf : 		ath9k_hw_set_radar_params(ah);
buf : 		rxfilter = ath9k_hw_getrxfilter(ah);
buf : 		rxfilter |= ATH9K_RX_FILTER_PHYRADAR |
buf : 				ATH9K_RX_FILTER_PHYERR;
buf : 		ath9k_hw_setrxfilter(ah, rxfilter);
buf : 		ath_dbg(common, DFS, "DFS enabled at freq %d\n",
buf : 			chan->center_freq);
buf : 	} else {
buf : 		/* perform spectral scan if requested. */
if requested. */ 
buf : 		if (test_bit(ATH_OP_SCANNING, &common->op_flags) &&
buf : 			sc->spectral_mode == SPECTRAL_CHANSCAN)
buf : 			ath9k_spectral_scan_trigger(hw);
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void ath_node_attach(struct ath_softc *sc, struct ieee80211_sta *sta,
buf : 			    struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ath_node *an;
buf : 	an = (struct ath_node *)sta->drv_priv;
buf : 
buf : 	an->sc = sc;
buf : 	an->sta = sta;
buf : 	an->vif = vif;
if = vif; 
buf : 	memset(&an->key_idx, 0, sizeof(an->key_idx));
buf : 
buf : 	ath_tx_node_init(sc, an);
buf : }
buf : 
buf : static void ath_node_detach(struct ath_softc *sc, struct ieee80211_sta *sta)
buf : {
buf : 	struct ath_node *an = (struct ath_node *)sta->drv_priv;
buf : 	ath_tx_node_cleanup(sc, an);
buf : }
buf : 
buf : void ath9k_tasklet(unsigned long data)
buf : {
buf : 	struct ath_softc *sc = (struct ath_softc *)data;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	enum ath_reset_type type;
buf : 	unsigned long flags;
buf : 	u32 status = sc->intrstatus;
buf : 	u32 rxmask;
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	spin_lock(&sc->sc_pcu_lock);
buf : 
buf : 	if (status & ATH9K_INT_FATAL) {
if (status & ATH9K_INT_FATAL) { 
buf : 		type = RESET_TYPE_FATAL_INT;
buf : 		ath9k_queue_reset(sc, type);
buf : 
buf : 		/*
buf : 		 * Increment the ref. counter here so that
buf : 		 * interrupts are enabled in the reset routine.
buf : 		 */
buf : 		atomic_inc(&ah->intr_ref_cnt);
buf : 		ath_dbg(common, RESET, "FATAL: Skipping interrupts\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	if ((ah->config.hw_hang_checks & HW_BB_WATCHDOG) &&
if ((ah->config.hw_hang_checks & HW_BB_WATCHDOG) && 
buf : 	    (status & ATH9K_INT_BB_WATCHDOG)) {
buf : 		spin_lock(&common->cc_lock);
buf : 		ath_hw_cycle_counters_update(common);
buf : 		ar9003_hw_bb_watchdog_dbg_info(ah);
buf : 		spin_unlock(&common->cc_lock);
buf : 
buf : 		if (ar9003_hw_bb_watchdog_check(ah)) {
if (ar9003_hw_bb_watchdog_check(ah)) { 
buf : 			type = RESET_TYPE_BB_WATCHDOG;
buf : 			ath9k_queue_reset(sc, type);
buf : 
buf : 			/*
buf : 			 * Increment the ref. counter here so that
buf : 			 * interrupts are enabled in the reset routine.
buf : 			 */
buf : 			atomic_inc(&ah->intr_ref_cnt);
buf : 			ath_dbg(common, RESET,
buf : 				"BB_WATCHDOG: Skipping interrupts\n");
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : 	if (status & ATH9K_INT_GTT) {
if (status & ATH9K_INT_GTT) { 
buf : 		sc->gtt_cnt++;
buf : 
buf : 		if ((sc->gtt_cnt >= MAX_GTT_CNT) && !ath9k_hw_check_alive(ah)) {
if ((sc->gtt_cnt >= MAX_GTT_CNT) && !ath9k_hw_check_alive(ah)) { 
buf : 			type = RESET_TYPE_TX_GTT;
buf : 			ath9k_queue_reset(sc, type);
buf : 			atomic_inc(&ah->intr_ref_cnt);
buf : 			ath_dbg(common, RESET,
buf : 				"GTT: Skipping interrupts\n");
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : 	spin_lock_irqsave(&sc->sc_pm_lock, flags);
buf : 	if ((status & ATH9K_INT_TSFOOR) && sc->ps_enabled) {
if ((status & ATH9K_INT_TSFOOR) && sc->ps_enabled) { 
buf : 		/*
buf : 		 * TSF sync does not look correct; remain awake to sync with
buf : 		 * the next Beacon.
buf : 		 */
buf : 		ath_dbg(common, PS, "TSFOOR - Sync with next Beacon\n");
buf : 		sc->ps_flags |= PS_WAIT_FOR_BEACON | PS_BEACON_SYNC;
buf : 	}
buf : 	spin_unlock_irqrestore(&sc->sc_pm_lock, flags);
buf : 
buf : 	if (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA)
if (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) 
buf : 		rxmask = (ATH9K_INT_RXHP | ATH9K_INT_RXLP | ATH9K_INT_RXEOL |
buf : 			  ATH9K_INT_RXORN);
buf : 	else
buf : 		rxmask = (ATH9K_INT_RX | ATH9K_INT_RXEOL | ATH9K_INT_RXORN);
buf : 
buf : 	if (status & rxmask) {
if (status & rxmask) { 
buf : 		/* Check for high priority Rx first */
for high priority Rx first */ 
buf : 		if ((ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) &&
buf : 		    (status & ATH9K_INT_RXHP))
buf : 			ath_rx_tasklet(sc, 0, true);
buf : 
buf : 		ath_rx_tasklet(sc, 0, false);
buf : 	}
buf : 
buf : 	if (status & ATH9K_INT_TX) {
if (status & ATH9K_INT_TX) { 
buf : 		if (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) {
buf : 			/*
buf : 			 * For EDMA chips, TX completion is enabled for the
for the 
buf : 			 * beacon queue, so if a beacon has been transmitted
buf : 			 * successfully after a GTT interrupt, the GTT counter
buf : 			 * gets reset to zero here.
buf : 			 */
buf : 			sc->gtt_cnt = 0;
buf : 
buf : 			ath_tx_edma_tasklet(sc);
buf : 		} else {
buf : 			ath_tx_tasklet(sc);
buf : 		}
buf : 
buf : 		wake_up(&sc->tx_wait);
buf : 	}
buf : 
buf : 	if (status & ATH9K_INT_GENTIMER)
if (status & ATH9K_INT_GENTIMER) 
buf : 		ath_gen_timer_isr(sc->sc_ah);
buf : 
buf : 	ath9k_btcoex_handle_interrupt(sc, status);
buf : 
buf : 	/* re-enable hardware interrupt */
buf : 	ath9k_hw_enable_interrupts(ah);
buf : out:
buf : 	spin_unlock(&sc->sc_pcu_lock);
buf : 	ath9k_ps_restore(sc);
buf : }
buf : 
buf : irqreturn_t ath_isr(int irq, void *dev)
buf : {
buf : #define SCHED_INTR (				\
buf : 		ATH9K_INT_FATAL |		\
buf : 		ATH9K_INT_BB_WATCHDOG |		\
buf : 		ATH9K_INT_RXORN |		\
buf : 		ATH9K_INT_RXEOL |		\
buf : 		ATH9K_INT_RX |			\
buf : 		ATH9K_INT_RXLP |		\
buf : 		ATH9K_INT_RXHP |		\
buf : 		ATH9K_INT_TX |			\
buf : 		ATH9K_INT_BMISS |		\
buf : 		ATH9K_INT_CST |			\
buf : 		ATH9K_INT_GTT |			\
buf : 		ATH9K_INT_TSFOOR |		\
buf : 		ATH9K_INT_GENTIMER |		\
buf : 		ATH9K_INT_MCI)
buf : 
buf : 	struct ath_softc *sc = dev;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	enum ath9k_int status;
buf : 	u32 sync_cause = 0;
buf : 	bool sched = false;
buf : 
buf : 	/*
buf : 	 * The hardware is not ready/present, don't
buf : 	 * touch anything. Note this can happen early
buf : 	 * on if the IRQ is shared.
if the IRQ is shared. 
buf : 	 */
buf : 	if (test_bit(ATH_OP_INVALID, &common->op_flags))
if (test_bit(ATH_OP_INVALID, &common->op_flags)) 
buf : 		return IRQ_NONE;
buf : 
buf : 	/* shared irq, not for us */
for us */ 
buf : 
buf : 	if (!ath9k_hw_intrpend(ah))
buf : 		return IRQ_NONE;
buf : 
buf : 	if (test_bit(ATH_OP_HW_RESET, &common->op_flags)) {
if (test_bit(ATH_OP_HW_RESET, &common->op_flags)) { 
buf : 		ath9k_hw_kill_interrupts(ah);
buf : 		return IRQ_HANDLED;
buf : 	}
buf : 
buf : 	/*
buf : 	 * Figure out the reason(s) for the interrupt.  Note
for the interrupt.  Note 
buf : 	 * that the hal returns a pseudo-ISR that may include
buf : 	 * bits we haven't explicitly enabled so we mask the
buf : 	 * value to insure we only process bits we requested.
buf : 	 */
buf : 	ath9k_hw_getisr(ah, &status, &sync_cause); /* NB: clears ISR too */
buf : 	ath9k_debug_sync_cause(sc, sync_cause);
buf : 	status &= ah->imask;	/* discard unasked-for bits */
for bits */ 
buf : 
buf : 	/*
buf : 	 * If there are no status bits set, then this interrupt was not
buf : 	 * for me (should have been caught above).
for me (should have been caught above). 
buf : 	 */
buf : 	if (!status)
if (!status) 
buf : 		return IRQ_NONE;
buf : 
buf : 	/* Cache the status */
buf : 	sc->intrstatus = status;
buf : 
buf : 	if (status & SCHED_INTR)
if (status & SCHED_INTR) 
buf : 		sched = true;
buf : 
buf : 	/*
buf : 	 * If a FATAL or RXORN interrupt is received, we have to reset the
buf : 	 * chip immediately.
buf : 	 */
buf : 	if ((status & ATH9K_INT_FATAL) || ((status & ATH9K_INT_RXORN) &&
if ((status & ATH9K_INT_FATAL) || ((status & ATH9K_INT_RXORN) && 
buf : 	    !(ah->caps.hw_caps & ATH9K_HW_CAP_EDMA)))
buf : 		goto chip_reset;
buf : 
buf : 	if ((ah->config.hw_hang_checks & HW_BB_WATCHDOG) &&
if ((ah->config.hw_hang_checks & HW_BB_WATCHDOG) && 
buf : 	    (status & ATH9K_INT_BB_WATCHDOG))
buf : 		goto chip_reset;
buf : 
buf : #ifdef CONFIG_ATH9K_WOW
ifdef CONFIG_ATH9K_WOW 
buf : 	if (status & ATH9K_INT_BMISS) {
buf : 		if (atomic_read(&sc->wow_sleep_proc_intr) == 0) {
if (atomic_read(&sc->wow_sleep_proc_intr) == 0) { 
buf : 			atomic_inc(&sc->wow_got_bmiss_intr);
buf : 			atomic_dec(&sc->wow_sleep_proc_intr);
buf : 		}
buf : 	}
buf : #endif
if 
buf : 
buf : 	if (status & ATH9K_INT_SWBA)
buf : 		tasklet_schedule(&sc->bcon_tasklet);
buf : 
buf : 	if (status & ATH9K_INT_TXURN)
if (status & ATH9K_INT_TXURN) 
buf : 		ath9k_hw_updatetxtriglevel(ah, true);
buf : 
buf : 	if (status & ATH9K_INT_RXEOL) {
if (status & ATH9K_INT_RXEOL) { 
buf : 		ah->imask &= ~(ATH9K_INT_RXEOL | ATH9K_INT_RXORN);
buf : 		ath9k_hw_set_interrupts(ah);
buf : 	}
buf : 
buf : 	if (!(ah->caps.hw_caps & ATH9K_HW_CAP_AUTOSLEEP))
if (!(ah->caps.hw_caps & ATH9K_HW_CAP_AUTOSLEEP)) 
buf : 		if (status & ATH9K_INT_TIM_TIMER) {
buf : 			if (ATH_DBG_WARN_ON_ONCE(sc->ps_idle))
if (ATH_DBG_WARN_ON_ONCE(sc->ps_idle)) 
buf : 				goto chip_reset;
buf : 			/* Clear RxAbort bit so that we can
buf : 			 * receive frames */
buf : 			ath9k_setpower(sc, ATH9K_PM_AWAKE);
buf : 			spin_lock(&sc->sc_pm_lock);
buf : 			ath9k_hw_setrxabort(sc->sc_ah, 0);
buf : 			sc->ps_flags |= PS_WAIT_FOR_BEACON;
buf : 			spin_unlock(&sc->sc_pm_lock);
buf : 		}
buf : 
buf : chip_reset:
buf : 
buf : 	ath_debug_stat_interrupt(sc, status);
buf : 
buf : 	if (sched) {
if (sched) { 
buf : 		/* turn off every interrupt */
buf : 		ath9k_hw_disable_interrupts(ah);
buf : 		tasklet_schedule(&sc->intr_tq);
buf : 	}
buf : 
buf : 	return IRQ_HANDLED;
buf : 
buf : #undef SCHED_INTR
buf : }
buf : 
buf : int ath_reset(struct ath_softc *sc)
buf : {
buf : 	int r;
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	r = ath_reset_internal(sc, NULL);
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	return r;
buf : }
buf : 
buf : void ath9k_queue_reset(struct ath_softc *sc, enum ath_reset_type type)
buf : {
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : #ifdef CONFIG_ATH9K_DEBUGFS
ifdef CONFIG_ATH9K_DEBUGFS 
buf : 	RESET_STAT_INC(sc, type);
buf : #endif
if 
buf : 	set_bit(ATH_OP_HW_RESET, &common->op_flags);
buf : 	ieee80211_queue_work(sc->hw, &sc->hw_reset_work);
buf : }
buf : 
buf : void ath_reset_work(struct work_struct *work)
buf : {
buf : 	struct ath_softc *sc = container_of(work, struct ath_softc, hw_reset_work);
buf : 
buf : 	ath_reset(sc);
buf : }
buf : 
buf : /**********************/
buf : /* mac80211 callbacks */
buf : /**********************/
buf : 
buf : static int ath9k_start(struct ieee80211_hw *hw)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	struct ieee80211_channel *curchan = hw->conf.chandef.chan;
buf : 	struct ath9k_channel *init_channel;
buf : 	int r;
buf : 
buf : 	ath_dbg(common, CONFIG,
buf : 		"Starting driver with initial channel: %d MHz\n",
buf : 		curchan->center_freq);
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	init_channel = ath9k_cmn_get_channel(hw, ah, &hw->conf.chandef);
buf : 
buf : 	/* Reset SERDES registers */
buf : 	ath9k_hw_configpcipowersave(ah, false);
buf : 
buf : 	/*
buf : 	 * The basic interface to setting the hardware in a good
buf : 	 * state is ``reset''.  On return the hardware is known to
buf : 	 * be powered up and with interrupts disabled.  This must
buf : 	 * be followed by initialization of the appropriate bits
buf : 	 * and then setup of the interrupt mask.
buf : 	 */
buf : 	spin_lock_bh(&sc->sc_pcu_lock);
buf : 
buf : 	atomic_set(&ah->intr_ref_cnt, -1);
buf : 
buf : 	r = ath9k_hw_reset(ah, init_channel, ah->caldata, false);
buf : 	if (r) {
if (r) { 
buf : 		ath_err(common,
buf : 			"Unable to reset hardware; reset status %d (freq %u MHz)\n",
buf : 			r, curchan->center_freq);
buf : 		ah->reset_power_on = false;
buf : 	}
buf : 
buf : 	/* Setup our intr mask. */
buf : 	ah->imask = ATH9K_INT_TX | ATH9K_INT_RXEOL |
buf : 		    ATH9K_INT_RXORN | ATH9K_INT_FATAL |
buf : 		    ATH9K_INT_GLOBAL;
buf : 
buf : 	if (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA)
if (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) 
buf : 		ah->imask |= ATH9K_INT_RXHP |
buf : 			     ATH9K_INT_RXLP;
buf : 	else
buf : 		ah->imask |= ATH9K_INT_RX;
buf : 
buf : 	if (ah->config.hw_hang_checks & HW_BB_WATCHDOG)
if (ah->config.hw_hang_checks & HW_BB_WATCHDOG) 
buf : 		ah->imask |= ATH9K_INT_BB_WATCHDOG;
buf : 
buf : 	/*
buf : 	 * Enable GTT interrupts only for AR9003/AR9004 chips
for AR9003/AR9004 chips 
buf : 	 * for now.
buf : 	 */
buf : 	if (AR_SREV_9300_20_OR_LATER(ah))
if (AR_SREV_9300_20_OR_LATER(ah)) 
buf : 		ah->imask |= ATH9K_INT_GTT;
buf : 
buf : 	if (ah->caps.hw_caps & ATH9K_HW_CAP_HT)
if (ah->caps.hw_caps & ATH9K_HW_CAP_HT) 
buf : 		ah->imask |= ATH9K_INT_CST;
buf : 
buf : 	ath_mci_enable(sc);
buf : 
buf : 	clear_bit(ATH_OP_INVALID, &common->op_flags);
buf : 	sc->sc_ah->is_monitoring = false;
buf : 
buf : 	if (!ath_complete_reset(sc, false))
if (!ath_complete_reset(sc, false)) 
buf : 		ah->reset_power_on = false;
buf : 
buf : 	if (ah->led_pin >= 0) {
if (ah->led_pin >= 0) { 
buf : 		ath9k_hw_cfg_output(ah, ah->led_pin,
buf : 				    AR_GPIO_OUTPUT_MUX_AS_OUTPUT);
buf : 		ath9k_hw_set_gpio(ah, ah->led_pin, 0);
buf : 	}
buf : 
buf : 	/*
buf : 	 * Reset key cache to sane defaults (all entries cleared) instead of
buf : 	 * semi-random values after suspend/resume.
buf : 	 */
buf : 	ath9k_cmn_init_crypto(sc->sc_ah);
buf : 
buf : 	ath9k_hw_reset_tsf(ah);
buf : 
buf : 	spin_unlock_bh(&sc->sc_pcu_lock);
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : 
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void ath9k_tx(struct ieee80211_hw *hw,
buf : 		     struct ieee80211_tx_control *control,
buf : 		     struct sk_buff *skb)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	struct ath_tx_control txctl;
buf : 	struct ieee80211_hdr *hdr = (struct ieee80211_hdr *) skb->data;
buf : 	unsigned long flags;
buf : 
buf : 	if (sc->ps_enabled) {
if (sc->ps_enabled) { 
buf : 		/*
buf : 		 * mac80211 does not set PM field for normal data frames, so we
for normal data frames, so we 
buf : 		 * need to update that based on the current PS mode.
buf : 		 */
buf : 		if (ieee80211_is_data(hdr->frame_control) &&
if (ieee80211_is_data(hdr->frame_control) && 
buf : 		    !ieee80211_is_nullfunc(hdr->frame_control) &&
buf : 		    !ieee80211_has_pm(hdr->frame_control)) {
buf : 			ath_dbg(common, PS,
buf : 				"Add PM=1 for a TX frame while in PS mode\n");
for a TX frame while in PS mode\n"); 
buf : 			hdr->frame_control |= cpu_to_le16(IEEE80211_FCTL_PM);
buf : 		}
buf : 	}
buf : 
buf : 	if (unlikely(sc->sc_ah->power_mode == ATH9K_PM_NETWORK_SLEEP)) {
if (unlikely(sc->sc_ah->power_mode == ATH9K_PM_NETWORK_SLEEP)) { 
buf : 		/*
buf : 		 * We are using PS-Poll and mac80211 can request TX while in
while in 
buf : 		 * power save mode. Need to wake up hardware for the TX to be
buf : 		 * completed and if needed, also for RX of buffered frames.
if needed, also for RX of buffered frames. 
buf : 		 */
buf : 		ath9k_ps_wakeup(sc);
buf : 		spin_lock_irqsave(&sc->sc_pm_lock, flags);
buf : 		if (!(sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_AUTOSLEEP))
if (!(sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_AUTOSLEEP)) 
buf : 			ath9k_hw_setrxabort(sc->sc_ah, 0);
buf : 		if (ieee80211_is_pspoll(hdr->frame_control)) {
if (ieee80211_is_pspoll(hdr->frame_control)) { 
buf : 			ath_dbg(common, PS,
buf : 				"Sending PS-Poll to pick a buffered frame\n");
buf : 			sc->ps_flags |= PS_WAIT_FOR_PSPOLL_DATA;
buf : 		} else {
buf : 			ath_dbg(common, PS, "Wake up to complete TX\n");
buf : 			sc->ps_flags |= PS_WAIT_FOR_TX_ACK;
buf : 		}
buf : 		/*
buf : 		 * The actual restore operation will happen only after
buf : 		 * the ps_flags bit is cleared. We are just dropping
buf : 		 * the ps_usecount here.
buf : 		 */
buf : 		spin_unlock_irqrestore(&sc->sc_pm_lock, flags);
buf : 		ath9k_ps_restore(sc);
buf : 	}
buf : 
buf : 	/*
buf : 	 * Cannot tx while the hardware is in full sleep, it first needs a full
while the hardware is in full sleep, it first needs a full 
buf : 	 * chip reset to recover from that
buf : 	 */
buf : 	if (unlikely(sc->sc_ah->power_mode == ATH9K_PM_FULL_SLEEP)) {
if (unlikely(sc->sc_ah->power_mode == ATH9K_PM_FULL_SLEEP)) { 
buf : 		ath_err(common, "TX while HW is in FULL_SLEEP mode\n");
while HW is in FULL_SLEEP mode\n"); 
buf : 		goto exit;
buf : 	}
buf : 
buf : 	memset(&txctl, 0, sizeof(struct ath_tx_control));
buf : 	txctl.txq = sc->tx.txq_map[skb_get_queue_mapping(skb)];
buf : 	txctl.sta = control->sta;
buf : 
buf : 	ath_dbg(common, XMIT, "transmitting packet, skb: %p\n", skb);
buf : 
buf : 	if (ath_tx_start(hw, skb, &txctl) != 0) {
if (ath_tx_start(hw, skb, &txctl) != 0) { 
buf : 		ath_dbg(common, XMIT, "TX failed\n");
buf : 		TX_STAT_INC(txctl.txq->axq_qnum, txfailed);
buf : 		goto exit;
buf : 	}
buf : 
buf : 	return;
buf : exit:
buf : 	ieee80211_free_txskb(hw, skb);
buf : }
buf : 
buf : static void ath9k_stop(struct ieee80211_hw *hw)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	bool prev_idle;
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	ath_cancel_work(sc);
buf : 
buf : 	if (test_bit(ATH_OP_INVALID, &common->op_flags)) {
if (test_bit(ATH_OP_INVALID, &common->op_flags)) { 
buf : 		ath_dbg(common, ANY, "Device not present\n");
buf : 		mutex_unlock(&sc->mutex);
buf : 		return;
buf : 	}
buf : 
buf : 	/* Ensure HW is awake when we try to shut it down. */
buf : 	ath9k_ps_wakeup(sc);
buf : 
buf : 	spin_lock_bh(&sc->sc_pcu_lock);
buf : 
buf : 	/* prevent tasklets to enable interrupts once we disable them */
buf : 	ah->imask &= ~ATH9K_INT_GLOBAL;
buf : 
buf : 	/* make sure h/w will not generate any interrupt
buf : 	 * before setting the invalid flag. */
fore setting the invalid flag. */ 
buf : 	ath9k_hw_disable_interrupts(ah);
buf : 
buf : 	spin_unlock_bh(&sc->sc_pcu_lock);
buf : 
buf : 	/* we can now sync irq and kill any running tasklets, since we already
buf : 	 * disabled interrupts and not holding a spin lock */
buf : 	synchronize_irq(sc->irq);
buf : 	tasklet_kill(&sc->intr_tq);
buf : 	tasklet_kill(&sc->bcon_tasklet);
buf : 
buf : 	prev_idle = sc->ps_idle;
buf : 	sc->ps_idle = true;
buf : 
buf : 	spin_lock_bh(&sc->sc_pcu_lock);
buf : 
buf : 	if (ah->led_pin >= 0) {
if (ah->led_pin >= 0) { 
buf : 		ath9k_hw_set_gpio(ah, ah->led_pin, 1);
buf : 		ath9k_hw_cfg_gpio_input(ah, ah->led_pin);
buf : 	}
buf : 
buf : 	ath_prepare_reset(sc);
buf : 
buf : 	if (sc->rx.frag) {
if (sc->rx.frag) { 
buf : 		dev_kfree_skb_any(sc->rx.frag);
buf : 		sc->rx.frag = NULL;
buf : 	}
buf : 
buf : 	if (!ah->curchan)
if (!ah->curchan) 
buf : 		ah->curchan = ath9k_cmn_get_channel(hw, ah, &hw->conf.chandef);
buf : 
buf : 	ath9k_hw_reset(ah, ah->curchan, ah->caldata, false);
buf : 	ath9k_hw_phy_disable(ah);
buf : 
buf : 	ath9k_hw_configpcipowersave(ah, true);
buf : 
buf : 	spin_unlock_bh(&sc->sc_pcu_lock);
buf : 
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	set_bit(ATH_OP_INVALID, &common->op_flags);
buf : 	sc->ps_idle = prev_idle;
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : 
buf : 	ath_dbg(common, CONFIG, "Driver halt\n");
buf : }
buf : 
buf : static bool ath9k_uses_beacons(int type)
buf : {
buf : 	switch (type) {
buf : 	case NL80211_IFTYPE_AP:
buf : 	case NL80211_IFTYPE_ADHOC:
buf : 	case NL80211_IFTYPE_MESH_POINT:
buf : 		return true;
buf : 	default:
buf : 		return false;
buf : 	}
buf : }
buf : 
buf : static void ath9k_vif_iter(void *data, u8 *mac, struct ieee80211_vif *vif)
if_iter(void *data, u8 *mac, struct ieee80211_vif *vif) 
buf : {
buf : 	struct ath9k_vif_iter_data *iter_data = data;
buf : 	int i;
buf : 
buf : 	if (iter_data->has_hw_macaddr) {
if (iter_data->has_hw_macaddr) { 
buf : 		for (i = 0; i < ETH_ALEN; i++)
for (i = 0; i < ETH_ALEN; i++) 
buf : 			iter_data->mask[i] &=
buf : 				~(iter_data->hw_macaddr[i] ^ mac[i]);
buf : 	} else {
buf : 		memcpy(iter_data->hw_macaddr, mac, ETH_ALEN);
buf : 		iter_data->has_hw_macaddr = true;
buf : 	}
buf : 
buf : 	switch (vif->type) {
if->type) { 
buf : 	case NL80211_IFTYPE_AP:
buf : 		iter_data->naps++;
buf : 		break;
buf : 	case NL80211_IFTYPE_STATION:
buf : 		iter_data->nstations++;
buf : 		break;
buf : 	case NL80211_IFTYPE_ADHOC:
buf : 		iter_data->nadhocs++;
buf : 		break;
buf : 	case NL80211_IFTYPE_MESH_POINT:
buf : 		iter_data->nmeshes++;
buf : 		break;
buf : 	case NL80211_IFTYPE_WDS:
buf : 		iter_data->nwds++;
buf : 		break;
buf : 	default:
buf : 		break;
buf : 	}
buf : }
buf : 
buf : static void ath9k_sta_vif_iter(void *data, u8 *mac, struct ieee80211_vif *vif)
if_iter(void *data, u8 *mac, struct ieee80211_vif *vif) 
buf : {
buf : 	struct ath_softc *sc = data;
buf : 	struct ath_vif *avp = (void *)vif->drv_priv;
if *avp = (void *)vif->drv_priv; 
buf : 
buf : 	if (vif->type != NL80211_IFTYPE_STATION)
buf : 		return;
buf : 
buf : 	if (avp->primary_sta_vif)
if (avp->primary_sta_vif) 
buf : 		ath9k_set_assoc_state(sc, vif);
buf : }
buf : 
buf : /* Called with sc->mutex held. */
buf : void ath9k_calculate_iter_data(struct ieee80211_hw *hw,
buf : 			       struct ieee80211_vif *vif,
if *vif, 
buf : 			       struct ath9k_vif_iter_data *iter_data)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 
buf : 	/*
buf : 	 * Pick the MAC address of the first interface as the new hardware
buf : 	 * MAC address. The hardware will use it together with the BSSID mask
buf : 	 * when matching addresses.
buf : 	 */
buf : 	memset(iter_data, 0, sizeof(*iter_data));
buf : 	memset(&iter_data->mask, 0xff, ETH_ALEN);
buf : 
buf : 	if (vif)
if (vif) 
buf : 		ath9k_vif_iter(iter_data, vif->addr, vif);
buf : 
buf : 	/* Get list of all active MAC addresses */
buf : 	ieee80211_iterate_active_interfaces_atomic(
buf : 		sc->hw, IEEE80211_IFACE_ITER_RESUME_ALL,
buf : 		ath9k_vif_iter, iter_data);
if_iter, iter_data); 
buf : 
buf : 	memcpy(common->macaddr, iter_data->hw_macaddr, ETH_ALEN);
buf : }
buf : 
buf : /* Called with sc->mutex held. */
buf : static void ath9k_calculate_summary_state(struct ieee80211_hw *hw,
buf : 					  struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	struct ath9k_vif_iter_data iter_data;
if_iter_data iter_data; 
buf : 	enum nl80211_iftype old_opmode = ah->opmode;
buf : 
buf : 	ath9k_calculate_iter_data(hw, vif, &iter_data);
if, &iter_data); 
buf : 
buf : 	memcpy(common->bssidmask, iter_data.mask, ETH_ALEN);
buf : 	ath_hw_setbssidmask(common);
buf : 
buf : 	if (iter_data.naps > 0) {
if (iter_data.naps > 0) { 
buf : 		ath9k_hw_set_tsfadjust(ah, true);
buf : 		ah->opmode = NL80211_IFTYPE_AP;
buf : 	} else {
buf : 		ath9k_hw_set_tsfadjust(ah, false);
buf : 
buf : 		if (iter_data.nmeshes)
if (iter_data.nmeshes) 
buf : 			ah->opmode = NL80211_IFTYPE_MESH_POINT;
buf : 		else if (iter_data.nwds)
if (iter_data.nwds) 
buf : 			ah->opmode = NL80211_IFTYPE_AP;
buf : 		else if (iter_data.nadhocs)
if (iter_data.nadhocs) 
buf : 			ah->opmode = NL80211_IFTYPE_ADHOC;
buf : 		else
buf : 			ah->opmode = NL80211_IFTYPE_STATION;
buf : 	}
buf : 
buf : 	ath9k_hw_setopmode(ah);
buf : 
buf : 	if ((iter_data.nstations + iter_data.nadhocs + iter_data.nmeshes) > 0)
if ((iter_data.nstations + iter_data.nadhocs + iter_data.nmeshes) > 0) 
buf : 		ah->imask |= ATH9K_INT_TSFOOR;
buf : 	else
buf : 		ah->imask &= ~ATH9K_INT_TSFOOR;
buf : 
buf : 	ath9k_hw_set_interrupts(ah);
buf : 
buf : 	/*
buf : 	 * If we are changing the opmode to STATION,
buf : 	 * a beacon sync needs to be done.
buf : 	 */
buf : 	if (ah->opmode == NL80211_IFTYPE_STATION &&
if (ah->opmode == NL80211_IFTYPE_STATION && 
buf : 	    old_opmode == NL80211_IFTYPE_AP &&
buf : 	    test_bit(ATH_OP_PRIM_STA_VIF, &common->op_flags)) {
buf : 		ieee80211_iterate_active_interfaces_atomic(
buf : 			sc->hw, IEEE80211_IFACE_ITER_RESUME_ALL,
buf : 			ath9k_sta_vif_iter, sc);
if_iter, sc); 
buf : 	}
buf : }
buf : 
buf : static int ath9k_add_interface(struct ieee80211_hw *hw,
buf : 			       struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	struct ath_vif *avp = (void *)vif->drv_priv;
if *avp = (void *)vif->drv_priv; 
buf : 	struct ath_node *an = &avp->mcast_node;
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	if (config_enabled(CONFIG_ATH9K_TX99)) {
if (config_enabled(CONFIG_ATH9K_TX99)) { 
buf : 		if (sc->nvifs >= 1) {
buf : 			mutex_unlock(&sc->mutex);
buf : 			return -EOPNOTSUPP;
buf : 		}
buf : 		sc->tx99_vif = vif;
if = vif; 
buf : 	}
buf : 
buf : 	ath_dbg(common, CONFIG, "Attach a VIF of type: %d\n", vif->type);
buf : 	sc->nvifs++;
ifs++; 
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	ath9k_calculate_summary_state(hw, vif);
if); 
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	if (ath9k_uses_beacons(vif->type))
if (ath9k_uses_beacons(vif->type)) 
buf : 		ath9k_beacon_assign_slot(sc, vif);
buf : 
buf : 	avp->vif = vif;
if = vif; 
buf : 
buf : 	an->sc = sc;
buf : 	an->sta = NULL;
buf : 	an->vif = vif;
if = vif; 
buf : 	an->no_ps_filter = true;
buf : 	ath_tx_node_init(sc, an);
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : 	return 0;
buf : }
buf : 
buf : static int ath9k_change_interface(struct ieee80211_hw *hw,
buf : 				  struct ieee80211_vif *vif,
if *vif, 
buf : 				  enum nl80211_iftype new_type,
buf : 				  bool p2p)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	if (config_enabled(CONFIG_ATH9K_TX99)) {
if (config_enabled(CONFIG_ATH9K_TX99)) { 
buf : 		mutex_unlock(&sc->mutex);
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	ath_dbg(common, CONFIG, "Change Interface\n");
buf : 
buf : 	if (ath9k_uses_beacons(vif->type))
if (ath9k_uses_beacons(vif->type)) 
buf : 		ath9k_beacon_remove_slot(sc, vif);
buf : 
buf : 	vif->type = new_type;
if->type = new_type; 
buf : 	vif->p2p = p2p;
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	ath9k_calculate_summary_state(hw, vif);
if); 
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	if (ath9k_uses_beacons(vif->type))
if (ath9k_uses_beacons(vif->type)) 
buf : 		ath9k_beacon_assign_slot(sc, vif);
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : 	return 0;
buf : }
buf : 
buf : static void
buf : ath9k_update_p2p_ps_timer(struct ath_softc *sc, struct ath_vif *avp)
if *avp) 
buf : {
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	s32 tsf, target_tsf;
buf : 
buf : 	if (!avp || !avp->noa.has_next_tsf)
if (!avp || !avp->noa.has_next_tsf) 
buf : 		return;
buf : 
buf : 	ath9k_hw_gen_timer_stop(ah, sc->p2p_ps_timer);
buf : 
buf : 	tsf = ath9k_hw_gettsf32(sc->sc_ah);
buf : 
buf : 	target_tsf = avp->noa.next_tsf;
buf : 	if (!avp->noa.absent)
if (!avp->noa.absent) 
buf : 		target_tsf -= ATH_P2P_PS_STOP_TIME;
buf : 
buf : 	if (target_tsf - tsf < ATH_P2P_PS_STOP_TIME)
if (target_tsf - tsf < ATH_P2P_PS_STOP_TIME) 
buf : 		target_tsf = tsf + ATH_P2P_PS_STOP_TIME;
buf : 
buf : 	ath9k_hw_gen_timer_start(ah, sc->p2p_ps_timer, (u32) target_tsf, 1000000);
buf : }
buf : 
buf : static void ath9k_remove_interface(struct ieee80211_hw *hw,
buf : 				   struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	struct ath_vif *avp = (void *)vif->drv_priv;
if *avp = (void *)vif->drv_priv; 
buf : 
buf : 	ath_dbg(common, CONFIG, "Detach Interface\n");
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	spin_lock_bh(&sc->sc_pcu_lock);
buf : 	if (avp == sc->p2p_ps_vif) {
if (avp == sc->p2p_ps_vif) { 
buf : 		sc->p2p_ps_vif = NULL;
buf : 		ath9k_update_p2p_ps_timer(sc, NULL);
buf : 	}
buf : 	spin_unlock_bh(&sc->sc_pcu_lock);
buf : 
buf : 	sc->nvifs--;
ifs--; 
buf : 	sc->tx99_vif = NULL;
buf : 
buf : 	if (ath9k_uses_beacons(vif->type))
if (ath9k_uses_beacons(vif->type)) 
buf : 		ath9k_beacon_remove_slot(sc, vif);
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	ath9k_calculate_summary_state(hw, NULL);
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	ath_tx_node_cleanup(sc, &avp->mcast_node);
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : }
buf : 
buf : static void ath9k_enable_ps(struct ath_softc *sc)
buf : {
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 
buf : 	if (config_enabled(CONFIG_ATH9K_TX99))
if (config_enabled(CONFIG_ATH9K_TX99)) 
buf : 		return;
buf : 
buf : 	sc->ps_enabled = true;
buf : 	if (!(ah->caps.hw_caps & ATH9K_HW_CAP_AUTOSLEEP)) {
if (!(ah->caps.hw_caps & ATH9K_HW_CAP_AUTOSLEEP)) { 
buf : 		if ((ah->imask & ATH9K_INT_TIM_TIMER) == 0) {
buf : 			ah->imask |= ATH9K_INT_TIM_TIMER;
buf : 			ath9k_hw_set_interrupts(ah);
buf : 		}
buf : 		ath9k_hw_setrxabort(ah, 1);
buf : 	}
buf : 	ath_dbg(common, PS, "PowerSave enabled\n");
buf : }
buf : 
buf : static void ath9k_disable_ps(struct ath_softc *sc)
buf : {
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 
buf : 	if (config_enabled(CONFIG_ATH9K_TX99))
if (config_enabled(CONFIG_ATH9K_TX99)) 
buf : 		return;
buf : 
buf : 	sc->ps_enabled = false;
buf : 	ath9k_hw_setpower(ah, ATH9K_PM_AWAKE);
buf : 	if (!(ah->caps.hw_caps & ATH9K_HW_CAP_AUTOSLEEP)) {
if (!(ah->caps.hw_caps & ATH9K_HW_CAP_AUTOSLEEP)) { 
buf : 		ath9k_hw_setrxabort(ah, 0);
buf : 		sc->ps_flags &= ~(PS_WAIT_FOR_BEACON |
buf : 				  PS_WAIT_FOR_CAB |
buf : 				  PS_WAIT_FOR_PSPOLL_DATA |
buf : 				  PS_WAIT_FOR_TX_ACK);
buf : 		if (ah->imask & ATH9K_INT_TIM_TIMER) {
if (ah->imask & ATH9K_INT_TIM_TIMER) { 
buf : 			ah->imask &= ~ATH9K_INT_TIM_TIMER;
buf : 			ath9k_hw_set_interrupts(ah);
buf : 		}
buf : 	}
buf : 	ath_dbg(common, PS, "PowerSave disabled\n");
buf : }
buf : 
buf : void ath9k_spectral_scan_trigger(struct ieee80211_hw *hw)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	u32 rxfilter;
buf : 
buf : 	if (config_enabled(CONFIG_ATH9K_TX99))
if (config_enabled(CONFIG_ATH9K_TX99)) 
buf : 		return;
buf : 
buf : 	if (!ath9k_hw_ops(ah)->spectral_scan_trigger) {
if (!ath9k_hw_ops(ah)->spectral_scan_trigger) { 
buf : 		ath_err(common, "spectrum analyzer not implemented on this hardware\n");
buf : 		return;
buf : 	}
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	rxfilter = ath9k_hw_getrxfilter(ah);
buf : 	ath9k_hw_setrxfilter(ah, rxfilter |
buf : 				 ATH9K_RX_FILTER_PHYRADAR |
buf : 				 ATH9K_RX_FILTER_PHYERR);
buf : 
buf : 	/* TODO: usually this should not be neccesary, but for some reason
for some reason 
buf : 	 * (or in some mode?) the trigger must be called after the
buf : 	 * configuration, otherwise the register will have its values reset
buf : 	 * (on my ar9220 to value 0x01002310)
buf : 	 */
buf : 	ath9k_spectral_scan_config(hw, sc->spectral_mode);
buf : 	ath9k_hw_ops(ah)->spectral_scan_trigger(ah);
buf : 	ath9k_ps_restore(sc);
buf : }
buf : 
buf : int ath9k_spectral_scan_config(struct ieee80211_hw *hw,
buf : 			       enum spectral_mode spectral_mode)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 
buf : 	if (!ath9k_hw_ops(ah)->spectral_scan_trigger) {
if (!ath9k_hw_ops(ah)->spectral_scan_trigger) { 
buf : 		ath_err(common, "spectrum analyzer not implemented on this hardware\n");
buf : 		return -1;
buf : 	}
buf : 
buf : 	switch (spectral_mode) {
buf : 	case SPECTRAL_DISABLED:
buf : 		sc->spec_config.enabled = 0;
buf : 		break;
buf : 	case SPECTRAL_BACKGROUND:
buf : 		/* send endless samples.
buf : 		 * TODO: is this really useful for "background"?
for "background"? 
buf : 		 */
buf : 		sc->spec_config.endless = 1;
buf : 		sc->spec_config.enabled = 1;
buf : 		break;
buf : 	case SPECTRAL_CHANSCAN:
buf : 	case SPECTRAL_MANUAL:
buf : 		sc->spec_config.endless = 0;
buf : 		sc->spec_config.enabled = 1;
buf : 		break;
buf : 	default:
buf : 		return -1;
buf : 	}
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	ath9k_hw_ops(ah)->spectral_scan_config(ah, &sc->spec_config);
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	sc->spectral_mode = spectral_mode;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int ath9k_config(struct ieee80211_hw *hw, u32 changed)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 	bool reset_channel = false;
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_IDLE) {
if (changed & IEEE80211_CONF_CHANGE_IDLE) { 
buf : 		sc->ps_idle = !!(conf->flags & IEEE80211_CONF_IDLE);
buf : 		if (sc->ps_idle) {
if (sc->ps_idle) { 
buf : 			ath_cancel_work(sc);
buf : 			ath9k_stop_btcoex(sc);
buf : 		} else {
buf : 			ath9k_start_btcoex(sc);
buf : 			/*
buf : 			 * The chip needs a reset to properly wake up from
buf : 			 * full sleep
buf : 			 */
buf : 			reset_channel = ah->chip_fullsleep;
buf : 		}
buf : 	}
buf : 
buf : 	/*
buf : 	 * We just prepare to enable PS. We have to wait until our AP has
buf : 	 * ACK'd our null data frame to disable RX otherwise we'll ignore
buf : 	 * those ACKs and end up retransmitting the same null data frames.
buf : 	 * IEEE80211_CONF_CHANGE_PS is only passed by mac80211 for STA mode.
for STA mode. 
buf : 	 */
buf : 	if (changed & IEEE80211_CONF_CHANGE_PS) {
if (changed & IEEE80211_CONF_CHANGE_PS) { 
buf : 		unsigned long flags;
buf : 		spin_lock_irqsave(&sc->sc_pm_lock, flags);
buf : 		if (conf->flags & IEEE80211_CONF_PS)
if (conf->flags & IEEE80211_CONF_PS) 
buf : 			ath9k_enable_ps(sc);
buf : 		else
buf : 			ath9k_disable_ps(sc);
buf : 		spin_unlock_irqrestore(&sc->sc_pm_lock, flags);
buf : 	}
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_MONITOR) {
if (changed & IEEE80211_CONF_CHANGE_MONITOR) { 
buf : 		if (conf->flags & IEEE80211_CONF_MONITOR) {
buf : 			ath_dbg(common, CONFIG, "Monitor mode is enabled\n");
buf : 			sc->sc_ah->is_monitoring = true;
buf : 		} else {
buf : 			ath_dbg(common, CONFIG, "Monitor mode is disabled\n");
buf : 			sc->sc_ah->is_monitoring = false;
buf : 		}
buf : 	}
buf : 
buf : 	if ((changed & IEEE80211_CONF_CHANGE_CHANNEL) || reset_channel) {
if ((changed & IEEE80211_CONF_CHANGE_CHANNEL) || reset_channel) { 
buf : 		if (ath_set_channel(sc, &hw->conf.chandef) < 0) {
buf : 			ath_err(common, "Unable to set channel\n");
buf : 			mutex_unlock(&sc->mutex);
buf : 			ath9k_ps_restore(sc);
buf : 			return -EINVAL;
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_POWER) {
if (changed & IEEE80211_CONF_CHANGE_POWER) { 
buf : 		ath_dbg(common, CONFIG, "Set power: %d\n", conf->power_level);
buf : 		sc->config.txpowlimit = 2 * conf->power_level;
buf : 		ath9k_cmn_update_txpow(ah, sc->curtxpow,
buf : 				       sc->config.txpowlimit, &sc->curtxpow);
buf : 	}
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : #define SUPPORTED_FILTERS			\
buf : 	(FIF_PROMISC_IN_BSS |			\
buf : 	FIF_ALLMULTI |				\
buf : 	FIF_CONTROL |				\
buf : 	FIF_PSPOLL |				\
buf : 	FIF_OTHER_BSS |				\
buf : 	FIF_BCN_PRBRESP_PROMISC |		\
buf : 	FIF_PROBE_REQ |				\
buf : 	FIF_FCSFAIL)
buf : 
buf : /* FIXME: sc->sc_full_reset ? */
buf : static void ath9k_configure_filter(struct ieee80211_hw *hw,
buf : 				   unsigned int changed_flags,
buf : 				   unsigned int *total_flags,
buf : 				   u64 multicast)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	u32 rfilt;
buf : 
buf : 	changed_flags &= SUPPORTED_FILTERS;
buf : 	*total_flags &= SUPPORTED_FILTERS;
buf : 
buf : 	sc->rx.rxfilter = *total_flags;
buf : 	ath9k_ps_wakeup(sc);
buf : 	rfilt = ath_calcrxfilter(sc);
buf : 	ath9k_hw_setrxfilter(sc->sc_ah, rfilt);
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	ath_dbg(ath9k_hw_common(sc->sc_ah), CONFIG, "Set HW RX filter: 0x%x\n",
buf : 		rfilt);
buf : }
buf : 
buf : static int ath9k_sta_add(struct ieee80211_hw *hw,
buf : 			 struct ieee80211_vif *vif,
if *vif, 
buf : 			 struct ieee80211_sta *sta)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	struct ath_node *an = (struct ath_node *) sta->drv_priv;
buf : 	struct ieee80211_key_conf ps_key = { };
buf : 	int key;
buf : 
buf : 	ath_node_attach(sc, sta, vif);
if); 
buf : 
buf : 	if (vif->type != NL80211_IFTYPE_AP &&
buf : 	    vif->type != NL80211_IFTYPE_AP_VLAN)
if->type != NL80211_IFTYPE_AP_VLAN) 
buf : 		return 0;
buf : 
buf : 	key = ath_key_config(common, vif, sta, &ps_key);
if, sta, &ps_key); 
buf : 	if (key > 0) {
buf : 		an->ps_key = key;
buf : 		an->key_idx[0] = key;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void ath9k_del_ps_key(struct ath_softc *sc,
buf : 			     struct ieee80211_vif *vif,
if *vif, 
buf : 			     struct ieee80211_sta *sta)
buf : {
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	struct ath_node *an = (struct ath_node *) sta->drv_priv;
buf : 	struct ieee80211_key_conf ps_key = { .hw_key_idx = an->ps_key };
buf : 
buf : 	if (!an->ps_key)
if (!an->ps_key) 
buf : 	    return;
buf : 
buf : 	ath_key_delete(common, &ps_key);
buf : 	an->ps_key = 0;
buf : 	an->key_idx[0] = 0;
buf : }
buf : 
buf : static int ath9k_sta_remove(struct ieee80211_hw *hw,
buf : 			    struct ieee80211_vif *vif,
if *vif, 
buf : 			    struct ieee80211_sta *sta)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 
buf : 	ath9k_del_ps_key(sc, vif, sta);
if, sta); 
buf : 	ath_node_detach(sc, sta);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void ath9k_sta_set_tx_filter(struct ath_hw *ah,
buf : 				    struct ath_node *an,
buf : 				    bool set)
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(an->key_idx); i++) {
for (i = 0; i < ARRAY_SIZE(an->key_idx); i++) { 
buf : 		if (!an->key_idx[i])
buf : 			continue;
buf : 		ath9k_hw_set_tx_filter(ah, an->key_idx[i], set);
buf : 	}
buf : }
buf : 
buf : static void ath9k_sta_notify(struct ieee80211_hw *hw,
ify(struct ieee80211_hw *hw, 
buf : 			 struct ieee80211_vif *vif,
buf : 			 enum sta_notify_cmd cmd,
ify_cmd cmd, 
buf : 			 struct ieee80211_sta *sta)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_node *an = (struct ath_node *) sta->drv_priv;
buf : 
buf : 	switch (cmd) {
buf : 	case STA_NOTIFY_SLEEP:
buf : 		an->sleeping = true;
buf : 		ath_tx_aggr_sleep(sta, sc, an);
buf : 		ath9k_sta_set_tx_filter(sc->sc_ah, an, true);
buf : 		break;
buf : 	case STA_NOTIFY_AWAKE:
buf : 		ath9k_sta_set_tx_filter(sc->sc_ah, an, false);
buf : 		an->sleeping = false;
buf : 		ath_tx_aggr_wakeup(sc, an);
buf : 		break;
buf : 	}
buf : }
buf : 
buf : static int ath9k_conf_tx(struct ieee80211_hw *hw,
buf : 			 struct ieee80211_vif *vif, u16 queue,
if *vif, u16 queue, 
buf : 			 const struct ieee80211_tx_queue_params *params)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	struct ath_txq *txq;
buf : 	struct ath9k_tx_queue_info qi;
buf : 	int ret = 0;
buf : 
buf : 	if (queue >= IEEE80211_NUM_ACS)
if (queue >= IEEE80211_NUM_ACS) 
buf : 		return 0;
buf : 
buf : 	txq = sc->tx.txq_map[queue];
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	memset(&qi, 0, sizeof(struct ath9k_tx_queue_info));
buf : 
buf : 	qi.tqi_aifs = params->aifs;
ifs = params->aifs; 
buf : 	qi.tqi_cwmin = params->cw_min;
buf : 	qi.tqi_cwmax = params->cw_max;
buf : 	qi.tqi_burstTime = params->txop * 32;
buf : 
buf : 	ath_dbg(common, CONFIG,
buf : 		"Configure tx [queue/halq] [%d/%d], aifs: %d, cw_min: %d, cw_max: %d, txop: %d\n",
ifs: %d, cw_min: %d, cw_max: %d, txop: %d\n", 
buf : 		queue, txq->axq_qnum, params->aifs, params->cw_min,
buf : 		params->cw_max, params->txop);
buf : 
buf : 	ath_update_max_aggr_framelen(sc, queue, qi.tqi_burstTime);
buf : 	ret = ath_txq_update(sc, txq->axq_qnum, &qi);
buf : 	if (ret)
if (ret) 
buf : 		ath_err(common, "TXQ Update failed\n");
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int ath9k_set_key(struct ieee80211_hw *hw,
buf : 			 enum set_key_cmd cmd,
buf : 			 struct ieee80211_vif *vif,
if *vif, 
buf : 			 struct ieee80211_sta *sta,
buf : 			 struct ieee80211_key_conf *key)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	struct ath_node *an = NULL;
buf : 	int ret = 0, i;
buf : 
buf : 	if (ath9k_modparam_nohwcrypt)
if (ath9k_modparam_nohwcrypt) 
buf : 		return -ENOSPC;
buf : 
buf : 	if ((vif->type == NL80211_IFTYPE_ADHOC ||
if ((vif->type == NL80211_IFTYPE_ADHOC || 
buf : 	     vif->type == NL80211_IFTYPE_MESH_POINT) &&
buf : 	    (key->cipher == WLAN_CIPHER_SUITE_TKIP ||
buf : 	     key->cipher == WLAN_CIPHER_SUITE_CCMP) &&
buf : 	    !(key->flags & IEEE80211_KEY_FLAG_PAIRWISE)) {
buf : 		/*
buf : 		 * For now, disable hw crypto for the RSN IBSS group keys. This
for the RSN IBSS group keys. This 
buf : 		 * could be optimized in the future to use a modified key cache
buf : 		 * design to support per-STA RX GTK, but until that gets
buf : 		 * implemented, use of software crypto for group addressed
for group addressed 
buf : 		 * frames is a acceptable to allow RSN IBSS to be used.
buf : 		 */
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 	ath9k_ps_wakeup(sc);
buf : 	ath_dbg(common, CONFIG, "Set HW Key %d\n", cmd);
buf : 	if (sta)
if (sta) 
buf : 		an = (struct ath_node *)sta->drv_priv;
buf : 
buf : 	switch (cmd) {
buf : 	case SET_KEY:
buf : 		if (sta)
if (sta) 
buf : 			ath9k_del_ps_key(sc, vif, sta);
buf : 
buf : 		key->hw_key_idx = 0;
buf : 		ret = ath_key_config(common, vif, sta, key);
if, sta, key); 
buf : 		if (ret >= 0) {
buf : 			key->hw_key_idx = ret;
buf : 			/* push IV and Michael MIC generation to stack */
buf : 			key->flags |= IEEE80211_KEY_FLAG_GENERATE_IV;
buf : 			if (key->cipher == WLAN_CIPHER_SUITE_TKIP)
if (key->cipher == WLAN_CIPHER_SUITE_TKIP) 
buf : 				key->flags |= IEEE80211_KEY_FLAG_GENERATE_MMIC;
buf : 			if (sc->sc_ah->sw_mgmt_crypto &&
if (sc->sc_ah->sw_mgmt_crypto && 
buf : 			    key->cipher == WLAN_CIPHER_SUITE_CCMP)
buf : 				key->flags |= IEEE80211_KEY_FLAG_SW_MGMT_TX;
buf : 			ret = 0;
buf : 		}
buf : 		if (an && key->hw_key_idx) {
if (an && key->hw_key_idx) { 
buf : 			for (i = 0; i < ARRAY_SIZE(an->key_idx); i++) {
for (i = 0; i < ARRAY_SIZE(an->key_idx); i++) { 
buf : 				if (an->key_idx[i])
buf : 					continue;
buf : 				an->key_idx[i] = key->hw_key_idx;
buf : 				break;
buf : 			}
buf : 			WARN_ON(i == ARRAY_SIZE(an->key_idx));
buf : 		}
buf : 		break;
buf : 	case DISABLE_KEY:
buf : 		ath_key_delete(common, key);
buf : 		if (an) {
if (an) { 
buf : 			for (i = 0; i < ARRAY_SIZE(an->key_idx); i++) {
for (i = 0; i < ARRAY_SIZE(an->key_idx); i++) { 
buf : 				if (an->key_idx[i] != key->hw_key_idx)
buf : 					continue;
buf : 				an->key_idx[i] = 0;
buf : 				break;
buf : 			}
buf : 		}
buf : 		key->hw_key_idx = 0;
buf : 		break;
buf : 	default:
buf : 		ret = -EINVAL;
buf : 	}
buf : 
buf : 	ath9k_ps_restore(sc);
buf : 	mutex_unlock(&sc->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void ath9k_set_assoc_state(struct ath_softc *sc,
buf : 				  struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	struct ath_vif *avp = (void *)vif->drv_priv;
if *avp = (void *)vif->drv_priv; 
buf : 	struct ieee80211_bss_conf *bss_conf = &vif->bss_conf;
buf : 	unsigned long flags;
buf : 
buf : 	set_bit(ATH_OP_PRIM_STA_VIF, &common->op_flags);
buf : 	avp->primary_sta_vif = true;
if = true; 
buf : 
buf : 	/*
buf : 	 * Set the AID, BSSID and do beacon-sync only when
buf : 	 * the HW opmode is STATION.
buf : 	 *
buf : 	 * But the primary bit is set above in any case.
buf : 	 */
buf : 	if (sc->sc_ah->opmode != NL80211_IFTYPE_STATION)
if (sc->sc_ah->opmode != NL80211_IFTYPE_STATION) 
buf : 		return;
buf : 
buf : 	memcpy(common->curbssid, bss_conf->bssid, ETH_ALEN);
buf : 	common->curaid = bss_conf->aid;
buf : 	ath9k_hw_write_associd(sc->sc_ah);
buf : 
buf : 	common->last_rssi = ATH_RSSI_DUMMY_MARKER;
buf : 	sc->sc_ah->stats.avgbrssi = ATH_RSSI_DUMMY_MARKER;
buf : 
buf : 	spin_lock_irqsave(&sc->sc_pm_lock, flags);
buf : 	sc->ps_flags |= PS_BEACON_SYNC | PS_WAIT_FOR_BEACON;
buf : 	spin_unlock_irqrestore(&sc->sc_pm_lock, flags);
buf : 
buf : 	if (ath9k_hw_mci_is_enabled(sc->sc_ah))
if (ath9k_hw_mci_is_enabled(sc->sc_ah)) 
buf : 		ath9k_mci_update_wlan_channels(sc, false);
buf : 
buf : 	ath_dbg(common, CONFIG,
buf : 		"Primary Station interface: %pM, BSSID: %pM\n",
buf : 		vif->addr, common->curbssid);
if->addr, common->curbssid); 
buf : }
buf : 
buf : static void ath9k_bss_assoc_iter(void *data, u8 *mac, struct ieee80211_vif *vif)
buf : {
buf : 	struct ath_softc *sc = data;
buf : 	struct ieee80211_bss_conf *bss_conf = &vif->bss_conf;
if->bss_conf; 
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 
buf : 	if (test_bit(ATH_OP_PRIM_STA_VIF, &common->op_flags))
if (test_bit(ATH_OP_PRIM_STA_VIF, &common->op_flags)) 
buf : 		return;
buf : 
buf : 	if (bss_conf->assoc)
if (bss_conf->assoc) 
buf : 		ath9k_set_assoc_state(sc, vif);
buf : }
buf : 
buf : void ath9k_p2p_ps_timer(void *priv)
buf : {
buf : 	struct ath_softc *sc = priv;
buf : 	struct ath_vif *avp = sc->p2p_ps_vif;
if *avp = sc->p2p_ps_vif; 
buf : 	struct ieee80211_vif *vif;
buf : 	struct ieee80211_sta *sta;
buf : 	struct ath_node *an;
buf : 	u32 tsf;
buf : 
buf : 	if (!avp)
if (!avp) 
buf : 		return;
buf : 
buf : 	tsf = ath9k_hw_gettsf32(sc->sc_ah);
buf : 	if (!avp->noa.absent)
if (!avp->noa.absent) 
buf : 		tsf += ATH_P2P_PS_STOP_TIME;
buf : 
buf : 	if (!avp->noa.has_next_tsf ||
if (!avp->noa.has_next_tsf || 
buf : 	    avp->noa.next_tsf - tsf > BIT(31))
buf : 		ieee80211_update_p2p_noa(&avp->noa, tsf);
buf : 
buf : 	ath9k_update_p2p_ps_timer(sc, avp);
buf : 
buf : 	rcu_read_lock();
buf : 
buf : 	vif = avp->vif;
if = avp->vif; 
buf : 	sta = ieee80211_find_sta(vif, vif->bss_conf.bssid);
buf : 	if (!sta)
if (!sta) 
buf : 		goto out;
buf : 
buf : 	an = (void *) sta->drv_priv;
buf : 	if (an->sleeping == !!avp->noa.absent)
if (an->sleeping == !!avp->noa.absent) 
buf : 		goto out;
buf : 
buf : 	an->sleeping = avp->noa.absent;
buf : 	if (an->sleeping)
if (an->sleeping) 
buf : 		ath_tx_aggr_sleep(sta, sc, an);
buf : 	else
buf : 		ath_tx_aggr_wakeup(sc, an);
buf : 
buf : out:
buf : 	rcu_read_unlock();
buf : }
buf : 
buf : void ath9k_update_p2p_ps(struct ath_softc *sc, struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ath_vif *avp = (void *)vif->drv_priv;
buf : 	u32 tsf;
buf : 
buf : 	if (!sc->p2p_ps_timer)
if (!sc->p2p_ps_timer) 
buf : 		return;
buf : 
buf : 	if (vif->type != NL80211_IFTYPE_STATION || !vif->p2p)
if (vif->type != NL80211_IFTYPE_STATION || !vif->p2p) 
buf : 		return;
buf : 
buf : 	sc->p2p_ps_vif = avp;
if = avp; 
buf : 	tsf = ath9k_hw_gettsf32(sc->sc_ah);
buf : 	ieee80211_parse_p2p_noa(&vif->bss_conf.p2p_noa_attr, &avp->noa, tsf);
if->bss_conf.p2p_noa_attr, &avp->noa, tsf); 
buf : 	ath9k_update_p2p_ps_timer(sc, avp);
buf : }
buf : 
buf : static void ath9k_bss_info_changed(struct ieee80211_hw *hw,
buf : 				   struct ieee80211_vif *vif,
if *vif, 
buf : 				   struct ieee80211_bss_conf *bss_conf,
buf : 				   u32 changed)
buf : {
buf : #define CHECK_ANI				\
buf : 	(BSS_CHANGED_ASSOC |			\
buf : 	 BSS_CHANGED_IBSS |			\
buf : 	 BSS_CHANGED_BEACON_ENABLED)
buf : 
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	struct ath_vif *avp = (void *)vif->drv_priv;
if *avp = (void *)vif->drv_priv; 
buf : 	unsigned long flags;
buf : 	int slottime;
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	if (changed & BSS_CHANGED_ASSOC) {
if (changed & BSS_CHANGED_ASSOC) { 
buf : 		ath_dbg(common, CONFIG, "BSSID %pM Changed ASSOC %d\n",
buf : 			bss_conf->bssid, bss_conf->assoc);
buf : 
buf : 		if (avp->primary_sta_vif && !bss_conf->assoc) {
if (avp->primary_sta_vif && !bss_conf->assoc) { 
buf : 			clear_bit(ATH_OP_PRIM_STA_VIF, &common->op_flags);
buf : 			avp->primary_sta_vif = false;
if = false; 
buf : 
buf : 			if (ah->opmode == NL80211_IFTYPE_STATION)
buf : 				clear_bit(ATH_OP_BEACONS, &common->op_flags);
buf : 		}
buf : 
buf : 		ieee80211_iterate_active_interfaces_atomic(
buf : 			sc->hw, IEEE80211_IFACE_ITER_RESUME_ALL,
buf : 			ath9k_bss_assoc_iter, sc);
buf : 
buf : 		if (!test_bit(ATH_OP_PRIM_STA_VIF, &common->op_flags) &&
if (!test_bit(ATH_OP_PRIM_STA_VIF, &common->op_flags) && 
buf : 		    ah->opmode == NL80211_IFTYPE_STATION) {
buf : 			memset(common->curbssid, 0, ETH_ALEN);
buf : 			common->curaid = 0;
buf : 			ath9k_hw_write_associd(sc->sc_ah);
buf : 			if (ath9k_hw_mci_is_enabled(sc->sc_ah))
if (ath9k_hw_mci_is_enabled(sc->sc_ah)) 
buf : 				ath9k_mci_update_wlan_channels(sc, true);
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_IBSS) {
if (changed & BSS_CHANGED_IBSS) { 
buf : 		memcpy(common->curbssid, bss_conf->bssid, ETH_ALEN);
buf : 		common->curaid = bss_conf->aid;
buf : 		ath9k_hw_write_associd(sc->sc_ah);
buf : 	}
buf : 
buf : 	if ((changed & BSS_CHANGED_BEACON_ENABLED) ||
if ((changed & BSS_CHANGED_BEACON_ENABLED) || 
buf : 	    (changed & BSS_CHANGED_BEACON_INT))
buf : 		ath9k_beacon_config(sc, vif, changed);
if, changed); 
buf : 
buf : 	if (changed & BSS_CHANGED_ERP_SLOT) {
buf : 		if (bss_conf->use_short_slot)
if (bss_conf->use_short_slot) 
buf : 			slottime = 9;
buf : 		else
buf : 			slottime = 20;
buf : 		if (vif->type == NL80211_IFTYPE_AP) {
if (vif->type == NL80211_IFTYPE_AP) { 
buf : 			/*
buf : 			 * Defer update, so that connected stations can adjust
buf : 			 * their settings at the same time.
buf : 			 * See beacon.c for more details
for more details 
buf : 			 */
buf : 			sc->beacon.slottime = slottime;
buf : 			sc->beacon.updateslot = UPDATE;
buf : 		} else {
buf : 			ah->slottime = slottime;
buf : 			ath9k_hw_init_global_settings(ah);
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_P2P_PS) {
if (changed & BSS_CHANGED_P2P_PS) { 
buf : 		spin_lock_bh(&sc->sc_pcu_lock);
buf : 		spin_lock_irqsave(&sc->sc_pm_lock, flags);
buf : 		if (!(sc->ps_flags & PS_BEACON_SYNC))
if (!(sc->ps_flags & PS_BEACON_SYNC)) 
buf : 			ath9k_update_p2p_ps(sc, vif);
buf : 		spin_unlock_irqrestore(&sc->sc_pm_lock, flags);
buf : 		spin_unlock_bh(&sc->sc_pcu_lock);
buf : 	}
buf : 
buf : 	if (changed & CHECK_ANI)
if (changed & CHECK_ANI) 
buf : 		ath_check_ani(sc);
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : 	ath9k_ps_restore(sc);
buf : 
buf : #undef CHECK_ANI
buf : }
buf : 
buf : static u64 ath9k_get_tsf(struct ieee80211_hw *hw, struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	u64 tsf;
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 	ath9k_ps_wakeup(sc);
buf : 	tsf = ath9k_hw_gettsf64(sc->sc_ah);
buf : 	ath9k_ps_restore(sc);
buf : 	mutex_unlock(&sc->mutex);
buf : 
buf : 	return tsf;
buf : }
buf : 
buf : static void ath9k_set_tsf(struct ieee80211_hw *hw,
buf : 			  struct ieee80211_vif *vif,
if *vif, 
buf : 			  u64 tsf)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 	ath9k_ps_wakeup(sc);
buf : 	ath9k_hw_settsf64(sc->sc_ah, tsf);
buf : 	ath9k_ps_restore(sc);
buf : 	mutex_unlock(&sc->mutex);
buf : }
buf : 
buf : static void ath9k_reset_tsf(struct ieee80211_hw *hw, struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	ath9k_hw_reset_tsf(sc->sc_ah);
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : }
buf : 
buf : static int ath9k_ampdu_action(struct ieee80211_hw *hw,
buf : 			      struct ieee80211_vif *vif,
if *vif, 
buf : 			      enum ieee80211_ampdu_mlme_action action,
buf : 			      struct ieee80211_sta *sta,
buf : 			      u16 tid, u16 *ssn, u8 buf_size)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	bool flush = false;
buf : 	int ret = 0;
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 
buf : 	switch (action) {
buf : 	case IEEE80211_AMPDU_RX_START:
buf : 		break;
buf : 	case IEEE80211_AMPDU_RX_STOP:
buf : 		break;
buf : 	case IEEE80211_AMPDU_TX_START:
buf : 		ath9k_ps_wakeup(sc);
buf : 		ret = ath_tx_aggr_start(sc, sta, tid, ssn);
buf : 		if (!ret)
if (!ret) 
buf : 			ieee80211_start_tx_ba_cb_irqsafe(vif, sta->addr, tid);
buf : 		ath9k_ps_restore(sc);
buf : 		break;
buf : 	case IEEE80211_AMPDU_TX_STOP_FLUSH:
buf : 	case IEEE80211_AMPDU_TX_STOP_FLUSH_CONT:
buf : 		flush = true;
buf : 	case IEEE80211_AMPDU_TX_STOP_CONT:
buf : 		ath9k_ps_wakeup(sc);
buf : 		ath_tx_aggr_stop(sc, sta, tid);
buf : 		if (!flush)
if (!flush) 
buf : 			ieee80211_stop_tx_ba_cb_irqsafe(vif, sta->addr, tid);
buf : 		ath9k_ps_restore(sc);
buf : 		break;
buf : 	case IEEE80211_AMPDU_TX_OPERATIONAL:
buf : 		ath9k_ps_wakeup(sc);
buf : 		ath_tx_aggr_resume(sc, sta, tid);
buf : 		ath9k_ps_restore(sc);
buf : 		break;
buf : 	default:
buf : 		ath_err(ath9k_hw_common(sc->sc_ah), "Unknown AMPDU action\n");
buf : 	}
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int ath9k_get_survey(struct ieee80211_hw *hw, int idx,
buf : 			     struct survey_info *survey)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	struct ieee80211_supported_band *sband;
buf : 	struct ieee80211_channel *chan;
buf : 	int pos;
buf : 
buf : 	if (config_enabled(CONFIG_ATH9K_TX99))
if (config_enabled(CONFIG_ATH9K_TX99)) 
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	spin_lock_bh(&common->cc_lock);
buf : 	if (idx == 0)
if (idx == 0) 
buf : 		ath_update_survey_stats(sc);
buf : 
buf : 	sband = hw->wiphy->bands[IEEE80211_BAND_2GHZ];
buf : 	if (sband && idx >= sband->n_channels) {
if (sband && idx >= sband->n_channels) { 
buf : 		idx -= sband->n_channels;
buf : 		sband = NULL;
buf : 	}
buf : 
buf : 	if (!sband)
if (!sband) 
buf : 		sband = hw->wiphy->bands[IEEE80211_BAND_5GHZ];
buf : 
buf : 	if (!sband || idx >= sband->n_channels) {
if (!sband || idx >= sband->n_channels) { 
buf : 		spin_unlock_bh(&common->cc_lock);
buf : 		return -ENOENT;
buf : 	}
buf : 
buf : 	chan = &sband->channels[idx];
buf : 	pos = chan->hw_value;
buf : 	memcpy(survey, &sc->survey[pos], sizeof(*survey));
buf : 	survey->channel = chan;
buf : 	spin_unlock_bh(&common->cc_lock);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void ath9k_set_coverage_class(struct ieee80211_hw *hw, u8 coverage_class)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 
buf : 	if (config_enabled(CONFIG_ATH9K_TX99))
if (config_enabled(CONFIG_ATH9K_TX99)) 
buf : 		return;
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 	ah->coverage_class = coverage_class;
buf : 
buf : 	ath9k_ps_wakeup(sc);
buf : 	ath9k_hw_init_global_settings(ah);
buf : 	ath9k_ps_restore(sc);
buf : 
buf : 	mutex_unlock(&sc->mutex);
buf : }
buf : 
buf : static bool ath9k_has_tx_pending(struct ath_softc *sc)
buf : {
buf : 	int i, npend = 0;
buf : 
buf : 	for (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {
for (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) { 
buf : 		if (!ATH_TXQ_SETUP(sc, i))
buf : 			continue;
buf : 
buf : 		if (!sc->tx.txq[i].axq_depth)
if (!sc->tx.txq[i].axq_depth) 
buf : 			continue;
buf : 
buf : 		npend = ath9k_has_pending_frames(sc, &sc->tx.txq[i]);
buf : 		if (npend)
if (npend) 
buf : 			break;
buf : 	}
buf : 
buf : 	return !!npend;
buf : }
buf : 
buf : static void ath9k_flush(struct ieee80211_hw *hw, struct ieee80211_vif *vif,
if *vif, 
buf : 			u32 queues, bool drop)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath_common *common = ath9k_hw_common(ah);
buf : 	int timeout = HZ / 5; /* 200 ms */
buf : 	bool drain_txq;
buf : 
buf : 	mutex_lock(&sc->mutex);
buf : 	cancel_delayed_work_sync(&sc->tx_complete_work);
buf : 
buf : 	if (ah->ah_flags & AH_UNPLUGGED) {
if (ah->ah_flags & AH_UNPLUGGED) { 
buf : 		ath_dbg(common, ANY, "Device has been unplugged!\n");
buf : 		mutex_unlock(&sc->mutex);
buf : 		return;
buf : 	}
buf : 
buf : 	if (test_bit(ATH_OP_INVALID, &common->op_flags)) {
if (test_bit(ATH_OP_INVALID, &common->op_flags)) { 
buf : 		ath_dbg(common, ANY, "Device not present\n");
buf : 		mutex_unlock(&sc->mutex);
buf : 		return;
buf : 	}
buf : 
buf : 	if (wait_event_timeout(sc->tx_wait, !ath9k_has_tx_pending(sc),
if (wait_event_timeout(sc->tx_wait, !ath9k_has_tx_pending(sc), 
buf : 			       timeout) > 0)
buf : 		drop = false;
buf : 
buf : 	if (drop) {
if (drop) { 
buf : 		ath9k_ps_wakeup(sc);
buf : 		spin_lock_bh(&sc->sc_pcu_lock);
buf : 		drain_txq = ath_drain_all_txq(sc);
buf : 		spin_unlock_bh(&sc->sc_pcu_lock);
buf : 
buf : 		if (!drain_txq)
if (!drain_txq) 
buf : 			ath_reset(sc);
buf : 
buf : 		ath9k_ps_restore(sc);
buf : 		ieee80211_wake_queues(hw);
buf : 	}
buf : 
buf : 	ieee80211_queue_delayed_work(hw, &sc->tx_complete_work, 0);
buf : 	mutex_unlock(&sc->mutex);
buf : }
buf : 
buf : static bool ath9k_tx_frames_pending(struct ieee80211_hw *hw)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	int i;
buf : 
buf : 	for (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {
for (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) { 
buf : 		if (!ATH_TXQ_SETUP(sc, i))
buf : 			continue;
buf : 
buf : 		if (ath9k_has_pending_frames(sc, &sc->tx.txq[i]))
if (ath9k_has_pending_frames(sc, &sc->tx.txq[i])) 
buf : 			return true;
buf : 	}
buf : 	return false;
buf : }
buf : 
buf : static int ath9k_tx_last_beacon(struct ieee80211_hw *hw)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ieee80211_vif *vif;
if *vif; 
buf : 	struct ath_vif *avp;
buf : 	struct ath_buf *bf;
buf : 	struct ath_tx_status ts;
buf : 	bool edma = !!(ah->caps.hw_caps & ATH9K_HW_CAP_EDMA);
buf : 	int status;
buf : 
buf : 	vif = sc->beacon.bslot[0];
if = sc->beacon.bslot[0]; 
buf : 	if (!vif)
buf : 		return 0;
buf : 
buf : 	if (!vif->bss_conf.enable_beacon)
if (!vif->bss_conf.enable_beacon) 
buf : 		return 0;
buf : 
buf : 	avp = (void *)vif->drv_priv;
if->drv_priv; 
buf : 
buf : 	if (!sc->beacon.tx_processed && !edma) {
buf : 		tasklet_disable(&sc->bcon_tasklet);
buf : 
buf : 		bf = avp->av_bcbuf;
buf : 		if (!bf || !bf->bf_mpdu)
if (!bf || !bf->bf_mpdu) 
buf : 			goto skip;
buf : 
buf : 		status = ath9k_hw_txprocdesc(ah, bf->bf_desc, &ts);
buf : 		if (status == -EINPROGRESS)
if (status == -EINPROGRESS) 
buf : 			goto skip;
buf : 
buf : 		sc->beacon.tx_processed = true;
buf : 		sc->beacon.tx_last = !(ts.ts_status & ATH9K_TXERR_MASK);
buf : 
buf : skip:
buf : 		tasklet_enable(&sc->bcon_tasklet);
buf : 	}
buf : 
buf : 	return sc->beacon.tx_last;
buf : }
buf : 
buf : static int ath9k_get_stats(struct ieee80211_hw *hw,
buf : 			   struct ieee80211_low_level_stats *stats)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 	struct ath9k_mib_stats *mib_stats = &ah->ah_mibStats;
buf : 
buf : 	stats->dot11ACKFailureCount = mib_stats->ackrcv_bad;
buf : 	stats->dot11RTSFailureCount = mib_stats->rts_bad;
buf : 	stats->dot11FCSErrorCount = mib_stats->fcs_bad;
buf : 	stats->dot11RTSSuccessCount = mib_stats->rts_good;
buf : 	return 0;
buf : }
buf : 
buf : static u32 fill_chainmask(u32 cap, u32 new)
buf : {
buf : 	u32 filled = 0;
buf : 	int i;
buf : 
buf : 	for (i = 0; cap && new; i++, cap >>= 1) {
for (i = 0; cap && new; i++, cap >>= 1) { 
buf : 		if (!(cap & BIT(0)))
buf : 			continue;
buf : 
buf : 		if (new & BIT(0))
if (new & BIT(0)) 
buf : 			filled |= BIT(i);
buf : 
buf : 		new >>= 1;
buf : 	}
buf : 
buf : 	return filled;
buf : }
buf : 
buf : static bool validate_antenna_mask(struct ath_hw *ah, u32 val)
buf : {
buf : 	if (AR_SREV_9300_20_OR_LATER(ah))
if (AR_SREV_9300_20_OR_LATER(ah)) 
buf : 		return true;
buf : 
buf : 	switch (val & 0x7) {
buf : 	case 0x1:
buf : 	case 0x3:
buf : 	case 0x7:
buf : 		return true;
buf : 	case 0x2:
buf : 		return (ah->caps.rx_chainmask == 1);
buf : 	default:
buf : 		return false;
buf : 	}
buf : }
buf : 
buf : static int ath9k_set_antenna(struct ieee80211_hw *hw, u32 tx_ant, u32 rx_ant)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_hw *ah = sc->sc_ah;
buf : 
buf : 	if (ah->caps.rx_chainmask != 1)
if (ah->caps.rx_chainmask != 1) 
buf : 		rx_ant |= tx_ant;
buf : 
buf : 	if (!validate_antenna_mask(ah, rx_ant) || !tx_ant)
if (!validate_antenna_mask(ah, rx_ant) || !tx_ant) 
buf : 		return -EINVAL;
buf : 
buf : 	sc->ant_rx = rx_ant;
buf : 	sc->ant_tx = tx_ant;
buf : 
buf : 	if (ah->caps.rx_chainmask == 1)
if (ah->caps.rx_chainmask == 1) 
buf : 		return 0;
buf : 
buf : 	/* AR9100 runs into calibration issues if not all rx chains are enabled */
if not all rx chains are enabled */ 
buf : 	if (AR_SREV_9100(ah))
buf : 		ah->rxchainmask = 0x7;
buf : 	else
buf : 		ah->rxchainmask = fill_chainmask(ah->caps.rx_chainmask, rx_ant);
buf : 
buf : 	ah->txchainmask = fill_chainmask(ah->caps.tx_chainmask, tx_ant);
buf : 	ath9k_cmn_reload_chainmask(ah);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int ath9k_get_antenna(struct ieee80211_hw *hw, u32 *tx_ant, u32 *rx_ant)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 
buf : 	*tx_ant = sc->ant_tx;
buf : 	*rx_ant = sc->ant_rx;
buf : 	return 0;
buf : }
buf : 
buf : static void ath9k_sw_scan_start(struct ieee80211_hw *hw)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	set_bit(ATH_OP_SCANNING, &common->op_flags);
buf : }
buf : 
buf : static void ath9k_sw_scan_complete(struct ieee80211_hw *hw)
buf : {
buf : 	struct ath_softc *sc = hw->priv;
buf : 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
buf : 	clear_bit(ATH_OP_SCANNING, &common->op_flags);
buf : }
buf : 
buf : struct ieee80211_ops ath9k_ops = {
buf : 	.tx 		    = ath9k_tx,
buf : 	.start 		    = ath9k_start,
buf : 	.stop 		    = ath9k_stop,
buf : 	.add_interface 	    = ath9k_add_interface,
buf : 	.change_interface   = ath9k_change_interface,
buf : 	.remove_interface   = ath9k_remove_interface,
buf : 	.config 	    = ath9k_config,
buf : 	.configure_filter   = ath9k_configure_filter,
buf : 	.sta_add	    = ath9k_sta_add,
buf : 	.sta_remove	    = ath9k_sta_remove,
buf : 	.sta_notify         = ath9k_sta_notify,
ify         = ath9k_sta_notify, 
buf : 	.conf_tx 	    = ath9k_conf_tx,
buf : 	.bss_info_changed   = ath9k_bss_info_changed,
buf : 	.set_key            = ath9k_set_key,
buf : 	.get_tsf 	    = ath9k_get_tsf,
buf : 	.set_tsf 	    = ath9k_set_tsf,
buf : 	.reset_tsf 	    = ath9k_reset_tsf,
buf : 	.ampdu_action       = ath9k_ampdu_action,
buf : 	.get_survey	    = ath9k_get_survey,
buf : 	.rfkill_poll        = ath9k_rfkill_poll_state,
buf : 	.set_coverage_class = ath9k_set_coverage_class,
buf : 	.flush		    = ath9k_flush,
buf : 	.tx_frames_pending  = ath9k_tx_frames_pending,
buf : 	.tx_last_beacon     = ath9k_tx_last_beacon,
buf : 	.release_buffered_frames = ath9k_release_buffered_frames,
buf : 	.get_stats	    = ath9k_get_stats,
buf : 	.set_antenna	    = ath9k_set_antenna,
buf : 	.get_antenna	    = ath9k_get_antenna,
buf : 
buf : #ifdef CONFIG_ATH9K_WOW
ifdef CONFIG_ATH9K_WOW 
buf : 	.suspend	    = ath9k_suspend,
buf : 	.resume		    = ath9k_resume,
buf : 	.set_wakeup	    = ath9k_set_wakeup,
buf : #endif
if 
buf : 
buf : #ifdef CONFIG_ATH9K_DEBUGFS
buf : 	.get_et_sset_count  = ath9k_get_et_sset_count,
buf : 	.get_et_stats       = ath9k_get_et_stats,
buf : 	.get_et_strings     = ath9k_get_et_strings,
buf : #endif
if 
buf : 
buf : #if defined(CONFIG_MAC80211_DEBUGFS) && defined(CONFIG_ATH9K_STATION_STATISTICS)
buf : 	.sta_add_debugfs    = ath9k_sta_add_debugfs,
buf : #endif
if 
buf : 	.sw_scan_start	    = ath9k_sw_scan_start,
buf : 	.sw_scan_complete   = ath9k_sw_scan_complete,
buf : };
file : ./test/kernel/drivers/net/wireless/ath/ath6kl/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2004-2011 Atheros Communications Inc.
buf :  * Copyright (c) 2011-2012 Qualcomm Atheros, Inc.
buf :  *
buf :  * Permission to use, copy, modify, and/or distribute this software for any
ify, and/or distribute this software for any 
buf :  * purpose with or without fee is hereby granted, provided that the above
buf :  * copyright notice and this permission notice appear in all copies.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
buf :  * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
buf :  * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
buf :  * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
buf :  * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
buf :  * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
buf :  * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
buf :  */
buf : 
buf : #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
buf : 
buf : #include "core.h"
buf : #include "hif-ops.h"
if-ops.h" 
buf : #include "cfg80211.h"
buf : #include "target.h"
buf : #include "debug.h"
buf : 
buf : struct ath6kl_sta *ath6kl_find_sta(struct ath6kl_vif *vif, u8 *node_addr)
if *vif, u8 *node_addr) 
buf : {
buf : 	struct ath6kl *ar = vif->ar;
buf : 	struct ath6kl_sta *conn = NULL;
buf : 	u8 i, max_conn;
buf : 
buf : 	if (is_zero_ether_addr(node_addr))
if (is_zero_ether_addr(node_addr)) 
buf : 		return NULL;
buf : 
buf : 	max_conn = (vif->nw_type == AP_NETWORK) ? AP_MAX_NUM_STA : 0;
if->nw_type == AP_NETWORK) ? AP_MAX_NUM_STA : 0; 
buf : 
buf : 	for (i = 0; i < max_conn; i++) {
for (i = 0; i < max_conn; i++) { 
buf : 		if (memcmp(node_addr, ar->sta_list[i].mac, ETH_ALEN) == 0) {
buf : 			conn = &ar->sta_list[i];
buf : 			break;
buf : 		}
buf : 	}
buf : 
buf : 	return conn;
buf : }
buf : 
buf : struct ath6kl_sta *ath6kl_find_sta_by_aid(struct ath6kl *ar, u8 aid)
buf : {
buf : 	struct ath6kl_sta *conn = NULL;
buf : 	u8 ctr;
buf : 
buf : 	for (ctr = 0; ctr < AP_MAX_NUM_STA; ctr++) {
for (ctr = 0; ctr < AP_MAX_NUM_STA; ctr++) { 
buf : 		if (ar->sta_list[ctr].aid == aid) {
buf : 			conn = &ar->sta_list[ctr];
buf : 			break;
buf : 		}
buf : 	}
buf : 	return conn;
buf : }
buf : 
buf : static void ath6kl_add_new_sta(struct ath6kl_vif *vif, u8 *mac, u16 aid,
if *vif, u8 *mac, u16 aid, 
buf : 			       u8 *wpaie, size_t ielen, u8 keymgmt,
buf : 			       u8 ucipher, u8 auth, u8 apsd_info)
buf : {
buf : 	struct ath6kl *ar = vif->ar;
if->ar; 
buf : 	struct ath6kl_sta *sta;
buf : 	u8 free_slot;
buf : 
buf : 	free_slot = aid - 1;
buf : 
buf : 	sta = &ar->sta_list[free_slot];
buf : 	memcpy(sta->mac, mac, ETH_ALEN);
buf : 	if (ielen <= ATH6KL_MAX_IE)
if (ielen <= ATH6KL_MAX_IE) 
buf : 		memcpy(sta->wpa_ie, wpaie, ielen);
buf : 	sta->aid = aid;
buf : 	sta->keymgmt = keymgmt;
buf : 	sta->ucipher = ucipher;
buf : 	sta->auth = auth;
buf : 	sta->apsd_info = apsd_info;
buf : 
buf : 	ar->sta_list_index = ar->sta_list_index | (1 << free_slot);
buf : 	ar->ap_stats.sta[free_slot].aid = cpu_to_le32(aid);
buf : 	aggr_conn_init(vif, vif->aggr_cntxt, sta->aggr_conn);
if, vif->aggr_cntxt, sta->aggr_conn); 
buf : }
buf : 
buf : static void ath6kl_sta_cleanup(struct ath6kl *ar, u8 i)
buf : {
buf : 	struct ath6kl_sta *sta = &ar->sta_list[i];
buf : 	struct ath6kl_mgmt_buff *entry, *tmp;
buf : 
buf : 	/* empty the queued pkts in the PS queue if any */
if any */ 
buf : 	spin_lock_bh(&sta->psq_lock);
buf : 	skb_queue_purge(&sta->psq);
buf : 	skb_queue_purge(&sta->apsdq);
buf : 
buf : 	if (sta->mgmt_psq_len != 0) {
if (sta->mgmt_psq_len != 0) { 
buf : 		list_for_each_entry_safe(entry, tmp, &sta->mgmt_psq, list) {
for_each_entry_safe(entry, tmp, &sta->mgmt_psq, list) { 
buf : 			kfree(entry);
buf : 		}
buf : 		INIT_LIST_HEAD(&sta->mgmt_psq);
buf : 		sta->mgmt_psq_len = 0;
buf : 	}
buf : 
buf : 	spin_unlock_bh(&sta->psq_lock);
buf : 
buf : 	memset(&ar->ap_stats.sta[sta->aid - 1], 0,
buf : 	       sizeof(struct wmi_per_sta_stat));
buf : 	memset(sta->mac, 0, ETH_ALEN);
buf : 	memset(sta->wpa_ie, 0, ATH6KL_MAX_IE);
buf : 	sta->aid = 0;
buf : 	sta->sta_flags = 0;
buf : 
buf : 	ar->sta_list_index = ar->sta_list_index & ~(1 << i);
buf : 	aggr_reset_state(sta->aggr_conn);
buf : }
buf : 
buf : static u8 ath6kl_remove_sta(struct ath6kl *ar, u8 *mac, u16 reason)
buf : {
buf : 	u8 i, removed = 0;
buf : 
buf : 	if (is_zero_ether_addr(mac))
if (is_zero_ether_addr(mac)) 
buf : 		return removed;
buf : 
buf : 	if (is_broadcast_ether_addr(mac)) {
if (is_broadcast_ether_addr(mac)) { 
buf : 		ath6kl_dbg(ATH6KL_DBG_TRC, "deleting all station\n");
buf : 
buf : 		for (i = 0; i < AP_MAX_NUM_STA; i++) {
for (i = 0; i < AP_MAX_NUM_STA; i++) { 
buf : 			if (!is_zero_ether_addr(ar->sta_list[i].mac)) {
buf : 				ath6kl_sta_cleanup(ar, i);
buf : 				removed = 1;
buf : 			}
buf : 		}
buf : 	} else {
buf : 		for (i = 0; i < AP_MAX_NUM_STA; i++) {
for (i = 0; i < AP_MAX_NUM_STA; i++) { 
buf : 			if (memcmp(ar->sta_list[i].mac, mac, ETH_ALEN) == 0) {
buf : 				ath6kl_dbg(ATH6KL_DBG_TRC,
buf : 					   "deleting station %pM aid=%d reason=%d\n",
buf : 					   mac, ar->sta_list[i].aid, reason);
buf : 				ath6kl_sta_cleanup(ar, i);
buf : 				removed = 1;
buf : 				break;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	return removed;
buf : }
buf : 
buf : enum htc_endpoint_id ath6kl_ac2_endpoint_id(void *devt, u8 ac)
buf : {
buf : 	struct ath6kl *ar = devt;
buf : 	return ar->ac2ep_map[ac];
buf : }
buf : 
buf : struct ath6kl_cookie *ath6kl_alloc_cookie(struct ath6kl *ar)
buf : {
buf : 	struct ath6kl_cookie *cookie;
buf : 
buf : 	cookie = ar->cookie_list;
buf : 	if (cookie != NULL) {
if (cookie != NULL) { 
buf : 		ar->cookie_list = cookie->arc_list_next;
buf : 		ar->cookie_count--;
buf : 	}
buf : 
buf : 	return cookie;
buf : }
buf : 
buf : void ath6kl_cookie_init(struct ath6kl *ar)
buf : {
buf : 	u32 i;
buf : 
buf : 	ar->cookie_list = NULL;
buf : 	ar->cookie_count = 0;
buf : 
buf : 	memset(ar->cookie_mem, 0, sizeof(ar->cookie_mem));
buf : 
buf : 	for (i = 0; i < MAX_COOKIE_NUM; i++)
for (i = 0; i < MAX_COOKIE_NUM; i++) 
buf : 		ath6kl_free_cookie(ar, &ar->cookie_mem[i]);
buf : }
buf : 
buf : void ath6kl_cookie_cleanup(struct ath6kl *ar)
buf : {
buf : 	ar->cookie_list = NULL;
buf : 	ar->cookie_count = 0;
buf : }
buf : 
buf : void ath6kl_free_cookie(struct ath6kl *ar, struct ath6kl_cookie *cookie)
buf : {
buf : 	/* Insert first */
buf : 
buf : 	if (!ar || !cookie)
if (!ar || !cookie) 
buf : 		return;
buf : 
buf : 	cookie->arc_list_next = ar->cookie_list;
buf : 	ar->cookie_list = cookie;
buf : 	ar->cookie_count++;
buf : }
buf : 
buf : /*
buf :  * Read from the hardware through its diagnostic window. No cooperation
buf :  * from the firmware is required for this.
for this. 
buf :  */
buf : int ath6kl_diag_read32(struct ath6kl *ar, u32 address, u32 *value)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = ath6kl_hif_diag_read32(ar, address, value);
if_diag_read32(ar, address, value); 
buf : 	if (ret) {
buf : 		ath6kl_warn("failed to read32 through diagnose window: %d\n",
buf : 			    ret);
buf : 		return ret;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * Write to the ATH6KL through its diagnostic window. No cooperation from
buf :  * the Target is required for this.
for this. 
buf :  */
buf : int ath6kl_diag_write32(struct ath6kl *ar, u32 address, __le32 value)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = ath6kl_hif_diag_write32(ar, address, value);
if_diag_write32(ar, address, value); 
buf : 
buf : 	if (ret) {
buf : 		ath6kl_err("failed to write 0x%x during diagnose window to 0x%d\n",
buf : 			   address, value);
buf : 		return ret;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int ath6kl_diag_read(struct ath6kl *ar, u32 address, void *data, u32 length)
buf : {
buf : 	u32 count, *buf = data;
buf : 	int ret;
buf : 
buf : 	if (WARN_ON(length % 4))
if (WARN_ON(length % 4)) 
buf : 		return -EINVAL;
buf : 
buf : 	for (count = 0; count < length / 4; count++, address += 4) {
for (count = 0; count < length / 4; count++, address += 4) { 
buf : 		ret = ath6kl_diag_read32(ar, address, &buf[count]);
buf : 		if (ret)
if (ret) 
buf : 			return ret;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int ath6kl_diag_write(struct ath6kl *ar, u32 address, void *data, u32 length)
buf : {
buf : 	u32 count;
buf : 	__le32 *buf = data;
buf : 	int ret;
buf : 
buf : 	if (WARN_ON(length % 4))
if (WARN_ON(length % 4)) 
buf : 		return -EINVAL;
buf : 
buf : 	for (count = 0; count < length / 4; count++, address += 4) {
for (count = 0; count < length / 4; count++, address += 4) { 
buf : 		ret = ath6kl_diag_write32(ar, address, buf[count]);
buf : 		if (ret)
if (ret) 
buf : 			return ret;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int ath6kl_read_fwlogs(struct ath6kl *ar)
buf : {
buf : 	struct ath6kl_dbglog_hdr debug_hdr;
buf : 	struct ath6kl_dbglog_buf debug_buf;
buf : 	u32 address, length, dropped, firstbuf, debug_hdr_addr;
buf : 	int ret, loop;
buf : 	u8 *buf;
buf : 
buf : 	buf = kmalloc(ATH6KL_FWLOG_PAYLOAD_SIZE, GFP_KERNEL);
buf : 	if (!buf)
if (!buf) 
buf : 		return -ENOMEM;
buf : 
buf : 	address = TARG_VTOP(ar->target_type,
buf : 			    ath6kl_get_hi_item_addr(ar,
buf : 						    HI_ITEM(hi_dbglog_hdr)));
buf : 
buf : 	ret = ath6kl_diag_read32(ar, address, &debug_hdr_addr);
buf : 	if (ret)
if (ret) 
buf : 		goto out;
buf : 
buf : 	/* Get the contents of the ring buffer */
buf : 	if (debug_hdr_addr == 0) {
if (debug_hdr_addr == 0) { 
buf : 		ath6kl_warn("Invalid address for debug_hdr_addr\n");
for debug_hdr_addr\n"); 
buf : 		ret = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	address = TARG_VTOP(ar->target_type, debug_hdr_addr);
buf : 	ret = ath6kl_diag_read(ar, address, &debug_hdr, sizeof(debug_hdr));
buf : 	if (ret)
if (ret) 
buf : 		goto out;
buf : 
buf : 	address = TARG_VTOP(ar->target_type,
buf : 			    le32_to_cpu(debug_hdr.dbuf_addr));
buf : 	firstbuf = address;
buf : 	dropped = le32_to_cpu(debug_hdr.dropped);
buf : 	ret = ath6kl_diag_read(ar, address, &debug_buf, sizeof(debug_buf));
buf : 	if (ret)
if (ret) 
buf : 		goto out;
buf : 
buf : 	loop = 100;
buf : 
buf : 	do {
buf : 		address = TARG_VTOP(ar->target_type,
buf : 				    le32_to_cpu(debug_buf.buffer_addr));
buf : 		length = le32_to_cpu(debug_buf.length);
buf : 
buf : 		if (length != 0 && (le32_to_cpu(debug_buf.length) <=
if (length != 0 && (le32_to_cpu(debug_buf.length) <= 
buf : 				    le32_to_cpu(debug_buf.bufsize))) {
buf : 			length = ALIGN(length, 4);
buf : 
buf : 			ret = ath6kl_diag_read(ar, address,
buf : 					       buf, length);
buf : 			if (ret)
if (ret) 
buf : 				goto out;
buf : 
buf : 			ath6kl_debug_fwlog_event(ar, buf, length);
buf : 		}
buf : 
buf : 		address = TARG_VTOP(ar->target_type,
buf : 				    le32_to_cpu(debug_buf.next));
buf : 		ret = ath6kl_diag_read(ar, address, &debug_buf,
buf : 				       sizeof(debug_buf));
buf : 		if (ret)
if (ret) 
buf : 			goto out;
buf : 
buf : 		loop--;
buf : 
buf : 		if (WARN_ON(loop == 0)) {
if (WARN_ON(loop == 0)) { 
buf : 			ret = -ETIMEDOUT;
buf : 			goto out;
buf : 		}
buf : 	} while (address != firstbuf);
while (address != firstbuf); 
buf : 
buf : out:
buf : 	kfree(buf);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void ath6kl_install_static_wep_keys(struct ath6kl_vif *vif)
if *vif) 
buf : {
buf : 	u8 index;
buf : 	u8 keyusage;
buf : 
buf : 	for (index = 0; index <= WMI_MAX_KEY_INDEX; index++) {
for (index = 0; index <= WMI_MAX_KEY_INDEX; index++) { 
buf : 		if (vif->wep_key_list[index].key_len) {
buf : 			keyusage = GROUP_USAGE;
buf : 			if (index == vif->def_txkey_index)
if (index == vif->def_txkey_index) 
buf : 				keyusage |= TX_USAGE;
buf : 
buf : 			ath6kl_wmi_addkey_cmd(vif->ar->wmi, vif->fw_vif_idx,
if->ar->wmi, vif->fw_vif_idx, 
buf : 					      index,
buf : 					      WEP_CRYPT,
buf : 					      keyusage,
buf : 					      vif->wep_key_list[index].key_len,
if->wep_key_list[index].key_len, 
buf : 					      NULL, 0,
buf : 					      vif->wep_key_list[index].key,
if->wep_key_list[index].key, 
buf : 					      KEY_OP_INIT_VAL, NULL,
buf : 					      NO_SYNC_WMIFLAG);
buf : 		}
buf : 	}
buf : }
buf : 
buf : void ath6kl_connect_ap_mode_bss(struct ath6kl_vif *vif, u16 channel)
if *vif, u16 channel) 
buf : {
buf : 	struct ath6kl *ar = vif->ar;
buf : 	struct ath6kl_req_key *ik;
buf : 	int res;
buf : 	u8 key_rsc[ATH6KL_KEY_SEQ_LEN];
buf : 
buf : 	ik = &ar->ap_mode_bkey;
buf : 
buf : 	ath6kl_dbg(ATH6KL_DBG_WLAN_CFG, "AP mode started on %u MHz\n", channel);
buf : 
buf : 	switch (vif->auth_mode) {
if->auth_mode) { 
buf : 	case NONE_AUTH:
buf : 		if (vif->prwise_crypto == WEP_CRYPT)
if (vif->prwise_crypto == WEP_CRYPT) 
buf : 			ath6kl_install_static_wep_keys(vif);
buf : 		if (!ik->valid || ik->key_type != WAPI_CRYPT)
if (!ik->valid || ik->key_type != WAPI_CRYPT) 
buf : 			break;
buf : 		/* for WAPI, we need to set the delayed group key, continue: */
for WAPI, we need to set the delayed group key, continue: */ 
buf : 	case WPA_PSK_AUTH:
buf : 	case WPA2_PSK_AUTH:
buf : 	case (WPA_PSK_AUTH | WPA2_PSK_AUTH):
buf : 		if (!ik->valid)
if (!ik->valid) 
buf : 			break;
buf : 
buf : 		ath6kl_dbg(ATH6KL_DBG_WLAN_CFG,
buf : 			   "Delayed addkey for the initial group key for AP mode\n");
for the initial group key for AP mode\n"); 
buf : 		memset(key_rsc, 0, sizeof(key_rsc));
buf : 		res = ath6kl_wmi_addkey_cmd(
buf : 			ar->wmi, vif->fw_vif_idx, ik->key_index, ik->key_type,
if->fw_vif_idx, ik->key_index, ik->key_type, 
buf : 			GROUP_USAGE, ik->key_len, key_rsc, ATH6KL_KEY_SEQ_LEN,
buf : 			ik->key,
buf : 			KEY_OP_INIT_VAL, NULL, SYNC_BOTH_WMIFLAG);
buf : 		if (res) {
if (res) { 
buf : 			ath6kl_dbg(ATH6KL_DBG_WLAN_CFG,
buf : 				   "Delayed addkey failed: %d\n", res);
buf : 		}
buf : 		break;
buf : 	}
buf : 
buf : 	if (ar->last_ch != channel)
if (ar->last_ch != channel) 
buf : 		/* we actually don't know the phymode, default to HT20 */
buf : 		ath6kl_cfg80211_ch_switch_notify(vif, channel, WMI_11G_HT20);
ify(vif, channel, WMI_11G_HT20); 
buf : 
buf : 	ath6kl_wmi_bssfilter_cmd(ar->wmi, vif->fw_vif_idx, NONE_BSS_FILTER, 0);
buf : 	set_bit(CONNECTED, &vif->flags);
if->flags); 
buf : 	netif_carrier_on(vif->ndev);
buf : }
buf : 
buf : void ath6kl_connect_ap_mode_sta(struct ath6kl_vif *vif, u16 aid, u8 *mac_addr,
if *vif, u16 aid, u8 *mac_addr, 
buf : 				u8 keymgmt, u8 ucipher, u8 auth,
buf : 				u8 assoc_req_len, u8 *assoc_info, u8 apsd_info)
buf : {
buf : 	u8 *ies = NULL, *wpa_ie = NULL, *pos;
buf : 	size_t ies_len = 0;
buf : 	struct station_info sinfo;
buf : 
buf : 	ath6kl_dbg(ATH6KL_DBG_TRC, "new station %pM aid=%d\n", mac_addr, aid);
buf : 
buf : 	if (assoc_req_len > sizeof(struct ieee80211_hdr_3addr)) {
if (assoc_req_len > sizeof(struct ieee80211_hdr_3addr)) { 
buf : 		struct ieee80211_mgmt *mgmt =
buf : 			(struct ieee80211_mgmt *) assoc_info;
buf : 		if (ieee80211_is_assoc_req(mgmt->frame_control) &&
if (ieee80211_is_assoc_req(mgmt->frame_control) && 
buf : 		    assoc_req_len >= sizeof(struct ieee80211_hdr_3addr) +
buf : 		    sizeof(mgmt->u.assoc_req)) {
buf : 			ies = mgmt->u.assoc_req.variable;
buf : 			ies_len = assoc_info + assoc_req_len - ies;
buf : 		} else if (ieee80211_is_reassoc_req(mgmt->frame_control) &&
if (ieee80211_is_reassoc_req(mgmt->frame_control) && 
buf : 			   assoc_req_len >= sizeof(struct ieee80211_hdr_3addr)
buf : 			   + sizeof(mgmt->u.reassoc_req)) {
buf : 			ies = mgmt->u.reassoc_req.variable;
buf : 			ies_len = assoc_info + assoc_req_len - ies;
buf : 		}
buf : 	}
buf : 
buf : 	pos = ies;
buf : 	while (pos && pos + 1 < ies + ies_len) {
while (pos && pos + 1 < ies + ies_len) { 
buf : 		if (pos + 2 + pos[1] > ies + ies_len)
buf : 			break;
buf : 		if (pos[0] == WLAN_EID_RSN)
if (pos[0] == WLAN_EID_RSN) 
buf : 			wpa_ie = pos; /* RSN IE */
buf : 		else if (pos[0] == WLAN_EID_VENDOR_SPECIFIC &&
if (pos[0] == WLAN_EID_VENDOR_SPECIFIC && 
buf : 			 pos[1] >= 4 &&
buf : 			 pos[2] == 0x00 && pos[3] == 0x50 && pos[4] == 0xf2) {
buf : 			if (pos[5] == 0x01)
if (pos[5] == 0x01) 
buf : 				wpa_ie = pos; /* WPA IE */
buf : 			else if (pos[5] == 0x04) {
if (pos[5] == 0x04) { 
buf : 				wpa_ie = pos; /* WPS IE */
buf : 				break; /* overrides WPA/RSN IE */
buf : 			}
buf : 		} else if (pos[0] == 0x44 && wpa_ie == NULL) {
if (pos[0] == 0x44 && wpa_ie == NULL) { 
buf : 			/*
buf : 			 * Note: WAPI Parameter Set IE re-uses Element ID that
buf : 			 * was officially allocated for BSS AC Access Delay. As
for BSS AC Access Delay. As 
buf : 			 * such, we need to be a bit more careful on when
buf : 			 * parsing the frame. However, BSS AC Access Delay
buf : 			 * element is not supposed to be included in
buf : 			 * (Re)Association Request frames, so this should not
buf : 			 * cause problems.
buf : 			 */
buf : 			wpa_ie = pos; /* WAPI IE */
buf : 			break;
buf : 		}
buf : 		pos += 2 + pos[1];
buf : 	}
buf : 
buf : 	ath6kl_add_new_sta(vif, mac_addr, aid, wpa_ie,
if, mac_addr, aid, wpa_ie, 
buf : 			   wpa_ie ? 2 + wpa_ie[1] : 0,
buf : 			   keymgmt, ucipher, auth, apsd_info);
buf : 
buf : 	/* send event to application */
buf : 	memset(&sinfo, 0, sizeof(sinfo));
buf : 
buf : 	/* TODO: sinfo.generation */
buf : 
buf : 	sinfo.assoc_req_ies = ies;
buf : 	sinfo.assoc_req_ies_len = ies_len;
buf : 	sinfo.filled |= STATION_INFO_ASSOC_REQ_IES;
buf : 
buf : 	cfg80211_new_sta(vif->ndev, mac_addr, &sinfo, GFP_KERNEL);
if->ndev, mac_addr, &sinfo, GFP_KERNEL); 
buf : 
buf : 	netif_wake_queue(vif->ndev);
buf : }
buf : 
buf : void disconnect_timer_handler(unsigned long ptr)
buf : {
buf : 	struct net_device *dev = (struct net_device *)ptr;
buf : 	struct ath6kl_vif *vif = netdev_priv(dev);
if *vif = netdev_priv(dev); 
buf : 
buf : 	ath6kl_init_profile_info(vif);
buf : 	ath6kl_disconnect(vif);
if); 
buf : }
buf : 
buf : void ath6kl_disconnect(struct ath6kl_vif *vif)
buf : {
buf : 	if (test_bit(CONNECTED, &vif->flags) ||
if (test_bit(CONNECTED, &vif->flags) || 
buf : 	    test_bit(CONNECT_PEND, &vif->flags)) {
buf : 		ath6kl_wmi_disconnect_cmd(vif->ar->wmi, vif->fw_vif_idx);
if->ar->wmi, vif->fw_vif_idx); 
buf : 		/*
buf : 		 * Disconnect command is issued, clear the connect pending
buf : 		 * flag. The connected flag will be cleared in
buf : 		 * disconnect event notification.
ification. 
buf : 		 */
buf : 		clear_bit(CONNECT_PEND, &vif->flags);
if->flags); 
buf : 	}
buf : }
buf : 
buf : /* WMI Event handlers */
buf : 
buf : void ath6kl_ready_event(void *devt, u8 *datap, u32 sw_ver, u32 abi_ver,
buf : 			enum wmi_phy_cap cap)
buf : {
buf : 	struct ath6kl *ar = devt;
buf : 
buf : 	memcpy(ar->mac_addr, datap, ETH_ALEN);
buf : 
buf : 	ath6kl_dbg(ATH6KL_DBG_BOOT,
buf : 		   "ready event mac addr %pM sw_ver 0x%x abi_ver 0x%x cap 0x%x\n",
buf : 		   ar->mac_addr, sw_ver, abi_ver, cap);
buf : 
buf : 	ar->version.wlan_ver = sw_ver;
buf : 	ar->version.abi_ver = abi_ver;
buf : 	ar->hw.cap = cap;
buf : 
buf : 	if (strlen(ar->wiphy->fw_version) == 0) {
if (strlen(ar->wiphy->fw_version) == 0) { 
buf : 		snprintf(ar->wiphy->fw_version,
buf : 			 sizeof(ar->wiphy->fw_version),
buf : 			 "%u.%u.%u.%u",
buf : 			 (ar->version.wlan_ver & 0xf0000000) >> 28,
buf : 			 (ar->version.wlan_ver & 0x0f000000) >> 24,
buf : 			 (ar->version.wlan_ver & 0x00ff0000) >> 16,
buf : 			 (ar->version.wlan_ver & 0x0000ffff));
buf : 	}
buf : 
buf : 	/* indicate to the waiting thread that the ready event was received */
buf : 	set_bit(WMI_READY, &ar->flag);
buf : 	wake_up(&ar->event_wq);
buf : }
buf : 
buf : void ath6kl_scan_complete_evt(struct ath6kl_vif *vif, int status)
if *vif, int status) 
buf : {
buf : 	struct ath6kl *ar = vif->ar;
buf : 	bool aborted = false;
buf : 
buf : 	if (status != WMI_SCAN_STATUS_SUCCESS)
if (status != WMI_SCAN_STATUS_SUCCESS) 
buf : 		aborted = true;
buf : 
buf : 	ath6kl_cfg80211_scan_complete_event(vif, aborted);
if, aborted); 
buf : 
buf : 	if (!ar->usr_bss_filter) {
buf : 		clear_bit(CLEAR_BSSFILTER_ON_BEACON, &vif->flags);
if->flags); 
buf : 		ath6kl_wmi_bssfilter_cmd(ar->wmi, vif->fw_vif_idx,
buf : 					 NONE_BSS_FILTER, 0);
buf : 	}
buf : 
buf : 	ath6kl_dbg(ATH6KL_DBG_WLAN_CFG, "scan complete: %d\n", status);
buf : }
buf : 
buf : static int ath6kl_commit_ch_switch(struct ath6kl_vif *vif, u16 channel)
if *vif, u16 channel) 
buf : {
buf : 	struct ath6kl *ar = vif->ar;
buf : 
buf : 	vif->profile.ch = cpu_to_le16(channel);
if->profile.ch = cpu_to_le16(channel); 
buf : 
buf : 	switch (vif->nw_type) {
buf : 	case AP_NETWORK:
buf : 		/*
buf : 		 * reconfigure any saved RSN IE capabilites in the beacon /
buf : 		 * probe response to stay in sync with the supplicant.
buf : 		 */
buf : 		if (vif->rsn_capab &&
if (vif->rsn_capab && 
buf : 		    test_bit(ATH6KL_FW_CAPABILITY_RSN_CAP_OVERRIDE,
buf : 			     ar->fw_capabilities))
buf : 			ath6kl_wmi_set_ie_cmd(ar->wmi, vif->fw_vif_idx,
if->fw_vif_idx, 
buf : 					      WLAN_EID_RSN, WMI_RSN_IE_CAPB,
buf : 					      (const u8 *) &vif->rsn_capab,
if->rsn_capab, 
buf : 					      sizeof(vif->rsn_capab));
buf : 
buf : 		return ath6kl_wmi_ap_profile_commit(ar->wmi, vif->fw_vif_idx,
if->fw_vif_idx, 
buf : 						    &vif->profile);
buf : 	default:
buf : 		ath6kl_err("won't switch channels nw_type=%d\n", vif->nw_type);
if->nw_type); 
buf : 		return -ENOTSUPP;
buf : 	}
buf : }
buf : 
buf : static void ath6kl_check_ch_switch(struct ath6kl *ar, u16 channel)
buf : {
buf : 	struct ath6kl_vif *vif;
if *vif; 
buf : 	int res = 0;
buf : 
buf : 	if (!ar->want_ch_switch)
if (!ar->want_ch_switch) 
buf : 		return;
buf : 
buf : 	spin_lock_bh(&ar->list_lock);
buf : 	list_for_each_entry(vif, &ar->vif_list, list) {
if, &ar->vif_list, list) { 
buf : 		if (ar->want_ch_switch & (1 << vif->fw_vif_idx))
buf : 			res = ath6kl_commit_ch_switch(vif, channel);
if, channel); 
buf : 
buf : 		/* if channel switch failed, oh well we tried */
buf : 		ar->want_ch_switch &= ~(1 << vif->fw_vif_idx);
if->fw_vif_idx); 
buf : 
buf : 		if (res)
buf : 			ath6kl_err("channel switch failed nw_type %d res %d\n",
buf : 				   vif->nw_type, res);
if->nw_type, res); 
buf : 	}
buf : 	spin_unlock_bh(&ar->list_lock);
buf : }
buf : 
buf : void ath6kl_connect_event(struct ath6kl_vif *vif, u16 channel, u8 *bssid,
if *vif, u16 channel, u8 *bssid, 
buf : 			  u16 listen_int, u16 beacon_int,
buf : 			  enum network_type net_type, u8 beacon_ie_len,
buf : 			  u8 assoc_req_len, u8 assoc_resp_len,
buf : 			  u8 *assoc_info)
buf : {
buf : 	struct ath6kl *ar = vif->ar;
if->ar; 
buf : 
buf : 	ath6kl_cfg80211_connect_event(vif, channel, bssid,
buf : 				      listen_int, beacon_int,
buf : 				      net_type, beacon_ie_len,
buf : 				      assoc_req_len, assoc_resp_len,
buf : 				      assoc_info);
buf : 
buf : 	memcpy(vif->bssid, bssid, sizeof(vif->bssid));
if->bssid, bssid, sizeof(vif->bssid)); 
buf : 	vif->bss_ch = channel;
buf : 
buf : 	if ((vif->nw_type == INFRA_NETWORK)) {
if ((vif->nw_type == INFRA_NETWORK)) { 
buf : 		ath6kl_wmi_listeninterval_cmd(ar->wmi, vif->fw_vif_idx,
buf : 					      vif->listen_intvl_t, 0);
if->listen_intvl_t, 0); 
buf : 		ath6kl_check_ch_switch(ar, channel);
buf : 	}
buf : 
buf : 	netif_wake_queue(vif->ndev);
if_wake_queue(vif->ndev); 
buf : 
buf : 	/* Update connect & link status atomically */
buf : 	spin_lock_bh(&vif->if_lock);
if->if_lock); 
buf : 	set_bit(CONNECTED, &vif->flags);
buf : 	clear_bit(CONNECT_PEND, &vif->flags);
if->flags); 
buf : 	netif_carrier_on(vif->ndev);
buf : 	spin_unlock_bh(&vif->if_lock);
if->if_lock); 
buf : 
buf : 	aggr_reset_state(vif->aggr_cntxt->aggr_conn);
buf : 	vif->reconnect_flag = 0;
if->reconnect_flag = 0; 
buf : 
buf : 	if ((vif->nw_type == ADHOC_NETWORK) && ar->ibss_ps_enable) {
buf : 		memset(ar->node_map, 0, sizeof(ar->node_map));
buf : 		ar->node_num = 0;
buf : 		ar->next_ep_id = ENDPOINT_2;
buf : 	}
buf : 
buf : 	if (!ar->usr_bss_filter) {
if (!ar->usr_bss_filter) { 
buf : 		set_bit(CLEAR_BSSFILTER_ON_BEACON, &vif->flags);
buf : 		ath6kl_wmi_bssfilter_cmd(ar->wmi, vif->fw_vif_idx,
if->fw_vif_idx, 
buf : 					 CURRENT_BSS_FILTER, 0);
buf : 	}
buf : }
buf : 
buf : void ath6kl_tkip_micerr_event(struct ath6kl_vif *vif, u8 keyid, bool ismcast)
if *vif, u8 keyid, bool ismcast) 
buf : {
buf : 	struct ath6kl_sta *sta;
buf : 	struct ath6kl *ar = vif->ar;
if->ar; 
buf : 	u8 tsc[6];
buf : 
buf : 	/*
buf : 	 * For AP case, keyid will have aid of STA which sent pkt with
buf : 	 * MIC error. Use this aid to get MAC & send it to hostapd.
buf : 	 */
buf : 	if (vif->nw_type == AP_NETWORK) {
if (vif->nw_type == AP_NETWORK) { 
buf : 		sta = ath6kl_find_sta_by_aid(ar, (keyid >> 2));
buf : 		if (!sta)
if (!sta) 
buf : 			return;
buf : 
buf : 		ath6kl_dbg(ATH6KL_DBG_TRC,
buf : 			   "ap tkip mic error received from aid=%d\n", keyid);
buf : 
buf : 		memset(tsc, 0, sizeof(tsc)); /* FIX: get correct TSC */
buf : 		cfg80211_michael_mic_failure(vif->ndev, sta->mac,
if->ndev, sta->mac, 
buf : 					     NL80211_KEYTYPE_PAIRWISE, keyid,
buf : 					     tsc, GFP_KERNEL);
buf : 	} else {
buf : 		ath6kl_cfg80211_tkip_micerr_event(vif, keyid, ismcast);
if, keyid, ismcast); 
buf : 	}
buf : }
buf : 
buf : static void ath6kl_update_target_stats(struct ath6kl_vif *vif, u8 *ptr, u32 len)
buf : {
buf : 	struct wmi_target_stats *tgt_stats =
buf : 		(struct wmi_target_stats *) ptr;
buf : 	struct ath6kl *ar = vif->ar;
if->ar; 
buf : 	struct target_stats *stats = &vif->target_stats;
buf : 	struct tkip_ccmp_stats *ccmp_stats;
buf : 	u8 ac;
buf : 
buf : 	if (len < sizeof(*tgt_stats))
if (len < sizeof(*tgt_stats)) 
buf : 		return;
buf : 
buf : 	ath6kl_dbg(ATH6KL_DBG_TRC, "updating target stats\n");
buf : 
buf : 	stats->tx_pkt += le32_to_cpu(tgt_stats->stats.tx.pkt);
buf : 	stats->tx_byte += le32_to_cpu(tgt_stats->stats.tx.byte);
buf : 	stats->tx_ucast_pkt += le32_to_cpu(tgt_stats->stats.tx.ucast_pkt);
buf : 	stats->tx_ucast_byte += le32_to_cpu(tgt_stats->stats.tx.ucast_byte);
buf : 	stats->tx_mcast_pkt += le32_to_cpu(tgt_stats->stats.tx.mcast_pkt);
buf : 	stats->tx_mcast_byte += le32_to_cpu(tgt_stats->stats.tx.mcast_byte);
buf : 	stats->tx_bcast_pkt  += le32_to_cpu(tgt_stats->stats.tx.bcast_pkt);
buf : 	stats->tx_bcast_byte += le32_to_cpu(tgt_stats->stats.tx.bcast_byte);
buf : 	stats->tx_rts_success_cnt +=
buf : 		le32_to_cpu(tgt_stats->stats.tx.rts_success_cnt);
buf : 
buf : 	for (ac = 0; ac < WMM_NUM_AC; ac++)
for (ac = 0; ac < WMM_NUM_AC; ac++) 
buf : 		stats->tx_pkt_per_ac[ac] +=
buf : 			le32_to_cpu(tgt_stats->stats.tx.pkt_per_ac[ac]);
buf : 
buf : 	stats->tx_err += le32_to_cpu(tgt_stats->stats.tx.err);
buf : 	stats->tx_fail_cnt += le32_to_cpu(tgt_stats->stats.tx.fail_cnt);
buf : 	stats->tx_retry_cnt += le32_to_cpu(tgt_stats->stats.tx.retry_cnt);
buf : 	stats->tx_mult_retry_cnt +=
buf : 		le32_to_cpu(tgt_stats->stats.tx.mult_retry_cnt);
buf : 	stats->tx_rts_fail_cnt +=
buf : 		le32_to_cpu(tgt_stats->stats.tx.rts_fail_cnt);
buf : 	stats->tx_ucast_rate =
buf : 	    ath6kl_wmi_get_rate(a_sle32_to_cpu(tgt_stats->stats.tx.ucast_rate));
buf : 
buf : 	stats->rx_pkt += le32_to_cpu(tgt_stats->stats.rx.pkt);
buf : 	stats->rx_byte += le32_to_cpu(tgt_stats->stats.rx.byte);
buf : 	stats->rx_ucast_pkt += le32_to_cpu(tgt_stats->stats.rx.ucast_pkt);
buf : 	stats->rx_ucast_byte += le32_to_cpu(tgt_stats->stats.rx.ucast_byte);
buf : 	stats->rx_mcast_pkt += le32_to_cpu(tgt_stats->stats.rx.mcast_pkt);
buf : 	stats->rx_mcast_byte += le32_to_cpu(tgt_stats->stats.rx.mcast_byte);
buf : 	stats->rx_bcast_pkt += le32_to_cpu(tgt_stats->stats.rx.bcast_pkt);
buf : 	stats->rx_bcast_byte += le32_to_cpu(tgt_stats->stats.rx.bcast_byte);
buf : 	stats->rx_frgment_pkt += le32_to_cpu(tgt_stats->stats.rx.frgment_pkt);
buf : 	stats->rx_err += le32_to_cpu(tgt_stats->stats.rx.err);
buf : 	stats->rx_crc_err += le32_to_cpu(tgt_stats->stats.rx.crc_err);
buf : 	stats->rx_key_cache_miss +=
buf : 		le32_to_cpu(tgt_stats->stats.rx.key_cache_miss);
buf : 	stats->rx_decrypt_err += le32_to_cpu(tgt_stats->stats.rx.decrypt_err);
buf : 	stats->rx_dupl_frame += le32_to_cpu(tgt_stats->stats.rx.dupl_frame);
buf : 	stats->rx_ucast_rate =
buf : 	    ath6kl_wmi_get_rate(a_sle32_to_cpu(tgt_stats->stats.rx.ucast_rate));
buf : 
buf : 	ccmp_stats = &tgt_stats->stats.tkip_ccmp_stats;
buf : 
buf : 	stats->tkip_local_mic_fail +=
buf : 		le32_to_cpu(ccmp_stats->tkip_local_mic_fail);
buf : 	stats->tkip_cnter_measures_invoked +=
buf : 		le32_to_cpu(ccmp_stats->tkip_cnter_measures_invoked);
buf : 	stats->tkip_fmt_err += le32_to_cpu(ccmp_stats->tkip_fmt_err);
buf : 
buf : 	stats->ccmp_fmt_err += le32_to_cpu(ccmp_stats->ccmp_fmt_err);
buf : 	stats->ccmp_replays += le32_to_cpu(ccmp_stats->ccmp_replays);
buf : 
buf : 	stats->pwr_save_fail_cnt +=
buf : 		le32_to_cpu(tgt_stats->pm_stats.pwr_save_failure_cnt);
buf : 	stats->noise_floor_calib =
buf : 		a_sle32_to_cpu(tgt_stats->noise_floor_calib);
buf : 
buf : 	stats->cs_bmiss_cnt +=
buf : 		le32_to_cpu(tgt_stats->cserv_stats.cs_bmiss_cnt);
buf : 	stats->cs_low_rssi_cnt +=
buf : 		le32_to_cpu(tgt_stats->cserv_stats.cs_low_rssi_cnt);
buf : 	stats->cs_connect_cnt +=
buf : 		le16_to_cpu(tgt_stats->cserv_stats.cs_connect_cnt);
buf : 	stats->cs_discon_cnt +=
buf : 		le16_to_cpu(tgt_stats->cserv_stats.cs_discon_cnt);
buf : 
buf : 	stats->cs_ave_beacon_rssi =
buf : 		a_sle16_to_cpu(tgt_stats->cserv_stats.cs_ave_beacon_rssi);
buf : 
buf : 	stats->cs_last_roam_msec =
buf : 		tgt_stats->cserv_stats.cs_last_roam_msec;
buf : 	stats->cs_snr = tgt_stats->cserv_stats.cs_snr;
buf : 	stats->cs_rssi = a_sle16_to_cpu(tgt_stats->cserv_stats.cs_rssi);
buf : 
buf : 	stats->lq_val = le32_to_cpu(tgt_stats->lq_val);
buf : 
buf : 	stats->wow_pkt_dropped +=
buf : 		le32_to_cpu(tgt_stats->wow_stats.wow_pkt_dropped);
buf : 	stats->wow_host_pkt_wakeups +=
buf : 		tgt_stats->wow_stats.wow_host_pkt_wakeups;
buf : 	stats->wow_host_evt_wakeups +=
buf : 		tgt_stats->wow_stats.wow_host_evt_wakeups;
buf : 	stats->wow_evt_discarded +=
buf : 		le16_to_cpu(tgt_stats->wow_stats.wow_evt_discarded);
buf : 
buf : 	stats->arp_received = le32_to_cpu(tgt_stats->arp_stats.arp_received);
buf : 	stats->arp_replied = le32_to_cpu(tgt_stats->arp_stats.arp_replied);
buf : 	stats->arp_matched = le32_to_cpu(tgt_stats->arp_stats.arp_matched);
buf : 
buf : 	if (test_bit(STATS_UPDATE_PEND, &vif->flags)) {
if (test_bit(STATS_UPDATE_PEND, &vif->flags)) { 
buf : 		clear_bit(STATS_UPDATE_PEND, &vif->flags);
buf : 		wake_up(&ar->event_wq);
buf : 	}
buf : }
buf : 
buf : static void ath6kl_add_le32(__le32 *var, __le32 val)
buf : {
buf : 	*var = cpu_to_le32(le32_to_cpu(*var) + le32_to_cpu(val));
buf : }
buf : 
buf : void ath6kl_tgt_stats_event(struct ath6kl_vif *vif, u8 *ptr, u32 len)
if *vif, u8 *ptr, u32 len) 
buf : {
buf : 	struct wmi_ap_mode_stat *p = (struct wmi_ap_mode_stat *) ptr;
buf : 	struct ath6kl *ar = vif->ar;
if->ar; 
buf : 	struct wmi_ap_mode_stat *ap = &ar->ap_stats;
buf : 	struct wmi_per_sta_stat *st_ap, *st_p;
buf : 	u8 ac;
buf : 
buf : 	if (vif->nw_type == AP_NETWORK) {
if (vif->nw_type == AP_NETWORK) { 
buf : 		if (len < sizeof(*p))
buf : 			return;
buf : 
buf : 		for (ac = 0; ac < AP_MAX_NUM_STA; ac++) {
for (ac = 0; ac < AP_MAX_NUM_STA; ac++) { 
buf : 			st_ap = &ap->sta[ac];
buf : 			st_p = &p->sta[ac];
buf : 
buf : 			ath6kl_add_le32(&st_ap->tx_bytes, st_p->tx_bytes);
buf : 			ath6kl_add_le32(&st_ap->tx_pkts, st_p->tx_pkts);
buf : 			ath6kl_add_le32(&st_ap->tx_error, st_p->tx_error);
buf : 			ath6kl_add_le32(&st_ap->tx_discard, st_p->tx_discard);
buf : 			ath6kl_add_le32(&st_ap->rx_bytes, st_p->rx_bytes);
buf : 			ath6kl_add_le32(&st_ap->rx_pkts, st_p->rx_pkts);
buf : 			ath6kl_add_le32(&st_ap->rx_error, st_p->rx_error);
buf : 			ath6kl_add_le32(&st_ap->rx_discard, st_p->rx_discard);
buf : 		}
buf : 
buf : 	} else {
buf : 		ath6kl_update_target_stats(vif, ptr, len);
if, ptr, len); 
buf : 	}
buf : }
buf : 
buf : void ath6kl_wakeup_event(void *dev)
buf : {
buf : 	struct ath6kl *ar = (struct ath6kl *) dev;
buf : 
buf : 	wake_up(&ar->event_wq);
buf : }
buf : 
buf : void ath6kl_txpwr_rx_evt(void *devt, u8 tx_pwr)
buf : {
buf : 	struct ath6kl *ar = (struct ath6kl *) devt;
buf : 
buf : 	ar->tx_pwr = tx_pwr;
buf : 	wake_up(&ar->event_wq);
buf : }
buf : 
buf : void ath6kl_pspoll_event(struct ath6kl_vif *vif, u8 aid)
if *vif, u8 aid) 
buf : {
buf : 	struct ath6kl_sta *conn;
buf : 	struct sk_buff *skb;
buf : 	bool psq_empty = false;
buf : 	struct ath6kl *ar = vif->ar;
if->ar; 
buf : 	struct ath6kl_mgmt_buff *mgmt_buf;
buf : 
buf : 	conn = ath6kl_find_sta_by_aid(ar, aid);
buf : 
buf : 	if (!conn)
if (!conn) 
buf : 		return;
buf : 	/*
buf : 	 * Send out a packet queued on ps queue. When the ps queue
buf : 	 * becomes empty update the PVB for this station.
for this station. 
buf : 	 */
buf : 	spin_lock_bh(&conn->psq_lock);
buf : 	psq_empty  = skb_queue_empty(&conn->psq) && (conn->mgmt_psq_len == 0);
buf : 	spin_unlock_bh(&conn->psq_lock);
buf : 
buf : 	if (psq_empty)
if (psq_empty) 
buf : 		/* TODO: Send out a NULL data frame */
buf : 		return;
buf : 
buf : 	spin_lock_bh(&conn->psq_lock);
buf : 	if (conn->mgmt_psq_len > 0) {
if (conn->mgmt_psq_len > 0) { 
buf : 		mgmt_buf = list_first_entry(&conn->mgmt_psq,
buf : 					struct ath6kl_mgmt_buff, list);
buf : 		list_del(&mgmt_buf->list);
buf : 		conn->mgmt_psq_len--;
buf : 		spin_unlock_bh(&conn->psq_lock);
buf : 
buf : 		conn->sta_flags |= STA_PS_POLLED;
buf : 		ath6kl_wmi_send_mgmt_cmd(ar->wmi, vif->fw_vif_idx,
if->fw_vif_idx, 
buf : 					 mgmt_buf->id, mgmt_buf->freq,
buf : 					 mgmt_buf->wait, mgmt_buf->buf,
buf : 					 mgmt_buf->len, mgmt_buf->no_cck);
buf : 		conn->sta_flags &= ~STA_PS_POLLED;
buf : 		kfree(mgmt_buf);
buf : 	} else {
buf : 		skb = skb_dequeue(&conn->psq);
buf : 		spin_unlock_bh(&conn->psq_lock);
buf : 
buf : 		conn->sta_flags |= STA_PS_POLLED;
buf : 		ath6kl_data_tx(skb, vif->ndev);
if->ndev); 
buf : 		conn->sta_flags &= ~STA_PS_POLLED;
buf : 	}
buf : 
buf : 	spin_lock_bh(&conn->psq_lock);
buf : 	psq_empty  = skb_queue_empty(&conn->psq) && (conn->mgmt_psq_len == 0);
buf : 	spin_unlock_bh(&conn->psq_lock);
buf : 
buf : 	if (psq_empty)
if (psq_empty) 
buf : 		ath6kl_wmi_set_pvb_cmd(ar->wmi, vif->fw_vif_idx, conn->aid, 0);
buf : }
buf : 
buf : void ath6kl_dtimexpiry_event(struct ath6kl_vif *vif)
if *vif) 
buf : {
buf : 	bool mcastq_empty = false;
buf : 	struct sk_buff *skb;
buf : 	struct ath6kl *ar = vif->ar;
if->ar; 
buf : 
buf : 	/*
buf : 	 * If there are no associated STAs, ignore the DTIM expiry event.
buf : 	 * There can be potential race conditions where the last associated
buf : 	 * STA may disconnect & before the host could clear the 'Indicate
fore the host could clear the 'Indicate 
buf : 	 * DTIM' request to the firmware, the firmware would have just
buf : 	 * indicated a DTIM expiry event. The race is between 'clear DTIM
buf : 	 * expiry cmd' going from the host to the firmware & the DTIM
buf : 	 * expiry event happening from the firmware to the host.
buf : 	 */
buf : 	if (!ar->sta_list_index)
if (!ar->sta_list_index) 
buf : 		return;
buf : 
buf : 	spin_lock_bh(&ar->mcastpsq_lock);
buf : 	mcastq_empty = skb_queue_empty(&ar->mcastpsq);
buf : 	spin_unlock_bh(&ar->mcastpsq_lock);
buf : 
buf : 	if (mcastq_empty)
if (mcastq_empty) 
buf : 		return;
buf : 
buf : 	/* set the STA flag to dtim_expired for the frame to go out */
for the frame to go out */ 
buf : 	set_bit(DTIM_EXPIRED, &vif->flags);
buf : 
buf : 	spin_lock_bh(&ar->mcastpsq_lock);
buf : 	while ((skb = skb_dequeue(&ar->mcastpsq)) != NULL) {
while ((skb = skb_dequeue(&ar->mcastpsq)) != NULL) { 
buf : 		spin_unlock_bh(&ar->mcastpsq_lock);
buf : 
buf : 		ath6kl_data_tx(skb, vif->ndev);
if->ndev); 
buf : 
buf : 		spin_lock_bh(&ar->mcastpsq_lock);
buf : 	}
buf : 	spin_unlock_bh(&ar->mcastpsq_lock);
buf : 
buf : 	clear_bit(DTIM_EXPIRED, &vif->flags);
if->flags); 
buf : 
buf : 	/* clear the LSB of the BitMapCtl field of the TIM IE */
buf : 	ath6kl_wmi_set_pvb_cmd(ar->wmi, vif->fw_vif_idx, MCAST_AID, 0);
if->fw_vif_idx, MCAST_AID, 0); 
buf : }
buf : 
buf : void ath6kl_disconnect_event(struct ath6kl_vif *vif, u8 reason, u8 *bssid,
buf : 			     u8 assoc_resp_len, u8 *assoc_info,
buf : 			     u16 prot_reason_status)
buf : {
buf : 	struct ath6kl *ar = vif->ar;
if->ar; 
buf : 
buf : 	if (vif->nw_type == AP_NETWORK) {
buf : 		/* disconnect due to other STA vif switching channels */
if switching channels */ 
buf : 		if (reason == BSS_DISCONNECTED &&
buf : 		    prot_reason_status == WMI_AP_REASON_STA_ROAM) {
buf : 			ar->want_ch_switch |= 1 << vif->fw_vif_idx;
if->fw_vif_idx; 
buf : 			/* bail back to this channel if STA vif fails connect */
buf : 			ar->last_ch = le16_to_cpu(vif->profile.ch);
if->profile.ch); 
buf : 		}
buf : 
buf : 		if (prot_reason_status == WMI_AP_REASON_MAX_STA) {
if (prot_reason_status == WMI_AP_REASON_MAX_STA) { 
buf : 			/* send max client reached notification to user space */
buf : 			cfg80211_conn_failed(vif->ndev, bssid,
if->ndev, bssid, 
buf : 					     NL80211_CONN_FAIL_MAX_CLIENTS,
buf : 					     GFP_KERNEL);
buf : 		}
buf : 
buf : 		if (prot_reason_status == WMI_AP_REASON_ACL) {
if (prot_reason_status == WMI_AP_REASON_ACL) { 
buf : 			/* send blocked client notification to user space */
buf : 			cfg80211_conn_failed(vif->ndev, bssid,
if->ndev, bssid, 
buf : 					     NL80211_CONN_FAIL_BLOCKED_CLIENT,
buf : 					     GFP_KERNEL);
buf : 		}
buf : 
buf : 		if (!ath6kl_remove_sta(ar, bssid, prot_reason_status))
if (!ath6kl_remove_sta(ar, bssid, prot_reason_status)) 
buf : 			return;
buf : 
buf : 		/* if no more associated STAs, empty the mcast PS q */
if no more associated STAs, empty the mcast PS q */ 
buf : 		if (ar->sta_list_index == 0) {
buf : 			spin_lock_bh(&ar->mcastpsq_lock);
buf : 			skb_queue_purge(&ar->mcastpsq);
buf : 			spin_unlock_bh(&ar->mcastpsq_lock);
buf : 
buf : 			/* clear the LSB of the TIM IE's BitMapCtl field */
buf : 			if (test_bit(WMI_READY, &ar->flag))
if (test_bit(WMI_READY, &ar->flag)) 
buf : 				ath6kl_wmi_set_pvb_cmd(ar->wmi, vif->fw_vif_idx,
buf : 						       MCAST_AID, 0);
buf : 		}
buf : 
buf : 		if (!is_broadcast_ether_addr(bssid)) {
if (!is_broadcast_ether_addr(bssid)) { 
buf : 			/* send event to application */
buf : 			cfg80211_del_sta(vif->ndev, bssid, GFP_KERNEL);
if->ndev, bssid, GFP_KERNEL); 
buf : 		}
buf : 
buf : 		if (memcmp(vif->ndev->dev_addr, bssid, ETH_ALEN) == 0) {
if (memcmp(vif->ndev->dev_addr, bssid, ETH_ALEN) == 0) { 
buf : 			memset(vif->wep_key_list, 0, sizeof(vif->wep_key_list));
buf : 			clear_bit(CONNECTED, &vif->flags);
if->flags); 
buf : 		}
buf : 		return;
buf : 	}
buf : 
buf : 	ath6kl_cfg80211_disconnect_event(vif, reason, bssid,
if, reason, bssid, 
buf : 					 assoc_resp_len, assoc_info,
buf : 					 prot_reason_status);
buf : 
buf : 	aggr_reset_state(vif->aggr_cntxt->aggr_conn);
if->aggr_cntxt->aggr_conn); 
buf : 
buf : 	del_timer(&vif->disconnect_timer);
buf : 
buf : 	ath6kl_dbg(ATH6KL_DBG_WLAN_CFG, "disconnect reason is %d\n", reason);
buf : 
buf : 	/*
buf : 	 * If the event is due to disconnect cmd from the host, only they
buf : 	 * the target would stop trying to connect. Under any other
buf : 	 * condition, target would keep trying to connect.
buf : 	 */
buf : 	if (reason == DISCONNECT_CMD) {
if (reason == DISCONNECT_CMD) { 
buf : 		if (!ar->usr_bss_filter && test_bit(WMI_READY, &ar->flag))
buf : 			ath6kl_wmi_bssfilter_cmd(ar->wmi, vif->fw_vif_idx,
if->fw_vif_idx, 
buf : 						 NONE_BSS_FILTER, 0);
buf : 	} else {
buf : 		set_bit(CONNECT_PEND, &vif->flags);
if->flags); 
buf : 		if (((reason == ASSOC_FAILED) &&
buf : 		     (prot_reason_status == 0x11)) ||
buf : 		    ((reason == ASSOC_FAILED) && (prot_reason_status == 0x0) &&
buf : 		     (vif->reconnect_flag == 1))) {
if->reconnect_flag == 1))) { 
buf : 			set_bit(CONNECTED, &vif->flags);
buf : 			return;
buf : 		}
buf : 	}
buf : 
buf : 	/* restart disconnected concurrent vifs waiting for new channel */
ifs waiting for new channel */ 
buf : 	ath6kl_check_ch_switch(ar, ar->last_ch);
buf : 
buf : 	/* update connect & link status atomically */
buf : 	spin_lock_bh(&vif->if_lock);
if->if_lock); 
buf : 	clear_bit(CONNECTED, &vif->flags);
buf : 	netif_carrier_off(vif->ndev);
if_carrier_off(vif->ndev); 
buf : 	spin_unlock_bh(&vif->if_lock);
buf : 
buf : 	if ((reason != CSERV_DISCONNECT) || (vif->reconnect_flag != 1))
if ((reason != CSERV_DISCONNECT) || (vif->reconnect_flag != 1)) 
buf : 		vif->reconnect_flag = 0;
buf : 
buf : 	if (reason != CSERV_DISCONNECT)
if (reason != CSERV_DISCONNECT) 
buf : 		ar->user_key_ctrl = 0;
buf : 
buf : 	netif_stop_queue(vif->ndev);
if_stop_queue(vif->ndev); 
buf : 	memset(vif->bssid, 0, sizeof(vif->bssid));
buf : 	vif->bss_ch = 0;
if->bss_ch = 0; 
buf : 
buf : 	ath6kl_tx_data_cleanup(ar);
buf : }
buf : 
buf : struct ath6kl_vif *ath6kl_vif_first(struct ath6kl *ar)
if *ath6kl_vif_first(struct ath6kl *ar) 
buf : {
buf : 	struct ath6kl_vif *vif;
buf : 
buf : 	spin_lock_bh(&ar->list_lock);
buf : 	if (list_empty(&ar->vif_list)) {
if (list_empty(&ar->vif_list)) { 
buf : 		spin_unlock_bh(&ar->list_lock);
buf : 		return NULL;
buf : 	}
buf : 
buf : 	vif = list_first_entry(&ar->vif_list, struct ath6kl_vif, list);
if = list_first_entry(&ar->vif_list, struct ath6kl_vif, list); 
buf : 
buf : 	spin_unlock_bh(&ar->list_lock);
buf : 
buf : 	return vif;
if; 
buf : }
buf : 
buf : static int ath6kl_open(struct net_device *dev)
buf : {
buf : 	struct ath6kl_vif *vif = netdev_priv(dev);
if *vif = netdev_priv(dev); 
buf : 
buf : 	set_bit(WLAN_ENABLED, &vif->flags);
buf : 
buf : 	if (test_bit(CONNECTED, &vif->flags)) {
if (test_bit(CONNECTED, &vif->flags)) { 
buf : 		netif_carrier_on(dev);
buf : 		netif_wake_queue(dev);
if_wake_queue(dev); 
buf : 	} else {
buf : 		netif_carrier_off(dev);
if_carrier_off(dev); 
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int ath6kl_close(struct net_device *dev)
buf : {
buf : 	struct ath6kl_vif *vif = netdev_priv(dev);
if *vif = netdev_priv(dev); 
buf : 
buf : 	netif_stop_queue(dev);
buf : 
buf : 	ath6kl_cfg80211_stop(vif);
if); 
buf : 
buf : 	clear_bit(WLAN_ENABLED, &vif->flags);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static struct net_device_stats *ath6kl_get_stats(struct net_device *dev)
buf : {
buf : 	struct ath6kl_vif *vif = netdev_priv(dev);
if *vif = netdev_priv(dev); 
buf : 
buf : 	return &vif->net_stats;
buf : }
buf : 
buf : static int ath6kl_set_features(struct net_device *dev,
buf : 			       netdev_features_t features)
buf : {
buf : 	struct ath6kl_vif *vif = netdev_priv(dev);
if *vif = netdev_priv(dev); 
buf : 	struct ath6kl *ar = vif->ar;
buf : 	int err = 0;
buf : 
buf : 	if ((features & NETIF_F_RXCSUM) &&
if ((features & NETIF_F_RXCSUM) && 
buf : 	    (ar->rx_meta_ver != WMI_META_VERSION_2)) {
buf : 		ar->rx_meta_ver = WMI_META_VERSION_2;
buf : 		err = ath6kl_wmi_set_rx_frame_format_cmd(ar->wmi,
format_cmd(ar->wmi, 
buf : 							 vif->fw_vif_idx,
buf : 							 ar->rx_meta_ver, 0, 0);
buf : 		if (err) {
if (err) { 
buf : 			dev->features = features & ~NETIF_F_RXCSUM;
buf : 			return err;
buf : 		}
buf : 	} else if (!(features & NETIF_F_RXCSUM) &&
if (!(features & NETIF_F_RXCSUM) && 
buf : 		   (ar->rx_meta_ver == WMI_META_VERSION_2)) {
buf : 		ar->rx_meta_ver = 0;
buf : 		err = ath6kl_wmi_set_rx_frame_format_cmd(ar->wmi,
format_cmd(ar->wmi, 
buf : 							 vif->fw_vif_idx,
buf : 							 ar->rx_meta_ver, 0, 0);
buf : 		if (err) {
if (err) { 
buf : 			dev->features = features | NETIF_F_RXCSUM;
buf : 			return err;
buf : 		}
buf : 	}
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void ath6kl_set_multicast_list(struct net_device *ndev)
buf : {
buf : 	struct ath6kl_vif *vif = netdev_priv(ndev);
if *vif = netdev_priv(ndev); 
buf : 	bool mc_all_on = false;
buf : 	int mc_count = netdev_mc_count(ndev);
buf : 	struct netdev_hw_addr *ha;
buf : 	bool found;
buf : 	struct ath6kl_mc_filter *mc_filter, *tmp;
buf : 	struct list_head mc_filter_new;
buf : 	int ret;
buf : 
buf : 	if (!test_bit(WMI_READY, &vif->ar->flag) ||
if (!test_bit(WMI_READY, &vif->ar->flag) || 
buf : 	    !test_bit(WLAN_ENABLED, &vif->flags))
buf : 		return;
buf : 
buf : 	/* Enable multicast-all filter. */
buf : 	mc_all_on = !!(ndev->flags & IFF_PROMISC) ||
buf : 		    !!(ndev->flags & IFF_ALLMULTI) ||
buf : 		    !!(mc_count > ATH6K_MAX_MC_FILTERS_PER_LIST);
buf : 
buf : 	if (mc_all_on)
if (mc_all_on) 
buf : 		set_bit(NETDEV_MCAST_ALL_ON, &vif->flags);
buf : 	else
buf : 		clear_bit(NETDEV_MCAST_ALL_ON, &vif->flags);
if->flags); 
buf : 
buf : 	if (test_bit(ATH6KL_FW_CAPABILITY_WOW_MULTICAST_FILTER,
buf : 		     vif->ar->fw_capabilities)) {
if->ar->fw_capabilities)) { 
buf : 		mc_all_on = mc_all_on || (vif->ar->state == ATH6KL_STATE_ON);
buf : 	}
buf : 
buf : 	if (!(ndev->flags & IFF_MULTICAST)) {
if (!(ndev->flags & IFF_MULTICAST)) { 
buf : 		mc_all_on = false;
buf : 		set_bit(NETDEV_MCAST_ALL_OFF, &vif->flags);
if->flags); 
buf : 	} else {
buf : 		clear_bit(NETDEV_MCAST_ALL_OFF, &vif->flags);
if->flags); 
buf : 	}
buf : 
buf : 	/* Enable/disable "multicast-all" filter*/
buf : 	ath6kl_dbg(ATH6KL_DBG_TRC, "%s multicast-all filter\n",
buf : 		   mc_all_on ? "enabling" : "disabling");
buf : 
buf : 	ret = ath6kl_wmi_mcast_filter_cmd(vif->ar->wmi, vif->fw_vif_idx,
if->ar->wmi, vif->fw_vif_idx, 
buf : 						  mc_all_on);
buf : 	if (ret) {
if (ret) { 
buf : 		ath6kl_warn("Failed to %s multicast-all receive\n",
buf : 			    mc_all_on ? "enable" : "disable");
buf : 		return;
buf : 	}
buf : 
buf : 	if (test_bit(NETDEV_MCAST_ALL_ON, &vif->flags))
if (test_bit(NETDEV_MCAST_ALL_ON, &vif->flags)) 
buf : 		return;
buf : 
buf : 	/* Keep the driver and firmware mcast list in sync. */
buf : 	list_for_each_entry_safe(mc_filter, tmp, &vif->mc_filter, list) {
if->mc_filter, list) { 
buf : 		found = false;
buf : 		netdev_for_each_mc_addr(ha, ndev) {
for_each_mc_addr(ha, ndev) { 
buf : 			if (memcmp(ha->addr, mc_filter->hw_addr,
buf : 				   ATH6KL_MCAST_FILTER_MAC_ADDR_SIZE) == 0) {
buf : 				found = true;
buf : 				break;
buf : 			}
buf : 		}
buf : 
buf : 		if (!found) {
if (!found) { 
buf : 			/*
buf : 			 * Delete the filter which was previously set
buf : 			 * but not in the new request.
buf : 			 */
buf : 			ath6kl_dbg(ATH6KL_DBG_TRC,
buf : 				   "Removing %pM from multicast filter\n",
buf : 				   mc_filter->hw_addr);
buf : 			ret = ath6kl_wmi_add_del_mcast_filter_cmd(vif->ar->wmi,
if->ar->wmi, 
buf : 					vif->fw_vif_idx, mc_filter->hw_addr,
buf : 					false);
buf : 			if (ret) {
if (ret) { 
buf : 				ath6kl_warn("Failed to remove multicast filter:%pM\n",
buf : 					    mc_filter->hw_addr);
buf : 				return;
buf : 			}
buf : 
buf : 			list_del(&mc_filter->list);
buf : 			kfree(mc_filter);
buf : 		}
buf : 	}
buf : 
buf : 	INIT_LIST_HEAD(&mc_filter_new);
buf : 
buf : 	netdev_for_each_mc_addr(ha, ndev) {
for_each_mc_addr(ha, ndev) { 
buf : 		found = false;
buf : 		list_for_each_entry(mc_filter, &vif->mc_filter, list) {
if->mc_filter, list) { 
buf : 			if (memcmp(ha->addr, mc_filter->hw_addr,
buf : 				   ATH6KL_MCAST_FILTER_MAC_ADDR_SIZE) == 0) {
buf : 				found = true;
buf : 				break;
buf : 			}
buf : 		}
buf : 
buf : 		if (!found) {
if (!found) { 
buf : 			mc_filter = kzalloc(sizeof(struct ath6kl_mc_filter),
buf : 					    GFP_ATOMIC);
buf : 			if (!mc_filter) {
if (!mc_filter) { 
buf : 				WARN_ON(1);
buf : 				goto out;
buf : 			}
buf : 
buf : 			memcpy(mc_filter->hw_addr, ha->addr,
buf : 			       ATH6KL_MCAST_FILTER_MAC_ADDR_SIZE);
buf : 			/* Set the multicast filter */
buf : 			ath6kl_dbg(ATH6KL_DBG_TRC,
buf : 				   "Adding %pM to multicast filter list\n",
buf : 				   mc_filter->hw_addr);
buf : 			ret = ath6kl_wmi_add_del_mcast_filter_cmd(vif->ar->wmi,
if->ar->wmi, 
buf : 					vif->fw_vif_idx, mc_filter->hw_addr,
buf : 					true);
buf : 			if (ret) {
if (ret) { 
buf : 				ath6kl_warn("Failed to add multicast filter :%pM\n",
buf : 					    mc_filter->hw_addr);
buf : 				kfree(mc_filter);
buf : 				goto out;
buf : 			}
buf : 
buf : 			list_add_tail(&mc_filter->list, &mc_filter_new);
buf : 		}
buf : 	}
buf : 
buf : out:
buf : 	list_splice_tail(&mc_filter_new, &vif->mc_filter);
if->mc_filter); 
buf : }
buf : 
buf : static const struct net_device_ops ath6kl_netdev_ops = {
buf : 	.ndo_open               = ath6kl_open,
buf : 	.ndo_stop               = ath6kl_close,
buf : 	.ndo_start_xmit         = ath6kl_data_tx,
buf : 	.ndo_get_stats          = ath6kl_get_stats,
buf : 	.ndo_set_features       = ath6kl_set_features,
buf : 	.ndo_set_rx_mode	= ath6kl_set_multicast_list,
buf : };
buf : 
buf : void init_netdev(struct net_device *dev)
buf : {
buf : 	dev->netdev_ops = &ath6kl_netdev_ops;
buf : 	dev->destructor = free_netdev;
buf : 	dev->watchdog_timeo = ATH6KL_TX_TIMEOUT;
buf : 
buf : 	dev->needed_headroom = ETH_HLEN;
buf : 	dev->needed_headroom += roundup(sizeof(struct ath6kl_llc_snap_hdr) +
buf : 					sizeof(struct wmi_data_hdr) +
buf : 					HTC_HDR_LENGTH +
buf : 					WMI_MAX_TX_META_SZ +
buf : 					ATH6KL_HTC_ALIGN_BYTES, 4);
buf : 
buf : 	dev->hw_features |= NETIF_F_IP_CSUM | NETIF_F_RXCSUM;
buf : 
buf : 	return;
buf : }
file : ./test/kernel/drivers/net/wireless/ath/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2009 Atheros Communications Inc.
buf :  *
buf :  * Permission to use, copy, modify, and/or distribute this software for any
ify, and/or distribute this software for any 
buf :  * purpose with or without fee is hereby granted, provided that the above
buf :  * copyright notice and this permission notice appear in all copies.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
buf :  * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
buf :  * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
buf :  * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
buf :  * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
buf :  * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
buf :  * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
buf :  */
buf : 
buf : #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
buf : 
buf : #include <linux/kernel.h>
buf : #include <linux/module.h>
buf : 
buf : #include "ath.h"
buf : 
buf : MODULE_AUTHOR("Atheros Communications");
buf : MODULE_DESCRIPTION("Shared library for Atheros wireless LAN cards.");
for Atheros wireless LAN cards."); 
buf : MODULE_LICENSE("Dual BSD/GPL");
buf : 
buf : struct sk_buff *ath_rxbuf_alloc(struct ath_common *common,
buf : 				u32 len,
buf : 				gfp_t gfp_mask)
buf : {
buf : 	struct sk_buff *skb;
buf : 	u32 off;
buf : 
buf : 	/*
buf : 	 * Cache-line-align.  This is important (for the
for the 
buf : 	 * 5210 at least) as not doing so causes bogus data
buf : 	 * in rx'd frames.
buf : 	 */
buf : 
buf : 	/* Note: the kernel can allocate a value greater than
buf : 	 * what we ask it to give us. We really only need 4 KB as that
buf : 	 * is this hardware supports and in fact we need at least 3849
buf : 	 * as that is the MAX AMSDU size this hardware supports.
buf : 	 * Unfortunately this means we may get 8 KB here from the
fortunately this means we may get 8 KB here from the 
buf : 	 * kernel... and that is actually what is observed on some
buf : 	 * systems :( */
buf : 	skb = __dev_alloc_skb(len + common->cachelsz - 1, gfp_mask);
buf : 	if (skb != NULL) {
if (skb != NULL) { 
buf : 		off = ((unsigned long) skb->data) % common->cachelsz;
buf : 		if (off != 0)
if (off != 0) 
buf : 			skb_reserve(skb, common->cachelsz - off);
buf : 	} else {
buf : 		pr_err("skbuff alloc of size %u failed\n", len);
buf : 		return NULL;
buf : 	}
buf : 
buf : 	return skb;
buf : }
buf : EXPORT_SYMBOL(ath_rxbuf_alloc);
buf : 
buf : bool ath_is_mybeacon(struct ath_common *common, struct ieee80211_hdr *hdr)
buf : {
buf : 	return ieee80211_is_beacon(hdr->frame_control) &&
buf : 		!is_zero_ether_addr(common->curbssid) &&
buf : 		ether_addr_equal_64bits(hdr->addr3, common->curbssid);
buf : }
buf : EXPORT_SYMBOL(ath_is_mybeacon);
buf : 
buf : void ath_printk(const char *level, const struct ath_common* common,
buf : 		const char *fmt, ...)
buf : {
buf : 	struct va_format vaf;
format vaf; 
buf : 	va_list args;
buf : 
buf : 	va_start(args, fmt);
buf : 
buf : 	vaf.fmt = fmt;
buf : 	vaf.va = &args;
buf : 
buf : 	if (common && common->hw && common->hw->wiphy)
if (common && common->hw && common->hw->wiphy) 
buf : 		printk("%sath: %s: %pV",
buf : 		       level, wiphy_name(common->hw->wiphy), &vaf);
buf : 	else
buf : 		printk("%sath: %pV", level, &vaf);
buf : 
buf : 	va_end(args);
buf : }
buf : EXPORT_SYMBOL(ath_printk);
file : ./test/kernel/drivers/net/wireless/ath/wil6210/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2012 Qualcomm Atheros, Inc.
buf :  *
buf :  * Permission to use, copy, modify, and/or distribute this software for any
ify, and/or distribute this software for any 
buf :  * purpose with or without fee is hereby granted, provided that the above
buf :  * copyright notice and this permission notice appear in all copies.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
buf :  * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
buf :  * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
buf :  * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
buf :  * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
buf :  * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
buf :  * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
buf :  */
buf : 
buf : #include <linux/moduleparam.h>
buf : #include <linux/if_arp.h>
if_arp.h> 
buf : #include <linux/etherdevice.h>
buf : 
buf : #include "wil6210.h"
buf : #include "txrx.h"
buf : 
buf : static bool no_fw_recovery;
buf : module_param(no_fw_recovery, bool, S_IRUGO | S_IWUSR);
buf : MODULE_PARM_DESC(no_fw_recovery, " disable FW error recovery");
buf : 
buf : /*
buf :  * Due to a hardware issue,
buf :  * one has to read/write to/from NIC in 32-bit chunks;
buf :  * regular memcpy_fromio and siblings will
buf :  * not work on 64-bit platform - it uses 64-bit transactions
form - it uses 64-bit transactions 
buf :  *
buf :  * Force 32-bit transactions to enable NIC on 64-bit platforms
buf :  *
buf :  * To avoid byte swap on big endian host, __raw_{read|write}l
buf :  * should be used - {read|write}l would swap bytes to provide
buf :  * little endian on PCI value in host endianness.
buf :  */
buf : void wil_memcpy_fromio_32(void *dst, const volatile void __iomem *src,
buf : 			  size_t count)
buf : {
buf : 	u32 *d = dst;
buf : 	const volatile u32 __iomem *s = src;
buf : 
buf : 	/* size_t is unsigned, if (count%4 != 0) it will wrap */
if (count%4 != 0) it will wrap */ 
buf : 	for (count += 4; count > 4; count -= 4)
for (count += 4; count > 4; count -= 4) 
buf : 		*d++ = __raw_readl(s++);
buf : }
buf : 
buf : void wil_memcpy_toio_32(volatile void __iomem *dst, const void *src,
buf : 			size_t count)
buf : {
buf : 	volatile u32 __iomem *d = dst;
buf : 	const u32 *s = src;
buf : 
buf : 	for (count += 4; count > 4; count -= 4)
for (count += 4; count > 4; count -= 4) 
buf : 		__raw_writel(*s++, d++);
buf : }
buf : 
buf : static void wil_disconnect_cid(struct wil6210_priv *wil, int cid)
buf : {
buf : 	uint i;
buf : 	struct wil_sta_info *sta = &wil->sta[cid];
buf : 
buf : 	sta->data_port_open = false;
buf : 	if (sta->status != wil_sta_unused) {
if (sta->status != wil_sta_unused) { 
buf : 		wmi_disconnect_sta(wil, sta->addr, WLAN_REASON_DEAUTH_LEAVING);
buf : 		sta->status = wil_sta_unused;
buf : 	}
buf : 
buf : 	for (i = 0; i < WIL_STA_TID_NUM; i++) {
for (i = 0; i < WIL_STA_TID_NUM; i++) { 
buf : 		struct wil_tid_ampdu_rx *r = sta->tid_rx[i];
buf : 		sta->tid_rx[i] = NULL;
buf : 		wil_tid_ampdu_rx_free(wil, r);
buf : 	}
buf : 	for (i = 0; i < ARRAY_SIZE(wil->vring_tx); i++) {
for (i = 0; i < ARRAY_SIZE(wil->vring_tx); i++) { 
buf : 		if (wil->vring2cid_tid[i][0] == cid)
buf : 			wil_vring_fini_tx(wil, i);
buf : 	}
buf : 	memset(&sta->stats, 0, sizeof(sta->stats));
buf : }
buf : 
buf : static void _wil6210_disconnect(struct wil6210_priv *wil, const u8 *bssid)
buf : {
buf : 	int cid = -ENOENT;
buf : 	struct net_device *ndev = wil_to_ndev(wil);
buf : 	struct wireless_dev *wdev = wil->wdev;
buf : 
buf : 	might_sleep();
buf : 	if (bssid) {
if (bssid) { 
buf : 		cid = wil_find_cid(wil, bssid);
buf : 		wil_dbg_misc(wil, "%s(%pM, CID %d)\n", __func__, bssid, cid);
buf : 	} else {
buf : 		wil_dbg_misc(wil, "%s(all)\n", __func__);
buf : 	}
buf : 
buf : 	if (cid >= 0) /* disconnect 1 peer */
if (cid >= 0) /* disconnect 1 peer */ 
buf : 		wil_disconnect_cid(wil, cid);
buf : 	else /* disconnect all */
buf : 		for (cid = 0; cid < WIL6210_MAX_CID; cid++)
for (cid = 0; cid < WIL6210_MAX_CID; cid++) 
buf : 			wil_disconnect_cid(wil, cid);
buf : 
buf : 	/* link state */
buf : 	switch (wdev->iftype) {
iftype) { 
buf : 	case NL80211_IFTYPE_STATION:
buf : 	case NL80211_IFTYPE_P2P_CLIENT:
buf : 		wil_link_off(wil);
buf : 		if (test_bit(wil_status_fwconnected, &wil->status)) {
if (test_bit(wil_status_fwconnected, &wil->status)) { 
buf : 			clear_bit(wil_status_fwconnected, &wil->status);
buf : 			cfg80211_disconnected(ndev,
buf : 					      WLAN_STATUS_UNSPECIFIED_FAILURE,
buf : 					      NULL, 0, GFP_KERNEL);
buf : 		} else if (test_bit(wil_status_fwconnecting, &wil->status)) {
if (test_bit(wil_status_fwconnecting, &wil->status)) { 
buf : 			cfg80211_connect_result(ndev, bssid, NULL, 0, NULL, 0,
buf : 						WLAN_STATUS_UNSPECIFIED_FAILURE,
buf : 						GFP_KERNEL);
buf : 		}
buf : 		clear_bit(wil_status_fwconnecting, &wil->status);
buf : 		break;
buf : 	default:
buf : 		/* AP-like interface and monitor:
buf : 		 * never scan, always connected
buf : 		 */
buf : 		if (bssid)
if (bssid) 
buf : 			cfg80211_del_sta(ndev, bssid, GFP_KERNEL);
buf : 		break;
buf : 	}
buf : }
buf : 
buf : static void wil_disconnect_worker(struct work_struct *work)
buf : {
buf : 	struct wil6210_priv *wil = container_of(work,
buf : 			struct wil6210_priv, disconnect_worker);
buf : 
buf : 	mutex_lock(&wil->mutex);
buf : 	_wil6210_disconnect(wil, NULL);
buf : 	mutex_unlock(&wil->mutex);
buf : }
buf : 
buf : static void wil_connect_timer_fn(ulong x)
buf : {
buf : 	struct wil6210_priv *wil = (void *)x;
buf : 
buf : 	wil_dbg_misc(wil, "Connect timeout\n");
buf : 
buf : 	/* reschedule to thread context - disconnect won't
buf : 	 * run from atomic context
buf : 	 */
buf : 	schedule_work(&wil->disconnect_worker);
buf : }
buf : 
buf : static void wil_scan_timer_fn(ulong x)
buf : {
buf : 	struct wil6210_priv *wil = (void *)x;
buf : 
buf : 	clear_bit(wil_status_fwready, &wil->status);
buf : 	wil_err(wil, "Scan timeout detected, start fw error recovery\n");
buf : 	schedule_work(&wil->fw_error_worker);
buf : }
buf : 
buf : static void wil_fw_error_worker(struct work_struct *work)
buf : {
buf : 	struct wil6210_priv *wil = container_of(work,
buf : 			struct wil6210_priv, fw_error_worker);
buf : 	struct wireless_dev *wdev = wil->wdev;
buf : 
buf : 	wil_dbg_misc(wil, "fw error worker\n");
buf : 
buf : 	if (no_fw_recovery)
if (no_fw_recovery) 
buf : 		return;
buf : 
buf : 	/* increment @recovery_count if less then WIL6210_FW_RECOVERY_TO
if less then WIL6210_FW_RECOVERY_TO 
buf : 	 * passed since last recovery attempt
buf : 	 */
buf : 	if (time_is_after_jiffies(wil->last_fw_recovery +
if (time_is_after_jiffies(wil->last_fw_recovery + 
buf : 				  WIL6210_FW_RECOVERY_TO))
buf : 		wil->recovery_count++;
buf : 	else
buf : 		wil->recovery_count = 1; /* fw was alive for a long time */
for a long time */ 
buf : 
buf : 	if (wil->recovery_count > WIL6210_FW_RECOVERY_RETRIES) {
buf : 		wil_err(wil, "too many recovery attempts (%d), giving up\n",
buf : 			wil->recovery_count);
buf : 		return;
buf : 	}
buf : 
buf : 	wil->last_fw_recovery = jiffies;
iffies; 
buf : 
buf : 	mutex_lock(&wil->mutex);
buf : 	switch (wdev->iftype) {
iftype) { 
buf : 	case NL80211_IFTYPE_STATION:
buf : 	case NL80211_IFTYPE_P2P_CLIENT:
buf : 	case NL80211_IFTYPE_MONITOR:
buf : 		wil_info(wil, "fw error recovery started (try %d)...\n",
buf : 			 wil->recovery_count);
buf : 		wil_reset(wil);
buf : 
buf : 		/* need to re-allocate Rx ring after reset */
buf : 		wil_rx_init(wil);
buf : 		break;
buf : 	case NL80211_IFTYPE_AP:
buf : 	case NL80211_IFTYPE_P2P_GO:
buf : 		/* recovery in these modes is done by upper layers */
buf : 		break;
buf : 	default:
buf : 		break;
buf : 	}
buf : 	mutex_unlock(&wil->mutex);
buf : }
buf : 
buf : static int wil_find_free_vring(struct wil6210_priv *wil)
buf : {
buf : 	int i;
buf : 	for (i = 0; i < WIL6210_MAX_TX_RINGS; i++) {
for (i = 0; i < WIL6210_MAX_TX_RINGS; i++) { 
buf : 		if (!wil->vring_tx[i].va)
buf : 			return i;
buf : 	}
buf : 	return -EINVAL;
buf : }
buf : 
buf : static void wil_connect_worker(struct work_struct *work)
buf : {
buf : 	int rc;
buf : 	struct wil6210_priv *wil = container_of(work, struct wil6210_priv,
buf : 						connect_worker);
buf : 	int cid = wil->pending_connect_cid;
buf : 	int ringid = wil_find_free_vring(wil);
buf : 
buf : 	if (cid < 0) {
if (cid < 0) { 
buf : 		wil_err(wil, "No connection pending\n");
buf : 		return;
buf : 	}
buf : 
buf : 	wil_dbg_wmi(wil, "Configure for connection CID %d\n", cid);
for connection CID %d\n", cid); 
buf : 
buf : 	rc = wil_vring_init_tx(wil, ringid, WIL6210_TX_RING_SIZE, cid, 0);
buf : 	wil->pending_connect_cid = -1;
buf : 	if (rc == 0) {
if (rc == 0) { 
buf : 		wil->sta[cid].status = wil_sta_connected;
buf : 		wil_link_on(wil);
buf : 	} else {
buf : 		wil->sta[cid].status = wil_sta_unused;
buf : 	}
buf : }
buf : 
buf : int wil_priv_init(struct wil6210_priv *wil)
buf : {
buf : 	wil_dbg_misc(wil, "%s()\n", __func__);
buf : 
buf : 	memset(wil->sta, 0, sizeof(wil->sta));
buf : 
buf : 	mutex_init(&wil->mutex);
buf : 	mutex_init(&wil->wmi_mutex);
buf : 
buf : 	init_completion(&wil->wmi_ready);
buf : 
buf : 	wil->pending_connect_cid = -1;
buf : 	setup_timer(&wil->connect_timer, wil_connect_timer_fn, (ulong)wil);
buf : 	setup_timer(&wil->scan_timer, wil_scan_timer_fn, (ulong)wil);
buf : 
buf : 	INIT_WORK(&wil->connect_worker, wil_connect_worker);
buf : 	INIT_WORK(&wil->disconnect_worker, wil_disconnect_worker);
buf : 	INIT_WORK(&wil->wmi_event_worker, wmi_event_worker);
buf : 	INIT_WORK(&wil->fw_error_worker, wil_fw_error_worker);
buf : 
buf : 	INIT_LIST_HEAD(&wil->pending_wmi_ev);
buf : 	spin_lock_init(&wil->wmi_ev_lock);
buf : 
buf : 	wil->wmi_wq = create_singlethread_workqueue(WIL_NAME"_wmi");
buf : 	if (!wil->wmi_wq)
if (!wil->wmi_wq) 
buf : 		return -EAGAIN;
buf : 
buf : 	wil->wmi_wq_conn = create_singlethread_workqueue(WIL_NAME"_connect");
buf : 	if (!wil->wmi_wq_conn) {
if (!wil->wmi_wq_conn) { 
buf : 		destroy_workqueue(wil->wmi_wq);
buf : 		return -EAGAIN;
buf : 	}
buf : 
buf : 	wil->last_fw_recovery = jiffies;
iffies; 
buf : 
buf : 	return 0;
buf : }
buf : 
buf : void wil6210_disconnect(struct wil6210_priv *wil, const u8 *bssid)
buf : {
buf : 	del_timer_sync(&wil->connect_timer);
buf : 	_wil6210_disconnect(wil, bssid);
buf : }
buf : 
buf : void wil_priv_deinit(struct wil6210_priv *wil)
buf : {
buf : 	del_timer_sync(&wil->scan_timer);
buf : 	cancel_work_sync(&wil->disconnect_worker);
buf : 	cancel_work_sync(&wil->fw_error_worker);
buf : 	mutex_lock(&wil->mutex);
buf : 	wil6210_disconnect(wil, NULL);
buf : 	mutex_unlock(&wil->mutex);
buf : 	wmi_event_flush(wil);
buf : 	destroy_workqueue(wil->wmi_wq_conn);
buf : 	destroy_workqueue(wil->wmi_wq);
buf : }
buf : 
buf : static void wil_target_reset(struct wil6210_priv *wil)
buf : {
buf : 	int delay = 0;
buf : 	u32 hw_state;
buf : 	u32 rev_id;
buf : 
buf : 	wil_dbg_misc(wil, "Resetting...\n");
buf : 
buf : 	/* register read */
buf : #define R(a) ioread32(wil->csr + HOSTADDR(a))
buf : 	/* register write */
buf : #define W(a, v) iowrite32(v, wil->csr + HOSTADDR(a))
buf : 	/* register set = read, OR, write */
buf : #define S(a, v) W(a, R(a) | v)
buf : 	/* register clear = read, AND with inverted, write */
buf : #define C(a, v) W(a, R(a) & ~v)
buf : 
buf : 	wil->hw_version = R(RGF_USER_FW_REV_ID);
buf : 	rev_id = wil->hw_version & 0xff;
buf : 	/* hpal_perst_from_pad_src_n_mask */
buf : 	S(RGF_USER_CLKS_CTL_SW_RST_MASK_0, BIT(6));
buf : 	/* car_perst_rst_src_n_mask */
buf : 	S(RGF_USER_CLKS_CTL_SW_RST_MASK_0, BIT(7));
buf : 	wmb(); /* order is important here */
buf : 
buf : 	W(RGF_USER_MAC_CPU_0,  BIT(1)); /* mac_cpu_man_rst */
buf : 	W(RGF_USER_USER_CPU_0, BIT(1)); /* user_cpu_man_rst */
buf : 	wmb(); /* order is important here */
buf : 
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_2, 0xFE000000);
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_1, 0x0000003F);
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_3, 0x00000170);
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_0, 0xFFE7FC00);
buf : 	wmb(); /* order is important here */
buf : 
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_3, 0);
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_2, 0);
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_1, 0);
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_0, 0);
buf : 	wmb(); /* order is important here */
buf : 
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_3, 0x00000001);
buf : 	if (rev_id == 1) {
if (rev_id == 1) { 
buf : 		W(RGF_USER_CLKS_CTL_SW_RST_VEC_2, 0x00000080);
buf : 	} else {
buf : 		W(RGF_PCIE_LOS_COUNTER_CTL, BIT(6) | BIT(8));
buf : 		W(RGF_USER_CLKS_CTL_SW_RST_VEC_2, 0x00008000);
buf : 	}
buf : 	W(RGF_USER_CLKS_CTL_SW_RST_VEC_0, 0);
buf : 	wmb(); /* order is important here */
buf : 
buf : 	/* wait until device ready */
buf : 	do {
buf : 		msleep(1);
buf : 		hw_state = R(RGF_USER_HW_MACHINE_STATE);
buf : 		if (delay++ > 100) {
if (delay++ > 100) { 
buf : 			wil_err(wil, "Reset not completed, hw_state 0x%08x\n",
buf : 				hw_state);
buf : 			return;
buf : 		}
buf : 	} while (hw_state != HW_MACHINE_BOOT_DONE);
while (hw_state != HW_MACHINE_BOOT_DONE); 
buf : 
buf : 	if (rev_id == 2)
buf : 		W(RGF_PCIE_LOS_COUNTER_CTL, BIT(8));
buf : 
buf : 	C(RGF_USER_CLKS_CTL_0, BIT_USER_CLKS_RST_PWGD);
buf : 	wmb(); /* order is important here */
buf : 
buf : 	wil_dbg_misc(wil, "Reset completed in %d ms\n", delay);
buf : 
buf : #undef R
buf : #undef W
buf : #undef S
buf : #undef C
buf : }
buf : 
buf : void wil_mbox_ring_le2cpus(struct wil6210_mbox_ring *r)
buf : {
buf : 	le32_to_cpus(&r->base);
buf : 	le16_to_cpus(&r->entry_size);
buf : 	le16_to_cpus(&r->size);
buf : 	le32_to_cpus(&r->tail);
buf : 	le32_to_cpus(&r->head);
buf : }
buf : 
buf : static int wil_wait_for_fw_ready(struct wil6210_priv *wil)
for_fw_ready(struct wil6210_priv *wil) 
buf : {
buf : 	ulong to = msecs_to_jiffies(1000);
buf : 	ulong left = wait_for_completion_timeout(&wil->wmi_ready, to);
for_completion_timeout(&wil->wmi_ready, to); 
buf : 	if (0 == left) {
buf : 		wil_err(wil, "Firmware not ready\n");
buf : 		return -ETIME;
buf : 	} else {
buf : 		wil_info(wil, "FW ready after %d ms. HW version 0x%08x\n",
buf : 			 jiffies_to_msecs(to-left), wil->hw_version);
iffies_to_msecs(to-left), wil->hw_version); 
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * We reset all the structures, and we reset the UMAC.
buf :  * After calling this routine, you're expected to reload
buf :  * the firmware.
buf :  */
buf : int wil_reset(struct wil6210_priv *wil)
buf : {
buf : 	int rc;
buf : 
buf : 	WARN_ON(!mutex_is_locked(&wil->mutex));
buf : 
buf : 	cancel_work_sync(&wil->disconnect_worker);
buf : 	wil6210_disconnect(wil, NULL);
buf : 
buf : 	wil->status = 0; /* prevent NAPI from being scheduled */
buf : 	if (test_bit(wil_status_napi_en, &wil->status)) {
if (test_bit(wil_status_napi_en, &wil->status)) { 
buf : 		napi_synchronize(&wil->napi_rx);
buf : 	}
buf : 
buf : 	if (wil->scan_request) {
if (wil->scan_request) { 
buf : 		wil_dbg_misc(wil, "Abort scan_request 0x%p\n",
buf : 			     wil->scan_request);
buf : 		del_timer_sync(&wil->scan_timer);
buf : 		cfg80211_scan_done(wil->scan_request, true);
buf : 		wil->scan_request = NULL;
buf : 	}
buf : 
buf : 	wil6210_disable_irq(wil);
buf : 
buf : 	wmi_event_flush(wil);
buf : 
buf : 	flush_workqueue(wil->wmi_wq_conn);
buf : 	flush_workqueue(wil->wmi_wq);
buf : 
buf : 	/* TODO: put MAC in reset */
buf : 	wil_target_reset(wil);
buf : 
buf : 	wil_rx_fini(wil);
buf : 
buf : 	/* init after reset */
buf : 	wil->pending_connect_cid = -1;
buf : 	reinit_completion(&wil->wmi_ready);
buf : 
buf : 	/* TODO: release MAC reset */
buf : 	wil6210_enable_irq(wil);
buf : 
buf : 	/* we just started MAC, wait for FW ready */
for FW ready */ 
buf : 	rc = wil_wait_for_fw_ready(wil);
buf : 
buf : 	return rc;
buf : }
buf : 
buf : void wil_fw_error_recovery(struct wil6210_priv *wil)
buf : {
buf : 	wil_dbg_misc(wil, "starting fw error recovery\n");
buf : 	schedule_work(&wil->fw_error_worker);
buf : }
buf : 
buf : void wil_link_on(struct wil6210_priv *wil)
buf : {
buf : 	struct net_device *ndev = wil_to_ndev(wil);
buf : 
buf : 	wil_dbg_misc(wil, "%s()\n", __func__);
buf : 
buf : 	netif_carrier_on(ndev);
if_carrier_on(ndev); 
buf : 	netif_tx_wake_all_queues(ndev);
buf : }
buf : 
buf : void wil_link_off(struct wil6210_priv *wil)
buf : {
buf : 	struct net_device *ndev = wil_to_ndev(wil);
buf : 
buf : 	wil_dbg_misc(wil, "%s()\n", __func__);
buf : 
buf : 	netif_tx_stop_all_queues(ndev);
if_tx_stop_all_queues(ndev); 
buf : 	netif_carrier_off(ndev);
buf : }
buf : 
buf : static int __wil_up(struct wil6210_priv *wil)
buf : {
buf : 	struct net_device *ndev = wil_to_ndev(wil);
buf : 	struct wireless_dev *wdev = wil->wdev;
buf : 	int rc;
buf : 
buf : 	WARN_ON(!mutex_is_locked(&wil->mutex));
buf : 
buf : 	rc = wil_reset(wil);
buf : 	if (rc)
if (rc) 
buf : 		return rc;
buf : 
buf : 	/* Rx VRING. After MAC and beacon */
buf : 	rc = wil_rx_init(wil);
buf : 	if (rc)
if (rc) 
buf : 		return rc;
buf : 
buf : 	switch (wdev->iftype) {
iftype) { 
buf : 	case NL80211_IFTYPE_STATION:
buf : 		wil_dbg_misc(wil, "type: STATION\n");
buf : 		ndev->type = ARPHRD_ETHER;
buf : 		break;
buf : 	case NL80211_IFTYPE_AP:
buf : 		wil_dbg_misc(wil, "type: AP\n");
buf : 		ndev->type = ARPHRD_ETHER;
buf : 		break;
buf : 	case NL80211_IFTYPE_P2P_CLIENT:
buf : 		wil_dbg_misc(wil, "type: P2P_CLIENT\n");
buf : 		ndev->type = ARPHRD_ETHER;
buf : 		break;
buf : 	case NL80211_IFTYPE_P2P_GO:
buf : 		wil_dbg_misc(wil, "type: P2P_GO\n");
buf : 		ndev->type = ARPHRD_ETHER;
buf : 		break;
buf : 	case NL80211_IFTYPE_MONITOR:
buf : 		wil_dbg_misc(wil, "type: Monitor\n");
buf : 		ndev->type = ARPHRD_IEEE80211_RADIOTAP;
buf : 		/* ARPHRD_IEEE80211 or ARPHRD_IEEE80211_RADIOTAP ? */
buf : 		break;
buf : 	default:
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	/* MAC address - pre-requisite for other commands */
for other commands */ 
buf : 	wmi_set_mac_address(wil, ndev->dev_addr);
buf : 
buf : 
buf : 	napi_enable(&wil->napi_rx);
buf : 	napi_enable(&wil->napi_tx);
buf : 	set_bit(wil_status_napi_en, &wil->status);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int wil_up(struct wil6210_priv *wil)
buf : {
buf : 	int rc;
buf : 
buf : 	mutex_lock(&wil->mutex);
buf : 	rc = __wil_up(wil);
buf : 	mutex_unlock(&wil->mutex);
buf : 
buf : 	return rc;
buf : }
buf : 
buf : static int __wil_down(struct wil6210_priv *wil)
buf : {
buf : 	WARN_ON(!mutex_is_locked(&wil->mutex));
buf : 
buf : 	clear_bit(wil_status_napi_en, &wil->status);
buf : 	napi_disable(&wil->napi_rx);
buf : 	napi_disable(&wil->napi_tx);
buf : 
buf : 	if (wil->scan_request) {
if (wil->scan_request) { 
buf : 		del_timer_sync(&wil->scan_timer);
buf : 		cfg80211_scan_done(wil->scan_request, true);
buf : 		wil->scan_request = NULL;
buf : 	}
buf : 
buf : 	wil6210_disconnect(wil, NULL);
buf : 	wil_rx_fini(wil);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int wil_down(struct wil6210_priv *wil)
buf : {
buf : 	int rc;
buf : 
buf : 	mutex_lock(&wil->mutex);
buf : 	rc = __wil_down(wil);
buf : 	mutex_unlock(&wil->mutex);
buf : 
buf : 	return rc;
buf : }
buf : 
buf : int wil_find_cid(struct wil6210_priv *wil, const u8 *mac)
buf : {
buf : 	int i;
buf : 	int rc = -ENOENT;
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(wil->sta); i++) {
for (i = 0; i < ARRAY_SIZE(wil->sta); i++) { 
buf : 		if ((wil->sta[i].status != wil_sta_unused) &&
buf : 		    ether_addr_equal(wil->sta[i].addr, mac)) {
buf : 			rc = i;
buf : 			break;
buf : 		}
buf : 	}
buf : 
buf : 	return rc;
buf : }
file : ./test/kernel/drivers/net/wireless/ath/wcn36xx/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2013 Eugene Krasnikov <k.eugene.e@gmail.com>
buf :  *
buf :  * Permission to use, copy, modify, and/or distribute this software for any
ify, and/or distribute this software for any 
buf :  * purpose with or without fee is hereby granted, provided that the above
buf :  * copyright notice and this permission notice appear in all copies.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
buf :  * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
buf :  * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
buf :  * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
buf :  * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
buf :  * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
buf :  * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
buf :  */
buf : 
buf : #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
buf : 
buf : #include <linux/module.h>
buf : #include <linux/firmware.h>
buf : #include <linux/platform_device.h>
form_device.h> 
buf : #include "wcn36xx.h"
buf : 
buf : unsigned int wcn36xx_dbg_mask;
buf : module_param_named(debug_mask, wcn36xx_dbg_mask, uint, 0644);
buf : MODULE_PARM_DESC(debug_mask, "Debugging mask");
buf : 
buf : #define CHAN2G(_freq, _idx) { \
buf : 	.band = IEEE80211_BAND_2GHZ, \
buf : 	.center_freq = (_freq), \
buf : 	.hw_value = (_idx), \
buf : 	.max_power = 25, \
buf : }
buf : 
buf : #define CHAN5G(_freq, _idx) { \
buf : 	.band = IEEE80211_BAND_5GHZ, \
buf : 	.center_freq = (_freq), \
buf : 	.hw_value = (_idx), \
buf : 	.max_power = 25, \
buf : }
buf : 
buf : /* The wcn firmware expects channel values to matching
buf :  * their mnemonic values. So use these for .hw_value. */
for .hw_value. */ 
buf : static struct ieee80211_channel wcn_2ghz_channels[] = {
buf : 	CHAN2G(2412, 1), /* Channel 1 */
buf : 	CHAN2G(2417, 2), /* Channel 2 */
buf : 	CHAN2G(2422, 3), /* Channel 3 */
buf : 	CHAN2G(2427, 4), /* Channel 4 */
buf : 	CHAN2G(2432, 5), /* Channel 5 */
buf : 	CHAN2G(2437, 6), /* Channel 6 */
buf : 	CHAN2G(2442, 7), /* Channel 7 */
buf : 	CHAN2G(2447, 8), /* Channel 8 */
buf : 	CHAN2G(2452, 9), /* Channel 9 */
buf : 	CHAN2G(2457, 10), /* Channel 10 */
buf : 	CHAN2G(2462, 11), /* Channel 11 */
buf : 	CHAN2G(2467, 12), /* Channel 12 */
buf : 	CHAN2G(2472, 13), /* Channel 13 */
buf : 	CHAN2G(2484, 14)  /* Channel 14 */
buf : 
buf : };
buf : 
buf : static struct ieee80211_channel wcn_5ghz_channels[] = {
buf : 	CHAN5G(5180, 36),
buf : 	CHAN5G(5200, 40),
buf : 	CHAN5G(5220, 44),
buf : 	CHAN5G(5240, 48),
buf : 	CHAN5G(5260, 52),
buf : 	CHAN5G(5280, 56),
buf : 	CHAN5G(5300, 60),
buf : 	CHAN5G(5320, 64),
buf : 	CHAN5G(5500, 100),
buf : 	CHAN5G(5520, 104),
buf : 	CHAN5G(5540, 108),
buf : 	CHAN5G(5560, 112),
buf : 	CHAN5G(5580, 116),
buf : 	CHAN5G(5600, 120),
buf : 	CHAN5G(5620, 124),
buf : 	CHAN5G(5640, 128),
buf : 	CHAN5G(5660, 132),
buf : 	CHAN5G(5700, 140),
buf : 	CHAN5G(5745, 149),
buf : 	CHAN5G(5765, 153),
buf : 	CHAN5G(5785, 157),
buf : 	CHAN5G(5805, 161),
buf : 	CHAN5G(5825, 165)
buf : };
buf : 
buf : #define RATE(_bitrate, _hw_rate, _flags) { \
buf : 	.bitrate        = (_bitrate),                   \
buf : 	.flags          = (_flags),                     \
buf : 	.hw_value       = (_hw_rate),                   \
buf : 	.hw_value_short = (_hw_rate)  \
buf : }
buf : 
buf : static struct ieee80211_rate wcn_2ghz_rates[] = {
buf : 	RATE(10, HW_RATE_INDEX_1MBPS, 0),
buf : 	RATE(20, HW_RATE_INDEX_2MBPS, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATE(55, HW_RATE_INDEX_5_5MBPS, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATE(110, HW_RATE_INDEX_11MBPS, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATE(60, HW_RATE_INDEX_6MBPS, 0),
buf : 	RATE(90, HW_RATE_INDEX_9MBPS, 0),
buf : 	RATE(120, HW_RATE_INDEX_12MBPS, 0),
buf : 	RATE(180, HW_RATE_INDEX_18MBPS, 0),
buf : 	RATE(240, HW_RATE_INDEX_24MBPS, 0),
buf : 	RATE(360, HW_RATE_INDEX_36MBPS, 0),
buf : 	RATE(480, HW_RATE_INDEX_48MBPS, 0),
buf : 	RATE(540, HW_RATE_INDEX_54MBPS, 0)
buf : };
buf : 
buf : static struct ieee80211_rate wcn_5ghz_rates[] = {
buf : 	RATE(60, HW_RATE_INDEX_6MBPS, 0),
buf : 	RATE(90, HW_RATE_INDEX_9MBPS, 0),
buf : 	RATE(120, HW_RATE_INDEX_12MBPS, 0),
buf : 	RATE(180, HW_RATE_INDEX_18MBPS, 0),
buf : 	RATE(240, HW_RATE_INDEX_24MBPS, 0),
buf : 	RATE(360, HW_RATE_INDEX_36MBPS, 0),
buf : 	RATE(480, HW_RATE_INDEX_48MBPS, 0),
buf : 	RATE(540, HW_RATE_INDEX_54MBPS, 0)
buf : };
buf : 
buf : static struct ieee80211_supported_band wcn_band_2ghz = {
buf : 	.channels	= wcn_2ghz_channels,
buf : 	.n_channels	= ARRAY_SIZE(wcn_2ghz_channels),
buf : 	.bitrates	= wcn_2ghz_rates,
buf : 	.n_bitrates	= ARRAY_SIZE(wcn_2ghz_rates),
buf : 	.ht_cap		= {
buf : 		.cap =	IEEE80211_HT_CAP_GRN_FLD |
buf : 			IEEE80211_HT_CAP_SGI_20 |
buf : 			IEEE80211_HT_CAP_DSSSCCK40 |
buf : 			IEEE80211_HT_CAP_LSIG_TXOP_PROT,
buf : 		.ht_supported = true,
buf : 		.ampdu_factor = IEEE80211_HT_MAX_AMPDU_64K,
buf : 		.ampdu_density = IEEE80211_HT_MPDU_DENSITY_16,
buf : 		.mcs = {
buf : 			.rx_mask = { 0xff, 0, 0, 0, 0, 0, 0, 0, 0, 0, },
buf : 			.rx_highest = cpu_to_le16(72),
buf : 			.tx_params = IEEE80211_HT_MCS_TX_DEFINED,
buf : 		}
buf : 	}
buf : };
buf : 
buf : static struct ieee80211_supported_band wcn_band_5ghz = {
buf : 	.channels	= wcn_5ghz_channels,
buf : 	.n_channels	= ARRAY_SIZE(wcn_5ghz_channels),
buf : 	.bitrates	= wcn_5ghz_rates,
buf : 	.n_bitrates	= ARRAY_SIZE(wcn_5ghz_rates),
buf : 	.ht_cap		= {
buf : 		.cap =	IEEE80211_HT_CAP_GRN_FLD |
buf : 			IEEE80211_HT_CAP_SGI_20 |
buf : 			IEEE80211_HT_CAP_DSSSCCK40 |
buf : 			IEEE80211_HT_CAP_LSIG_TXOP_PROT |
buf : 			IEEE80211_HT_CAP_SGI_40 |
buf : 			IEEE80211_HT_CAP_SUP_WIDTH_20_40,
buf : 		.ht_supported = true,
buf : 		.ampdu_factor = IEEE80211_HT_MAX_AMPDU_64K,
buf : 		.ampdu_density = IEEE80211_HT_MPDU_DENSITY_16,
buf : 		.mcs = {
buf : 			.rx_mask = { 0xff, 0, 0, 0, 0, 0, 0, 0, 0, 0, },
buf : 			.rx_highest = cpu_to_le16(72),
buf : 			.tx_params = IEEE80211_HT_MCS_TX_DEFINED,
buf : 		}
buf : 	}
buf : };
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 
buf : static const struct wiphy_wowlan_support wowlan_support = {
buf : 	.flags = WIPHY_WOWLAN_ANY
buf : };
buf : 
buf : #endif
if 
buf : 
buf : static inline u8 get_sta_index(struct ieee80211_vif *vif,
buf : 			       struct wcn36xx_sta *sta_priv)
buf : {
buf : 	return NL80211_IFTYPE_STATION == vif->type ?
if->type ? 
buf : 	       sta_priv->bss_sta_index :
buf : 	       sta_priv->sta_index;
buf : }
buf : 
buf : static const char * const wcn36xx_caps_names[] = {
buf : 	"MCC",				/* 0 */
buf : 	"P2P",				/* 1 */
buf : 	"DOT11AC",			/* 2 */
buf : 	"SLM_SESSIONIZATION",		/* 3 */
buf : 	"DOT11AC_OPMODE",		/* 4 */
buf : 	"SAP32STA",			/* 5 */
buf : 	"TDLS",				/* 6 */
buf : 	"P2P_GO_NOA_DECOUPLE_INIT_SCAN",/* 7 */
buf : 	"WLANACTIVE_OFFLOAD",		/* 8 */
buf : 	"BEACON_OFFLOAD",		/* 9 */
buf : 	"SCAN_OFFLOAD",			/* 10 */
buf : 	"ROAM_OFFLOAD",			/* 11 */
buf : 	"BCN_MISS_OFFLOAD",		/* 12 */
buf : 	"STA_POWERSAVE",		/* 13 */
buf : 	"STA_ADVANCED_PWRSAVE",		/* 14 */
buf : 	"AP_UAPSD",			/* 15 */
buf : 	"AP_DFS",			/* 16 */
buf : 	"BLOCKACK",			/* 17 */
buf : 	"PHY_ERR",			/* 18 */
buf : 	"BCN_FILTER",			/* 19 */
buf : 	"RTT",				/* 20 */
buf : 	"RATECTRL",			/* 21 */
buf : 	"WOW"				/* 22 */
buf : };
buf : 
buf : static const char *wcn36xx_get_cap_name(enum place_holder_in_cap_bitmap x)
buf : {
buf : 	if (x >= ARRAY_SIZE(wcn36xx_caps_names))
if (x >= ARRAY_SIZE(wcn36xx_caps_names)) 
buf : 		return "UNKNOWN";
buf : 	return wcn36xx_caps_names[x];
buf : }
buf : 
buf : static void wcn36xx_feat_caps_info(struct wcn36xx *wcn)
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 0; i < MAX_FEATURE_SUPPORTED; i++) {
for (i = 0; i < MAX_FEATURE_SUPPORTED; i++) { 
buf : 		if (get_feat_caps(wcn->fw_feat_caps, i))
buf : 			wcn36xx_info("FW Cap %s\n", wcn36xx_get_cap_name(i));
buf : 	}
buf : }
buf : 
buf : static void wcn36xx_detect_chip_version(struct wcn36xx *wcn)
buf : {
buf : 	if (get_feat_caps(wcn->fw_feat_caps, DOT11AC)) {
if (get_feat_caps(wcn->fw_feat_caps, DOT11AC)) { 
buf : 		wcn36xx_info("Chip is 3680\n");
buf : 		wcn->chip_version = WCN36XX_CHIP_3680;
buf : 	} else {
buf : 		wcn36xx_info("Chip is 3660\n");
buf : 		wcn->chip_version = WCN36XX_CHIP_3660;
buf : 	}
buf : }
buf : 
buf : static int wcn36xx_start(struct ieee80211_hw *hw)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	int ret;
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac start\n");
buf : 
buf : 	/* SMD initialization */
buf : 	ret = wcn36xx_smd_open(wcn);
buf : 	if (ret) {
if (ret) { 
buf : 		wcn36xx_err("Failed to open smd channel: %d\n", ret);
buf : 		goto out_err;
buf : 	}
buf : 
buf : 	/* Allocate memory pools for Mgmt BD headers and Data BD headers */
for Mgmt BD headers and Data BD headers */ 
buf : 	ret = wcn36xx_dxe_allocate_mem_pools(wcn);
buf : 	if (ret) {
if (ret) { 
buf : 		wcn36xx_err("Failed to alloc DXE mempool: %d\n", ret);
buf : 		goto out_smd_close;
buf : 	}
buf : 
buf : 	ret = wcn36xx_dxe_alloc_ctl_blks(wcn);
buf : 	if (ret) {
if (ret) { 
buf : 		wcn36xx_err("Failed to alloc DXE ctl blocks: %d\n", ret);
buf : 		goto out_free_dxe_pool;
buf : 	}
buf : 
buf : 	wcn->hal_buf = kmalloc(WCN36XX_HAL_BUF_SIZE, GFP_KERNEL);
buf : 	if (!wcn->hal_buf) {
if (!wcn->hal_buf) { 
buf : 		wcn36xx_err("Failed to allocate smd buf\n");
buf : 		ret = -ENOMEM;
buf : 		goto out_free_dxe_ctl;
buf : 	}
buf : 
buf : 	ret = wcn36xx_smd_load_nv(wcn);
buf : 	if (ret) {
if (ret) { 
buf : 		wcn36xx_err("Failed to push NV to chip\n");
buf : 		goto out_free_smd_buf;
buf : 	}
buf : 
buf : 	ret = wcn36xx_smd_start(wcn);
buf : 	if (ret) {
if (ret) { 
buf : 		wcn36xx_err("Failed to start chip\n");
buf : 		goto out_free_smd_buf;
buf : 	}
buf : 
buf : 	if (!wcn36xx_is_fw_version(wcn, 1, 2, 2, 24)) {
if (!wcn36xx_is_fw_version(wcn, 1, 2, 2, 24)) { 
buf : 		ret = wcn36xx_smd_feature_caps_exchange(wcn);
buf : 		if (ret)
if (ret) 
buf : 			wcn36xx_warn("Exchange feature caps failed\n");
buf : 		else
buf : 			wcn36xx_feat_caps_info(wcn);
buf : 	}
buf : 
buf : 	wcn36xx_detect_chip_version(wcn);
buf : 
buf : 	/* DMA channel initialization */
buf : 	ret = wcn36xx_dxe_init(wcn);
buf : 	if (ret) {
if (ret) { 
buf : 		wcn36xx_err("DXE init failed\n");
buf : 		goto out_smd_stop;
buf : 	}
buf : 
buf : 	wcn36xx_debugfs_init(wcn);
buf : 
buf : 	INIT_LIST_HEAD(&wcn->vif_list);
if_list); 
buf : 	return 0;
buf : 
buf : out_smd_stop:
buf : 	wcn36xx_smd_stop(wcn);
buf : out_free_smd_buf:
buf : 	kfree(wcn->hal_buf);
buf : out_free_dxe_pool:
buf : 	wcn36xx_dxe_free_mem_pools(wcn);
buf : out_free_dxe_ctl:
buf : 	wcn36xx_dxe_free_ctl_blks(wcn);
buf : out_smd_close:
buf : 	wcn36xx_smd_close(wcn);
buf : out_err:
buf : 	return ret;
buf : }
buf : 
buf : static void wcn36xx_stop(struct ieee80211_hw *hw)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac stop\n");
buf : 
buf : 	wcn36xx_debugfs_exit(wcn);
buf : 	wcn36xx_smd_stop(wcn);
buf : 	wcn36xx_dxe_deinit(wcn);
buf : 	wcn36xx_smd_close(wcn);
buf : 
buf : 	wcn36xx_dxe_free_mem_pools(wcn);
buf : 	wcn36xx_dxe_free_ctl_blks(wcn);
buf : 
buf : 	kfree(wcn->hal_buf);
buf : }
buf : 
buf : static int wcn36xx_config(struct ieee80211_hw *hw, u32 changed)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	struct ieee80211_vif *vif = NULL;
if *vif = NULL; 
buf : 	struct wcn36xx_vif *tmp;
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac config changed 0x%08x\n", changed);
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_CHANNEL) {
if (changed & IEEE80211_CONF_CHANGE_CHANNEL) { 
buf : 		int ch = WCN36XX_HW_CHANNEL(wcn);
buf : 		wcn36xx_dbg(WCN36XX_DBG_MAC, "wcn36xx_config channel switch=%d\n",
buf : 			    ch);
buf : 		list_for_each_entry(tmp, &wcn->vif_list, list) {
if_list, list) { 
buf : 			vif = container_of((void *)tmp,
buf : 					   struct ieee80211_vif,
if, 
buf : 					   drv_priv);
buf : 			wcn36xx_smd_switch_channel(wcn, vif, ch);
if, ch); 
buf : 		}
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : #define WCN36XX_SUPPORTED_FILTERS (0)
buf : 
buf : static void wcn36xx_configure_filter(struct ieee80211_hw *hw,
buf : 				     unsigned int changed,
buf : 				     unsigned int *total, u64 multicast)
buf : {
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac configure filter\n");
buf : 
buf : 	*total &= WCN36XX_SUPPORTED_FILTERS;
buf : }
buf : 
buf : static void wcn36xx_tx(struct ieee80211_hw *hw,
buf : 		       struct ieee80211_tx_control *control,
buf : 		       struct sk_buff *skb)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	struct wcn36xx_sta *sta_priv = NULL;
buf : 
buf : 	if (control->sta)
if (control->sta) 
buf : 		sta_priv = (struct wcn36xx_sta *)control->sta->drv_priv;
buf : 
buf : 	if (wcn36xx_start_tx(wcn, sta_priv, skb))
if (wcn36xx_start_tx(wcn, sta_priv, skb)) 
buf : 		ieee80211_free_txskb(wcn->hw, skb);
buf : }
buf : 
buf : static int wcn36xx_set_key(struct ieee80211_hw *hw, enum set_key_cmd cmd,
buf : 			   struct ieee80211_vif *vif,
if *vif, 
buf : 			   struct ieee80211_sta *sta,
buf : 			   struct ieee80211_key_conf *key_conf)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	struct wcn36xx_vif *vif_priv = (struct wcn36xx_vif *)vif->drv_priv;
if *vif_priv = (struct wcn36xx_vif *)vif->drv_priv; 
buf : 	struct wcn36xx_sta *sta_priv = vif_priv->sta;
buf : 	int ret = 0;
buf : 	u8 key[WLAN_MAX_KEY_LEN];
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac80211 set key\n");
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "Key: cmd=0x%x algo:0x%x, id:%d, len:%d flags 0x%x\n",
buf : 		    cmd, key_conf->cipher, key_conf->keyidx,
buf : 		    key_conf->keylen, key_conf->flags);
buf : 	wcn36xx_dbg_dump(WCN36XX_DBG_MAC, "KEY: ",
buf : 			 key_conf->key,
buf : 			 key_conf->keylen);
buf : 
buf : 	switch (key_conf->cipher) {
buf : 	case WLAN_CIPHER_SUITE_WEP40:
buf : 		vif_priv->encrypt_type = WCN36XX_HAL_ED_WEP40;
if_priv->encrypt_type = WCN36XX_HAL_ED_WEP40; 
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_WEP104:
buf : 		vif_priv->encrypt_type = WCN36XX_HAL_ED_WEP40;
if_priv->encrypt_type = WCN36XX_HAL_ED_WEP40; 
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_CCMP:
buf : 		vif_priv->encrypt_type = WCN36XX_HAL_ED_CCMP;
if_priv->encrypt_type = WCN36XX_HAL_ED_CCMP; 
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_TKIP:
buf : 		vif_priv->encrypt_type = WCN36XX_HAL_ED_TKIP;
if_priv->encrypt_type = WCN36XX_HAL_ED_TKIP; 
buf : 		break;
buf : 	default:
buf : 		wcn36xx_err("Unsupported key type 0x%x\n",
buf : 			      key_conf->cipher);
buf : 		ret = -EOPNOTSUPP;
buf : 		goto out;
buf : 	}
buf : 
buf : 	switch (cmd) {
buf : 	case SET_KEY:
buf : 		if (WCN36XX_HAL_ED_TKIP == vif_priv->encrypt_type) {
if (WCN36XX_HAL_ED_TKIP == vif_priv->encrypt_type) { 
buf : 			/*
buf : 			 * Supplicant is sending key in the wrong order:
buf : 			 * Temporal Key (16 b) - TX MIC (8 b) - RX MIC (8 b)
buf : 			 * but HW expects it to be in the order as described in
buf : 			 * IEEE 802.11 spec (see chapter 11.7) like this:
buf : 			 * Temporal Key (16 b) - RX MIC (8 b) - TX MIC (8 b)
buf : 			 */
buf : 			memcpy(key, key_conf->key, 16);
buf : 			memcpy(key + 16, key_conf->key + 24, 8);
buf : 			memcpy(key + 24, key_conf->key + 16, 8);
buf : 		} else {
buf : 			memcpy(key, key_conf->key, key_conf->keylen);
buf : 		}
buf : 
buf : 		if (IEEE80211_KEY_FLAG_PAIRWISE & key_conf->flags) {
if (IEEE80211_KEY_FLAG_PAIRWISE & key_conf->flags) { 
buf : 			sta_priv->is_data_encrypted = true;
buf : 			/* Reconfigure bss with encrypt_type */
buf : 			if (NL80211_IFTYPE_STATION == vif->type)
if (NL80211_IFTYPE_STATION == vif->type) 
buf : 				wcn36xx_smd_config_bss(wcn,
buf : 						       vif,
if, 
buf : 						       sta,
buf : 						       sta->addr,
buf : 						       true);
buf : 
buf : 			wcn36xx_smd_set_stakey(wcn,
buf : 				vif_priv->encrypt_type,
if_priv->encrypt_type, 
buf : 				key_conf->keyidx,
buf : 				key_conf->keylen,
buf : 				key,
buf : 				get_sta_index(vif, sta_priv));
if, sta_priv)); 
buf : 		} else {
buf : 			wcn36xx_smd_set_bsskey(wcn,
buf : 				vif_priv->encrypt_type,
if_priv->encrypt_type, 
buf : 				key_conf->keyidx,
buf : 				key_conf->keylen,
buf : 				key);
buf : 			if ((WLAN_CIPHER_SUITE_WEP40 == key_conf->cipher) ||
if ((WLAN_CIPHER_SUITE_WEP40 == key_conf->cipher) || 
buf : 			    (WLAN_CIPHER_SUITE_WEP104 == key_conf->cipher)) {
buf : 				sta_priv->is_data_encrypted = true;
buf : 				wcn36xx_smd_set_stakey(wcn,
buf : 					vif_priv->encrypt_type,
if_priv->encrypt_type, 
buf : 					key_conf->keyidx,
buf : 					key_conf->keylen,
buf : 					key,
buf : 					get_sta_index(vif, sta_priv));
if, sta_priv)); 
buf : 			}
buf : 		}
buf : 		break;
buf : 	case DISABLE_KEY:
buf : 		if (!(IEEE80211_KEY_FLAG_PAIRWISE & key_conf->flags)) {
if (!(IEEE80211_KEY_FLAG_PAIRWISE & key_conf->flags)) { 
buf : 			wcn36xx_smd_remove_bsskey(wcn,
buf : 				vif_priv->encrypt_type,
if_priv->encrypt_type, 
buf : 				key_conf->keyidx);
buf : 		} else {
buf : 			sta_priv->is_data_encrypted = false;
buf : 			/* do not remove key if disassociated */
if disassociated */ 
buf : 			if (sta_priv->aid)
buf : 				wcn36xx_smd_remove_stakey(wcn,
buf : 					vif_priv->encrypt_type,
if_priv->encrypt_type, 
buf : 					key_conf->keyidx,
buf : 					get_sta_index(vif, sta_priv));
if, sta_priv)); 
buf : 		}
buf : 		break;
buf : 	default:
buf : 		wcn36xx_err("Unsupported key cmd 0x%x\n", cmd);
buf : 		ret = -EOPNOTSUPP;
buf : 		goto out;
buf : 		break;
buf : 	}
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static void wcn36xx_sw_scan_start(struct ieee80211_hw *hw)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 
buf : 	wcn36xx_smd_init_scan(wcn, HAL_SYS_MODE_SCAN);
buf : 	wcn36xx_smd_start_scan(wcn);
buf : }
buf : 
buf : static void wcn36xx_sw_scan_complete(struct ieee80211_hw *hw)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 
buf : 	wcn36xx_smd_end_scan(wcn);
buf : 	wcn36xx_smd_finish_scan(wcn, HAL_SYS_MODE_SCAN);
buf : }
buf : 
buf : static void wcn36xx_update_allowed_rates(struct ieee80211_sta *sta,
buf : 					 enum ieee80211_band band)
buf : {
buf : 	int i, size;
buf : 	u16 *rates_table;
buf : 	struct wcn36xx_sta *sta_priv = (struct wcn36xx_sta *)sta->drv_priv;
buf : 	u32 rates = sta->supp_rates[band];
buf : 
buf : 	memset(&sta_priv->supported_rates, 0,
buf : 		sizeof(sta_priv->supported_rates));
buf : 	sta_priv->supported_rates.op_rate_mode = STA_11n;
buf : 
buf : 	size = ARRAY_SIZE(sta_priv->supported_rates.dsss_rates);
buf : 	rates_table = sta_priv->supported_rates.dsss_rates;
buf : 	if (band == IEEE80211_BAND_2GHZ) {
if (band == IEEE80211_BAND_2GHZ) { 
buf : 		for (i = 0; i < size; i++) {
for (i = 0; i < size; i++) { 
buf : 			if (rates & 0x01) {
buf : 				rates_table[i] = wcn_2ghz_rates[i].hw_value;
buf : 				rates = rates >> 1;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	size = ARRAY_SIZE(sta_priv->supported_rates.ofdm_rates);
buf : 	rates_table = sta_priv->supported_rates.ofdm_rates;
buf : 	for (i = 0; i < size; i++) {
for (i = 0; i < size; i++) { 
buf : 		if (rates & 0x01) {
buf : 			rates_table[i] = wcn_5ghz_rates[i].hw_value;
buf : 			rates = rates >> 1;
buf : 		}
buf : 	}
buf : 
buf : 	if (sta->ht_cap.ht_supported) {
if (sta->ht_cap.ht_supported) { 
buf : 		BUILD_BUG_ON(sizeof(sta->ht_cap.mcs.rx_mask) >
buf : 			sizeof(sta_priv->supported_rates.supported_mcs_set));
buf : 		memcpy(sta_priv->supported_rates.supported_mcs_set,
buf : 		       sta->ht_cap.mcs.rx_mask,
buf : 		       sizeof(sta->ht_cap.mcs.rx_mask));
buf : 	}
buf : }
buf : void wcn36xx_set_default_rates(struct wcn36xx_hal_supported_rates *rates)
buf : {
buf : 	u16 ofdm_rates[WCN36XX_HAL_NUM_OFDM_RATES] = {
buf : 		HW_RATE_INDEX_6MBPS,
buf : 		HW_RATE_INDEX_9MBPS,
buf : 		HW_RATE_INDEX_12MBPS,
buf : 		HW_RATE_INDEX_18MBPS,
buf : 		HW_RATE_INDEX_24MBPS,
buf : 		HW_RATE_INDEX_36MBPS,
buf : 		HW_RATE_INDEX_48MBPS,
buf : 		HW_RATE_INDEX_54MBPS
buf : 	};
buf : 	u16 dsss_rates[WCN36XX_HAL_NUM_DSSS_RATES] = {
buf : 		HW_RATE_INDEX_1MBPS,
buf : 		HW_RATE_INDEX_2MBPS,
buf : 		HW_RATE_INDEX_5_5MBPS,
buf : 		HW_RATE_INDEX_11MBPS
buf : 	};
buf : 
buf : 	rates->op_rate_mode = STA_11n;
buf : 	memcpy(rates->dsss_rates, dsss_rates,
buf : 		sizeof(*dsss_rates) * WCN36XX_HAL_NUM_DSSS_RATES);
buf : 	memcpy(rates->ofdm_rates, ofdm_rates,
buf : 		sizeof(*ofdm_rates) * WCN36XX_HAL_NUM_OFDM_RATES);
buf : 	rates->supported_mcs_set[0] = 0xFF;
buf : }
buf : static void wcn36xx_bss_info_changed(struct ieee80211_hw *hw,
buf : 				     struct ieee80211_vif *vif,
if *vif, 
buf : 				     struct ieee80211_bss_conf *bss_conf,
buf : 				     u32 changed)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	struct sk_buff *skb = NULL;
buf : 	u16 tim_off, tim_len;
buf : 	enum wcn36xx_hal_link_state link_state;
buf : 	struct wcn36xx_vif *vif_priv = (struct wcn36xx_vif *)vif->drv_priv;
if *vif_priv = (struct wcn36xx_vif *)vif->drv_priv; 
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac bss info changed vif %p changed 0x%08x\n",
buf : 		    vif, changed);
if, changed); 
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON_INFO) {
buf : 		wcn36xx_dbg(WCN36XX_DBG_MAC,
buf : 			    "mac bss changed dtim period %d\n",
buf : 			    bss_conf->dtim_period);
buf : 
buf : 		vif_priv->dtim_period = bss_conf->dtim_period;
if_priv->dtim_period = bss_conf->dtim_period; 
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_PS) {
buf : 		wcn36xx_dbg(WCN36XX_DBG_MAC,
buf : 			    "mac bss PS set %d\n",
buf : 			    bss_conf->ps);
buf : 		if (bss_conf->ps) {
if (bss_conf->ps) { 
buf : 			wcn36xx_pmc_enter_bmps_state(wcn, vif);
buf : 		} else {
buf : 			wcn36xx_pmc_exit_bmps_state(wcn, vif);
if); 
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_BSSID) {
if (changed & BSS_CHANGED_BSSID) { 
buf : 		wcn36xx_dbg(WCN36XX_DBG_MAC, "mac bss changed_bssid %pM\n",
buf : 			    bss_conf->bssid);
buf : 
buf : 		if (!is_zero_ether_addr(bss_conf->bssid)) {
if (!is_zero_ether_addr(bss_conf->bssid)) { 
buf : 			vif_priv->is_joining = true;
buf : 			vif_priv->bss_index = 0xff;
if_priv->bss_index = 0xff; 
buf : 			wcn36xx_smd_join(wcn, bss_conf->bssid,
buf : 					 vif->addr, WCN36XX_HW_CHANNEL(wcn));
if->addr, WCN36XX_HW_CHANNEL(wcn)); 
buf : 			wcn36xx_smd_config_bss(wcn, vif, NULL,
buf : 					       bss_conf->bssid, false);
buf : 		} else {
buf : 			vif_priv->is_joining = false;
if_priv->is_joining = false; 
buf : 			wcn36xx_smd_delete_bss(wcn, vif);
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_SSID) {
if (changed & BSS_CHANGED_SSID) { 
buf : 		wcn36xx_dbg(WCN36XX_DBG_MAC,
buf : 			    "mac bss changed ssid\n");
buf : 		wcn36xx_dbg_dump(WCN36XX_DBG_MAC, "ssid ",
buf : 				 bss_conf->ssid, bss_conf->ssid_len);
buf : 
buf : 		vif_priv->ssid.length = bss_conf->ssid_len;
if_priv->ssid.length = bss_conf->ssid_len; 
buf : 		memcpy(&vif_priv->ssid.ssid,
buf : 		       bss_conf->ssid,
buf : 		       bss_conf->ssid_len);
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ASSOC) {
if (changed & BSS_CHANGED_ASSOC) { 
buf : 		vif_priv->is_joining = false;
buf : 		if (bss_conf->assoc) {
if (bss_conf->assoc) { 
buf : 			struct ieee80211_sta *sta;
buf : 			struct wcn36xx_sta *sta_priv;
buf : 
buf : 			wcn36xx_dbg(WCN36XX_DBG_MAC,
buf : 				    "mac assoc bss %pM vif %pM AID=%d\n",
if %pM AID=%d\n", 
buf : 				     bss_conf->bssid,
buf : 				     vif->addr,
if->addr, 
buf : 				     bss_conf->aid);
buf : 
buf : 			rcu_read_lock();
buf : 			sta = ieee80211_find_sta(vif, bss_conf->bssid);
if, bss_conf->bssid); 
buf : 			if (!sta) {
buf : 				wcn36xx_err("sta %pM is not found\n",
buf : 					      bss_conf->bssid);
buf : 				rcu_read_unlock();
buf : 				goto out;
buf : 			}
buf : 			sta_priv = (struct wcn36xx_sta *)sta->drv_priv;
buf : 
buf : 			wcn36xx_update_allowed_rates(sta, WCN36XX_BAND(wcn));
buf : 
buf : 			wcn36xx_smd_set_link_st(wcn, bss_conf->bssid,
buf : 				vif->addr,
if->addr, 
buf : 				WCN36XX_HAL_LINK_POSTASSOC_STATE);
buf : 			wcn36xx_smd_config_bss(wcn, vif, sta,
if, sta, 
buf : 					       bss_conf->bssid,
buf : 					       true);
buf : 			sta_priv->aid = bss_conf->aid;
buf : 			/*
buf : 			 * config_sta must be called from  because this is the
buf : 			 * place where AID is available.
buf : 			 */
buf : 			wcn36xx_smd_config_sta(wcn, vif, sta);
if, sta); 
buf : 			rcu_read_unlock();
buf : 		} else {
buf : 			wcn36xx_dbg(WCN36XX_DBG_MAC,
buf : 				    "disassociated bss %pM vif %pM AID=%d\n",
if %pM AID=%d\n", 
buf : 				    bss_conf->bssid,
buf : 				    vif->addr,
if->addr, 
buf : 				    bss_conf->aid);
buf : 			wcn36xx_smd_set_link_st(wcn,
buf : 						bss_conf->bssid,
buf : 						vif->addr,
if->addr, 
buf : 						WCN36XX_HAL_LINK_IDLE_STATE);
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_AP_PROBE_RESP) {
if (changed & BSS_CHANGED_AP_PROBE_RESP) { 
buf : 		wcn36xx_dbg(WCN36XX_DBG_MAC, "mac bss changed ap probe resp\n");
buf : 		skb = ieee80211_proberesp_get(hw, vif);
if); 
buf : 		if (!skb) {
buf : 			wcn36xx_err("failed to alloc probereq skb\n");
buf : 			goto out;
buf : 		}
buf : 
buf : 		wcn36xx_smd_update_proberesp_tmpl(wcn, vif, skb);
if, skb); 
buf : 		dev_kfree_skb(skb);
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON_ENABLED ||
if (changed & BSS_CHANGED_BEACON_ENABLED || 
buf : 	    changed & BSS_CHANGED_BEACON) {
buf : 		wcn36xx_dbg(WCN36XX_DBG_MAC,
buf : 			    "mac bss changed beacon enabled %d\n",
buf : 			    bss_conf->enable_beacon);
buf : 
buf : 		if (bss_conf->enable_beacon) {
if (bss_conf->enable_beacon) { 
buf : 			vif_priv->dtim_period = bss_conf->dtim_period;
buf : 			vif_priv->bss_index = 0xff;
if_priv->bss_index = 0xff; 
buf : 			wcn36xx_smd_config_bss(wcn, vif, NULL,
buf : 					       vif->addr, false);
if->addr, false); 
buf : 			skb = ieee80211_beacon_get_tim(hw, vif, &tim_off,
buf : 						       &tim_len);
buf : 			if (!skb) {
if (!skb) { 
buf : 				wcn36xx_err("failed to alloc beacon skb\n");
buf : 				goto out;
buf : 			}
buf : 			wcn36xx_smd_send_beacon(wcn, vif, skb, tim_off, 0);
if, skb, tim_off, 0); 
buf : 			dev_kfree_skb(skb);
buf : 
buf : 			if (vif->type == NL80211_IFTYPE_ADHOC ||
if (vif->type == NL80211_IFTYPE_ADHOC || 
buf : 			    vif->type == NL80211_IFTYPE_MESH_POINT)
buf : 				link_state = WCN36XX_HAL_LINK_IBSS_STATE;
buf : 			else
buf : 				link_state = WCN36XX_HAL_LINK_AP_STATE;
buf : 
buf : 			wcn36xx_smd_set_link_st(wcn, vif->addr, vif->addr,
if->addr, vif->addr, 
buf : 						link_state);
buf : 		} else {
buf : 			wcn36xx_smd_set_link_st(wcn, vif->addr, vif->addr,
if->addr, vif->addr, 
buf : 						WCN36XX_HAL_LINK_IDLE_STATE);
buf : 			wcn36xx_smd_delete_bss(wcn, vif);
if); 
buf : 		}
buf : 	}
buf : out:
buf : 	return;
buf : }
buf : 
buf : /* this is required when using IEEE80211_HW_HAS_RATE_CONTROL */
buf : static int wcn36xx_set_rts_threshold(struct ieee80211_hw *hw, u32 value)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac set RTS threshold %d\n", value);
buf : 
buf : 	wcn36xx_smd_update_cfg(wcn, WCN36XX_HAL_CFG_RTS_THRESHOLD, value);
buf : 	return 0;
buf : }
buf : 
buf : static void wcn36xx_remove_interface(struct ieee80211_hw *hw,
buf : 				     struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	struct wcn36xx_vif *vif_priv = (struct wcn36xx_vif *)vif->drv_priv;
if *vif_priv = (struct wcn36xx_vif *)vif->drv_priv; 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac remove interface vif %p\n", vif);
buf : 
buf : 	list_del(&vif_priv->list);
if_priv->list); 
buf : 	wcn36xx_smd_delete_sta_self(wcn, vif->addr);
buf : }
buf : 
buf : static int wcn36xx_add_interface(struct ieee80211_hw *hw,
buf : 				 struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	struct wcn36xx_vif *vif_priv = (struct wcn36xx_vif *)vif->drv_priv;
if *vif_priv = (struct wcn36xx_vif *)vif->drv_priv; 
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac add interface vif %p type %d\n",
buf : 		    vif, vif->type);
if, vif->type); 
buf : 
buf : 	if (!(NL80211_IFTYPE_STATION == vif->type ||
buf : 	      NL80211_IFTYPE_AP == vif->type ||
if->type || 
buf : 	      NL80211_IFTYPE_ADHOC == vif->type ||
buf : 	      NL80211_IFTYPE_MESH_POINT == vif->type)) {
if->type)) { 
buf : 		wcn36xx_warn("Unsupported interface type requested: %d\n",
buf : 			     vif->type);
if->type); 
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	list_add(&vif_priv->list, &wcn->vif_list);
if_priv->list, &wcn->vif_list); 
buf : 	wcn36xx_smd_add_sta_self(wcn, vif);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wcn36xx_sta_add(struct ieee80211_hw *hw, struct ieee80211_vif *vif,
if *vif, 
buf : 			   struct ieee80211_sta *sta)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	struct wcn36xx_vif *vif_priv = (struct wcn36xx_vif *)vif->drv_priv;
if *vif_priv = (struct wcn36xx_vif *)vif->drv_priv; 
buf : 	struct wcn36xx_sta *sta_priv = (struct wcn36xx_sta *)sta->drv_priv;
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac sta add vif %p sta %pM\n",
if %p sta %pM\n", 
buf : 		    vif, sta->addr);
buf : 
buf : 	vif_priv->sta = sta_priv;
if_priv->sta = sta_priv; 
buf : 	sta_priv->vif = vif_priv;
buf : 	/*
buf : 	 * For STA mode HW will be configured on BSS_CHANGED_ASSOC because
buf : 	 * at this stage AID is not available yet.
buf : 	 */
buf : 	if (NL80211_IFTYPE_STATION != vif->type) {
if (NL80211_IFTYPE_STATION != vif->type) { 
buf : 		wcn36xx_update_allowed_rates(sta, WCN36XX_BAND(wcn));
buf : 		sta_priv->aid = sta->aid;
buf : 		wcn36xx_smd_config_sta(wcn, vif, sta);
if, sta); 
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static int wcn36xx_sta_remove(struct ieee80211_hw *hw,
buf : 			      struct ieee80211_vif *vif,
if *vif, 
buf : 			      struct ieee80211_sta *sta)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	struct wcn36xx_vif *vif_priv = (struct wcn36xx_vif *)vif->drv_priv;
if *vif_priv = (struct wcn36xx_vif *)vif->drv_priv; 
buf : 	struct wcn36xx_sta *sta_priv = (struct wcn36xx_sta *)sta->drv_priv;
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac sta remove vif %p sta %pM index %d\n",
if %p sta %pM index %d\n", 
buf : 		    vif, sta->addr, sta_priv->sta_index);
buf : 
buf : 	wcn36xx_smd_delete_sta(wcn, sta_priv->sta_index);
buf : 	vif_priv->sta = NULL;
if_priv->sta = NULL; 
buf : 	sta_priv->vif = NULL;
buf : 	return 0;
buf : }
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 
buf : static int wcn36xx_suspend(struct ieee80211_hw *hw, struct cfg80211_wowlan *wow)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac suspend\n");
buf : 
buf : 	flush_workqueue(wcn->hal_ind_wq);
buf : 	wcn36xx_smd_set_power_params(wcn, true);
buf : 	return 0;
buf : }
buf : 
buf : static int wcn36xx_resume(struct ieee80211_hw *hw)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac resume\n");
buf : 
buf : 	flush_workqueue(wcn->hal_ind_wq);
buf : 	wcn36xx_smd_set_power_params(wcn, false);
buf : 	return 0;
buf : }
buf : 
buf : #endif
if 
buf : 
buf : static int wcn36xx_ampdu_action(struct ieee80211_hw *hw,
buf : 		    struct ieee80211_vif *vif,
if *vif, 
buf : 		    enum ieee80211_ampdu_mlme_action action,
buf : 		    struct ieee80211_sta *sta, u16 tid, u16 *ssn,
buf : 		    u8 buf_size)
buf : {
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	struct wcn36xx_sta *sta_priv = NULL;
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "mac ampdu action action %d tid %d\n",
buf : 		    action, tid);
buf : 
buf : 	sta_priv = (struct wcn36xx_sta *)sta->drv_priv;
buf : 
buf : 	switch (action) {
buf : 	case IEEE80211_AMPDU_RX_START:
buf : 		sta_priv->tid = tid;
buf : 		wcn36xx_smd_add_ba_session(wcn, sta, tid, ssn, 0,
buf : 			get_sta_index(vif, sta_priv));
if, sta_priv)); 
buf : 		wcn36xx_smd_add_ba(wcn);
buf : 		wcn36xx_smd_trigger_ba(wcn, get_sta_index(vif, sta_priv));
if, sta_priv)); 
buf : 		ieee80211_start_tx_ba_session(sta, tid, 0);
buf : 		break;
buf : 	case IEEE80211_AMPDU_RX_STOP:
buf : 		wcn36xx_smd_del_ba(wcn, tid, get_sta_index(vif, sta_priv));
if, sta_priv)); 
buf : 		break;
buf : 	case IEEE80211_AMPDU_TX_START:
buf : 		ieee80211_start_tx_ba_cb_irqsafe(vif, sta->addr, tid);
if, sta->addr, tid); 
buf : 		break;
buf : 	case IEEE80211_AMPDU_TX_OPERATIONAL:
buf : 		wcn36xx_smd_add_ba_session(wcn, sta, tid, ssn, 1,
buf : 			get_sta_index(vif, sta_priv));
if, sta_priv)); 
buf : 		break;
buf : 	case IEEE80211_AMPDU_TX_STOP_FLUSH:
buf : 	case IEEE80211_AMPDU_TX_STOP_FLUSH_CONT:
buf : 	case IEEE80211_AMPDU_TX_STOP_CONT:
buf : 		ieee80211_stop_tx_ba_cb_irqsafe(vif, sta->addr, tid);
if, sta->addr, tid); 
buf : 		break;
buf : 	default:
buf : 		wcn36xx_err("Unknown AMPDU action\n");
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static const struct ieee80211_ops wcn36xx_ops = {
buf : 	.start			= wcn36xx_start,
buf : 	.stop			= wcn36xx_stop,
buf : 	.add_interface		= wcn36xx_add_interface,
buf : 	.remove_interface	= wcn36xx_remove_interface,
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 	.suspend		= wcn36xx_suspend,
buf : 	.resume			= wcn36xx_resume,
buf : #endif
if 
buf : 	.config			= wcn36xx_config,
buf : 	.configure_filter       = wcn36xx_configure_filter,
buf : 	.tx			= wcn36xx_tx,
buf : 	.set_key		= wcn36xx_set_key,
buf : 	.sw_scan_start		= wcn36xx_sw_scan_start,
buf : 	.sw_scan_complete	= wcn36xx_sw_scan_complete,
buf : 	.bss_info_changed	= wcn36xx_bss_info_changed,
buf : 	.set_rts_threshold	= wcn36xx_set_rts_threshold,
buf : 	.sta_add		= wcn36xx_sta_add,
buf : 	.sta_remove		= wcn36xx_sta_remove,
buf : 	.ampdu_action		= wcn36xx_ampdu_action,
buf : };
buf : 
buf : static int wcn36xx_init_ieee80211(struct wcn36xx *wcn)
buf : {
buf : 	int ret = 0;
buf : 
buf : 	static const u32 cipher_suites[] = {
buf : 		WLAN_CIPHER_SUITE_WEP40,
buf : 		WLAN_CIPHER_SUITE_WEP104,
buf : 		WLAN_CIPHER_SUITE_TKIP,
buf : 		WLAN_CIPHER_SUITE_CCMP,
buf : 	};
buf : 
buf : 	wcn->hw->flags = IEEE80211_HW_SIGNAL_DBM |
buf : 		IEEE80211_HW_HAS_RATE_CONTROL |
buf : 		IEEE80211_HW_SUPPORTS_PS |
buf : 		IEEE80211_HW_CONNECTION_MONITOR |
buf : 		IEEE80211_HW_AMPDU_AGGREGATION |
buf : 		IEEE80211_HW_TIMING_BEACON_ONLY;
buf : 
buf : 	wcn->hw->wiphy->interface_modes = BIT(NL80211_IFTYPE_STATION) |
buf : 		BIT(NL80211_IFTYPE_AP) |
buf : 		BIT(NL80211_IFTYPE_ADHOC) |
buf : 		BIT(NL80211_IFTYPE_MESH_POINT);
buf : 
buf : 	wcn->hw->wiphy->bands[IEEE80211_BAND_2GHZ] = &wcn_band_2ghz;
buf : 	wcn->hw->wiphy->bands[IEEE80211_BAND_5GHZ] = &wcn_band_5ghz;
buf : 
buf : 	wcn->hw->wiphy->cipher_suites = cipher_suites;
buf : 	wcn->hw->wiphy->n_cipher_suites = ARRAY_SIZE(cipher_suites);
buf : 
buf : 	wcn->hw->wiphy->flags |= WIPHY_FLAG_AP_PROBE_RESP_OFFLOAD;
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 	wcn->hw->wiphy->wowlan = &wowlan_support;
buf : #endif
if 
buf : 
buf : 	wcn->hw->max_listen_interval = 200;
buf : 
buf : 	wcn->hw->queues = 4;
buf : 
buf : 	SET_IEEE80211_DEV(wcn->hw, wcn->dev);
buf : 
buf : 	wcn->hw->sta_data_size = sizeof(struct wcn36xx_sta);
buf : 	wcn->hw->vif_data_size = sizeof(struct wcn36xx_vif);
if_data_size = sizeof(struct wcn36xx_vif); 
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wcn36xx_platform_get_resources(struct wcn36xx *wcn,
form_get_resources(struct wcn36xx *wcn, 
buf : 					  struct platform_device *pdev)
buf : {
buf : 	struct resource *res;
buf : 	/* Set TX IRQ */
buf : 	res = platform_get_resource_byname(pdev, IORESOURCE_IRQ,
form_get_resource_byname(pdev, IORESOURCE_IRQ, 
buf : 					   "wcnss_wlantx_irq");
buf : 	if (!res) {
if (!res) { 
buf : 		wcn36xx_err("failed to get tx_irq\n");
buf : 		return -ENOENT;
buf : 	}
buf : 	wcn->tx_irq = res->start;
buf : 
buf : 	/* Set RX IRQ */
buf : 	res = platform_get_resource_byname(pdev, IORESOURCE_IRQ,
form_get_resource_byname(pdev, IORESOURCE_IRQ, 
buf : 					   "wcnss_wlanrx_irq");
buf : 	if (!res) {
if (!res) { 
buf : 		wcn36xx_err("failed to get rx_irq\n");
buf : 		return -ENOENT;
buf : 	}
buf : 	wcn->rx_irq = res->start;
buf : 
buf : 	/* Map the memory */
buf : 	res = platform_get_resource_byname(pdev, IORESOURCE_MEM,
form_get_resource_byname(pdev, IORESOURCE_MEM, 
buf : 						 "wcnss_mmio");
buf : 	if (!res) {
if (!res) { 
buf : 		wcn36xx_err("failed to get mmio\n");
buf : 		return -ENOENT;
buf : 	}
buf : 	wcn->mmio = ioremap(res->start, resource_size(res));
buf : 	if (!wcn->mmio) {
if (!wcn->mmio) { 
buf : 		wcn36xx_err("failed to map io memory\n");
buf : 		return -ENOMEM;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static int wcn36xx_probe(struct platform_device *pdev)
form_device *pdev) 
buf : {
buf : 	struct ieee80211_hw *hw;
buf : 	struct wcn36xx *wcn;
buf : 	int ret;
buf : 	u8 addr[ETH_ALEN];
buf : 
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "platform probe\n");
form probe\n"); 
buf : 
buf : 	hw = ieee80211_alloc_hw(sizeof(struct wcn36xx), &wcn36xx_ops);
buf : 	if (!hw) {
if (!hw) { 
buf : 		wcn36xx_err("failed to alloc hw\n");
buf : 		ret = -ENOMEM;
buf : 		goto out_err;
buf : 	}
buf : 	platform_set_drvdata(pdev, hw);
form_set_drvdata(pdev, hw); 
buf : 	wcn = hw->priv;
buf : 	wcn->hw = hw;
buf : 	wcn->dev = &pdev->dev;
buf : 	wcn->ctrl_ops = pdev->dev.platform_data;
form_data; 
buf : 
buf : 	mutex_init(&wcn->hal_mutex);
buf : 
buf : 	if (!wcn->ctrl_ops->get_hw_mac(addr)) {
if (!wcn->ctrl_ops->get_hw_mac(addr)) { 
buf : 		wcn36xx_info("mac address: %pM\n", addr);
buf : 		SET_IEEE80211_PERM_ADDR(wcn->hw, addr);
buf : 	}
buf : 
buf : 	ret = wcn36xx_platform_get_resources(wcn, pdev);
form_get_resources(wcn, pdev); 
buf : 	if (ret)
buf : 		goto out_wq;
buf : 
buf : 	wcn36xx_init_ieee80211(wcn);
buf : 	ret = ieee80211_register_hw(wcn->hw);
buf : 	if (ret)
if (ret) 
buf : 		goto out_unmap;
buf : 
buf : 	return 0;
buf : 
buf : out_unmap:
buf : 	iounmap(wcn->mmio);
buf : out_wq:
buf : 	ieee80211_free_hw(hw);
buf : out_err:
buf : 	return ret;
buf : }
buf : static int wcn36xx_remove(struct platform_device *pdev)
form_device *pdev) 
buf : {
buf : 	struct ieee80211_hw *hw = platform_get_drvdata(pdev);
buf : 	struct wcn36xx *wcn = hw->priv;
buf : 	wcn36xx_dbg(WCN36XX_DBG_MAC, "platform remove\n");
form remove\n"); 
buf : 
buf : 	release_firmware(wcn->nv);
buf : 	mutex_destroy(&wcn->hal_mutex);
buf : 
buf : 	ieee80211_unregister_hw(hw);
buf : 	iounmap(wcn->mmio);
buf : 	ieee80211_free_hw(hw);
buf : 
buf : 	return 0;
buf : }
buf : static const struct platform_device_id wcn36xx_platform_id_table[] = {
form_device_id wcn36xx_platform_id_table[] = { 
buf : 	{
buf : 		.name = "wcn36xx",
buf : 		.driver_data = 0
buf : 	},
buf : 	{}
buf : };
buf : MODULE_DEVICE_TABLE(platform, wcn36xx_platform_id_table);
form, wcn36xx_platform_id_table); 
buf : 
buf : static struct platform_driver wcn36xx_driver = {
buf : 	.probe      = wcn36xx_probe,
buf : 	.remove     = wcn36xx_remove,
buf : 	.driver         = {
buf : 		.name   = "wcn36xx",
buf : 		.owner  = THIS_MODULE,
buf : 	},
buf : 	.id_table    = wcn36xx_platform_id_table,
form_id_table, 
buf : };
buf : 
buf : static int __init wcn36xx_init(void)
buf : {
buf : 	platform_driver_register(&wcn36xx_driver);
form_driver_register(&wcn36xx_driver); 
buf : 	return 0;
buf : }
buf : module_init(wcn36xx_init);
buf : 
buf : static void __exit wcn36xx_exit(void)
buf : {
buf : 	platform_driver_unregister(&wcn36xx_driver);
form_driver_unregister(&wcn36xx_driver); 
buf : }
buf : module_exit(wcn36xx_exit);
buf : 
buf : MODULE_LICENSE("Dual BSD/GPL");
buf : MODULE_AUTHOR("Eugene Krasnikov k.eugene.e@gmail.com");
buf : MODULE_FIRMWARE(WLAN_NV_FILE);
file : ./test/kernel/drivers/net/wireless/b43legacy/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  *
buf :  *  Broadcom B43legacy wireless driver
buf :  *
buf :  *  Copyright (c) 2005 Martin Langer <martin-langer@gmx.de>
buf :  *  Copyright (c) 2005-2008 Stefano Brivio <stefano.brivio@polimi.it>
buf :  *  Copyright (c) 2005, 2006 Michael Buesch <m@bues.ch>
buf :  *  Copyright (c) 2005 Danny van Dyk <kugelfang@gentoo.org>
buf :  *  Copyright (c) 2005 Andreas Jaggi <andreas.jaggi@waterwave.ch>
buf :  *  Copyright (c) 2007 Larry Finger <Larry.Finger@lwfinger.net>
buf :  *
buf :  *  Some parts of the code in this file are derived from the ipw2200
buf :  *  driver  Copyright(c) 2003 - 2004 Intel Corporation.
buf : 
buf :  *  This program is free software; you can redistribute it and/or modify
ify 
buf :  *  it under the terms of the GNU General Public License as published by
buf :  *  the Free Software Foundation; either version 2 of the License, or
buf :  *  (at your option) any later version.
buf :  *
buf :  *  This program is distributed in the hope that it will be useful,
buf :  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
buf :  *  GNU General Public License for more details.
for more details. 
buf :  *
buf :  *  You should have received a copy of the GNU General Public License
buf :  *  along with this program; see the file COPYING.  If not, write to
buf :  *  the Free Software Foundation, Inc., 51 Franklin Steet, Fifth Floor,
ifth Floor, 
buf :  *  Boston, MA 02110-1301, USA.
buf :  *
buf :  */
buf : 
buf : #include <linux/delay.h>
buf : #include <linux/init.h>
buf : #include <linux/module.h>
buf : #include <linux/if_arp.h>
if_arp.h> 
buf : #include <linux/etherdevice.h>
buf : #include <linux/firmware.h>
buf : #include <linux/workqueue.h>
buf : #include <linux/sched.h>
buf : #include <linux/skbuff.h>
buf : #include <linux/dma-mapping.h>
buf : #include <linux/slab.h>
buf : #include <net/dst.h>
buf : #include <asm/unaligned.h>
buf : 
buf : #include "b43legacy.h"
buf : #include "main.h"
buf : #include "debugfs.h"
buf : #include "phy.h"
buf : #include "dma.h"
buf : #include "pio.h"
buf : #include "sysfs.h"
buf : #include "xmit.h"
buf : #include "radio.h"
buf : 
buf : 
buf : MODULE_DESCRIPTION("Broadcom B43legacy wireless driver");
buf : MODULE_AUTHOR("Martin Langer");
buf : MODULE_AUTHOR("Stefano Brivio");
buf : MODULE_AUTHOR("Michael Buesch");
buf : MODULE_LICENSE("GPL");
buf : 
buf : MODULE_FIRMWARE("b43legacy/ucode2.fw");
buf : MODULE_FIRMWARE("b43legacy/ucode4.fw");
buf : 
buf : #if defined(CONFIG_B43LEGACY_DMA) && defined(CONFIG_B43LEGACY_PIO)
if defined(CONFIG_B43LEGACY_DMA) && defined(CONFIG_B43LEGACY_PIO) 
buf : static int modparam_pio;
buf : module_param_named(pio, modparam_pio, int, 0444);
buf : MODULE_PARM_DESC(pio, "enable(1) / disable(0) PIO mode");
buf : #elif defined(CONFIG_B43LEGACY_DMA)
if defined(CONFIG_B43LEGACY_DMA) 
buf : # define modparam_pio	0
buf : #elif defined(CONFIG_B43LEGACY_PIO)
if defined(CONFIG_B43LEGACY_PIO) 
buf : # define modparam_pio	1
buf : #endif
if 
buf : 
buf : static int modparam_bad_frames_preempt;
buf : module_param_named(bad_frames_preempt, modparam_bad_frames_preempt, int, 0444);
buf : MODULE_PARM_DESC(bad_frames_preempt, "enable(1) / disable(0) Bad Frames"
buf : 		 " Preemption");
buf : 
buf : static char modparam_fwpostfix[16];
buf : module_param_string(fwpostfix, modparam_fwpostfix, 16, 0444);
buf : MODULE_PARM_DESC(fwpostfix, "Postfix for the firmware files to load.");
for the firmware files to load."); 
buf : 
buf : /* The following table supports BCM4301, BCM4303 and BCM4306/2 devices. */
buf : static const struct ssb_device_id b43legacy_ssb_tbl[] = {
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 2),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 4),
buf : 	SSB_DEVTABLE_END
buf : };
buf : MODULE_DEVICE_TABLE(ssb, b43legacy_ssb_tbl);
buf : 
buf : 
buf : /* Channel and ratetables are shared for all devices.
for all devices. 
buf :  * They can't be const, because ieee80211 puts some precalculated
buf :  * data in there. This data is the same for all devices, so we don't
for all devices, so we don't 
buf :  * get concurrency issues */
buf : #define RATETAB_ENT(_rateid, _flags) \
buf : 	{								\
buf : 		.bitrate	= B43legacy_RATE_TO_100KBPS(_rateid),	\
buf : 		.hw_value	= (_rateid),				\
buf : 		.flags		= (_flags),				\
buf : 	}
buf : /*
buf :  * NOTE: When changing this, sync with xmit.c's
buf :  *	 b43legacy_plcp_get_bitrate_idx_* functions!
buf :  */
buf : static struct ieee80211_rate __b43legacy_ratetable[] = {
buf : 	RATETAB_ENT(B43legacy_CCK_RATE_1MB, 0),
buf : 	RATETAB_ENT(B43legacy_CCK_RATE_2MB, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATETAB_ENT(B43legacy_CCK_RATE_5MB, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATETAB_ENT(B43legacy_CCK_RATE_11MB, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATETAB_ENT(B43legacy_OFDM_RATE_6MB, 0),
buf : 	RATETAB_ENT(B43legacy_OFDM_RATE_9MB, 0),
buf : 	RATETAB_ENT(B43legacy_OFDM_RATE_12MB, 0),
buf : 	RATETAB_ENT(B43legacy_OFDM_RATE_18MB, 0),
buf : 	RATETAB_ENT(B43legacy_OFDM_RATE_24MB, 0),
buf : 	RATETAB_ENT(B43legacy_OFDM_RATE_36MB, 0),
buf : 	RATETAB_ENT(B43legacy_OFDM_RATE_48MB, 0),
buf : 	RATETAB_ENT(B43legacy_OFDM_RATE_54MB, 0),
buf : };
buf : #define b43legacy_b_ratetable		(__b43legacy_ratetable + 0)
buf : #define b43legacy_b_ratetable_size	4
buf : #define b43legacy_g_ratetable		(__b43legacy_ratetable + 0)
buf : #define b43legacy_g_ratetable_size	12
buf : 
buf : #define CHANTAB_ENT(_chanid, _freq) \
buf : 	{							\
buf : 		.center_freq	= (_freq),			\
buf : 		.hw_value	= (_chanid),			\
buf : 	}
buf : static struct ieee80211_channel b43legacy_bg_chantable[] = {
buf : 	CHANTAB_ENT(1, 2412),
buf : 	CHANTAB_ENT(2, 2417),
buf : 	CHANTAB_ENT(3, 2422),
buf : 	CHANTAB_ENT(4, 2427),
buf : 	CHANTAB_ENT(5, 2432),
buf : 	CHANTAB_ENT(6, 2437),
buf : 	CHANTAB_ENT(7, 2442),
buf : 	CHANTAB_ENT(8, 2447),
buf : 	CHANTAB_ENT(9, 2452),
buf : 	CHANTAB_ENT(10, 2457),
buf : 	CHANTAB_ENT(11, 2462),
buf : 	CHANTAB_ENT(12, 2467),
buf : 	CHANTAB_ENT(13, 2472),
buf : 	CHANTAB_ENT(14, 2484),
buf : };
buf : 
buf : static struct ieee80211_supported_band b43legacy_band_2GHz_BPHY = {
buf : 	.channels = b43legacy_bg_chantable,
buf : 	.n_channels = ARRAY_SIZE(b43legacy_bg_chantable),
buf : 	.bitrates = b43legacy_b_ratetable,
buf : 	.n_bitrates = b43legacy_b_ratetable_size,
buf : };
buf : 
buf : static struct ieee80211_supported_band b43legacy_band_2GHz_GPHY = {
buf : 	.channels = b43legacy_bg_chantable,
buf : 	.n_channels = ARRAY_SIZE(b43legacy_bg_chantable),
buf : 	.bitrates = b43legacy_g_ratetable,
buf : 	.n_bitrates = b43legacy_g_ratetable_size,
buf : };
buf : 
buf : static void b43legacy_wireless_core_exit(struct b43legacy_wldev *dev);
buf : static int b43legacy_wireless_core_init(struct b43legacy_wldev *dev);
buf : static void b43legacy_wireless_core_stop(struct b43legacy_wldev *dev);
buf : static int b43legacy_wireless_core_start(struct b43legacy_wldev *dev);
buf : 
buf : 
buf : static int b43legacy_ratelimit(struct b43legacy_wl *wl)
buf : {
buf : 	if (!wl || !wl->current_dev)
if (!wl || !wl->current_dev) 
buf : 		return 1;
buf : 	if (b43legacy_status(wl->current_dev) < B43legacy_STAT_STARTED)
if (b43legacy_status(wl->current_dev) < B43legacy_STAT_STARTED) 
buf : 		return 1;
buf : 	/* We are up and running.
buf : 	 * Ratelimit the messages to avoid DoS over the net. */
buf : 	return net_ratelimit();
buf : }
buf : 
buf : void b43legacyinfo(struct b43legacy_wl *wl, const char *fmt, ...)
buf : {
buf : 	struct va_format vaf;
format vaf; 
buf : 	va_list args;
buf : 
buf : 	if (!b43legacy_ratelimit(wl))
if (!b43legacy_ratelimit(wl)) 
buf : 		return;
buf : 
buf : 	va_start(args, fmt);
buf : 
buf : 	vaf.fmt = fmt;
buf : 	vaf.va = &args;
buf : 
buf : 	printk(KERN_INFO "b43legacy-%s: %pV",
buf : 	       (wl && wl->hw) ? wiphy_name(wl->hw->wiphy) : "wlan", &vaf);
buf : 
buf : 	va_end(args);
buf : }
buf : 
buf : void b43legacyerr(struct b43legacy_wl *wl, const char *fmt, ...)
buf : {
buf : 	struct va_format vaf;
format vaf; 
buf : 	va_list args;
buf : 
buf : 	if (!b43legacy_ratelimit(wl))
if (!b43legacy_ratelimit(wl)) 
buf : 		return;
buf : 
buf : 	va_start(args, fmt);
buf : 
buf : 	vaf.fmt = fmt;
buf : 	vaf.va = &args;
buf : 
buf : 	printk(KERN_ERR "b43legacy-%s ERROR: %pV",
buf : 	       (wl && wl->hw) ? wiphy_name(wl->hw->wiphy) : "wlan", &vaf);
buf : 
buf : 	va_end(args);
buf : }
buf : 
buf : void b43legacywarn(struct b43legacy_wl *wl, const char *fmt, ...)
buf : {
buf : 	struct va_format vaf;
format vaf; 
buf : 	va_list args;
buf : 
buf : 	if (!b43legacy_ratelimit(wl))
if (!b43legacy_ratelimit(wl)) 
buf : 		return;
buf : 
buf : 	va_start(args, fmt);
buf : 
buf : 	vaf.fmt = fmt;
buf : 	vaf.va = &args;
buf : 
buf : 	printk(KERN_WARNING "b43legacy-%s warning: %pV",
buf : 	       (wl && wl->hw) ? wiphy_name(wl->hw->wiphy) : "wlan", &vaf);
buf : 
buf : 	va_end(args);
buf : }
buf : 
buf : #if B43legacy_DEBUG
if B43legacy_DEBUG 
buf : void b43legacydbg(struct b43legacy_wl *wl, const char *fmt, ...)
buf : {
buf : 	struct va_format vaf;
format vaf; 
buf : 	va_list args;
buf : 
buf : 	va_start(args, fmt);
buf : 
buf : 	vaf.fmt = fmt;
buf : 	vaf.va = &args;
buf : 
buf : 	printk(KERN_DEBUG "b43legacy-%s debug: %pV",
buf : 	       (wl && wl->hw) ? wiphy_name(wl->hw->wiphy) : "wlan", &vaf);
buf : 
buf : 	va_end(args);
buf : }
buf : #endif /* DEBUG */
if /* DEBUG */ 
buf : 
buf : static void b43legacy_ram_write(struct b43legacy_wldev *dev, u16 offset,
buf : 				u32 val)
buf : {
buf : 	u32 status;
buf : 
buf : 	B43legacy_WARN_ON(offset % 4 != 0);
buf : 
buf : 	status = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	if (status & B43legacy_MACCTL_BE)
if (status & B43legacy_MACCTL_BE) 
buf : 		val = swab32(val);
buf : 
buf : 	b43legacy_write32(dev, B43legacy_MMIO_RAM_CONTROL, offset);
buf : 	mmiowb();
buf : 	b43legacy_write32(dev, B43legacy_MMIO_RAM_DATA, val);
buf : }
buf : 
buf : static inline
buf : void b43legacy_shm_control_word(struct b43legacy_wldev *dev,
buf : 				u16 routing, u16 offset)
buf : {
buf : 	u32 control;
buf : 
buf : 	/* "offset" is the WORD offset. */
buf : 
buf : 	control = routing;
buf : 	control <<= 16;
buf : 	control |= offset;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_SHM_CONTROL, control);
buf : }
buf : 
buf : u32 b43legacy_shm_read32(struct b43legacy_wldev *dev,
buf : 		       u16 routing, u16 offset)
buf : {
buf : 	u32 ret;
buf : 
buf : 	if (routing == B43legacy_SHM_SHARED) {
if (routing == B43legacy_SHM_SHARED) { 
buf : 		B43legacy_WARN_ON((offset & 0x0001) != 0);
buf : 		if (offset & 0x0003) {
if (offset & 0x0003) { 
buf : 			/* Unaligned access */
buf : 			b43legacy_shm_control_word(dev, routing, offset >> 2);
buf : 			ret = b43legacy_read16(dev,
buf : 				B43legacy_MMIO_SHM_DATA_UNALIGNED);
buf : 			ret <<= 16;
buf : 			b43legacy_shm_control_word(dev, routing,
buf : 						     (offset >> 2) + 1);
buf : 			ret |= b43legacy_read16(dev, B43legacy_MMIO_SHM_DATA);
buf : 
buf : 			return ret;
buf : 		}
buf : 		offset >>= 2;
buf : 	}
buf : 	b43legacy_shm_control_word(dev, routing, offset);
buf : 	ret = b43legacy_read32(dev, B43legacy_MMIO_SHM_DATA);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : u16 b43legacy_shm_read16(struct b43legacy_wldev *dev,
buf : 			   u16 routing, u16 offset)
buf : {
buf : 	u16 ret;
buf : 
buf : 	if (routing == B43legacy_SHM_SHARED) {
if (routing == B43legacy_SHM_SHARED) { 
buf : 		B43legacy_WARN_ON((offset & 0x0001) != 0);
buf : 		if (offset & 0x0003) {
if (offset & 0x0003) { 
buf : 			/* Unaligned access */
buf : 			b43legacy_shm_control_word(dev, routing, offset >> 2);
buf : 			ret = b43legacy_read16(dev,
buf : 					     B43legacy_MMIO_SHM_DATA_UNALIGNED);
buf : 
buf : 			return ret;
buf : 		}
buf : 		offset >>= 2;
buf : 	}
buf : 	b43legacy_shm_control_word(dev, routing, offset);
buf : 	ret = b43legacy_read16(dev, B43legacy_MMIO_SHM_DATA);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : void b43legacy_shm_write32(struct b43legacy_wldev *dev,
buf : 			   u16 routing, u16 offset,
buf : 			   u32 value)
buf : {
buf : 	if (routing == B43legacy_SHM_SHARED) {
if (routing == B43legacy_SHM_SHARED) { 
buf : 		B43legacy_WARN_ON((offset & 0x0001) != 0);
buf : 		if (offset & 0x0003) {
if (offset & 0x0003) { 
buf : 			/* Unaligned access */
buf : 			b43legacy_shm_control_word(dev, routing, offset >> 2);
buf : 			mmiowb();
buf : 			b43legacy_write16(dev,
buf : 					  B43legacy_MMIO_SHM_DATA_UNALIGNED,
buf : 					  (value >> 16) & 0xffff);
buf : 			mmiowb();
buf : 			b43legacy_shm_control_word(dev, routing,
buf : 						   (offset >> 2) + 1);
buf : 			mmiowb();
buf : 			b43legacy_write16(dev, B43legacy_MMIO_SHM_DATA,
buf : 					  value & 0xffff);
buf : 			return;
buf : 		}
buf : 		offset >>= 2;
buf : 	}
buf : 	b43legacy_shm_control_word(dev, routing, offset);
buf : 	mmiowb();
buf : 	b43legacy_write32(dev, B43legacy_MMIO_SHM_DATA, value);
buf : }
buf : 
buf : void b43legacy_shm_write16(struct b43legacy_wldev *dev, u16 routing, u16 offset,
buf : 			   u16 value)
buf : {
buf : 	if (routing == B43legacy_SHM_SHARED) {
if (routing == B43legacy_SHM_SHARED) { 
buf : 		B43legacy_WARN_ON((offset & 0x0001) != 0);
buf : 		if (offset & 0x0003) {
if (offset & 0x0003) { 
buf : 			/* Unaligned access */
buf : 			b43legacy_shm_control_word(dev, routing, offset >> 2);
buf : 			mmiowb();
buf : 			b43legacy_write16(dev,
buf : 					  B43legacy_MMIO_SHM_DATA_UNALIGNED,
buf : 					  value);
buf : 			return;
buf : 		}
buf : 		offset >>= 2;
buf : 	}
buf : 	b43legacy_shm_control_word(dev, routing, offset);
buf : 	mmiowb();
buf : 	b43legacy_write16(dev, B43legacy_MMIO_SHM_DATA, value);
buf : }
buf : 
buf : /* Read HostFlags */
buf : u32 b43legacy_hf_read(struct b43legacy_wldev *dev)
buf : {
buf : 	u32 ret;
buf : 
buf : 	ret = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				   B43legacy_SHM_SH_HOSTFHI);
buf : 	ret <<= 16;
buf : 	ret |= b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				    B43legacy_SHM_SH_HOSTFLO);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : /* Write HostFlags */
buf : void b43legacy_hf_write(struct b43legacy_wldev *dev, u32 value)
buf : {
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_HOSTFLO,
buf : 			      (value & 0x0000FFFF));
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_HOSTFHI,
buf : 			      ((value & 0xFFFF0000) >> 16));
buf : }
buf : 
buf : void b43legacy_tsf_read(struct b43legacy_wldev *dev, u64 *tsf)
buf : {
buf : 	/* We need to be careful. As we read the TSF from multiple
buf : 	 * registers, we should take care of register overflows.
buf : 	 * In theory, the whole tsf read process should be atomic.
buf : 	 * We try to be atomic here, by restaring the read process,
buf : 	 * if any of the high registers changed (overflew).
if any of the high registers changed (overflew). 
buf : 	 */
buf : 	if (dev->dev->id.revision >= 3) {
if (dev->dev->id.revision >= 3) { 
buf : 		u32 low;
buf : 		u32 high;
buf : 		u32 high2;
buf : 
buf : 		do {
buf : 			high = b43legacy_read32(dev,
buf : 					B43legacy_MMIO_REV3PLUS_TSF_HIGH);
buf : 			low = b43legacy_read32(dev,
buf : 					B43legacy_MMIO_REV3PLUS_TSF_LOW);
buf : 			high2 = b43legacy_read32(dev,
buf : 					B43legacy_MMIO_REV3PLUS_TSF_HIGH);
buf : 		} while (unlikely(high != high2));
while (unlikely(high != high2)); 
buf : 
buf : 		*tsf = high;
buf : 		*tsf <<= 32;
buf : 		*tsf |= low;
buf : 	} else {
buf : 		u64 tmp;
buf : 		u16 v0;
buf : 		u16 v1;
buf : 		u16 v2;
buf : 		u16 v3;
buf : 		u16 test1;
buf : 		u16 test2;
buf : 		u16 test3;
buf : 
buf : 		do {
buf : 			v3 = b43legacy_read16(dev, B43legacy_MMIO_TSF_3);
buf : 			v2 = b43legacy_read16(dev, B43legacy_MMIO_TSF_2);
buf : 			v1 = b43legacy_read16(dev, B43legacy_MMIO_TSF_1);
buf : 			v0 = b43legacy_read16(dev, B43legacy_MMIO_TSF_0);
buf : 
buf : 			test3 = b43legacy_read16(dev, B43legacy_MMIO_TSF_3);
buf : 			test2 = b43legacy_read16(dev, B43legacy_MMIO_TSF_2);
buf : 			test1 = b43legacy_read16(dev, B43legacy_MMIO_TSF_1);
buf : 		} while (v3 != test3 || v2 != test2 || v1 != test1);
while (v3 != test3 || v2 != test2 || v1 != test1); 
buf : 
buf : 		*tsf = v3;
buf : 		*tsf <<= 48;
buf : 		tmp = v2;
buf : 		tmp <<= 32;
buf : 		*tsf |= tmp;
buf : 		tmp = v1;
buf : 		tmp <<= 16;
buf : 		*tsf |= tmp;
buf : 		*tsf |= v0;
buf : 	}
buf : }
buf : 
buf : static void b43legacy_time_lock(struct b43legacy_wldev *dev)
buf : {
buf : 	u32 status;
buf : 
buf : 	status = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	status |= B43legacy_MACCTL_TBTTHOLD;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, status);
buf : 	mmiowb();
buf : }
buf : 
buf : static void b43legacy_time_unlock(struct b43legacy_wldev *dev)
buf : {
buf : 	u32 status;
buf : 
buf : 	status = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	status &= ~B43legacy_MACCTL_TBTTHOLD;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, status);
buf : }
buf : 
buf : static void b43legacy_tsf_write_locked(struct b43legacy_wldev *dev, u64 tsf)
buf : {
buf : 	/* Be careful with the in-progress timer.
buf : 	 * First zero out the low register, so we have a full
buf : 	 * register-overflow duration to complete the operation.
buf : 	 */
buf : 	if (dev->dev->id.revision >= 3) {
if (dev->dev->id.revision >= 3) { 
buf : 		u32 lo = (tsf & 0x00000000FFFFFFFFULL);
buf : 		u32 hi = (tsf & 0xFFFFFFFF00000000ULL) >> 32;
buf : 
buf : 		b43legacy_write32(dev, B43legacy_MMIO_REV3PLUS_TSF_LOW, 0);
buf : 		mmiowb();
buf : 		b43legacy_write32(dev, B43legacy_MMIO_REV3PLUS_TSF_HIGH,
buf : 				    hi);
buf : 		mmiowb();
buf : 		b43legacy_write32(dev, B43legacy_MMIO_REV3PLUS_TSF_LOW,
buf : 				    lo);
buf : 	} else {
buf : 		u16 v0 = (tsf & 0x000000000000FFFFULL);
buf : 		u16 v1 = (tsf & 0x00000000FFFF0000ULL) >> 16;
buf : 		u16 v2 = (tsf & 0x0000FFFF00000000ULL) >> 32;
buf : 		u16 v3 = (tsf & 0xFFFF000000000000ULL) >> 48;
buf : 
buf : 		b43legacy_write16(dev, B43legacy_MMIO_TSF_0, 0);
buf : 		mmiowb();
buf : 		b43legacy_write16(dev, B43legacy_MMIO_TSF_3, v3);
buf : 		mmiowb();
buf : 		b43legacy_write16(dev, B43legacy_MMIO_TSF_2, v2);
buf : 		mmiowb();
buf : 		b43legacy_write16(dev, B43legacy_MMIO_TSF_1, v1);
buf : 		mmiowb();
buf : 		b43legacy_write16(dev, B43legacy_MMIO_TSF_0, v0);
buf : 	}
buf : }
buf : 
buf : void b43legacy_tsf_write(struct b43legacy_wldev *dev, u64 tsf)
buf : {
buf : 	b43legacy_time_lock(dev);
buf : 	b43legacy_tsf_write_locked(dev, tsf);
buf : 	b43legacy_time_unlock(dev);
buf : }
buf : 
buf : static
buf : void b43legacy_macfilter_set(struct b43legacy_wldev *dev,
buf : 			     u16 offset, const u8 *mac)
buf : {
buf : 	static const u8 zero_addr[ETH_ALEN] = { 0 };
buf : 	u16 data;
buf : 
buf : 	if (!mac)
if (!mac) 
buf : 		mac = zero_addr;
buf : 
buf : 	offset |= 0x0020;
buf : 	b43legacy_write16(dev, B43legacy_MMIO_MACFILTER_CONTROL, offset);
buf : 
buf : 	data = mac[0];
buf : 	data |= mac[1] << 8;
buf : 	b43legacy_write16(dev, B43legacy_MMIO_MACFILTER_DATA, data);
buf : 	data = mac[2];
buf : 	data |= mac[3] << 8;
buf : 	b43legacy_write16(dev, B43legacy_MMIO_MACFILTER_DATA, data);
buf : 	data = mac[4];
buf : 	data |= mac[5] << 8;
buf : 	b43legacy_write16(dev, B43legacy_MMIO_MACFILTER_DATA, data);
buf : }
buf : 
buf : static void b43legacy_write_mac_bssid_templates(struct b43legacy_wldev *dev)
buf : {
buf : 	static const u8 zero_addr[ETH_ALEN] = { 0 };
buf : 	const u8 *mac = dev->wl->mac_addr;
buf : 	const u8 *bssid = dev->wl->bssid;
buf : 	u8 mac_bssid[ETH_ALEN * 2];
buf : 	int i;
buf : 	u32 tmp;
buf : 
buf : 	if (!bssid)
if (!bssid) 
buf : 		bssid = zero_addr;
buf : 	if (!mac)
if (!mac) 
buf : 		mac = zero_addr;
buf : 
buf : 	b43legacy_macfilter_set(dev, B43legacy_MACFILTER_BSSID, bssid);
buf : 
buf : 	memcpy(mac_bssid, mac, ETH_ALEN);
buf : 	memcpy(mac_bssid + ETH_ALEN, bssid, ETH_ALEN);
buf : 
buf : 	/* Write our MAC address and BSSID to template ram */
buf : 	for (i = 0; i < ARRAY_SIZE(mac_bssid); i += sizeof(u32)) {
for (i = 0; i < ARRAY_SIZE(mac_bssid); i += sizeof(u32)) { 
buf : 		tmp =  (u32)(mac_bssid[i + 0]);
buf : 		tmp |= (u32)(mac_bssid[i + 1]) << 8;
buf : 		tmp |= (u32)(mac_bssid[i + 2]) << 16;
buf : 		tmp |= (u32)(mac_bssid[i + 3]) << 24;
buf : 		b43legacy_ram_write(dev, 0x20 + i, tmp);
buf : 		b43legacy_ram_write(dev, 0x78 + i, tmp);
buf : 		b43legacy_ram_write(dev, 0x478 + i, tmp);
buf : 	}
buf : }
buf : 
buf : static void b43legacy_upload_card_macaddress(struct b43legacy_wldev *dev)
buf : {
buf : 	b43legacy_write_mac_bssid_templates(dev);
buf : 	b43legacy_macfilter_set(dev, B43legacy_MACFILTER_SELF,
buf : 				dev->wl->mac_addr);
buf : }
buf : 
buf : static void b43legacy_set_slot_time(struct b43legacy_wldev *dev,
buf : 				    u16 slot_time)
buf : {
buf : 	/* slot_time is in usec. */
buf : 	if (dev->phy.type != B43legacy_PHYTYPE_G)
if (dev->phy.type != B43legacy_PHYTYPE_G) 
buf : 		return;
buf : 	b43legacy_write16(dev, 0x684, 510 + slot_time);
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, 0x0010,
buf : 			      slot_time);
buf : }
buf : 
buf : static void b43legacy_short_slot_timing_enable(struct b43legacy_wldev *dev)
buf : {
buf : 	b43legacy_set_slot_time(dev, 9);
buf : }
buf : 
buf : static void b43legacy_short_slot_timing_disable(struct b43legacy_wldev *dev)
buf : {
buf : 	b43legacy_set_slot_time(dev, 20);
buf : }
buf : 
buf : /* Synchronize IRQ top- and bottom-half.
buf :  * IRQs must be masked before calling this.
fore calling this. 
buf :  * This must not be called with the irq_lock held.
buf :  */
buf : static void b43legacy_synchronize_irq(struct b43legacy_wldev *dev)
buf : {
buf : 	synchronize_irq(dev->dev->irq);
buf : 	tasklet_kill(&dev->isr_tasklet);
buf : }
buf : 
buf : /* DummyTransmission function, as documented on
buf :  * http://bcm-specs.sipsolutions.net/DummyTransmission
buf :  */
buf : void b43legacy_dummy_transmission(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_phy *phy = &dev->phy;
buf : 	unsigned int i;
buf : 	unsigned int max_loop;
buf : 	u16 value;
buf : 	u32 buffer[5] = {
buf : 		0x00000000,
buf : 		0x00D40000,
buf : 		0x00000000,
buf : 		0x01000000,
buf : 		0x00000000,
buf : 	};
buf : 
buf : 	switch (phy->type) {
buf : 	case B43legacy_PHYTYPE_B:
buf : 	case B43legacy_PHYTYPE_G:
buf : 		max_loop = 0xFA;
buf : 		buffer[0] = 0x000B846E;
buf : 		break;
buf : 	default:
buf : 		B43legacy_BUG_ON(1);
buf : 		return;
buf : 	}
buf : 
buf : 	for (i = 0; i < 5; i++)
for (i = 0; i < 5; i++) 
buf : 		b43legacy_ram_write(dev, i * 4, buffer[i]);
buf : 
buf : 	/* dummy read follows */
buf : 	b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 
buf : 	b43legacy_write16(dev, 0x0568, 0x0000);
buf : 	b43legacy_write16(dev, 0x07C0, 0x0000);
buf : 	b43legacy_write16(dev, 0x050C, 0x0000);
buf : 	b43legacy_write16(dev, 0x0508, 0x0000);
buf : 	b43legacy_write16(dev, 0x050A, 0x0000);
buf : 	b43legacy_write16(dev, 0x054C, 0x0000);
buf : 	b43legacy_write16(dev, 0x056A, 0x0014);
buf : 	b43legacy_write16(dev, 0x0568, 0x0826);
buf : 	b43legacy_write16(dev, 0x0500, 0x0000);
buf : 	b43legacy_write16(dev, 0x0502, 0x0030);
buf : 
buf : 	if (phy->radio_ver == 0x2050 && phy->radio_rev <= 0x5)
if (phy->radio_ver == 0x2050 && phy->radio_rev <= 0x5) 
buf : 		b43legacy_radio_write16(dev, 0x0051, 0x0017);
buf : 	for (i = 0x00; i < max_loop; i++) {
for (i = 0x00; i < max_loop; i++) { 
buf : 		value = b43legacy_read16(dev, 0x050E);
buf : 		if (value & 0x0080)
if (value & 0x0080) 
buf : 			break;
buf : 		udelay(10);
buf : 	}
buf : 	for (i = 0x00; i < 0x0A; i++) {
for (i = 0x00; i < 0x0A; i++) { 
buf : 		value = b43legacy_read16(dev, 0x050E);
buf : 		if (value & 0x0400)
if (value & 0x0400) 
buf : 			break;
buf : 		udelay(10);
buf : 	}
buf : 	for (i = 0x00; i < 0x0A; i++) {
for (i = 0x00; i < 0x0A; i++) { 
buf : 		value = b43legacy_read16(dev, 0x0690);
buf : 		if (!(value & 0x0100))
if (!(value & 0x0100)) 
buf : 			break;
buf : 		udelay(10);
buf : 	}
buf : 	if (phy->radio_ver == 0x2050 && phy->radio_rev <= 0x5)
if (phy->radio_ver == 0x2050 && phy->radio_rev <= 0x5) 
buf : 		b43legacy_radio_write16(dev, 0x0051, 0x0037);
buf : }
buf : 
buf : /* Turn the Analog ON/OFF */
buf : static void b43legacy_switch_analog(struct b43legacy_wldev *dev, int on)
buf : {
buf : 	b43legacy_write16(dev, B43legacy_MMIO_PHY0, on ? 0 : 0xF4);
buf : }
buf : 
buf : void b43legacy_wireless_core_reset(struct b43legacy_wldev *dev, u32 flags)
buf : {
buf : 	u32 tmslow;
buf : 	u32 macctl;
buf : 
buf : 	flags |= B43legacy_TMSLOW_PHYCLKEN;
buf : 	flags |= B43legacy_TMSLOW_PHYRESET;
buf : 	ssb_device_enable(dev->dev, flags);
buf : 	msleep(2); /* Wait for the PLL to turn on. */
for the PLL to turn on. */ 
buf : 
buf : 	/* Now take the PHY out of Reset again */
buf : 	tmslow = ssb_read32(dev->dev, SSB_TMSLOW);
buf : 	tmslow |= SSB_TMSLOW_FGC;
buf : 	tmslow &= ~B43legacy_TMSLOW_PHYRESET;
buf : 	ssb_write32(dev->dev, SSB_TMSLOW, tmslow);
buf : 	ssb_read32(dev->dev, SSB_TMSLOW); /* flush */
buf : 	msleep(1);
buf : 	tmslow &= ~SSB_TMSLOW_FGC;
buf : 	ssb_write32(dev->dev, SSB_TMSLOW, tmslow);
buf : 	ssb_read32(dev->dev, SSB_TMSLOW); /* flush */
buf : 	msleep(1);
buf : 
buf : 	/* Turn Analog ON */
buf : 	b43legacy_switch_analog(dev, 1);
buf : 
buf : 	macctl = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	macctl &= ~B43legacy_MACCTL_GMODE;
buf : 	if (flags & B43legacy_TMSLOW_GMODE) {
if (flags & B43legacy_TMSLOW_GMODE) { 
buf : 		macctl |= B43legacy_MACCTL_GMODE;
buf : 		dev->phy.gmode = true;
buf : 	} else
buf : 		dev->phy.gmode = false;
buf : 	macctl |= B43legacy_MACCTL_IHR_ENABLED;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, macctl);
buf : }
buf : 
buf : static void handle_irq_transmit_status(struct b43legacy_wldev *dev)
buf : {
buf : 	u32 v0;
buf : 	u32 v1;
buf : 	u16 tmp;
buf : 	struct b43legacy_txstatus stat;
buf : 
buf : 	while (1) {
while (1) { 
buf : 		v0 = b43legacy_read32(dev, B43legacy_MMIO_XMITSTAT_0);
buf : 		if (!(v0 & 0x00000001))
if (!(v0 & 0x00000001)) 
buf : 			break;
buf : 		v1 = b43legacy_read32(dev, B43legacy_MMIO_XMITSTAT_1);
buf : 
buf : 		stat.cookie = (v0 >> 16);
buf : 		stat.seq = (v1 & 0x0000FFFF);
buf : 		stat.phy_stat = ((v1 & 0x00FF0000) >> 16);
buf : 		tmp = (v0 & 0x0000FFFF);
buf : 		stat.frame_count = ((tmp & 0xF000) >> 12);
buf : 		stat.rts_count = ((tmp & 0x0F00) >> 8);
buf : 		stat.supp_reason = ((tmp & 0x001C) >> 2);
buf : 		stat.pm_indicated = !!(tmp & 0x0080);
buf : 		stat.intermediate = !!(tmp & 0x0040);
buf : 		stat.for_ampdu = !!(tmp & 0x0020);
for_ampdu = !!(tmp & 0x0020); 
buf : 		stat.acked = !!(tmp & 0x0002);
buf : 
buf : 		b43legacy_handle_txstatus(dev, &stat);
buf : 	}
buf : }
buf : 
buf : static void drain_txstatus_queue(struct b43legacy_wldev *dev)
buf : {
buf : 	u32 dummy;
buf : 
buf : 	if (dev->dev->id.revision < 5)
if (dev->dev->id.revision < 5) 
buf : 		return;
buf : 	/* Read all entries from the microcode TXstatus FIFO
buf : 	 * and throw them away.
buf : 	 */
buf : 	while (1) {
while (1) { 
buf : 		dummy = b43legacy_read32(dev, B43legacy_MMIO_XMITSTAT_0);
buf : 		if (!(dummy & 0x00000001))
if (!(dummy & 0x00000001)) 
buf : 			break;
buf : 		dummy = b43legacy_read32(dev, B43legacy_MMIO_XMITSTAT_1);
buf : 	}
buf : }
buf : 
buf : static u32 b43legacy_jssi_read(struct b43legacy_wldev *dev)
buf : {
buf : 	u32 val = 0;
buf : 
buf : 	val = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED, 0x40A);
buf : 	val <<= 16;
buf : 	val |= b43legacy_shm_read16(dev, B43legacy_SHM_SHARED, 0x408);
buf : 
buf : 	return val;
buf : }
buf : 
buf : static void b43legacy_jssi_write(struct b43legacy_wldev *dev, u32 jssi)
buf : {
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, 0x408,
buf : 			      (jssi & 0x0000FFFF));
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, 0x40A,
buf : 			      (jssi & 0xFFFF0000) >> 16);
buf : }
buf : 
buf : static void b43legacy_generate_noise_sample(struct b43legacy_wldev *dev)
buf : {
buf : 	b43legacy_jssi_write(dev, 0x7F7F7F7F);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCMD,
buf : 			  b43legacy_read32(dev, B43legacy_MMIO_MACCMD)
buf : 			  | B43legacy_MACCMD_BGNOISE);
buf : 	B43legacy_WARN_ON(dev->noisecalc.channel_at_start !=
buf : 			    dev->phy.channel);
buf : }
buf : 
buf : static void b43legacy_calculate_link_quality(struct b43legacy_wldev *dev)
buf : {
buf : 	/* Top half of Link Quality calculation. */
buf : 
buf : 	if (dev->noisecalc.calculation_running)
if (dev->noisecalc.calculation_running) 
buf : 		return;
buf : 	dev->noisecalc.channel_at_start = dev->phy.channel;
buf : 	dev->noisecalc.calculation_running = true;
buf : 	dev->noisecalc.nr_samples = 0;
buf : 
buf : 	b43legacy_generate_noise_sample(dev);
buf : }
buf : 
buf : static void handle_irq_noise(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_phy *phy = &dev->phy;
buf : 	u16 tmp;
buf : 	u8 noise[4];
buf : 	u8 i;
buf : 	u8 j;
buf : 	s32 average;
buf : 
buf : 	/* Bottom half of Link Quality calculation. */
buf : 
buf : 	B43legacy_WARN_ON(!dev->noisecalc.calculation_running);
buf : 	if (dev->noisecalc.channel_at_start != phy->channel)
if (dev->noisecalc.channel_at_start != phy->channel) 
buf : 		goto drop_calculation;
buf : 	*((__le32 *)noise) = cpu_to_le32(b43legacy_jssi_read(dev));
buf : 	if (noise[0] == 0x7F || noise[1] == 0x7F ||
if (noise[0] == 0x7F || noise[1] == 0x7F || 
buf : 	    noise[2] == 0x7F || noise[3] == 0x7F)
buf : 		goto generate_new;
buf : 
buf : 	/* Get the noise samples. */
buf : 	B43legacy_WARN_ON(dev->noisecalc.nr_samples >= 8);
buf : 	i = dev->noisecalc.nr_samples;
buf : 	noise[0] = clamp_val(noise[0], 0, ARRAY_SIZE(phy->nrssi_lt) - 1);
buf : 	noise[1] = clamp_val(noise[1], 0, ARRAY_SIZE(phy->nrssi_lt) - 1);
buf : 	noise[2] = clamp_val(noise[2], 0, ARRAY_SIZE(phy->nrssi_lt) - 1);
buf : 	noise[3] = clamp_val(noise[3], 0, ARRAY_SIZE(phy->nrssi_lt) - 1);
buf : 	dev->noisecalc.samples[i][0] = phy->nrssi_lt[noise[0]];
buf : 	dev->noisecalc.samples[i][1] = phy->nrssi_lt[noise[1]];
buf : 	dev->noisecalc.samples[i][2] = phy->nrssi_lt[noise[2]];
buf : 	dev->noisecalc.samples[i][3] = phy->nrssi_lt[noise[3]];
buf : 	dev->noisecalc.nr_samples++;
buf : 	if (dev->noisecalc.nr_samples == 8) {
if (dev->noisecalc.nr_samples == 8) { 
buf : 		/* Calculate the Link Quality by the noise samples. */
buf : 		average = 0;
buf : 		for (i = 0; i < 8; i++) {
for (i = 0; i < 8; i++) { 
buf : 			for (j = 0; j < 4; j++)
buf : 				average += dev->noisecalc.samples[i][j];
buf : 		}
buf : 		average /= (8 * 4);
buf : 		average *= 125;
buf : 		average += 64;
buf : 		average /= 128;
buf : 		tmp = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 					     0x40C);
buf : 		tmp = (tmp / 128) & 0x1F;
buf : 		if (tmp >= 8)
if (tmp >= 8) 
buf : 			average += 2;
buf : 		else
buf : 			average -= 25;
buf : 		if (tmp == 8)
if (tmp == 8) 
buf : 			average -= 72;
buf : 		else
buf : 			average -= 48;
buf : 
buf : 		dev->stats.link_noise = average;
buf : drop_calculation:
buf : 		dev->noisecalc.calculation_running = false;
buf : 		return;
buf : 	}
buf : generate_new:
buf : 	b43legacy_generate_noise_sample(dev);
buf : }
buf : 
buf : static void handle_irq_tbtt_indication(struct b43legacy_wldev *dev)
buf : {
buf : 	if (b43legacy_is_mode(dev->wl, NL80211_IFTYPE_AP)) {
if (b43legacy_is_mode(dev->wl, NL80211_IFTYPE_AP)) { 
buf : 		/* TODO: PS TBTT */
buf : 	} else {
buf : 		if (1/*FIXME: the last PSpoll frame was sent successfully */)
if (1/*FIXME: the last PSpoll frame was sent successfully */) 
buf : 			b43legacy_power_saving_ctl_bits(dev, -1, -1);
buf : 	}
buf : 	if (b43legacy_is_mode(dev->wl, NL80211_IFTYPE_ADHOC))
if (b43legacy_is_mode(dev->wl, NL80211_IFTYPE_ADHOC)) 
buf : 		dev->dfq_valid = true;
buf : }
buf : 
buf : static void handle_irq_atim_end(struct b43legacy_wldev *dev)
buf : {
buf : 	if (dev->dfq_valid) {
if (dev->dfq_valid) { 
buf : 		b43legacy_write32(dev, B43legacy_MMIO_MACCMD,
buf : 				  b43legacy_read32(dev, B43legacy_MMIO_MACCMD)
buf : 				  | B43legacy_MACCMD_DFQ_VALID);
buf : 		dev->dfq_valid = false;
buf : 	}
buf : }
buf : 
buf : static void handle_irq_pmq(struct b43legacy_wldev *dev)
buf : {
buf : 	u32 tmp;
buf : 
buf : 	/* TODO: AP mode. */
buf : 
buf : 	while (1) {
while (1) { 
buf : 		tmp = b43legacy_read32(dev, B43legacy_MMIO_PS_STATUS);
buf : 		if (!(tmp & 0x00000008))
if (!(tmp & 0x00000008)) 
buf : 			break;
buf : 	}
buf : 	/* 16bit write is odd, but correct. */
buf : 	b43legacy_write16(dev, B43legacy_MMIO_PS_STATUS, 0x0002);
buf : }
buf : 
buf : static void b43legacy_write_template_common(struct b43legacy_wldev *dev,
buf : 					    const u8 *data, u16 size,
buf : 					    u16 ram_offset,
buf : 					    u16 shm_size_offset, u8 rate)
buf : {
buf : 	u32 i;
buf : 	u32 tmp;
buf : 	struct b43legacy_plcp_hdr4 plcp;
buf : 
buf : 	plcp.data = 0;
buf : 	b43legacy_generate_plcp_hdr(&plcp, size + FCS_LEN, rate);
buf : 	b43legacy_ram_write(dev, ram_offset, le32_to_cpu(plcp.data));
buf : 	ram_offset += sizeof(u32);
buf : 	/* The PLCP is 6 bytes long, but we only wrote 4 bytes, yet.
buf : 	 * So leave the first two bytes of the next write blank.
buf : 	 */
buf : 	tmp = (u32)(data[0]) << 16;
buf : 	tmp |= (u32)(data[1]) << 24;
buf : 	b43legacy_ram_write(dev, ram_offset, tmp);
buf : 	ram_offset += sizeof(u32);
buf : 	for (i = 2; i < size; i += sizeof(u32)) {
for (i = 2; i < size; i += sizeof(u32)) { 
buf : 		tmp = (u32)(data[i + 0]);
buf : 		if (i + 1 < size)
if (i + 1 < size) 
buf : 			tmp |= (u32)(data[i + 1]) << 8;
buf : 		if (i + 2 < size)
if (i + 2 < size) 
buf : 			tmp |= (u32)(data[i + 2]) << 16;
buf : 		if (i + 3 < size)
if (i + 3 < size) 
buf : 			tmp |= (u32)(data[i + 3]) << 24;
buf : 		b43legacy_ram_write(dev, ram_offset + i - 2, tmp);
buf : 	}
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, shm_size_offset,
buf : 			      size + sizeof(struct b43legacy_plcp_hdr6));
buf : }
buf : 
buf : /* Convert a b43legacy antenna number value to the PHY TX control value. */
buf : static u16 b43legacy_antenna_to_phyctl(int antenna)
buf : {
buf : 	switch (antenna) {
buf : 	case B43legacy_ANTENNA0:
buf : 		return B43legacy_TX4_PHY_ANT0;
buf : 	case B43legacy_ANTENNA1:
buf : 		return B43legacy_TX4_PHY_ANT1;
buf : 	}
buf : 	return B43legacy_TX4_PHY_ANTLAST;
buf : }
buf : 
buf : static void b43legacy_write_beacon_template(struct b43legacy_wldev *dev,
buf : 					    u16 ram_offset,
buf : 					    u16 shm_size_offset)
buf : {
buf : 
buf : 	unsigned int i, len, variable_len;
buf : 	const struct ieee80211_mgmt *bcn;
buf : 	const u8 *ie;
buf : 	bool tim_found = false;
buf : 	unsigned int rate;
buf : 	u16 ctl;
buf : 	int antenna;
buf : 	struct ieee80211_tx_info *info = IEEE80211_SKB_CB(dev->wl->current_beacon);
buf : 
buf : 	bcn = (const struct ieee80211_mgmt *)(dev->wl->current_beacon->data);
buf : 	len = min_t(size_t, dev->wl->current_beacon->len,
buf : 		  0x200 - sizeof(struct b43legacy_plcp_hdr6));
buf : 	rate = ieee80211_get_tx_rate(dev->wl->hw, info)->hw_value;
buf : 
buf : 	b43legacy_write_template_common(dev, (const u8 *)bcn, len, ram_offset,
buf : 					shm_size_offset, rate);
buf : 
buf : 	/* Write the PHY TX control parameters. */
buf : 	antenna = B43legacy_ANTENNA_DEFAULT;
buf : 	antenna = b43legacy_antenna_to_phyctl(antenna);
buf : 	ctl = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				   B43legacy_SHM_SH_BEACPHYCTL);
buf : 	/* We can't send beacons with short preamble. Would get PHY errors. */
buf : 	ctl &= ~B43legacy_TX4_PHY_SHORTPRMBL;
buf : 	ctl &= ~B43legacy_TX4_PHY_ANT;
buf : 	ctl &= ~B43legacy_TX4_PHY_ENC;
buf : 	ctl |= antenna;
buf : 	ctl |= B43legacy_TX4_PHY_ENC_CCK;
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_BEACPHYCTL, ctl);
buf : 
buf : 	/* Find the position of the TIM and the DTIM_period value
buf : 	 * and write them to SHM. */
buf : 	ie = bcn->u.beacon.variable;
buf : 	variable_len = len - offsetof(struct ieee80211_mgmt, u.beacon.variable);
buf : 	for (i = 0; i < variable_len - 2; ) {
for (i = 0; i < variable_len - 2; ) { 
buf : 		uint8_t ie_id, ie_len;
buf : 
buf : 		ie_id = ie[i];
buf : 		ie_len = ie[i + 1];
buf : 		if (ie_id == 5) {
if (ie_id == 5) { 
buf : 			u16 tim_position;
buf : 			u16 dtim_period;
buf : 			/* This is the TIM Information Element */
formation Element */ 
buf : 
buf : 			/* Check whether the ie_len is in the beacon data range. */
buf : 			if (variable_len < ie_len + 2 + i)
if (variable_len < ie_len + 2 + i) 
buf : 				break;
buf : 			/* A valid TIM is at least 4 bytes long. */
buf : 			if (ie_len < 4)
if (ie_len < 4) 
buf : 				break;
buf : 			tim_found = true;
buf : 
buf : 			tim_position = sizeof(struct b43legacy_plcp_hdr6);
buf : 			tim_position += offsetof(struct ieee80211_mgmt,
buf : 						 u.beacon.variable);
buf : 			tim_position += i;
buf : 
buf : 			dtim_period = ie[i + 3];
buf : 
buf : 			b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 					B43legacy_SHM_SH_TIMPOS, tim_position);
buf : 			b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 					B43legacy_SHM_SH_DTIMP, dtim_period);
buf : 			break;
buf : 		}
buf : 		i += ie_len + 2;
buf : 	}
buf : 	if (!tim_found) {
if (!tim_found) { 
buf : 		b43legacywarn(dev->wl, "Did not find a valid TIM IE in the "
buf : 			      "beacon template packet. AP or IBSS operation "
buf : 			      "may be broken.\n");
buf : 	} else
buf : 		b43legacydbg(dev->wl, "Updated beacon template\n");
buf : }
buf : 
buf : static void b43legacy_write_probe_resp_plcp(struct b43legacy_wldev *dev,
buf : 					    u16 shm_offset, u16 size,
buf : 					    struct ieee80211_rate *rate)
buf : {
buf : 	struct b43legacy_plcp_hdr4 plcp;
buf : 	u32 tmp;
buf : 	__le16 dur;
buf : 
buf : 	plcp.data = 0;
buf : 	b43legacy_generate_plcp_hdr(&plcp, size + FCS_LEN, rate->hw_value);
buf : 	dur = ieee80211_generic_frame_duration(dev->wl->hw,
buf : 					       dev->wl->vif,
if, 
buf : 					       IEEE80211_BAND_2GHZ,
buf : 					       size,
buf : 					       rate);
buf : 	/* Write PLCP in two parts and timing for packet transfer */
for packet transfer */ 
buf : 	tmp = le32_to_cpu(plcp.data);
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, shm_offset,
buf : 			      tmp & 0xFFFF);
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, shm_offset + 2,
buf : 			      tmp >> 16);
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, shm_offset + 6,
buf : 			      le16_to_cpu(dur));
buf : }
buf : 
buf : /* Instead of using custom probe response template, this function
buf :  * just patches custom beacon template by:
buf :  * 1) Changing packet type
buf :  * 2) Patching duration field
buf :  * 3) Stripping TIM
buf :  */
buf : static const u8 *b43legacy_generate_probe_resp(struct b43legacy_wldev *dev,
buf : 					       u16 *dest_size,
buf : 					       struct ieee80211_rate *rate)
buf : {
buf : 	const u8 *src_data;
buf : 	u8 *dest_data;
buf : 	u16 src_size, elem_size, src_pos, dest_pos;
buf : 	__le16 dur;
buf : 	struct ieee80211_hdr *hdr;
buf : 	size_t ie_start;
buf : 
buf : 	src_size = dev->wl->current_beacon->len;
buf : 	src_data = (const u8 *)dev->wl->current_beacon->data;
buf : 
buf : 	/* Get the start offset of the variable IEs in the packet. */
buf : 	ie_start = offsetof(struct ieee80211_mgmt, u.probe_resp.variable);
buf : 	B43legacy_WARN_ON(ie_start != offsetof(struct ieee80211_mgmt,
buf : 					       u.beacon.variable));
buf : 
buf : 	if (B43legacy_WARN_ON(src_size < ie_start))
if (B43legacy_WARN_ON(src_size < ie_start)) 
buf : 		return NULL;
buf : 
buf : 	dest_data = kmalloc(src_size, GFP_ATOMIC);
buf : 	if (unlikely(!dest_data))
if (unlikely(!dest_data)) 
buf : 		return NULL;
buf : 
buf : 	/* Copy the static data and all Information Elements, except the TIM. */
formation Elements, except the TIM. */ 
buf : 	memcpy(dest_data, src_data, ie_start);
buf : 	src_pos = ie_start;
buf : 	dest_pos = ie_start;
buf : 	for ( ; src_pos < src_size - 2; src_pos += elem_size) {
for ( ; src_pos < src_size - 2; src_pos += elem_size) { 
buf : 		elem_size = src_data[src_pos + 1] + 2;
buf : 		if (src_data[src_pos] == 5) {
if (src_data[src_pos] == 5) { 
buf : 			/* This is the TIM. */
buf : 			continue;
buf : 		}
buf : 		memcpy(dest_data + dest_pos, src_data + src_pos, elem_size);
buf : 		dest_pos += elem_size;
buf : 	}
buf : 	*dest_size = dest_pos;
buf : 	hdr = (struct ieee80211_hdr *)dest_data;
buf : 
buf : 	/* Set the frame control. */
buf : 	hdr->frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
buf : 					 IEEE80211_STYPE_PROBE_RESP);
buf : 	dur = ieee80211_generic_frame_duration(dev->wl->hw,
buf : 					       dev->wl->vif,
if, 
buf : 					       IEEE80211_BAND_2GHZ,
buf : 					       *dest_size,
buf : 					       rate);
buf : 	hdr->duration_id = dur;
buf : 
buf : 	return dest_data;
buf : }
buf : 
buf : static void b43legacy_write_probe_resp_template(struct b43legacy_wldev *dev,
buf : 						u16 ram_offset,
buf : 						u16 shm_size_offset,
buf : 						struct ieee80211_rate *rate)
buf : {
buf : 	const u8 *probe_resp_data;
buf : 	u16 size;
buf : 
buf : 	size = dev->wl->current_beacon->len;
buf : 	probe_resp_data = b43legacy_generate_probe_resp(dev, &size, rate);
buf : 	if (unlikely(!probe_resp_data))
if (unlikely(!probe_resp_data)) 
buf : 		return;
buf : 
buf : 	/* Looks like PLCP headers plus packet timings are stored for
for 
buf : 	 * all possible basic rates
buf : 	 */
buf : 	b43legacy_write_probe_resp_plcp(dev, 0x31A, size,
buf : 					&b43legacy_b_ratetable[0]);
buf : 	b43legacy_write_probe_resp_plcp(dev, 0x32C, size,
buf : 					&b43legacy_b_ratetable[1]);
buf : 	b43legacy_write_probe_resp_plcp(dev, 0x33E, size,
buf : 					&b43legacy_b_ratetable[2]);
buf : 	b43legacy_write_probe_resp_plcp(dev, 0x350, size,
buf : 					&b43legacy_b_ratetable[3]);
buf : 
buf : 	size = min_t(size_t, size,
buf : 		   0x200 - sizeof(struct b43legacy_plcp_hdr6));
buf : 	b43legacy_write_template_common(dev, probe_resp_data,
buf : 					size, ram_offset,
buf : 					shm_size_offset, rate->hw_value);
buf : 	kfree(probe_resp_data);
buf : }
buf : 
buf : static void b43legacy_upload_beacon0(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_wl *wl = dev->wl;
buf : 
buf : 	if (wl->beacon0_uploaded)
if (wl->beacon0_uploaded) 
buf : 		return;
buf : 	b43legacy_write_beacon_template(dev, 0x68, 0x18);
buf : 	/* FIXME: Probe resp upload doesn't really belong here,
buf : 	 *        but we don't use that feature anyway. */
buf : 	b43legacy_write_probe_resp_template(dev, 0x268, 0x4A,
buf : 				      &__b43legacy_ratetable[3]);
buf : 	wl->beacon0_uploaded = true;
buf : }
buf : 
buf : static void b43legacy_upload_beacon1(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_wl *wl = dev->wl;
buf : 
buf : 	if (wl->beacon1_uploaded)
if (wl->beacon1_uploaded) 
buf : 		return;
buf : 	b43legacy_write_beacon_template(dev, 0x468, 0x1A);
buf : 	wl->beacon1_uploaded = true;
buf : }
buf : 
buf : static void handle_irq_beacon(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_wl *wl = dev->wl;
buf : 	u32 cmd, beacon0_valid, beacon1_valid;
buf : 
buf : 	if (!b43legacy_is_mode(wl, NL80211_IFTYPE_AP))
if (!b43legacy_is_mode(wl, NL80211_IFTYPE_AP)) 
buf : 		return;
buf : 
buf : 	/* This is the bottom half of the asynchronous beacon update. */
buf : 
buf : 	/* Ignore interrupt in the future. */
buf : 	dev->irq_mask &= ~B43legacy_IRQ_BEACON;
buf : 
buf : 	cmd = b43legacy_read32(dev, B43legacy_MMIO_MACCMD);
buf : 	beacon0_valid = (cmd & B43legacy_MACCMD_BEACON0_VALID);
buf : 	beacon1_valid = (cmd & B43legacy_MACCMD_BEACON1_VALID);
buf : 
buf : 	/* Schedule interrupt manually, if busy. */
if busy. */ 
buf : 	if (beacon0_valid && beacon1_valid) {
buf : 		b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_REASON, B43legacy_IRQ_BEACON);
buf : 		dev->irq_mask |= B43legacy_IRQ_BEACON;
buf : 		return;
buf : 	}
buf : 
buf : 	if (unlikely(wl->beacon_templates_virgin)) {
if (unlikely(wl->beacon_templates_virgin)) { 
buf : 		/* We never uploaded a beacon before.
fore. 
buf : 		 * Upload both templates now, but only mark one valid. */
buf : 		wl->beacon_templates_virgin = false;
buf : 		b43legacy_upload_beacon0(dev);
buf : 		b43legacy_upload_beacon1(dev);
buf : 		cmd = b43legacy_read32(dev, B43legacy_MMIO_MACCMD);
buf : 		cmd |= B43legacy_MACCMD_BEACON0_VALID;
buf : 		b43legacy_write32(dev, B43legacy_MMIO_MACCMD, cmd);
buf : 	} else {
buf : 		if (!beacon0_valid) {
if (!beacon0_valid) { 
buf : 			b43legacy_upload_beacon0(dev);
buf : 			cmd = b43legacy_read32(dev, B43legacy_MMIO_MACCMD);
buf : 			cmd |= B43legacy_MACCMD_BEACON0_VALID;
buf : 			b43legacy_write32(dev, B43legacy_MMIO_MACCMD, cmd);
buf : 		} else if (!beacon1_valid) {
if (!beacon1_valid) { 
buf : 			b43legacy_upload_beacon1(dev);
buf : 			cmd = b43legacy_read32(dev, B43legacy_MMIO_MACCMD);
buf : 			cmd |= B43legacy_MACCMD_BEACON1_VALID;
buf : 			b43legacy_write32(dev, B43legacy_MMIO_MACCMD, cmd);
buf : 		}
buf : 	}
buf : }
buf : 
buf : static void b43legacy_beacon_update_trigger_work(struct work_struct *work)
buf : {
buf : 	struct b43legacy_wl *wl = container_of(work, struct b43legacy_wl,
buf : 					 beacon_update_trigger);
buf : 	struct b43legacy_wldev *dev;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (likely(dev && (b43legacy_status(dev) >= B43legacy_STAT_INITIALIZED))) {
if (likely(dev && (b43legacy_status(dev) >= B43legacy_STAT_INITIALIZED))) { 
buf : 		spin_lock_irq(&wl->irq_lock);
buf : 		/* Update beacon right away or defer to IRQ. */
buf : 		handle_irq_beacon(dev);
buf : 		/* The handler might have updated the IRQ mask. */
buf : 		b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK,
buf : 				  dev->irq_mask);
buf : 		mmiowb();
buf : 		spin_unlock_irq(&wl->irq_lock);
buf : 	}
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : /* Asynchronously update the packet templates in template RAM.
buf :  * Locking: Requires wl->irq_lock to be locked. */
buf : static void b43legacy_update_templates(struct b43legacy_wl *wl)
buf : {
buf : 	struct sk_buff *beacon;
buf : 	/* This is the top half of the ansynchronous beacon update. The bottom
buf : 	 * half is the beacon IRQ. Beacon update must be asynchronous to avoid
buf : 	 * sending an invalid beacon. This can happen for example, if the
if the 
buf : 	 * firmware transmits a beacon while we are updating it. */
while we are updating it. */ 
buf : 
buf : 	/* We could modify the existing beacon and set the aid bit in the TIM
buf : 	 * field, but that would probably require resizing and moving of data
buf : 	 * within the beacon template. Simply request a new beacon and let
buf : 	 * mac80211 do the hard work. */
buf : 	beacon = ieee80211_beacon_get(wl->hw, wl->vif);
if); 
buf : 	if (unlikely(!beacon))
buf : 		return;
buf : 
buf : 	if (wl->current_beacon)
if (wl->current_beacon) 
buf : 		dev_kfree_skb_any(wl->current_beacon);
buf : 	wl->current_beacon = beacon;
buf : 	wl->beacon0_uploaded = false;
buf : 	wl->beacon1_uploaded = false;
buf : 	ieee80211_queue_work(wl->hw, &wl->beacon_update_trigger);
buf : }
buf : 
buf : static void b43legacy_set_beacon_int(struct b43legacy_wldev *dev,
buf : 				     u16 beacon_int)
buf : {
buf : 	b43legacy_time_lock(dev);
buf : 	if (dev->dev->id.revision >= 3) {
if (dev->dev->id.revision >= 3) { 
buf : 		b43legacy_write32(dev, B43legacy_MMIO_TSF_CFP_REP,
buf : 				 (beacon_int << 16));
buf : 		b43legacy_write32(dev, B43legacy_MMIO_TSF_CFP_START,
buf : 				 (beacon_int << 10));
buf : 	} else {
buf : 		b43legacy_write16(dev, 0x606, (beacon_int >> 6));
buf : 		b43legacy_write16(dev, 0x610, beacon_int);
buf : 	}
buf : 	b43legacy_time_unlock(dev);
buf : 	b43legacydbg(dev->wl, "Set beacon interval to %u\n", beacon_int);
buf : }
buf : 
buf : static void handle_irq_ucode_debug(struct b43legacy_wldev *dev)
buf : {
buf : }
buf : 
buf : /* Interrupt handler bottom-half */
buf : static void b43legacy_interrupt_tasklet(struct b43legacy_wldev *dev)
buf : {
buf : 	u32 reason;
buf : 	u32 dma_reason[ARRAY_SIZE(dev->dma_reason)];
buf : 	u32 merged_dma_reason = 0;
buf : 	int i;
buf : 	unsigned long flags;
buf : 
buf : 	spin_lock_irqsave(&dev->wl->irq_lock, flags);
buf : 
buf : 	B43legacy_WARN_ON(b43legacy_status(dev) <
buf : 			  B43legacy_STAT_INITIALIZED);
buf : 
buf : 	reason = dev->irq_reason;
buf : 	for (i = 0; i < ARRAY_SIZE(dma_reason); i++) {
for (i = 0; i < ARRAY_SIZE(dma_reason); i++) { 
buf : 		dma_reason[i] = dev->dma_reason[i];
buf : 		merged_dma_reason |= dma_reason[i];
buf : 	}
buf : 
buf : 	if (unlikely(reason & B43legacy_IRQ_MAC_TXERR))
if (unlikely(reason & B43legacy_IRQ_MAC_TXERR)) 
buf : 		b43legacyerr(dev->wl, "MAC transmission error\n");
buf : 
buf : 	if (unlikely(reason & B43legacy_IRQ_PHY_TXERR)) {
if (unlikely(reason & B43legacy_IRQ_PHY_TXERR)) { 
buf : 		b43legacyerr(dev->wl, "PHY transmission error\n");
buf : 		rmb();
buf : 		if (unlikely(atomic_dec_and_test(&dev->phy.txerr_cnt))) {
if (unlikely(atomic_dec_and_test(&dev->phy.txerr_cnt))) { 
buf : 			b43legacyerr(dev->wl, "Too many PHY TX errors, "
buf : 					      "restarting the controller\n");
buf : 			b43legacy_controller_restart(dev, "PHY TX errors");
buf : 		}
buf : 	}
buf : 
buf : 	if (unlikely(merged_dma_reason & (B43legacy_DMAIRQ_FATALMASK |
if (unlikely(merged_dma_reason & (B43legacy_DMAIRQ_FATALMASK | 
buf : 					  B43legacy_DMAIRQ_NONFATALMASK))) {
buf : 		if (merged_dma_reason & B43legacy_DMAIRQ_FATALMASK) {
if (merged_dma_reason & B43legacy_DMAIRQ_FATALMASK) { 
buf : 			b43legacyerr(dev->wl, "Fatal DMA error: "
buf : 			       "0x%08X, 0x%08X, 0x%08X, "
buf : 			       "0x%08X, 0x%08X, 0x%08X\n",
buf : 			       dma_reason[0], dma_reason[1],
buf : 			       dma_reason[2], dma_reason[3],
buf : 			       dma_reason[4], dma_reason[5]);
buf : 			b43legacy_controller_restart(dev, "DMA error");
buf : 			mmiowb();
buf : 			spin_unlock_irqrestore(&dev->wl->irq_lock, flags);
buf : 			return;
buf : 		}
buf : 		if (merged_dma_reason & B43legacy_DMAIRQ_NONFATALMASK)
if (merged_dma_reason & B43legacy_DMAIRQ_NONFATALMASK) 
buf : 			b43legacyerr(dev->wl, "DMA error: "
buf : 			       "0x%08X, 0x%08X, 0x%08X, "
buf : 			       "0x%08X, 0x%08X, 0x%08X\n",
buf : 			       dma_reason[0], dma_reason[1],
buf : 			       dma_reason[2], dma_reason[3],
buf : 			       dma_reason[4], dma_reason[5]);
buf : 	}
buf : 
buf : 	if (unlikely(reason & B43legacy_IRQ_UCODE_DEBUG))
if (unlikely(reason & B43legacy_IRQ_UCODE_DEBUG)) 
buf : 		handle_irq_ucode_debug(dev);
buf : 	if (reason & B43legacy_IRQ_TBTT_INDI)
if (reason & B43legacy_IRQ_TBTT_INDI) 
buf : 		handle_irq_tbtt_indication(dev);
buf : 	if (reason & B43legacy_IRQ_ATIM_END)
if (reason & B43legacy_IRQ_ATIM_END) 
buf : 		handle_irq_atim_end(dev);
buf : 	if (reason & B43legacy_IRQ_BEACON)
if (reason & B43legacy_IRQ_BEACON) 
buf : 		handle_irq_beacon(dev);
buf : 	if (reason & B43legacy_IRQ_PMQ)
if (reason & B43legacy_IRQ_PMQ) 
buf : 		handle_irq_pmq(dev);
buf : 	if (reason & B43legacy_IRQ_TXFIFO_FLUSH_OK)
if (reason & B43legacy_IRQ_TXFIFO_FLUSH_OK) 
buf : 		;/*TODO*/
buf : 	if (reason & B43legacy_IRQ_NOISESAMPLE_OK)
if (reason & B43legacy_IRQ_NOISESAMPLE_OK) 
buf : 		handle_irq_noise(dev);
buf : 
buf : 	/* Check the DMA reason registers for received data. */
for received data. */ 
buf : 	if (dma_reason[0] & B43legacy_DMAIRQ_RX_DONE) {
buf : 		if (b43legacy_using_pio(dev))
if (b43legacy_using_pio(dev)) 
buf : 			b43legacy_pio_rx(dev->pio.queue0);
buf : 		else
buf : 			b43legacy_dma_rx(dev->dma.rx_ring0);
buf : 	}
buf : 	B43legacy_WARN_ON(dma_reason[1] & B43legacy_DMAIRQ_RX_DONE);
buf : 	B43legacy_WARN_ON(dma_reason[2] & B43legacy_DMAIRQ_RX_DONE);
buf : 	if (dma_reason[3] & B43legacy_DMAIRQ_RX_DONE) {
if (dma_reason[3] & B43legacy_DMAIRQ_RX_DONE) { 
buf : 		if (b43legacy_using_pio(dev))
buf : 			b43legacy_pio_rx(dev->pio.queue3);
buf : 		else
buf : 			b43legacy_dma_rx(dev->dma.rx_ring3);
buf : 	}
buf : 	B43legacy_WARN_ON(dma_reason[4] & B43legacy_DMAIRQ_RX_DONE);
buf : 	B43legacy_WARN_ON(dma_reason[5] & B43legacy_DMAIRQ_RX_DONE);
buf : 
buf : 	if (reason & B43legacy_IRQ_TX_OK)
if (reason & B43legacy_IRQ_TX_OK) 
buf : 		handle_irq_transmit_status(dev);
buf : 
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK, dev->irq_mask);
buf : 	mmiowb();
buf : 	spin_unlock_irqrestore(&dev->wl->irq_lock, flags);
buf : }
buf : 
buf : static void pio_irq_workaround(struct b43legacy_wldev *dev,
buf : 			       u16 base, int queueidx)
buf : {
buf : 	u16 rxctl;
buf : 
buf : 	rxctl = b43legacy_read16(dev, base + B43legacy_PIO_RXCTL);
buf : 	if (rxctl & B43legacy_PIO_RXCTL_DATAAVAILABLE)
if (rxctl & B43legacy_PIO_RXCTL_DATAAVAILABLE) 
buf : 		dev->dma_reason[queueidx] |= B43legacy_DMAIRQ_RX_DONE;
buf : 	else
buf : 		dev->dma_reason[queueidx] &= ~B43legacy_DMAIRQ_RX_DONE;
buf : }
buf : 
buf : static void b43legacy_interrupt_ack(struct b43legacy_wldev *dev, u32 reason)
buf : {
buf : 	if (b43legacy_using_pio(dev) &&
if (b43legacy_using_pio(dev) && 
buf : 	    (dev->dev->id.revision < 3) &&
buf : 	    (!(reason & B43legacy_IRQ_PIO_WORKAROUND))) {
buf : 		/* Apply a PIO specific workaround to the dma_reasons */
ific workaround to the dma_reasons */ 
buf : 		pio_irq_workaround(dev, B43legacy_MMIO_PIO1_BASE, 0);
buf : 		pio_irq_workaround(dev, B43legacy_MMIO_PIO2_BASE, 1);
buf : 		pio_irq_workaround(dev, B43legacy_MMIO_PIO3_BASE, 2);
buf : 		pio_irq_workaround(dev, B43legacy_MMIO_PIO4_BASE, 3);
buf : 	}
buf : 
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_REASON, reason);
buf : 
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA0_REASON,
buf : 			  dev->dma_reason[0]);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA1_REASON,
buf : 			  dev->dma_reason[1]);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA2_REASON,
buf : 			  dev->dma_reason[2]);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA3_REASON,
buf : 			  dev->dma_reason[3]);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA4_REASON,
buf : 			  dev->dma_reason[4]);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA5_REASON,
buf : 			  dev->dma_reason[5]);
buf : }
buf : 
buf : /* Interrupt handler top-half */
buf : static irqreturn_t b43legacy_interrupt_handler(int irq, void *dev_id)
buf : {
buf : 	irqreturn_t ret = IRQ_NONE;
buf : 	struct b43legacy_wldev *dev = dev_id;
buf : 	u32 reason;
buf : 
buf : 	B43legacy_WARN_ON(!dev);
buf : 
buf : 	spin_lock(&dev->wl->irq_lock);
buf : 
buf : 	if (unlikely(b43legacy_status(dev) < B43legacy_STAT_STARTED))
if (unlikely(b43legacy_status(dev) < B43legacy_STAT_STARTED)) 
buf : 		/* This can only happen on shared IRQ lines. */
buf : 		goto out;
buf : 	reason = b43legacy_read32(dev, B43legacy_MMIO_GEN_IRQ_REASON);
buf : 	if (reason == 0xffffffff) /* shared IRQ */
if (reason == 0xffffffff) /* shared IRQ */ 
buf : 		goto out;
buf : 	ret = IRQ_HANDLED;
buf : 	reason &= dev->irq_mask;
buf : 	if (!reason)
if (!reason) 
buf : 		goto out;
buf : 
buf : 	dev->dma_reason[0] = b43legacy_read32(dev,
buf : 					      B43legacy_MMIO_DMA0_REASON)
buf : 					      & 0x0001DC00;
buf : 	dev->dma_reason[1] = b43legacy_read32(dev,
buf : 					      B43legacy_MMIO_DMA1_REASON)
buf : 					      & 0x0000DC00;
buf : 	dev->dma_reason[2] = b43legacy_read32(dev,
buf : 					      B43legacy_MMIO_DMA2_REASON)
buf : 					      & 0x0000DC00;
buf : 	dev->dma_reason[3] = b43legacy_read32(dev,
buf : 					      B43legacy_MMIO_DMA3_REASON)
buf : 					      & 0x0001DC00;
buf : 	dev->dma_reason[4] = b43legacy_read32(dev,
buf : 					      B43legacy_MMIO_DMA4_REASON)
buf : 					      & 0x0000DC00;
buf : 	dev->dma_reason[5] = b43legacy_read32(dev,
buf : 					      B43legacy_MMIO_DMA5_REASON)
buf : 					      & 0x0000DC00;
buf : 
buf : 	b43legacy_interrupt_ack(dev, reason);
buf : 	/* Disable all IRQs. They are enabled again in the bottom half. */
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK, 0);
buf : 	/* Save the reason code and call our bottom half. */
buf : 	dev->irq_reason = reason;
buf : 	tasklet_schedule(&dev->isr_tasklet);
buf : out:
buf : 	mmiowb();
buf : 	spin_unlock(&dev->wl->irq_lock);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void b43legacy_release_firmware(struct b43legacy_wldev *dev)
buf : {
buf : 	release_firmware(dev->fw.ucode);
buf : 	dev->fw.ucode = NULL;
buf : 	release_firmware(dev->fw.pcm);
buf : 	dev->fw.pcm = NULL;
buf : 	release_firmware(dev->fw.initvals);
buf : 	dev->fw.initvals = NULL;
buf : 	release_firmware(dev->fw.initvals_band);
buf : 	dev->fw.initvals_band = NULL;
buf : }
buf : 
buf : static void b43legacy_print_fw_helptext(struct b43legacy_wl *wl)
buf : {
buf : 	b43legacyerr(wl, "You must go to http://wireless.kernel.org/en/users/"
buf : 		     "Drivers/b43#devicefirmware "
buf : 		     "and download the correct firmware (version 3).\n");
buf : }
buf : 
buf : static void b43legacy_fw_cb(const struct firmware *firmware, void *context)
buf : {
buf : 	struct b43legacy_wldev *dev = context;
buf : 
buf : 	dev->fwp = firmware;
buf : 	complete(&dev->fw_load_complete);
buf : }
buf : 
buf : static int do_request_fw(struct b43legacy_wldev *dev,
buf : 			 const char *name,
buf : 			 const struct firmware **fw, bool async)
buf : {
buf : 	char path[sizeof(modparam_fwpostfix) + 32];
buf : 	struct b43legacy_fw_header *hdr;
buf : 	u32 size;
buf : 	int err;
buf : 
buf : 	if (!name)
if (!name) 
buf : 		return 0;
buf : 
buf : 	snprintf(path, ARRAY_SIZE(path),
buf : 		 "b43legacy%s/%s.fw",
buf : 		 modparam_fwpostfix, name);
buf : 	b43legacyinfo(dev->wl, "Loading firmware %s\n", path);
buf : 	if (async) {
if (async) { 
buf : 		init_completion(&dev->fw_load_complete);
buf : 		err = request_firmware_nowait(THIS_MODULE, 1, path,
buf : 					      dev->dev->dev, GFP_KERNEL,
buf : 					      dev, b43legacy_fw_cb);
buf : 		if (err) {
if (err) { 
buf : 			b43legacyerr(dev->wl, "Unable to load firmware\n");
buf : 			return err;
buf : 		}
buf : 		/* stall here until fw ready */
buf : 		wait_for_completion(&dev->fw_load_complete);
for_completion(&dev->fw_load_complete); 
buf : 		if (!dev->fwp)
buf : 			err = -EINVAL;
buf : 		*fw = dev->fwp;
buf : 	} else {
buf : 		err = request_firmware(fw, path, dev->dev->dev);
buf : 	}
buf : 	if (err) {
if (err) { 
buf : 		b43legacyerr(dev->wl, "Firmware file \"%s\" not found "
buf : 		       "or load failed.\n", path);
buf : 		return err;
buf : 	}
buf : 	if ((*fw)->size < sizeof(struct b43legacy_fw_header))
if ((*fw)->size < sizeof(struct b43legacy_fw_header)) 
buf : 		goto err_format;
format; 
buf : 	hdr = (struct b43legacy_fw_header *)((*fw)->data);
buf : 	switch (hdr->type) {
buf : 	case B43legacy_FW_TYPE_UCODE:
buf : 	case B43legacy_FW_TYPE_PCM:
buf : 		size = be32_to_cpu(hdr->size);
buf : 		if (size != (*fw)->size - sizeof(struct b43legacy_fw_header))
if (size != (*fw)->size - sizeof(struct b43legacy_fw_header)) 
buf : 			goto err_format;
format; 
buf : 		/* fallthrough */
buf : 	case B43legacy_FW_TYPE_IV:
buf : 		if (hdr->ver != 1)
if (hdr->ver != 1) 
buf : 			goto err_format;
format; 
buf : 		break;
buf : 	default:
buf : 		goto err_format;
format; 
buf : 	}
buf : 
buf : 	return err;
buf : 
buf : err_format:
format: 
buf : 	b43legacyerr(dev->wl, "Firmware file \"%s\" format error.\n", path);
buf : 	return -EPROTO;
buf : }
buf : 
buf : static int b43legacy_one_core_attach(struct ssb_device *dev,
buf : 				     struct b43legacy_wl *wl);
buf : static void b43legacy_one_core_detach(struct ssb_device *dev);
buf : 
buf : static void b43legacy_request_firmware(struct work_struct *work)
buf : {
buf : 	struct b43legacy_wl *wl = container_of(work,
buf : 				  struct b43legacy_wl, firmware_load);
buf : 	struct b43legacy_wldev *dev = wl->current_dev;
buf : 	struct b43legacy_firmware *fw = &dev->fw;
buf : 	const u8 rev = dev->dev->id.revision;
buf : 	const char *filename;
buf : 	int err;
buf : 
buf : 	if (!fw->ucode) {
if (!fw->ucode) { 
buf : 		if (rev == 2)
buf : 			filename = "ucode2";
buf : 		else if (rev == 4)
if (rev == 4) 
buf : 			filename = "ucode4";
buf : 		else
buf : 			filename = "ucode5";
buf : 		err = do_request_fw(dev, filename, &fw->ucode, true);
buf : 		if (err)
if (err) 
buf : 			goto err_load;
buf : 	}
buf : 	if (!fw->pcm) {
if (!fw->pcm) { 
buf : 		if (rev < 5)
buf : 			filename = "pcm4";
buf : 		else
buf : 			filename = "pcm5";
buf : 		err = do_request_fw(dev, filename, &fw->pcm, false);
buf : 		if (err)
if (err) 
buf : 			goto err_load;
buf : 	}
buf : 	if (!fw->initvals) {
if (!fw->initvals) { 
buf : 		switch (dev->phy.type) {
buf : 		case B43legacy_PHYTYPE_B:
buf : 		case B43legacy_PHYTYPE_G:
buf : 			if ((rev >= 5) && (rev <= 10))
if ((rev >= 5) && (rev <= 10)) 
buf : 				filename = "b0g0initvals5";
buf : 			else if (rev == 2 || rev == 4)
if (rev == 2 || rev == 4) 
buf : 				filename = "b0g0initvals2";
buf : 			else
buf : 				goto err_no_initvals;
buf : 			break;
buf : 		default:
buf : 			goto err_no_initvals;
buf : 		}
buf : 		err = do_request_fw(dev, filename, &fw->initvals, false);
buf : 		if (err)
if (err) 
buf : 			goto err_load;
buf : 	}
buf : 	if (!fw->initvals_band) {
if (!fw->initvals_band) { 
buf : 		switch (dev->phy.type) {
buf : 		case B43legacy_PHYTYPE_B:
buf : 		case B43legacy_PHYTYPE_G:
buf : 			if ((rev >= 5) && (rev <= 10))
if ((rev >= 5) && (rev <= 10)) 
buf : 				filename = "b0g0bsinitvals5";
buf : 			else if (rev >= 11)
if (rev >= 11) 
buf : 				filename = NULL;
buf : 			else if (rev == 2 || rev == 4)
if (rev == 2 || rev == 4) 
buf : 				filename = NULL;
buf : 			else
buf : 				goto err_no_initvals;
buf : 			break;
buf : 		default:
buf : 			goto err_no_initvals;
buf : 		}
buf : 		err = do_request_fw(dev, filename, &fw->initvals_band, false);
buf : 		if (err)
if (err) 
buf : 			goto err_load;
buf : 	}
buf : 	err = ieee80211_register_hw(wl->hw);
buf : 	if (err)
if (err) 
buf : 		goto err_one_core_detach;
buf : 	return;
buf : 
buf : err_one_core_detach:
buf : 	b43legacy_one_core_detach(dev->dev);
buf : 	goto error;
buf : 
buf : err_load:
buf : 	b43legacy_print_fw_helptext(dev->wl);
buf : 	goto error;
buf : 
buf : err_no_initvals:
buf : 	err = -ENODEV;
buf : 	b43legacyerr(dev->wl, "No Initial Values firmware file for PHY %u, "
for PHY %u, " 
buf : 	       "core rev %u\n", dev->phy.type, rev);
buf : 	goto error;
buf : 
buf : error:
buf : 	b43legacy_release_firmware(dev);
buf : 	return;
buf : }
buf : 
buf : static int b43legacy_upload_microcode(struct b43legacy_wldev *dev)
buf : {
buf : 	struct wiphy *wiphy = dev->wl->hw->wiphy;
buf : 	const size_t hdr_len = sizeof(struct b43legacy_fw_header);
buf : 	const __be32 *data;
buf : 	unsigned int i;
buf : 	unsigned int len;
buf : 	u16 fwrev;
buf : 	u16 fwpatch;
buf : 	u16 fwdate;
buf : 	u16 fwtime;
buf : 	u32 tmp, macctl;
buf : 	int err = 0;
buf : 
buf : 	/* Jump the microcode PSM to offset 0 */
buf : 	macctl = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	B43legacy_WARN_ON(macctl & B43legacy_MACCTL_PSM_RUN);
buf : 	macctl |= B43legacy_MACCTL_PSM_JMP0;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, macctl);
buf : 	/* Zero out all microcode PSM registers and shared memory. */
buf : 	for (i = 0; i < 64; i++)
for (i = 0; i < 64; i++) 
buf : 		b43legacy_shm_write16(dev, B43legacy_SHM_WIRELESS, i, 0);
buf : 	for (i = 0; i < 4096; i += 2)
for (i = 0; i < 4096; i += 2) 
buf : 		b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, i, 0);
buf : 
buf : 	/* Upload Microcode. */
buf : 	data = (__be32 *) (dev->fw.ucode->data + hdr_len);
buf : 	len = (dev->fw.ucode->size - hdr_len) / sizeof(__be32);
buf : 	b43legacy_shm_control_word(dev,
buf : 				   B43legacy_SHM_UCODE |
buf : 				   B43legacy_SHM_AUTOINC_W,
buf : 				   0x0000);
buf : 	for (i = 0; i < len; i++) {
for (i = 0; i < len; i++) { 
buf : 		b43legacy_write32(dev, B43legacy_MMIO_SHM_DATA,
buf : 				    be32_to_cpu(data[i]));
buf : 		udelay(10);
buf : 	}
buf : 
buf : 	if (dev->fw.pcm) {
if (dev->fw.pcm) { 
buf : 		/* Upload PCM data. */
buf : 		data = (__be32 *) (dev->fw.pcm->data + hdr_len);
buf : 		len = (dev->fw.pcm->size - hdr_len) / sizeof(__be32);
buf : 		b43legacy_shm_control_word(dev, B43legacy_SHM_HW, 0x01EA);
buf : 		b43legacy_write32(dev, B43legacy_MMIO_SHM_DATA, 0x00004000);
buf : 		/* No need for autoinc bit in SHM_HW */
for autoinc bit in SHM_HW */ 
buf : 		b43legacy_shm_control_word(dev, B43legacy_SHM_HW, 0x01EB);
buf : 		for (i = 0; i < len; i++) {
for (i = 0; i < len; i++) { 
buf : 			b43legacy_write32(dev, B43legacy_MMIO_SHM_DATA,
buf : 					  be32_to_cpu(data[i]));
buf : 			udelay(10);
buf : 		}
buf : 	}
buf : 
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_REASON,
buf : 			  B43legacy_IRQ_ALL);
buf : 
buf : 	/* Start the microcode PSM */
buf : 	macctl = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	macctl &= ~B43legacy_MACCTL_PSM_JMP0;
buf : 	macctl |= B43legacy_MACCTL_PSM_RUN;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, macctl);
buf : 
buf : 	/* Wait for the microcode to load and respond */
for the microcode to load and respond */ 
buf : 	i = 0;
buf : 	while (1) {
while (1) { 
buf : 		tmp = b43legacy_read32(dev, B43legacy_MMIO_GEN_IRQ_REASON);
buf : 		if (tmp == B43legacy_IRQ_MAC_SUSPENDED)
if (tmp == B43legacy_IRQ_MAC_SUSPENDED) 
buf : 			break;
buf : 		i++;
buf : 		if (i >= B43legacy_IRQWAIT_MAX_RETRIES) {
if (i >= B43legacy_IRQWAIT_MAX_RETRIES) { 
buf : 			b43legacyerr(dev->wl, "Microcode not responding\n");
buf : 			b43legacy_print_fw_helptext(dev->wl);
buf : 			err = -ENODEV;
buf : 			goto error;
buf : 		}
buf : 		msleep_interruptible(50);
buf : 		if (signal_pending(current)) {
if (signal_pending(current)) { 
buf : 			err = -EINTR;
buf : 			goto error;
buf : 		}
buf : 	}
buf : 	/* dummy read follows */
buf : 	b43legacy_read32(dev, B43legacy_MMIO_GEN_IRQ_REASON);
buf : 
buf : 	/* Get and check the revisions. */
buf : 	fwrev = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				     B43legacy_SHM_SH_UCODEREV);
buf : 	fwpatch = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				       B43legacy_SHM_SH_UCODEPATCH);
buf : 	fwdate = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				      B43legacy_SHM_SH_UCODEDATE);
buf : 	fwtime = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				      B43legacy_SHM_SH_UCODETIME);
buf : 
buf : 	if (fwrev > 0x128) {
if (fwrev > 0x128) { 
buf : 		b43legacyerr(dev->wl, "YOU ARE TRYING TO LOAD V4 FIRMWARE."
buf : 			     " Only firmware from binary drivers version 3.x"
buf : 			     " is supported. You must change your firmware"
buf : 			     " files.\n");
buf : 		b43legacy_print_fw_helptext(dev->wl);
buf : 		err = -EOPNOTSUPP;
buf : 		goto error;
buf : 	}
buf : 	b43legacyinfo(dev->wl, "Loading firmware version 0x%X, patch level %u "
buf : 		      "(20%.2i-%.2i-%.2i %.2i:%.2i:%.2i)\n", fwrev, fwpatch,
buf : 		      (fwdate >> 12) & 0xF, (fwdate >> 8) & 0xF, fwdate & 0xFF,
buf : 		      (fwtime >> 11) & 0x1F, (fwtime >> 5) & 0x3F,
buf : 		      fwtime & 0x1F);
buf : 
buf : 	dev->fw.rev = fwrev;
buf : 	dev->fw.patch = fwpatch;
buf : 
buf : 	snprintf(wiphy->fw_version, sizeof(wiphy->fw_version), "%u.%u",
buf : 			dev->fw.rev, dev->fw.patch);
buf : 	wiphy->hw_version = dev->dev->id.coreid;
buf : 
buf : 	return 0;
buf : 
buf : error:
buf : 	macctl = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	macctl &= ~B43legacy_MACCTL_PSM_RUN;
buf : 	macctl |= B43legacy_MACCTL_PSM_JMP0;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, macctl);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int b43legacy_write_initvals(struct b43legacy_wldev *dev,
buf : 				    const struct b43legacy_iv *ivals,
buf : 				    size_t count,
buf : 				    size_t array_size)
buf : {
buf : 	const struct b43legacy_iv *iv;
buf : 	u16 offset;
buf : 	size_t i;
buf : 	bool bit32;
buf : 
buf : 	BUILD_BUG_ON(sizeof(struct b43legacy_iv) != 6);
buf : 	iv = ivals;
buf : 	for (i = 0; i < count; i++) {
for (i = 0; i < count; i++) { 
buf : 		if (array_size < sizeof(iv->offset_size))
buf : 			goto err_format;
format; 
buf : 		array_size -= sizeof(iv->offset_size);
buf : 		offset = be16_to_cpu(iv->offset_size);
buf : 		bit32 = !!(offset & B43legacy_IV_32BIT);
buf : 		offset &= B43legacy_IV_OFFSET_MASK;
buf : 		if (offset >= 0x1000)
if (offset >= 0x1000) 
buf : 			goto err_format;
format; 
buf : 		if (bit32) {
buf : 			u32 value;
buf : 
buf : 			if (array_size < sizeof(iv->data.d32))
if (array_size < sizeof(iv->data.d32)) 
buf : 				goto err_format;
format; 
buf : 			array_size -= sizeof(iv->data.d32);
buf : 
buf : 			value = get_unaligned_be32(&iv->data.d32);
buf : 			b43legacy_write32(dev, offset, value);
buf : 
buf : 			iv = (const struct b43legacy_iv *)((const uint8_t *)iv +
buf : 							sizeof(__be16) +
buf : 							sizeof(__be32));
buf : 		} else {
buf : 			u16 value;
buf : 
buf : 			if (array_size < sizeof(iv->data.d16))
if (array_size < sizeof(iv->data.d16)) 
buf : 				goto err_format;
format; 
buf : 			array_size -= sizeof(iv->data.d16);
buf : 
buf : 			value = be16_to_cpu(iv->data.d16);
buf : 			b43legacy_write16(dev, offset, value);
buf : 
buf : 			iv = (const struct b43legacy_iv *)((const uint8_t *)iv +
buf : 							sizeof(__be16) +
buf : 							sizeof(__be16));
buf : 		}
buf : 	}
buf : 	if (array_size)
if (array_size) 
buf : 		goto err_format;
format; 
buf : 
buf : 	return 0;
buf : 
buf : err_format:
format: 
buf : 	b43legacyerr(dev->wl, "Initial Values Firmware file-format error.\n");
buf : 	b43legacy_print_fw_helptext(dev->wl);
buf : 
buf : 	return -EPROTO;
buf : }
buf : 
buf : static int b43legacy_upload_initvals(struct b43legacy_wldev *dev)
buf : {
buf : 	const size_t hdr_len = sizeof(struct b43legacy_fw_header);
buf : 	const struct b43legacy_fw_header *hdr;
buf : 	struct b43legacy_firmware *fw = &dev->fw;
buf : 	const struct b43legacy_iv *ivals;
buf : 	size_t count;
buf : 	int err;
buf : 
buf : 	hdr = (const struct b43legacy_fw_header *)(fw->initvals->data);
buf : 	ivals = (const struct b43legacy_iv *)(fw->initvals->data + hdr_len);
buf : 	count = be32_to_cpu(hdr->size);
buf : 	err = b43legacy_write_initvals(dev, ivals, count,
buf : 				 fw->initvals->size - hdr_len);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 	if (fw->initvals_band) {
if (fw->initvals_band) { 
buf : 		hdr = (const struct b43legacy_fw_header *)
buf : 		      (fw->initvals_band->data);
buf : 		ivals = (const struct b43legacy_iv *)(fw->initvals_band->data
buf : 			+ hdr_len);
buf : 		count = be32_to_cpu(hdr->size);
buf : 		err = b43legacy_write_initvals(dev, ivals, count,
buf : 					 fw->initvals_band->size - hdr_len);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : out:
buf : 
buf : 	return err;
buf : }
buf : 
buf : /* Initialize the GPIOs
buf :  * http://bcm-specs.sipsolutions.net/GPIO
buf :  */
buf : static int b43legacy_gpio_init(struct b43legacy_wldev *dev)
buf : {
buf : 	struct ssb_bus *bus = dev->dev->bus;
buf : 	struct ssb_device *gpiodev, *pcidev = NULL;
buf : 	u32 mask;
buf : 	u32 set;
buf : 
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL,
buf : 			  b43legacy_read32(dev,
buf : 			  B43legacy_MMIO_MACCTL)
buf : 			  & 0xFFFF3FFF);
buf : 
buf : 	b43legacy_write16(dev, B43legacy_MMIO_GPIO_MASK,
buf : 			  b43legacy_read16(dev,
buf : 			  B43legacy_MMIO_GPIO_MASK)
buf : 			  | 0x000F);
buf : 
buf : 	mask = 0x0000001F;
buf : 	set = 0x0000000F;
buf : 	if (dev->dev->bus->chip_id == 0x4301) {
if (dev->dev->bus->chip_id == 0x4301) { 
buf : 		mask |= 0x0060;
buf : 		set |= 0x0060;
buf : 	}
buf : 	if (dev->dev->bus->sprom.boardflags_lo & B43legacy_BFL_PACTRL) {
if (dev->dev->bus->sprom.boardflags_lo & B43legacy_BFL_PACTRL) { 
buf : 		b43legacy_write16(dev, B43legacy_MMIO_GPIO_MASK,
buf : 				  b43legacy_read16(dev,
buf : 				  B43legacy_MMIO_GPIO_MASK)
buf : 				  | 0x0200);
buf : 		mask |= 0x0200;
buf : 		set |= 0x0200;
buf : 	}
buf : 	if (dev->dev->id.revision >= 2)
if (dev->dev->id.revision >= 2) 
buf : 		mask  |= 0x0010; /* FIXME: This is redundant. */
buf : 
buf : #ifdef CONFIG_SSB_DRIVER_PCICORE
ifdef CONFIG_SSB_DRIVER_PCICORE 
buf : 	pcidev = bus->pcicore.dev;
buf : #endif
if 
buf : 	gpiodev = bus->chipco.dev ? : pcidev;
buf : 	if (!gpiodev)
if (!gpiodev) 
buf : 		return 0;
buf : 	ssb_write32(gpiodev, B43legacy_GPIO_CONTROL,
buf : 		    (ssb_read32(gpiodev, B43legacy_GPIO_CONTROL)
buf : 		     & ~mask) | set);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /* Turn off all GPIO stuff. Call this on module unload, for example. */
for example. */ 
buf : static void b43legacy_gpio_cleanup(struct b43legacy_wldev *dev)
buf : {
buf : 	struct ssb_bus *bus = dev->dev->bus;
buf : 	struct ssb_device *gpiodev, *pcidev = NULL;
buf : 
buf : #ifdef CONFIG_SSB_DRIVER_PCICORE
ifdef CONFIG_SSB_DRIVER_PCICORE 
buf : 	pcidev = bus->pcicore.dev;
buf : #endif
if 
buf : 	gpiodev = bus->chipco.dev ? : pcidev;
buf : 	if (!gpiodev)
if (!gpiodev) 
buf : 		return;
buf : 	ssb_write32(gpiodev, B43legacy_GPIO_CONTROL, 0);
buf : }
buf : 
buf : /* http://bcm-specs.sipsolutions.net/EnableMac */
buf : void b43legacy_mac_enable(struct b43legacy_wldev *dev)
buf : {
buf : 	dev->mac_suspended--;
buf : 	B43legacy_WARN_ON(dev->mac_suspended < 0);
buf : 	B43legacy_WARN_ON(irqs_disabled());
buf : 	if (dev->mac_suspended == 0) {
if (dev->mac_suspended == 0) { 
buf : 		b43legacy_write32(dev, B43legacy_MMIO_MACCTL,
buf : 				  b43legacy_read32(dev,
buf : 				  B43legacy_MMIO_MACCTL)
buf : 				  | B43legacy_MACCTL_ENABLED);
buf : 		b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_REASON,
buf : 				  B43legacy_IRQ_MAC_SUSPENDED);
buf : 		/* the next two are dummy reads */
buf : 		b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 		b43legacy_read32(dev, B43legacy_MMIO_GEN_IRQ_REASON);
buf : 		b43legacy_power_saving_ctl_bits(dev, -1, -1);
buf : 
buf : 		/* Re-enable IRQs. */
buf : 		spin_lock_irq(&dev->wl->irq_lock);
buf : 		b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK,
buf : 				  dev->irq_mask);
buf : 		spin_unlock_irq(&dev->wl->irq_lock);
buf : 	}
buf : }
buf : 
buf : /* http://bcm-specs.sipsolutions.net/SuspendMAC */
buf : void b43legacy_mac_suspend(struct b43legacy_wldev *dev)
buf : {
buf : 	int i;
buf : 	u32 tmp;
buf : 
buf : 	might_sleep();
buf : 	B43legacy_WARN_ON(irqs_disabled());
buf : 	B43legacy_WARN_ON(dev->mac_suspended < 0);
buf : 
buf : 	if (dev->mac_suspended == 0) {
if (dev->mac_suspended == 0) { 
buf : 		/* Mask IRQs before suspending MAC. Otherwise
fore suspending MAC. Otherwise 
buf : 		 * the MAC stays busy and won't suspend. */
buf : 		spin_lock_irq(&dev->wl->irq_lock);
buf : 		b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK, 0);
buf : 		spin_unlock_irq(&dev->wl->irq_lock);
buf : 		b43legacy_synchronize_irq(dev);
buf : 
buf : 		b43legacy_power_saving_ctl_bits(dev, -1, 1);
buf : 		b43legacy_write32(dev, B43legacy_MMIO_MACCTL,
buf : 				  b43legacy_read32(dev,
buf : 				  B43legacy_MMIO_MACCTL)
buf : 				  & ~B43legacy_MACCTL_ENABLED);
buf : 		b43legacy_read32(dev, B43legacy_MMIO_GEN_IRQ_REASON);
buf : 		for (i = 40; i; i--) {
for (i = 40; i; i--) { 
buf : 			tmp = b43legacy_read32(dev,
buf : 					       B43legacy_MMIO_GEN_IRQ_REASON);
buf : 			if (tmp & B43legacy_IRQ_MAC_SUSPENDED)
if (tmp & B43legacy_IRQ_MAC_SUSPENDED) 
buf : 				goto out;
buf : 			msleep(1);
buf : 		}
buf : 		b43legacyerr(dev->wl, "MAC suspend failed\n");
buf : 	}
buf : out:
buf : 	dev->mac_suspended++;
buf : }
buf : 
buf : static void b43legacy_adjust_opmode(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_wl *wl = dev->wl;
buf : 	u32 ctl;
buf : 	u16 cfp_pretbtt;
buf : 
buf : 	ctl = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	/* Reset status to STA infrastructure mode. */
buf : 	ctl &= ~B43legacy_MACCTL_AP;
buf : 	ctl &= ~B43legacy_MACCTL_KEEP_CTL;
buf : 	ctl &= ~B43legacy_MACCTL_KEEP_BADPLCP;
buf : 	ctl &= ~B43legacy_MACCTL_KEEP_BAD;
buf : 	ctl &= ~B43legacy_MACCTL_PROMISC;
buf : 	ctl &= ~B43legacy_MACCTL_BEACPROMISC;
buf : 	ctl |= B43legacy_MACCTL_INFRA;
buf : 
buf : 	if (b43legacy_is_mode(wl, NL80211_IFTYPE_AP))
if (b43legacy_is_mode(wl, NL80211_IFTYPE_AP)) 
buf : 		ctl |= B43legacy_MACCTL_AP;
buf : 	else if (b43legacy_is_mode(wl, NL80211_IFTYPE_ADHOC))
if (b43legacy_is_mode(wl, NL80211_IFTYPE_ADHOC)) 
buf : 		ctl &= ~B43legacy_MACCTL_INFRA;
buf : 
buf : 	if (wl->filter_flags & FIF_CONTROL)
if (wl->filter_flags & FIF_CONTROL) 
buf : 		ctl |= B43legacy_MACCTL_KEEP_CTL;
buf : 	if (wl->filter_flags & FIF_FCSFAIL)
if (wl->filter_flags & FIF_FCSFAIL) 
buf : 		ctl |= B43legacy_MACCTL_KEEP_BAD;
buf : 	if (wl->filter_flags & FIF_PLCPFAIL)
if (wl->filter_flags & FIF_PLCPFAIL) 
buf : 		ctl |= B43legacy_MACCTL_KEEP_BADPLCP;
buf : 	if (wl->filter_flags & FIF_PROMISC_IN_BSS)
if (wl->filter_flags & FIF_PROMISC_IN_BSS) 
buf : 		ctl |= B43legacy_MACCTL_PROMISC;
buf : 	if (wl->filter_flags & FIF_BCN_PRBRESP_PROMISC)
if (wl->filter_flags & FIF_BCN_PRBRESP_PROMISC) 
buf : 		ctl |= B43legacy_MACCTL_BEACPROMISC;
buf : 
buf : 	/* Workaround: On old hardware the HW-MAC-address-filter
buf : 	 * doesn't work properly, so always run promisc in filter
buf : 	 * it in software. */
buf : 	if (dev->dev->id.revision <= 4)
if (dev->dev->id.revision <= 4) 
buf : 		ctl |= B43legacy_MACCTL_PROMISC;
buf : 
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, ctl);
buf : 
buf : 	cfp_pretbtt = 2;
buf : 	if ((ctl & B43legacy_MACCTL_INFRA) &&
if ((ctl & B43legacy_MACCTL_INFRA) && 
buf : 	    !(ctl & B43legacy_MACCTL_AP)) {
buf : 		if (dev->dev->bus->chip_id == 0x4306 &&
if (dev->dev->bus->chip_id == 0x4306 && 
buf : 		    dev->dev->bus->chip_rev == 3)
buf : 			cfp_pretbtt = 100;
buf : 		else
buf : 			cfp_pretbtt = 50;
buf : 	}
buf : 	b43legacy_write16(dev, 0x612, cfp_pretbtt);
buf : }
buf : 
buf : static void b43legacy_rate_memory_write(struct b43legacy_wldev *dev,
buf : 					u16 rate,
buf : 					int is_ofdm)
buf : {
buf : 	u16 offset;
buf : 
buf : 	if (is_ofdm) {
if (is_ofdm) { 
buf : 		offset = 0x480;
buf : 		offset += (b43legacy_plcp_get_ratecode_ofdm(rate) & 0x000F) * 2;
buf : 	} else {
buf : 		offset = 0x4C0;
buf : 		offset += (b43legacy_plcp_get_ratecode_cck(rate) & 0x000F) * 2;
buf : 	}
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, offset + 0x20,
buf : 			      b43legacy_shm_read16(dev,
buf : 			      B43legacy_SHM_SHARED, offset));
buf : }
buf : 
buf : static void b43legacy_rate_memory_init(struct b43legacy_wldev *dev)
buf : {
buf : 	switch (dev->phy.type) {
buf : 	case B43legacy_PHYTYPE_G:
buf : 		b43legacy_rate_memory_write(dev, B43legacy_OFDM_RATE_6MB, 1);
buf : 		b43legacy_rate_memory_write(dev, B43legacy_OFDM_RATE_12MB, 1);
buf : 		b43legacy_rate_memory_write(dev, B43legacy_OFDM_RATE_18MB, 1);
buf : 		b43legacy_rate_memory_write(dev, B43legacy_OFDM_RATE_24MB, 1);
buf : 		b43legacy_rate_memory_write(dev, B43legacy_OFDM_RATE_36MB, 1);
buf : 		b43legacy_rate_memory_write(dev, B43legacy_OFDM_RATE_48MB, 1);
buf : 		b43legacy_rate_memory_write(dev, B43legacy_OFDM_RATE_54MB, 1);
buf : 		/* fallthrough */
buf : 	case B43legacy_PHYTYPE_B:
buf : 		b43legacy_rate_memory_write(dev, B43legacy_CCK_RATE_1MB, 0);
buf : 		b43legacy_rate_memory_write(dev, B43legacy_CCK_RATE_2MB, 0);
buf : 		b43legacy_rate_memory_write(dev, B43legacy_CCK_RATE_5MB, 0);
buf : 		b43legacy_rate_memory_write(dev, B43legacy_CCK_RATE_11MB, 0);
buf : 		break;
buf : 	default:
buf : 		B43legacy_BUG_ON(1);
buf : 	}
buf : }
buf : 
buf : /* Set the TX-Antenna for management frames sent by firmware. */
for management frames sent by firmware. */ 
buf : static void b43legacy_mgmtframe_txantenna(struct b43legacy_wldev *dev,
buf : 					  int antenna)
buf : {
buf : 	u16 ant = 0;
buf : 	u16 tmp;
buf : 
buf : 	switch (antenna) {
buf : 	case B43legacy_ANTENNA0:
buf : 		ant |= B43legacy_TX4_PHY_ANT0;
buf : 		break;
buf : 	case B43legacy_ANTENNA1:
buf : 		ant |= B43legacy_TX4_PHY_ANT1;
buf : 		break;
buf : 	case B43legacy_ANTENNA_AUTO:
buf : 		ant |= B43legacy_TX4_PHY_ANTLAST;
buf : 		break;
buf : 	default:
buf : 		B43legacy_BUG_ON(1);
buf : 	}
buf : 
buf : 	/* FIXME We also need to set the other flags of the PHY control
buf : 	 * field somewhere. */
buf : 
buf : 	/* For Beacons */
buf : 	tmp = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				   B43legacy_SHM_SH_BEACPHYCTL);
buf : 	tmp = (tmp & ~B43legacy_TX4_PHY_ANT) | ant;
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_BEACPHYCTL, tmp);
buf : 	/* For ACK/CTS */
buf : 	tmp = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				   B43legacy_SHM_SH_ACKCTSPHYCTL);
buf : 	tmp = (tmp & ~B43legacy_TX4_PHY_ANT) | ant;
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_ACKCTSPHYCTL, tmp);
buf : 	/* For Probe Resposes */
buf : 	tmp = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 				   B43legacy_SHM_SH_PRPHYCTL);
buf : 	tmp = (tmp & ~B43legacy_TX4_PHY_ANT) | ant;
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_PRPHYCTL, tmp);
buf : }
buf : 
buf : /* This is the opposite of b43legacy_chip_init() */
buf : static void b43legacy_chip_exit(struct b43legacy_wldev *dev)
buf : {
buf : 	b43legacy_radio_turn_off(dev, 1);
buf : 	b43legacy_gpio_cleanup(dev);
buf : 	/* firmware is released later */
buf : }
buf : 
buf : /* Initialize the chip
buf :  * http://bcm-specs.sipsolutions.net/ChipInit
buf :  */
buf : static int b43legacy_chip_init(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_phy *phy = &dev->phy;
buf : 	int err;
buf : 	int tmp;
buf : 	u32 value32, macctl;
buf : 	u16 value16;
buf : 
buf : 	/* Initialize the MAC control */
buf : 	macctl = B43legacy_MACCTL_IHR_ENABLED | B43legacy_MACCTL_SHM_ENABLED;
buf : 	if (dev->phy.gmode)
if (dev->phy.gmode) 
buf : 		macctl |= B43legacy_MACCTL_GMODE;
buf : 	macctl |= B43legacy_MACCTL_INFRA;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, macctl);
buf : 
buf : 	err = b43legacy_upload_microcode(dev);
buf : 	if (err)
if (err) 
buf : 		goto out; /* firmware is released later */
buf : 
buf : 	err = b43legacy_gpio_init(dev);
buf : 	if (err)
if (err) 
buf : 		goto out; /* firmware is released later */
buf : 
buf : 	err = b43legacy_upload_initvals(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_gpio_clean;
buf : 	b43legacy_radio_turn_on(dev);
buf : 
buf : 	b43legacy_write16(dev, 0x03E6, 0x0000);
buf : 	err = b43legacy_phy_init(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_radio_off;
buf : 
buf : 	/* Select initial Interference Mitigation. */
buf : 	tmp = phy->interfmode;
buf : 	phy->interfmode = B43legacy_INTERFMODE_NONE;
buf : 	b43legacy_radio_set_interference_mitigation(dev, tmp);
buf : 
buf : 	b43legacy_phy_set_antenna_diversity(dev);
buf : 	b43legacy_mgmtframe_txantenna(dev, B43legacy_ANTENNA_DEFAULT);
buf : 
buf : 	if (phy->type == B43legacy_PHYTYPE_B) {
if (phy->type == B43legacy_PHYTYPE_B) { 
buf : 		value16 = b43legacy_read16(dev, 0x005E);
buf : 		value16 |= 0x0004;
buf : 		b43legacy_write16(dev, 0x005E, value16);
buf : 	}
buf : 	b43legacy_write32(dev, 0x0100, 0x01000000);
buf : 	if (dev->dev->id.revision < 5)
if (dev->dev->id.revision < 5) 
buf : 		b43legacy_write32(dev, 0x010C, 0x01000000);
buf : 
buf : 	value32 = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	value32 &= ~B43legacy_MACCTL_INFRA;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, value32);
buf : 	value32 = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	value32 |= B43legacy_MACCTL_INFRA;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, value32);
buf : 
buf : 	if (b43legacy_using_pio(dev)) {
if (b43legacy_using_pio(dev)) { 
buf : 		b43legacy_write32(dev, 0x0210, 0x00000100);
buf : 		b43legacy_write32(dev, 0x0230, 0x00000100);
buf : 		b43legacy_write32(dev, 0x0250, 0x00000100);
buf : 		b43legacy_write32(dev, 0x0270, 0x00000100);
buf : 		b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, 0x0034,
buf : 				      0x0000);
buf : 	}
buf : 
buf : 	/* Probe Response Timeout value */
buf : 	/* FIXME: Default to 0, has to be set by ioctl probably... :-/ */
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED, 0x0074, 0x0000);
buf : 
buf : 	/* Initially set the wireless operation mode. */
buf : 	b43legacy_adjust_opmode(dev);
buf : 
buf : 	if (dev->dev->id.revision < 3) {
if (dev->dev->id.revision < 3) { 
buf : 		b43legacy_write16(dev, 0x060E, 0x0000);
buf : 		b43legacy_write16(dev, 0x0610, 0x8000);
buf : 		b43legacy_write16(dev, 0x0604, 0x0000);
buf : 		b43legacy_write16(dev, 0x0606, 0x0200);
buf : 	} else {
buf : 		b43legacy_write32(dev, 0x0188, 0x80000000);
buf : 		b43legacy_write32(dev, 0x018C, 0x02000000);
buf : 	}
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_REASON, 0x00004000);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA0_IRQ_MASK, 0x0001DC00);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA1_IRQ_MASK, 0x0000DC00);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA2_IRQ_MASK, 0x0000DC00);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA3_IRQ_MASK, 0x0001DC00);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA4_IRQ_MASK, 0x0000DC00);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_DMA5_IRQ_MASK, 0x0000DC00);
buf : 
buf : 	value32 = ssb_read32(dev->dev, SSB_TMSLOW);
buf : 	value32 |= B43legacy_TMSLOW_MACPHYCLKEN;
buf : 	ssb_write32(dev->dev, SSB_TMSLOW, value32);
buf : 
buf : 	b43legacy_write16(dev, B43legacy_MMIO_POWERUP_DELAY,
buf : 			  dev->dev->bus->chipco.fast_pwrup_delay);
buf : 
buf : 	/* PHY TX errors counter. */
buf : 	atomic_set(&phy->txerr_cnt, B43legacy_PHY_TX_BADNESS_LIMIT);
buf : 
buf : 	B43legacy_WARN_ON(err != 0);
buf : 	b43legacydbg(dev->wl, "Chip initialized\n");
buf : out:
buf : 	return err;
buf : 
buf : err_radio_off:
buf : 	b43legacy_radio_turn_off(dev, 1);
buf : err_gpio_clean:
buf : 	b43legacy_gpio_cleanup(dev);
buf : 	goto out;
buf : }
buf : 
buf : static void b43legacy_periodic_every120sec(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_phy *phy = &dev->phy;
buf : 
buf : 	if (phy->type != B43legacy_PHYTYPE_G || phy->rev < 2)
if (phy->type != B43legacy_PHYTYPE_G || phy->rev < 2) 
buf : 		return;
buf : 
buf : 	b43legacy_mac_suspend(dev);
buf : 	b43legacy_phy_lo_g_measure(dev);
buf : 	b43legacy_mac_enable(dev);
buf : }
buf : 
buf : static void b43legacy_periodic_every60sec(struct b43legacy_wldev *dev)
buf : {
buf : 	b43legacy_phy_lo_mark_all_unused(dev);
buf : 	if (dev->dev->bus->sprom.boardflags_lo & B43legacy_BFL_RSSI) {
if (dev->dev->bus->sprom.boardflags_lo & B43legacy_BFL_RSSI) { 
buf : 		b43legacy_mac_suspend(dev);
buf : 		b43legacy_calc_nrssi_slope(dev);
buf : 		b43legacy_mac_enable(dev);
buf : 	}
buf : }
buf : 
buf : static void b43legacy_periodic_every30sec(struct b43legacy_wldev *dev)
buf : {
buf : 	/* Update device statistics. */
buf : 	b43legacy_calculate_link_quality(dev);
buf : }
buf : 
buf : static void b43legacy_periodic_every15sec(struct b43legacy_wldev *dev)
buf : {
buf : 	b43legacy_phy_xmitpower(dev); /* FIXME: unless scanning? */
buf : 
buf : 	atomic_set(&dev->phy.txerr_cnt, B43legacy_PHY_TX_BADNESS_LIMIT);
buf : 	wmb();
buf : }
buf : 
buf : static void do_periodic_work(struct b43legacy_wldev *dev)
buf : {
buf : 	unsigned int state;
buf : 
buf : 	state = dev->periodic_state;
buf : 	if (state % 8 == 0)
if (state % 8 == 0) 
buf : 		b43legacy_periodic_every120sec(dev);
buf : 	if (state % 4 == 0)
if (state % 4 == 0) 
buf : 		b43legacy_periodic_every60sec(dev);
buf : 	if (state % 2 == 0)
if (state % 2 == 0) 
buf : 		b43legacy_periodic_every30sec(dev);
buf : 	b43legacy_periodic_every15sec(dev);
buf : }
buf : 
buf : /* Periodic work locking policy:
buf :  * 	The whole periodic work handler is protected by
buf :  * 	wl->mutex. If another lock is needed somewhere in the
buf :  * 	pwork callchain, it's acquired in-place, where it's needed.
buf :  */
buf : static void b43legacy_periodic_work_handler(struct work_struct *work)
buf : {
buf : 	struct b43legacy_wldev *dev = container_of(work, struct b43legacy_wldev,
buf : 					     periodic_work.work);
buf : 	struct b43legacy_wl *wl = dev->wl;
buf : 	unsigned long delay;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(b43legacy_status(dev) != B43legacy_STAT_STARTED))
if (unlikely(b43legacy_status(dev) != B43legacy_STAT_STARTED)) 
buf : 		goto out;
buf : 	if (b43legacy_debug(dev, B43legacy_DBG_PWORK_STOP))
if (b43legacy_debug(dev, B43legacy_DBG_PWORK_STOP)) 
buf : 		goto out_requeue;
buf : 
buf : 	do_periodic_work(dev);
buf : 
buf : 	dev->periodic_state++;
buf : out_requeue:
buf : 	if (b43legacy_debug(dev, B43legacy_DBG_PWORK_FAST))
if (b43legacy_debug(dev, B43legacy_DBG_PWORK_FAST)) 
buf : 		delay = msecs_to_jiffies(50);
buf : 	else
buf : 		delay = round_jiffies_relative(HZ * 15);
iffies_relative(HZ * 15); 
buf : 	ieee80211_queue_delayed_work(wl->hw, &dev->periodic_work, delay);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void b43legacy_periodic_tasks_setup(struct b43legacy_wldev *dev)
buf : {
buf : 	struct delayed_work *work = &dev->periodic_work;
buf : 
buf : 	dev->periodic_state = 0;
buf : 	INIT_DELAYED_WORK(work, b43legacy_periodic_work_handler);
buf : 	ieee80211_queue_delayed_work(dev->wl->hw, work, 0);
buf : }
buf : 
buf : /* Validate access to the chip (SHM) */
buf : static int b43legacy_validate_chipaccess(struct b43legacy_wldev *dev)
buf : {
buf : 	u32 value;
buf : 	u32 shm_backup;
buf : 
buf : 	shm_backup = b43legacy_shm_read32(dev, B43legacy_SHM_SHARED, 0);
buf : 	b43legacy_shm_write32(dev, B43legacy_SHM_SHARED, 0, 0xAA5555AA);
buf : 	if (b43legacy_shm_read32(dev, B43legacy_SHM_SHARED, 0) !=
if (b43legacy_shm_read32(dev, B43legacy_SHM_SHARED, 0) != 
buf : 				 0xAA5555AA)
buf : 		goto error;
buf : 	b43legacy_shm_write32(dev, B43legacy_SHM_SHARED, 0, 0x55AAAA55);
buf : 	if (b43legacy_shm_read32(dev, B43legacy_SHM_SHARED, 0) !=
if (b43legacy_shm_read32(dev, B43legacy_SHM_SHARED, 0) != 
buf : 				 0x55AAAA55)
buf : 		goto error;
buf : 	b43legacy_shm_write32(dev, B43legacy_SHM_SHARED, 0, shm_backup);
buf : 
buf : 	value = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	if ((value | B43legacy_MACCTL_GMODE) !=
if ((value | B43legacy_MACCTL_GMODE) != 
buf : 	    (B43legacy_MACCTL_GMODE | B43legacy_MACCTL_IHR_ENABLED))
buf : 		goto error;
buf : 
buf : 	value = b43legacy_read32(dev, B43legacy_MMIO_GEN_IRQ_REASON);
buf : 	if (value)
if (value) 
buf : 		goto error;
buf : 
buf : 	return 0;
buf : error:
buf : 	b43legacyerr(dev->wl, "Failed to validate the chipaccess\n");
buf : 	return -ENODEV;
buf : }
buf : 
buf : static void b43legacy_security_init(struct b43legacy_wldev *dev)
buf : {
buf : 	dev->max_nr_keys = (dev->dev->id.revision >= 5) ? 58 : 20;
buf : 	B43legacy_WARN_ON(dev->max_nr_keys > ARRAY_SIZE(dev->key));
buf : 	dev->ktp = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 					0x0056);
buf : 	/* KTP is a word address, but we address SHM bytewise.
buf : 	 * So multiply by two.
buf : 	 */
buf : 	dev->ktp *= 2;
buf : 	if (dev->dev->id.revision >= 5)
if (dev->dev->id.revision >= 5) 
buf : 		/* Number of RCMTA address slots */
buf : 		b43legacy_write16(dev, B43legacy_MMIO_RCMTA_COUNT,
buf : 				  dev->max_nr_keys - 8);
buf : }
buf : 
buf : #ifdef CONFIG_B43LEGACY_HWRNG
ifdef CONFIG_B43LEGACY_HWRNG 
buf : static int b43legacy_rng_read(struct hwrng *rng, u32 *data)
buf : {
buf : 	struct b43legacy_wl *wl = (struct b43legacy_wl *)rng->priv;
buf : 	unsigned long flags;
buf : 
buf : 	/* Don't take wl->mutex here, as it could deadlock with
buf : 	 * hwrng internal locking. It's not needed to take
buf : 	 * wl->mutex here, anyway. */
buf : 
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	*data = b43legacy_read16(wl->current_dev, B43legacy_MMIO_RNG);
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 
buf : 	return (sizeof(u16));
buf : }
buf : #endif
if 
buf : 
buf : static void b43legacy_rng_exit(struct b43legacy_wl *wl)
buf : {
buf : #ifdef CONFIG_B43LEGACY_HWRNG
ifdef CONFIG_B43LEGACY_HWRNG 
buf : 	if (wl->rng_initialized)
buf : 		hwrng_unregister(&wl->rng);
buf : #endif
if 
buf : }
buf : 
buf : static int b43legacy_rng_init(struct b43legacy_wl *wl)
buf : {
buf : 	int err = 0;
buf : 
buf : #ifdef CONFIG_B43LEGACY_HWRNG
ifdef CONFIG_B43LEGACY_HWRNG 
buf : 	snprintf(wl->rng_name, ARRAY_SIZE(wl->rng_name),
buf : 		 "%s_%s", KBUILD_MODNAME, wiphy_name(wl->hw->wiphy));
buf : 	wl->rng.name = wl->rng_name;
buf : 	wl->rng.data_read = b43legacy_rng_read;
buf : 	wl->rng.priv = (unsigned long)wl;
buf : 	wl->rng_initialized = 1;
buf : 	err = hwrng_register(&wl->rng);
buf : 	if (err) {
if (err) { 
buf : 		wl->rng_initialized = 0;
buf : 		b43legacyerr(wl, "Failed to register the random "
buf : 		       "number generator (%d)\n", err);
buf : 	}
buf : 
buf : #endif
if 
buf : 	return err;
buf : }
buf : 
buf : static void b43legacy_tx_work(struct work_struct *work)
buf : {
buf : 	struct b43legacy_wl *wl = container_of(work, struct b43legacy_wl,
buf : 				  tx_work);
buf : 	struct b43legacy_wldev *dev;
buf : 	struct sk_buff *skb;
buf : 	int queue_num;
buf : 	int err = 0;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (unlikely(!dev || b43legacy_status(dev) < B43legacy_STAT_STARTED)) {
if (unlikely(!dev || b43legacy_status(dev) < B43legacy_STAT_STARTED)) { 
buf : 		mutex_unlock(&wl->mutex);
buf : 		return;
buf : 	}
buf : 
buf : 	for (queue_num = 0; queue_num < B43legacy_QOS_QUEUE_NUM; queue_num++) {
for (queue_num = 0; queue_num < B43legacy_QOS_QUEUE_NUM; queue_num++) { 
buf : 		while (skb_queue_len(&wl->tx_queue[queue_num])) {
while (skb_queue_len(&wl->tx_queue[queue_num])) { 
buf : 			skb = skb_dequeue(&wl->tx_queue[queue_num]);
buf : 			if (b43legacy_using_pio(dev))
if (b43legacy_using_pio(dev)) 
buf : 				err = b43legacy_pio_tx(dev, skb);
buf : 			else
buf : 				err = b43legacy_dma_tx(dev, skb);
buf : 			if (err == -ENOSPC) {
if (err == -ENOSPC) { 
buf : 				wl->tx_queue_stopped[queue_num] = 1;
buf : 				ieee80211_stop_queue(wl->hw, queue_num);
buf : 				skb_queue_head(&wl->tx_queue[queue_num], skb);
buf : 				break;
buf : 			}
buf : 			if (unlikely(err))
if (unlikely(err)) 
buf : 				dev_kfree_skb(skb); /* Drop it */
buf : 			err = 0;
buf : 		}
buf : 
buf : 		if (!err)
if (!err) 
buf : 			wl->tx_queue_stopped[queue_num] = 0;
buf : 	}
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void b43legacy_op_tx(struct ieee80211_hw *hw,
buf : 			    struct ieee80211_tx_control *control,
buf : 			    struct sk_buff *skb)
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 
buf : 	if (unlikely(skb->len < 2 + 2 + 6)) {
if (unlikely(skb->len < 2 + 2 + 6)) { 
buf : 		/* Too short, this can't be a valid frame. */
buf : 		dev_kfree_skb_any(skb);
buf : 		return;
buf : 	}
buf : 	B43legacy_WARN_ON(skb_shinfo(skb)->nr_frags);
buf : 
buf : 	skb_queue_tail(&wl->tx_queue[skb->queue_mapping], skb);
buf : 	if (!wl->tx_queue_stopped[skb->queue_mapping])
if (!wl->tx_queue_stopped[skb->queue_mapping]) 
buf : 		ieee80211_queue_work(wl->hw, &wl->tx_work);
buf : 	else
buf : 		ieee80211_stop_queue(wl->hw, skb->queue_mapping);
buf : }
buf : 
buf : static int b43legacy_op_conf_tx(struct ieee80211_hw *hw,
buf : 				struct ieee80211_vif *vif, u16 queue,
if *vif, u16 queue, 
buf : 				const struct ieee80211_tx_queue_params *params)
buf : {
buf : 	return 0;
buf : }
buf : 
buf : static int b43legacy_op_get_stats(struct ieee80211_hw *hw,
buf : 				  struct ieee80211_low_level_stats *stats)
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	unsigned long flags;
buf : 
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	memcpy(stats, &wl->ieee_stats, sizeof(*stats));
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static const char *phymode_to_string(unsigned int phymode)
buf : {
buf : 	switch (phymode) {
buf : 	case B43legacy_PHYMODE_B:
buf : 		return "B";
buf : 	case B43legacy_PHYMODE_G:
buf : 		return "G";
buf : 	default:
buf : 		B43legacy_BUG_ON(1);
buf : 	}
buf : 	return "";
buf : }
buf : 
buf : static int find_wldev_for_phymode(struct b43legacy_wl *wl,
for_phymode(struct b43legacy_wl *wl, 
buf : 				  unsigned int phymode,
buf : 				  struct b43legacy_wldev **dev,
buf : 				  bool *gmode)
buf : {
buf : 	struct b43legacy_wldev *d;
buf : 
buf : 	list_for_each_entry(d, &wl->devlist, list) {
for_each_entry(d, &wl->devlist, list) { 
buf : 		if (d->phy.possible_phymodes & phymode) {
buf : 			/* Ok, this device supports the PHY-mode.
buf : 			 * Set the gmode bit. */
buf : 			*gmode = true;
buf : 			*dev = d;
buf : 
buf : 			return 0;
buf : 		}
buf : 	}
buf : 
buf : 	return -ESRCH;
buf : }
buf : 
buf : static void b43legacy_put_phy_into_reset(struct b43legacy_wldev *dev)
buf : {
buf : 	struct ssb_device *sdev = dev->dev;
buf : 	u32 tmslow;
buf : 
buf : 	tmslow = ssb_read32(sdev, SSB_TMSLOW);
buf : 	tmslow &= ~B43legacy_TMSLOW_GMODE;
buf : 	tmslow |= B43legacy_TMSLOW_PHYRESET;
buf : 	tmslow |= SSB_TMSLOW_FGC;
buf : 	ssb_write32(sdev, SSB_TMSLOW, tmslow);
buf : 	msleep(1);
buf : 
buf : 	tmslow = ssb_read32(sdev, SSB_TMSLOW);
buf : 	tmslow &= ~SSB_TMSLOW_FGC;
buf : 	tmslow |= B43legacy_TMSLOW_PHYRESET;
buf : 	ssb_write32(sdev, SSB_TMSLOW, tmslow);
buf : 	msleep(1);
buf : }
buf : 
buf : /* Expects wl->mutex locked */
buf : static int b43legacy_switch_phymode(struct b43legacy_wl *wl,
buf : 				      unsigned int new_mode)
buf : {
buf : 	struct b43legacy_wldev *uninitialized_var(up_dev);
buf : 	struct b43legacy_wldev *down_dev;
buf : 	int err;
buf : 	bool gmode = false;
buf : 	int prev_status;
buf : 
buf : 	err = find_wldev_for_phymode(wl, new_mode, &up_dev, &gmode);
for_phymode(wl, new_mode, &up_dev, &gmode); 
buf : 	if (err) {
buf : 		b43legacyerr(wl, "Could not find a device for %s-PHY mode\n",
for %s-PHY mode\n", 
buf : 		       phymode_to_string(new_mode));
buf : 		return err;
buf : 	}
buf : 	if ((up_dev == wl->current_dev) &&
if ((up_dev == wl->current_dev) && 
buf : 	    (!!wl->current_dev->phy.gmode == !!gmode))
buf : 		/* This device is already running. */
buf : 		return 0;
buf : 	b43legacydbg(wl, "Reconfiguring PHYmode to %s-PHY\n",
buf : 	       phymode_to_string(new_mode));
buf : 	down_dev = wl->current_dev;
buf : 
buf : 	prev_status = b43legacy_status(down_dev);
buf : 	/* Shutdown the currently running core. */
buf : 	if (prev_status >= B43legacy_STAT_STARTED)
if (prev_status >= B43legacy_STAT_STARTED) 
buf : 		b43legacy_wireless_core_stop(down_dev);
buf : 	if (prev_status >= B43legacy_STAT_INITIALIZED)
if (prev_status >= B43legacy_STAT_INITIALIZED) 
buf : 		b43legacy_wireless_core_exit(down_dev);
buf : 
buf : 	if (down_dev != up_dev)
if (down_dev != up_dev) 
buf : 		/* We switch to a different core, so we put PHY into
buf : 		 * RESET on the old core. */
buf : 		b43legacy_put_phy_into_reset(down_dev);
buf : 
buf : 	/* Now start the new core. */
buf : 	up_dev->phy.gmode = gmode;
buf : 	if (prev_status >= B43legacy_STAT_INITIALIZED) {
if (prev_status >= B43legacy_STAT_INITIALIZED) { 
buf : 		err = b43legacy_wireless_core_init(up_dev);
buf : 		if (err) {
if (err) { 
buf : 			b43legacyerr(wl, "Fatal: Could not initialize device"
buf : 				     " for newly selected %s-PHY mode\n",
for newly selected %s-PHY mode\n", 
buf : 				     phymode_to_string(new_mode));
buf : 			goto init_failure;
buf : 		}
buf : 	}
buf : 	if (prev_status >= B43legacy_STAT_STARTED) {
if (prev_status >= B43legacy_STAT_STARTED) { 
buf : 		err = b43legacy_wireless_core_start(up_dev);
buf : 		if (err) {
if (err) { 
buf : 			b43legacyerr(wl, "Fatal: Could not start device for "
for " 
buf : 			       "newly selected %s-PHY mode\n",
buf : 			       phymode_to_string(new_mode));
buf : 			b43legacy_wireless_core_exit(up_dev);
buf : 			goto init_failure;
buf : 		}
buf : 	}
buf : 	B43legacy_WARN_ON(b43legacy_status(up_dev) != prev_status);
buf : 
buf : 	b43legacy_shm_write32(up_dev, B43legacy_SHM_SHARED, 0x003E, 0);
buf : 
buf : 	wl->current_dev = up_dev;
buf : 
buf : 	return 0;
buf : init_failure:
buf : 	/* Whoops, failed to init the new core. No core is operating now. */
buf : 	wl->current_dev = NULL;
buf : 	return err;
buf : }
buf : 
buf : /* Write the short and long frame retry limit values. */
buf : static void b43legacy_set_retry_limits(struct b43legacy_wldev *dev,
buf : 				       unsigned int short_retry,
buf : 				       unsigned int long_retry)
buf : {
buf : 	/* The retry limit is a 4-bit counter. Enforce this to avoid overflowing
force this to avoid overflowing 
buf : 	 * the chip-internal counter. */
buf : 	short_retry = min(short_retry, (unsigned int)0xF);
buf : 	long_retry = min(long_retry, (unsigned int)0xF);
buf : 
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_WIRELESS, 0x0006, short_retry);
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_WIRELESS, 0x0007, long_retry);
buf : }
buf : 
buf : static int b43legacy_op_dev_config(struct ieee80211_hw *hw,
buf : 				   u32 changed)
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	struct b43legacy_wldev *dev;
buf : 	struct b43legacy_phy *phy;
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 	unsigned long flags;
buf : 	unsigned int new_phymode = 0xFFFF;
buf : 	int antenna_tx;
buf : 	int err = 0;
buf : 
buf : 	antenna_tx = B43legacy_ANTENNA_DEFAULT;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	phy = &dev->phy;
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_RETRY_LIMITS)
if (changed & IEEE80211_CONF_CHANGE_RETRY_LIMITS) 
buf : 		b43legacy_set_retry_limits(dev,
buf : 					   conf->short_frame_max_tx_count,
buf : 					   conf->long_frame_max_tx_count);
buf : 	changed &= ~IEEE80211_CONF_CHANGE_RETRY_LIMITS;
buf : 	if (!changed)
if (!changed) 
buf : 		goto out_unlock_mutex;
buf : 
buf : 	/* Switch the PHY mode (if necessary). */
if necessary). */ 
buf : 	switch (conf->chandef.chan->band) {
buf : 	case IEEE80211_BAND_2GHZ:
buf : 		if (phy->type == B43legacy_PHYTYPE_B)
if (phy->type == B43legacy_PHYTYPE_B) 
buf : 			new_phymode = B43legacy_PHYMODE_B;
buf : 		else
buf : 			new_phymode = B43legacy_PHYMODE_G;
buf : 		break;
buf : 	default:
buf : 		B43legacy_WARN_ON(1);
buf : 	}
buf : 	err = b43legacy_switch_phymode(wl, new_phymode);
buf : 	if (err)
if (err) 
buf : 		goto out_unlock_mutex;
buf : 
buf : 	/* Disable IRQs while reconfiguring the device.
while reconfiguring the device. 
buf : 	 * This makes it possible to drop the spinlock throughout
buf : 	 * the reconfiguration process. */
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	if (b43legacy_status(dev) < B43legacy_STAT_STARTED) {
if (b43legacy_status(dev) < B43legacy_STAT_STARTED) { 
buf : 		spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 		goto out_unlock_mutex;
buf : 	}
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK, 0);
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 	b43legacy_synchronize_irq(dev);
buf : 
buf : 	/* Switch to the requested channel.
buf : 	 * The firmware takes care of races with the TX handler. */
buf : 	if (conf->chandef.chan->hw_value != phy->channel)
if (conf->chandef.chan->hw_value != phy->channel) 
buf : 		b43legacy_radio_selectchannel(dev, conf->chandef.chan->hw_value,
buf : 					      0);
buf : 
buf : 	dev->wl->radiotap_enabled = !!(conf->flags & IEEE80211_CONF_MONITOR);
buf : 
buf : 	/* Adjust the desired TX power level. */
buf : 	if (conf->power_level != 0) {
if (conf->power_level != 0) { 
buf : 		if (conf->power_level != phy->power_level) {
buf : 			phy->power_level = conf->power_level;
buf : 			b43legacy_phy_xmitpower(dev);
buf : 		}
buf : 	}
buf : 
buf : 	/* Antennas for RX and management frame TX. */
for RX and management frame TX. */ 
buf : 	b43legacy_mgmtframe_txantenna(dev, antenna_tx);
buf : 
buf : 	if (wl->radio_enabled != phy->radio_on) {
if (wl->radio_enabled != phy->radio_on) { 
buf : 		if (wl->radio_enabled) {
buf : 			b43legacy_radio_turn_on(dev);
buf : 			b43legacyinfo(dev->wl, "Radio turned on by software\n");
buf : 			if (!dev->radio_hw_enable)
if (!dev->radio_hw_enable) 
buf : 				b43legacyinfo(dev->wl, "The hardware RF-kill"
buf : 					      " button still turns the radio"
buf : 					      " physically off. Press the"
buf : 					      " button to turn it on.\n");
buf : 		} else {
buf : 			b43legacy_radio_turn_off(dev, 0);
buf : 			b43legacyinfo(dev->wl, "Radio turned off by"
buf : 				      " software\n");
buf : 		}
buf : 	}
buf : 
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK, dev->irq_mask);
buf : 	mmiowb();
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : out_unlock_mutex:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void b43legacy_update_basic_rates(struct b43legacy_wldev *dev, u32 brates)
buf : {
buf : 	struct ieee80211_supported_band *sband =
buf : 		dev->wl->hw->wiphy->bands[IEEE80211_BAND_2GHZ];
buf : 	struct ieee80211_rate *rate;
buf : 	int i;
buf : 	u16 basic, direct, offset, basic_offset, rateptr;
buf : 
buf : 	for (i = 0; i < sband->n_bitrates; i++) {
for (i = 0; i < sband->n_bitrates; i++) { 
buf : 		rate = &sband->bitrates[i];
buf : 
buf : 		if (b43legacy_is_cck_rate(rate->hw_value)) {
if (b43legacy_is_cck_rate(rate->hw_value)) { 
buf : 			direct = B43legacy_SHM_SH_CCKDIRECT;
buf : 			basic = B43legacy_SHM_SH_CCKBASIC;
buf : 			offset = b43legacy_plcp_get_ratecode_cck(rate->hw_value);
buf : 			offset &= 0xF;
buf : 		} else {
buf : 			direct = B43legacy_SHM_SH_OFDMDIRECT;
buf : 			basic = B43legacy_SHM_SH_OFDMBASIC;
buf : 			offset = b43legacy_plcp_get_ratecode_ofdm(rate->hw_value);
buf : 			offset &= 0xF;
buf : 		}
buf : 
buf : 		rate = ieee80211_get_response_rate(sband, brates, rate->bitrate);
buf : 
buf : 		if (b43legacy_is_cck_rate(rate->hw_value)) {
if (b43legacy_is_cck_rate(rate->hw_value)) { 
buf : 			basic_offset = b43legacy_plcp_get_ratecode_cck(rate->hw_value);
buf : 			basic_offset &= 0xF;
buf : 		} else {
buf : 			basic_offset = b43legacy_plcp_get_ratecode_ofdm(rate->hw_value);
buf : 			basic_offset &= 0xF;
buf : 		}
buf : 
buf : 		/*
buf : 		 * Get the pointer that we need to point to
buf : 		 * from the direct map
buf : 		 */
buf : 		rateptr = b43legacy_shm_read16(dev, B43legacy_SHM_SHARED,
buf : 					       direct + 2 * basic_offset);
buf : 		/* and write it to the basic map */
buf : 		b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 				      basic + 2 * offset, rateptr);
buf : 	}
buf : }
buf : 
buf : static void b43legacy_op_bss_info_changed(struct ieee80211_hw *hw,
buf : 				    struct ieee80211_vif *vif,
if *vif, 
buf : 				    struct ieee80211_bss_conf *conf,
buf : 				    u32 changed)
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	struct b43legacy_wldev *dev;
buf : 	unsigned long flags;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	B43legacy_WARN_ON(wl->vif != vif);
if != vif); 
buf : 
buf : 	dev = wl->current_dev;
buf : 
buf : 	/* Disable IRQs while reconfiguring the device.
while reconfiguring the device. 
buf : 	 * This makes it possible to drop the spinlock throughout
buf : 	 * the reconfiguration process. */
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	if (b43legacy_status(dev) < B43legacy_STAT_STARTED) {
if (b43legacy_status(dev) < B43legacy_STAT_STARTED) { 
buf : 		spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 		goto out_unlock_mutex;
buf : 	}
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK, 0);
buf : 
buf : 	if (changed & BSS_CHANGED_BSSID) {
if (changed & BSS_CHANGED_BSSID) { 
buf : 		b43legacy_synchronize_irq(dev);
buf : 
buf : 		if (conf->bssid)
if (conf->bssid) 
buf : 			memcpy(wl->bssid, conf->bssid, ETH_ALEN);
buf : 		else
buf : 			memset(wl->bssid, 0, ETH_ALEN);
buf : 	}
buf : 
buf : 	if (b43legacy_status(dev) >= B43legacy_STAT_INITIALIZED) {
if (b43legacy_status(dev) >= B43legacy_STAT_INITIALIZED) { 
buf : 		if (changed & BSS_CHANGED_BEACON &&
buf : 		    (b43legacy_is_mode(wl, NL80211_IFTYPE_AP) ||
buf : 		     b43legacy_is_mode(wl, NL80211_IFTYPE_ADHOC)))
buf : 			b43legacy_update_templates(wl);
buf : 
buf : 		if (changed & BSS_CHANGED_BSSID)
if (changed & BSS_CHANGED_BSSID) 
buf : 			b43legacy_write_mac_bssid_templates(dev);
buf : 	}
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 
buf : 	b43legacy_mac_suspend(dev);
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON_INT &&
if (changed & BSS_CHANGED_BEACON_INT && 
buf : 	    (b43legacy_is_mode(wl, NL80211_IFTYPE_AP) ||
buf : 	     b43legacy_is_mode(wl, NL80211_IFTYPE_ADHOC)))
buf : 		b43legacy_set_beacon_int(dev, conf->beacon_int);
buf : 
buf : 	if (changed & BSS_CHANGED_BASIC_RATES)
if (changed & BSS_CHANGED_BASIC_RATES) 
buf : 		b43legacy_update_basic_rates(dev, conf->basic_rates);
buf : 
buf : 	if (changed & BSS_CHANGED_ERP_SLOT) {
if (changed & BSS_CHANGED_ERP_SLOT) { 
buf : 		if (conf->use_short_slot)
buf : 			b43legacy_short_slot_timing_enable(dev);
buf : 		else
buf : 			b43legacy_short_slot_timing_disable(dev);
buf : 	}
buf : 
buf : 	b43legacy_mac_enable(dev);
buf : 
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK, dev->irq_mask);
buf : 	/* XXX: why? */
buf : 	mmiowb();
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf :  out_unlock_mutex:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void b43legacy_op_configure_filter(struct ieee80211_hw *hw,
buf : 					  unsigned int changed,
buf : 					  unsigned int *fflags,u64 multicast)
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	struct b43legacy_wldev *dev = wl->current_dev;
buf : 	unsigned long flags;
buf : 
buf : 	if (!dev) {
if (!dev) { 
buf : 		*fflags = 0;
buf : 		return;
buf : 	}
buf : 
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	*fflags &= FIF_PROMISC_IN_BSS |
buf : 		  FIF_ALLMULTI |
buf : 		  FIF_FCSFAIL |
buf : 		  FIF_PLCPFAIL |
buf : 		  FIF_CONTROL |
buf : 		  FIF_OTHER_BSS |
buf : 		  FIF_BCN_PRBRESP_PROMISC;
buf : 
buf : 	changed &= FIF_PROMISC_IN_BSS |
buf : 		   FIF_ALLMULTI |
buf : 		   FIF_FCSFAIL |
buf : 		   FIF_PLCPFAIL |
buf : 		   FIF_CONTROL |
buf : 		   FIF_OTHER_BSS |
buf : 		   FIF_BCN_PRBRESP_PROMISC;
buf : 
buf : 	wl->filter_flags = *fflags;
buf : 
buf : 	if (changed && b43legacy_status(dev) >= B43legacy_STAT_INITIALIZED)
if (changed && b43legacy_status(dev) >= B43legacy_STAT_INITIALIZED) 
buf : 		b43legacy_adjust_opmode(dev);
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : }
buf : 
buf : /* Locking: wl->mutex */
buf : static void b43legacy_wireless_core_stop(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_wl *wl = dev->wl;
buf : 	unsigned long flags;
buf : 	int queue_num;
buf : 
buf : 	if (b43legacy_status(dev) < B43legacy_STAT_STARTED)
if (b43legacy_status(dev) < B43legacy_STAT_STARTED) 
buf : 		return;
buf : 
buf : 	/* Disable and sync interrupts. We must do this before than
fore than 
buf : 	 * setting the status to INITIALIZED, as the interrupt handler
buf : 	 * won't care about IRQs then. */
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK, 0);
buf : 	b43legacy_read32(dev, B43legacy_MMIO_GEN_IRQ_MASK); /* flush */
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 	b43legacy_synchronize_irq(dev);
buf : 
buf : 	b43legacy_set_status(dev, B43legacy_STAT_INITIALIZED);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : 	/* Must unlock as it would otherwise deadlock. No races here.
buf : 	 * Cancel the possibly running self-rearming periodic work. */
buf : 	cancel_delayed_work_sync(&dev->periodic_work);
buf : 	cancel_work_sync(&wl->tx_work);
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	/* Drain all TX queues. */
buf : 	for (queue_num = 0; queue_num < B43legacy_QOS_QUEUE_NUM; queue_num++) {
for (queue_num = 0; queue_num < B43legacy_QOS_QUEUE_NUM; queue_num++) { 
buf : 		while (skb_queue_len(&wl->tx_queue[queue_num]))
while (skb_queue_len(&wl->tx_queue[queue_num])) 
buf : 			dev_kfree_skb(skb_dequeue(&wl->tx_queue[queue_num]));
buf : 	}
buf : 
buf : b43legacy_mac_suspend(dev);
buf : 	free_irq(dev->dev->irq, dev);
buf : 	b43legacydbg(wl, "Wireless interface stopped\n");
buf : }
buf : 
buf : /* Locking: wl->mutex */
buf : static int b43legacy_wireless_core_start(struct b43legacy_wldev *dev)
buf : {
buf : 	int err;
buf : 
buf : 	B43legacy_WARN_ON(b43legacy_status(dev) != B43legacy_STAT_INITIALIZED);
buf : 
buf : 	drain_txstatus_queue(dev);
buf : 	err = request_irq(dev->dev->irq, b43legacy_interrupt_handler,
buf : 			  IRQF_SHARED, KBUILD_MODNAME, dev);
buf : 	if (err) {
if (err) { 
buf : 		b43legacyerr(dev->wl, "Cannot request IRQ-%d\n",
buf : 		       dev->dev->irq);
buf : 		goto out;
buf : 	}
buf : 	/* We are ready to run. */
buf : 	ieee80211_wake_queues(dev->wl->hw);
buf : 	b43legacy_set_status(dev, B43legacy_STAT_STARTED);
buf : 
buf : 	/* Start data flow (TX/RX) */
buf : 	b43legacy_mac_enable(dev);
buf : 	b43legacy_write32(dev, B43legacy_MMIO_GEN_IRQ_MASK, dev->irq_mask);
buf : 
buf : 	/* Start maintenance work */
buf : 	b43legacy_periodic_tasks_setup(dev);
buf : 
buf : 	b43legacydbg(dev->wl, "Wireless interface started\n");
buf : out:
buf : 	return err;
buf : }
buf : 
buf : /* Get PHY and RADIO versioning numbers */
buf : static int b43legacy_phy_versioning(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_phy *phy = &dev->phy;
buf : 	u32 tmp;
buf : 	u8 analog_type;
buf : 	u8 phy_type;
buf : 	u8 phy_rev;
buf : 	u16 radio_manuf;
buf : 	u16 radio_ver;
buf : 	u16 radio_rev;
buf : 	int unsupported = 0;
buf : 
buf : 	/* Get PHY versioning */
buf : 	tmp = b43legacy_read16(dev, B43legacy_MMIO_PHY_VER);
buf : 	analog_type = (tmp & B43legacy_PHYVER_ANALOG)
buf : 		      >> B43legacy_PHYVER_ANALOG_SHIFT;
buf : 	phy_type = (tmp & B43legacy_PHYVER_TYPE) >> B43legacy_PHYVER_TYPE_SHIFT;
buf : 	phy_rev = (tmp & B43legacy_PHYVER_VERSION);
buf : 	switch (phy_type) {
buf : 	case B43legacy_PHYTYPE_B:
buf : 		if (phy_rev != 2 && phy_rev != 4
if (phy_rev != 2 && phy_rev != 4 
buf : 		    && phy_rev != 6 && phy_rev != 7)
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43legacy_PHYTYPE_G:
buf : 		if (phy_rev > 8)
if (phy_rev > 8) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	default:
buf : 		unsupported = 1;
buf : 	}
buf : 	if (unsupported) {
if (unsupported) { 
buf : 		b43legacyerr(dev->wl, "FOUND UNSUPPORTED PHY "
buf : 		       "(Analog %u, Type %u, Revision %u)\n",
buf : 		       analog_type, phy_type, phy_rev);
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 	b43legacydbg(dev->wl, "Found PHY: Analog %u, Type %u, Revision %u\n",
buf : 	       analog_type, phy_type, phy_rev);
buf : 
buf : 
buf : 	/* Get RADIO versioning */
buf : 	if (dev->dev->bus->chip_id == 0x4317) {
if (dev->dev->bus->chip_id == 0x4317) { 
buf : 		if (dev->dev->bus->chip_rev == 0)
buf : 			tmp = 0x3205017F;
buf : 		else if (dev->dev->bus->chip_rev == 1)
if (dev->dev->bus->chip_rev == 1) 
buf : 			tmp = 0x4205017F;
buf : 		else
buf : 			tmp = 0x5205017F;
buf : 	} else {
buf : 		b43legacy_write16(dev, B43legacy_MMIO_RADIO_CONTROL,
buf : 				  B43legacy_RADIOCTL_ID);
buf : 		tmp = b43legacy_read16(dev, B43legacy_MMIO_RADIO_DATA_HIGH);
buf : 		tmp <<= 16;
buf : 		b43legacy_write16(dev, B43legacy_MMIO_RADIO_CONTROL,
buf : 				  B43legacy_RADIOCTL_ID);
buf : 		tmp |= b43legacy_read16(dev, B43legacy_MMIO_RADIO_DATA_LOW);
buf : 	}
buf : 	radio_manuf = (tmp & 0x00000FFF);
buf : 	radio_ver = (tmp & 0x0FFFF000) >> 12;
buf : 	radio_rev = (tmp & 0xF0000000) >> 28;
buf : 	switch (phy_type) {
buf : 	case B43legacy_PHYTYPE_B:
buf : 		if ((radio_ver & 0xFFF0) != 0x2050)
if ((radio_ver & 0xFFF0) != 0x2050) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43legacy_PHYTYPE_G:
buf : 		if (radio_ver != 0x2050)
if (radio_ver != 0x2050) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	default:
buf : 		B43legacy_BUG_ON(1);
buf : 	}
buf : 	if (unsupported) {
if (unsupported) { 
buf : 		b43legacyerr(dev->wl, "FOUND UNSUPPORTED RADIO "
buf : 		       "(Manuf 0x%X, Version 0x%X, Revision %u)\n",
buf : 		       radio_manuf, radio_ver, radio_rev);
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 	b43legacydbg(dev->wl, "Found Radio: Manuf 0x%X, Version 0x%X,"
buf : 		     " Revision %u\n", radio_manuf, radio_ver, radio_rev);
buf : 
buf : 
buf : 	phy->radio_manuf = radio_manuf;
buf : 	phy->radio_ver = radio_ver;
buf : 	phy->radio_rev = radio_rev;
buf : 
buf : 	phy->analog = analog_type;
buf : 	phy->type = phy_type;
buf : 	phy->rev = phy_rev;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void setup_struct_phy_for_init(struct b43legacy_wldev *dev,
for_init(struct b43legacy_wldev *dev, 
buf : 				      struct b43legacy_phy *phy)
buf : {
buf : 	struct b43legacy_lopair *lo;
buf : 	int i;
buf : 
buf : 	memset(phy->minlowsig, 0xFF, sizeof(phy->minlowsig));
buf : 	memset(phy->minlowsigpos, 0, sizeof(phy->minlowsigpos));
buf : 
buf : 	/* Assume the radio is enabled. If it's not enabled, the state will
buf : 	 * immediately get fixed on the first periodic work run. */
buf : 	dev->radio_hw_enable = true;
buf : 
buf : 	phy->savedpctlreg = 0xFFFF;
buf : 	phy->aci_enable = false;
buf : 	phy->aci_wlan_automatic = false;
buf : 	phy->aci_hw_rssi = false;
buf : 
buf : 	lo = phy->_lo_pairs;
buf : 	if (lo)
if (lo) 
buf : 		memset(lo, 0, sizeof(struct b43legacy_lopair) *
buf : 				     B43legacy_LO_COUNT);
buf : 	phy->max_lb_gain = 0;
buf : 	phy->trsw_rx_gain = 0;
buf : 
buf : 	/* Set default attenuation values. */
buf : 	phy->bbatt = b43legacy_default_baseband_attenuation(dev);
buf : 	phy->rfatt = b43legacy_default_radio_attenuation(dev);
buf : 	phy->txctl1 = b43legacy_default_txctl1(dev);
buf : 	phy->txpwr_offset = 0;
buf : 
buf : 	/* NRSSI */
buf : 	phy->nrssislope = 0;
buf : 	for (i = 0; i < ARRAY_SIZE(phy->nrssi); i++)
for (i = 0; i < ARRAY_SIZE(phy->nrssi); i++) 
buf : 		phy->nrssi[i] = -1000;
buf : 	for (i = 0; i < ARRAY_SIZE(phy->nrssi_lt); i++)
for (i = 0; i < ARRAY_SIZE(phy->nrssi_lt); i++) 
buf : 		phy->nrssi_lt[i] = i;
buf : 
buf : 	phy->lofcal = 0xFFFF;
buf : 	phy->initval = 0xFFFF;
buf : 
buf : 	phy->interfmode = B43legacy_INTERFMODE_NONE;
buf : 	phy->channel = 0xFF;
buf : }
buf : 
buf : static void setup_struct_wldev_for_init(struct b43legacy_wldev *dev)
for_init(struct b43legacy_wldev *dev) 
buf : {
buf : 	/* Flags */
buf : 	dev->dfq_valid = false;
buf : 
buf : 	/* Stats */
buf : 	memset(&dev->stats, 0, sizeof(dev->stats));
buf : 
buf : 	setup_struct_phy_for_init(dev, &dev->phy);
for_init(dev, &dev->phy); 
buf : 
buf : 	/* IRQ related flags */
buf : 	dev->irq_reason = 0;
buf : 	memset(dev->dma_reason, 0, sizeof(dev->dma_reason));
buf : 	dev->irq_mask = B43legacy_IRQ_MASKTEMPLATE;
buf : 
buf : 	dev->mac_suspended = 1;
buf : 
buf : 	/* Noise calculation context */
buf : 	memset(&dev->noisecalc, 0, sizeof(dev->noisecalc));
buf : }
buf : 
buf : static void b43legacy_set_synth_pu_delay(struct b43legacy_wldev *dev,
buf : 					  bool idle) {
buf : 	u16 pu_delay = 1050;
buf : 
buf : 	if (b43legacy_is_mode(dev->wl, NL80211_IFTYPE_ADHOC) || idle)
if (b43legacy_is_mode(dev->wl, NL80211_IFTYPE_ADHOC) || idle) 
buf : 		pu_delay = 500;
buf : 	if ((dev->phy.radio_ver == 0x2050) && (dev->phy.radio_rev == 8))
if ((dev->phy.radio_ver == 0x2050) && (dev->phy.radio_rev == 8)) 
buf : 		pu_delay = max(pu_delay, (u16)2400);
buf : 
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_SPUWKUP, pu_delay);
buf : }
buf : 
buf : /* Set the TSF CFP pre-TargetBeaconTransmissionTime. */
buf : static void b43legacy_set_pretbtt(struct b43legacy_wldev *dev)
buf : {
buf : 	u16 pretbtt;
buf : 
buf : 	/* The time value is in microseconds. */
buf : 	if (b43legacy_is_mode(dev->wl, NL80211_IFTYPE_ADHOC))
if (b43legacy_is_mode(dev->wl, NL80211_IFTYPE_ADHOC)) 
buf : 		pretbtt = 2;
buf : 	else
buf : 		pretbtt = 250;
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_PRETBTT, pretbtt);
buf : 	b43legacy_write16(dev, B43legacy_MMIO_TSF_CFP_PRETBTT, pretbtt);
buf : }
buf : 
buf : /* Shutdown a wireless core */
buf : /* Locking: wl->mutex */
buf : static void b43legacy_wireless_core_exit(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_phy *phy = &dev->phy;
buf : 	u32 macctl;
buf : 
buf : 	B43legacy_WARN_ON(b43legacy_status(dev) > B43legacy_STAT_INITIALIZED);
buf : 	if (b43legacy_status(dev) != B43legacy_STAT_INITIALIZED)
if (b43legacy_status(dev) != B43legacy_STAT_INITIALIZED) 
buf : 		return;
buf : 	b43legacy_set_status(dev, B43legacy_STAT_UNINIT);
buf : 
buf : 	/* Stop the microcode PSM. */
buf : 	macctl = b43legacy_read32(dev, B43legacy_MMIO_MACCTL);
buf : 	macctl &= ~B43legacy_MACCTL_PSM_RUN;
buf : 	macctl |= B43legacy_MACCTL_PSM_JMP0;
buf : 	b43legacy_write32(dev, B43legacy_MMIO_MACCTL, macctl);
buf : 
buf : 	b43legacy_leds_exit(dev);
buf : 	b43legacy_rng_exit(dev->wl);
buf : 	b43legacy_pio_free(dev);
buf : 	b43legacy_dma_free(dev);
buf : 	b43legacy_chip_exit(dev);
buf : 	b43legacy_radio_turn_off(dev, 1);
buf : 	b43legacy_switch_analog(dev, 0);
buf : 	if (phy->dyn_tssi_tbl)
if (phy->dyn_tssi_tbl) 
buf : 		kfree(phy->tssi2dbm);
buf : 	kfree(phy->lo_control);
buf : 	phy->lo_control = NULL;
buf : 	if (dev->wl->current_beacon) {
if (dev->wl->current_beacon) { 
buf : 		dev_kfree_skb_any(dev->wl->current_beacon);
buf : 		dev->wl->current_beacon = NULL;
buf : 	}
buf : 
buf : 	ssb_device_disable(dev->dev, 0);
buf : 	ssb_bus_may_powerdown(dev->dev->bus);
buf : }
buf : 
buf : static void prepare_phy_data_for_init(struct b43legacy_wldev *dev)
for_init(struct b43legacy_wldev *dev) 
buf : {
buf : 	struct b43legacy_phy *phy = &dev->phy;
buf : 	int i;
buf : 
buf : 	/* Set default attenuation values. */
buf : 	phy->bbatt = b43legacy_default_baseband_attenuation(dev);
buf : 	phy->rfatt = b43legacy_default_radio_attenuation(dev);
buf : 	phy->txctl1 = b43legacy_default_txctl1(dev);
buf : 	phy->txctl2 = 0xFFFF;
buf : 	phy->txpwr_offset = 0;
buf : 
buf : 	/* NRSSI */
buf : 	phy->nrssislope = 0;
buf : 	for (i = 0; i < ARRAY_SIZE(phy->nrssi); i++)
for (i = 0; i < ARRAY_SIZE(phy->nrssi); i++) 
buf : 		phy->nrssi[i] = -1000;
buf : 	for (i = 0; i < ARRAY_SIZE(phy->nrssi_lt); i++)
for (i = 0; i < ARRAY_SIZE(phy->nrssi_lt); i++) 
buf : 		phy->nrssi_lt[i] = i;
buf : 
buf : 	phy->lofcal = 0xFFFF;
buf : 	phy->initval = 0xFFFF;
buf : 
buf : 	phy->aci_enable = false;
buf : 	phy->aci_wlan_automatic = false;
buf : 	phy->aci_hw_rssi = false;
buf : 
buf : 	phy->antenna_diversity = 0xFFFF;
buf : 	memset(phy->minlowsig, 0xFF, sizeof(phy->minlowsig));
buf : 	memset(phy->minlowsigpos, 0, sizeof(phy->minlowsigpos));
buf : 
buf : 	/* Flags */
buf : 	phy->calibrated = 0;
buf : 
buf : 	if (phy->_lo_pairs)
if (phy->_lo_pairs) 
buf : 		memset(phy->_lo_pairs, 0,
buf : 		       sizeof(struct b43legacy_lopair) * B43legacy_LO_COUNT);
buf : 	memset(phy->loopback_gain, 0, sizeof(phy->loopback_gain));
buf : }
buf : 
buf : /* Initialize a wireless core */
buf : static int b43legacy_wireless_core_init(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_wl *wl = dev->wl;
buf : 	struct ssb_bus *bus = dev->dev->bus;
buf : 	struct b43legacy_phy *phy = &dev->phy;
buf : 	struct ssb_sprom *sprom = &dev->dev->bus->sprom;
buf : 	int err;
buf : 	u32 hf;
buf : 	u32 tmp;
buf : 
buf : 	B43legacy_WARN_ON(b43legacy_status(dev) != B43legacy_STAT_UNINIT);
buf : 
buf : 	err = ssb_bus_powerup(bus, 0);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 	if (!ssb_device_is_enabled(dev->dev)) {
if (!ssb_device_is_enabled(dev->dev)) { 
buf : 		tmp = phy->gmode ? B43legacy_TMSLOW_GMODE : 0;
buf : 		b43legacy_wireless_core_reset(dev, tmp);
buf : 	}
buf : 
buf : 	if ((phy->type == B43legacy_PHYTYPE_B) ||
if ((phy->type == B43legacy_PHYTYPE_B) || 
buf : 	    (phy->type == B43legacy_PHYTYPE_G)) {
buf : 		phy->_lo_pairs = kzalloc(sizeof(struct b43legacy_lopair)
buf : 					 * B43legacy_LO_COUNT,
buf : 					 GFP_KERNEL);
buf : 		if (!phy->_lo_pairs)
if (!phy->_lo_pairs) 
buf : 			return -ENOMEM;
buf : 	}
buf : 	setup_struct_wldev_for_init(dev);
for_init(dev); 
buf : 
buf : 	err = b43legacy_phy_init_tssi2dbm_table(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_kfree_lo_control;
buf : 
buf : 	/* Enable IRQ routing to this device. */
buf : 	ssb_pcicore_dev_irqvecs_enable(&bus->pcicore, dev->dev);
buf : 
buf : 	prepare_phy_data_for_init(dev);
for_init(dev); 
buf : 	b43legacy_phy_calibrate(dev);
buf : 	err = b43legacy_chip_init(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_kfree_tssitbl;
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_WLCOREREV,
buf : 			      dev->dev->id.revision);
buf : 	hf = b43legacy_hf_read(dev);
buf : 	if (phy->type == B43legacy_PHYTYPE_G) {
if (phy->type == B43legacy_PHYTYPE_G) { 
buf : 		hf |= B43legacy_HF_SYMW;
buf : 		if (phy->rev == 1)
if (phy->rev == 1) 
buf : 			hf |= B43legacy_HF_GDCW;
buf : 		if (sprom->boardflags_lo & B43legacy_BFL_PACTRL)
if (sprom->boardflags_lo & B43legacy_BFL_PACTRL) 
buf : 			hf |= B43legacy_HF_OFDMPABOOST;
buf : 	} else if (phy->type == B43legacy_PHYTYPE_B) {
if (phy->type == B43legacy_PHYTYPE_B) { 
buf : 		hf |= B43legacy_HF_SYMW;
buf : 		if (phy->rev >= 2 && phy->radio_ver == 0x2050)
if (phy->rev >= 2 && phy->radio_ver == 0x2050) 
buf : 			hf &= ~B43legacy_HF_GDCW;
buf : 	}
buf : 	b43legacy_hf_write(dev, hf);
buf : 
buf : 	b43legacy_set_retry_limits(dev,
buf : 				   B43legacy_DEFAULT_SHORT_RETRY_LIMIT,
buf : 				   B43legacy_DEFAULT_LONG_RETRY_LIMIT);
buf : 
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      0x0044, 3);
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      0x0046, 2);
buf : 
buf : 	/* Disable sending probe responses from firmware.
buf : 	 * Setting the MaxTime to one usec will always trigger
buf : 	 * a timeout, so we never send any probe resp.
buf : 	 * A timeout of zero is infinite. */
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_SHARED,
buf : 			      B43legacy_SHM_SH_PRMAXTIME, 1);
buf : 
buf : 	b43legacy_rate_memory_init(dev);
buf : 
buf : 	/* Minimum Contention Window */
buf : 	if (phy->type == B43legacy_PHYTYPE_B)
if (phy->type == B43legacy_PHYTYPE_B) 
buf : 		b43legacy_shm_write16(dev, B43legacy_SHM_WIRELESS,
buf : 				      0x0003, 31);
buf : 	else
buf : 		b43legacy_shm_write16(dev, B43legacy_SHM_WIRELESS,
buf : 				      0x0003, 15);
buf : 	/* Maximum Contention Window */
buf : 	b43legacy_shm_write16(dev, B43legacy_SHM_WIRELESS,
buf : 			      0x0004, 1023);
buf : 
buf : 	do {
buf : 		if (b43legacy_using_pio(dev))
if (b43legacy_using_pio(dev)) 
buf : 			err = b43legacy_pio_init(dev);
buf : 		else {
buf : 			err = b43legacy_dma_init(dev);
buf : 			if (!err)
if (!err) 
buf : 				b43legacy_qos_init(dev);
buf : 		}
buf : 	} while (err == -EAGAIN);
while (err == -EAGAIN); 
buf : 	if (err)
buf : 		goto err_chip_exit;
buf : 
buf : 	b43legacy_set_synth_pu_delay(dev, 1);
buf : 
buf : 	ssb_bus_powerup(bus, 1); /* Enable dynamic PCTL */
buf : 	b43legacy_upload_card_macaddress(dev);
buf : 	b43legacy_security_init(dev);
buf : 	b43legacy_rng_init(wl);
buf : 
buf : 	ieee80211_wake_queues(dev->wl->hw);
buf : 	b43legacy_set_status(dev, B43legacy_STAT_INITIALIZED);
buf : 
buf : 	b43legacy_leds_init(dev);
buf : out:
buf : 	return err;
buf : 
buf : err_chip_exit:
buf : 	b43legacy_chip_exit(dev);
buf : err_kfree_tssitbl:
buf : 	if (phy->dyn_tssi_tbl)
if (phy->dyn_tssi_tbl) 
buf : 		kfree(phy->tssi2dbm);
buf : err_kfree_lo_control:
buf : 	kfree(phy->lo_control);
buf : 	phy->lo_control = NULL;
buf : 	ssb_bus_may_powerdown(bus);
buf : 	B43legacy_WARN_ON(b43legacy_status(dev) != B43legacy_STAT_UNINIT);
buf : 	return err;
buf : }
buf : 
buf : static int b43legacy_op_add_interface(struct ieee80211_hw *hw,
buf : 				      struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	struct b43legacy_wldev *dev;
buf : 	unsigned long flags;
buf : 	int err = -EOPNOTSUPP;
buf : 
buf : 	/* TODO: allow WDS/AP devices to coexist */
buf : 
buf : 	if (vif->type != NL80211_IFTYPE_AP &&
if (vif->type != NL80211_IFTYPE_AP && 
buf : 	    vif->type != NL80211_IFTYPE_STATION &&
buf : 	    vif->type != NL80211_IFTYPE_WDS &&
if->type != NL80211_IFTYPE_WDS && 
buf : 	    vif->type != NL80211_IFTYPE_ADHOC)
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	if (wl->operating)
if (wl->operating) 
buf : 		goto out_mutex_unlock;
buf : 
buf : 	b43legacydbg(wl, "Adding Interface type %d\n", vif->type);
if->type); 
buf : 
buf : 	dev = wl->current_dev;
buf : 	wl->operating = true;
buf : 	wl->vif = vif;
if = vif; 
buf : 	wl->if_type = vif->type;
buf : 	memcpy(wl->mac_addr, vif->addr, ETH_ALEN);
if->addr, ETH_ALEN); 
buf : 
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	b43legacy_adjust_opmode(dev);
buf : 	b43legacy_set_pretbtt(dev);
buf : 	b43legacy_set_synth_pu_delay(dev, 0);
buf : 	b43legacy_upload_card_macaddress(dev);
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 
buf : 	err = 0;
buf :  out_mutex_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void b43legacy_op_remove_interface(struct ieee80211_hw *hw,
buf : 					  struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	struct b43legacy_wldev *dev = wl->current_dev;
buf : 	unsigned long flags;
buf : 
buf : 	b43legacydbg(wl, "Removing Interface type %d\n", vif->type);
if->type); 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	B43legacy_WARN_ON(!wl->operating);
buf : 	B43legacy_WARN_ON(wl->vif != vif);
if != vif); 
buf : 	wl->vif = NULL;
buf : 
buf : 	wl->operating = false;
buf : 
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	b43legacy_adjust_opmode(dev);
buf : 	memset(wl->mac_addr, 0, ETH_ALEN);
buf : 	b43legacy_upload_card_macaddress(dev);
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int b43legacy_op_start(struct ieee80211_hw *hw)
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	struct b43legacy_wldev *dev = wl->current_dev;
buf : 	int did_init = 0;
buf : 	int err = 0;
buf : 
buf : 	/* Kill all old instance specific information to make sure
ific information to make sure 
buf : 	 * the card won't use it in the short timeframe between start
buf : 	 * and mac80211 reconfiguring it. */
buf : 	memset(wl->bssid, 0, ETH_ALEN);
buf : 	memset(wl->mac_addr, 0, ETH_ALEN);
buf : 	wl->filter_flags = 0;
buf : 	wl->beacon0_uploaded = false;
buf : 	wl->beacon1_uploaded = false;
buf : 	wl->beacon_templates_virgin = true;
buf : 	wl->radio_enabled = true;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (b43legacy_status(dev) < B43legacy_STAT_INITIALIZED) {
if (b43legacy_status(dev) < B43legacy_STAT_INITIALIZED) { 
buf : 		err = b43legacy_wireless_core_init(dev);
buf : 		if (err)
if (err) 
buf : 			goto out_mutex_unlock;
buf : 		did_init = 1;
buf : 	}
buf : 
buf : 	if (b43legacy_status(dev) < B43legacy_STAT_STARTED) {
if (b43legacy_status(dev) < B43legacy_STAT_STARTED) { 
buf : 		err = b43legacy_wireless_core_start(dev);
buf : 		if (err) {
if (err) { 
buf : 			if (did_init)
buf : 				b43legacy_wireless_core_exit(dev);
buf : 			goto out_mutex_unlock;
buf : 		}
buf : 	}
buf : 
buf : 	wiphy_rfkill_start_polling(hw->wiphy);
buf : 
buf : out_mutex_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void b43legacy_op_stop(struct ieee80211_hw *hw)
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	struct b43legacy_wldev *dev = wl->current_dev;
buf : 
buf : 	cancel_work_sync(&(wl->beacon_update_trigger));
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	if (b43legacy_status(dev) >= B43legacy_STAT_STARTED)
if (b43legacy_status(dev) >= B43legacy_STAT_STARTED) 
buf : 		b43legacy_wireless_core_stop(dev);
buf : 	b43legacy_wireless_core_exit(dev);
buf : 	wl->radio_enabled = false;
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int b43legacy_op_beacon_set_tim(struct ieee80211_hw *hw,
buf : 				       struct ieee80211_sta *sta, bool set)
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	unsigned long flags;
buf : 
buf : 	spin_lock_irqsave(&wl->irq_lock, flags);
buf : 	b43legacy_update_templates(wl);
buf : 	spin_unlock_irqrestore(&wl->irq_lock, flags);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int b43legacy_op_get_survey(struct ieee80211_hw *hw, int idx,
buf : 				   struct survey_info *survey)
buf : {
buf : 	struct b43legacy_wl *wl = hw_to_b43legacy_wl(hw);
buf : 	struct b43legacy_wldev *dev = wl->current_dev;
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 
buf : 	if (idx != 0)
if (idx != 0) 
buf : 		return -ENOENT;
buf : 
buf : 	survey->channel = conf->chandef.chan;
buf : 	survey->filled = SURVEY_INFO_NOISE_DBM;
buf : 	survey->noise = dev->stats.link_noise;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static const struct ieee80211_ops b43legacy_hw_ops = {
buf : 	.tx			= b43legacy_op_tx,
buf : 	.conf_tx		= b43legacy_op_conf_tx,
buf : 	.add_interface		= b43legacy_op_add_interface,
buf : 	.remove_interface	= b43legacy_op_remove_interface,
buf : 	.config			= b43legacy_op_dev_config,
buf : 	.bss_info_changed	= b43legacy_op_bss_info_changed,
buf : 	.configure_filter	= b43legacy_op_configure_filter,
buf : 	.get_stats		= b43legacy_op_get_stats,
buf : 	.start			= b43legacy_op_start,
buf : 	.stop			= b43legacy_op_stop,
buf : 	.set_tim		= b43legacy_op_beacon_set_tim,
buf : 	.get_survey		= b43legacy_op_get_survey,
buf : 	.rfkill_poll		= b43legacy_rfkill_poll,
buf : };
buf : 
buf : /* Hard-reset the chip. Do not call this directly.
buf :  * Use b43legacy_controller_restart()
buf :  */
buf : static void b43legacy_chip_reset(struct work_struct *work)
buf : {
buf : 	struct b43legacy_wldev *dev =
buf : 		container_of(work, struct b43legacy_wldev, restart_work);
buf : 	struct b43legacy_wl *wl = dev->wl;
buf : 	int err = 0;
buf : 	int prev_status;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	prev_status = b43legacy_status(dev);
buf : 	/* Bring the device down... */
buf : 	if (prev_status >= B43legacy_STAT_STARTED)
if (prev_status >= B43legacy_STAT_STARTED) 
buf : 		b43legacy_wireless_core_stop(dev);
buf : 	if (prev_status >= B43legacy_STAT_INITIALIZED)
if (prev_status >= B43legacy_STAT_INITIALIZED) 
buf : 		b43legacy_wireless_core_exit(dev);
buf : 
buf : 	/* ...and up again. */
buf : 	if (prev_status >= B43legacy_STAT_INITIALIZED) {
if (prev_status >= B43legacy_STAT_INITIALIZED) { 
buf : 		err = b43legacy_wireless_core_init(dev);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 	if (prev_status >= B43legacy_STAT_STARTED) {
if (prev_status >= B43legacy_STAT_STARTED) { 
buf : 		err = b43legacy_wireless_core_start(dev);
buf : 		if (err) {
if (err) { 
buf : 			b43legacy_wireless_core_exit(dev);
buf : 			goto out;
buf : 		}
buf : 	}
buf : out:
buf : 	if (err)
if (err) 
buf : 		wl->current_dev = NULL; /* Failed to init the dev. */
buf : 	mutex_unlock(&wl->mutex);
buf : 	if (err)
if (err) 
buf : 		b43legacyerr(wl, "Controller restart FAILED\n");
buf : 	else
buf : 		b43legacyinfo(wl, "Controller restarted\n");
buf : }
buf : 
buf : static int b43legacy_setup_modes(struct b43legacy_wldev *dev,
buf : 				 int have_bphy,
buf : 				 int have_gphy)
buf : {
buf : 	struct ieee80211_hw *hw = dev->wl->hw;
buf : 	struct b43legacy_phy *phy = &dev->phy;
buf : 
buf : 	phy->possible_phymodes = 0;
buf : 	if (have_bphy) {
if (have_bphy) { 
buf : 		hw->wiphy->bands[IEEE80211_BAND_2GHZ] =
buf : 			&b43legacy_band_2GHz_BPHY;
buf : 		phy->possible_phymodes |= B43legacy_PHYMODE_B;
buf : 	}
buf : 
buf : 	if (have_gphy) {
if (have_gphy) { 
buf : 		hw->wiphy->bands[IEEE80211_BAND_2GHZ] =
buf : 			&b43legacy_band_2GHz_GPHY;
buf : 		phy->possible_phymodes |= B43legacy_PHYMODE_G;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void b43legacy_wireless_core_detach(struct b43legacy_wldev *dev)
buf : {
buf : 	/* We release firmware that late to not be required to re-request
buf : 	 * is all the time when we reinit the core. */
buf : 	b43legacy_release_firmware(dev);
buf : }
buf : 
buf : static int b43legacy_wireless_core_attach(struct b43legacy_wldev *dev)
buf : {
buf : 	struct b43legacy_wl *wl = dev->wl;
buf : 	struct ssb_bus *bus = dev->dev->bus;
buf : 	struct pci_dev *pdev = (bus->bustype == SSB_BUSTYPE_PCI) ? bus->host_pci : NULL;
buf : 	int err;
buf : 	int have_bphy = 0;
buf : 	int have_gphy = 0;
buf : 	u32 tmp;
buf : 
buf : 	/* Do NOT do any device initialization here.
buf : 	 * Do it in wireless_core_init() instead.
buf : 	 * This function is for gathering basic information about the HW, only.
for gathering basic information about the HW, only. 
buf : 	 * Also some structs may be set up here. But most likely you want to
buf : 	 * have that in core_init(), too.
buf : 	 */
buf : 
buf : 	err = ssb_bus_powerup(bus, 0);
buf : 	if (err) {
if (err) { 
buf : 		b43legacyerr(wl, "Bus powerup failed\n");
buf : 		goto out;
buf : 	}
buf : 	/* Get the PHY type. */
buf : 	if (dev->dev->id.revision >= 5) {
if (dev->dev->id.revision >= 5) { 
buf : 		u32 tmshigh;
buf : 
buf : 		tmshigh = ssb_read32(dev->dev, SSB_TMSHIGH);
buf : 		have_gphy = !!(tmshigh & B43legacy_TMSHIGH_GPHY);
buf : 		if (!have_gphy)
if (!have_gphy) 
buf : 			have_bphy = 1;
buf : 	} else if (dev->dev->id.revision == 4)
if (dev->dev->id.revision == 4) 
buf : 		have_gphy = 1;
buf : 	else
buf : 		have_bphy = 1;
buf : 
buf : 	dev->phy.gmode = (have_gphy || have_bphy);
buf : 	dev->phy.radio_on = true;
buf : 	tmp = dev->phy.gmode ? B43legacy_TMSLOW_GMODE : 0;
buf : 	b43legacy_wireless_core_reset(dev, tmp);
buf : 
buf : 	err = b43legacy_phy_versioning(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_powerdown;
buf : 	/* Check if this device supports multiband. */
if this device supports multiband. */ 
buf : 	if (!pdev ||
buf : 	    (pdev->device != 0x4312 &&
buf : 	     pdev->device != 0x4319 &&
buf : 	     pdev->device != 0x4324)) {
buf : 		/* No multiband support. */
buf : 		have_bphy = 0;
buf : 		have_gphy = 0;
buf : 		switch (dev->phy.type) {
buf : 		case B43legacy_PHYTYPE_B:
buf : 			have_bphy = 1;
buf : 			break;
buf : 		case B43legacy_PHYTYPE_G:
buf : 			have_gphy = 1;
buf : 			break;
buf : 		default:
buf : 			B43legacy_BUG_ON(1);
buf : 		}
buf : 	}
buf : 	dev->phy.gmode = (have_gphy || have_bphy);
buf : 	tmp = dev->phy.gmode ? B43legacy_TMSLOW_GMODE : 0;
buf : 	b43legacy_wireless_core_reset(dev, tmp);
buf : 
buf : 	err = b43legacy_validate_chipaccess(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_powerdown;
buf : 	err = b43legacy_setup_modes(dev, have_bphy, have_gphy);
buf : 	if (err)
if (err) 
buf : 		goto err_powerdown;
buf : 
buf : 	/* Now set some default "current_dev" */
buf : 	if (!wl->current_dev)
if (!wl->current_dev) 
buf : 		wl->current_dev = dev;
buf : 	INIT_WORK(&dev->restart_work, b43legacy_chip_reset);
buf : 
buf : 	b43legacy_radio_turn_off(dev, 1);
buf : 	b43legacy_switch_analog(dev, 0);
buf : 	ssb_device_disable(dev->dev, 0);
buf : 	ssb_bus_may_powerdown(bus);
buf : 
buf : out:
buf : 	return err;
buf : 
buf : err_powerdown:
buf : 	ssb_bus_may_powerdown(bus);
buf : 	return err;
buf : }
buf : 
buf : static void b43legacy_one_core_detach(struct ssb_device *dev)
buf : {
buf : 	struct b43legacy_wldev *wldev;
buf : 	struct b43legacy_wl *wl;
buf : 
buf : 	/* Do not cancel ieee80211-workqueue based work here.
buf : 	 * See comment in b43legacy_remove(). */
buf : 
buf : 	wldev = ssb_get_drvdata(dev);
buf : 	wl = wldev->wl;
buf : 	b43legacy_debugfs_remove_device(wldev);
buf : 	b43legacy_wireless_core_detach(wldev);
buf : 	list_del(&wldev->list);
buf : 	wl->nr_devs--;
buf : 	ssb_set_drvdata(dev, NULL);
buf : 	kfree(wldev);
buf : }
buf : 
buf : static int b43legacy_one_core_attach(struct ssb_device *dev,
buf : 				     struct b43legacy_wl *wl)
buf : {
buf : 	struct b43legacy_wldev *wldev;
buf : 	int err = -ENOMEM;
buf : 
buf : 	wldev = kzalloc(sizeof(*wldev), GFP_KERNEL);
buf : 	if (!wldev)
if (!wldev) 
buf : 		goto out;
buf : 
buf : 	wldev->dev = dev;
buf : 	wldev->wl = wl;
buf : 	b43legacy_set_status(wldev, B43legacy_STAT_UNINIT);
buf : 	wldev->bad_frames_preempt = modparam_bad_frames_preempt;
buf : 	tasklet_init(&wldev->isr_tasklet,
buf : 		     (void (*)(unsigned long))b43legacy_interrupt_tasklet,
buf : 		     (unsigned long)wldev);
buf : 	if (modparam_pio)
if (modparam_pio) 
buf : 		wldev->__using_pio = true;
buf : 	INIT_LIST_HEAD(&wldev->list);
buf : 
buf : 	err = b43legacy_wireless_core_attach(wldev);
buf : 	if (err)
if (err) 
buf : 		goto err_kfree_wldev;
buf : 
buf : 	list_add(&wldev->list, &wl->devlist);
buf : 	wl->nr_devs++;
buf : 	ssb_set_drvdata(dev, wldev);
buf : 	b43legacy_debugfs_add_device(wldev);
buf : out:
buf : 	return err;
buf : 
buf : err_kfree_wldev:
buf : 	kfree(wldev);
buf : 	return err;
buf : }
buf : 
buf : static void b43legacy_sprom_fixup(struct ssb_bus *bus)
buf : {
buf : 	/* boardflags workarounds */
buf : 	if (bus->boardinfo.vendor == PCI_VENDOR_ID_APPLE &&
if (bus->boardinfo.vendor == PCI_VENDOR_ID_APPLE && 
buf : 	    bus->boardinfo.type == 0x4E &&
buf : 	    bus->sprom.board_rev > 0x40)
buf : 		bus->sprom.boardflags_lo |= B43legacy_BFL_PACTRL;
buf : }
buf : 
buf : static void b43legacy_wireless_exit(struct ssb_device *dev,
buf : 				  struct b43legacy_wl *wl)
buf : {
buf : 	struct ieee80211_hw *hw = wl->hw;
buf : 
buf : 	ssb_set_devtypedata(dev, NULL);
buf : 	ieee80211_free_hw(hw);
buf : }
buf : 
buf : static int b43legacy_wireless_init(struct ssb_device *dev)
buf : {
buf : 	struct ssb_sprom *sprom = &dev->bus->sprom;
buf : 	struct ieee80211_hw *hw;
buf : 	struct b43legacy_wl *wl;
buf : 	int err = -ENOMEM;
buf : 	int queue_num;
buf : 
buf : 	b43legacy_sprom_fixup(dev->bus);
buf : 
buf : 	hw = ieee80211_alloc_hw(sizeof(*wl), &b43legacy_hw_ops);
buf : 	if (!hw) {
if (!hw) { 
buf : 		b43legacyerr(NULL, "Could not allocate ieee80211 device\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	/* fill hw info */
buf : 	hw->flags = IEEE80211_HW_RX_INCLUDES_FCS |
buf : 		    IEEE80211_HW_SIGNAL_DBM;
buf : 	hw->wiphy->interface_modes =
buf : 		BIT(NL80211_IFTYPE_AP) |
buf : 		BIT(NL80211_IFTYPE_STATION) |
buf : 		BIT(NL80211_IFTYPE_WDS) |
buf : 		BIT(NL80211_IFTYPE_ADHOC);
buf : 	hw->queues = 1; /* FIXME: hardware has more queues */
buf : 	hw->max_rates = 2;
buf : 	SET_IEEE80211_DEV(hw, dev->dev);
buf : 	if (is_valid_ether_addr(sprom->et1mac))
if (is_valid_ether_addr(sprom->et1mac)) 
buf : 		SET_IEEE80211_PERM_ADDR(hw, sprom->et1mac);
buf : 	else
buf : 		SET_IEEE80211_PERM_ADDR(hw, sprom->il0mac);
buf : 
buf : 	/* Get and initialize struct b43legacy_wl */
buf : 	wl = hw_to_b43legacy_wl(hw);
buf : 	memset(wl, 0, sizeof(*wl));
buf : 	wl->hw = hw;
buf : 	spin_lock_init(&wl->irq_lock);
buf : 	spin_lock_init(&wl->leds_lock);
buf : 	mutex_init(&wl->mutex);
buf : 	INIT_LIST_HEAD(&wl->devlist);
buf : 	INIT_WORK(&wl->beacon_update_trigger, b43legacy_beacon_update_trigger_work);
buf : 	INIT_WORK(&wl->tx_work, b43legacy_tx_work);
buf : 
buf : 	/* Initialize queues and flags. */
buf : 	for (queue_num = 0; queue_num < B43legacy_QOS_QUEUE_NUM; queue_num++) {
for (queue_num = 0; queue_num < B43legacy_QOS_QUEUE_NUM; queue_num++) { 
buf : 		skb_queue_head_init(&wl->tx_queue[queue_num]);
buf : 		wl->tx_queue_stopped[queue_num] = 0;
buf : 	}
buf : 
buf : 	ssb_set_devtypedata(dev, wl);
buf : 	b43legacyinfo(wl, "Broadcom %04X WLAN found (core revision %u)\n",
buf : 		      dev->bus->chip_id, dev->id.revision);
buf : 	err = 0;
buf : out:
buf : 	return err;
buf : }
buf : 
buf : static int b43legacy_probe(struct ssb_device *dev,
buf : 			 const struct ssb_device_id *id)
buf : {
buf : 	struct b43legacy_wl *wl;
buf : 	int err;
buf : 	int first = 0;
buf : 
buf : 	wl = ssb_get_devtypedata(dev);
buf : 	if (!wl) {
if (!wl) { 
buf : 		/* Probing the first core - setup common struct b43legacy_wl */
buf : 		first = 1;
buf : 		err = b43legacy_wireless_init(dev);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 		wl = ssb_get_devtypedata(dev);
buf : 		B43legacy_WARN_ON(!wl);
buf : 	}
buf : 	err = b43legacy_one_core_attach(dev, wl);
buf : 	if (err)
if (err) 
buf : 		goto err_wireless_exit;
buf : 
buf : 	/* setup and start work to load firmware */
buf : 	INIT_WORK(&wl->firmware_load, b43legacy_request_firmware);
buf : 	schedule_work(&wl->firmware_load);
buf : 
buf : out:
buf : 	return err;
buf : 
buf : err_wireless_exit:
buf : 	if (first)
if (first) 
buf : 		b43legacy_wireless_exit(dev, wl);
buf : 	return err;
buf : }
buf : 
buf : static void b43legacy_remove(struct ssb_device *dev)
buf : {
buf : 	struct b43legacy_wl *wl = ssb_get_devtypedata(dev);
buf : 	struct b43legacy_wldev *wldev = ssb_get_drvdata(dev);
buf : 
buf : 	/* We must cancel any work here before unregistering from ieee80211,
fore unregistering from ieee80211, 
buf : 	 * as the ieee80211 unreg will destroy the workqueue. */
buf : 	cancel_work_sync(&wldev->restart_work);
buf : 	cancel_work_sync(&wl->firmware_load);
buf : 	complete(&wldev->fw_load_complete);
buf : 
buf : 	B43legacy_WARN_ON(!wl);
buf : 	if (!wldev->fw.ucode)
if (!wldev->fw.ucode) 
buf : 		return;			/* NULL if fw never loaded */
buf : 	if (wl->current_dev == wldev)
if (wl->current_dev == wldev) 
buf : 		ieee80211_unregister_hw(wl->hw);
buf : 
buf : 	b43legacy_one_core_detach(dev);
buf : 
buf : 	if (list_empty(&wl->devlist))
if (list_empty(&wl->devlist)) 
buf : 		/* Last core on the chip unregistered.
buf : 		 * We can destroy common struct b43legacy_wl.
buf : 		 */
buf : 		b43legacy_wireless_exit(dev, wl);
buf : }
buf : 
buf : /* Perform a hardware reset. This can be called from any context. */
form a hardware reset. This can be called from any context. */ 
buf : void b43legacy_controller_restart(struct b43legacy_wldev *dev,
buf : 				  const char *reason)
buf : {
buf : 	/* Must avoid requeueing, if we are in shutdown. */
if we are in shutdown. */ 
buf : 	if (b43legacy_status(dev) < B43legacy_STAT_INITIALIZED)
buf : 		return;
buf : 	b43legacyinfo(dev->wl, "Controller RESET (%s) ...\n", reason);
buf : 	ieee80211_queue_work(dev->wl->hw, &dev->restart_work);
buf : }
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 
buf : static int b43legacy_suspend(struct ssb_device *dev, pm_message_t state)
buf : {
buf : 	struct b43legacy_wldev *wldev = ssb_get_drvdata(dev);
buf : 	struct b43legacy_wl *wl = wldev->wl;
buf : 
buf : 	b43legacydbg(wl, "Suspending...\n");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	wldev->suspend_init_status = b43legacy_status(wldev);
buf : 	if (wldev->suspend_init_status >= B43legacy_STAT_STARTED)
if (wldev->suspend_init_status >= B43legacy_STAT_STARTED) 
buf : 		b43legacy_wireless_core_stop(wldev);
buf : 	if (wldev->suspend_init_status >= B43legacy_STAT_INITIALIZED)
if (wldev->suspend_init_status >= B43legacy_STAT_INITIALIZED) 
buf : 		b43legacy_wireless_core_exit(wldev);
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	b43legacydbg(wl, "Device suspended.\n");
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int b43legacy_resume(struct ssb_device *dev)
buf : {
buf : 	struct b43legacy_wldev *wldev = ssb_get_drvdata(dev);
buf : 	struct b43legacy_wl *wl = wldev->wl;
buf : 	int err = 0;
buf : 
buf : 	b43legacydbg(wl, "Resuming...\n");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	if (wldev->suspend_init_status >= B43legacy_STAT_INITIALIZED) {
if (wldev->suspend_init_status >= B43legacy_STAT_INITIALIZED) { 
buf : 		err = b43legacy_wireless_core_init(wldev);
buf : 		if (err) {
if (err) { 
buf : 			b43legacyerr(wl, "Resume failed at core init\n");
buf : 			goto out;
buf : 		}
buf : 	}
buf : 	if (wldev->suspend_init_status >= B43legacy_STAT_STARTED) {
if (wldev->suspend_init_status >= B43legacy_STAT_STARTED) { 
buf : 		err = b43legacy_wireless_core_start(wldev);
buf : 		if (err) {
if (err) { 
buf : 			b43legacy_wireless_core_exit(wldev);
buf : 			b43legacyerr(wl, "Resume failed at core start\n");
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : 	b43legacydbg(wl, "Device resumed.\n");
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 	return err;
buf : }
buf : 
buf : #else	/* CONFIG_PM */
buf : # define b43legacy_suspend	NULL
buf : # define b43legacy_resume		NULL
buf : #endif	/* CONFIG_PM */
if	/* CONFIG_PM */ 
buf : 
buf : static struct ssb_driver b43legacy_ssb_driver = {
buf : 	.name		= KBUILD_MODNAME,
buf : 	.id_table	= b43legacy_ssb_tbl,
buf : 	.probe		= b43legacy_probe,
buf : 	.remove		= b43legacy_remove,
buf : 	.suspend	= b43legacy_suspend,
buf : 	.resume		= b43legacy_resume,
buf : };
buf : 
buf : static void b43legacy_print_driverinfo(void)
buf : {
buf : 	const char *feat_pci = "", *feat_leds = "",
buf : 		   *feat_pio = "", *feat_dma = "";
buf : 
buf : #ifdef CONFIG_B43LEGACY_PCI_AUTOSELECT
ifdef CONFIG_B43LEGACY_PCI_AUTOSELECT 
buf : 	feat_pci = "P";
buf : #endif
if 
buf : #ifdef CONFIG_B43LEGACY_LEDS
buf : 	feat_leds = "L";
buf : #endif
if 
buf : #ifdef CONFIG_B43LEGACY_PIO
buf : 	feat_pio = "I";
buf : #endif
if 
buf : #ifdef CONFIG_B43LEGACY_DMA
buf : 	feat_dma = "D";
buf : #endif
if 
buf : 	printk(KERN_INFO "Broadcom 43xx-legacy driver loaded "
buf : 	       "[ Features: %s%s%s%s ]\n",
buf : 	       feat_pci, feat_leds, feat_pio, feat_dma);
buf : }
buf : 
buf : static int __init b43legacy_init(void)
buf : {
buf : 	int err;
buf : 
buf : 	b43legacy_debugfs_init();
buf : 
buf : 	err = ssb_driver_register(&b43legacy_ssb_driver);
buf : 	if (err)
if (err) 
buf : 		goto err_dfs_exit;
buf : 
buf : 	b43legacy_print_driverinfo();
buf : 
buf : 	return err;
buf : 
buf : err_dfs_exit:
buf : 	b43legacy_debugfs_exit();
buf : 	return err;
buf : }
buf : 
buf : static void __exit b43legacy_exit(void)
buf : {
buf : 	ssb_driver_unregister(&b43legacy_ssb_driver);
buf : 	b43legacy_debugfs_exit();
buf : }
buf : 
buf : module_init(b43legacy_init)
buf : module_exit(b43legacy_exit)
file : ./test/kernel/drivers/net/wireless/rtlwifi/rtl8723com/main.c 
[ OK ] open : 4 ok... 
buf : /******************************************************************************
buf :  *
buf :  * Copyright(c) 2009-2014  Realtek Corporation.
buf :  *
buf :  * This program is free software; you can redistribute it and/or modify it
ify it 
buf :  * under the terms of version 2 of the GNU General Public License as
buf :  * published by the Free Software Foundation.
buf :  *
buf :  * This program is distributed in the hope that it will be useful, but WITHOUT
buf :  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
buf :  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
for 
buf :  * more details.
buf :  *
buf :  * The full GNU General Public License is included in this distribution in the
buf :  * file called LICENSE.
buf :  *
buf :  * Contact Information:
formation: 
buf :  * wlanfae <wlanfae@realtek.com>
buf :  * Realtek Corporation, No. 2, Innovation Road II, Hsinchu Science Park,
buf :  * Hsinchu 300, Taiwan.
buf :  *
buf :  * Larry Finger <Larry.Finger@lwfinger.net>
buf :  *
buf :  *****************************************************************************/
buf : 
buf : #include "../wifi.h"
ifi.h" 
buf : #include <linux/module.h>
buf : 
buf : 
buf : MODULE_AUTHOR("Realtek WlanFAE	<wlanfae@realtek.com>");
buf : MODULE_AUTHOR("Larry Finger	<Larry.Finger@lwfinger.net>");
buf : MODULE_LICENSE("GPL");
buf : MODULE_DESCRIPTION("Realtek RTL8723AE/RTL8723BE 802.11n PCI wireless common routines");
file : ./test/kernel/drivers/net/wireless/rtlwifi/rtl8192c/main.c 
[ OK ] open : 4 ok... 
buf : /******************************************************************************
buf :  *
buf :  * Copyright(c) 2009-2012  Realtek Corporation.
buf :  *
buf :  * This program is free software; you can redistribute it and/or modify it
ify it 
buf :  * under the terms of version 2 of the GNU General Public License as
buf :  * published by the Free Software Foundation.
buf :  *
buf :  * This program is distributed in the hope that it will be useful, but WITHOUT
buf :  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
buf :  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
for 
buf :  * more details.
buf :  *
buf :  * You should have received a copy of the GNU General Public License along with
buf :  * this program; if not, write to the Free Software Foundation, Inc.,
if not, write to the Free Software Foundation, Inc., 
buf :  * 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
buf :  *
buf :  * The full GNU General Public License is included in this distribution in the
buf :  * file called LICENSE.
buf :  *
buf :  * Contact Information:
formation: 
buf :  * wlanfae <wlanfae@realtek.com>
buf :  * Realtek Corporation, No. 2, Innovation Road II, Hsinchu Science Park,
buf :  * Hsinchu 300, Taiwan.
buf :  *
buf :  * Larry Finger <Larry.Finger@lwfinger.net>
buf :  *
buf :  *****************************************************************************/
buf : 
buf : #include "../wifi.h"
ifi.h" 
buf : #include <linux/module.h>
buf : 
buf : 
buf : MODULE_AUTHOR("lizhaoming	<chaoming_li@realsil.com.cn>");
buf : MODULE_AUTHOR("Realtek WlanFAE	<wlanfae@realtek.com>");
buf : MODULE_AUTHOR("Georgia		<georgia@realtek.com>");
buf : MODULE_AUTHOR("Ziv Huang	<ziv_huang@realtek.com>");
buf : MODULE_AUTHOR("Larry Finger	<Larry.Finger@lwfinger.net>");
buf : MODULE_LICENSE("GPL");
buf : MODULE_DESCRIPTION("Realtek 8192C/8188C 802.11n PCI wireless");
file : ./test/kernel/drivers/net/wireless/mwifiex/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Marvell Wireless LAN device driver: major functions
buf :  *
buf :  * Copyright (C) 2011, Marvell International Ltd.
buf :  *
buf :  * This software file (the "File") is distributed by Marvell International
buf :  * Ltd. under the terms of the GNU General Public License Version 2, June 1991
buf :  * (the "License").  You may use, redistribute and/or modify this File in
ify this File in 
buf :  * accordance with the terms and conditions of the License, a copy of which
buf :  * is available by writing to the Free Software Foundation, Inc.,
buf :  * 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA or on the
ifth Floor, Boston, MA 02110-1301 USA or on the 
buf :  * worldwide web at http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
buf :  *
buf :  * THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE
buf :  * IMPLIED WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE
buf :  * ARE EXPRESSLY DISCLAIMED.  The License provides additional details about
buf :  * this warranty disclaimer.
buf :  */
buf : 
buf : #include "main.h"
buf : #include "wmm.h"
buf : #include "cfg80211.h"
buf : #include "11n.h"
buf : 
buf : #define VERSION	"1.0"
buf : 
buf : const char driver_version[] = "mwifiex " VERSION " (%s) ";
ifiex " VERSION " (%s) "; 
buf : static char *cal_data_cfg;
buf : module_param(cal_data_cfg, charp, 0);
buf : 
buf : static void scan_delay_timer_fn(unsigned long data)
buf : {
buf : 	struct mwifiex_private *priv = (struct mwifiex_private *)data;
ifiex_private *priv = (struct mwifiex_private *)data; 
buf : 	struct mwifiex_adapter *adapter = priv->adapter;
buf : 	struct cmd_ctrl_node *cmd_node, *tmp_node;
buf : 	unsigned long flags;
buf : 
buf : 	if (adapter->surprise_removed)
if (adapter->surprise_removed) 
buf : 		return;
buf : 
buf : 	if (adapter->scan_delay_cnt == MWIFIEX_MAX_SCAN_DELAY_CNT ||
if (adapter->scan_delay_cnt == MWIFIEX_MAX_SCAN_DELAY_CNT || 
buf : 	    !adapter->scan_processing) {
buf : 		/*
buf : 		 * Abort scan operation by cancelling all pending scan
buf : 		 * commands
buf : 		 */
buf : 		spin_lock_irqsave(&adapter->scan_pending_q_lock, flags);
buf : 		list_for_each_entry_safe(cmd_node, tmp_node,
for_each_entry_safe(cmd_node, tmp_node, 
buf : 					 &adapter->scan_pending_q, list) {
buf : 			list_del(&cmd_node->list);
buf : 			mwifiex_insert_cmd_to_free_q(adapter, cmd_node);
ifiex_insert_cmd_to_free_q(adapter, cmd_node); 
buf : 		}
buf : 		spin_unlock_irqrestore(&adapter->scan_pending_q_lock, flags);
buf : 
buf : 		spin_lock_irqsave(&adapter->mwifiex_cmd_lock, flags);
ifiex_cmd_lock, flags); 
buf : 		adapter->scan_processing = false;
buf : 		adapter->scan_delay_cnt = 0;
buf : 		adapter->empty_tx_q_cnt = 0;
buf : 		spin_unlock_irqrestore(&adapter->mwifiex_cmd_lock, flags);
ifiex_cmd_lock, flags); 
buf : 
buf : 		if (priv->scan_request) {
buf : 			dev_dbg(adapter->dev, "info: aborting scan\n");
buf : 			cfg80211_scan_done(priv->scan_request, 1);
buf : 			priv->scan_request = NULL;
buf : 		} else {
buf : 			priv->scan_aborting = false;
buf : 			dev_dbg(adapter->dev, "info: scan already aborted\n");
buf : 		}
buf : 		goto done;
buf : 	}
buf : 
buf : 	if (!atomic_read(&priv->adapter->is_tx_received)) {
if (!atomic_read(&priv->adapter->is_tx_received)) { 
buf : 		adapter->empty_tx_q_cnt++;
buf : 		if (adapter->empty_tx_q_cnt == MWIFIEX_MAX_EMPTY_TX_Q_CNT) {
if (adapter->empty_tx_q_cnt == MWIFIEX_MAX_EMPTY_TX_Q_CNT) { 
buf : 			/*
buf : 			 * No Tx traffic for 200msec. Get scan command from
for 200msec. Get scan command from 
buf : 			 * scan pending queue and put to cmd pending queue to
buf : 			 * resume scan operation
buf : 			 */
buf : 			adapter->scan_delay_cnt = 0;
buf : 			adapter->empty_tx_q_cnt = 0;
buf : 			spin_lock_irqsave(&adapter->scan_pending_q_lock, flags);
buf : 			cmd_node = list_first_entry(&adapter->scan_pending_q,
buf : 						    struct cmd_ctrl_node, list);
buf : 			list_del(&cmd_node->list);
buf : 			spin_unlock_irqrestore(&adapter->scan_pending_q_lock,
buf : 					       flags);
buf : 
buf : 			mwifiex_insert_cmd_to_pending_q(adapter, cmd_node,
ifiex_insert_cmd_to_pending_q(adapter, cmd_node, 
buf : 							true);
buf : 			queue_work(adapter->workqueue, &adapter->main_work);
buf : 			goto done;
buf : 		}
buf : 	} else {
buf : 		adapter->empty_tx_q_cnt = 0;
buf : 	}
buf : 
buf : 	/* Delay scan operation further by 20msec */
buf : 	mod_timer(&priv->scan_delay_timer, jiffies +
iffies + 
buf : 		  msecs_to_jiffies(MWIFIEX_SCAN_DELAY_MSEC));
buf : 	adapter->scan_delay_cnt++;
buf : 
buf : done:
buf : 	if (atomic_read(&priv->adapter->is_tx_received))
if (atomic_read(&priv->adapter->is_tx_received)) 
buf : 		atomic_set(&priv->adapter->is_tx_received, false);
buf : 
buf : 	return;
buf : }
buf : 
buf : /*
buf :  * This function registers the device and performs all the necessary
forms all the necessary 
buf :  * initializations.
buf :  *
buf :  * The following initialization operations are performed -
formed - 
buf :  *      - Allocate adapter structure
buf :  *      - Save interface specific operations table in adapter
ific operations table in adapter 
buf :  *      - Call interface specific initialization routine
buf :  *      - Allocate private structures
buf :  *      - Set default adapter structure parameters
buf :  *      - Initialize locks
buf :  *
buf :  * In case of any errors during inittialization, this function also ensures
buf :  * proper cleanup before exiting.
fore exiting. 
buf :  */
buf : static int mwifiex_register(void *card, struct mwifiex_if_ops *if_ops,
ifiex_register(void *card, struct mwifiex_if_ops *if_ops, 
buf : 			    void **padapter)
buf : {
buf : 	struct mwifiex_adapter *adapter;
ifiex_adapter *adapter; 
buf : 	int i;
buf : 
buf : 	adapter = kzalloc(sizeof(struct mwifiex_adapter), GFP_KERNEL);
ifiex_adapter), GFP_KERNEL); 
buf : 	if (!adapter)
buf : 		return -ENOMEM;
buf : 
buf : 	*padapter = adapter;
buf : 	adapter->card = card;
buf : 
buf : 	/* Save interface specific operations in adapter */
ific operations in adapter */ 
buf : 	memmove(&adapter->if_ops, if_ops, sizeof(struct mwifiex_if_ops));
buf : 
buf : 	/* card specific initialization has been deferred until now .. */
ific initialization has been deferred until now .. */ 
buf : 	if (adapter->if_ops.init_if)
buf : 		if (adapter->if_ops.init_if(adapter))
if (adapter->if_ops.init_if(adapter)) 
buf : 			goto error;
buf : 
buf : 	adapter->priv_num = 0;
buf : 
buf : 	for (i = 0; i < MWIFIEX_MAX_BSS_NUM; i++) {
for (i = 0; i < MWIFIEX_MAX_BSS_NUM; i++) { 
buf : 		/* Allocate memory for private structure */
buf : 		adapter->priv[i] =
buf : 			kzalloc(sizeof(struct mwifiex_private), GFP_KERNEL);
ifiex_private), GFP_KERNEL); 
buf : 		if (!adapter->priv[i])
buf : 			goto error;
buf : 
buf : 		adapter->priv[i]->adapter = adapter;
buf : 		adapter->priv_num++;
buf : 
buf : 		setup_timer(&adapter->priv[i]->scan_delay_timer,
buf : 			    scan_delay_timer_fn,
buf : 			    (unsigned long)adapter->priv[i]);
buf : 	}
buf : 	mwifiex_init_lock_list(adapter);
ifiex_init_lock_list(adapter); 
buf : 
buf : 	init_timer(&adapter->cmd_timer);
buf : 	adapter->cmd_timer.function = mwifiex_cmd_timeout_func;
ifiex_cmd_timeout_func; 
buf : 	adapter->cmd_timer.data = (unsigned long) adapter;
buf : 
buf : 	return 0;
buf : 
buf : error:
buf : 	dev_dbg(adapter->dev, "info: leave mwifiex_register with error\n");
ifiex_register with error\n"); 
buf : 
buf : 	for (i = 0; i < adapter->priv_num; i++)
for (i = 0; i < adapter->priv_num; i++) 
buf : 		kfree(adapter->priv[i]);
buf : 
buf : 	kfree(adapter);
buf : 
buf : 	return -1;
buf : }
buf : 
buf : /*
buf :  * This function unregisters the device and performs all the necessary
forms all the necessary 
buf :  * cleanups.
buf :  *
buf :  * The following cleanup operations are performed -
formed - 
buf :  *      - Free the timers
buf :  *      - Free beacon buffers
buf :  *      - Free private structures
buf :  *      - Free adapter structure
buf :  */
buf : static int mwifiex_unregister(struct mwifiex_adapter *adapter)
ifiex_unregister(struct mwifiex_adapter *adapter) 
buf : {
buf : 	s32 i;
buf : 
buf : 	if (adapter->if_ops.cleanup_if)
if (adapter->if_ops.cleanup_if) 
buf : 		adapter->if_ops.cleanup_if(adapter);
buf : 
buf : 	del_timer_sync(&adapter->cmd_timer);
buf : 
buf : 	/* Free private structures */
buf : 	for (i = 0; i < adapter->priv_num; i++) {
for (i = 0; i < adapter->priv_num; i++) { 
buf : 		if (adapter->priv[i]) {
buf : 			mwifiex_free_curr_bcn(adapter->priv[i]);
ifiex_free_curr_bcn(adapter->priv[i]); 
buf : 			del_timer_sync(&adapter->priv[i]->scan_delay_timer);
buf : 			kfree(adapter->priv[i]);
buf : 		}
buf : 	}
buf : 
buf : 	kfree(adapter);
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * The main process.
buf :  *
buf :  * This function is the main procedure of the driver and handles various driver
buf :  * operations. It runs in a loop and provides the core functionalities.
buf :  *
buf :  * The main responsibilities of this function are -
buf :  *      - Ensure concurrency control
buf :  *      - Handle pending interrupts and call interrupt handlers
buf :  *      - Wake up the card if required
if required 
buf :  *      - Handle command responses and call response handlers
buf :  *      - Handle events and call event handlers
buf :  *      - Execute pending commands
buf :  *      - Transmit pending data packets
buf :  */
buf : int mwifiex_main_process(struct mwifiex_adapter *adapter)
ifiex_main_process(struct mwifiex_adapter *adapter) 
buf : {
buf : 	int ret = 0;
buf : 	unsigned long flags;
buf : 	struct sk_buff *skb;
buf : 
buf : 	spin_lock_irqsave(&adapter->main_proc_lock, flags);
buf : 
buf : 	/* Check if already processing */
if already processing */ 
buf : 	if (adapter->mwifiex_processing) {
buf : 		spin_unlock_irqrestore(&adapter->main_proc_lock, flags);
buf : 		goto exit_main_proc;
buf : 	} else {
buf : 		adapter->mwifiex_processing = true;
ifiex_processing = true; 
buf : 		spin_unlock_irqrestore(&adapter->main_proc_lock, flags);
buf : 	}
buf : process_start:
buf : 	do {
buf : 		if ((adapter->hw_status == MWIFIEX_HW_STATUS_CLOSING) ||
if ((adapter->hw_status == MWIFIEX_HW_STATUS_CLOSING) || 
buf : 		    (adapter->hw_status == MWIFIEX_HW_STATUS_NOT_READY))
buf : 			break;
buf : 
buf : 		/* Handle pending interrupt if any */
if any */ 
buf : 		if (adapter->int_status) {
buf : 			if (adapter->hs_activated)
if (adapter->hs_activated) 
buf : 				mwifiex_process_hs_config(adapter);
buf : 			if (adapter->if_ops.process_int_status)
if (adapter->if_ops.process_int_status) 
buf : 				adapter->if_ops.process_int_status(adapter);
buf : 		}
buf : 
buf : 		/* Need to wake up the card ? */
buf : 		if ((adapter->ps_state == PS_STATE_SLEEP) &&
if ((adapter->ps_state == PS_STATE_SLEEP) && 
buf : 		    (adapter->pm_wakeup_card_req &&
buf : 		     !adapter->pm_wakeup_fw_try) &&
buf : 		    (is_command_pending(adapter) ||
buf : 		     !mwifiex_wmm_lists_empty(adapter))) {
ifiex_wmm_lists_empty(adapter))) { 
buf : 			adapter->pm_wakeup_fw_try = true;
buf : 			adapter->if_ops.wakeup(adapter);
if_ops.wakeup(adapter); 
buf : 			continue;
buf : 		}
buf : 
buf : 		if (IS_CARD_RX_RCVD(adapter)) {
if (IS_CARD_RX_RCVD(adapter)) { 
buf : 			adapter->pm_wakeup_fw_try = false;
buf : 			if (adapter->ps_state == PS_STATE_SLEEP)
if (adapter->ps_state == PS_STATE_SLEEP) 
buf : 				adapter->ps_state = PS_STATE_AWAKE;
buf : 		} else {
buf : 			/* We have tried to wakeup the card already */
buf : 			if (adapter->pm_wakeup_fw_try)
if (adapter->pm_wakeup_fw_try) 
buf : 				break;
buf : 			if (adapter->ps_state != PS_STATE_AWAKE ||
if (adapter->ps_state != PS_STATE_AWAKE || 
buf : 			    adapter->tx_lock_flag)
buf : 				break;
buf : 
buf : 			if ((adapter->scan_processing &&
if ((adapter->scan_processing && 
buf : 			     !adapter->scan_delay_cnt) || adapter->data_sent ||
buf : 			    mwifiex_wmm_lists_empty(adapter)) {
ifiex_wmm_lists_empty(adapter)) { 
buf : 				if (adapter->cmd_sent || adapter->curr_cmd ||
buf : 				    (!is_command_pending(adapter)))
buf : 					break;
buf : 			}
buf : 		}
buf : 
buf : 		/* Check Rx data for USB */
for USB */ 
buf : 		if (adapter->iface_type == MWIFIEX_USB)
buf : 			while ((skb = skb_dequeue(&adapter->usb_rx_data_q)))
while ((skb = skb_dequeue(&adapter->usb_rx_data_q))) 
buf : 				mwifiex_handle_rx_packet(adapter, skb);
buf : 
buf : 		/* Check for event */
for event */ 
buf : 		if (adapter->event_received) {
buf : 			adapter->event_received = false;
buf : 			mwifiex_process_event(adapter);
ifiex_process_event(adapter); 
buf : 		}
buf : 
buf : 		/* Check for Cmd Resp */
for Cmd Resp */ 
buf : 		if (adapter->cmd_resp_received) {
buf : 			adapter->cmd_resp_received = false;
buf : 			mwifiex_process_cmdresp(adapter);
ifiex_process_cmdresp(adapter); 
buf : 
buf : 			/* call mwifiex back when init_fw is done */
buf : 			if (adapter->hw_status == MWIFIEX_HW_STATUS_INIT_DONE) {
if (adapter->hw_status == MWIFIEX_HW_STATUS_INIT_DONE) { 
buf : 				adapter->hw_status = MWIFIEX_HW_STATUS_READY;
buf : 				mwifiex_init_fw_complete(adapter);
ifiex_init_fw_complete(adapter); 
buf : 			}
buf : 		}
buf : 
buf : 		/* Check if we need to confirm Sleep Request
if we need to confirm Sleep Request 
buf : 		   received previously */
buf : 		if (adapter->ps_state == PS_STATE_PRE_SLEEP) {
if (adapter->ps_state == PS_STATE_PRE_SLEEP) { 
buf : 			if (!adapter->cmd_sent && !adapter->curr_cmd)
buf : 				mwifiex_check_ps_cond(adapter);
ifiex_check_ps_cond(adapter); 
buf : 		}
buf : 
buf : 		/* * The ps_state may have been changed during processing of
buf : 		 * Sleep Request event.
buf : 		 */
buf : 		if ((adapter->ps_state == PS_STATE_SLEEP) ||
if ((adapter->ps_state == PS_STATE_SLEEP) || 
buf : 		    (adapter->ps_state == PS_STATE_PRE_SLEEP) ||
buf : 		    (adapter->ps_state == PS_STATE_SLEEP_CFM) ||
buf : 		    adapter->tx_lock_flag)
buf : 			continue;
buf : 
buf : 		if (!adapter->cmd_sent && !adapter->curr_cmd) {
if (!adapter->cmd_sent && !adapter->curr_cmd) { 
buf : 			if (mwifiex_exec_next_cmd(adapter) == -1) {
buf : 				ret = -1;
buf : 				break;
buf : 			}
buf : 		}
buf : 
buf : 		if ((!adapter->scan_processing || adapter->scan_delay_cnt) &&
if ((!adapter->scan_processing || adapter->scan_delay_cnt) && 
buf : 		    !adapter->data_sent && !mwifiex_wmm_lists_empty(adapter)) {
buf : 			mwifiex_wmm_process_tx(adapter);
ifiex_wmm_process_tx(adapter); 
buf : 			if (adapter->hs_activated) {
buf : 				adapter->is_hs_configured = false;
buf : 				mwifiex_hs_activated_event
ifiex_hs_activated_event 
buf : 					(mwifiex_get_priv
buf : 					 (adapter, MWIFIEX_BSS_ROLE_ANY),
buf : 					 false);
buf : 			}
buf : 		}
buf : 
buf : 		if (adapter->delay_null_pkt && !adapter->cmd_sent &&
if (adapter->delay_null_pkt && !adapter->cmd_sent && 
buf : 		    !adapter->curr_cmd && !is_command_pending(adapter) &&
buf : 		    mwifiex_wmm_lists_empty(adapter)) {
ifiex_wmm_lists_empty(adapter)) { 
buf : 			if (!mwifiex_send_null_packet
buf : 			    (mwifiex_get_priv(adapter, MWIFIEX_BSS_ROLE_STA),
ifiex_get_priv(adapter, MWIFIEX_BSS_ROLE_STA), 
buf : 			     MWIFIEX_TxPD_POWER_MGMT_NULL_PACKET |
buf : 			     MWIFIEX_TxPD_POWER_MGMT_LAST_PACKET)) {
buf : 				adapter->delay_null_pkt = false;
buf : 				adapter->ps_state = PS_STATE_SLEEP;
buf : 			}
buf : 			break;
buf : 		}
buf : 	} while (true);
while (true); 
buf : 
buf : 	spin_lock_irqsave(&adapter->main_proc_lock, flags);
buf : 	if ((adapter->int_status) || IS_CARD_RX_RCVD(adapter)) {
if ((adapter->int_status) || IS_CARD_RX_RCVD(adapter)) { 
buf : 		spin_unlock_irqrestore(&adapter->main_proc_lock, flags);
buf : 		goto process_start;
buf : 	}
buf : 
buf : 	adapter->mwifiex_processing = false;
ifiex_processing = false; 
buf : 	spin_unlock_irqrestore(&adapter->main_proc_lock, flags);
buf : 
buf : exit_main_proc:
buf : 	if (adapter->hw_status == MWIFIEX_HW_STATUS_CLOSING)
if (adapter->hw_status == MWIFIEX_HW_STATUS_CLOSING) 
buf : 		mwifiex_shutdown_drv(adapter);
buf : 	return ret;
buf : }
buf : EXPORT_SYMBOL_GPL(mwifiex_main_process);
ifiex_main_process); 
buf : 
buf : /*
buf :  * This function frees the adapter structure.
buf :  *
buf :  * Additionally, this closes the netlink socket, frees the timers
buf :  * and private structures.
buf :  */
buf : static void mwifiex_free_adapter(struct mwifiex_adapter *adapter)
ifiex_free_adapter(struct mwifiex_adapter *adapter) 
buf : {
buf : 	if (!adapter) {
buf : 		pr_err("%s: adapter is NULL\n", __func__);
buf : 		return;
buf : 	}
buf : 
buf : 	mwifiex_unregister(adapter);
ifiex_unregister(adapter); 
buf : 	pr_debug("info: %s: free adapter\n", __func__);
buf : }
buf : 
buf : /*
buf :  * This function cancels all works in the queue and destroys
buf :  * the main workqueue.
buf :  */
buf : static void mwifiex_terminate_workqueue(struct mwifiex_adapter *adapter)
ifiex_terminate_workqueue(struct mwifiex_adapter *adapter) 
buf : {
buf : 	flush_workqueue(adapter->workqueue);
buf : 	destroy_workqueue(adapter->workqueue);
buf : 	adapter->workqueue = NULL;
buf : }
buf : 
buf : /*
buf :  * This function gets firmware and initializes it.
buf :  *
buf :  * The main initialization steps followed are -
buf :  *      - Download the correct firmware to card
buf :  *      - Issue the init commands to firmware
buf :  */
buf : static void mwifiex_fw_dpc(const struct firmware *firmware, void *context)
ifiex_fw_dpc(const struct firmware *firmware, void *context) 
buf : {
buf : 	int ret;
buf : 	char fmt[64];
buf : 	struct mwifiex_private *priv;
ifiex_private *priv; 
buf : 	struct mwifiex_adapter *adapter = context;
buf : 	struct mwifiex_fw_image fw;
ifiex_fw_image fw; 
buf : 	struct semaphore *sem = adapter->card_sem;
buf : 	bool init_failed = false;
buf : 	struct wireless_dev *wdev;
buf : 
buf : 	if (!firmware) {
if (!firmware) { 
buf : 		dev_err(adapter->dev,
buf : 			"Failed to get firmware %s\n", adapter->fw_name);
buf : 		goto err_dnld_fw;
buf : 	}
buf : 
buf : 	memset(&fw, 0, sizeof(struct mwifiex_fw_image));
ifiex_fw_image)); 
buf : 	adapter->firmware = firmware;
buf : 	fw.fw_buf = (u8 *) adapter->firmware->data;
buf : 	fw.fw_len = adapter->firmware->size;
buf : 
buf : 	if (adapter->if_ops.dnld_fw)
if (adapter->if_ops.dnld_fw) 
buf : 		ret = adapter->if_ops.dnld_fw(adapter, &fw);
buf : 	else
buf : 		ret = mwifiex_dnld_fw(adapter, &fw);
ifiex_dnld_fw(adapter, &fw); 
buf : 	if (ret == -1)
buf : 		goto err_dnld_fw;
buf : 
buf : 	dev_notice(adapter->dev, "WLAN FW is active\n");
buf : 
buf : 	if (cal_data_cfg) {
if (cal_data_cfg) { 
buf : 		if ((request_firmware(&adapter->cal_data, cal_data_cfg,
buf : 				      adapter->dev)) < 0)
buf : 			dev_err(adapter->dev,
buf : 				"Cal data request_firmware() failed\n");
buf : 	}
buf : 
buf : 	/* enable host interrupt after fw dnld is successful */
buf : 	if (adapter->if_ops.enable_int) {
if (adapter->if_ops.enable_int) { 
buf : 		if (adapter->if_ops.enable_int(adapter))
buf : 			goto err_dnld_fw;
buf : 	}
buf : 
buf : 	adapter->init_wait_q_woken = false;
buf : 	ret = mwifiex_init_fw(adapter);
ifiex_init_fw(adapter); 
buf : 	if (ret == -1) {
buf : 		goto err_init_fw;
buf : 	} else if (!ret) {
if (!ret) { 
buf : 		adapter->hw_status = MWIFIEX_HW_STATUS_READY;
buf : 		goto done;
buf : 	}
buf : 	/* Wait for mwifiex_init to complete */
ifiex_init to complete */ 
buf : 	wait_event_interruptible(adapter->init_wait_q,
buf : 				 adapter->init_wait_q_woken);
buf : 	if (adapter->hw_status != MWIFIEX_HW_STATUS_READY)
if (adapter->hw_status != MWIFIEX_HW_STATUS_READY) 
buf : 		goto err_init_fw;
buf : 
buf : 	priv = adapter->priv[MWIFIEX_BSS_ROLE_STA];
buf : 	if (mwifiex_register_cfg80211(adapter)) {
if (mwifiex_register_cfg80211(adapter)) { 
buf : 		dev_err(adapter->dev, "cannot register with cfg80211\n");
buf : 		goto err_init_fw;
buf : 	}
buf : 
buf : 	rtnl_lock();
buf : 	/* Create station interface by default */
buf : 	wdev = mwifiex_add_virtual_intf(adapter->wiphy, "mlan%d",
ifiex_add_virtual_intf(adapter->wiphy, "mlan%d", 
buf : 					NL80211_IFTYPE_STATION, NULL, NULL);
buf : 	if (IS_ERR(wdev)) {
if (IS_ERR(wdev)) { 
buf : 		dev_err(adapter->dev, "cannot create default STA interface\n");
buf : 		rtnl_unlock();
buf : 		goto err_add_intf;
buf : 	}
buf : 	rtnl_unlock();
buf : 
buf : 	mwifiex_drv_get_driver_version(adapter, fmt, sizeof(fmt) - 1);
ifiex_drv_get_driver_version(adapter, fmt, sizeof(fmt) - 1); 
buf : 	dev_notice(adapter->dev, "driver_version = %s\n", fmt);
buf : 	goto done;
buf : 
buf : err_add_intf:
buf : 	wiphy_unregister(adapter->wiphy);
buf : 	wiphy_free(adapter->wiphy);
buf : err_init_fw:
buf : 	if (adapter->if_ops.disable_int)
if (adapter->if_ops.disable_int) 
buf : 		adapter->if_ops.disable_int(adapter);
buf : err_dnld_fw:
buf : 	pr_debug("info: %s: unregister device\n", __func__);
buf : 	if (adapter->if_ops.unregister_dev)
if (adapter->if_ops.unregister_dev) 
buf : 		adapter->if_ops.unregister_dev(adapter);
buf : 
buf : 	if ((adapter->hw_status == MWIFIEX_HW_STATUS_FW_READY) ||
if ((adapter->hw_status == MWIFIEX_HW_STATUS_FW_READY) || 
buf : 	    (adapter->hw_status == MWIFIEX_HW_STATUS_READY)) {
buf : 		pr_debug("info: %s: shutdown mwifiex\n", __func__);
ifiex\n", __func__); 
buf : 		adapter->init_wait_q_woken = false;
buf : 
buf : 		if (mwifiex_shutdown_drv(adapter) == -EINPROGRESS)
if (mwifiex_shutdown_drv(adapter) == -EINPROGRESS) 
buf : 			wait_event_interruptible(adapter->init_wait_q,
buf : 						 adapter->init_wait_q_woken);
buf : 	}
buf : 	adapter->surprise_removed = true;
buf : 	mwifiex_terminate_workqueue(adapter);
ifiex_terminate_workqueue(adapter); 
buf : 	init_failed = true;
buf : done:
buf : 	if (adapter->cal_data) {
if (adapter->cal_data) { 
buf : 		release_firmware(adapter->cal_data);
buf : 		adapter->cal_data = NULL;
buf : 	}
buf : 	if (adapter->firmware) {
if (adapter->firmware) { 
buf : 		release_firmware(adapter->firmware);
buf : 		adapter->firmware = NULL;
buf : 	}
buf : 	if (init_failed)
if (init_failed) 
buf : 		mwifiex_free_adapter(adapter);
buf : 	up(sem);
buf : 	return;
buf : }
buf : 
buf : /*
buf :  * This function initializes the hardware and gets firmware.
buf :  */
buf : static int mwifiex_init_hw_fw(struct mwifiex_adapter *adapter)
ifiex_init_hw_fw(struct mwifiex_adapter *adapter) 
buf : {
buf : 	int ret;
buf : 
buf : 	ret = request_firmware_nowait(THIS_MODULE, 1, adapter->fw_name,
buf : 				      adapter->dev, GFP_KERNEL, adapter,
buf : 				      mwifiex_fw_dpc);
ifiex_fw_dpc); 
buf : 	if (ret < 0)
buf : 		dev_err(adapter->dev,
buf : 			"request_firmware_nowait() returned error %d\n", ret);
buf : 	return ret;
buf : }
buf : 
buf : /*
buf :  * CFG802.11 network device handler for open.
for open. 
buf :  *
buf :  * Starts the data queue.
buf :  */
buf : static int
buf : mwifiex_open(struct net_device *dev)
ifiex_open(struct net_device *dev) 
buf : {
buf : 	netif_tx_start_all_queues(dev);
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * CFG802.11 network device handler for close.
for close. 
buf :  */
buf : static int
buf : mwifiex_close(struct net_device *dev)
ifiex_close(struct net_device *dev) 
buf : {
buf : 	struct mwifiex_private *priv = mwifiex_netdev_get_priv(dev);
buf : 
buf : 	if (priv->scan_request) {
if (priv->scan_request) { 
buf : 		dev_dbg(priv->adapter->dev, "aborting scan on ndo_stop\n");
buf : 		cfg80211_scan_done(priv->scan_request, 1);
buf : 		priv->scan_request = NULL;
buf : 		priv->scan_aborting = true;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * Add buffer into wmm tx queue and queue work to transmit it.
buf :  */
buf : int mwifiex_queue_tx_pkt(struct mwifiex_private *priv, struct sk_buff *skb)
ifiex_queue_tx_pkt(struct mwifiex_private *priv, struct sk_buff *skb) 
buf : {
buf : 	struct netdev_queue *txq;
buf : 	int index = mwifiex_1d_to_wmm_queue[skb->priority];
ifiex_1d_to_wmm_queue[skb->priority]; 
buf : 
buf : 	if (atomic_inc_return(&priv->wmm_tx_pending[index]) >= MAX_TX_PENDING) {
buf : 		txq = netdev_get_tx_queue(priv->netdev, index);
buf : 		if (!netif_tx_queue_stopped(txq)) {
if (!netif_tx_queue_stopped(txq)) { 
buf : 			netif_tx_stop_queue(txq);
buf : 			dev_dbg(priv->adapter->dev, "stop queue: %d\n", index);
buf : 		}
buf : 	}
buf : 
buf : 	atomic_inc(&priv->adapter->tx_pending);
buf : 	mwifiex_wmm_add_buf_txqueue(priv, skb);
ifiex_wmm_add_buf_txqueue(priv, skb); 
buf : 
buf : 	if (priv->adapter->scan_delay_cnt)
buf : 		atomic_set(&priv->adapter->is_tx_received, true);
buf : 
buf : 	queue_work(priv->adapter->workqueue, &priv->adapter->main_work);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * CFG802.11 network device handler for data transmission.
for data transmission. 
buf :  */
buf : static int
buf : mwifiex_hard_start_xmit(struct sk_buff *skb, struct net_device *dev)
ifiex_hard_start_xmit(struct sk_buff *skb, struct net_device *dev) 
buf : {
buf : 	struct mwifiex_private *priv = mwifiex_netdev_get_priv(dev);
buf : 	struct sk_buff *new_skb;
buf : 	struct mwifiex_txinfo *tx_info;
ifiex_txinfo *tx_info; 
buf : 	struct timeval tv;
buf : 
buf : 	dev_dbg(priv->adapter->dev, "data: %lu BSS(%d-%d): Data <= kernel\n",
buf : 		jiffies, priv->bss_type, priv->bss_num);
iffies, priv->bss_type, priv->bss_num); 
buf : 
buf : 	if (priv->adapter->surprise_removed) {
buf : 		kfree_skb(skb);
buf : 		priv->stats.tx_dropped++;
buf : 		return 0;
buf : 	}
buf : 	if (!skb->len || (skb->len > ETH_FRAME_LEN)) {
if (!skb->len || (skb->len > ETH_FRAME_LEN)) { 
buf : 		dev_err(priv->adapter->dev, "Tx: bad skb len %d\n", skb->len);
buf : 		kfree_skb(skb);
buf : 		priv->stats.tx_dropped++;
buf : 		return 0;
buf : 	}
buf : 	if (skb_headroom(skb) < MWIFIEX_MIN_DATA_HEADER_LEN) {
if (skb_headroom(skb) < MWIFIEX_MIN_DATA_HEADER_LEN) { 
buf : 		dev_dbg(priv->adapter->dev,
buf : 			"data: Tx: insufficient skb headroom %d\n",
buf : 			skb_headroom(skb));
buf : 		/* Insufficient skb headroom - allocate a new skb */
buf : 		new_skb =
buf : 			skb_realloc_headroom(skb, MWIFIEX_MIN_DATA_HEADER_LEN);
buf : 		if (unlikely(!new_skb)) {
if (unlikely(!new_skb)) { 
buf : 			dev_err(priv->adapter->dev, "Tx: cannot alloca new_skb\n");
buf : 			kfree_skb(skb);
buf : 			priv->stats.tx_dropped++;
buf : 			return 0;
buf : 		}
buf : 		kfree_skb(skb);
buf : 		skb = new_skb;
buf : 		dev_dbg(priv->adapter->dev, "info: new skb headroomd %d\n",
buf : 			skb_headroom(skb));
buf : 	}
buf : 
buf : 	tx_info = MWIFIEX_SKB_TXCB(skb);
buf : 	tx_info->bss_num = priv->bss_num;
buf : 	tx_info->bss_type = priv->bss_type;
buf : 	tx_info->pkt_len = skb->len;
buf : 
buf : 	/* Record the current time the packet was queued; used to
buf : 	 * determine the amount of time the packet was queued in
buf : 	 * the driver before it was sent to the firmware.
fore it was sent to the firmware. 
buf : 	 * The delay is then sent along with the packet to the
buf : 	 * firmware for aggregate delay calculation for stats and
for aggregate delay calculation for stats and 
buf : 	 * MSDU lifetime expiry.
buf : 	 */
buf : 	do_gettimeofday(&tv);
buf : 	skb->tstamp = timeval_to_ktime(tv);
buf : 
buf : 	mwifiex_queue_tx_pkt(priv, skb);
ifiex_queue_tx_pkt(priv, skb); 
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * CFG802.11 network device handler for setting MAC address.
for setting MAC address. 
buf :  */
buf : static int
buf : mwifiex_set_mac_address(struct net_device *dev, void *addr)
ifiex_set_mac_address(struct net_device *dev, void *addr) 
buf : {
buf : 	struct mwifiex_private *priv = mwifiex_netdev_get_priv(dev);
buf : 	struct sockaddr *hw_addr = addr;
buf : 	int ret;
buf : 
buf : 	memcpy(priv->curr_addr, hw_addr->sa_data, ETH_ALEN);
buf : 
buf : 	/* Send request to firmware */
buf : 	ret = mwifiex_send_cmd(priv, HostCmd_CMD_802_11_MAC_ADDRESS,
ifiex_send_cmd(priv, HostCmd_CMD_802_11_MAC_ADDRESS, 
buf : 			       HostCmd_ACT_GEN_SET, 0, NULL, true);
buf : 
buf : 	if (!ret)
if (!ret) 
buf : 		memcpy(priv->netdev->dev_addr, priv->curr_addr, ETH_ALEN);
buf : 	else
buf : 		dev_err(priv->adapter->dev,
buf : 			"set mac address failed: ret=%d\n", ret);
buf : 
buf : 	memcpy(dev->dev_addr, priv->curr_addr, ETH_ALEN);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : /*
buf :  * CFG802.11 network device handler for setting multicast list.
for setting multicast list. 
buf :  */
buf : static void mwifiex_set_multicast_list(struct net_device *dev)
ifiex_set_multicast_list(struct net_device *dev) 
buf : {
buf : 	struct mwifiex_private *priv = mwifiex_netdev_get_priv(dev);
buf : 	struct mwifiex_multicast_list mcast_list;
ifiex_multicast_list mcast_list; 
buf : 
buf : 	if (dev->flags & IFF_PROMISC) {
buf : 		mcast_list.mode = MWIFIEX_PROMISC_MODE;
buf : 	} else if (dev->flags & IFF_ALLMULTI ||
if (dev->flags & IFF_ALLMULTI || 
buf : 		   netdev_mc_count(dev) > MWIFIEX_MAX_MULTICAST_LIST_SIZE) {
buf : 		mcast_list.mode = MWIFIEX_ALL_MULTI_MODE;
buf : 	} else {
buf : 		mcast_list.mode = MWIFIEX_MULTICAST_MODE;
buf : 		mcast_list.num_multicast_addr =
buf : 			mwifiex_copy_mcast_addr(&mcast_list, dev);
ifiex_copy_mcast_addr(&mcast_list, dev); 
buf : 	}
buf : 	mwifiex_request_set_multicast_list(priv, &mcast_list);
buf : }
buf : 
buf : /*
buf :  * CFG802.11 network device handler for transmission timeout.
for transmission timeout. 
buf :  */
buf : static void
buf : mwifiex_tx_timeout(struct net_device *dev)
ifiex_tx_timeout(struct net_device *dev) 
buf : {
buf : 	struct mwifiex_private *priv = mwifiex_netdev_get_priv(dev);
buf : 
buf : 	priv->num_tx_timeout++;
buf : 	priv->tx_timeout_cnt++;
buf : 	dev_err(priv->adapter->dev,
buf : 		"%lu : Tx timeout(#%d), bss_type-num = %d-%d\n",
buf : 		jiffies, priv->tx_timeout_cnt, priv->bss_type, priv->bss_num);
iffies, priv->tx_timeout_cnt, priv->bss_type, priv->bss_num); 
buf : 	mwifiex_set_trans_start(dev);
buf : 
buf : 	if (priv->tx_timeout_cnt > TX_TIMEOUT_THRESHOLD &&
if (priv->tx_timeout_cnt > TX_TIMEOUT_THRESHOLD && 
buf : 	    priv->adapter->if_ops.card_reset) {
buf : 		dev_err(priv->adapter->dev,
buf : 			"tx_timeout_cnt exceeds threshold. Triggering card reset!\n");
buf : 		priv->adapter->if_ops.card_reset(priv->adapter);
if_ops.card_reset(priv->adapter); 
buf : 	}
buf : }
buf : 
buf : /*
buf :  * CFG802.11 network device handler for statistics retrieval.
for statistics retrieval. 
buf :  */
buf : static struct net_device_stats *mwifiex_get_stats(struct net_device *dev)
ifiex_get_stats(struct net_device *dev) 
buf : {
buf : 	struct mwifiex_private *priv = mwifiex_netdev_get_priv(dev);
buf : 
buf : 	return &priv->stats;
buf : }
buf : 
buf : static u16
buf : mwifiex_netdev_select_wmm_queue(struct net_device *dev, struct sk_buff *skb,
ifiex_netdev_select_wmm_queue(struct net_device *dev, struct sk_buff *skb, 
buf : 				void *accel_priv, select_queue_fallback_t fallback)
buf : {
buf : 	skb->priority = cfg80211_classify8021d(skb, NULL);
ify8021d(skb, NULL); 
buf : 	return mwifiex_1d_to_wmm_queue[skb->priority];
buf : }
buf : 
buf : /* Network device handlers */
buf : static const struct net_device_ops mwifiex_netdev_ops = {
ifiex_netdev_ops = { 
buf : 	.ndo_open = mwifiex_open,
buf : 	.ndo_stop = mwifiex_close,
ifiex_close, 
buf : 	.ndo_start_xmit = mwifiex_hard_start_xmit,
buf : 	.ndo_set_mac_address = mwifiex_set_mac_address,
ifiex_set_mac_address, 
buf : 	.ndo_tx_timeout = mwifiex_tx_timeout,
buf : 	.ndo_get_stats = mwifiex_get_stats,
ifiex_get_stats, 
buf : 	.ndo_set_rx_mode = mwifiex_set_multicast_list,
buf : 	.ndo_select_queue = mwifiex_netdev_select_wmm_queue,
ifiex_netdev_select_wmm_queue, 
buf : };
buf : 
buf : /*
buf :  * This function initializes the private structure parameters.
buf :  *
buf :  * The following wait queues are initialized -
buf :  *      - IOCTL wait queue
buf :  *      - Command wait queue
buf :  *      - Statistics wait queue
buf :  *
buf :  * ...and the following default parameters are set -
buf :  *      - Current key index     : Set to 0
buf :  *      - Rate index            : Set to auto
buf :  *      - Media connected       : Set to disconnected
buf :  *      - Adhoc link sensed     : Set to false
buf :  *      - Nick name             : Set to null
buf :  *      - Number of Tx timeout  : Set to 0
buf :  *      - Device address        : Set to current address
buf :  *
buf :  * In addition, the CFG80211 work queue is also created.
buf :  */
buf : void mwifiex_init_priv_params(struct mwifiex_private *priv,
ifiex_init_priv_params(struct mwifiex_private *priv, 
buf : 						struct net_device *dev)
buf : {
buf : 	dev->netdev_ops = &mwifiex_netdev_ops;
ifiex_netdev_ops; 
buf : 	dev->destructor = free_netdev;
buf : 	/* Initialize private structure */
buf : 	priv->current_key_index = 0;
buf : 	priv->media_connected = false;
buf : 	memset(&priv->nick_name, 0, sizeof(priv->nick_name));
buf : 	memset(priv->mgmt_ie, 0,
buf : 	       sizeof(struct mwifiex_ie) * MAX_MGMT_IE_INDEX);
ifiex_ie) * MAX_MGMT_IE_INDEX); 
buf : 	priv->beacon_idx = MWIFIEX_AUTO_IDX_MASK;
buf : 	priv->proberesp_idx = MWIFIEX_AUTO_IDX_MASK;
buf : 	priv->assocresp_idx = MWIFIEX_AUTO_IDX_MASK;
buf : 	priv->rsn_idx = MWIFIEX_AUTO_IDX_MASK;
buf : 	priv->num_tx_timeout = 0;
buf : 	memcpy(dev->dev_addr, priv->curr_addr, ETH_ALEN);
buf : }
buf : 
buf : /*
buf :  * This function check if command is pending.
if command is pending. 
buf :  */
buf : int is_command_pending(struct mwifiex_adapter *adapter)
ifiex_adapter *adapter) 
buf : {
buf : 	unsigned long flags;
buf : 	int is_cmd_pend_q_empty;
buf : 
buf : 	spin_lock_irqsave(&adapter->cmd_pending_q_lock, flags);
buf : 	is_cmd_pend_q_empty = list_empty(&adapter->cmd_pending_q);
buf : 	spin_unlock_irqrestore(&adapter->cmd_pending_q_lock, flags);
buf : 
buf : 	return !is_cmd_pend_q_empty;
buf : }
buf : 
buf : /*
buf :  * This is the main work queue function.
buf :  *
buf :  * It handles the main process, which in turn handles the complete
buf :  * driver operations.
buf :  */
buf : static void mwifiex_main_work_queue(struct work_struct *work)
ifiex_main_work_queue(struct work_struct *work) 
buf : {
buf : 	struct mwifiex_adapter *adapter =
buf : 		container_of(work, struct mwifiex_adapter, main_work);
ifiex_adapter, main_work); 
buf : 
buf : 	if (adapter->surprise_removed)
buf : 		return;
buf : 	mwifiex_main_process(adapter);
ifiex_main_process(adapter); 
buf : }
buf : 
buf : /*
buf :  * This function adds the card.
buf :  *
buf :  * This function follows the following major steps to set up the device -
buf :  *      - Initialize software. This includes probing the card, registering
buf :  *        the interface operations table, and allocating/initializing the
buf :  *        adapter structure
buf :  *      - Set up the netlink socket
buf :  *      - Create and start the main work queue
buf :  *      - Register the device
buf :  *      - Initialize firmware and hardware
buf :  *      - Add logical interfaces
buf :  */
buf : int
buf : mwifiex_add_card(void *card, struct semaphore *sem,
ifiex_add_card(void *card, struct semaphore *sem, 
buf : 		 struct mwifiex_if_ops *if_ops, u8 iface_type)
buf : {
buf : 	struct mwifiex_adapter *adapter;
ifiex_adapter *adapter; 
buf : 
buf : 	if (down_interruptible(sem))
buf : 		goto exit_sem_err;
buf : 
buf : 	if (mwifiex_register(card, if_ops, (void **)&adapter)) {
if (mwifiex_register(card, if_ops, (void **)&adapter)) { 
buf : 		pr_err("%s: software init failed\n", __func__);
buf : 		goto err_init_sw;
buf : 	}
buf : 
buf : 	adapter->iface_type = iface_type;
iface_type = iface_type; 
buf : 	adapter->card_sem = sem;
buf : 
buf : 	adapter->hw_status = MWIFIEX_HW_STATUS_INITIALIZING;
buf : 	adapter->surprise_removed = false;
buf : 	init_waitqueue_head(&adapter->init_wait_q);
buf : 	adapter->is_suspended = false;
buf : 	adapter->hs_activated = false;
buf : 	init_waitqueue_head(&adapter->hs_activate_wait_q);
buf : 	init_waitqueue_head(&adapter->cmd_wait_q.wait);
buf : 	adapter->cmd_wait_q.status = 0;
buf : 	adapter->scan_wait_q_woken = false;
buf : 
buf : 	adapter->workqueue =
buf : 		alloc_workqueue("MWIFIEX_WORK_QUEUE",
buf : 				WQ_HIGHPRI | WQ_MEM_RECLAIM | WQ_UNBOUND, 1);
buf : 	if (!adapter->workqueue)
if (!adapter->workqueue) 
buf : 		goto err_kmalloc;
buf : 
buf : 	INIT_WORK(&adapter->main_work, mwifiex_main_work_queue);
ifiex_main_work_queue); 
buf : 
buf : 	/* Register the device. Fill up the private data structure with relevant
buf : 	   information from the card. */
formation from the card. */ 
buf : 	if (adapter->if_ops.register_dev(adapter)) {
buf : 		pr_err("%s: failed to register mwifiex device\n", __func__);
ifiex device\n", __func__); 
buf : 		goto err_registerdev;
buf : 	}
buf : 
buf : 	if (mwifiex_init_hw_fw(adapter)) {
if (mwifiex_init_hw_fw(adapter)) { 
buf : 		pr_err("%s: firmware init failed\n", __func__);
buf : 		goto err_init_fw;
buf : 	}
buf : 
buf : 	return 0;
buf : 
buf : err_init_fw:
buf : 	pr_debug("info: %s: unregister device\n", __func__);
buf : 	if (adapter->if_ops.unregister_dev)
if (adapter->if_ops.unregister_dev) 
buf : 		adapter->if_ops.unregister_dev(adapter);
buf : 	if ((adapter->hw_status == MWIFIEX_HW_STATUS_FW_READY) ||
if ((adapter->hw_status == MWIFIEX_HW_STATUS_FW_READY) || 
buf : 	    (adapter->hw_status == MWIFIEX_HW_STATUS_READY)) {
buf : 		pr_debug("info: %s: shutdown mwifiex\n", __func__);
ifiex\n", __func__); 
buf : 		adapter->init_wait_q_woken = false;
buf : 
buf : 		if (mwifiex_shutdown_drv(adapter) == -EINPROGRESS)
if (mwifiex_shutdown_drv(adapter) == -EINPROGRESS) 
buf : 			wait_event_interruptible(adapter->init_wait_q,
buf : 						 adapter->init_wait_q_woken);
buf : 	}
buf : err_registerdev:
buf : 	adapter->surprise_removed = true;
buf : 	mwifiex_terminate_workqueue(adapter);
ifiex_terminate_workqueue(adapter); 
buf : err_kmalloc:
buf : 	mwifiex_free_adapter(adapter);
ifiex_free_adapter(adapter); 
buf : 
buf : err_init_sw:
buf : 	up(sem);
buf : 
buf : exit_sem_err:
buf : 	return -1;
buf : }
buf : EXPORT_SYMBOL_GPL(mwifiex_add_card);
ifiex_add_card); 
buf : 
buf : /*
buf :  * This function removes the card.
buf :  *
buf :  * This function follows the following major steps to remove the device -
buf :  *      - Stop data traffic
buf :  *      - Shutdown firmware
buf :  *      - Remove the logical interfaces
buf :  *      - Terminate the work queue
buf :  *      - Unregister the device
buf :  *      - Free the adapter structure
buf :  */
buf : int mwifiex_remove_card(struct mwifiex_adapter *adapter, struct semaphore *sem)
ifiex_remove_card(struct mwifiex_adapter *adapter, struct semaphore *sem) 
buf : {
buf : 	struct mwifiex_private *priv = NULL;
buf : 	int i;
buf : 
buf : 	if (down_interruptible(sem))
if (down_interruptible(sem)) 
buf : 		goto exit_sem_err;
buf : 
buf : 	if (!adapter)
if (!adapter) 
buf : 		goto exit_remove;
buf : 
buf : 	/* We can no longer handle interrupts once we start doing the teardown
buf : 	 * below. */
buf : 	if (adapter->if_ops.disable_int)
if (adapter->if_ops.disable_int) 
buf : 		adapter->if_ops.disable_int(adapter);
buf : 
buf : 	adapter->surprise_removed = true;
buf : 
buf : 	/* Stop data */
buf : 	for (i = 0; i < adapter->priv_num; i++) {
for (i = 0; i < adapter->priv_num; i++) { 
buf : 		priv = adapter->priv[i];
buf : 		if (priv && priv->netdev) {
if (priv && priv->netdev) { 
buf : 			mwifiex_stop_net_dev_queue(priv->netdev, adapter);
buf : 			if (netif_carrier_ok(priv->netdev))
if (netif_carrier_ok(priv->netdev)) 
buf : 				netif_carrier_off(priv->netdev);
buf : 		}
buf : 	}
buf : 
buf : 	dev_dbg(adapter->dev, "cmd: calling mwifiex_shutdown_drv...\n");
ifiex_shutdown_drv...\n"); 
buf : 	adapter->init_wait_q_woken = false;
buf : 
buf : 	if (mwifiex_shutdown_drv(adapter) == -EINPROGRESS)
if (mwifiex_shutdown_drv(adapter) == -EINPROGRESS) 
buf : 		wait_event_interruptible(adapter->init_wait_q,
buf : 					 adapter->init_wait_q_woken);
buf : 	dev_dbg(adapter->dev, "cmd: mwifiex_shutdown_drv done\n");
ifiex_shutdown_drv done\n"); 
buf : 	if (atomic_read(&adapter->rx_pending) ||
buf : 	    atomic_read(&adapter->tx_pending) ||
buf : 	    atomic_read(&adapter->cmd_pending)) {
buf : 		dev_err(adapter->dev, "rx_pending=%d, tx_pending=%d, "
buf : 		       "cmd_pending=%d\n",
buf : 		       atomic_read(&adapter->rx_pending),
buf : 		       atomic_read(&adapter->tx_pending),
buf : 		       atomic_read(&adapter->cmd_pending));
buf : 	}
buf : 
buf : 	for (i = 0; i < adapter->priv_num; i++) {
for (i = 0; i < adapter->priv_num; i++) { 
buf : 		priv = adapter->priv[i];
buf : 
buf : 		if (!priv)
if (!priv) 
buf : 			continue;
buf : 
buf : 		rtnl_lock();
buf : 		if (priv->wdev && priv->netdev)
if (priv->wdev && priv->netdev) 
buf : 			mwifiex_del_virtual_intf(adapter->wiphy, priv->wdev);
buf : 		rtnl_unlock();
buf : 	}
buf : 
buf : 	wiphy_unregister(adapter->wiphy);
buf : 	wiphy_free(adapter->wiphy);
buf : 
buf : 	mwifiex_terminate_workqueue(adapter);
ifiex_terminate_workqueue(adapter); 
buf : 
buf : 	/* Unregister device */
buf : 	dev_dbg(adapter->dev, "info: unregister device\n");
buf : 	if (adapter->if_ops.unregister_dev)
if (adapter->if_ops.unregister_dev) 
buf : 		adapter->if_ops.unregister_dev(adapter);
buf : 	/* Free adapter structure */
buf : 	dev_dbg(adapter->dev, "info: free adapter\n");
buf : 	mwifiex_free_adapter(adapter);
ifiex_free_adapter(adapter); 
buf : 
buf : exit_remove:
buf : 	up(sem);
buf : exit_sem_err:
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL_GPL(mwifiex_remove_card);
ifiex_remove_card); 
buf : 
buf : /*
buf :  * This function initializes the module.
buf :  *
buf :  * The debug FS is also initialized if configured.
if configured. 
buf :  */
buf : static int
buf : mwifiex_init_module(void)
ifiex_init_module(void) 
buf : {
buf : #ifdef CONFIG_DEBUG_FS
buf : 	mwifiex_debugfs_init();
ifiex_debugfs_init(); 
buf : #endif
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * This function cleans up the module.
buf :  *
buf :  * The debug FS is removed if available.
if available. 
buf :  */
buf : static void
buf : mwifiex_cleanup_module(void)
ifiex_cleanup_module(void) 
buf : {
buf : #ifdef CONFIG_DEBUG_FS
buf : 	mwifiex_debugfs_remove();
ifiex_debugfs_remove(); 
buf : #endif
buf : }
buf : 
buf : module_init(mwifiex_init_module);
ifiex_init_module); 
buf : module_exit(mwifiex_cleanup_module);
buf : 
buf : MODULE_AUTHOR("Marvell International Ltd.");
buf : MODULE_DESCRIPTION("Marvell WiFi-Ex Driver version " VERSION);
buf : MODULE_VERSION(VERSION);
buf : MODULE_LICENSE("GPL v2");
file : ./test/kernel/drivers/net/wireless/iwlwifi/dvm/main.c 
[ OK ] open : 4 ok... 
buf : /******************************************************************************
buf :  *
buf :  * Copyright(c) 2003 - 2014 Intel Corporation. All rights reserved.
buf :  *
buf :  * Portions of this file are derived from the ipw3945 project, as well
buf :  * as portions of the ieee80211 subsystem header files.
buf :  *
buf :  * This program is free software; you can redistribute it and/or modify it
ify it 
buf :  * under the terms of version 2 of the GNU General Public License as
buf :  * published by the Free Software Foundation.
buf :  *
buf :  * This program is distributed in the hope that it will be useful, but WITHOUT
buf :  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
buf :  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
for 
buf :  * more details.
buf :  *
buf :  * You should have received a copy of the GNU General Public License along with
buf :  * this program; if not, write to the Free Software Foundation, Inc.,
if not, write to the Free Software Foundation, Inc., 
buf :  * 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
buf :  *
buf :  * The full GNU General Public License is included in this distribution in the
buf :  * file called LICENSE.
buf :  *
buf :  * Contact Information:
formation: 
buf :  *  Intel Linux Wireless <ilw@linux.intel.com>
buf :  * Intel Corporation, 5200 N.E. Elam Young Parkway, Hillsboro, OR 97124-6497
buf :  *
buf :  *****************************************************************************/
buf : 
buf : #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
buf : 
buf : #include <linux/kernel.h>
buf : #include <linux/module.h>
buf : #include <linux/init.h>
buf : #include <linux/slab.h>
buf : #include <linux/delay.h>
buf : #include <linux/sched.h>
buf : #include <linux/skbuff.h>
buf : #include <linux/netdevice.h>
buf : #include <linux/etherdevice.h>
buf : #include <linux/if_arp.h>
if_arp.h> 
buf : 
buf : #include <net/mac80211.h>
buf : 
buf : #include <asm/div64.h>
buf : 
buf : #include "iwl-eeprom-read.h"
buf : #include "iwl-eeprom-parse.h"
buf : #include "iwl-io.h"
buf : #include "iwl-trans.h"
buf : #include "iwl-op-mode.h"
buf : #include "iwl-drv.h"
buf : #include "iwl-modparams.h"
buf : #include "iwl-prph.h"
buf : 
buf : #include "dev.h"
buf : #include "calib.h"
buf : #include "agn.h"
buf : 
buf : 
buf : /******************************************************************************
buf :  *
buf :  * module boiler plate
buf :  *
buf :  ******************************************************************************/
buf : 
buf : /*
buf :  * module name, copyright, version, etc.
buf :  */
buf : #define DRV_DESCRIPTION	"Intel(R) Wireless WiFi Link AGN driver for Linux"
for Linux" 
buf : 
buf : #ifdef CONFIG_IWLWIFI_DEBUG
buf : #define VD "d"
buf : #else
buf : #define VD
buf : #endif
if 
buf : 
buf : #define DRV_VERSION     IWLWIFI_VERSION VD
buf : 
buf : 
buf : MODULE_DESCRIPTION(DRV_DESCRIPTION);
buf : MODULE_VERSION(DRV_VERSION);
buf : MODULE_AUTHOR(DRV_COPYRIGHT " " DRV_AUTHOR);
buf : MODULE_LICENSE("GPL");
buf : 
buf : static const struct iwl_op_mode_ops iwl_dvm_ops;
buf : 
buf : void iwl_update_chain_flags(struct iwl_priv *priv)
buf : {
buf : 	struct iwl_rxon_context *ctx;
buf : 
buf : 	for_each_context(priv, ctx) {
for_each_context(priv, ctx) { 
buf : 		iwlagn_set_rxon_chain(priv, ctx);
buf : 		if (ctx->active.rx_chain != ctx->staging.rx_chain)
if (ctx->active.rx_chain != ctx->staging.rx_chain) 
buf : 			iwlagn_commit_rxon(priv, ctx);
buf : 	}
buf : }
buf : 
buf : /* Parse the beacon frame to find the TIM element and set tim_idx & tim_size */
buf : static void iwl_set_beacon_tim(struct iwl_priv *priv,
buf : 			       struct iwl_tx_beacon_cmd *tx_beacon_cmd,
buf : 			       u8 *beacon, u32 frame_size)
buf : {
buf : 	u16 tim_idx;
buf : 	struct ieee80211_mgmt *mgmt = (struct ieee80211_mgmt *)beacon;
buf : 
buf : 	/*
buf : 	 * The index is relative to frame start but we start looking at the
buf : 	 * variable-length part of the beacon.
buf : 	 */
buf : 	tim_idx = mgmt->u.beacon.variable - beacon;
buf : 
buf : 	/* Parse variable-length elements of beacon to find WLAN_EID_TIM */
buf : 	while ((tim_idx < (frame_size - 2)) &&
while ((tim_idx < (frame_size - 2)) && 
buf : 			(beacon[tim_idx] != WLAN_EID_TIM))
buf : 		tim_idx += beacon[tim_idx+1] + 2;
buf : 
buf : 	/* If TIM field was found, set variables */
buf : 	if ((tim_idx < (frame_size - 1)) && (beacon[tim_idx] == WLAN_EID_TIM)) {
if ((tim_idx < (frame_size - 1)) && (beacon[tim_idx] == WLAN_EID_TIM)) { 
buf : 		tx_beacon_cmd->tim_idx = cpu_to_le16(tim_idx);
buf : 		tx_beacon_cmd->tim_size = beacon[tim_idx+1];
buf : 	} else
buf : 		IWL_WARN(priv, "Unable to find TIM Element in beacon\n");
buf : }
buf : 
buf : int iwlagn_send_beacon_cmd(struct iwl_priv *priv)
buf : {
buf : 	struct iwl_tx_beacon_cmd *tx_beacon_cmd;
buf : 	struct iwl_host_cmd cmd = {
buf : 		.id = REPLY_TX_BEACON,
buf : 	};
buf : 	struct ieee80211_tx_info *info;
buf : 	u32 frame_size;
buf : 	u32 rate_flags;
buf : 	u32 rate;
buf : 
buf : 	/*
buf : 	 * We have to set up the TX command, the TX Beacon command, and the
buf : 	 * beacon contents.
buf : 	 */
buf : 
buf : 	lockdep_assert_held(&priv->mutex);
buf : 
buf : 	if (!priv->beacon_ctx) {
if (!priv->beacon_ctx) { 
buf : 		IWL_ERR(priv, "trying to build beacon w/o beacon context!\n");
buf : 		return 0;
buf : 	}
buf : 
buf : 	if (WARN_ON(!priv->beacon_skb))
if (WARN_ON(!priv->beacon_skb)) 
buf : 		return -EINVAL;
buf : 
buf : 	/* Allocate beacon command */
buf : 	if (!priv->beacon_cmd)
if (!priv->beacon_cmd) 
buf : 		priv->beacon_cmd = kzalloc(sizeof(*tx_beacon_cmd), GFP_KERNEL);
buf : 	tx_beacon_cmd = priv->beacon_cmd;
buf : 	if (!tx_beacon_cmd)
if (!tx_beacon_cmd) 
buf : 		return -ENOMEM;
buf : 
buf : 	frame_size = priv->beacon_skb->len;
buf : 
buf : 	/* Set up TX command fields */
buf : 	tx_beacon_cmd->tx.len = cpu_to_le16((u16)frame_size);
buf : 	tx_beacon_cmd->tx.sta_id = priv->beacon_ctx->bcast_sta_id;
buf : 	tx_beacon_cmd->tx.stop_time.life_time = TX_CMD_LIFE_TIME_INFINITE;
ife_time = TX_CMD_LIFE_TIME_INFINITE; 
buf : 	tx_beacon_cmd->tx.tx_flags = TX_CMD_FLG_SEQ_CTL_MSK |
buf : 		TX_CMD_FLG_TSF_MSK | TX_CMD_FLG_STA_RATE_MSK;
buf : 
buf : 	/* Set up TX beacon command fields */
buf : 	iwl_set_beacon_tim(priv, tx_beacon_cmd, priv->beacon_skb->data,
buf : 			   frame_size);
buf : 
buf : 	/* Set up packet rate and flags */
buf : 	info = IEEE80211_SKB_CB(priv->beacon_skb);
buf : 
buf : 	/*
buf : 	 * Let's set up the rate at least somewhat correctly;
buf : 	 * it will currently not actually be used by the uCode,
buf : 	 * it uses the broadcast station's rate instead.
buf : 	 */
buf : 	if (info->control.rates[0].idx < 0 ||
if (info->control.rates[0].idx < 0 || 
buf : 	    info->control.rates[0].flags & IEEE80211_TX_RC_MCS)
buf : 		rate = 0;
buf : 	else
buf : 		rate = info->control.rates[0].idx;
buf : 
buf : 	priv->mgmt_tx_ant = iwl_toggle_tx_ant(priv, priv->mgmt_tx_ant,
buf : 					      priv->nvm_data->valid_tx_ant);
buf : 	rate_flags = iwl_ant_idx_to_flags(priv->mgmt_tx_ant);
buf : 
buf : 	/* In mac80211, rates for 5 GHz start at 0 */
for 5 GHz start at 0 */ 
buf : 	if (info->band == IEEE80211_BAND_5GHZ)
buf : 		rate += IWL_FIRST_OFDM_RATE;
buf : 	else if (rate >= IWL_FIRST_CCK_RATE && rate <= IWL_LAST_CCK_RATE)
if (rate >= IWL_FIRST_CCK_RATE && rate <= IWL_LAST_CCK_RATE) 
buf : 		rate_flags |= RATE_MCS_CCK_MSK;
buf : 
buf : 	tx_beacon_cmd->tx.rate_n_flags =
buf : 			iwl_hw_set_rate_n_flags(rate, rate_flags);
buf : 
buf : 	/* Submit command */
buf : 	cmd.len[0] = sizeof(*tx_beacon_cmd);
buf : 	cmd.data[0] = tx_beacon_cmd;
buf : 	cmd.dataflags[0] = IWL_HCMD_DFL_NOCOPY;
buf : 	cmd.len[1] = frame_size;
buf : 	cmd.data[1] = priv->beacon_skb->data;
buf : 	cmd.dataflags[1] = IWL_HCMD_DFL_NOCOPY;
buf : 
buf : 	return iwl_dvm_send_cmd(priv, &cmd);
buf : }
buf : 
buf : static void iwl_bg_beacon_update(struct work_struct *work)
buf : {
buf : 	struct iwl_priv *priv =
buf : 		container_of(work, struct iwl_priv, beacon_update);
buf : 	struct sk_buff *beacon;
buf : 
buf : 	mutex_lock(&priv->mutex);
buf : 	if (!priv->beacon_ctx) {
if (!priv->beacon_ctx) { 
buf : 		IWL_ERR(priv, "updating beacon w/o beacon context!\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (priv->beacon_ctx->vif->type != NL80211_IFTYPE_AP) {
if (priv->beacon_ctx->vif->type != NL80211_IFTYPE_AP) { 
buf : 		/*
buf : 		 * The ucode will send beacon notifications even in
ifications even in 
buf : 		 * IBSS mode, but we don't want to process them. But
buf : 		 * we need to defer the type check to here due to
buf : 		 * requiring locking around the beacon_ctx access.
buf : 		 */
buf : 		goto out;
buf : 	}
buf : 
buf : 	/* Pull updated AP beacon from mac80211. will fail if not in AP mode */
if not in AP mode */ 
buf : 	beacon = ieee80211_beacon_get(priv->hw, priv->beacon_ctx->vif);
buf : 	if (!beacon) {
if (!beacon) { 
buf : 		IWL_ERR(priv, "update beacon failed -- keeping old\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	/* new beacon skb is allocated every time; dispose previous.*/
buf : 	dev_kfree_skb(priv->beacon_skb);
buf : 
buf : 	priv->beacon_skb = beacon;
buf : 
buf : 	iwlagn_send_beacon_cmd(priv);
buf :  out:
buf : 	mutex_unlock(&priv->mutex);
buf : }
buf : 
buf : static void iwl_bg_bt_runtime_config(struct work_struct *work)
buf : {
buf : 	struct iwl_priv *priv =
buf : 		container_of(work, struct iwl_priv, bt_runtime_config);
buf : 
buf : 	mutex_lock(&priv->mutex);
buf : 	if (test_bit(STATUS_EXIT_PENDING, &priv->status))
if (test_bit(STATUS_EXIT_PENDING, &priv->status)) 
buf : 		goto out;
buf : 
buf : 	/* dont send host command if rf-kill is on */
if rf-kill is on */ 
buf : 	if (!iwl_is_ready_rf(priv))
buf : 		goto out;
buf : 
buf : 	iwlagn_send_advance_bt_config(priv);
buf : out:
buf : 	mutex_unlock(&priv->mutex);
buf : }
buf : 
buf : static void iwl_bg_bt_full_concurrency(struct work_struct *work)
buf : {
buf : 	struct iwl_priv *priv =
buf : 		container_of(work, struct iwl_priv, bt_full_concurrency);
buf : 	struct iwl_rxon_context *ctx;
buf : 
buf : 	mutex_lock(&priv->mutex);
buf : 
buf : 	if (test_bit(STATUS_EXIT_PENDING, &priv->status))
if (test_bit(STATUS_EXIT_PENDING, &priv->status)) 
buf : 		goto out;
buf : 
buf : 	/* dont send host command if rf-kill is on */
if rf-kill is on */ 
buf : 	if (!iwl_is_ready_rf(priv))
buf : 		goto out;
buf : 
buf : 	IWL_DEBUG_INFO(priv, "BT coex in %s mode\n",
buf : 		       priv->bt_full_concurrent ?
buf : 		       "full concurrency" : "3-wire");
buf : 
buf : 	/*
buf : 	 * LQ & RXON updated cmds must be sent before BT Config cmd
fore BT Config cmd 
buf : 	 * to avoid 3-wire collisions
buf : 	 */
buf : 	for_each_context(priv, ctx) {
for_each_context(priv, ctx) { 
buf : 		iwlagn_set_rxon_chain(priv, ctx);
buf : 		iwlagn_commit_rxon(priv, ctx);
buf : 	}
buf : 
buf : 	iwlagn_send_advance_bt_config(priv);
buf : out:
buf : 	mutex_unlock(&priv->mutex);
buf : }
buf : 
buf : int iwl_send_statistics_request(struct iwl_priv *priv, u8 flags, bool clear)
buf : {
buf : 	struct iwl_statistics_cmd statistics_cmd = {
buf : 		.configuration_flags =
buf : 			clear ? IWL_STATS_CONF_CLEAR_STATS : 0,
buf : 	};
buf : 
buf : 	if (flags & CMD_ASYNC)
if (flags & CMD_ASYNC) 
buf : 		return iwl_dvm_send_cmd_pdu(priv, REPLY_STATISTICS_CMD,
buf : 					CMD_ASYNC,
buf : 					sizeof(struct iwl_statistics_cmd),
buf : 					&statistics_cmd);
buf : 	else
buf : 		return iwl_dvm_send_cmd_pdu(priv, REPLY_STATISTICS_CMD, 0,
buf : 					sizeof(struct iwl_statistics_cmd),
buf : 					&statistics_cmd);
buf : }
buf : 
buf : /**
buf :  * iwl_bg_statistics_periodic - Timer callback to queue statistics
buf :  *
buf :  * This callback is provided in order to send a statistics request.
buf :  *
buf :  * This timer function is continually reset to execute within
buf :  * REG_RECALIB_PERIOD seconds since the last STATISTICS_NOTIFICATION
buf :  * was received.  We need to ensure we receive the statistics in order
buf :  * to update the temperature used for calibrating the TXPOWER.
for calibrating the TXPOWER. 
buf :  */
buf : static void iwl_bg_statistics_periodic(unsigned long data)
buf : {
buf : 	struct iwl_priv *priv = (struct iwl_priv *)data;
buf : 
buf : 	if (test_bit(STATUS_EXIT_PENDING, &priv->status))
if (test_bit(STATUS_EXIT_PENDING, &priv->status)) 
buf : 		return;
buf : 
buf : 	/* dont send host command if rf-kill is on */
if rf-kill is on */ 
buf : 	if (!iwl_is_ready_rf(priv))
buf : 		return;
buf : 
buf : 	iwl_send_statistics_request(priv, CMD_ASYNC, false);
buf : }
buf : 
buf : 
buf : static void iwl_print_cont_event_trace(struct iwl_priv *priv, u32 base,
buf : 					u32 start_idx, u32 num_events,
buf : 					u32 capacity, u32 mode)
buf : {
buf : 	u32 i;
buf : 	u32 ptr;        /* SRAM byte address of log data */
buf : 	u32 ev, time, data; /* event log data */
buf : 	unsigned long reg_flags;
buf : 
buf : 	if (mode == 0)
if (mode == 0) 
buf : 		ptr = base + (4 * sizeof(u32)) + (start_idx * 2 * sizeof(u32));
buf : 	else
buf : 		ptr = base + (4 * sizeof(u32)) + (start_idx * 3 * sizeof(u32));
buf : 
buf : 	/* Make sure device is powered up for SRAM reads */
for SRAM reads */ 
buf : 	if (!iwl_trans_grab_nic_access(priv->trans, false, &reg_flags))
buf : 		return;
buf : 
buf : 	/* Set starting address; reads will auto-increment */
buf : 	iwl_write32(priv->trans, HBUS_TARG_MEM_RADDR, ptr);
buf : 
buf : 	/*
buf : 	 * Refuse to read more than would have fit into the log from
buf : 	 * the current start_idx. This used to happen due to the race
buf : 	 * described below, but now WARN because the code below should
buf : 	 * prevent it from happening here.
buf : 	 */
buf : 	if (WARN_ON(num_events > capacity - start_idx))
if (WARN_ON(num_events > capacity - start_idx)) 
buf : 		num_events = capacity - start_idx;
buf : 
buf : 	/*
buf : 	 * "time" is actually "data" for mode 0 (no timestamp).
for mode 0 (no timestamp). 
buf : 	 * place event id # at far right for easier visual parsing.
buf : 	 */
buf : 	for (i = 0; i < num_events; i++) {
for (i = 0; i < num_events; i++) { 
buf : 		ev = iwl_read32(priv->trans, HBUS_TARG_MEM_RDAT);
buf : 		time = iwl_read32(priv->trans, HBUS_TARG_MEM_RDAT);
buf : 		if (mode == 0) {
if (mode == 0) { 
buf : 			trace_iwlwifi_dev_ucode_cont_event(
buf : 					priv->trans->dev, 0, time, ev);
buf : 		} else {
buf : 			data = iwl_read32(priv->trans, HBUS_TARG_MEM_RDAT);
buf : 			trace_iwlwifi_dev_ucode_cont_event(
ifi_dev_ucode_cont_event( 
buf : 					priv->trans->dev, time, data, ev);
buf : 		}
buf : 	}
buf : 	/* Allow device to power down */
buf : 	iwl_trans_release_nic_access(priv->trans, &reg_flags);
buf : }
buf : 
buf : static void iwl_continuous_event_trace(struct iwl_priv *priv)
buf : {
buf : 	u32 capacity;   /* event log capacity in # entries */
buf : 	struct {
buf : 		u32 capacity;
buf : 		u32 mode;
buf : 		u32 wrap_counter;
buf : 		u32 write_counter;
buf : 	} __packed read;
buf : 	u32 base;       /* SRAM byte address of event log header */
buf : 	u32 mode;       /* 0 - no timestamp, 1 - timestamp recorded */
buf : 	u32 num_wraps;  /* # times uCode wrapped to top of log */
buf : 	u32 next_entry; /* index of next entry to be written by uCode */
buf : 
buf : 	base = priv->device_pointers.log_event_table;
buf : 	if (iwlagn_hw_valid_rtc_data_addr(base)) {
if (iwlagn_hw_valid_rtc_data_addr(base)) { 
buf : 		iwl_trans_read_mem_bytes(priv->trans, base,
buf : 					 &read, sizeof(read));
buf : 		capacity = read.capacity;
buf : 		mode = read.mode;
buf : 		num_wraps = read.wrap_counter;
buf : 		next_entry = read.write_counter;
buf : 	} else
buf : 		return;
buf : 
buf : 	/*
buf : 	 * Unfortunately, the uCode doesn't use temporary variables.
fortunately, the uCode doesn't use temporary variables. 
buf : 	 * Therefore, it can happen that we read next_entry == capacity,
buf : 	 * which really means next_entry == 0.
buf : 	 */
buf : 	if (unlikely(next_entry == capacity))
if (unlikely(next_entry == capacity)) 
buf : 		next_entry = 0;
buf : 	/*
buf : 	 * Additionally, the uCode increases the write pointer before
fore 
buf : 	 * the wraps counter, so if the write pointer is smaller than
buf : 	 * the old write pointer (wrap occurred) but we read that no
buf : 	 * wrap occurred, we actually read between the next_entry and
buf : 	 * num_wraps update (this does happen in practice!!) -- take
buf : 	 * that into account by increasing num_wraps.
buf : 	 */
buf : 	if (unlikely(next_entry < priv->event_log.next_entry &&
if (unlikely(next_entry < priv->event_log.next_entry && 
buf : 		     num_wraps == priv->event_log.num_wraps))
buf : 		num_wraps++;
buf : 
buf : 	if (num_wraps == priv->event_log.num_wraps) {
if (num_wraps == priv->event_log.num_wraps) { 
buf : 		iwl_print_cont_event_trace(
buf : 			priv, base, priv->event_log.next_entry,
buf : 			next_entry - priv->event_log.next_entry,
buf : 			capacity, mode);
buf : 
buf : 		priv->event_log.non_wraps_count++;
buf : 	} else {
buf : 		if (num_wraps - priv->event_log.num_wraps > 1)
if (num_wraps - priv->event_log.num_wraps > 1) 
buf : 			priv->event_log.wraps_more_count++;
buf : 		else
buf : 			priv->event_log.wraps_once_count++;
buf : 
buf : 		trace_iwlwifi_dev_ucode_wrap_event(priv->trans->dev,
ifi_dev_ucode_wrap_event(priv->trans->dev, 
buf : 				num_wraps - priv->event_log.num_wraps,
buf : 				next_entry, priv->event_log.next_entry);
buf : 
buf : 		if (next_entry < priv->event_log.next_entry) {
if (next_entry < priv->event_log.next_entry) { 
buf : 			iwl_print_cont_event_trace(
buf : 				priv, base, priv->event_log.next_entry,
buf : 				capacity - priv->event_log.next_entry,
buf : 				capacity, mode);
buf : 
buf : 			iwl_print_cont_event_trace(
buf : 				priv, base, 0, next_entry, capacity, mode);
buf : 		} else {
buf : 			iwl_print_cont_event_trace(
buf : 				priv, base, next_entry,
buf : 				capacity - next_entry,
buf : 				capacity, mode);
buf : 
buf : 			iwl_print_cont_event_trace(
buf : 				priv, base, 0, next_entry, capacity, mode);
buf : 		}
buf : 	}
buf : 
buf : 	priv->event_log.num_wraps = num_wraps;
buf : 	priv->event_log.next_entry = next_entry;
buf : }
buf : 
buf : /**
buf :  * iwl_bg_ucode_trace - Timer callback to log ucode event
buf :  *
buf :  * The timer is continually set to execute every
buf :  * UCODE_TRACE_PERIOD milliseconds after the last timer expired
buf :  * this function is to perform continuous uCode event logging operation
form continuous uCode event logging operation 
buf :  * if enabled
buf :  */
buf : static void iwl_bg_ucode_trace(unsigned long data)
buf : {
buf : 	struct iwl_priv *priv = (struct iwl_priv *)data;
buf : 
buf : 	if (test_bit(STATUS_EXIT_PENDING, &priv->status))
if (test_bit(STATUS_EXIT_PENDING, &priv->status)) 
buf : 		return;
buf : 
buf : 	if (priv->event_log.ucode_trace) {
if (priv->event_log.ucode_trace) { 
buf : 		iwl_continuous_event_trace(priv);
buf : 		/* Reschedule the timer to occur in UCODE_TRACE_PERIOD */
buf : 		mod_timer(&priv->ucode_trace,
buf : 			 jiffies + msecs_to_jiffies(UCODE_TRACE_PERIOD));
iffies + msecs_to_jiffies(UCODE_TRACE_PERIOD)); 
buf : 	}
buf : }
buf : 
buf : static void iwl_bg_tx_flush(struct work_struct *work)
buf : {
buf : 	struct iwl_priv *priv =
buf : 		container_of(work, struct iwl_priv, tx_flush);
buf : 
buf : 	if (test_bit(STATUS_EXIT_PENDING, &priv->status))
if (test_bit(STATUS_EXIT_PENDING, &priv->status)) 
buf : 		return;
buf : 
buf : 	/* do nothing if rf-kill is on */
if rf-kill is on */ 
buf : 	if (!iwl_is_ready_rf(priv))
buf : 		return;
buf : 
buf : 	IWL_DEBUG_INFO(priv, "device request: flush all tx frames\n");
buf : 	iwlagn_dev_txfifo_flush(priv);
ifo_flush(priv); 
buf : }
buf : 
buf : /*
buf :  * queue/FIFO/AC mapping definitions
buf :  */
buf : 
buf : static const u8 iwlagn_bss_ac_to_fifo[] = {
ifo[] = { 
buf : 	IWL_TX_FIFO_VO,
buf : 	IWL_TX_FIFO_VI,
buf : 	IWL_TX_FIFO_BE,
buf : 	IWL_TX_FIFO_BK,
buf : };
buf : 
buf : static const u8 iwlagn_bss_ac_to_queue[] = {
buf : 	0, 1, 2, 3,
buf : };
buf : 
buf : static const u8 iwlagn_pan_ac_to_fifo[] = {
ifo[] = { 
buf : 	IWL_TX_FIFO_VO_IPAN,
buf : 	IWL_TX_FIFO_VI_IPAN,
buf : 	IWL_TX_FIFO_BE_IPAN,
buf : 	IWL_TX_FIFO_BK_IPAN,
buf : };
buf : 
buf : static const u8 iwlagn_pan_ac_to_queue[] = {
buf : 	7, 6, 5, 4,
buf : };
buf : 
buf : static void iwl_init_context(struct iwl_priv *priv, u32 ucode_flags)
buf : {
buf : 	int i;
buf : 
buf : 	/*
buf : 	 * The default context is always valid,
buf : 	 * the PAN context depends on uCode.
buf : 	 */
buf : 	priv->valid_contexts = BIT(IWL_RXON_CTX_BSS);
buf : 	if (ucode_flags & IWL_UCODE_TLV_FLAGS_PAN)
if (ucode_flags & IWL_UCODE_TLV_FLAGS_PAN) 
buf : 		priv->valid_contexts |= BIT(IWL_RXON_CTX_PAN);
buf : 
buf : 	for (i = 0; i < NUM_IWL_RXON_CTX; i++)
for (i = 0; i < NUM_IWL_RXON_CTX; i++) 
buf : 		priv->contexts[i].ctxid = i;
buf : 
buf : 	priv->contexts[IWL_RXON_CTX_BSS].always_active = true;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].is_active = true;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].rxon_cmd = REPLY_RXON;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].rxon_timing_cmd = REPLY_RXON_TIMING;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].rxon_assoc_cmd = REPLY_RXON_ASSOC;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].qos_cmd = REPLY_QOS_PARAM;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].ap_sta_id = IWL_AP_ID;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].wep_key_cmd = REPLY_WEPKEY;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].bcast_sta_id = IWLAGN_BROADCAST_ID;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].exclusive_interface_modes =
buf : 		BIT(NL80211_IFTYPE_ADHOC) | BIT(NL80211_IFTYPE_MONITOR);
buf : 	priv->contexts[IWL_RXON_CTX_BSS].interface_modes =
buf : 		BIT(NL80211_IFTYPE_STATION);
buf : 	priv->contexts[IWL_RXON_CTX_BSS].ap_devtype = RXON_DEV_TYPE_AP;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].ibss_devtype = RXON_DEV_TYPE_IBSS;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].station_devtype = RXON_DEV_TYPE_ESS;
buf : 	priv->contexts[IWL_RXON_CTX_BSS].unused_devtype = RXON_DEV_TYPE_ESS;
buf : 	memcpy(priv->contexts[IWL_RXON_CTX_BSS].ac_to_queue,
buf : 	       iwlagn_bss_ac_to_queue, sizeof(iwlagn_bss_ac_to_queue));
buf : 	memcpy(priv->contexts[IWL_RXON_CTX_BSS].ac_to_fifo,
ifo, 
buf : 	       iwlagn_bss_ac_to_fifo, sizeof(iwlagn_bss_ac_to_fifo));
buf : 
buf : 	priv->contexts[IWL_RXON_CTX_PAN].rxon_cmd = REPLY_WIPAN_RXON;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].rxon_timing_cmd =
buf : 		REPLY_WIPAN_RXON_TIMING;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].rxon_assoc_cmd =
buf : 		REPLY_WIPAN_RXON_ASSOC;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].qos_cmd = REPLY_WIPAN_QOS_PARAM;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].ap_sta_id = IWL_AP_ID_PAN;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].wep_key_cmd = REPLY_WIPAN_WEPKEY;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].bcast_sta_id = IWLAGN_PAN_BCAST_ID;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].station_flags = STA_FLG_PAN_STATION;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].interface_modes =
buf : 		BIT(NL80211_IFTYPE_STATION) | BIT(NL80211_IFTYPE_AP);
buf : 
buf : 	priv->contexts[IWL_RXON_CTX_PAN].ap_devtype = RXON_DEV_TYPE_CP;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].station_devtype = RXON_DEV_TYPE_2STA;
buf : 	priv->contexts[IWL_RXON_CTX_PAN].unused_devtype = RXON_DEV_TYPE_P2P;
buf : 	memcpy(priv->contexts[IWL_RXON_CTX_PAN].ac_to_queue,
buf : 	       iwlagn_pan_ac_to_queue, sizeof(iwlagn_pan_ac_to_queue));
buf : 	memcpy(priv->contexts[IWL_RXON_CTX_PAN].ac_to_fifo,
ifo, 
buf : 	       iwlagn_pan_ac_to_fifo, sizeof(iwlagn_pan_ac_to_fifo));
buf : 	priv->contexts[IWL_RXON_CTX_PAN].mcast_queue = IWL_IPAN_MCAST_QUEUE;
buf : 
buf : 	BUILD_BUG_ON(NUM_IWL_RXON_CTX != 2);
buf : }
buf : 
buf : static void iwl_rf_kill_ct_config(struct iwl_priv *priv)
buf : {
buf : 	struct iwl_ct_kill_config cmd;
buf : 	struct iwl_ct_kill_throttling_config adv_cmd;
buf : 	int ret = 0;
buf : 
buf : 	iwl_write32(priv->trans, CSR_UCODE_DRV_GP1_CLR,
buf : 		    CSR_UCODE_DRV_GP1_REG_BIT_CT_KILL_EXIT);
buf : 
buf : 	priv->thermal_throttle.ct_kill_toggle = false;
buf : 
buf : 	if (priv->lib->support_ct_kill_exit) {
if (priv->lib->support_ct_kill_exit) { 
buf : 		adv_cmd.critical_temperature_enter =
buf : 			cpu_to_le32(priv->hw_params.ct_kill_threshold);
buf : 		adv_cmd.critical_temperature_exit =
buf : 			cpu_to_le32(priv->hw_params.ct_kill_exit_threshold);
buf : 
buf : 		ret = iwl_dvm_send_cmd_pdu(priv,
buf : 				       REPLY_CT_KILL_CONFIG_CMD,
buf : 				       0, sizeof(adv_cmd), &adv_cmd);
buf : 		if (ret)
if (ret) 
buf : 			IWL_ERR(priv, "REPLY_CT_KILL_CONFIG_CMD failed\n");
buf : 		else
buf : 			IWL_DEBUG_INFO(priv, "REPLY_CT_KILL_CONFIG_CMD "
buf : 				"succeeded, critical temperature enter is %d,"
buf : 				"exit is %d\n",
buf : 				priv->hw_params.ct_kill_threshold,
buf : 				priv->hw_params.ct_kill_exit_threshold);
buf : 	} else {
buf : 		cmd.critical_temperature_R =
buf : 			cpu_to_le32(priv->hw_params.ct_kill_threshold);
buf : 
buf : 		ret = iwl_dvm_send_cmd_pdu(priv,
buf : 				       REPLY_CT_KILL_CONFIG_CMD,
buf : 				       0, sizeof(cmd), &cmd);
buf : 		if (ret)
if (ret) 
buf : 			IWL_ERR(priv, "REPLY_CT_KILL_CONFIG_CMD failed\n");
buf : 		else
buf : 			IWL_DEBUG_INFO(priv, "REPLY_CT_KILL_CONFIG_CMD "
buf : 				"succeeded, "
buf : 				"critical temperature is %d\n",
buf : 				priv->hw_params.ct_kill_threshold);
buf : 	}
buf : }
buf : 
buf : static int iwlagn_send_calib_cfg_rt(struct iwl_priv *priv, u32 cfg)
buf : {
buf : 	struct iwl_calib_cfg_cmd calib_cfg_cmd;
buf : 	struct iwl_host_cmd cmd = {
buf : 		.id = CALIBRATION_CFG_CMD,
buf : 		.len = { sizeof(struct iwl_calib_cfg_cmd), },
buf : 		.data = { &calib_cfg_cmd, },
buf : 	};
buf : 
buf : 	memset(&calib_cfg_cmd, 0, sizeof(calib_cfg_cmd));
buf : 	calib_cfg_cmd.ucd_calib_cfg.once.is_enable = IWL_CALIB_RT_CFG_ALL;
buf : 	calib_cfg_cmd.ucd_calib_cfg.once.start = cpu_to_le32(cfg);
buf : 
buf : 	return iwl_dvm_send_cmd(priv, &cmd);
buf : }
buf : 
buf : 
buf : static int iwlagn_send_tx_ant_config(struct iwl_priv *priv, u8 valid_tx_ant)
buf : {
buf : 	struct iwl_tx_ant_config_cmd tx_ant_cmd = {
buf : 	  .valid = cpu_to_le32(valid_tx_ant),
buf : 	};
buf : 
buf : 	if (IWL_UCODE_API(priv->fw->ucode_ver) > 1) {
if (IWL_UCODE_API(priv->fw->ucode_ver) > 1) { 
buf : 		IWL_DEBUG_HC(priv, "select valid tx ant: %u\n", valid_tx_ant);
buf : 		return iwl_dvm_send_cmd_pdu(priv, TX_ANT_CONFIGURATION_CMD, 0,
buf : 					sizeof(struct iwl_tx_ant_config_cmd),
buf : 					&tx_ant_cmd);
buf : 	} else {
buf : 		IWL_DEBUG_HC(priv, "TX_ANT_CONFIGURATION_CMD not supported\n");
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : }
buf : 
buf : static void iwl_send_bt_config(struct iwl_priv *priv)
buf : {
buf : 	struct iwl_bt_cmd bt_cmd = {
buf : 		.lead_time = BT_LEAD_TIME_DEF,
buf : 		.max_kill = BT_MAX_KILL_DEF,
buf : 		.kill_ack_mask = 0,
buf : 		.kill_cts_mask = 0,
buf : 	};
buf : 
buf : 	if (!iwlwifi_mod_params.bt_coex_active)
if (!iwlwifi_mod_params.bt_coex_active) 
buf : 		bt_cmd.flags = BT_COEX_DISABLE;
buf : 	else
buf : 		bt_cmd.flags = BT_COEX_ENABLE;
buf : 
buf : 	priv->bt_enable_flag = bt_cmd.flags;
buf : 	IWL_DEBUG_INFO(priv, "BT coex %s\n",
buf : 		(bt_cmd.flags == BT_COEX_DISABLE) ? "disable" : "active");
buf : 
buf : 	if (iwl_dvm_send_cmd_pdu(priv, REPLY_BT_CONFIG,
if (iwl_dvm_send_cmd_pdu(priv, REPLY_BT_CONFIG, 
buf : 			     0, sizeof(struct iwl_bt_cmd), &bt_cmd))
buf : 		IWL_ERR(priv, "failed to send BT Coex Config\n");
buf : }
buf : 
buf : /**
buf :  * iwl_alive_start - called after REPLY_ALIVE notification received
ification received 
buf :  *                   from protocol/runtime uCode (initialization uCode's
buf :  *                   Alive gets handled by iwl_init_alive_start()).
buf :  */
buf : int iwl_alive_start(struct iwl_priv *priv)
buf : {
buf : 	int ret = 0;
buf : 	struct iwl_rxon_context *ctx = &priv->contexts[IWL_RXON_CTX_BSS];
buf : 
buf : 	IWL_DEBUG_INFO(priv, "Runtime Alive received.\n");
buf : 
buf : 	/* After the ALIVE response, we can send host commands to the uCode */
buf : 	set_bit(STATUS_ALIVE, &priv->status);
buf : 
buf : 	if (iwl_is_rfkill(priv))
if (iwl_is_rfkill(priv)) 
buf : 		return -ERFKILL;
buf : 
buf : 	if (priv->event_log.ucode_trace) {
if (priv->event_log.ucode_trace) { 
buf : 		/* start collecting data now */
buf : 		mod_timer(&priv->ucode_trace, jiffies);
iffies); 
buf : 	}
buf : 
buf : 	/* download priority table before any calibration request */
fore any calibration request */ 
buf : 	if (priv->lib->bt_params &&
buf : 	    priv->lib->bt_params->advanced_bt_coexist) {
buf : 		/* Configure Bluetooth device coexistence support */
buf : 		if (priv->lib->bt_params->bt_sco_disable)
if (priv->lib->bt_params->bt_sco_disable) 
buf : 			priv->bt_enable_pspoll = false;
buf : 		else
buf : 			priv->bt_enable_pspoll = true;
buf : 
buf : 		priv->bt_valid = IWLAGN_BT_ALL_VALID_MSK;
buf : 		priv->kill_ack_mask = IWLAGN_BT_KILL_ACK_MASK_DEFAULT;
buf : 		priv->kill_cts_mask = IWLAGN_BT_KILL_CTS_MASK_DEFAULT;
buf : 		iwlagn_send_advance_bt_config(priv);
buf : 		priv->bt_valid = IWLAGN_BT_VALID_ENABLE_FLAGS;
buf : 		priv->cur_rssi_ctx = NULL;
buf : 
buf : 		iwl_send_prio_tbl(priv);
buf : 
buf : 		/* FIXME: w/a to force change uCode BT state machine */
force change uCode BT state machine */ 
buf : 		ret = iwl_send_bt_env(priv, IWL_BT_COEX_ENV_OPEN,
buf : 					 BT_COEX_PRIO_TBL_EVT_INIT_CALIB2);
buf : 		if (ret)
if (ret) 
buf : 			return ret;
buf : 		ret = iwl_send_bt_env(priv, IWL_BT_COEX_ENV_CLOSE,
buf : 					 BT_COEX_PRIO_TBL_EVT_INIT_CALIB2);
buf : 		if (ret)
if (ret) 
buf : 			return ret;
buf : 	} else if (priv->lib->bt_params) {
if (priv->lib->bt_params) { 
buf : 		/*
buf : 		 * default is 2-wire BT coexexistence support
buf : 		 */
buf : 		iwl_send_bt_config(priv);
buf : 	}
buf : 
buf : 	/*
buf : 	 * Perform runtime calibrations, including DC calibration.
form runtime calibrations, including DC calibration. 
buf : 	 */
buf : 	iwlagn_send_calib_cfg_rt(priv, IWL_CALIB_CFG_DC_IDX);
buf : 
buf : 	ieee80211_wake_queues(priv->hw);
buf : 
buf : 	/* Configure Tx antenna selection based on H/W config */
buf : 	iwlagn_send_tx_ant_config(priv, priv->nvm_data->valid_tx_ant);
buf : 
buf : 	if (iwl_is_associated_ctx(ctx) && !priv->wowlan) {
if (iwl_is_associated_ctx(ctx) && !priv->wowlan) { 
buf : 		struct iwl_rxon_cmd *active_rxon =
buf : 				(struct iwl_rxon_cmd *)&ctx->active;
buf : 		/* apply any changes in staging */
buf : 		ctx->staging.filter_flags |= RXON_FILTER_ASSOC_MSK;
buf : 		active_rxon->filter_flags &= ~RXON_FILTER_ASSOC_MSK;
buf : 	} else {
buf : 		struct iwl_rxon_context *tmp;
buf : 		/* Initialize our rx_config data */
buf : 		for_each_context(priv, tmp)
for_each_context(priv, tmp) 
buf : 			iwl_connection_init_rx_config(priv, tmp);
buf : 
buf : 		iwlagn_set_rxon_chain(priv, ctx);
buf : 	}
buf : 
buf : 	if (!priv->wowlan) {
if (!priv->wowlan) { 
buf : 		/* WoWLAN ucode will not reply in the same way, skip it */
buf : 		iwl_reset_run_time_calib(priv);
buf : 	}
buf : 
buf : 	set_bit(STATUS_READY, &priv->status);
buf : 
buf : 	/* Configure the adapter for unassociated operation */
for unassociated operation */ 
buf : 	ret = iwlagn_commit_rxon(priv, ctx);
buf : 	if (ret)
if (ret) 
buf : 		return ret;
buf : 
buf : 	/* At this point, the NIC is initialized and operational */
buf : 	iwl_rf_kill_ct_config(priv);
buf : 
buf : 	IWL_DEBUG_INFO(priv, "ALIVE processing complete.\n");
buf : 
buf : 	return iwl_power_update_mode(priv, true);
buf : }
buf : 
buf : /**
buf :  * iwl_clear_driver_stations - clear knowledge of all stations from driver
buf :  * @priv: iwl priv struct
buf :  *
buf :  * This is called during iwl_down() to make sure that in the case
buf :  * we're coming there from a hardware restart mac80211 will be
buf :  * able to reconfigure stations -- if we're getting there in the
if we're getting there in the 
buf :  * normal down flow then the stations will already be cleared.
buf :  */
buf : static void iwl_clear_driver_stations(struct iwl_priv *priv)
buf : {
buf : 	struct iwl_rxon_context *ctx;
buf : 
buf : 	spin_lock_bh(&priv->sta_lock);
buf : 	memset(priv->stations, 0, sizeof(priv->stations));
buf : 	priv->num_stations = 0;
buf : 
buf : 	priv->ucode_key_table = 0;
buf : 
buf : 	for_each_context(priv, ctx) {
for_each_context(priv, ctx) { 
buf : 		/*
buf : 		 * Remove all key information that is not stored as part
formation that is not stored as part 
buf : 		 * of station information since mac80211 may not have had
buf : 		 * a chance to remove all the keys. When device is
buf : 		 * reconfigured by mac80211 after an error all keys will
buf : 		 * be reconfigured.
buf : 		 */
buf : 		memset(ctx->wep_keys, 0, sizeof(ctx->wep_keys));
buf : 		ctx->key_mapping_keys = 0;
buf : 	}
buf : 
buf : 	spin_unlock_bh(&priv->sta_lock);
buf : }
buf : 
buf : void iwl_down(struct iwl_priv *priv)
buf : {
buf : 	int exit_pending;
buf : 
buf : 	IWL_DEBUG_INFO(priv, DRV_NAME " is going down\n");
buf : 
buf : 	lockdep_assert_held(&priv->mutex);
buf : 
buf : 	iwl_scan_cancel_timeout(priv, 200);
buf : 
buf : 	exit_pending =
buf : 		test_and_set_bit(STATUS_EXIT_PENDING, &priv->status);
buf : 
buf : 	iwl_clear_ucode_stations(priv, NULL);
buf : 	iwl_dealloc_bcast_stations(priv);
buf : 	iwl_clear_driver_stations(priv);
buf : 
buf : 	/* reset BT coex data */
buf : 	priv->bt_status = 0;
buf : 	priv->cur_rssi_ctx = NULL;
buf : 	priv->bt_is_sco = 0;
buf : 	if (priv->lib->bt_params)
if (priv->lib->bt_params) 
buf : 		priv->bt_traffic_load =
buf : 			 priv->lib->bt_params->bt_init_traffic_load;
buf : 	else
buf : 		priv->bt_traffic_load = 0;
buf : 	priv->bt_full_concurrent = false;
buf : 	priv->bt_ci_compliance = 0;
buf : 
buf : 	/* Wipe out the EXIT_PENDING status bit if we are not actually
if we are not actually 
buf : 	 * exiting the module */
buf : 	if (!exit_pending)
if (!exit_pending) 
buf : 		clear_bit(STATUS_EXIT_PENDING, &priv->status);
buf : 
buf : 	if (priv->mac80211_registered)
if (priv->mac80211_registered) 
buf : 		ieee80211_stop_queues(priv->hw);
buf : 
buf : 	priv->ucode_loaded = false;
buf : 	iwl_trans_stop_device(priv->trans);
buf : 
buf : 	/* Set num_aux_in_flight must be done after the transport is stopped */
buf : 	atomic_set(&priv->num_aux_in_flight, 0);
buf : 
buf : 	/* Clear out all status bits but a few that are stable across reset */
buf : 	priv->status &= test_bit(STATUS_RF_KILL_HW, &priv->status) <<
buf : 				STATUS_RF_KILL_HW |
buf : 			test_bit(STATUS_FW_ERROR, &priv->status) <<
buf : 				STATUS_FW_ERROR |
buf : 			test_bit(STATUS_EXIT_PENDING, &priv->status) <<
buf : 				STATUS_EXIT_PENDING;
buf : 
buf : 	dev_kfree_skb(priv->beacon_skb);
buf : 	priv->beacon_skb = NULL;
buf : }
buf : 
buf : /*****************************************************************************
buf :  *
buf :  * Workqueue callbacks
buf :  *
buf :  *****************************************************************************/
buf : 
buf : static void iwl_bg_run_time_calib_work(struct work_struct *work)
buf : {
buf : 	struct iwl_priv *priv = container_of(work, struct iwl_priv,
buf : 			run_time_calib_work);
buf : 
buf : 	mutex_lock(&priv->mutex);
buf : 
buf : 	if (test_bit(STATUS_EXIT_PENDING, &priv->status) ||
if (test_bit(STATUS_EXIT_PENDING, &priv->status) || 
buf : 	    test_bit(STATUS_SCANNING, &priv->status)) {
buf : 		mutex_unlock(&priv->mutex);
buf : 		return;
buf : 	}
buf : 
buf : 	if (priv->start_calib) {
if (priv->start_calib) { 
buf : 		iwl_chain_noise_calibration(priv);
buf : 		iwl_sensitivity_calibration(priv);
buf : 	}
buf : 
buf : 	mutex_unlock(&priv->mutex);
buf : }
buf : 
buf : void iwlagn_prepare_restart(struct iwl_priv *priv)
buf : {
buf : 	bool bt_full_concurrent;
buf : 	u8 bt_ci_compliance;
buf : 	u8 bt_load;
buf : 	u8 bt_status;
buf : 	bool bt_is_sco;
buf : 	int i;
buf : 
buf : 	lockdep_assert_held(&priv->mutex);
buf : 
buf : 	priv->is_open = 0;
buf : 
buf : 	/*
buf : 	 * __iwl_down() will clear the BT status variables,
buf : 	 * which is correct, but when we restart we really
buf : 	 * want to keep them so restore them afterwards.
buf : 	 *
buf : 	 * The restart process will later pick them up and
buf : 	 * re-configure the hw when we reconfigure the BT
buf : 	 * command.
buf : 	 */
buf : 	bt_full_concurrent = priv->bt_full_concurrent;
buf : 	bt_ci_compliance = priv->bt_ci_compliance;
buf : 	bt_load = priv->bt_traffic_load;
buf : 	bt_status = priv->bt_status;
buf : 	bt_is_sco = priv->bt_is_sco;
buf : 
buf : 	iwl_down(priv);
buf : 
buf : 	priv->bt_full_concurrent = bt_full_concurrent;
buf : 	priv->bt_ci_compliance = bt_ci_compliance;
buf : 	priv->bt_traffic_load = bt_load;
buf : 	priv->bt_status = bt_status;
buf : 	priv->bt_is_sco = bt_is_sco;
buf : 
buf : 	/* reset aggregation queues */
buf : 	for (i = IWLAGN_FIRST_AMPDU_QUEUE; i < IWL_MAX_HW_QUEUES; i++)
for (i = IWLAGN_FIRST_AMPDU_QUEUE; i < IWL_MAX_HW_QUEUES; i++) 
buf : 		priv->queue_to_mac80211[i] = IWL_INVALID_MAC80211_QUEUE;
buf : 	/* and stop counts */
buf : 	for (i = 0; i < IWL_MAX_HW_QUEUES; i++)
for (i = 0; i < IWL_MAX_HW_QUEUES; i++) 
buf : 		atomic_set(&priv->queue_stop_count[i], 0);
buf : 
buf : 	memset(priv->agg_q_alloc, 0, sizeof(priv->agg_q_alloc));
buf : }
buf : 
buf : static void iwl_bg_restart(struct work_struct *data)
buf : {
buf : 	struct iwl_priv *priv = container_of(data, struct iwl_priv, restart);
buf : 
buf : 	if (test_bit(STATUS_EXIT_PENDING, &priv->status))
if (test_bit(STATUS_EXIT_PENDING, &priv->status)) 
buf : 		return;
buf : 
buf : 	if (test_and_clear_bit(STATUS_FW_ERROR, &priv->status)) {
if (test_and_clear_bit(STATUS_FW_ERROR, &priv->status)) { 
buf : 		mutex_lock(&priv->mutex);
buf : 		iwlagn_prepare_restart(priv);
buf : 		mutex_unlock(&priv->mutex);
buf : 		iwl_cancel_deferred_work(priv);
buf : 		if (priv->mac80211_registered)
if (priv->mac80211_registered) 
buf : 			ieee80211_restart_hw(priv->hw);
buf : 		else
buf : 			IWL_ERR(priv,
buf : 				"Cannot request restart before registrating with mac80211\n");
fore registrating with mac80211\n"); 
buf : 	} else {
buf : 		WARN_ON(1);
buf : 	}
buf : }
buf : 
buf : /*****************************************************************************
buf :  *
buf :  * driver setup and teardown
buf :  *
buf :  *****************************************************************************/
buf : 
buf : static void iwl_setup_deferred_work(struct iwl_priv *priv)
buf : {
buf : 	priv->workqueue = create_singlethread_workqueue(DRV_NAME);
buf : 
buf : 	INIT_WORK(&priv->restart, iwl_bg_restart);
buf : 	INIT_WORK(&priv->beacon_update, iwl_bg_beacon_update);
buf : 	INIT_WORK(&priv->run_time_calib_work, iwl_bg_run_time_calib_work);
buf : 	INIT_WORK(&priv->tx_flush, iwl_bg_tx_flush);
buf : 	INIT_WORK(&priv->bt_full_concurrency, iwl_bg_bt_full_concurrency);
buf : 	INIT_WORK(&priv->bt_runtime_config, iwl_bg_bt_runtime_config);
buf : 
buf : 	iwl_setup_scan_deferred_work(priv);
buf : 
buf : 	if (priv->lib->bt_params)
if (priv->lib->bt_params) 
buf : 		iwlagn_bt_setup_deferred_work(priv);
buf : 
buf : 	init_timer(&priv->statistics_periodic);
buf : 	priv->statistics_periodic.data = (unsigned long)priv;
buf : 	priv->statistics_periodic.function = iwl_bg_statistics_periodic;
buf : 
buf : 	init_timer(&priv->ucode_trace);
buf : 	priv->ucode_trace.data = (unsigned long)priv;
buf : 	priv->ucode_trace.function = iwl_bg_ucode_trace;
buf : }
buf : 
buf : void iwl_cancel_deferred_work(struct iwl_priv *priv)
buf : {
buf : 	if (priv->lib->bt_params)
if (priv->lib->bt_params) 
buf : 		iwlagn_bt_cancel_deferred_work(priv);
buf : 
buf : 	cancel_work_sync(&priv->run_time_calib_work);
buf : 	cancel_work_sync(&priv->beacon_update);
buf : 
buf : 	iwl_cancel_scan_deferred_work(priv);
buf : 
buf : 	cancel_work_sync(&priv->bt_full_concurrency);
buf : 	cancel_work_sync(&priv->bt_runtime_config);
buf : 
buf : 	del_timer_sync(&priv->statistics_periodic);
buf : 	del_timer_sync(&priv->ucode_trace);
buf : }
buf : 
buf : static int iwl_init_drv(struct iwl_priv *priv)
buf : {
buf : 	spin_lock_init(&priv->sta_lock);
buf : 
buf : 	mutex_init(&priv->mutex);
buf : 
buf : 	INIT_LIST_HEAD(&priv->calib_results);
buf : 
buf : 	priv->band = IEEE80211_BAND_2GHZ;
buf : 
buf : 	priv->plcp_delta_threshold = priv->lib->plcp_delta_threshold;
buf : 
buf : 	priv->iw_mode = NL80211_IFTYPE_STATION;
buf : 	priv->current_ht_config.smps = IEEE80211_SMPS_STATIC;
buf : 	priv->missed_beacon_threshold = IWL_MISSED_BEACON_THRESHOLD_DEF;
buf : 	priv->agg_tids_count = 0;
buf : 
buf : 	priv->rx_statistics_jiffies = jiffies;
iffies = jiffies; 
buf : 
buf : 	/* Choose which receivers/antennas to use */
buf : 	iwlagn_set_rxon_chain(priv, &priv->contexts[IWL_RXON_CTX_BSS]);
buf : 
buf : 	iwl_init_scan_params(priv);
buf : 
buf : 	/* init bt coex */
buf : 	if (priv->lib->bt_params &&
if (priv->lib->bt_params && 
buf : 	    priv->lib->bt_params->advanced_bt_coexist) {
buf : 		priv->kill_ack_mask = IWLAGN_BT_KILL_ACK_MASK_DEFAULT;
buf : 		priv->kill_cts_mask = IWLAGN_BT_KILL_CTS_MASK_DEFAULT;
buf : 		priv->bt_valid = IWLAGN_BT_ALL_VALID_MSK;
buf : 		priv->bt_on_thresh = BT_ON_THRESHOLD_DEF;
buf : 		priv->bt_duration = BT_DURATION_LIMIT_DEF;
buf : 		priv->dynamic_frag_thresh = BT_FRAG_THRESHOLD_DEF;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void iwl_uninit_drv(struct iwl_priv *priv)
buf : {
buf : 	kfree(priv->scan_cmd);
buf : 	kfree(priv->beacon_cmd);
buf : 	kfree(rcu_dereference_raw(priv->noa_data));
buf : 	iwl_calib_free_results(priv);
buf : #ifdef CONFIG_IWLWIFI_DEBUGFS
ifdef CONFIG_IWLWIFI_DEBUGFS 
buf : 	kfree(priv->wowlan_sram);
buf : #endif
if 
buf : }
buf : 
buf : static void iwl_set_hw_params(struct iwl_priv *priv)
buf : {
buf : 	if (priv->cfg->ht_params)
if (priv->cfg->ht_params) 
buf : 		priv->hw_params.use_rts_for_aggregation =
for_aggregation = 
buf : 			priv->cfg->ht_params->use_rts_for_aggregation;
buf : 
buf : 	/* Device-specific setup */
ific setup */ 
buf : 	priv->lib->set_hw_params(priv);
buf : }
buf : 
buf : 
buf : 
buf : /* show what optional capabilities we have */
buf : static void iwl_option_config(struct iwl_priv *priv)
buf : {
buf : #ifdef CONFIG_IWLWIFI_DEBUG
ifdef CONFIG_IWLWIFI_DEBUG 
buf : 	IWL_INFO(priv, "CONFIG_IWLWIFI_DEBUG enabled\n");
buf : #else
buf : 	IWL_INFO(priv, "CONFIG_IWLWIFI_DEBUG disabled\n");
buf : #endif
if 
buf : 
buf : #ifdef CONFIG_IWLWIFI_DEBUGFS
buf : 	IWL_INFO(priv, "CONFIG_IWLWIFI_DEBUGFS enabled\n");
buf : #else
buf : 	IWL_INFO(priv, "CONFIG_IWLWIFI_DEBUGFS disabled\n");
buf : #endif
if 
buf : 
buf : #ifdef CONFIG_IWLWIFI_DEVICE_TRACING
buf : 	IWL_INFO(priv, "CONFIG_IWLWIFI_DEVICE_TRACING enabled\n");
buf : #else
buf : 	IWL_INFO(priv, "CONFIG_IWLWIFI_DEVICE_TRACING disabled\n");
buf : #endif
if 
buf : }
buf : 
buf : static int iwl_eeprom_init_hw_params(struct iwl_priv *priv)
buf : {
buf : 	struct iwl_nvm_data *data = priv->nvm_data;
buf : 
buf : 	if (data->sku_cap_11n_enable &&
if (data->sku_cap_11n_enable && 
buf : 	    !priv->cfg->ht_params) {
buf : 		IWL_ERR(priv, "Invalid 11n configuration\n");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	if (!data->sku_cap_11n_enable && !data->sku_cap_band_24GHz_enable &&
if (!data->sku_cap_11n_enable && !data->sku_cap_band_24GHz_enable && 
buf : 	    !data->sku_cap_band_52GHz_enable) {
buf : 		IWL_ERR(priv, "Invalid device sku\n");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	IWL_DEBUG_INFO(priv,
buf : 		       "Device SKU: 24GHz %s %s, 52GHz %s %s, 11.n %s %s\n",
buf : 		       data->sku_cap_band_24GHz_enable ? "" : "NOT", "enabled",
buf : 		       data->sku_cap_band_52GHz_enable ? "" : "NOT", "enabled",
buf : 		       data->sku_cap_11n_enable ? "" : "NOT", "enabled");
buf : 
buf : 	priv->hw_params.tx_chains_num =
buf : 		num_of_ant(data->valid_tx_ant);
buf : 	if (priv->cfg->rx_with_siso_diversity)
if (priv->cfg->rx_with_siso_diversity) 
buf : 		priv->hw_params.rx_chains_num = 1;
buf : 	else
buf : 		priv->hw_params.rx_chains_num =
buf : 			num_of_ant(data->valid_rx_ant);
buf : 
buf : 	IWL_DEBUG_INFO(priv, "Valid Tx ant: 0x%X, Valid Rx ant: 0x%X\n",
buf : 		       data->valid_tx_ant,
buf : 		       data->valid_rx_ant);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static struct iwl_op_mode *iwl_op_mode_dvm_start(struct iwl_trans *trans,
buf : 						 const struct iwl_cfg *cfg,
buf : 						 const struct iwl_fw *fw,
buf : 						 struct dentry *dbgfs_dir)
buf : {
buf : 	struct iwl_priv *priv;
buf : 	struct ieee80211_hw *hw;
buf : 	struct iwl_op_mode *op_mode;
buf : 	u16 num_mac;
buf : 	u32 ucode_flags;
buf : 	struct iwl_trans_config trans_cfg = {};
buf : 	static const u8 no_reclaim_cmds[] = {
buf : 		REPLY_RX_PHY_CMD,
buf : 		REPLY_RX_MPDU_CMD,
buf : 		REPLY_COMPRESSED_BA,
buf : 		STATISTICS_NOTIFICATION,
buf : 		REPLY_TX,
buf : 	};
buf : 	int i;
buf : 
buf : 	/************************
buf : 	 * 1. Allocating HW data
buf : 	 ************************/
buf : 	hw = iwl_alloc_all();
buf : 	if (!hw) {
if (!hw) { 
buf : 		pr_err("%s: Cannot allocate network device\n", cfg->name);
buf : 		goto out;
buf : 	}
buf : 
buf : 	op_mode = hw->priv;
buf : 	op_mode->ops = &iwl_dvm_ops;
buf : 	priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 	priv->trans = trans;
buf : 	priv->dev = trans->dev;
buf : 	priv->cfg = cfg;
buf : 	priv->fw = fw;
buf : 
buf : 	switch (priv->cfg->device_family) {
buf : 	case IWL_DEVICE_FAMILY_1000:
buf : 	case IWL_DEVICE_FAMILY_100:
buf : 		priv->lib = &iwl_dvm_1000_cfg;
buf : 		break;
buf : 	case IWL_DEVICE_FAMILY_2000:
buf : 		priv->lib = &iwl_dvm_2000_cfg;
buf : 		break;
buf : 	case IWL_DEVICE_FAMILY_105:
buf : 		priv->lib = &iwl_dvm_105_cfg;
buf : 		break;
buf : 	case IWL_DEVICE_FAMILY_2030:
buf : 	case IWL_DEVICE_FAMILY_135:
buf : 		priv->lib = &iwl_dvm_2030_cfg;
buf : 		break;
buf : 	case IWL_DEVICE_FAMILY_5000:
buf : 		priv->lib = &iwl_dvm_5000_cfg;
buf : 		break;
buf : 	case IWL_DEVICE_FAMILY_5150:
buf : 		priv->lib = &iwl_dvm_5150_cfg;
buf : 		break;
buf : 	case IWL_DEVICE_FAMILY_6000:
buf : 	case IWL_DEVICE_FAMILY_6000i:
buf : 		priv->lib = &iwl_dvm_6000_cfg;
buf : 		break;
buf : 	case IWL_DEVICE_FAMILY_6005:
buf : 		priv->lib = &iwl_dvm_6005_cfg;
buf : 		break;
buf : 	case IWL_DEVICE_FAMILY_6050:
buf : 	case IWL_DEVICE_FAMILY_6150:
buf : 		priv->lib = &iwl_dvm_6050_cfg;
buf : 		break;
buf : 	case IWL_DEVICE_FAMILY_6030:
buf : 		priv->lib = &iwl_dvm_6030_cfg;
buf : 		break;
buf : 	default:
buf : 		break;
buf : 	}
buf : 
buf : 	if (WARN_ON(!priv->lib))
if (WARN_ON(!priv->lib)) 
buf : 		goto out_free_hw;
buf : 
buf : 	/*
buf : 	 * Populate the state variables that the transport layer needs
buf : 	 * to know about.
buf : 	 */
buf : 	trans_cfg.op_mode = op_mode;
buf : 	trans_cfg.no_reclaim_cmds = no_reclaim_cmds;
buf : 	trans_cfg.n_no_reclaim_cmds = ARRAY_SIZE(no_reclaim_cmds);
buf : 	trans_cfg.rx_buf_size_8k = iwlwifi_mod_params.amsdu_size_8K;
ifi_mod_params.amsdu_size_8K; 
buf : 	if (!iwlwifi_mod_params.wd_disable)
buf : 		trans_cfg.queue_watchdog_timeout =
buf : 			priv->cfg->base_params->wd_timeout;
buf : 	else
buf : 		trans_cfg.queue_watchdog_timeout = IWL_WATCHDOG_DISABLED;
buf : 	trans_cfg.command_names = iwl_dvm_cmd_strings;
buf : 	trans_cfg.cmd_fifo = IWLAGN_CMD_FIFO_NUM;
ifo = IWLAGN_CMD_FIFO_NUM; 
buf : 
buf : 	WARN_ON(sizeof(priv->transport_queue_stop) * BITS_PER_BYTE <
buf : 		priv->cfg->base_params->num_of_queues);
buf : 
buf : 	ucode_flags = fw->ucode_capa.flags;
buf : 
buf : 	if (ucode_flags & IWL_UCODE_TLV_FLAGS_PAN) {
if (ucode_flags & IWL_UCODE_TLV_FLAGS_PAN) { 
buf : 		priv->sta_key_max_num = STA_KEY_MAX_NUM_PAN;
buf : 		trans_cfg.cmd_queue = IWL_IPAN_CMD_QUEUE_NUM;
buf : 	} else {
buf : 		priv->sta_key_max_num = STA_KEY_MAX_NUM;
buf : 		trans_cfg.cmd_queue = IWL_DEFAULT_CMD_QUEUE_NUM;
buf : 	}
buf : 
buf : 	/* Configure transport layer */
buf : 	iwl_trans_configure(priv->trans, &trans_cfg);
buf : 
buf : 	trans->rx_mpdu_cmd = REPLY_RX_MPDU_CMD;
buf : 	trans->rx_mpdu_cmd_hdr_size = sizeof(struct iwl_rx_mpdu_res_start);
buf : 
buf : 	/* At this point both hw and priv are allocated. */
buf : 
buf : 	SET_IEEE80211_DEV(priv->hw, priv->trans->dev);
buf : 
buf : 	iwl_option_config(priv);
buf : 
buf : 	IWL_DEBUG_INFO(priv, "*** LOAD DRIVER ***\n");
buf : 
buf : 	/* is antenna coupling more than 35dB ? */
buf : 	priv->bt_ant_couple_ok =
buf : 		(iwlwifi_mod_params.ant_coupling >
ifi_mod_params.ant_coupling > 
buf : 			IWL_BT_ANTENNA_COUPLING_THRESHOLD) ?
buf : 			true : false;
buf : 
buf : 	/* bt channel inhibition enabled*/
buf : 	priv->bt_ch_announce = true;
buf : 	IWL_DEBUG_INFO(priv, "BT channel inhibition is %s\n",
buf : 		       (priv->bt_ch_announce) ? "On" : "Off");
buf : 
buf : 	/* these spin locks will be used in apm_ops.init and EEPROM access
buf : 	 * we should init now
buf : 	 */
buf : 	spin_lock_init(&priv->statistics.lock);
buf : 
buf : 	/***********************
buf : 	 * 2. Read REV register
buf : 	 ***********************/
buf : 	IWL_INFO(priv, "Detected %s, REV=0x%X\n",
buf : 		priv->cfg->name, priv->trans->hw_rev);
buf : 
buf : 	if (iwl_trans_start_hw(priv->trans))
if (iwl_trans_start_hw(priv->trans)) 
buf : 		goto out_free_hw;
buf : 
buf : 	/* Read the EEPROM */
buf : 	if (iwl_read_eeprom(priv->trans, &priv->eeprom_blob,
if (iwl_read_eeprom(priv->trans, &priv->eeprom_blob, 
buf : 			    &priv->eeprom_blob_size)) {
buf : 		IWL_ERR(priv, "Unable to init EEPROM\n");
buf : 		goto out_free_hw;
buf : 	}
buf : 
buf : 	/* Reset chip to save power until we load uCode during "up". */
buf : 	iwl_trans_stop_device(priv->trans);
buf : 
buf : 	priv->nvm_data = iwl_parse_eeprom_data(priv->trans->dev, priv->cfg,
buf : 						  priv->eeprom_blob,
buf : 						  priv->eeprom_blob_size);
buf : 	if (!priv->nvm_data)
if (!priv->nvm_data) 
buf : 		goto out_free_eeprom_blob;
buf : 
buf : 	if (iwl_nvm_check_version(priv->nvm_data, priv->trans))
if (iwl_nvm_check_version(priv->nvm_data, priv->trans)) 
buf : 		goto out_free_eeprom;
buf : 
buf : 	if (iwl_eeprom_init_hw_params(priv))
if (iwl_eeprom_init_hw_params(priv)) 
buf : 		goto out_free_eeprom;
buf : 
buf : 	/* extract MAC Address */
buf : 	memcpy(priv->addresses[0].addr, priv->nvm_data->hw_addr, ETH_ALEN);
buf : 	IWL_DEBUG_INFO(priv, "MAC address: %pM\n", priv->addresses[0].addr);
buf : 	priv->hw->wiphy->addresses = priv->addresses;
buf : 	priv->hw->wiphy->n_addresses = 1;
buf : 	num_mac = priv->nvm_data->n_hw_addrs;
buf : 	if (num_mac > 1) {
if (num_mac > 1) { 
buf : 		memcpy(priv->addresses[1].addr, priv->addresses[0].addr,
buf : 		       ETH_ALEN);
buf : 		priv->addresses[1].addr[5]++;
buf : 		priv->hw->wiphy->n_addresses++;
buf : 	}
buf : 
buf : 	/************************
buf : 	 * 4. Setup HW constants
buf : 	 ************************/
buf : 	iwl_set_hw_params(priv);
buf : 
buf : 	if (!(priv->nvm_data->sku_cap_ipan_enable)) {
if (!(priv->nvm_data->sku_cap_ipan_enable)) { 
buf : 		IWL_DEBUG_INFO(priv, "Your EEPROM disabled PAN\n");
buf : 		ucode_flags &= ~IWL_UCODE_TLV_FLAGS_PAN;
buf : 		/*
buf : 		 * if not PAN, then don't support P2P -- might be a uCode
if not PAN, then don't support P2P -- might be a uCode 
buf : 		 * packaging bug or due to the eeprom check above
buf : 		 */
buf : 		priv->sta_key_max_num = STA_KEY_MAX_NUM;
buf : 		trans_cfg.cmd_queue = IWL_DEFAULT_CMD_QUEUE_NUM;
buf : 
buf : 		/* Configure transport layer again*/
buf : 		iwl_trans_configure(priv->trans, &trans_cfg);
buf : 	}
buf : 
buf : 	/*******************
buf : 	 * 5. Setup priv
buf : 	 *******************/
buf : 	for (i = 0; i < IWL_MAX_HW_QUEUES; i++) {
for (i = 0; i < IWL_MAX_HW_QUEUES; i++) { 
buf : 		priv->queue_to_mac80211[i] = IWL_INVALID_MAC80211_QUEUE;
buf : 		if (i < IWLAGN_FIRST_AMPDU_QUEUE &&
if (i < IWLAGN_FIRST_AMPDU_QUEUE && 
buf : 		    i != IWL_DEFAULT_CMD_QUEUE_NUM &&
buf : 		    i != IWL_IPAN_CMD_QUEUE_NUM)
buf : 			priv->queue_to_mac80211[i] = i;
buf : 		atomic_set(&priv->queue_stop_count[i], 0);
buf : 	}
buf : 
buf : 	if (iwl_init_drv(priv))
if (iwl_init_drv(priv)) 
buf : 		goto out_free_eeprom;
buf : 
buf : 	/* At this point both hw and priv are initialized. */
buf : 
buf : 	/********************
buf : 	 * 6. Setup services
buf : 	 ********************/
buf : 	iwl_setup_deferred_work(priv);
buf : 	iwl_setup_rx_handlers(priv);
buf : 
buf : 	iwl_power_initialize(priv);
buf : 	iwl_tt_initialize(priv);
buf : 
buf : 	snprintf(priv->hw->wiphy->fw_version,
buf : 		 sizeof(priv->hw->wiphy->fw_version),
buf : 		 "%s", fw->fw_version);
buf : 
buf : 	priv->new_scan_threshold_behaviour =
buf : 		!!(ucode_flags & IWL_UCODE_TLV_FLAGS_NEWSCAN);
buf : 
buf : 	priv->phy_calib_chain_noise_reset_cmd =
buf : 		fw->ucode_capa.standard_phy_calibration_size;
buf : 	priv->phy_calib_chain_noise_gain_cmd =
buf : 		fw->ucode_capa.standard_phy_calibration_size + 1;
buf : 
buf : 	/* initialize all valid contexts */
buf : 	iwl_init_context(priv, ucode_flags);
buf : 
buf : 	/**************************************************
buf : 	 * This is still part of probe() in a sense...
buf : 	 *
buf : 	 * 7. Setup and register with mac80211 and debugfs
buf : 	 **************************************************/
buf : 	if (iwlagn_mac_setup_register(priv, &fw->ucode_capa))
if (iwlagn_mac_setup_register(priv, &fw->ucode_capa)) 
buf : 		goto out_destroy_workqueue;
buf : 
buf : 	if (iwl_dbgfs_register(priv, dbgfs_dir))
if (iwl_dbgfs_register(priv, dbgfs_dir)) 
buf : 		goto out_mac80211_unregister;
buf : 
buf : 	return op_mode;
buf : 
buf : out_mac80211_unregister:
buf : 	iwlagn_mac_unregister(priv);
buf : out_destroy_workqueue:
buf : 	iwl_tt_exit(priv);
buf : 	iwl_cancel_deferred_work(priv);
buf : 	destroy_workqueue(priv->workqueue);
buf : 	priv->workqueue = NULL;
buf : 	iwl_uninit_drv(priv);
buf : out_free_eeprom_blob:
buf : 	kfree(priv->eeprom_blob);
buf : out_free_eeprom:
buf : 	iwl_free_nvm_data(priv->nvm_data);
buf : out_free_hw:
buf : 	ieee80211_free_hw(priv->hw);
buf : out:
buf : 	op_mode = NULL;
buf : 	return op_mode;
buf : }
buf : 
buf : static void iwl_op_mode_dvm_stop(struct iwl_op_mode *op_mode)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 
buf : 	IWL_DEBUG_INFO(priv, "*** UNLOAD DRIVER ***\n");
buf : 
buf : 	iwlagn_mac_unregister(priv);
buf : 
buf : 	iwl_tt_exit(priv);
buf : 
buf : 	kfree(priv->eeprom_blob);
buf : 	iwl_free_nvm_data(priv->nvm_data);
buf : 
buf : 	/*netif_stop_queue(dev); */
if_stop_queue(dev); */ 
buf : 	flush_workqueue(priv->workqueue);
buf : 
buf : 	/* ieee80211_unregister_hw calls iwlagn_mac_stop, which flushes
buf : 	 * priv->workqueue... so we can't take down the workqueue
buf : 	 * until now... */
buf : 	destroy_workqueue(priv->workqueue);
buf : 	priv->workqueue = NULL;
buf : 
buf : 	iwl_uninit_drv(priv);
buf : 
buf : 	dev_kfree_skb(priv->beacon_skb);
buf : 
buf : 	iwl_trans_op_mode_leave(priv->trans);
buf : 	ieee80211_free_hw(priv->hw);
buf : }
buf : 
buf : static const char * const desc_lookup_text[] = {
buf : 	"OK",
buf : 	"FAIL",
buf : 	"BAD_PARAM",
buf : 	"BAD_CHECKSUM",
buf : 	"NMI_INTERRUPT_WDG",
buf : 	"SYSASSERT",
buf : 	"FATAL_ERROR",
buf : 	"BAD_COMMAND",
buf : 	"HW_ERROR_TUNE_LOCK",
buf : 	"HW_ERROR_TEMPERATURE",
buf : 	"ILLEGAL_CHAN_FREQ",
buf : 	"VCC_NOT_STABLE",
buf : 	"FH_ERROR",
buf : 	"NMI_INTERRUPT_HOST",
buf : 	"NMI_INTERRUPT_ACTION_PT",
buf : 	"NMI_INTERRUPT_UNKNOWN",
buf : 	"UCODE_VERSION_MISMATCH",
buf : 	"HW_ERROR_ABS_LOCK",
buf : 	"HW_ERROR_CAL_LOCK_FAIL",
buf : 	"NMI_INTERRUPT_INST_ACTION_PT",
buf : 	"NMI_INTERRUPT_DATA_ACTION_PT",
buf : 	"NMI_TRM_HW_ER",
buf : 	"NMI_INTERRUPT_TRM",
buf : 	"NMI_INTERRUPT_BREAK_POINT",
buf : 	"DEBUG_0",
buf : 	"DEBUG_1",
buf : 	"DEBUG_2",
buf : 	"DEBUG_3",
buf : };
buf : 
buf : static struct { char *name; u8 num; } advanced_lookup[] = {
buf : 	{ "NMI_INTERRUPT_WDG", 0x34 },
buf : 	{ "SYSASSERT", 0x35 },
buf : 	{ "UCODE_VERSION_MISMATCH", 0x37 },
buf : 	{ "BAD_COMMAND", 0x38 },
buf : 	{ "NMI_INTERRUPT_DATA_ACTION_PT", 0x3C },
buf : 	{ "FATAL_ERROR", 0x3D },
buf : 	{ "NMI_TRM_HW_ERR", 0x46 },
buf : 	{ "NMI_INTERRUPT_TRM", 0x4C },
buf : 	{ "NMI_INTERRUPT_BREAK_POINT", 0x54 },
buf : 	{ "NMI_INTERRUPT_WDG_RXF_FULL", 0x5C },
buf : 	{ "NMI_INTERRUPT_WDG_NO_RBD_RXF_FULL", 0x64 },
buf : 	{ "NMI_INTERRUPT_HOST", 0x66 },
buf : 	{ "NMI_INTERRUPT_ACTION_PT", 0x7C },
buf : 	{ "NMI_INTERRUPT_UNKNOWN", 0x84 },
buf : 	{ "NMI_INTERRUPT_INST_ACTION_PT", 0x86 },
buf : 	{ "ADVANCED_SYSASSERT", 0 },
buf : };
buf : 
buf : static const char *desc_lookup(u32 num)
buf : {
buf : 	int i;
buf : 	int max = ARRAY_SIZE(desc_lookup_text);
buf : 
buf : 	if (num < max)
if (num < max) 
buf : 		return desc_lookup_text[num];
buf : 
buf : 	max = ARRAY_SIZE(advanced_lookup) - 1;
buf : 	for (i = 0; i < max; i++) {
for (i = 0; i < max; i++) { 
buf : 		if (advanced_lookup[i].num == num)
buf : 			break;
buf : 	}
buf : 	return advanced_lookup[i].name;
buf : }
buf : 
buf : #define ERROR_START_OFFSET  (1 * sizeof(u32))
buf : #define ERROR_ELEM_SIZE     (7 * sizeof(u32))
buf : 
buf : static void iwl_dump_nic_error_log(struct iwl_priv *priv)
buf : {
buf : 	struct iwl_trans *trans = priv->trans;
buf : 	u32 base;
buf : 	struct iwl_error_event_table table;
buf : 
buf : 	base = priv->device_pointers.error_event_table;
buf : 	if (priv->cur_ucode == IWL_UCODE_INIT) {
if (priv->cur_ucode == IWL_UCODE_INIT) { 
buf : 		if (!base)
buf : 			base = priv->fw->init_errlog_ptr;
buf : 	} else {
buf : 		if (!base)
if (!base) 
buf : 			base = priv->fw->inst_errlog_ptr;
buf : 	}
buf : 
buf : 	if (!iwlagn_hw_valid_rtc_data_addr(base)) {
if (!iwlagn_hw_valid_rtc_data_addr(base)) { 
buf : 		IWL_ERR(priv,
buf : 			"Not valid error log pointer 0x%08X for %s uCode\n",
for %s uCode\n", 
buf : 			base,
buf : 			(priv->cur_ucode == IWL_UCODE_INIT)
buf : 					? "Init" : "RT");
buf : 		return;
buf : 	}
buf : 
buf : 	/*TODO: Update dbgfs with ISR error stats obtained below */
buf : 	iwl_trans_read_mem_bytes(trans, base, &table, sizeof(table));
buf : 
buf : 	if (ERROR_START_OFFSET <= table.valid * ERROR_ELEM_SIZE) {
if (ERROR_START_OFFSET <= table.valid * ERROR_ELEM_SIZE) { 
buf : 		IWL_ERR(trans, "Start IWL Error Log Dump:\n");
buf : 		IWL_ERR(trans, "Status: 0x%08lX, count: %d\n",
buf : 			priv->status, table.valid);
buf : 	}
buf : 
buf : 	trace_iwlwifi_dev_ucode_error(trans->dev, table.error_id, table.tsf_low,
ifi_dev_ucode_error(trans->dev, table.error_id, table.tsf_low, 
buf : 				      table.data1, table.data2, table.line,
buf : 				      table.blink1, table.blink2, table.ilink1,
buf : 				      table.ilink2, table.bcon_time, table.gp1,
buf : 				      table.gp2, table.gp3, table.ucode_ver,
buf : 				      table.hw_ver, table.brd_ver);
buf : 	IWL_ERR(priv, "0x%08X | %-28s\n", table.error_id,
buf : 		desc_lookup(table.error_id));
buf : 	IWL_ERR(priv, "0x%08X | uPc\n", table.pc);
buf : 	IWL_ERR(priv, "0x%08X | branchlink1\n", table.blink1);
buf : 	IWL_ERR(priv, "0x%08X | branchlink2\n", table.blink2);
buf : 	IWL_ERR(priv, "0x%08X | interruptlink1\n", table.ilink1);
buf : 	IWL_ERR(priv, "0x%08X | interruptlink2\n", table.ilink2);
buf : 	IWL_ERR(priv, "0x%08X | data1\n", table.data1);
buf : 	IWL_ERR(priv, "0x%08X | data2\n", table.data2);
buf : 	IWL_ERR(priv, "0x%08X | line\n", table.line);
buf : 	IWL_ERR(priv, "0x%08X | beacon time\n", table.bcon_time);
buf : 	IWL_ERR(priv, "0x%08X | tsf low\n", table.tsf_low);
buf : 	IWL_ERR(priv, "0x%08X | tsf hi\n", table.tsf_hi);
buf : 	IWL_ERR(priv, "0x%08X | time gp1\n", table.gp1);
buf : 	IWL_ERR(priv, "0x%08X | time gp2\n", table.gp2);
buf : 	IWL_ERR(priv, "0x%08X | time gp3\n", table.gp3);
buf : 	IWL_ERR(priv, "0x%08X | uCode version\n", table.ucode_ver);
buf : 	IWL_ERR(priv, "0x%08X | hw version\n", table.hw_ver);
buf : 	IWL_ERR(priv, "0x%08X | board version\n", table.brd_ver);
buf : 	IWL_ERR(priv, "0x%08X | hcmd\n", table.hcmd);
buf : 	IWL_ERR(priv, "0x%08X | isr0\n", table.isr0);
buf : 	IWL_ERR(priv, "0x%08X | isr1\n", table.isr1);
buf : 	IWL_ERR(priv, "0x%08X | isr2\n", table.isr2);
buf : 	IWL_ERR(priv, "0x%08X | isr3\n", table.isr3);
buf : 	IWL_ERR(priv, "0x%08X | isr4\n", table.isr4);
buf : 	IWL_ERR(priv, "0x%08X | isr_pref\n", table.isr_pref);
buf : 	IWL_ERR(priv, "0x%08X | wait_event\n", table.wait_event);
buf : 	IWL_ERR(priv, "0x%08X | l2p_control\n", table.l2p_control);
buf : 	IWL_ERR(priv, "0x%08X | l2p_duration\n", table.l2p_duration);
buf : 	IWL_ERR(priv, "0x%08X | l2p_mhvalid\n", table.l2p_mhvalid);
buf : 	IWL_ERR(priv, "0x%08X | l2p_addr_match\n", table.l2p_addr_match);
buf : 	IWL_ERR(priv, "0x%08X | lmpm_pmg_sel\n", table.lmpm_pmg_sel);
buf : 	IWL_ERR(priv, "0x%08X | timestamp\n", table.u_timestamp);
buf : 	IWL_ERR(priv, "0x%08X | flow_handler\n", table.flow_handler);
buf : }
buf : 
buf : #define EVENT_START_OFFSET  (4 * sizeof(u32))
buf : 
buf : /**
buf :  * iwl_print_event_log - Dump error event log to syslog
buf :  *
buf :  */
buf : static int iwl_print_event_log(struct iwl_priv *priv, u32 start_idx,
buf : 			       u32 num_events, u32 mode,
buf : 			       int pos, char **buf, size_t bufsz)
buf : {
buf : 	u32 i;
buf : 	u32 base;       /* SRAM byte address of event log header */
buf : 	u32 event_size; /* 2 u32s, or 3 u32s if timestamp recorded */
if timestamp recorded */ 
buf : 	u32 ptr;        /* SRAM byte address of log data */
buf : 	u32 ev, time, data; /* event log data */
buf : 	unsigned long reg_flags;
buf : 
buf : 	struct iwl_trans *trans = priv->trans;
buf : 
buf : 	if (num_events == 0)
if (num_events == 0) 
buf : 		return pos;
buf : 
buf : 	base = priv->device_pointers.log_event_table;
buf : 	if (priv->cur_ucode == IWL_UCODE_INIT) {
if (priv->cur_ucode == IWL_UCODE_INIT) { 
buf : 		if (!base)
buf : 			base = priv->fw->init_evtlog_ptr;
buf : 	} else {
buf : 		if (!base)
if (!base) 
buf : 			base = priv->fw->inst_evtlog_ptr;
buf : 	}
buf : 
buf : 	if (mode == 0)
if (mode == 0) 
buf : 		event_size = 2 * sizeof(u32);
buf : 	else
buf : 		event_size = 3 * sizeof(u32);
buf : 
buf : 	ptr = base + EVENT_START_OFFSET + (start_idx * event_size);
buf : 
buf : 	/* Make sure device is powered up for SRAM reads */
for SRAM reads */ 
buf : 	if (!iwl_trans_grab_nic_access(trans, false, &reg_flags))
buf : 		return pos;
buf : 
buf : 	/* Set starting address; reads will auto-increment */
buf : 	iwl_write32(trans, HBUS_TARG_MEM_RADDR, ptr);
buf : 
buf : 	/* "time" is actually "data" for mode 0 (no timestamp).
for mode 0 (no timestamp). 
buf : 	* place event id # at far right for easier visual parsing. */
buf : 	for (i = 0; i < num_events; i++) {
for (i = 0; i < num_events; i++) { 
buf : 		ev = iwl_read32(trans, HBUS_TARG_MEM_RDAT);
buf : 		time = iwl_read32(trans, HBUS_TARG_MEM_RDAT);
buf : 		if (mode == 0) {
if (mode == 0) { 
buf : 			/* data, ev */
buf : 			if (bufsz) {
if (bufsz) { 
buf : 				pos += scnprintf(*buf + pos, bufsz - pos,
buf : 						"EVT_LOG:0x%08x:%04u\n",
buf : 						time, ev);
buf : 			} else {
buf : 				trace_iwlwifi_dev_ucode_event(trans->dev, 0,
ifi_dev_ucode_event(trans->dev, 0, 
buf : 					time, ev);
buf : 				IWL_ERR(priv, "EVT_LOG:0x%08x:%04u\n",
buf : 					time, ev);
buf : 			}
buf : 		} else {
buf : 			data = iwl_read32(trans, HBUS_TARG_MEM_RDAT);
buf : 			if (bufsz) {
if (bufsz) { 
buf : 				pos += scnprintf(*buf + pos, bufsz - pos,
buf : 						"EVT_LOGT:%010u:0x%08x:%04u\n",
buf : 						 time, data, ev);
buf : 			} else {
buf : 				IWL_ERR(priv, "EVT_LOGT:%010u:0x%08x:%04u\n",
buf : 					time, data, ev);
buf : 				trace_iwlwifi_dev_ucode_event(trans->dev, time,
ifi_dev_ucode_event(trans->dev, time, 
buf : 					data, ev);
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	/* Allow device to power down */
buf : 	iwl_trans_release_nic_access(trans, &reg_flags);
buf : 	return pos;
buf : }
buf : 
buf : /**
buf :  * iwl_print_last_event_logs - Dump the newest # of event log to syslog
buf :  */
buf : static int iwl_print_last_event_logs(struct iwl_priv *priv, u32 capacity,
buf : 				    u32 num_wraps, u32 next_entry,
buf : 				    u32 size, u32 mode,
buf : 				    int pos, char **buf, size_t bufsz)
buf : {
buf : 	/*
buf : 	 * display the newest DEFAULT_LOG_ENTRIES entries
buf : 	 * i.e the entries just before the next ont that uCode would fill.
fore the next ont that uCode would fill. 
buf : 	 */
buf : 	if (num_wraps) {
if (num_wraps) { 
buf : 		if (next_entry < size) {
buf : 			pos = iwl_print_event_log(priv,
buf : 						capacity - (size - next_entry),
buf : 						size - next_entry, mode,
buf : 						pos, buf, bufsz);
buf : 			pos = iwl_print_event_log(priv, 0,
buf : 						  next_entry, mode,
buf : 						  pos, buf, bufsz);
buf : 		} else
buf : 			pos = iwl_print_event_log(priv, next_entry - size,
buf : 						  size, mode, pos, buf, bufsz);
buf : 	} else {
buf : 		if (next_entry < size) {
if (next_entry < size) { 
buf : 			pos = iwl_print_event_log(priv, 0, next_entry,
buf : 						  mode, pos, buf, bufsz);
buf : 		} else {
buf : 			pos = iwl_print_event_log(priv, next_entry - size,
buf : 						  size, mode, pos, buf, bufsz);
buf : 		}
buf : 	}
buf : 	return pos;
buf : }
buf : 
buf : #define DEFAULT_DUMP_EVENT_LOG_ENTRIES (20)
buf : 
buf : int iwl_dump_nic_event_log(struct iwl_priv *priv, bool full_log,
buf : 			    char **buf)
buf : {
buf : 	u32 base;       /* SRAM byte address of event log header */
buf : 	u32 capacity;   /* event log capacity in # entries */
buf : 	u32 mode;       /* 0 - no timestamp, 1 - timestamp recorded */
buf : 	u32 num_wraps;  /* # times uCode wrapped to top of log */
buf : 	u32 next_entry; /* index of next entry to be written by uCode */
buf : 	u32 size;       /* # entries that we'll print */
buf : 	u32 logsize;
buf : 	int pos = 0;
buf : 	size_t bufsz = 0;
buf : 	struct iwl_trans *trans = priv->trans;
buf : 
buf : 	base = priv->device_pointers.log_event_table;
buf : 	if (priv->cur_ucode == IWL_UCODE_INIT) {
if (priv->cur_ucode == IWL_UCODE_INIT) { 
buf : 		logsize = priv->fw->init_evtlog_size;
buf : 		if (!base)
if (!base) 
buf : 			base = priv->fw->init_evtlog_ptr;
buf : 	} else {
buf : 		logsize = priv->fw->inst_evtlog_size;
buf : 		if (!base)
if (!base) 
buf : 			base = priv->fw->inst_evtlog_ptr;
buf : 	}
buf : 
buf : 	if (!iwlagn_hw_valid_rtc_data_addr(base)) {
if (!iwlagn_hw_valid_rtc_data_addr(base)) { 
buf : 		IWL_ERR(priv,
buf : 			"Invalid event log pointer 0x%08X for %s uCode\n",
for %s uCode\n", 
buf : 			base,
buf : 			(priv->cur_ucode == IWL_UCODE_INIT)
buf : 					? "Init" : "RT");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	/* event log header */
buf : 	capacity = iwl_trans_read_mem32(trans, base);
buf : 	mode = iwl_trans_read_mem32(trans, base + (1 * sizeof(u32)));
buf : 	num_wraps = iwl_trans_read_mem32(trans, base + (2 * sizeof(u32)));
buf : 	next_entry = iwl_trans_read_mem32(trans, base + (3 * sizeof(u32)));
buf : 
buf : 	if (capacity > logsize) {
if (capacity > logsize) { 
buf : 		IWL_ERR(priv, "Log capacity %d is bogus, limit to %d "
buf : 			"entries\n", capacity, logsize);
buf : 		capacity = logsize;
buf : 	}
buf : 
buf : 	if (next_entry > logsize) {
if (next_entry > logsize) { 
buf : 		IWL_ERR(priv, "Log write index %d is bogus, limit to %d\n",
buf : 			next_entry, logsize);
buf : 		next_entry = logsize;
buf : 	}
buf : 
buf : 	size = num_wraps ? capacity : next_entry;
buf : 
buf : 	/* bail out if nothing in log */
if nothing in log */ 
buf : 	if (size == 0) {
buf : 		IWL_ERR(trans, "Start IWL Event Log Dump: nothing in log\n");
buf : 		return pos;
buf : 	}
buf : 
buf : 	if (!(iwl_have_debug_level(IWL_DL_FW_ERRORS)) && !full_log)
if (!(iwl_have_debug_level(IWL_DL_FW_ERRORS)) && !full_log) 
buf : 		size = (size > DEFAULT_DUMP_EVENT_LOG_ENTRIES)
buf : 			? DEFAULT_DUMP_EVENT_LOG_ENTRIES : size;
buf : 	IWL_ERR(priv, "Start IWL Event Log Dump: display last %u entries\n",
buf : 		size);
buf : 
buf : #ifdef CONFIG_IWLWIFI_DEBUG
ifdef CONFIG_IWLWIFI_DEBUG 
buf : 	if (buf) {
buf : 		if (full_log)
if (full_log) 
buf : 			bufsz = capacity * 48;
buf : 		else
buf : 			bufsz = size * 48;
buf : 		*buf = kmalloc(bufsz, GFP_KERNEL);
buf : 		if (!*buf)
if (!*buf) 
buf : 			return -ENOMEM;
buf : 	}
buf : 	if (iwl_have_debug_level(IWL_DL_FW_ERRORS) || full_log) {
if (iwl_have_debug_level(IWL_DL_FW_ERRORS) || full_log) { 
buf : 		/*
buf : 		 * if uCode has wrapped back to top of log,
if uCode has wrapped back to top of log, 
buf : 		 * start at the oldest entry,
buf : 		 * i.e the next one that uCode would fill.
buf : 		 */
buf : 		if (num_wraps)
if (num_wraps) 
buf : 			pos = iwl_print_event_log(priv, next_entry,
buf : 						capacity - next_entry, mode,
buf : 						pos, buf, bufsz);
buf : 		/* (then/else) start at top of log */
buf : 		pos = iwl_print_event_log(priv, 0,
buf : 					  next_entry, mode, pos, buf, bufsz);
buf : 	} else
buf : 		pos = iwl_print_last_event_logs(priv, capacity, num_wraps,
buf : 						next_entry, size, mode,
buf : 						pos, buf, bufsz);
buf : #else
buf : 	pos = iwl_print_last_event_logs(priv, capacity, num_wraps,
buf : 					next_entry, size, mode,
buf : 					pos, buf, bufsz);
buf : #endif
if 
buf : 	return pos;
buf : }
buf : 
buf : static void iwlagn_fw_error(struct iwl_priv *priv, bool ondemand)
buf : {
buf : 	unsigned int reload_msec;
buf : 	unsigned long reload_jiffies;
iffies; 
buf : 
buf : 	if (iwl_have_debug_level(IWL_DL_FW_ERRORS))
buf : 		iwl_print_rx_config_cmd(priv, IWL_RXON_CTX_BSS);
buf : 
buf : 	/* uCode is no longer loaded. */
buf : 	priv->ucode_loaded = false;
buf : 
buf : 	/* Set the FW error flag -- cleared on iwl_down */
buf : 	set_bit(STATUS_FW_ERROR, &priv->status);
buf : 
buf : 	iwl_abort_notification_waits(&priv->notif_wait);
ification_waits(&priv->notif_wait); 
buf : 
buf : 	/* Keep the restart process from trying to send host
buf : 	 * commands by clearing the ready bit */
buf : 	clear_bit(STATUS_READY, &priv->status);
buf : 
buf : 	if (!ondemand) {
if (!ondemand) { 
buf : 		/*
buf : 		 * If firmware keep reloading, then it indicate something
buf : 		 * serious wrong and firmware having problem to recover
buf : 		 * from it. Instead of keep trying which will fill the syslog
buf : 		 * and hang the system, let's just stop it
buf : 		 */
buf : 		reload_jiffies = jiffies;
iffies = jiffies; 
buf : 		reload_msec = jiffies_to_msecs((long) reload_jiffies -
buf : 					(long) priv->reload_jiffies);
iffies); 
buf : 		priv->reload_jiffies = reload_jiffies;
buf : 		if (reload_msec <= IWL_MIN_RELOAD_DURATION) {
if (reload_msec <= IWL_MIN_RELOAD_DURATION) { 
buf : 			priv->reload_count++;
buf : 			if (priv->reload_count >= IWL_MAX_CONTINUE_RELOAD_CNT) {
if (priv->reload_count >= IWL_MAX_CONTINUE_RELOAD_CNT) { 
buf : 				IWL_ERR(priv, "BUG_ON, Stop restarting\n");
buf : 				return;
buf : 			}
buf : 		} else
buf : 			priv->reload_count = 0;
buf : 	}
buf : 
buf : 	if (!test_bit(STATUS_EXIT_PENDING, &priv->status)) {
if (!test_bit(STATUS_EXIT_PENDING, &priv->status)) { 
buf : 		if (iwlwifi_mod_params.restart_fw) {
buf : 			IWL_DEBUG_FW_ERRORS(priv,
buf : 				  "Restarting adapter due to uCode error.\n");
buf : 			queue_work(priv->workqueue, &priv->restart);
buf : 		} else
buf : 			IWL_DEBUG_FW_ERRORS(priv,
buf : 				  "Detected FW error, but not restarting\n");
buf : 	}
buf : }
buf : 
buf : static void iwl_nic_error(struct iwl_op_mode *op_mode)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 
buf : 	IWL_ERR(priv, "Loaded firmware version: %s\n",
buf : 		priv->fw->fw_version);
buf : 
buf : 	iwl_dump_nic_error_log(priv);
buf : 	iwl_dump_nic_event_log(priv, false, NULL);
buf : 
buf : 	iwlagn_fw_error(priv, false);
buf : }
buf : 
buf : static void iwl_cmd_queue_full(struct iwl_op_mode *op_mode)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 
buf : 	if (!iwl_check_for_ct_kill(priv)) {
if (!iwl_check_for_ct_kill(priv)) { 
buf : 		IWL_ERR(priv, "Restarting adapter queue is full\n");
buf : 		iwlagn_fw_error(priv, false);
buf : 	}
buf : }
buf : 
buf : #define EEPROM_RF_CONFIG_TYPE_MAX      0x3
buf : 
buf : static void iwl_nic_config(struct iwl_op_mode *op_mode)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 
buf : 	/* SKU Control */
buf : 	iwl_trans_set_bits_mask(priv->trans, CSR_HW_IF_CONFIG_REG,
buf : 				CSR_HW_IF_CONFIG_REG_MSK_MAC_DASH |
buf : 				CSR_HW_IF_CONFIG_REG_MSK_MAC_STEP,
buf : 				(CSR_HW_REV_STEP(priv->trans->hw_rev) <<
buf : 					CSR_HW_IF_CONFIG_REG_POS_MAC_STEP) |
buf : 				(CSR_HW_REV_DASH(priv->trans->hw_rev) <<
buf : 					CSR_HW_IF_CONFIG_REG_POS_MAC_DASH));
buf : 
buf : 	/* write radio config values to register */
buf : 	if (priv->nvm_data->radio_cfg_type <= EEPROM_RF_CONFIG_TYPE_MAX) {
if (priv->nvm_data->radio_cfg_type <= EEPROM_RF_CONFIG_TYPE_MAX) { 
buf : 		u32 reg_val =
buf : 			priv->nvm_data->radio_cfg_type <<
buf : 				CSR_HW_IF_CONFIG_REG_POS_PHY_TYPE |
buf : 			priv->nvm_data->radio_cfg_step <<
buf : 				CSR_HW_IF_CONFIG_REG_POS_PHY_STEP |
buf : 			priv->nvm_data->radio_cfg_dash <<
buf : 				CSR_HW_IF_CONFIG_REG_POS_PHY_DASH;
buf : 
buf : 		iwl_trans_set_bits_mask(priv->trans, CSR_HW_IF_CONFIG_REG,
buf : 					CSR_HW_IF_CONFIG_REG_MSK_PHY_TYPE |
buf : 					CSR_HW_IF_CONFIG_REG_MSK_PHY_STEP |
buf : 					CSR_HW_IF_CONFIG_REG_MSK_PHY_DASH,
buf : 					reg_val);
buf : 
buf : 		IWL_INFO(priv, "Radio type=0x%x-0x%x-0x%x\n",
buf : 			 priv->nvm_data->radio_cfg_type,
buf : 			 priv->nvm_data->radio_cfg_step,
buf : 			 priv->nvm_data->radio_cfg_dash);
buf : 	} else {
buf : 		WARN_ON(1);
buf : 	}
buf : 
buf : 	/* set CSR_HW_CONFIG_REG for uCode use */
for uCode use */ 
buf : 	iwl_set_bit(priv->trans, CSR_HW_IF_CONFIG_REG,
buf : 		    CSR_HW_IF_CONFIG_REG_BIT_RADIO_SI |
buf : 		    CSR_HW_IF_CONFIG_REG_BIT_MAC_SI);
buf : 
buf : 	/* W/A : NIC is stuck in a reset state after Early PCIe power off
buf : 	 * (PCIe power is lost before PERST# is asserted),
fore PERST# is asserted), 
buf : 	 * causing ME FW to lose ownership and not being able to obtain it back.
buf : 	 */
buf : 	iwl_set_bits_mask_prph(priv->trans, APMG_PS_CTRL_REG,
buf : 			       APMG_PS_CTRL_EARLY_PWR_OFF_RESET_DIS,
buf : 			       ~APMG_PS_CTRL_EARLY_PWR_OFF_RESET_DIS);
buf : 
buf : 	if (priv->lib->nic_config)
if (priv->lib->nic_config) 
buf : 		priv->lib->nic_config(priv);
buf : }
buf : 
buf : static void iwl_wimax_active(struct iwl_op_mode *op_mode)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 
buf : 	clear_bit(STATUS_READY, &priv->status);
buf : 	IWL_ERR(priv, "RF is used by WiMAX\n");
buf : }
buf : 
buf : static void iwl_stop_sw_queue(struct iwl_op_mode *op_mode, int queue)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 	int mq = priv->queue_to_mac80211[queue];
buf : 
buf : 	if (WARN_ON_ONCE(mq == IWL_INVALID_MAC80211_QUEUE))
if (WARN_ON_ONCE(mq == IWL_INVALID_MAC80211_QUEUE)) 
buf : 		return;
buf : 
buf : 	if (atomic_inc_return(&priv->queue_stop_count[mq]) > 1) {
if (atomic_inc_return(&priv->queue_stop_count[mq]) > 1) { 
buf : 		IWL_DEBUG_TX_QUEUES(priv,
buf : 			"queue %d (mac80211 %d) already stopped\n",
buf : 			queue, mq);
buf : 		return;
buf : 	}
buf : 
buf : 	set_bit(mq, &priv->transport_queue_stop);
buf : 	ieee80211_stop_queue(priv->hw, mq);
buf : }
buf : 
buf : static void iwl_wake_sw_queue(struct iwl_op_mode *op_mode, int queue)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 	int mq = priv->queue_to_mac80211[queue];
buf : 
buf : 	if (WARN_ON_ONCE(mq == IWL_INVALID_MAC80211_QUEUE))
if (WARN_ON_ONCE(mq == IWL_INVALID_MAC80211_QUEUE)) 
buf : 		return;
buf : 
buf : 	if (atomic_dec_return(&priv->queue_stop_count[mq]) > 0) {
if (atomic_dec_return(&priv->queue_stop_count[mq]) > 0) { 
buf : 		IWL_DEBUG_TX_QUEUES(priv,
buf : 			"queue %d (mac80211 %d) already awake\n",
buf : 			queue, mq);
buf : 		return;
buf : 	}
buf : 
buf : 	clear_bit(mq, &priv->transport_queue_stop);
buf : 
buf : 	if (!priv->passive_no_rx)
if (!priv->passive_no_rx) 
buf : 		ieee80211_wake_queue(priv->hw, mq);
buf : }
buf : 
buf : void iwlagn_lift_passive_no_rx(struct iwl_priv *priv)
ift_passive_no_rx(struct iwl_priv *priv) 
buf : {
buf : 	int mq;
buf : 
buf : 	if (!priv->passive_no_rx)
if (!priv->passive_no_rx) 
buf : 		return;
buf : 
buf : 	for (mq = 0; mq < IWLAGN_FIRST_AMPDU_QUEUE; mq++) {
for (mq = 0; mq < IWLAGN_FIRST_AMPDU_QUEUE; mq++) { 
buf : 		if (!test_bit(mq, &priv->transport_queue_stop)) {
buf : 			IWL_DEBUG_TX_QUEUES(priv, "Wake queue %d\n", mq);
buf : 			ieee80211_wake_queue(priv->hw, mq);
buf : 		} else {
buf : 			IWL_DEBUG_TX_QUEUES(priv, "Don't wake queue %d\n", mq);
buf : 		}
buf : 	}
buf : 
buf : 	priv->passive_no_rx = false;
buf : }
buf : 
buf : static void iwl_free_skb(struct iwl_op_mode *op_mode, struct sk_buff *skb)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 	struct ieee80211_tx_info *info;
buf : 
buf : 	info = IEEE80211_SKB_CB(skb);
buf : 	iwl_trans_free_tx_cmd(priv->trans, info->driver_data[1]);
buf : 	ieee80211_free_txskb(priv->hw, skb);
buf : }
buf : 
buf : static bool iwl_set_hw_rfkill_state(struct iwl_op_mode *op_mode, bool state)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 
buf : 	if (state)
if (state) 
buf : 		set_bit(STATUS_RF_KILL_HW, &priv->status);
buf : 	else
buf : 		clear_bit(STATUS_RF_KILL_HW, &priv->status);
buf : 
buf : 	wiphy_rfkill_set_hw_state(priv->hw->wiphy, state);
buf : 
buf : 	return false;
buf : }
buf : 
buf : static void iwl_napi_add(struct iwl_op_mode *op_mode,
buf : 			 struct napi_struct *napi,
buf : 			 struct net_device *napi_dev,
buf : 			 int (*poll)(struct napi_struct *, int),
buf : 			 int weight)
buf : {
buf : 	struct iwl_priv *priv = IWL_OP_MODE_GET_DVM(op_mode);
buf : 
buf : 	ieee80211_napi_add(priv->hw, napi, napi_dev, poll, weight);
buf : }
buf : 
buf : static const struct iwl_op_mode_ops iwl_dvm_ops = {
buf : 	.start = iwl_op_mode_dvm_start,
buf : 	.stop = iwl_op_mode_dvm_stop,
buf : 	.rx = iwl_rx_dispatch,
buf : 	.queue_full = iwl_stop_sw_queue,
buf : 	.queue_not_full = iwl_wake_sw_queue,
buf : 	.hw_rf_kill = iwl_set_hw_rfkill_state,
buf : 	.free_skb = iwl_free_skb,
buf : 	.nic_error = iwl_nic_error,
buf : 	.cmd_queue_full = iwl_cmd_queue_full,
buf : 	.nic_config = iwl_nic_config,
buf : 	.wimax_active = iwl_wimax_active,
buf : 	.napi_add = iwl_napi_add,
buf : };
buf : 
buf : /*****************************************************************************
buf :  *
buf :  * driver and module entry point
buf :  *
buf :  *****************************************************************************/
buf : static int __init iwl_init(void)
buf : {
buf : 
buf : 	int ret;
buf : 
buf : 	ret = iwlagn_rate_control_register();
buf : 	if (ret) {
if (ret) { 
buf : 		pr_err("Unable to register rate control algorithm: %d\n", ret);
buf : 		return ret;
buf : 	}
buf : 
buf : 	ret = iwl_opmode_register("iwldvm", &iwl_dvm_ops);
buf : 	if (ret) {
if (ret) { 
buf : 		pr_err("Unable to register op_mode: %d\n", ret);
buf : 		iwlagn_rate_control_unregister();
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : module_init(iwl_init);
buf : 
buf : static void __exit iwl_exit(void)
buf : {
buf : 	iwl_opmode_deregister("iwldvm");
buf : 	iwlagn_rate_control_unregister();
buf : }
buf : module_exit(iwl_exit);
file : ./test/kernel/drivers/net/wireless/p54/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * mac80211 glue code for mac80211 Prism54 drivers
for mac80211 Prism54 drivers 
buf :  *
buf :  * Copyright (c) 2006, Michael Wu <flamingice@sourmilk.net>
buf :  * Copyright (c) 2007-2009, Christian Lamparter <chunkeey@web.de>
buf :  * Copyright 2008, Johannes Berg <johannes@sipsolutions.net>
buf :  *
buf :  * Based on:
buf :  * - the islsm (softmac prism54) driver, which is:
buf :  *   Copyright 2004-2006 Jean-Baptiste Note <jbnote@gmail.com>, et al.
buf :  * - stlc45xx driver
buf :  *   Copyright (C) 2008 Nokia Corporation and/or its subsidiary(-ies).
buf :  *
buf :  * This program is free software; you can redistribute it and/or modify
ify 
buf :  * it under the terms of the GNU General Public License version 2 as
buf :  * published by the Free Software Foundation.
buf :  */
buf : 
buf : #include <linux/slab.h>
buf : #include <linux/firmware.h>
buf : #include <linux/etherdevice.h>
buf : #include <linux/module.h>
buf : 
buf : #include <net/mac80211.h>
buf : 
buf : #include "p54.h"
buf : #include "lmac.h"
buf : 
buf : static bool modparam_nohwcrypt;
buf : module_param_named(nohwcrypt, modparam_nohwcrypt, bool, S_IRUGO);
buf : MODULE_PARM_DESC(nohwcrypt, "Disable hardware encryption.");
buf : MODULE_AUTHOR("Michael Wu <flamingice@sourmilk.net>");
buf : MODULE_DESCRIPTION("Softmac Prism54 common code");
buf : MODULE_LICENSE("GPL");
buf : MODULE_ALIAS("prism54common");
buf : 
buf : static int p54_sta_add_remove(struct ieee80211_hw *hw,
buf : 			      struct ieee80211_vif *vif,
if *vif, 
buf : 			      struct ieee80211_sta *sta)
buf : {
buf : 	struct p54_common *priv = hw->priv;
buf : 
buf : 	/*
buf : 	 * Notify the firmware that we don't want or we don't
ify the firmware that we don't want or we don't 
buf : 	 * need to buffer frames for this station anymore.
for this station anymore. 
buf : 	 */
buf : 
buf : 	p54_sta_unlock(priv, sta->addr);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void p54_sta_notify(struct ieee80211_hw *dev, struct ieee80211_vif *vif,
ify(struct ieee80211_hw *dev, struct ieee80211_vif *vif, 
buf : 			      enum sta_notify_cmd notify_cmd,
buf : 			      struct ieee80211_sta *sta)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 
buf : 	switch (notify_cmd) {
ify_cmd) { 
buf : 	case STA_NOTIFY_AWAKE:
buf : 		/* update the firmware's filter table */
buf : 		p54_sta_unlock(priv, sta->addr);
buf : 		break;
buf : 	default:
buf : 		break;
buf : 	}
buf : }
buf : 
buf : static int p54_set_tim(struct ieee80211_hw *dev, struct ieee80211_sta *sta,
buf : 			bool set)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 
buf : 	return p54_update_beacon_tim(priv, sta->aid, set);
buf : }
buf : 
buf : u8 *p54_find_ie(struct sk_buff *skb, u8 ie)
buf : {
buf : 	struct ieee80211_mgmt *mgmt = (void *)skb->data;
buf : 	u8 *pos, *end;
buf : 
buf : 	if (skb->len <= sizeof(mgmt))
if (skb->len <= sizeof(mgmt)) 
buf : 		return NULL;
buf : 
buf : 	pos = (u8 *)mgmt->u.beacon.variable;
buf : 	end = skb->data + skb->len;
buf : 	while (pos < end) {
while (pos < end) { 
buf : 		if (pos + 2 + pos[1] > end)
buf : 			return NULL;
buf : 
buf : 		if (pos[0] == ie)
if (pos[0] == ie) 
buf : 			return pos;
buf : 
buf : 		pos += 2 + pos[1];
buf : 	}
buf : 	return NULL;
buf : }
buf : 
buf : static int p54_beacon_format_ie_tim(struct sk_buff *skb)
format_ie_tim(struct sk_buff *skb) 
buf : {
buf : 	/*
buf : 	 * the good excuse for this mess is ... the firmware.
for this mess is ... the firmware. 
buf : 	 * The dummy TIM MUST be at the end of the beacon frame,
buf : 	 * because it'll be overwritten!
buf : 	 */
buf : 	u8 *tim;
buf : 	u8 dtim_len;
buf : 	u8 dtim_period;
buf : 	u8 *next;
buf : 
buf : 	tim = p54_find_ie(skb, WLAN_EID_TIM);
buf : 	if (!tim)
if (!tim) 
buf : 		return 0;
buf : 
buf : 	dtim_len = tim[1];
buf : 	dtim_period = tim[3];
buf : 	next = tim + 2 + dtim_len;
buf : 
buf : 	if (dtim_len < 3)
if (dtim_len < 3) 
buf : 		return -EINVAL;
buf : 
buf : 	memmove(tim, next, skb_tail_pointer(skb) - next);
buf : 	tim = skb_tail_pointer(skb) - (dtim_len + 2);
buf : 
buf : 	/* add the dummy at the end */
buf : 	tim[0] = WLAN_EID_TIM;
buf : 	tim[1] = 3;
buf : 	tim[2] = 0;
buf : 	tim[3] = dtim_period;
buf : 	tim[4] = 0;
buf : 
buf : 	if (dtim_len > 3)
if (dtim_len > 3) 
buf : 		skb_trim(skb, skb->len - (dtim_len - 3));
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int p54_beacon_update(struct p54_common *priv,
buf : 			struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct ieee80211_tx_control control = { };
buf : 	struct sk_buff *beacon;
buf : 	int ret;
buf : 
buf : 	beacon = ieee80211_beacon_get(priv->hw, vif);
if); 
buf : 	if (!beacon)
buf : 		return -ENOMEM;
buf : 	ret = p54_beacon_format_ie_tim(beacon);
format_ie_tim(beacon); 
buf : 	if (ret)
buf : 		return ret;
buf : 
buf : 	/*
buf : 	 * During operation, the firmware takes care of beaconing.
buf : 	 * The driver only needs to upload a new beacon template, once
buf : 	 * the template was changed by the stack or userspace.
buf : 	 *
buf : 	 * LMAC API 3.2.2 also specifies that the driver does not need
ifies that the driver does not need 
buf : 	 * to cancel the old beacon template by hand, instead the firmware
buf : 	 * will release the previous one through the feedback mechanism.
buf : 	 */
buf : 	p54_tx_80211(priv->hw, &control, beacon);
buf : 	priv->tsf_high32 = 0;
buf : 	priv->tsf_low32 = 0;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int p54_start(struct ieee80211_hw *dev)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	int err;
buf : 
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	err = priv->open(dev);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 	P54_SET_QUEUE(priv->qos_params[0], 0x0002, 0x0003, 0x0007, 47);
buf : 	P54_SET_QUEUE(priv->qos_params[1], 0x0002, 0x0007, 0x000f, 94);
buf : 	P54_SET_QUEUE(priv->qos_params[2], 0x0003, 0x000f, 0x03ff, 0);
buf : 	P54_SET_QUEUE(priv->qos_params[3], 0x0007, 0x000f, 0x03ff, 0);
buf : 	err = p54_set_edcf(priv);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	memset(priv->bssid, ~0, ETH_ALEN);
buf : 	priv->mode = NL80211_IFTYPE_MONITOR;
buf : 	err = p54_setup_mac(priv);
buf : 	if (err) {
if (err) { 
buf : 		priv->mode = NL80211_IFTYPE_UNSPECIFIED;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ieee80211_queue_delayed_work(dev, &priv->work, 0);
buf : 
buf : 	priv->softled_state = 0;
buf : 	err = p54_set_leds(priv);
buf : 
buf : out:
buf : 	mutex_unlock(&priv->conf_mutex);
buf : 	return err;
buf : }
buf : 
buf : static void p54_stop(struct ieee80211_hw *dev)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	int i;
buf : 
buf : 	priv->mode = NL80211_IFTYPE_UNSPECIFIED;
buf : 	priv->softled_state = 0;
buf : 	cancel_delayed_work_sync(&priv->work);
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	p54_set_leds(priv);
buf : 	priv->stop(dev);
buf : 	skb_queue_purge(&priv->tx_pending);
buf : 	skb_queue_purge(&priv->tx_queue);
buf : 	for (i = 0; i < P54_QUEUE_NUM; i++) {
for (i = 0; i < P54_QUEUE_NUM; i++) { 
buf : 		priv->tx_stats[i].count = 0;
buf : 		priv->tx_stats[i].len = 0;
buf : 	}
buf : 
buf : 	priv->beacon_req_id = cpu_to_le32(0);
buf : 	priv->tsf_high32 = priv->tsf_low32 = 0;
buf : 	mutex_unlock(&priv->conf_mutex);
buf : }
buf : 
buf : static int p54_add_interface(struct ieee80211_hw *dev,
buf : 			     struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	int err;
buf : 
buf : 	vif->driver_flags |= IEEE80211_VIF_BEACON_FILTER;
if->driver_flags |= IEEE80211_VIF_BEACON_FILTER; 
buf : 
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	if (priv->mode != NL80211_IFTYPE_MONITOR) {
if (priv->mode != NL80211_IFTYPE_MONITOR) { 
buf : 		mutex_unlock(&priv->conf_mutex);
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	priv->vif = vif;
if = vif; 
buf : 
buf : 	switch (vif->type) {
buf : 	case NL80211_IFTYPE_STATION:
buf : 	case NL80211_IFTYPE_ADHOC:
buf : 	case NL80211_IFTYPE_AP:
buf : 	case NL80211_IFTYPE_MESH_POINT:
buf : 		priv->mode = vif->type;
if->type; 
buf : 		break;
buf : 	default:
buf : 		mutex_unlock(&priv->conf_mutex);
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	memcpy(priv->mac_addr, vif->addr, ETH_ALEN);
if->addr, ETH_ALEN); 
buf : 	err = p54_setup_mac(priv);
buf : 	mutex_unlock(&priv->conf_mutex);
buf : 	return err;
buf : }
buf : 
buf : static void p54_remove_interface(struct ieee80211_hw *dev,
buf : 				 struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	priv->vif = NULL;
if = NULL; 
buf : 
buf : 	/*
buf : 	 * LMAC API 3.2.2 states that any active beacon template must be
buf : 	 * canceled by the driver before attempting a mode transition.
fore attempting a mode transition. 
buf : 	 */
buf : 	if (le32_to_cpu(priv->beacon_req_id) != 0) {
if (le32_to_cpu(priv->beacon_req_id) != 0) { 
buf : 		p54_tx_cancel(priv, priv->beacon_req_id);
buf : 		wait_for_completion_interruptible_timeout(&priv->beacon_comp, HZ);
for_completion_interruptible_timeout(&priv->beacon_comp, HZ); 
buf : 	}
buf : 	priv->mode = NL80211_IFTYPE_MONITOR;
buf : 	memset(priv->mac_addr, 0, ETH_ALEN);
buf : 	memset(priv->bssid, 0, ETH_ALEN);
buf : 	p54_setup_mac(priv);
buf : 	mutex_unlock(&priv->conf_mutex);
buf : }
buf : 
buf : static int p54_wait_for_stats(struct ieee80211_hw *dev)
for_stats(struct ieee80211_hw *dev) 
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	int ret;
buf : 
buf : 	priv->update_stats = true;
buf : 	ret = p54_fetch_statistics(priv);
buf : 	if (ret)
if (ret) 
buf : 		return ret;
buf : 
buf : 	ret = wait_for_completion_interruptible_timeout(&priv->stat_comp, HZ);
for_completion_interruptible_timeout(&priv->stat_comp, HZ); 
buf : 	if (ret == 0)
buf : 		return -ETIMEDOUT;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void p54_reset_stats(struct p54_common *priv)
buf : {
buf : 	struct ieee80211_channel *chan = priv->curchan;
buf : 
buf : 	if (chan) {
if (chan) { 
buf : 		struct survey_info *info = &priv->survey[chan->hw_value];
buf : 
buf : 		/* only reset channel statistics, don't touch .filled, etc. */
buf : 		info->channel_time = 0;
buf : 		info->channel_time_busy = 0;
buf : 		info->channel_time_tx = 0;
buf : 	}
buf : 
buf : 	priv->update_stats = true;
buf : 	priv->survey_raw.active = 0;
buf : 	priv->survey_raw.cca = 0;
buf : 	priv->survey_raw.tx = 0;
buf : }
buf : 
buf : static int p54_config(struct ieee80211_hw *dev, u32 changed)
buf : {
buf : 	int ret = 0;
buf : 	struct p54_common *priv = dev->priv;
buf : 	struct ieee80211_conf *conf = &dev->conf;
buf : 
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	if (changed & IEEE80211_CONF_CHANGE_POWER)
if (changed & IEEE80211_CONF_CHANGE_POWER) 
buf : 		priv->output_power = conf->power_level << 2;
buf : 	if (changed & IEEE80211_CONF_CHANGE_CHANNEL) {
if (changed & IEEE80211_CONF_CHANGE_CHANNEL) { 
buf : 		struct ieee80211_channel *oldchan;
buf : 		WARN_ON(p54_wait_for_stats(dev));
for_stats(dev)); 
buf : 		oldchan = priv->curchan;
buf : 		priv->curchan = NULL;
buf : 		ret = p54_scan(priv, P54_SCAN_EXIT, 0);
buf : 		if (ret) {
if (ret) { 
buf : 			priv->curchan = oldchan;
buf : 			goto out;
buf : 		}
buf : 		/*
buf : 		 * TODO: Use the LM_SCAN_TRAP to determine the current
buf : 		 * operating channel.
buf : 		 */
buf : 		priv->curchan = priv->hw->conf.chandef.chan;
buf : 		p54_reset_stats(priv);
buf : 		WARN_ON(p54_fetch_statistics(priv));
buf : 	}
buf : 	if (changed & IEEE80211_CONF_CHANGE_PS) {
if (changed & IEEE80211_CONF_CHANGE_PS) { 
buf : 		WARN_ON(p54_wait_for_stats(dev));
for_stats(dev)); 
buf : 		ret = p54_set_ps(priv);
buf : 		if (ret)
if (ret) 
buf : 			goto out;
buf : 		WARN_ON(p54_wait_for_stats(dev));
for_stats(dev)); 
buf : 	}
buf : 	if (changed & IEEE80211_CONF_CHANGE_IDLE) {
buf : 		WARN_ON(p54_wait_for_stats(dev));
for_stats(dev)); 
buf : 		ret = p54_setup_mac(priv);
buf : 		if (ret)
if (ret) 
buf : 			goto out;
buf : 		WARN_ON(p54_wait_for_stats(dev));
for_stats(dev)); 
buf : 	}
buf : 
buf : out:
buf : 	mutex_unlock(&priv->conf_mutex);
buf : 	return ret;
buf : }
buf : 
buf : static u64 p54_prepare_multicast(struct ieee80211_hw *dev,
buf : 				 struct netdev_hw_addr_list *mc_list)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	struct netdev_hw_addr *ha;
buf : 	int i;
buf : 
buf : 	BUILD_BUG_ON(ARRAY_SIZE(priv->mc_maclist) !=
buf : 		ARRAY_SIZE(((struct p54_group_address_table *)NULL)->mac_list));
buf : 	/*
buf : 	 * The first entry is reserved for the global broadcast MAC.
for the global broadcast MAC. 
buf : 	 * Otherwise the firmware will drop it and ARP will no longer work.
buf : 	 */
buf : 	i = 1;
buf : 	priv->mc_maclist_num = netdev_hw_addr_list_count(mc_list) + i;
buf : 	netdev_hw_addr_list_for_each(ha, mc_list) {
for_each(ha, mc_list) { 
buf : 		memcpy(&priv->mc_maclist[i], ha->addr, ETH_ALEN);
buf : 		i++;
buf : 		if (i >= ARRAY_SIZE(priv->mc_maclist))
if (i >= ARRAY_SIZE(priv->mc_maclist)) 
buf : 			break;
buf : 	}
buf : 
buf : 	return 1; /* update */
buf : }
buf : 
buf : static void p54_configure_filter(struct ieee80211_hw *dev,
buf : 				 unsigned int changed_flags,
buf : 				 unsigned int *total_flags,
buf : 				 u64 multicast)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 
buf : 	*total_flags &= FIF_PROMISC_IN_BSS |
buf : 			FIF_ALLMULTI |
buf : 			FIF_OTHER_BSS;
buf : 
buf : 	priv->filter_flags = *total_flags;
buf : 
buf : 	if (changed_flags & (FIF_PROMISC_IN_BSS | FIF_OTHER_BSS))
if (changed_flags & (FIF_PROMISC_IN_BSS | FIF_OTHER_BSS)) 
buf : 		p54_setup_mac(priv);
buf : 
buf : 	if (changed_flags & FIF_ALLMULTI || multicast)
if (changed_flags & FIF_ALLMULTI || multicast) 
buf : 		p54_set_groupfilter(priv);
buf : }
buf : 
buf : static int p54_conf_tx(struct ieee80211_hw *dev,
buf : 		       struct ieee80211_vif *vif, u16 queue,
if *vif, u16 queue, 
buf : 		       const struct ieee80211_tx_queue_params *params)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	int ret;
buf : 
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	if (queue < dev->queues) {
if (queue < dev->queues) { 
buf : 		P54_SET_QUEUE(priv->qos_params[queue], params->aifs,
buf : 			params->cw_min, params->cw_max, params->txop);
buf : 		ret = p54_set_edcf(priv);
buf : 	} else
buf : 		ret = -EINVAL;
buf : 	mutex_unlock(&priv->conf_mutex);
buf : 	return ret;
buf : }
buf : 
buf : static void p54_work(struct work_struct *work)
buf : {
buf : 	struct p54_common *priv = container_of(work, struct p54_common,
buf : 					       work.work);
buf : 
buf : 	if (unlikely(priv->mode == NL80211_IFTYPE_UNSPECIFIED))
if (unlikely(priv->mode == NL80211_IFTYPE_UNSPECIFIED)) 
buf : 		return ;
buf : 
buf : 	/*
buf : 	 * TODO: walk through tx_queue and do the following tasks
buf : 	 * 	1. initiate bursts.
buf : 	 *      2. cancel stuck frames / reset the device if necessary.
if necessary. 
buf : 	 */
buf : 
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	WARN_ON_ONCE(p54_fetch_statistics(priv));
buf : 	mutex_unlock(&priv->conf_mutex);
buf : }
buf : 
buf : static int p54_get_stats(struct ieee80211_hw *dev,
buf : 			 struct ieee80211_low_level_stats *stats)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 
buf : 	memcpy(stats, &priv->stats, sizeof(*stats));
buf : 	return 0;
buf : }
buf : 
buf : static void p54_bss_info_changed(struct ieee80211_hw *dev,
buf : 				 struct ieee80211_vif *vif,
if *vif, 
buf : 				 struct ieee80211_bss_conf *info,
buf : 				 u32 changed)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	if (changed & BSS_CHANGED_BSSID) {
if (changed & BSS_CHANGED_BSSID) { 
buf : 		memcpy(priv->bssid, info->bssid, ETH_ALEN);
buf : 		p54_setup_mac(priv);
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON) {
if (changed & BSS_CHANGED_BEACON) { 
buf : 		p54_scan(priv, P54_SCAN_EXIT, 0);
buf : 		p54_setup_mac(priv);
buf : 		p54_beacon_update(priv, vif);
if); 
buf : 		p54_set_edcf(priv);
buf : 	}
buf : 
buf : 	if (changed & (BSS_CHANGED_ERP_SLOT | BSS_CHANGED_BEACON)) {
if (changed & (BSS_CHANGED_ERP_SLOT | BSS_CHANGED_BEACON)) { 
buf : 		priv->use_short_slot = info->use_short_slot;
buf : 		p54_set_edcf(priv);
buf : 	}
buf : 	if (changed & BSS_CHANGED_BASIC_RATES) {
if (changed & BSS_CHANGED_BASIC_RATES) { 
buf : 		if (dev->conf.chandef.chan->band == IEEE80211_BAND_5GHZ)
buf : 			priv->basic_rate_mask = (info->basic_rates << 4);
buf : 		else
buf : 			priv->basic_rate_mask = info->basic_rates;
buf : 		p54_setup_mac(priv);
buf : 		if (priv->fw_var >= 0x500)
if (priv->fw_var >= 0x500) 
buf : 			p54_scan(priv, P54_SCAN_EXIT, 0);
buf : 	}
buf : 	if (changed & BSS_CHANGED_ASSOC) {
if (changed & BSS_CHANGED_ASSOC) { 
buf : 		if (info->assoc) {
buf : 			priv->aid = info->aid;
buf : 			priv->wakeup_timer = info->beacon_int *
buf : 					     info->dtim_period * 5;
buf : 			p54_setup_mac(priv);
buf : 		} else {
buf : 			priv->wakeup_timer = 500;
buf : 			priv->aid = 0;
buf : 		}
buf : 	}
buf : 
buf : 	mutex_unlock(&priv->conf_mutex);
buf : }
buf : 
buf : static int p54_set_key(struct ieee80211_hw *dev, enum set_key_cmd cmd,
buf : 		       struct ieee80211_vif *vif, struct ieee80211_sta *sta,
if *vif, struct ieee80211_sta *sta, 
buf : 		       struct ieee80211_key_conf *key)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	int slot, ret = 0;
buf : 	u8 algo = 0;
buf : 	u8 *addr = NULL;
buf : 
buf : 	if (modparam_nohwcrypt)
if (modparam_nohwcrypt) 
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	if (key->flags & IEEE80211_KEY_FLAG_RX_MGMT) {
if (key->flags & IEEE80211_KEY_FLAG_RX_MGMT) { 
buf : 		/*
buf : 		 * Unfortunately most/all firmwares are trying to decrypt
fortunately most/all firmwares are trying to decrypt 
buf : 		 * incoming management frames if a suitable key can be found.
buf : 		 * However, in doing so the data in these frames gets
buf : 		 * corrupted. So, we can't have firmware supported crypto
buf : 		 * offload in this case.
buf : 		 */
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	if (cmd == SET_KEY) {
if (cmd == SET_KEY) { 
buf : 		switch (key->cipher) {
buf : 		case WLAN_CIPHER_SUITE_TKIP:
buf : 			if (!(priv->privacy_caps & (BR_DESC_PRIV_CAP_MICHAEL |
if (!(priv->privacy_caps & (BR_DESC_PRIV_CAP_MICHAEL | 
buf : 			      BR_DESC_PRIV_CAP_TKIP))) {
buf : 				ret = -EOPNOTSUPP;
buf : 				goto out_unlock;
buf : 			}
buf : 			key->flags |= IEEE80211_KEY_FLAG_GENERATE_IV;
buf : 			algo = P54_CRYPTO_TKIPMICHAEL;
buf : 			break;
buf : 		case WLAN_CIPHER_SUITE_WEP40:
buf : 		case WLAN_CIPHER_SUITE_WEP104:
buf : 			if (!(priv->privacy_caps & BR_DESC_PRIV_CAP_WEP)) {
if (!(priv->privacy_caps & BR_DESC_PRIV_CAP_WEP)) { 
buf : 				ret = -EOPNOTSUPP;
buf : 				goto out_unlock;
buf : 			}
buf : 			key->flags |= IEEE80211_KEY_FLAG_GENERATE_IV;
buf : 			algo = P54_CRYPTO_WEP;
buf : 			break;
buf : 		case WLAN_CIPHER_SUITE_CCMP:
buf : 			if (!(priv->privacy_caps & BR_DESC_PRIV_CAP_AESCCMP)) {
if (!(priv->privacy_caps & BR_DESC_PRIV_CAP_AESCCMP)) { 
buf : 				ret = -EOPNOTSUPP;
buf : 				goto out_unlock;
buf : 			}
buf : 			key->flags |= IEEE80211_KEY_FLAG_GENERATE_IV;
buf : 			algo = P54_CRYPTO_AESCCMP;
buf : 			break;
buf : 		default:
buf : 			ret = -EOPNOTSUPP;
buf : 			goto out_unlock;
buf : 		}
buf : 		slot = bitmap_find_free_region(priv->used_rxkeys,
buf : 					       priv->rx_keycache_size, 0);
buf : 
buf : 		if (slot < 0) {
if (slot < 0) { 
buf : 			/*
buf : 			 * The device supports the chosen algorithm, but the
buf : 			 * firmware does not provide enough key slots to store
buf : 			 * all of them.
buf : 			 * But encryption offload for outgoing frames is always
for outgoing frames is always 
buf : 			 * possible, so we just pretend that the upload was
buf : 			 * successful and do the decryption in software.
buf : 			 */
buf : 
buf : 			/* mark the key as invalid. */
buf : 			key->hw_key_idx = 0xff;
buf : 			goto out_unlock;
buf : 		}
buf : 	} else {
buf : 		slot = key->hw_key_idx;
buf : 
buf : 		if (slot == 0xff) {
if (slot == 0xff) { 
buf : 			/* This key was not uploaded into the rx key cache. */
buf : 
buf : 			goto out_unlock;
buf : 		}
buf : 
buf : 		bitmap_release_region(priv->used_rxkeys, slot, 0);
buf : 		algo = 0;
buf : 	}
buf : 
buf : 	if (sta)
if (sta) 
buf : 		addr = sta->addr;
buf : 
buf : 	ret = p54_upload_key(priv, algo, slot, key->keyidx,
buf : 			     key->keylen, addr, key->key);
buf : 	if (ret) {
if (ret) { 
buf : 		bitmap_release_region(priv->used_rxkeys, slot, 0);
buf : 		ret = -EOPNOTSUPP;
buf : 		goto out_unlock;
buf : 	}
buf : 
buf : 	key->hw_key_idx = slot;
buf : 
buf : out_unlock:
buf : 	mutex_unlock(&priv->conf_mutex);
buf : 	return ret;
buf : }
buf : 
buf : static int p54_get_survey(struct ieee80211_hw *dev, int idx,
buf : 				struct survey_info *survey)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	struct ieee80211_channel *chan;
buf : 	int err, tries;
buf : 	bool in_use = false;
buf : 
buf : 	if (idx >= priv->chan_num)
if (idx >= priv->chan_num) 
buf : 		return -ENOENT;
buf : 
buf : #define MAX_TRIES 1
buf : 	for (tries = 0; tries < MAX_TRIES; tries++) {
for (tries = 0; tries < MAX_TRIES; tries++) { 
buf : 		chan = priv->curchan;
buf : 		if (chan && chan->hw_value == idx) {
if (chan && chan->hw_value == idx) { 
buf : 			mutex_lock(&priv->conf_mutex);
buf : 			err = p54_wait_for_stats(dev);
for_stats(dev); 
buf : 			mutex_unlock(&priv->conf_mutex);
buf : 			if (err)
if (err) 
buf : 				return err;
buf : 
buf : 			in_use = true;
buf : 		}
buf : 
buf : 		memcpy(survey, &priv->survey[idx], sizeof(*survey));
buf : 
buf : 		if (in_use) {
if (in_use) { 
buf : 			/* test if the reported statistics are valid. */
buf : 			if  (survey->channel_time != 0) {
if  (survey->channel_time != 0) { 
buf : 				survey->filled |= SURVEY_INFO_IN_USE;
buf : 			} else {
buf : 				/*
buf : 				 * hw/fw has not accumulated enough sample sets.
buf : 				 * Wait for 100ms, this ought to be enough to
for 100ms, this ought to be enough to 
buf : 				 * to get at least one non-null set of channel
buf : 				 * usage statistics.
buf : 				 */
buf : 				msleep(100);
buf : 				continue;
buf : 			}
buf : 		}
buf : 		return 0;
buf : 	}
buf : 	return -ETIMEDOUT;
buf : #undef MAX_TRIES
buf : }
buf : 
buf : static unsigned int p54_flush_count(struct p54_common *priv)
buf : {
buf : 	unsigned int total = 0, i;
buf : 
buf : 	BUILD_BUG_ON(P54_QUEUE_NUM > ARRAY_SIZE(priv->tx_stats));
buf : 
buf : 	/*
buf : 	 * Because the firmware has the sole control over any frames
buf : 	 * in the P54_QUEUE_BEACON or P54_QUEUE_SCAN queues, they
buf : 	 * don't really count as pending or active.
buf : 	 */
buf : 	for (i = P54_QUEUE_MGMT; i < P54_QUEUE_NUM; i++)
for (i = P54_QUEUE_MGMT; i < P54_QUEUE_NUM; i++) 
buf : 		total += priv->tx_stats[i].len;
buf : 	return total;
buf : }
buf : 
buf : static void p54_flush(struct ieee80211_hw *dev, struct ieee80211_vif *vif,
if *vif, 
buf : 		      u32 queues, bool drop)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	unsigned int total, i;
buf : 
buf : 	/*
buf : 	 * Currently, it wouldn't really matter if we wait for one second
if we wait for one second 
buf : 	 * or 15 minutes. But once someone gets around and completes the
buf : 	 * TODOs [ancel stuck frames / reset device] in p54_work, it will
buf : 	 * suddenly make sense to wait that long.
buf : 	 */
buf : 	i = P54_STATISTICS_UPDATE * 2 / 20;
buf : 
buf : 	/*
buf : 	 * In this case no locking is required because as we speak the
buf : 	 * queues have already been stopped and no new frames can sneak
buf : 	 * up from behind.
buf : 	 */
buf : 	while ((total = p54_flush_count(priv) && i--)) {
while ((total = p54_flush_count(priv) && i--)) { 
buf : 		/* waste time */
buf : 		msleep(20);
buf : 	}
buf : 
buf : 	WARN(total, "tx flush timeout, unresponsive firmware");
buf : }
buf : 
buf : static void p54_set_coverage_class(struct ieee80211_hw *dev, u8 coverage_class)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 
buf : 	mutex_lock(&priv->conf_mutex);
buf : 	/* support all coverage class values as in 802.11-2007 Table 7-27 */
buf : 	priv->coverage_class = clamp_t(u8, coverage_class, 0, 31);
buf : 	p54_set_edcf(priv);
buf : 	mutex_unlock(&priv->conf_mutex);
buf : }
buf : 
buf : static const struct ieee80211_ops p54_ops = {
buf : 	.tx			= p54_tx_80211,
buf : 	.start			= p54_start,
buf : 	.stop			= p54_stop,
buf : 	.add_interface		= p54_add_interface,
buf : 	.remove_interface	= p54_remove_interface,
buf : 	.set_tim		= p54_set_tim,
buf : 	.sta_notify		= p54_sta_notify,
ify		= p54_sta_notify, 
buf : 	.sta_add		= p54_sta_add_remove,
buf : 	.sta_remove		= p54_sta_add_remove,
buf : 	.set_key		= p54_set_key,
buf : 	.config			= p54_config,
buf : 	.flush			= p54_flush,
buf : 	.bss_info_changed	= p54_bss_info_changed,
buf : 	.prepare_multicast	= p54_prepare_multicast,
buf : 	.configure_filter	= p54_configure_filter,
buf : 	.conf_tx		= p54_conf_tx,
buf : 	.get_stats		= p54_get_stats,
buf : 	.get_survey		= p54_get_survey,
buf : 	.set_coverage_class	= p54_set_coverage_class,
buf : };
buf : 
buf : struct ieee80211_hw *p54_init_common(size_t priv_data_len)
buf : {
buf : 	struct ieee80211_hw *dev;
buf : 	struct p54_common *priv;
buf : 
buf : 	dev = ieee80211_alloc_hw(priv_data_len, &p54_ops);
buf : 	if (!dev)
if (!dev) 
buf : 		return NULL;
buf : 
buf : 	priv = dev->priv;
buf : 	priv->hw = dev;
buf : 	priv->mode = NL80211_IFTYPE_UNSPECIFIED;
buf : 	priv->basic_rate_mask = 0x15f;
buf : 	spin_lock_init(&priv->tx_stats_lock);
buf : 	skb_queue_head_init(&priv->tx_queue);
buf : 	skb_queue_head_init(&priv->tx_pending);
buf : 	dev->flags = IEEE80211_HW_RX_INCLUDES_FCS |
buf : 		     IEEE80211_HW_SIGNAL_DBM |
buf : 		     IEEE80211_HW_SUPPORTS_PS |
buf : 		     IEEE80211_HW_PS_NULLFUNC_STACK |
buf : 		     IEEE80211_HW_MFP_CAPABLE |
buf : 		     IEEE80211_HW_REPORTS_TX_ACK_STATUS;
buf : 
buf : 	dev->wiphy->interface_modes = BIT(NL80211_IFTYPE_STATION) |
buf : 				      BIT(NL80211_IFTYPE_ADHOC) |
buf : 				      BIT(NL80211_IFTYPE_AP) |
buf : 				      BIT(NL80211_IFTYPE_MESH_POINT);
buf : 
buf : 	priv->beacon_req_id = cpu_to_le32(0);
buf : 	priv->tx_stats[P54_QUEUE_BEACON].limit = 1;
buf : 	priv->tx_stats[P54_QUEUE_FWSCAN].limit = 1;
buf : 	priv->tx_stats[P54_QUEUE_MGMT].limit = 3;
buf : 	priv->tx_stats[P54_QUEUE_CAB].limit = 3;
buf : 	priv->tx_stats[P54_QUEUE_DATA].limit = 5;
buf : 	dev->queues = 1;
buf : 	priv->noise = -94;
buf : 	/*
buf : 	 * We support at most 8 tries no matter which rate they're at,
buf : 	 * we cannot support max_rates * max_rate_tries as we set it
buf : 	 * here, but setting it correctly to 4/2 or so would limit us
buf : 	 * artificially if the RC algorithm wants just two rates, so
ificially if the RC algorithm wants just two rates, so 
buf : 	 * let's say 4/7, we'll redistribute it at TX time, see the
buf : 	 * comments there.
buf : 	 */
buf : 	dev->max_rates = 4;
buf : 	dev->max_rate_tries = 7;
buf : 	dev->extra_tx_headroom = sizeof(struct p54_hdr) + 4 +
buf : 				 sizeof(struct p54_tx_data);
buf : 
buf : 	/*
buf : 	 * For now, disable PS by default because it affects
buf : 	 * link stability significantly.
ificantly. 
buf : 	 */
buf : 	dev->wiphy->flags &= ~WIPHY_FLAG_PS_ON_BY_DEFAULT;
buf : 
buf : 	mutex_init(&priv->conf_mutex);
buf : 	mutex_init(&priv->eeprom_mutex);
buf : 	init_completion(&priv->stat_comp);
buf : 	init_completion(&priv->eeprom_comp);
buf : 	init_completion(&priv->beacon_comp);
buf : 	INIT_DELAYED_WORK(&priv->work, p54_work);
buf : 
buf : 	memset(&priv->mc_maclist[0], ~0, ETH_ALEN);
buf : 	priv->curchan = NULL;
buf : 	p54_reset_stats(priv);
buf : 	return dev;
buf : }
buf : EXPORT_SYMBOL_GPL(p54_init_common);
buf : 
buf : int p54_register_common(struct ieee80211_hw *dev, struct device *pdev)
buf : {
buf : 	struct p54_common __maybe_unused *priv = dev->priv;
buf : 	int err;
buf : 
buf : 	err = ieee80211_register_hw(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(pdev, "Cannot register device (%d).\n", err);
buf : 		return err;
buf : 	}
buf : 	priv->registered = true;
buf : 
buf : #ifdef CONFIG_P54_LEDS
ifdef CONFIG_P54_LEDS 
buf : 	err = p54_init_leds(priv);
buf : 	if (err) {
if (err) { 
buf : 		p54_unregister_common(dev);
buf : 		return err;
buf : 	}
buf : #endif /* CONFIG_P54_LEDS */
if /* CONFIG_P54_LEDS */ 
buf : 
buf : 	dev_info(pdev, "is registered as '%s'\n", wiphy_name(dev->wiphy));
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL_GPL(p54_register_common);
buf : 
buf : void p54_free_common(struct ieee80211_hw *dev)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 	unsigned int i;
buf : 
buf : 	for (i = 0; i < IEEE80211_NUM_BANDS; i++)
for (i = 0; i < IEEE80211_NUM_BANDS; i++) 
buf : 		kfree(priv->band_table[i]);
buf : 
buf : 	kfree(priv->iq_autocal);
buf : 	kfree(priv->output_limit);
buf : 	kfree(priv->curve_data);
buf : 	kfree(priv->rssi_db);
buf : 	kfree(priv->used_rxkeys);
buf : 	kfree(priv->survey);
buf : 	priv->iq_autocal = NULL;
buf : 	priv->output_limit = NULL;
buf : 	priv->curve_data = NULL;
buf : 	priv->rssi_db = NULL;
buf : 	priv->used_rxkeys = NULL;
buf : 	priv->survey = NULL;
buf : 	ieee80211_free_hw(dev);
buf : }
buf : EXPORT_SYMBOL_GPL(p54_free_common);
buf : 
buf : void p54_unregister_common(struct ieee80211_hw *dev)
buf : {
buf : 	struct p54_common *priv = dev->priv;
buf : 
buf : #ifdef CONFIG_P54_LEDS
ifdef CONFIG_P54_LEDS 
buf : 	p54_unregister_leds(priv);
buf : #endif /* CONFIG_P54_LEDS */
if /* CONFIG_P54_LEDS */ 
buf : 
buf : 	if (priv->registered) {
buf : 		priv->registered = false;
buf : 		ieee80211_unregister_hw(dev);
buf : 	}
buf : 
buf : 	mutex_destroy(&priv->conf_mutex);
buf : 	mutex_destroy(&priv->eeprom_mutex);
buf : }
buf : EXPORT_SYMBOL_GPL(p54_unregister_common);
file : ./test/kernel/drivers/net/wireless/b43/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf : 
buf :   Broadcom B43 wireless driver
buf : 
buf :   Copyright (c) 2005 Martin Langer <martin-langer@gmx.de>
buf :   Copyright (c) 2005 Stefano Brivio <stefano.brivio@polimi.it>
buf :   Copyright (c) 2005-2009 Michael Buesch <m@bues.ch>
buf :   Copyright (c) 2005 Danny van Dyk <kugelfang@gentoo.org>
buf :   Copyright (c) 2005 Andreas Jaggi <andreas.jaggi@waterwave.ch>
buf :   Copyright (c) 2010-2011 Rafał Miłecki <zajec5@gmail.com>
buf : 
buf :   SDIO support
buf :   Copyright (c) 2009 Albert Herranz <albert_herranz@yahoo.es>
buf : 
buf :   Some parts of the code in this file are derived from the ipw2200
buf :   driver  Copyright(c) 2003 - 2004 Intel Corporation.
buf : 
buf :   This program is free software; you can redistribute it and/or modify
ify 
buf :   it under the terms of the GNU General Public License as published by
buf :   the Free Software Foundation; either version 2 of the License, or
buf :   (at your option) any later version.
buf : 
buf :   This program is distributed in the hope that it will be useful,
buf :   but WITHOUT ANY WARRANTY; without even the implied warranty of
buf :   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
buf :   GNU General Public License for more details.
for more details. 
buf : 
buf :   You should have received a copy of the GNU General Public License
buf :   along with this program; see the file COPYING.  If not, write to
buf :   the Free Software Foundation, Inc., 51 Franklin Steet, Fifth Floor,
ifth Floor, 
buf :   Boston, MA 02110-1301, USA.
buf : 
buf : */
buf : 
buf : #include <linux/delay.h>
buf : #include <linux/init.h>
buf : #include <linux/module.h>
buf : #include <linux/if_arp.h>
if_arp.h> 
buf : #include <linux/etherdevice.h>
buf : #include <linux/firmware.h>
buf : #include <linux/workqueue.h>
buf : #include <linux/skbuff.h>
buf : #include <linux/io.h>
buf : #include <linux/dma-mapping.h>
buf : #include <linux/slab.h>
buf : #include <asm/unaligned.h>
buf : 
buf : #include "b43.h"
buf : #include "main.h"
buf : #include "debugfs.h"
buf : #include "phy_common.h"
buf : #include "phy_g.h"
buf : #include "phy_n.h"
buf : #include "dma.h"
buf : #include "pio.h"
buf : #include "sysfs.h"
buf : #include "xmit.h"
buf : #include "lo.h"
buf : #include "pcmcia.h"
buf : #include "sdio.h"
buf : #include <linux/mmc/sdio_func.h>
buf : 
buf : MODULE_DESCRIPTION("Broadcom B43 wireless driver");
buf : MODULE_AUTHOR("Martin Langer");
buf : MODULE_AUTHOR("Stefano Brivio");
buf : MODULE_AUTHOR("Michael Buesch");
buf : MODULE_AUTHOR("Gábor Stefanik");
buf : MODULE_AUTHOR("Rafał Miłecki");
buf : MODULE_LICENSE("GPL");
buf : 
buf : MODULE_FIRMWARE("b43/ucode11.fw");
buf : MODULE_FIRMWARE("b43/ucode13.fw");
buf : MODULE_FIRMWARE("b43/ucode14.fw");
buf : MODULE_FIRMWARE("b43/ucode15.fw");
buf : MODULE_FIRMWARE("b43/ucode16_mimo.fw");
buf : MODULE_FIRMWARE("b43/ucode5.fw");
buf : MODULE_FIRMWARE("b43/ucode9.fw");
buf : 
buf : static int modparam_bad_frames_preempt;
buf : module_param_named(bad_frames_preempt, modparam_bad_frames_preempt, int, 0444);
buf : MODULE_PARM_DESC(bad_frames_preempt,
buf : 		 "enable(1) / disable(0) Bad Frames Preemption");
buf : 
buf : static char modparam_fwpostfix[16];
buf : module_param_string(fwpostfix, modparam_fwpostfix, 16, 0444);
buf : MODULE_PARM_DESC(fwpostfix, "Postfix for the .fw files to load.");
for the .fw files to load."); 
buf : 
buf : static int modparam_hwpctl;
buf : module_param_named(hwpctl, modparam_hwpctl, int, 0444);
buf : MODULE_PARM_DESC(hwpctl, "Enable hardware-side power control (default off)");
buf : 
buf : static int modparam_nohwcrypt;
buf : module_param_named(nohwcrypt, modparam_nohwcrypt, int, 0444);
buf : MODULE_PARM_DESC(nohwcrypt, "Disable hardware encryption.");
buf : 
buf : static int modparam_hwtkip;
buf : module_param_named(hwtkip, modparam_hwtkip, int, 0444);
buf : MODULE_PARM_DESC(hwtkip, "Enable hardware tkip.");
buf : 
buf : static int modparam_qos = 1;
buf : module_param_named(qos, modparam_qos, int, 0444);
buf : MODULE_PARM_DESC(qos, "Enable QOS support (default on)");
buf : 
buf : static int modparam_btcoex = 1;
buf : module_param_named(btcoex, modparam_btcoex, int, 0444);
buf : MODULE_PARM_DESC(btcoex, "Enable Bluetooth coexistence (default on)");
buf : 
buf : int b43_modparam_verbose = B43_VERBOSITY_DEFAULT;
buf : module_param_named(verbose, b43_modparam_verbose, int, 0644);
buf : MODULE_PARM_DESC(verbose, "Log message verbosity: 0=error, 1=warn, 2=info(default), 3=debug");
buf : 
buf : static int b43_modparam_pio = 0;
buf : module_param_named(pio, b43_modparam_pio, int, 0644);
buf : MODULE_PARM_DESC(pio, "Use PIO accesses by default: 0=DMA, 1=PIO");
buf : 
buf : static int modparam_allhwsupport = !IS_ENABLED(CONFIG_BRCMSMAC);
buf : module_param_named(allhwsupport, modparam_allhwsupport, int, 0444);
buf : MODULE_PARM_DESC(allhwsupport, "Enable support for all hardware (even it if overlaps with the brcmsmac driver)");
if overlaps with the brcmsmac driver)"); 
buf : 
buf : #ifdef CONFIG_B43_BCMA
buf : static const struct bcma_device_id b43_bcma_tbl[] = {
buf : 	BCMA_CORE(BCMA_MANUF_BCM, BCMA_CORE_80211, 0x11, BCMA_ANY_CLASS),
buf : 	BCMA_CORE(BCMA_MANUF_BCM, BCMA_CORE_80211, 0x17, BCMA_ANY_CLASS),
buf : 	BCMA_CORE(BCMA_MANUF_BCM, BCMA_CORE_80211, 0x18, BCMA_ANY_CLASS),
buf : 	BCMA_CORE(BCMA_MANUF_BCM, BCMA_CORE_80211, 0x1D, BCMA_ANY_CLASS),
buf : 	BCMA_CORETABLE_END
buf : };
buf : MODULE_DEVICE_TABLE(bcma, b43_bcma_tbl);
buf : #endif
if 
buf : 
buf : #ifdef CONFIG_B43_SSB
buf : static const struct ssb_device_id b43_ssb_tbl[] = {
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 5),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 6),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 7),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 9),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 10),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 11),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 12),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 13),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 15),
buf : 	SSB_DEVICE(SSB_VENDOR_BROADCOM, SSB_DEV_80211, 16),
buf : 	SSB_DEVTABLE_END
buf : };
buf : MODULE_DEVICE_TABLE(ssb, b43_ssb_tbl);
buf : #endif
if 
buf : 
buf : /* Channel and ratetables are shared for all devices.
for all devices. 
buf :  * They can't be const, because ieee80211 puts some precalculated
buf :  * data in there. This data is the same for all devices, so we don't
for all devices, so we don't 
buf :  * get concurrency issues */
buf : #define RATETAB_ENT(_rateid, _flags) \
buf : 	{								\
buf : 		.bitrate	= B43_RATE_TO_BASE100KBPS(_rateid),	\
buf : 		.hw_value	= (_rateid),				\
buf : 		.flags		= (_flags),				\
buf : 	}
buf : 
buf : /*
buf :  * NOTE: When changing this, sync with xmit.c's
buf :  *	 b43_plcp_get_bitrate_idx_* functions!
buf :  */
buf : static struct ieee80211_rate __b43_ratetable[] = {
buf : 	RATETAB_ENT(B43_CCK_RATE_1MB, 0),
buf : 	RATETAB_ENT(B43_CCK_RATE_2MB, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATETAB_ENT(B43_CCK_RATE_5MB, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATETAB_ENT(B43_CCK_RATE_11MB, IEEE80211_RATE_SHORT_PREAMBLE),
buf : 	RATETAB_ENT(B43_OFDM_RATE_6MB, 0),
buf : 	RATETAB_ENT(B43_OFDM_RATE_9MB, 0),
buf : 	RATETAB_ENT(B43_OFDM_RATE_12MB, 0),
buf : 	RATETAB_ENT(B43_OFDM_RATE_18MB, 0),
buf : 	RATETAB_ENT(B43_OFDM_RATE_24MB, 0),
buf : 	RATETAB_ENT(B43_OFDM_RATE_36MB, 0),
buf : 	RATETAB_ENT(B43_OFDM_RATE_48MB, 0),
buf : 	RATETAB_ENT(B43_OFDM_RATE_54MB, 0),
buf : };
buf : 
buf : #define b43_a_ratetable		(__b43_ratetable + 4)
buf : #define b43_a_ratetable_size	8
buf : #define b43_b_ratetable		(__b43_ratetable + 0)
buf : #define b43_b_ratetable_size	4
buf : #define b43_g_ratetable		(__b43_ratetable + 0)
buf : #define b43_g_ratetable_size	12
buf : 
buf : #define CHAN2G(_channel, _freq, _flags) {			\
buf : 	.band			= IEEE80211_BAND_2GHZ,		\
buf : 	.center_freq		= (_freq),			\
buf : 	.hw_value		= (_channel),			\
buf : 	.flags			= (_flags),			\
buf : 	.max_antenna_gain	= 0,				\
buf : 	.max_power		= 30,				\
buf : }
buf : static struct ieee80211_channel b43_2ghz_chantable[] = {
buf : 	CHAN2G(1, 2412, 0),
buf : 	CHAN2G(2, 2417, 0),
buf : 	CHAN2G(3, 2422, 0),
buf : 	CHAN2G(4, 2427, 0),
buf : 	CHAN2G(5, 2432, 0),
buf : 	CHAN2G(6, 2437, 0),
buf : 	CHAN2G(7, 2442, 0),
buf : 	CHAN2G(8, 2447, 0),
buf : 	CHAN2G(9, 2452, 0),
buf : 	CHAN2G(10, 2457, 0),
buf : 	CHAN2G(11, 2462, 0),
buf : 	CHAN2G(12, 2467, 0),
buf : 	CHAN2G(13, 2472, 0),
buf : 	CHAN2G(14, 2484, 0),
buf : };
buf : #undef CHAN2G
buf : 
buf : #define CHAN4G(_channel, _flags) {				\
buf : 	.band			= IEEE80211_BAND_5GHZ,		\
buf : 	.center_freq		= 4000 + (5 * (_channel)),	\
buf : 	.hw_value		= (_channel),			\
buf : 	.flags			= (_flags),			\
buf : 	.max_antenna_gain	= 0,				\
buf : 	.max_power		= 30,				\
buf : }
buf : #define CHAN5G(_channel, _flags) {				\
buf : 	.band			= IEEE80211_BAND_5GHZ,		\
buf : 	.center_freq		= 5000 + (5 * (_channel)),	\
buf : 	.hw_value		= (_channel),			\
buf : 	.flags			= (_flags),			\
buf : 	.max_antenna_gain	= 0,				\
buf : 	.max_power		= 30,				\
buf : }
buf : static struct ieee80211_channel b43_5ghz_nphy_chantable[] = {
buf : 	CHAN4G(184, 0),		CHAN4G(186, 0),
buf : 	CHAN4G(188, 0),		CHAN4G(190, 0),
buf : 	CHAN4G(192, 0),		CHAN4G(194, 0),
buf : 	CHAN4G(196, 0),		CHAN4G(198, 0),
buf : 	CHAN4G(200, 0),		CHAN4G(202, 0),
buf : 	CHAN4G(204, 0),		CHAN4G(206, 0),
buf : 	CHAN4G(208, 0),		CHAN4G(210, 0),
buf : 	CHAN4G(212, 0),		CHAN4G(214, 0),
buf : 	CHAN4G(216, 0),		CHAN4G(218, 0),
buf : 	CHAN4G(220, 0),		CHAN4G(222, 0),
buf : 	CHAN4G(224, 0),		CHAN4G(226, 0),
buf : 	CHAN4G(228, 0),
buf : 	CHAN5G(32, 0),		CHAN5G(34, 0),
buf : 	CHAN5G(36, 0),		CHAN5G(38, 0),
buf : 	CHAN5G(40, 0),		CHAN5G(42, 0),
buf : 	CHAN5G(44, 0),		CHAN5G(46, 0),
buf : 	CHAN5G(48, 0),		CHAN5G(50, 0),
buf : 	CHAN5G(52, 0),		CHAN5G(54, 0),
buf : 	CHAN5G(56, 0),		CHAN5G(58, 0),
buf : 	CHAN5G(60, 0),		CHAN5G(62, 0),
buf : 	CHAN5G(64, 0),		CHAN5G(66, 0),
buf : 	CHAN5G(68, 0),		CHAN5G(70, 0),
buf : 	CHAN5G(72, 0),		CHAN5G(74, 0),
buf : 	CHAN5G(76, 0),		CHAN5G(78, 0),
buf : 	CHAN5G(80, 0),		CHAN5G(82, 0),
buf : 	CHAN5G(84, 0),		CHAN5G(86, 0),
buf : 	CHAN5G(88, 0),		CHAN5G(90, 0),
buf : 	CHAN5G(92, 0),		CHAN5G(94, 0),
buf : 	CHAN5G(96, 0),		CHAN5G(98, 0),
buf : 	CHAN5G(100, 0),		CHAN5G(102, 0),
buf : 	CHAN5G(104, 0),		CHAN5G(106, 0),
buf : 	CHAN5G(108, 0),		CHAN5G(110, 0),
buf : 	CHAN5G(112, 0),		CHAN5G(114, 0),
buf : 	CHAN5G(116, 0),		CHAN5G(118, 0),
buf : 	CHAN5G(120, 0),		CHAN5G(122, 0),
buf : 	CHAN5G(124, 0),		CHAN5G(126, 0),
buf : 	CHAN5G(128, 0),		CHAN5G(130, 0),
buf : 	CHAN5G(132, 0),		CHAN5G(134, 0),
buf : 	CHAN5G(136, 0),		CHAN5G(138, 0),
buf : 	CHAN5G(140, 0),		CHAN5G(142, 0),
buf : 	CHAN5G(144, 0),		CHAN5G(145, 0),
buf : 	CHAN5G(146, 0),		CHAN5G(147, 0),
buf : 	CHAN5G(148, 0),		CHAN5G(149, 0),
buf : 	CHAN5G(150, 0),		CHAN5G(151, 0),
buf : 	CHAN5G(152, 0),		CHAN5G(153, 0),
buf : 	CHAN5G(154, 0),		CHAN5G(155, 0),
buf : 	CHAN5G(156, 0),		CHAN5G(157, 0),
buf : 	CHAN5G(158, 0),		CHAN5G(159, 0),
buf : 	CHAN5G(160, 0),		CHAN5G(161, 0),
buf : 	CHAN5G(162, 0),		CHAN5G(163, 0),
buf : 	CHAN5G(164, 0),		CHAN5G(165, 0),
buf : 	CHAN5G(166, 0),		CHAN5G(168, 0),
buf : 	CHAN5G(170, 0),		CHAN5G(172, 0),
buf : 	CHAN5G(174, 0),		CHAN5G(176, 0),
buf : 	CHAN5G(178, 0),		CHAN5G(180, 0),
buf : 	CHAN5G(182, 0),
buf : };
buf : 
buf : static struct ieee80211_channel b43_5ghz_aphy_chantable[] = {
buf : 	CHAN5G(34, 0),		CHAN5G(36, 0),
buf : 	CHAN5G(38, 0),		CHAN5G(40, 0),
buf : 	CHAN5G(42, 0),		CHAN5G(44, 0),
buf : 	CHAN5G(46, 0),		CHAN5G(48, 0),
buf : 	CHAN5G(52, 0),		CHAN5G(56, 0),
buf : 	CHAN5G(60, 0),		CHAN5G(64, 0),
buf : 	CHAN5G(100, 0),		CHAN5G(104, 0),
buf : 	CHAN5G(108, 0),		CHAN5G(112, 0),
buf : 	CHAN5G(116, 0),		CHAN5G(120, 0),
buf : 	CHAN5G(124, 0),		CHAN5G(128, 0),
buf : 	CHAN5G(132, 0),		CHAN5G(136, 0),
buf : 	CHAN5G(140, 0),		CHAN5G(149, 0),
buf : 	CHAN5G(153, 0),		CHAN5G(157, 0),
buf : 	CHAN5G(161, 0),		CHAN5G(165, 0),
buf : 	CHAN5G(184, 0),		CHAN5G(188, 0),
buf : 	CHAN5G(192, 0),		CHAN5G(196, 0),
buf : 	CHAN5G(200, 0),		CHAN5G(204, 0),
buf : 	CHAN5G(208, 0),		CHAN5G(212, 0),
buf : 	CHAN5G(216, 0),
buf : };
buf : #undef CHAN4G
buf : #undef CHAN5G
buf : 
buf : static struct ieee80211_supported_band b43_band_5GHz_nphy = {
buf : 	.band		= IEEE80211_BAND_5GHZ,
buf : 	.channels	= b43_5ghz_nphy_chantable,
buf : 	.n_channels	= ARRAY_SIZE(b43_5ghz_nphy_chantable),
buf : 	.bitrates	= b43_a_ratetable,
buf : 	.n_bitrates	= b43_a_ratetable_size,
buf : };
buf : 
buf : static struct ieee80211_supported_band b43_band_5GHz_aphy = {
buf : 	.band		= IEEE80211_BAND_5GHZ,
buf : 	.channels	= b43_5ghz_aphy_chantable,
buf : 	.n_channels	= ARRAY_SIZE(b43_5ghz_aphy_chantable),
buf : 	.bitrates	= b43_a_ratetable,
buf : 	.n_bitrates	= b43_a_ratetable_size,
buf : };
buf : 
buf : static struct ieee80211_supported_band b43_band_2GHz = {
buf : 	.band		= IEEE80211_BAND_2GHZ,
buf : 	.channels	= b43_2ghz_chantable,
buf : 	.n_channels	= ARRAY_SIZE(b43_2ghz_chantable),
buf : 	.bitrates	= b43_g_ratetable,
buf : 	.n_bitrates	= b43_g_ratetable_size,
buf : };
buf : 
buf : static void b43_wireless_core_exit(struct b43_wldev *dev);
buf : static int b43_wireless_core_init(struct b43_wldev *dev);
buf : static struct b43_wldev * b43_wireless_core_stop(struct b43_wldev *dev);
buf : static int b43_wireless_core_start(struct b43_wldev *dev);
buf : static void b43_op_bss_info_changed(struct ieee80211_hw *hw,
buf : 				    struct ieee80211_vif *vif,
if *vif, 
buf : 				    struct ieee80211_bss_conf *conf,
buf : 				    u32 changed);
buf : 
buf : static int b43_ratelimit(struct b43_wl *wl)
buf : {
buf : 	if (!wl || !wl->current_dev)
if (!wl || !wl->current_dev) 
buf : 		return 1;
buf : 	if (b43_status(wl->current_dev) < B43_STAT_STARTED)
if (b43_status(wl->current_dev) < B43_STAT_STARTED) 
buf : 		return 1;
buf : 	/* We are up and running.
buf : 	 * Ratelimit the messages to avoid DoS over the net. */
buf : 	return net_ratelimit();
buf : }
buf : 
buf : void b43info(struct b43_wl *wl, const char *fmt, ...)
buf : {
buf : 	struct va_format vaf;
format vaf; 
buf : 	va_list args;
buf : 
buf : 	if (b43_modparam_verbose < B43_VERBOSITY_INFO)
if (b43_modparam_verbose < B43_VERBOSITY_INFO) 
buf : 		return;
buf : 	if (!b43_ratelimit(wl))
if (!b43_ratelimit(wl)) 
buf : 		return;
buf : 
buf : 	va_start(args, fmt);
buf : 
buf : 	vaf.fmt = fmt;
buf : 	vaf.va = &args;
buf : 
buf : 	printk(KERN_INFO "b43-%s: %pV",
buf : 	       (wl && wl->hw) ? wiphy_name(wl->hw->wiphy) : "wlan", &vaf);
buf : 
buf : 	va_end(args);
buf : }
buf : 
buf : void b43err(struct b43_wl *wl, const char *fmt, ...)
buf : {
buf : 	struct va_format vaf;
format vaf; 
buf : 	va_list args;
buf : 
buf : 	if (b43_modparam_verbose < B43_VERBOSITY_ERROR)
if (b43_modparam_verbose < B43_VERBOSITY_ERROR) 
buf : 		return;
buf : 	if (!b43_ratelimit(wl))
if (!b43_ratelimit(wl)) 
buf : 		return;
buf : 
buf : 	va_start(args, fmt);
buf : 
buf : 	vaf.fmt = fmt;
buf : 	vaf.va = &args;
buf : 
buf : 	printk(KERN_ERR "b43-%s ERROR: %pV",
buf : 	       (wl && wl->hw) ? wiphy_name(wl->hw->wiphy) : "wlan", &vaf);
buf : 
buf : 	va_end(args);
buf : }
buf : 
buf : void b43warn(struct b43_wl *wl, const char *fmt, ...)
buf : {
buf : 	struct va_format vaf;
format vaf; 
buf : 	va_list args;
buf : 
buf : 	if (b43_modparam_verbose < B43_VERBOSITY_WARN)
if (b43_modparam_verbose < B43_VERBOSITY_WARN) 
buf : 		return;
buf : 	if (!b43_ratelimit(wl))
if (!b43_ratelimit(wl)) 
buf : 		return;
buf : 
buf : 	va_start(args, fmt);
buf : 
buf : 	vaf.fmt = fmt;
buf : 	vaf.va = &args;
buf : 
buf : 	printk(KERN_WARNING "b43-%s warning: %pV",
buf : 	       (wl && wl->hw) ? wiphy_name(wl->hw->wiphy) : "wlan", &vaf);
buf : 
buf : 	va_end(args);
buf : }
buf : 
buf : void b43dbg(struct b43_wl *wl, const char *fmt, ...)
buf : {
buf : 	struct va_format vaf;
format vaf; 
buf : 	va_list args;
buf : 
buf : 	if (b43_modparam_verbose < B43_VERBOSITY_DEBUG)
if (b43_modparam_verbose < B43_VERBOSITY_DEBUG) 
buf : 		return;
buf : 
buf : 	va_start(args, fmt);
buf : 
buf : 	vaf.fmt = fmt;
buf : 	vaf.va = &args;
buf : 
buf : 	printk(KERN_DEBUG "b43-%s debug: %pV",
buf : 	       (wl && wl->hw) ? wiphy_name(wl->hw->wiphy) : "wlan", &vaf);
buf : 
buf : 	va_end(args);
buf : }
buf : 
buf : static void b43_ram_write(struct b43_wldev *dev, u16 offset, u32 val)
buf : {
buf : 	u32 macctl;
buf : 
buf : 	B43_WARN_ON(offset % 4 != 0);
buf : 
buf : 	macctl = b43_read32(dev, B43_MMIO_MACCTL);
buf : 	if (macctl & B43_MACCTL_BE)
if (macctl & B43_MACCTL_BE) 
buf : 		val = swab32(val);
buf : 
buf : 	b43_write32(dev, B43_MMIO_RAM_CONTROL, offset);
buf : 	mmiowb();
buf : 	b43_write32(dev, B43_MMIO_RAM_DATA, val);
buf : }
buf : 
buf : static inline void b43_shm_control_word(struct b43_wldev *dev,
buf : 					u16 routing, u16 offset)
buf : {
buf : 	u32 control;
buf : 
buf : 	/* "offset" is the WORD offset. */
buf : 	control = routing;
buf : 	control <<= 16;
buf : 	control |= offset;
buf : 	b43_write32(dev, B43_MMIO_SHM_CONTROL, control);
buf : }
buf : 
buf : u32 b43_shm_read32(struct b43_wldev *dev, u16 routing, u16 offset)
buf : {
buf : 	u32 ret;
buf : 
buf : 	if (routing == B43_SHM_SHARED) {
if (routing == B43_SHM_SHARED) { 
buf : 		B43_WARN_ON(offset & 0x0001);
buf : 		if (offset & 0x0003) {
if (offset & 0x0003) { 
buf : 			/* Unaligned access */
buf : 			b43_shm_control_word(dev, routing, offset >> 2);
buf : 			ret = b43_read16(dev, B43_MMIO_SHM_DATA_UNALIGNED);
buf : 			b43_shm_control_word(dev, routing, (offset >> 2) + 1);
buf : 			ret |= ((u32)b43_read16(dev, B43_MMIO_SHM_DATA)) << 16;
buf : 
buf : 			goto out;
buf : 		}
buf : 		offset >>= 2;
buf : 	}
buf : 	b43_shm_control_word(dev, routing, offset);
buf : 	ret = b43_read32(dev, B43_MMIO_SHM_DATA);
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : u16 b43_shm_read16(struct b43_wldev *dev, u16 routing, u16 offset)
buf : {
buf : 	u16 ret;
buf : 
buf : 	if (routing == B43_SHM_SHARED) {
if (routing == B43_SHM_SHARED) { 
buf : 		B43_WARN_ON(offset & 0x0001);
buf : 		if (offset & 0x0003) {
if (offset & 0x0003) { 
buf : 			/* Unaligned access */
buf : 			b43_shm_control_word(dev, routing, offset >> 2);
buf : 			ret = b43_read16(dev, B43_MMIO_SHM_DATA_UNALIGNED);
buf : 
buf : 			goto out;
buf : 		}
buf : 		offset >>= 2;
buf : 	}
buf : 	b43_shm_control_word(dev, routing, offset);
buf : 	ret = b43_read16(dev, B43_MMIO_SHM_DATA);
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : void b43_shm_write32(struct b43_wldev *dev, u16 routing, u16 offset, u32 value)
buf : {
buf : 	if (routing == B43_SHM_SHARED) {
if (routing == B43_SHM_SHARED) { 
buf : 		B43_WARN_ON(offset & 0x0001);
buf : 		if (offset & 0x0003) {
if (offset & 0x0003) { 
buf : 			/* Unaligned access */
buf : 			b43_shm_control_word(dev, routing, offset >> 2);
buf : 			b43_write16(dev, B43_MMIO_SHM_DATA_UNALIGNED,
buf : 				    value & 0xFFFF);
buf : 			b43_shm_control_word(dev, routing, (offset >> 2) + 1);
buf : 			b43_write16(dev, B43_MMIO_SHM_DATA,
buf : 				    (value >> 16) & 0xFFFF);
buf : 			return;
buf : 		}
buf : 		offset >>= 2;
buf : 	}
buf : 	b43_shm_control_word(dev, routing, offset);
buf : 	b43_write32(dev, B43_MMIO_SHM_DATA, value);
buf : }
buf : 
buf : void b43_shm_write16(struct b43_wldev *dev, u16 routing, u16 offset, u16 value)
buf : {
buf : 	if (routing == B43_SHM_SHARED) {
if (routing == B43_SHM_SHARED) { 
buf : 		B43_WARN_ON(offset & 0x0001);
buf : 		if (offset & 0x0003) {
if (offset & 0x0003) { 
buf : 			/* Unaligned access */
buf : 			b43_shm_control_word(dev, routing, offset >> 2);
buf : 			b43_write16(dev, B43_MMIO_SHM_DATA_UNALIGNED, value);
buf : 			return;
buf : 		}
buf : 		offset >>= 2;
buf : 	}
buf : 	b43_shm_control_word(dev, routing, offset);
buf : 	b43_write16(dev, B43_MMIO_SHM_DATA, value);
buf : }
buf : 
buf : /* Read HostFlags */
buf : u64 b43_hf_read(struct b43_wldev *dev)
buf : {
buf : 	u64 ret;
buf : 
buf : 	ret = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_HOSTF3);
buf : 	ret <<= 16;
buf : 	ret |= b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_HOSTF2);
buf : 	ret <<= 16;
buf : 	ret |= b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_HOSTF1);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : /* Write HostFlags */
buf : void b43_hf_write(struct b43_wldev *dev, u64 value)
buf : {
buf : 	u16 lo, mi, hi;
buf : 
buf : 	lo = (value & 0x00000000FFFFULL);
buf : 	mi = (value & 0x0000FFFF0000ULL) >> 16;
buf : 	hi = (value & 0xFFFF00000000ULL) >> 32;
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_HOSTF1, lo);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_HOSTF2, mi);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_HOSTF3, hi);
buf : }
buf : 
buf : /* Read the firmware capabilities bitmask (Opensource firmware only) */
buf : static u16 b43_fwcapa_read(struct b43_wldev *dev)
buf : {
buf : 	B43_WARN_ON(!dev->fw.opensource);
buf : 	return b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_FWCAPA);
buf : }
buf : 
buf : void b43_tsf_read(struct b43_wldev *dev, u64 *tsf)
buf : {
buf : 	u32 low, high;
buf : 
buf : 	B43_WARN_ON(dev->dev->core_rev < 3);
buf : 
buf : 	/* The hardware guarantees us an atomic read, if we
if we 
buf : 	 * read the low register first. */
buf : 	low = b43_read32(dev, B43_MMIO_REV3PLUS_TSF_LOW);
buf : 	high = b43_read32(dev, B43_MMIO_REV3PLUS_TSF_HIGH);
buf : 
buf : 	*tsf = high;
buf : 	*tsf <<= 32;
buf : 	*tsf |= low;
buf : }
buf : 
buf : static void b43_time_lock(struct b43_wldev *dev)
buf : {
buf : 	b43_maskset32(dev, B43_MMIO_MACCTL, ~0, B43_MACCTL_TBTTHOLD);
buf : 	/* Commit the write */
buf : 	b43_read32(dev, B43_MMIO_MACCTL);
buf : }
buf : 
buf : static void b43_time_unlock(struct b43_wldev *dev)
buf : {
buf : 	b43_maskset32(dev, B43_MMIO_MACCTL, ~B43_MACCTL_TBTTHOLD, 0);
buf : 	/* Commit the write */
buf : 	b43_read32(dev, B43_MMIO_MACCTL);
buf : }
buf : 
buf : static void b43_tsf_write_locked(struct b43_wldev *dev, u64 tsf)
buf : {
buf : 	u32 low, high;
buf : 
buf : 	B43_WARN_ON(dev->dev->core_rev < 3);
buf : 
buf : 	low = tsf;
buf : 	high = (tsf >> 32);
buf : 	/* The hardware guarantees us an atomic write, if we
if we 
buf : 	 * write the low register first. */
buf : 	b43_write32(dev, B43_MMIO_REV3PLUS_TSF_LOW, low);
buf : 	mmiowb();
buf : 	b43_write32(dev, B43_MMIO_REV3PLUS_TSF_HIGH, high);
buf : 	mmiowb();
buf : }
buf : 
buf : void b43_tsf_write(struct b43_wldev *dev, u64 tsf)
buf : {
buf : 	b43_time_lock(dev);
buf : 	b43_tsf_write_locked(dev, tsf);
buf : 	b43_time_unlock(dev);
buf : }
buf : 
buf : static
buf : void b43_macfilter_set(struct b43_wldev *dev, u16 offset, const u8 *mac)
buf : {
buf : 	static const u8 zero_addr[ETH_ALEN] = { 0 };
buf : 	u16 data;
buf : 
buf : 	if (!mac)
if (!mac) 
buf : 		mac = zero_addr;
buf : 
buf : 	offset |= 0x0020;
buf : 	b43_write16(dev, B43_MMIO_MACFILTER_CONTROL, offset);
buf : 
buf : 	data = mac[0];
buf : 	data |= mac[1] << 8;
buf : 	b43_write16(dev, B43_MMIO_MACFILTER_DATA, data);
buf : 	data = mac[2];
buf : 	data |= mac[3] << 8;
buf : 	b43_write16(dev, B43_MMIO_MACFILTER_DATA, data);
buf : 	data = mac[4];
buf : 	data |= mac[5] << 8;
buf : 	b43_write16(dev, B43_MMIO_MACFILTER_DATA, data);
buf : }
buf : 
buf : static void b43_write_mac_bssid_templates(struct b43_wldev *dev)
buf : {
buf : 	const u8 *mac;
buf : 	const u8 *bssid;
buf : 	u8 mac_bssid[ETH_ALEN * 2];
buf : 	int i;
buf : 	u32 tmp;
buf : 
buf : 	bssid = dev->wl->bssid;
buf : 	mac = dev->wl->mac_addr;
buf : 
buf : 	b43_macfilter_set(dev, B43_MACFILTER_BSSID, bssid);
buf : 
buf : 	memcpy(mac_bssid, mac, ETH_ALEN);
buf : 	memcpy(mac_bssid + ETH_ALEN, bssid, ETH_ALEN);
buf : 
buf : 	/* Write our MAC address and BSSID to template ram */
buf : 	for (i = 0; i < ARRAY_SIZE(mac_bssid); i += sizeof(u32)) {
for (i = 0; i < ARRAY_SIZE(mac_bssid); i += sizeof(u32)) { 
buf : 		tmp = (u32) (mac_bssid[i + 0]);
buf : 		tmp |= (u32) (mac_bssid[i + 1]) << 8;
buf : 		tmp |= (u32) (mac_bssid[i + 2]) << 16;
buf : 		tmp |= (u32) (mac_bssid[i + 3]) << 24;
buf : 		b43_ram_write(dev, 0x20 + i, tmp);
buf : 	}
buf : }
buf : 
buf : static void b43_upload_card_macaddress(struct b43_wldev *dev)
buf : {
buf : 	b43_write_mac_bssid_templates(dev);
buf : 	b43_macfilter_set(dev, B43_MACFILTER_SELF, dev->wl->mac_addr);
buf : }
buf : 
buf : static void b43_set_slot_time(struct b43_wldev *dev, u16 slot_time)
buf : {
buf : 	/* slot_time is in usec. */
buf : 	/* This test used to exit for all but a G PHY. */
for all but a G PHY. */ 
buf : 	if (b43_current_band(dev->wl) == IEEE80211_BAND_5GHZ)
buf : 		return;
buf : 	b43_write16(dev, B43_MMIO_IFSSLOT, 510 + slot_time);
buf : 	/* Shared memory location 0x0010 is the slot time and should be
buf : 	 * set to slot_time; however, this register is initially 0 and changing
buf : 	 * the value adversely affects the transmit rate for BCM4311
for BCM4311 
buf : 	 * devices. Until this behavior is unterstood, delete this step
buf : 	 *
buf : 	 * b43_shm_write16(dev, B43_SHM_SHARED, 0x0010, slot_time);
buf : 	 */
buf : }
buf : 
buf : static void b43_short_slot_timing_enable(struct b43_wldev *dev)
buf : {
buf : 	b43_set_slot_time(dev, 9);
buf : }
buf : 
buf : static void b43_short_slot_timing_disable(struct b43_wldev *dev)
buf : {
buf : 	b43_set_slot_time(dev, 20);
buf : }
buf : 
buf : /* DummyTransmission function, as documented on
buf :  * http://bcm-v4.sipsolutions.net/802.11/DummyTransmission
buf :  */
buf : void b43_dummy_transmission(struct b43_wldev *dev, bool ofdm, bool pa_on)
buf : {
buf : 	struct b43_phy *phy = &dev->phy;
buf : 	unsigned int i, max_loop;
buf : 	u16 value;
buf : 	u32 buffer[5] = {
buf : 		0x00000000,
buf : 		0x00D40000,
buf : 		0x00000000,
buf : 		0x01000000,
buf : 		0x00000000,
buf : 	};
buf : 
buf : 	if (ofdm) {
if (ofdm) { 
buf : 		max_loop = 0x1E;
buf : 		buffer[0] = 0x000201CC;
buf : 	} else {
buf : 		max_loop = 0xFA;
buf : 		buffer[0] = 0x000B846E;
buf : 	}
buf : 
buf : 	for (i = 0; i < 5; i++)
for (i = 0; i < 5; i++) 
buf : 		b43_ram_write(dev, i * 4, buffer[i]);
buf : 
buf : 	b43_write16(dev, B43_MMIO_XMTSEL, 0x0000);
buf : 
buf : 	if (dev->dev->core_rev < 11)
if (dev->dev->core_rev < 11) 
buf : 		b43_write16(dev, B43_MMIO_WEPCTL, 0x0000);
buf : 	else
buf : 		b43_write16(dev, B43_MMIO_WEPCTL, 0x0100);
buf : 
buf : 	value = (ofdm ? 0x41 : 0x40);
buf : 	b43_write16(dev, B43_MMIO_TXE0_PHYCTL, value);
buf : 	if (phy->type == B43_PHYTYPE_N || phy->type == B43_PHYTYPE_LP ||
if (phy->type == B43_PHYTYPE_N || phy->type == B43_PHYTYPE_LP || 
buf : 	    phy->type == B43_PHYTYPE_LCN)
buf : 		b43_write16(dev, B43_MMIO_TXE0_PHYCTL1, 0x1A02);
buf : 
buf : 	b43_write16(dev, B43_MMIO_TXE0_WM_0, 0x0000);
buf : 	b43_write16(dev, B43_MMIO_TXE0_WM_1, 0x0000);
buf : 
buf : 	b43_write16(dev, B43_MMIO_XMTTPLATETXPTR, 0x0000);
buf : 	b43_write16(dev, B43_MMIO_XMTTXCNT, 0x0014);
buf : 	b43_write16(dev, B43_MMIO_XMTSEL, 0x0826);
buf : 	b43_write16(dev, B43_MMIO_TXE0_CTL, 0x0000);
buf : 
buf : 	if (!pa_on && phy->type == B43_PHYTYPE_N)
if (!pa_on && phy->type == B43_PHYTYPE_N) 
buf : 		; /*b43_nphy_pa_override(dev, false) */
buf : 
buf : 	switch (phy->type) {
buf : 	case B43_PHYTYPE_N:
buf : 	case B43_PHYTYPE_LCN:
buf : 		b43_write16(dev, B43_MMIO_TXE0_AUX, 0x00D0);
buf : 		break;
buf : 	case B43_PHYTYPE_LP:
buf : 		b43_write16(dev, B43_MMIO_TXE0_AUX, 0x0050);
buf : 		break;
buf : 	default:
buf : 		b43_write16(dev, B43_MMIO_TXE0_AUX, 0x0030);
buf : 	}
buf : 	b43_read16(dev, B43_MMIO_TXE0_AUX);
buf : 
buf : 	if (phy->radio_ver == 0x2050 && phy->radio_rev <= 0x5)
if (phy->radio_ver == 0x2050 && phy->radio_rev <= 0x5) 
buf : 		b43_radio_write16(dev, 0x0051, 0x0017);
buf : 	for (i = 0x00; i < max_loop; i++) {
for (i = 0x00; i < max_loop; i++) { 
buf : 		value = b43_read16(dev, B43_MMIO_TXE0_STATUS);
buf : 		if (value & 0x0080)
if (value & 0x0080) 
buf : 			break;
buf : 		udelay(10);
buf : 	}
buf : 	for (i = 0x00; i < 0x0A; i++) {
for (i = 0x00; i < 0x0A; i++) { 
buf : 		value = b43_read16(dev, B43_MMIO_TXE0_STATUS);
buf : 		if (value & 0x0400)
if (value & 0x0400) 
buf : 			break;
buf : 		udelay(10);
buf : 	}
buf : 	for (i = 0x00; i < 0x19; i++) {
for (i = 0x00; i < 0x19; i++) { 
buf : 		value = b43_read16(dev, B43_MMIO_IFSSTAT);
buf : 		if (!(value & 0x0100))
if (!(value & 0x0100)) 
buf : 			break;
buf : 		udelay(10);
buf : 	}
buf : 	if (phy->radio_ver == 0x2050 && phy->radio_rev <= 0x5)
if (phy->radio_ver == 0x2050 && phy->radio_rev <= 0x5) 
buf : 		b43_radio_write16(dev, 0x0051, 0x0037);
buf : }
buf : 
buf : static void key_write(struct b43_wldev *dev,
buf : 		      u8 index, u8 algorithm, const u8 *key)
buf : {
buf : 	unsigned int i;
buf : 	u32 offset;
buf : 	u16 value;
buf : 	u16 kidx;
buf : 
buf : 	/* Key index/algo block */
buf : 	kidx = b43_kidx_to_fw(dev, index);
buf : 	value = ((kidx << 4) | algorithm);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED,
buf : 			B43_SHM_SH_KEYIDXBLOCK + (kidx * 2), value);
buf : 
buf : 	/* Write the key to the Key Table Pointer offset */
buf : 	offset = dev->ktp + (index * B43_SEC_KEYSIZE);
buf : 	for (i = 0; i < B43_SEC_KEYSIZE; i += 2) {
for (i = 0; i < B43_SEC_KEYSIZE; i += 2) { 
buf : 		value = key[i];
buf : 		value |= (u16) (key[i + 1]) << 8;
buf : 		b43_shm_write16(dev, B43_SHM_SHARED, offset + i, value);
buf : 	}
buf : }
buf : 
buf : static void keymac_write(struct b43_wldev *dev, u8 index, const u8 *addr)
buf : {
buf : 	u32 addrtmp[2] = { 0, 0, };
buf : 	u8 pairwise_keys_start = B43_NR_GROUP_KEYS * 2;
buf : 
buf : 	if (b43_new_kidx_api(dev))
if (b43_new_kidx_api(dev)) 
buf : 		pairwise_keys_start = B43_NR_GROUP_KEYS;
buf : 
buf : 	B43_WARN_ON(index < pairwise_keys_start);
buf : 	/* We have four default TX keys and possibly four default RX keys.
buf : 	 * Physical mac 0 is mapped to physical key 4 or 8, depending
buf : 	 * on the firmware version.
buf : 	 * So we must adjust the index here.
buf : 	 */
buf : 	index -= pairwise_keys_start;
buf : 	B43_WARN_ON(index >= B43_NR_PAIRWISE_KEYS);
buf : 
buf : 	if (addr) {
if (addr) { 
buf : 		addrtmp[0] = addr[0];
buf : 		addrtmp[0] |= ((u32) (addr[1]) << 8);
buf : 		addrtmp[0] |= ((u32) (addr[2]) << 16);
buf : 		addrtmp[0] |= ((u32) (addr[3]) << 24);
buf : 		addrtmp[1] = addr[4];
buf : 		addrtmp[1] |= ((u32) (addr[5]) << 8);
buf : 	}
buf : 
buf : 	/* Receive match transmitter address (RCMTA) mechanism */
buf : 	b43_shm_write32(dev, B43_SHM_RCMTA,
buf : 			(index * 2) + 0, addrtmp[0]);
buf : 	b43_shm_write16(dev, B43_SHM_RCMTA,
buf : 			(index * 2) + 1, addrtmp[1]);
buf : }
buf : 
buf : /* The ucode will use phase1 key with TEK key to decrypt rx packets.
buf :  * When a packet is received, the iv32 is checked.
buf :  * - if it doesn't the packet is returned without modification (and software
if it doesn't the packet is returned without modification (and software 
buf :  *   decryption can be done). That's what happen when iv16 wrap.
buf :  * - if it does, the rc4 key is computed, and decryption is tried.
if it does, the rc4 key is computed, and decryption is tried. 
buf :  *   Either it will success and B43_RX_MAC_DEC is returned,
buf :  *   either it fails and B43_RX_MAC_DEC|B43_RX_MAC_DECERR is returned
buf :  *   and the packet is not usable (it got modified by the ucode).
ified by the ucode). 
buf :  * So in order to never have B43_RX_MAC_DECERR, we should provide
buf :  * a iv32 and phase1key that match. Because we drop packets in case of
buf :  * B43_RX_MAC_DECERR, if we have a correct iv32 but a wrong phase1key, all
if we have a correct iv32 but a wrong phase1key, all 
buf :  * packets will be lost without higher layer knowing (ie no resync possible
buf :  * until next wrap).
buf :  *
buf :  * NOTE : this should support 50 key like RCMTA because
buf :  * (B43_SHM_SH_KEYIDXBLOCK - B43_SHM_SH_TKIPTSCTTAK)/14 = 50
buf :  */
buf : static void rx_tkip_phase1_write(struct b43_wldev *dev, u8 index, u32 iv32,
buf : 		u16 *phase1key)
buf : {
buf : 	unsigned int i;
buf : 	u32 offset;
buf : 	u8 pairwise_keys_start = B43_NR_GROUP_KEYS * 2;
buf : 
buf : 	if (!modparam_hwtkip)
if (!modparam_hwtkip) 
buf : 		return;
buf : 
buf : 	if (b43_new_kidx_api(dev))
if (b43_new_kidx_api(dev)) 
buf : 		pairwise_keys_start = B43_NR_GROUP_KEYS;
buf : 
buf : 	B43_WARN_ON(index < pairwise_keys_start);
buf : 	/* We have four default TX keys and possibly four default RX keys.
buf : 	 * Physical mac 0 is mapped to physical key 4 or 8, depending
buf : 	 * on the firmware version.
buf : 	 * So we must adjust the index here.
buf : 	 */
buf : 	index -= pairwise_keys_start;
buf : 	B43_WARN_ON(index >= B43_NR_PAIRWISE_KEYS);
buf : 
buf : 	if (b43_debug(dev, B43_DBG_KEYS)) {
if (b43_debug(dev, B43_DBG_KEYS)) { 
buf : 		b43dbg(dev->wl, "rx_tkip_phase1_write : idx 0x%x, iv32 0x%x\n",
buf : 				index, iv32);
buf : 	}
buf : 	/* Write the key to the  RX tkip shared mem */
buf : 	offset = B43_SHM_SH_TKIPTSCTTAK + index * (10 + 4);
buf : 	for (i = 0; i < 10; i += 2) {
for (i = 0; i < 10; i += 2) { 
buf : 		b43_shm_write16(dev, B43_SHM_SHARED, offset + i,
buf : 				phase1key ? phase1key[i / 2] : 0);
buf : 	}
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, offset + i, iv32);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, offset + i + 2, iv32 >> 16);
buf : }
buf : 
buf : static void b43_op_update_tkip_key(struct ieee80211_hw *hw,
buf : 				   struct ieee80211_vif *vif,
if *vif, 
buf : 				   struct ieee80211_key_conf *keyconf,
buf : 				   struct ieee80211_sta *sta,
buf : 				   u32 iv32, u16 *phase1key)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 	int index = keyconf->hw_key_idx;
buf : 
buf : 	if (B43_WARN_ON(!modparam_hwtkip))
if (B43_WARN_ON(!modparam_hwtkip)) 
buf : 		return;
buf : 
buf : 	/* This is only called from the RX path through mac80211, where
buf : 	 * our mutex is already locked. */
buf : 	B43_WARN_ON(!mutex_is_locked(&wl->mutex));
buf : 	dev = wl->current_dev;
buf : 	B43_WARN_ON(!dev || b43_status(dev) < B43_STAT_INITIALIZED);
buf : 
buf : 	keymac_write(dev, index, NULL);	/* First zero out mac to avoid race */
buf : 
buf : 	rx_tkip_phase1_write(dev, index, iv32, phase1key);
buf : 	/* only pairwise TKIP keys are supported right now */
buf : 	if (WARN_ON(!sta))
if (WARN_ON(!sta)) 
buf : 		return;
buf : 	keymac_write(dev, index, sta->addr);
buf : }
buf : 
buf : static void do_key_write(struct b43_wldev *dev,
buf : 			 u8 index, u8 algorithm,
buf : 			 const u8 *key, size_t key_len, const u8 *mac_addr)
buf : {
buf : 	u8 buf[B43_SEC_KEYSIZE] = { 0, };
buf : 	u8 pairwise_keys_start = B43_NR_GROUP_KEYS * 2;
buf : 
buf : 	if (b43_new_kidx_api(dev))
if (b43_new_kidx_api(dev)) 
buf : 		pairwise_keys_start = B43_NR_GROUP_KEYS;
buf : 
buf : 	B43_WARN_ON(index >= ARRAY_SIZE(dev->key));
buf : 	B43_WARN_ON(key_len > B43_SEC_KEYSIZE);
buf : 
buf : 	if (index >= pairwise_keys_start)
if (index >= pairwise_keys_start) 
buf : 		keymac_write(dev, index, NULL);	/* First zero out mac. */
buf : 	if (algorithm == B43_SEC_ALGO_TKIP) {
if (algorithm == B43_SEC_ALGO_TKIP) { 
buf : 		/*
buf : 		 * We should provide an initial iv32, phase1key pair.
buf : 		 * We could start with iv32=0 and compute the corresponding
buf : 		 * phase1key, but this means calling ieee80211_get_tkip_key
buf : 		 * with a fake skb (or export other tkip function).
buf : 		 * Because we are lazy we hope iv32 won't start with
buf : 		 * 0xffffffff and let's b43_op_update_tkip_key provide a
buf : 		 * correct pair.
buf : 		 */
buf : 		rx_tkip_phase1_write(dev, index, 0xffffffff, (u16*)buf);
buf : 	} else if (index >= pairwise_keys_start) /* clear it */
if (index >= pairwise_keys_start) /* clear it */ 
buf : 		rx_tkip_phase1_write(dev, index, 0, NULL);
buf : 	if (key)
if (key) 
buf : 		memcpy(buf, key, key_len);
buf : 	key_write(dev, index, algorithm, buf);
buf : 	if (index >= pairwise_keys_start)
if (index >= pairwise_keys_start) 
buf : 		keymac_write(dev, index, mac_addr);
buf : 
buf : 	dev->key[index].algorithm = algorithm;
buf : }
buf : 
buf : static int b43_key_write(struct b43_wldev *dev,
buf : 			 int index, u8 algorithm,
buf : 			 const u8 *key, size_t key_len,
buf : 			 const u8 *mac_addr,
buf : 			 struct ieee80211_key_conf *keyconf)
buf : {
buf : 	int i;
buf : 	int pairwise_keys_start;
buf : 
buf : 	/* For ALG_TKIP the key is encoded as a 256-bit (32 byte) data block:
buf : 	 * 	- Temporal Encryption Key (128 bits)
buf : 	 * 	- Temporal Authenticator Tx MIC Key (64 bits)
buf : 	 * 	- Temporal Authenticator Rx MIC Key (64 bits)
buf : 	 *
buf : 	 * 	Hardware only store TEK
buf : 	 */
buf : 	if (algorithm == B43_SEC_ALGO_TKIP && key_len == 32)
if (algorithm == B43_SEC_ALGO_TKIP && key_len == 32) 
buf : 		key_len = 16;
buf : 	if (key_len > B43_SEC_KEYSIZE)
if (key_len > B43_SEC_KEYSIZE) 
buf : 		return -EINVAL;
buf : 	for (i = 0; i < ARRAY_SIZE(dev->key); i++) {
for (i = 0; i < ARRAY_SIZE(dev->key); i++) { 
buf : 		/* Check that we don't already have this key. */
buf : 		B43_WARN_ON(dev->key[i].keyconf == keyconf);
buf : 	}
buf : 	if (index < 0) {
if (index < 0) { 
buf : 		/* Pairwise key. Get an empty slot for the key. */
for the key. */ 
buf : 		if (b43_new_kidx_api(dev))
buf : 			pairwise_keys_start = B43_NR_GROUP_KEYS;
buf : 		else
buf : 			pairwise_keys_start = B43_NR_GROUP_KEYS * 2;
buf : 		for (i = pairwise_keys_start;
for (i = pairwise_keys_start; 
buf : 		     i < pairwise_keys_start + B43_NR_PAIRWISE_KEYS;
buf : 		     i++) {
buf : 			B43_WARN_ON(i >= ARRAY_SIZE(dev->key));
buf : 			if (!dev->key[i].keyconf) {
if (!dev->key[i].keyconf) { 
buf : 				/* found empty */
buf : 				index = i;
buf : 				break;
buf : 			}
buf : 		}
buf : 		if (index < 0) {
if (index < 0) { 
buf : 			b43warn(dev->wl, "Out of hardware key memory\n");
buf : 			return -ENOSPC;
buf : 		}
buf : 	} else
buf : 		B43_WARN_ON(index > 3);
buf : 
buf : 	do_key_write(dev, index, algorithm, key, key_len, mac_addr);
buf : 	if ((index <= 3) && !b43_new_kidx_api(dev)) {
if ((index <= 3) && !b43_new_kidx_api(dev)) { 
buf : 		/* Default RX key */
buf : 		B43_WARN_ON(mac_addr);
buf : 		do_key_write(dev, index + 4, algorithm, key, key_len, NULL);
buf : 	}
buf : 	keyconf->hw_key_idx = index;
buf : 	dev->key[index].keyconf = keyconf;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int b43_key_clear(struct b43_wldev *dev, int index)
buf : {
buf : 	if (B43_WARN_ON((index < 0) || (index >= ARRAY_SIZE(dev->key))))
if (B43_WARN_ON((index < 0) || (index >= ARRAY_SIZE(dev->key)))) 
buf : 		return -EINVAL;
buf : 	do_key_write(dev, index, B43_SEC_ALGO_NONE,
buf : 		     NULL, B43_SEC_KEYSIZE, NULL);
buf : 	if ((index <= 3) && !b43_new_kidx_api(dev)) {
if ((index <= 3) && !b43_new_kidx_api(dev)) { 
buf : 		do_key_write(dev, index + 4, B43_SEC_ALGO_NONE,
buf : 			     NULL, B43_SEC_KEYSIZE, NULL);
buf : 	}
buf : 	dev->key[index].keyconf = NULL;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void b43_clear_keys(struct b43_wldev *dev)
buf : {
buf : 	int i, count;
buf : 
buf : 	if (b43_new_kidx_api(dev))
if (b43_new_kidx_api(dev)) 
buf : 		count = B43_NR_GROUP_KEYS + B43_NR_PAIRWISE_KEYS;
buf : 	else
buf : 		count = B43_NR_GROUP_KEYS * 2 + B43_NR_PAIRWISE_KEYS;
buf : 	for (i = 0; i < count; i++)
for (i = 0; i < count; i++) 
buf : 		b43_key_clear(dev, i);
buf : }
buf : 
buf : static void b43_dump_keymemory(struct b43_wldev *dev)
buf : {
buf : 	unsigned int i, index, count, offset, pairwise_keys_start;
buf : 	u8 mac[ETH_ALEN];
buf : 	u16 algo;
buf : 	u32 rcmta0;
buf : 	u16 rcmta1;
buf : 	u64 hf;
buf : 	struct b43_key *key;
buf : 
buf : 	if (!b43_debug(dev, B43_DBG_KEYS))
if (!b43_debug(dev, B43_DBG_KEYS)) 
buf : 		return;
buf : 
buf : 	hf = b43_hf_read(dev);
buf : 	b43dbg(dev->wl, "Hardware key memory dump:  USEDEFKEYS=%u\n",
buf : 	       !!(hf & B43_HF_USEDEFKEYS));
buf : 	if (b43_new_kidx_api(dev)) {
if (b43_new_kidx_api(dev)) { 
buf : 		pairwise_keys_start = B43_NR_GROUP_KEYS;
buf : 		count = B43_NR_GROUP_KEYS + B43_NR_PAIRWISE_KEYS;
buf : 	} else {
buf : 		pairwise_keys_start = B43_NR_GROUP_KEYS * 2;
buf : 		count = B43_NR_GROUP_KEYS * 2 + B43_NR_PAIRWISE_KEYS;
buf : 	}
buf : 	for (index = 0; index < count; index++) {
for (index = 0; index < count; index++) { 
buf : 		key = &(dev->key[index]);
buf : 		printk(KERN_DEBUG "Key slot %02u: %s",
buf : 		       index, (key->keyconf == NULL) ? " " : "*");
buf : 		offset = dev->ktp + (index * B43_SEC_KEYSIZE);
buf : 		for (i = 0; i < B43_SEC_KEYSIZE; i += 2) {
for (i = 0; i < B43_SEC_KEYSIZE; i += 2) { 
buf : 			u16 tmp = b43_shm_read16(dev, B43_SHM_SHARED, offset + i);
buf : 			printk("%02X%02X", (tmp & 0xFF), ((tmp >> 8) & 0xFF));
buf : 		}
buf : 
buf : 		algo = b43_shm_read16(dev, B43_SHM_SHARED,
buf : 				      B43_SHM_SH_KEYIDXBLOCK + (index * 2));
buf : 		printk("   Algo: %04X/%02X", algo, key->algorithm);
buf : 
buf : 		if (index >= pairwise_keys_start) {
if (index >= pairwise_keys_start) { 
buf : 			if (key->algorithm == B43_SEC_ALGO_TKIP) {
buf : 				printk("   TKIP: ");
buf : 				offset = B43_SHM_SH_TKIPTSCTTAK + (index - 4) * (10 + 4);
buf : 				for (i = 0; i < 14; i += 2) {
for (i = 0; i < 14; i += 2) { 
buf : 					u16 tmp = b43_shm_read16(dev, B43_SHM_SHARED, offset + i);
buf : 					printk("%02X%02X", (tmp & 0xFF), ((tmp >> 8) & 0xFF));
buf : 				}
buf : 			}
buf : 			rcmta0 = b43_shm_read32(dev, B43_SHM_RCMTA,
buf : 						((index - pairwise_keys_start) * 2) + 0);
buf : 			rcmta1 = b43_shm_read16(dev, B43_SHM_RCMTA,
buf : 						((index - pairwise_keys_start) * 2) + 1);
buf : 			*((__le32 *)(&mac[0])) = cpu_to_le32(rcmta0);
buf : 			*((__le16 *)(&mac[4])) = cpu_to_le16(rcmta1);
buf : 			printk("   MAC: %pM", mac);
buf : 		} else
buf : 			printk("   DEFAULT KEY");
buf : 		printk("\n");
buf : 	}
buf : }
buf : 
buf : void b43_power_saving_ctl_bits(struct b43_wldev *dev, unsigned int ps_flags)
buf : {
buf : 	u32 macctl;
buf : 	u16 ucstat;
buf : 	bool hwps;
buf : 	bool awake;
buf : 	int i;
buf : 
buf : 	B43_WARN_ON((ps_flags & B43_PS_ENABLED) &&
buf : 		    (ps_flags & B43_PS_DISABLED));
buf : 	B43_WARN_ON((ps_flags & B43_PS_AWAKE) && (ps_flags & B43_PS_ASLEEP));
buf : 
buf : 	if (ps_flags & B43_PS_ENABLED) {
if (ps_flags & B43_PS_ENABLED) { 
buf : 		hwps = true;
buf : 	} else if (ps_flags & B43_PS_DISABLED) {
if (ps_flags & B43_PS_DISABLED) { 
buf : 		hwps = false;
buf : 	} else {
buf : 		//TODO: If powersave is not off and FIXME is not set and we are not in adhoc
buf : 		//      and thus is not an AP and we are associated, set bit 25
buf : 	}
buf : 	if (ps_flags & B43_PS_AWAKE) {
if (ps_flags & B43_PS_AWAKE) { 
buf : 		awake = true;
buf : 	} else if (ps_flags & B43_PS_ASLEEP) {
if (ps_flags & B43_PS_ASLEEP) { 
buf : 		awake = false;
buf : 	} else {
buf : 		//TODO: If the device is awake or this is an AP, or we are scanning, or FIXME,
buf : 		//      or we are associated, or FIXME, or the latest PS-Poll packet sent was
buf : 		//      successful, set bit26
buf : 	}
buf : 
buf : /* FIXME: For now we force awake-on and hwps-off */
force awake-on and hwps-off */ 
buf : 	hwps = false;
buf : 	awake = true;
buf : 
buf : 	macctl = b43_read32(dev, B43_MMIO_MACCTL);
buf : 	if (hwps)
if (hwps) 
buf : 		macctl |= B43_MACCTL_HWPS;
buf : 	else
buf : 		macctl &= ~B43_MACCTL_HWPS;
buf : 	if (awake)
if (awake) 
buf : 		macctl |= B43_MACCTL_AWAKE;
buf : 	else
buf : 		macctl &= ~B43_MACCTL_AWAKE;
buf : 	b43_write32(dev, B43_MMIO_MACCTL, macctl);
buf : 	/* Commit write */
buf : 	b43_read32(dev, B43_MMIO_MACCTL);
buf : 	if (awake && dev->dev->core_rev >= 5) {
if (awake && dev->dev->core_rev >= 5) { 
buf : 		/* Wait for the microcode to wake up. */
for the microcode to wake up. */ 
buf : 		for (i = 0; i < 100; i++) {
buf : 			ucstat = b43_shm_read16(dev, B43_SHM_SHARED,
buf : 						B43_SHM_SH_UCODESTAT);
buf : 			if (ucstat != B43_SHM_SH_UCODESTAT_SLEEP)
if (ucstat != B43_SHM_SH_UCODESTAT_SLEEP) 
buf : 				break;
buf : 			udelay(10);
buf : 		}
buf : 	}
buf : }
buf : 
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : static void b43_bcma_phy_reset(struct b43_wldev *dev)
buf : {
buf : 	u32 flags;
buf : 
buf : 	/* Put PHY into reset */
buf : 	flags = bcma_aread32(dev->dev->bdev, BCMA_IOCTL);
buf : 	flags |= B43_BCMA_IOCTL_PHY_RESET;
buf : 	flags |= B43_BCMA_IOCTL_PHY_BW_20MHZ; /* Make 20 MHz def */
buf : 	bcma_awrite32(dev->dev->bdev, BCMA_IOCTL, flags);
buf : 	udelay(2);
buf : 
buf : 	b43_phy_take_out_of_reset(dev);
buf : }
buf : 
buf : static void b43_bcma_wireless_core_reset(struct b43_wldev *dev, bool gmode)
buf : {
buf : 	u32 req = B43_BCMA_CLKCTLST_80211_PLL_REQ |
buf : 		  B43_BCMA_CLKCTLST_PHY_PLL_REQ;
buf : 	u32 status = B43_BCMA_CLKCTLST_80211_PLL_ST |
buf : 		     B43_BCMA_CLKCTLST_PHY_PLL_ST;
buf : 	u32 flags;
buf : 
buf : 	flags = B43_BCMA_IOCTL_PHY_CLKEN;
buf : 	if (gmode)
if (gmode) 
buf : 		flags |= B43_BCMA_IOCTL_GMODE;
buf : 	b43_device_enable(dev, flags);
buf : 
buf : 	bcma_core_set_clockmode(dev->dev->bdev, BCMA_CLKMODE_FAST);
buf : 	b43_bcma_phy_reset(dev);
buf : 	bcma_core_pll_ctl(dev->dev->bdev, req, status, true);
buf : }
buf : #endif
if 
buf : 
buf : #ifdef CONFIG_B43_SSB
buf : static void b43_ssb_wireless_core_reset(struct b43_wldev *dev, bool gmode)
buf : {
buf : 	u32 flags = 0;
buf : 
buf : 	if (gmode)
if (gmode) 
buf : 		flags |= B43_TMSLOW_GMODE;
buf : 	flags |= B43_TMSLOW_PHYCLKEN;
buf : 	flags |= B43_TMSLOW_PHYRESET;
buf : 	if (dev->phy.type == B43_PHYTYPE_N)
if (dev->phy.type == B43_PHYTYPE_N) 
buf : 		flags |= B43_TMSLOW_PHY_BANDWIDTH_20MHZ; /* Make 20 MHz def */
buf : 	b43_device_enable(dev, flags);
buf : 	msleep(2);		/* Wait for the PLL to turn on. */
for the PLL to turn on. */ 
buf : 
buf : 	b43_phy_take_out_of_reset(dev);
buf : }
buf : #endif
if 
buf : 
buf : void b43_wireless_core_reset(struct b43_wldev *dev, bool gmode)
buf : {
buf : 	u32 macctl;
buf : 
buf : 	switch (dev->dev->bus_type) {
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	case B43_BUS_BCMA:
buf : 		b43_bcma_wireless_core_reset(dev, gmode);
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	case B43_BUS_SSB:
buf : 		b43_ssb_wireless_core_reset(dev, gmode);
buf : 		break;
buf : #endif
if 
buf : 	}
buf : 
buf : 	/* Turn Analog ON, but only if we already know the PHY-type.
buf : 	 * This protects against very early setup where we don't know the
buf : 	 * PHY-type, yet. wireless_core_reset will be called once again later,
buf : 	 * when we know the PHY-type. */
buf : 	if (dev->phy.ops)
if (dev->phy.ops) 
buf : 		dev->phy.ops->switch_analog(dev, 1);
buf : 
buf : 	macctl = b43_read32(dev, B43_MMIO_MACCTL);
buf : 	macctl &= ~B43_MACCTL_GMODE;
buf : 	if (gmode)
if (gmode) 
buf : 		macctl |= B43_MACCTL_GMODE;
buf : 	macctl |= B43_MACCTL_IHR_ENABLED;
buf : 	b43_write32(dev, B43_MMIO_MACCTL, macctl);
buf : }
buf : 
buf : static void handle_irq_transmit_status(struct b43_wldev *dev)
buf : {
buf : 	u32 v0, v1;
buf : 	u16 tmp;
buf : 	struct b43_txstatus stat;
buf : 
buf : 	while (1) {
while (1) { 
buf : 		v0 = b43_read32(dev, B43_MMIO_XMITSTAT_0);
buf : 		if (!(v0 & 0x00000001))
if (!(v0 & 0x00000001)) 
buf : 			break;
buf : 		v1 = b43_read32(dev, B43_MMIO_XMITSTAT_1);
buf : 
buf : 		stat.cookie = (v0 >> 16);
buf : 		stat.seq = (v1 & 0x0000FFFF);
buf : 		stat.phy_stat = ((v1 & 0x00FF0000) >> 16);
buf : 		tmp = (v0 & 0x0000FFFF);
buf : 		stat.frame_count = ((tmp & 0xF000) >> 12);
buf : 		stat.rts_count = ((tmp & 0x0F00) >> 8);
buf : 		stat.supp_reason = ((tmp & 0x001C) >> 2);
buf : 		stat.pm_indicated = !!(tmp & 0x0080);
buf : 		stat.intermediate = !!(tmp & 0x0040);
buf : 		stat.for_ampdu = !!(tmp & 0x0020);
for_ampdu = !!(tmp & 0x0020); 
buf : 		stat.acked = !!(tmp & 0x0002);
buf : 
buf : 		b43_handle_txstatus(dev, &stat);
buf : 	}
buf : }
buf : 
buf : static void drain_txstatus_queue(struct b43_wldev *dev)
buf : {
buf : 	u32 dummy;
buf : 
buf : 	if (dev->dev->core_rev < 5)
if (dev->dev->core_rev < 5) 
buf : 		return;
buf : 	/* Read all entries from the microcode TXstatus FIFO
buf : 	 * and throw them away.
buf : 	 */
buf : 	while (1) {
while (1) { 
buf : 		dummy = b43_read32(dev, B43_MMIO_XMITSTAT_0);
buf : 		if (!(dummy & 0x00000001))
if (!(dummy & 0x00000001)) 
buf : 			break;
buf : 		dummy = b43_read32(dev, B43_MMIO_XMITSTAT_1);
buf : 	}
buf : }
buf : 
buf : static u32 b43_jssi_read(struct b43_wldev *dev)
buf : {
buf : 	u32 val = 0;
buf : 
buf : 	val = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_JSSI1);
buf : 	val <<= 16;
buf : 	val |= b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_JSSI0);
buf : 
buf : 	return val;
buf : }
buf : 
buf : static void b43_jssi_write(struct b43_wldev *dev, u32 jssi)
buf : {
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_JSSI0,
buf : 			(jssi & 0x0000FFFF));
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_JSSI1,
buf : 			(jssi & 0xFFFF0000) >> 16);
buf : }
buf : 
buf : static void b43_generate_noise_sample(struct b43_wldev *dev)
buf : {
buf : 	b43_jssi_write(dev, 0x7F7F7F7F);
buf : 	b43_write32(dev, B43_MMIO_MACCMD,
buf : 		    b43_read32(dev, B43_MMIO_MACCMD) | B43_MACCMD_BGNOISE);
buf : }
buf : 
buf : static void b43_calculate_link_quality(struct b43_wldev *dev)
buf : {
buf : 	/* Top half of Link Quality calculation. */
buf : 
buf : 	if (dev->phy.type != B43_PHYTYPE_G)
if (dev->phy.type != B43_PHYTYPE_G) 
buf : 		return;
buf : 	if (dev->noisecalc.calculation_running)
if (dev->noisecalc.calculation_running) 
buf : 		return;
buf : 	dev->noisecalc.calculation_running = true;
buf : 	dev->noisecalc.nr_samples = 0;
buf : 
buf : 	b43_generate_noise_sample(dev);
buf : }
buf : 
buf : static void handle_irq_noise(struct b43_wldev *dev)
buf : {
buf : 	struct b43_phy_g *phy = dev->phy.g;
buf : 	u16 tmp;
buf : 	u8 noise[4];
buf : 	u8 i, j;
buf : 	s32 average;
buf : 
buf : 	/* Bottom half of Link Quality calculation. */
buf : 
buf : 	if (dev->phy.type != B43_PHYTYPE_G)
if (dev->phy.type != B43_PHYTYPE_G) 
buf : 		return;
buf : 
buf : 	/* Possible race condition: It might be possible that the user
buf : 	 * changed to a different channel in the meantime since we
ifferent channel in the meantime since we 
buf : 	 * started the calculation. We ignore that fact, since it's
buf : 	 * not really that much of a problem. The background noise is
buf : 	 * an estimation only anyway. Slightly wrong results will get damped
buf : 	 * by the averaging of the 8 sample rounds. Additionally the
buf : 	 * value is shortlived. So it will be replaced by the next noise
buf : 	 * calculation round soon. */
buf : 
buf : 	B43_WARN_ON(!dev->noisecalc.calculation_running);
buf : 	*((__le32 *)noise) = cpu_to_le32(b43_jssi_read(dev));
buf : 	if (noise[0] == 0x7F || noise[1] == 0x7F ||
if (noise[0] == 0x7F || noise[1] == 0x7F || 
buf : 	    noise[2] == 0x7F || noise[3] == 0x7F)
buf : 		goto generate_new;
buf : 
buf : 	/* Get the noise samples. */
buf : 	B43_WARN_ON(dev->noisecalc.nr_samples >= 8);
buf : 	i = dev->noisecalc.nr_samples;
buf : 	noise[0] = clamp_val(noise[0], 0, ARRAY_SIZE(phy->nrssi_lt) - 1);
buf : 	noise[1] = clamp_val(noise[1], 0, ARRAY_SIZE(phy->nrssi_lt) - 1);
buf : 	noise[2] = clamp_val(noise[2], 0, ARRAY_SIZE(phy->nrssi_lt) - 1);
buf : 	noise[3] = clamp_val(noise[3], 0, ARRAY_SIZE(phy->nrssi_lt) - 1);
buf : 	dev->noisecalc.samples[i][0] = phy->nrssi_lt[noise[0]];
buf : 	dev->noisecalc.samples[i][1] = phy->nrssi_lt[noise[1]];
buf : 	dev->noisecalc.samples[i][2] = phy->nrssi_lt[noise[2]];
buf : 	dev->noisecalc.samples[i][3] = phy->nrssi_lt[noise[3]];
buf : 	dev->noisecalc.nr_samples++;
buf : 	if (dev->noisecalc.nr_samples == 8) {
if (dev->noisecalc.nr_samples == 8) { 
buf : 		/* Calculate the Link Quality by the noise samples. */
buf : 		average = 0;
buf : 		for (i = 0; i < 8; i++) {
for (i = 0; i < 8; i++) { 
buf : 			for (j = 0; j < 4; j++)
buf : 				average += dev->noisecalc.samples[i][j];
buf : 		}
buf : 		average /= (8 * 4);
buf : 		average *= 125;
buf : 		average += 64;
buf : 		average /= 128;
buf : 		tmp = b43_shm_read16(dev, B43_SHM_SHARED, 0x40C);
buf : 		tmp = (tmp / 128) & 0x1F;
buf : 		if (tmp >= 8)
if (tmp >= 8) 
buf : 			average += 2;
buf : 		else
buf : 			average -= 25;
buf : 		if (tmp == 8)
if (tmp == 8) 
buf : 			average -= 72;
buf : 		else
buf : 			average -= 48;
buf : 
buf : 		dev->stats.link_noise = average;
buf : 		dev->noisecalc.calculation_running = false;
buf : 		return;
buf : 	}
buf : generate_new:
buf : 	b43_generate_noise_sample(dev);
buf : }
buf : 
buf : static void handle_irq_tbtt_indication(struct b43_wldev *dev)
buf : {
buf : 	if (b43_is_mode(dev->wl, NL80211_IFTYPE_AP)) {
if (b43_is_mode(dev->wl, NL80211_IFTYPE_AP)) { 
buf : 		///TODO: PS TBTT
buf : 	} else {
buf : 		if (1 /*FIXME: the last PSpoll frame was sent successfully */ )
if (1 /*FIXME: the last PSpoll frame was sent successfully */ ) 
buf : 			b43_power_saving_ctl_bits(dev, 0);
buf : 	}
buf : 	if (b43_is_mode(dev->wl, NL80211_IFTYPE_ADHOC))
if (b43_is_mode(dev->wl, NL80211_IFTYPE_ADHOC)) 
buf : 		dev->dfq_valid = true;
buf : }
buf : 
buf : static void handle_irq_atim_end(struct b43_wldev *dev)
buf : {
buf : 	if (dev->dfq_valid) {
if (dev->dfq_valid) { 
buf : 		b43_write32(dev, B43_MMIO_MACCMD,
buf : 			    b43_read32(dev, B43_MMIO_MACCMD)
buf : 			    | B43_MACCMD_DFQ_VALID);
buf : 		dev->dfq_valid = false;
buf : 	}
buf : }
buf : 
buf : static void handle_irq_pmq(struct b43_wldev *dev)
buf : {
buf : 	u32 tmp;
buf : 
buf : 	//TODO: AP mode.
buf : 
buf : 	while (1) {
while (1) { 
buf : 		tmp = b43_read32(dev, B43_MMIO_PS_STATUS);
buf : 		if (!(tmp & 0x00000008))
if (!(tmp & 0x00000008)) 
buf : 			break;
buf : 	}
buf : 	/* 16bit write is odd, but correct. */
buf : 	b43_write16(dev, B43_MMIO_PS_STATUS, 0x0002);
buf : }
buf : 
buf : static void b43_write_template_common(struct b43_wldev *dev,
buf : 				      const u8 *data, u16 size,
buf : 				      u16 ram_offset,
buf : 				      u16 shm_size_offset, u8 rate)
buf : {
buf : 	u32 i, tmp;
buf : 	struct b43_plcp_hdr4 plcp;
buf : 
buf : 	plcp.data = 0;
buf : 	b43_generate_plcp_hdr(&plcp, size + FCS_LEN, rate);
buf : 	b43_ram_write(dev, ram_offset, le32_to_cpu(plcp.data));
buf : 	ram_offset += sizeof(u32);
buf : 	/* The PLCP is 6 bytes long, but we only wrote 4 bytes, yet.
buf : 	 * So leave the first two bytes of the next write blank.
buf : 	 */
buf : 	tmp = (u32) (data[0]) << 16;
buf : 	tmp |= (u32) (data[1]) << 24;
buf : 	b43_ram_write(dev, ram_offset, tmp);
buf : 	ram_offset += sizeof(u32);
buf : 	for (i = 2; i < size; i += sizeof(u32)) {
for (i = 2; i < size; i += sizeof(u32)) { 
buf : 		tmp = (u32) (data[i + 0]);
buf : 		if (i + 1 < size)
if (i + 1 < size) 
buf : 			tmp |= (u32) (data[i + 1]) << 8;
buf : 		if (i + 2 < size)
if (i + 2 < size) 
buf : 			tmp |= (u32) (data[i + 2]) << 16;
buf : 		if (i + 3 < size)
if (i + 3 < size) 
buf : 			tmp |= (u32) (data[i + 3]) << 24;
buf : 		b43_ram_write(dev, ram_offset + i - 2, tmp);
buf : 	}
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, shm_size_offset,
buf : 			size + sizeof(struct b43_plcp_hdr6));
buf : }
buf : 
buf : /* Check if the use of the antenna that ieee80211 told us to
if the use of the antenna that ieee80211 told us to 
buf :  * use is possible. This will fall back to DEFAULT.
buf :  * "antenna_nr" is the antenna identifier we got from ieee80211. */
ifier we got from ieee80211. */ 
buf : u8 b43_ieee80211_antenna_sanitize(struct b43_wldev *dev,
buf : 				  u8 antenna_nr)
buf : {
buf : 	u8 antenna_mask;
buf : 
buf : 	if (antenna_nr == 0) {
if (antenna_nr == 0) { 
buf : 		/* Zero means "use default antenna". That's always OK. */
buf : 		return 0;
buf : 	}
buf : 
buf : 	/* Get the mask of available antennas. */
buf : 	if (dev->phy.gmode)
if (dev->phy.gmode) 
buf : 		antenna_mask = dev->dev->bus_sprom->ant_available_bg;
buf : 	else
buf : 		antenna_mask = dev->dev->bus_sprom->ant_available_a;
buf : 
buf : 	if (!(antenna_mask & (1 << (antenna_nr - 1)))) {
if (!(antenna_mask & (1 << (antenna_nr - 1)))) { 
buf : 		/* This antenna is not available. Fall back to default. */
buf : 		return 0;
buf : 	}
buf : 
buf : 	return antenna_nr;
buf : }
buf : 
buf : /* Convert a b43 antenna number value to the PHY TX control value. */
buf : static u16 b43_antenna_to_phyctl(int antenna)
buf : {
buf : 	switch (antenna) {
buf : 	case B43_ANTENNA0:
buf : 		return B43_TXH_PHY_ANT0;
buf : 	case B43_ANTENNA1:
buf : 		return B43_TXH_PHY_ANT1;
buf : 	case B43_ANTENNA2:
buf : 		return B43_TXH_PHY_ANT2;
buf : 	case B43_ANTENNA3:
buf : 		return B43_TXH_PHY_ANT3;
buf : 	case B43_ANTENNA_AUTO0:
buf : 	case B43_ANTENNA_AUTO1:
buf : 		return B43_TXH_PHY_ANT01AUTO;
buf : 	}
buf : 	B43_WARN_ON(1);
buf : 	return 0;
buf : }
buf : 
buf : static void b43_write_beacon_template(struct b43_wldev *dev,
buf : 				      u16 ram_offset,
buf : 				      u16 shm_size_offset)
buf : {
buf : 	unsigned int i, len, variable_len;
buf : 	const struct ieee80211_mgmt *bcn;
buf : 	const u8 *ie;
buf : 	bool tim_found = false;
buf : 	unsigned int rate;
buf : 	u16 ctl;
buf : 	int antenna;
buf : 	struct ieee80211_tx_info *info = IEEE80211_SKB_CB(dev->wl->current_beacon);
buf : 
buf : 	bcn = (const struct ieee80211_mgmt *)(dev->wl->current_beacon->data);
buf : 	len = min_t(size_t, dev->wl->current_beacon->len,
buf : 		  0x200 - sizeof(struct b43_plcp_hdr6));
buf : 	rate = ieee80211_get_tx_rate(dev->wl->hw, info)->hw_value;
buf : 
buf : 	b43_write_template_common(dev, (const u8 *)bcn,
buf : 				  len, ram_offset, shm_size_offset, rate);
buf : 
buf : 	/* Write the PHY TX control parameters. */
buf : 	antenna = B43_ANTENNA_DEFAULT;
buf : 	antenna = b43_antenna_to_phyctl(antenna);
buf : 	ctl = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_BEACPHYCTL);
buf : 	/* We can't send beacons with short preamble. Would get PHY errors. */
buf : 	ctl &= ~B43_TXH_PHY_SHORTPRMBL;
buf : 	ctl &= ~B43_TXH_PHY_ANT;
buf : 	ctl &= ~B43_TXH_PHY_ENC;
buf : 	ctl |= antenna;
buf : 	if (b43_is_cck_rate(rate))
if (b43_is_cck_rate(rate)) 
buf : 		ctl |= B43_TXH_PHY_ENC_CCK;
buf : 	else
buf : 		ctl |= B43_TXH_PHY_ENC_OFDM;
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_BEACPHYCTL, ctl);
buf : 
buf : 	/* Find the position of the TIM and the DTIM_period value
buf : 	 * and write them to SHM. */
buf : 	ie = bcn->u.beacon.variable;
buf : 	variable_len = len - offsetof(struct ieee80211_mgmt, u.beacon.variable);
buf : 	for (i = 0; i < variable_len - 2; ) {
for (i = 0; i < variable_len - 2; ) { 
buf : 		uint8_t ie_id, ie_len;
buf : 
buf : 		ie_id = ie[i];
buf : 		ie_len = ie[i + 1];
buf : 		if (ie_id == 5) {
if (ie_id == 5) { 
buf : 			u16 tim_position;
buf : 			u16 dtim_period;
buf : 			/* This is the TIM Information Element */
formation Element */ 
buf : 
buf : 			/* Check whether the ie_len is in the beacon data range. */
buf : 			if (variable_len < ie_len + 2 + i)
if (variable_len < ie_len + 2 + i) 
buf : 				break;
buf : 			/* A valid TIM is at least 4 bytes long. */
buf : 			if (ie_len < 4)
if (ie_len < 4) 
buf : 				break;
buf : 			tim_found = true;
buf : 
buf : 			tim_position = sizeof(struct b43_plcp_hdr6);
buf : 			tim_position += offsetof(struct ieee80211_mgmt, u.beacon.variable);
buf : 			tim_position += i;
buf : 
buf : 			dtim_period = ie[i + 3];
buf : 
buf : 			b43_shm_write16(dev, B43_SHM_SHARED,
buf : 					B43_SHM_SH_TIMBPOS, tim_position);
buf : 			b43_shm_write16(dev, B43_SHM_SHARED,
buf : 					B43_SHM_SH_DTIMPER, dtim_period);
buf : 			break;
buf : 		}
buf : 		i += ie_len + 2;
buf : 	}
buf : 	if (!tim_found) {
if (!tim_found) { 
buf : 		/*
buf : 		 * If ucode wants to modify TIM do it behind the beacon, this
ify TIM do it behind the beacon, this 
buf : 		 * will happen, for example, when doing mesh networking.
for example, when doing mesh networking. 
buf : 		 */
buf : 		b43_shm_write16(dev, B43_SHM_SHARED,
buf : 				B43_SHM_SH_TIMBPOS,
buf : 				len + sizeof(struct b43_plcp_hdr6));
buf : 		b43_shm_write16(dev, B43_SHM_SHARED,
buf : 				B43_SHM_SH_DTIMPER, 0);
buf : 	}
buf : 	b43dbg(dev->wl, "Updated beacon template at 0x%x\n", ram_offset);
buf : }
buf : 
buf : static void b43_upload_beacon0(struct b43_wldev *dev)
buf : {
buf : 	struct b43_wl *wl = dev->wl;
buf : 
buf : 	if (wl->beacon0_uploaded)
if (wl->beacon0_uploaded) 
buf : 		return;
buf : 	b43_write_beacon_template(dev, B43_SHM_SH_BT_BASE0, B43_SHM_SH_BTL0);
buf : 	wl->beacon0_uploaded = true;
buf : }
buf : 
buf : static void b43_upload_beacon1(struct b43_wldev *dev)
buf : {
buf : 	struct b43_wl *wl = dev->wl;
buf : 
buf : 	if (wl->beacon1_uploaded)
if (wl->beacon1_uploaded) 
buf : 		return;
buf : 	b43_write_beacon_template(dev, B43_SHM_SH_BT_BASE1, B43_SHM_SH_BTL1);
buf : 	wl->beacon1_uploaded = true;
buf : }
buf : 
buf : static void handle_irq_beacon(struct b43_wldev *dev)
buf : {
buf : 	struct b43_wl *wl = dev->wl;
buf : 	u32 cmd, beacon0_valid, beacon1_valid;
buf : 
buf : 	if (!b43_is_mode(wl, NL80211_IFTYPE_AP) &&
if (!b43_is_mode(wl, NL80211_IFTYPE_AP) && 
buf : 	    !b43_is_mode(wl, NL80211_IFTYPE_MESH_POINT) &&
buf : 	    !b43_is_mode(wl, NL80211_IFTYPE_ADHOC))
buf : 		return;
buf : 
buf : 	/* This is the bottom half of the asynchronous beacon update. */
buf : 
buf : 	/* Ignore interrupt in the future. */
buf : 	dev->irq_mask &= ~B43_IRQ_BEACON;
buf : 
buf : 	cmd = b43_read32(dev, B43_MMIO_MACCMD);
buf : 	beacon0_valid = (cmd & B43_MACCMD_BEACON0_VALID);
buf : 	beacon1_valid = (cmd & B43_MACCMD_BEACON1_VALID);
buf : 
buf : 	/* Schedule interrupt manually, if busy. */
if busy. */ 
buf : 	if (beacon0_valid && beacon1_valid) {
buf : 		b43_write32(dev, B43_MMIO_GEN_IRQ_REASON, B43_IRQ_BEACON);
buf : 		dev->irq_mask |= B43_IRQ_BEACON;
buf : 		return;
buf : 	}
buf : 
buf : 	if (unlikely(wl->beacon_templates_virgin)) {
if (unlikely(wl->beacon_templates_virgin)) { 
buf : 		/* We never uploaded a beacon before.
fore. 
buf : 		 * Upload both templates now, but only mark one valid. */
buf : 		wl->beacon_templates_virgin = false;
buf : 		b43_upload_beacon0(dev);
buf : 		b43_upload_beacon1(dev);
buf : 		cmd = b43_read32(dev, B43_MMIO_MACCMD);
buf : 		cmd |= B43_MACCMD_BEACON0_VALID;
buf : 		b43_write32(dev, B43_MMIO_MACCMD, cmd);
buf : 	} else {
buf : 		if (!beacon0_valid) {
if (!beacon0_valid) { 
buf : 			b43_upload_beacon0(dev);
buf : 			cmd = b43_read32(dev, B43_MMIO_MACCMD);
buf : 			cmd |= B43_MACCMD_BEACON0_VALID;
buf : 			b43_write32(dev, B43_MMIO_MACCMD, cmd);
buf : 		} else if (!beacon1_valid) {
if (!beacon1_valid) { 
buf : 			b43_upload_beacon1(dev);
buf : 			cmd = b43_read32(dev, B43_MMIO_MACCMD);
buf : 			cmd |= B43_MACCMD_BEACON1_VALID;
buf : 			b43_write32(dev, B43_MMIO_MACCMD, cmd);
buf : 		}
buf : 	}
buf : }
buf : 
buf : static void b43_do_beacon_update_trigger_work(struct b43_wldev *dev)
buf : {
buf : 	u32 old_irq_mask = dev->irq_mask;
buf : 
buf : 	/* update beacon right away or defer to irq */
buf : 	handle_irq_beacon(dev);
buf : 	if (old_irq_mask != dev->irq_mask) {
if (old_irq_mask != dev->irq_mask) { 
buf : 		/* The handler updated the IRQ mask. */
buf : 		B43_WARN_ON(!dev->irq_mask);
buf : 		if (b43_read32(dev, B43_MMIO_GEN_IRQ_MASK)) {
if (b43_read32(dev, B43_MMIO_GEN_IRQ_MASK)) { 
buf : 			b43_write32(dev, B43_MMIO_GEN_IRQ_MASK, dev->irq_mask);
buf : 		} else {
buf : 			/* Device interrupts are currently disabled. That means
buf : 			 * we just ran the hardirq handler and scheduled the
buf : 			 * IRQ thread. The thread will write the IRQ mask when
buf : 			 * it finished, so there's nothing to do here. Writing
buf : 			 * the mask _here_ would incorrectly re-enable IRQs. */
buf : 		}
buf : 	}
buf : }
buf : 
buf : static void b43_beacon_update_trigger_work(struct work_struct *work)
buf : {
buf : 	struct b43_wl *wl = container_of(work, struct b43_wl,
buf : 					 beacon_update_trigger);
buf : 	struct b43_wldev *dev;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (likely(dev && (b43_status(dev) >= B43_STAT_INITIALIZED))) {
if (likely(dev && (b43_status(dev) >= B43_STAT_INITIALIZED))) { 
buf : 		if (b43_bus_host_is_sdio(dev->dev)) {
buf : 			/* wl->mutex is enough. */
buf : 			b43_do_beacon_update_trigger_work(dev);
buf : 			mmiowb();
buf : 		} else {
buf : 			spin_lock_irq(&wl->hardirq_lock);
buf : 			b43_do_beacon_update_trigger_work(dev);
buf : 			mmiowb();
buf : 			spin_unlock_irq(&wl->hardirq_lock);
buf : 		}
buf : 	}
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : /* Asynchronously update the packet templates in template RAM.
buf :  * Locking: Requires wl->mutex to be locked. */
buf : static void b43_update_templates(struct b43_wl *wl)
buf : {
buf : 	struct sk_buff *beacon;
buf : 
buf : 	/* This is the top half of the ansynchronous beacon update.
buf : 	 * The bottom half is the beacon IRQ.
buf : 	 * Beacon update must be asynchronous to avoid sending an
buf : 	 * invalid beacon. This can happen for example, if the firmware
if the firmware 
buf : 	 * transmits a beacon while we are updating it. */
while we are updating it. */ 
buf : 
buf : 	/* We could modify the existing beacon and set the aid bit in
buf : 	 * the TIM field, but that would probably require resizing and
buf : 	 * moving of data within the beacon template.
buf : 	 * Simply request a new beacon and let mac80211 do the hard work. */
buf : 	beacon = ieee80211_beacon_get(wl->hw, wl->vif);
if); 
buf : 	if (unlikely(!beacon))
buf : 		return;
buf : 
buf : 	if (wl->current_beacon)
if (wl->current_beacon) 
buf : 		dev_kfree_skb_any(wl->current_beacon);
buf : 	wl->current_beacon = beacon;
buf : 	wl->beacon0_uploaded = false;
buf : 	wl->beacon1_uploaded = false;
buf : 	ieee80211_queue_work(wl->hw, &wl->beacon_update_trigger);
buf : }
buf : 
buf : static void b43_set_beacon_int(struct b43_wldev *dev, u16 beacon_int)
buf : {
buf : 	b43_time_lock(dev);
buf : 	if (dev->dev->core_rev >= 3) {
if (dev->dev->core_rev >= 3) { 
buf : 		b43_write32(dev, B43_MMIO_TSF_CFP_REP, (beacon_int << 16));
buf : 		b43_write32(dev, B43_MMIO_TSF_CFP_START, (beacon_int << 10));
buf : 	} else {
buf : 		b43_write16(dev, 0x606, (beacon_int >> 6));
buf : 		b43_write16(dev, 0x610, beacon_int);
buf : 	}
buf : 	b43_time_unlock(dev);
buf : 	b43dbg(dev->wl, "Set beacon interval to %u\n", beacon_int);
buf : }
buf : 
buf : static void b43_handle_firmware_panic(struct b43_wldev *dev)
buf : {
buf : 	u16 reason;
buf : 
buf : 	/* Read the register that contains the reason code for the panic. */
for the panic. */ 
buf : 	reason = b43_shm_read16(dev, B43_SHM_SCRATCH, B43_FWPANIC_REASON_REG);
buf : 	b43err(dev->wl, "Whoopsy, firmware panic! Reason: %u\n", reason);
buf : 
buf : 	switch (reason) {
buf : 	default:
buf : 		b43dbg(dev->wl, "The panic reason is unknown.\n");
buf : 		/* fallthrough */
buf : 	case B43_FWPANIC_DIE:
buf : 		/* Do not restart the controller or firmware.
buf : 		 * The device is nonfunctional from now on.
buf : 		 * Restarting would result in this panic to trigger again,
buf : 		 * so we avoid that recursion. */
buf : 		break;
buf : 	case B43_FWPANIC_RESTART:
buf : 		b43_controller_restart(dev, "Microcode panic");
buf : 		break;
buf : 	}
buf : }
buf : 
buf : static void handle_irq_ucode_debug(struct b43_wldev *dev)
buf : {
buf : 	unsigned int i, cnt;
buf : 	u16 reason, marker_id, marker_line;
buf : 	__le16 *buf;
buf : 
buf : 	/* The proprietary firmware doesn't have this IRQ. */
buf : 	if (!dev->fw.opensource)
if (!dev->fw.opensource) 
buf : 		return;
buf : 
buf : 	/* Read the register that contains the reason code for this IRQ. */
for this IRQ. */ 
buf : 	reason = b43_shm_read16(dev, B43_SHM_SCRATCH, B43_DEBUGIRQ_REASON_REG);
buf : 
buf : 	switch (reason) {
buf : 	case B43_DEBUGIRQ_PANIC:
buf : 		b43_handle_firmware_panic(dev);
buf : 		break;
buf : 	case B43_DEBUGIRQ_DUMP_SHM:
buf : 		if (!B43_DEBUG)
if (!B43_DEBUG) 
buf : 			break; /* Only with driver debugging enabled. */
buf : 		buf = kmalloc(4096, GFP_ATOMIC);
buf : 		if (!buf) {
if (!buf) { 
buf : 			b43dbg(dev->wl, "SHM-dump: Failed to allocate memory\n");
buf : 			goto out;
buf : 		}
buf : 		for (i = 0; i < 4096; i += 2) {
for (i = 0; i < 4096; i += 2) { 
buf : 			u16 tmp = b43_shm_read16(dev, B43_SHM_SHARED, i);
buf : 			buf[i / 2] = cpu_to_le16(tmp);
buf : 		}
buf : 		b43info(dev->wl, "Shared memory dump:\n");
buf : 		print_hex_dump(KERN_INFO, "", DUMP_PREFIX_OFFSET,
buf : 			       16, 2, buf, 4096, 1);
buf : 		kfree(buf);
buf : 		break;
buf : 	case B43_DEBUGIRQ_DUMP_REGS:
buf : 		if (!B43_DEBUG)
if (!B43_DEBUG) 
buf : 			break; /* Only with driver debugging enabled. */
buf : 		b43info(dev->wl, "Microcode register dump:\n");
buf : 		for (i = 0, cnt = 0; i < 64; i++) {
for (i = 0, cnt = 0; i < 64; i++) { 
buf : 			u16 tmp = b43_shm_read16(dev, B43_SHM_SCRATCH, i);
buf : 			if (cnt == 0)
if (cnt == 0) 
buf : 				printk(KERN_INFO);
buf : 			printk("r%02u: 0x%04X  ", i, tmp);
buf : 			cnt++;
buf : 			if (cnt == 6) {
if (cnt == 6) { 
buf : 				printk("\n");
buf : 				cnt = 0;
buf : 			}
buf : 		}
buf : 		printk("\n");
buf : 		break;
buf : 	case B43_DEBUGIRQ_MARKER:
buf : 		if (!B43_DEBUG)
if (!B43_DEBUG) 
buf : 			break; /* Only with driver debugging enabled. */
buf : 		marker_id = b43_shm_read16(dev, B43_SHM_SCRATCH,
buf : 					   B43_MARKER_ID_REG);
buf : 		marker_line = b43_shm_read16(dev, B43_SHM_SCRATCH,
buf : 					     B43_MARKER_LINE_REG);
buf : 		b43info(dev->wl, "The firmware just executed the MARKER(%u) "
buf : 			"at line number %u\n",
buf : 			marker_id, marker_line);
buf : 		break;
buf : 	default:
buf : 		b43dbg(dev->wl, "Debug-IRQ triggered for unknown reason: %u\n",
for unknown reason: %u\n", 
buf : 		       reason);
buf : 	}
buf : out:
buf : 	/* Acknowledge the debug-IRQ, so the firmware can continue. */
buf : 	b43_shm_write16(dev, B43_SHM_SCRATCH,
buf : 			B43_DEBUGIRQ_REASON_REG, B43_DEBUGIRQ_ACK);
buf : }
buf : 
buf : static void b43_do_interrupt_thread(struct b43_wldev *dev)
buf : {
buf : 	u32 reason;
buf : 	u32 dma_reason[ARRAY_SIZE(dev->dma_reason)];
buf : 	u32 merged_dma_reason = 0;
buf : 	int i;
buf : 
buf : 	if (unlikely(b43_status(dev) != B43_STAT_STARTED))
if (unlikely(b43_status(dev) != B43_STAT_STARTED)) 
buf : 		return;
buf : 
buf : 	reason = dev->irq_reason;
buf : 	for (i = 0; i < ARRAY_SIZE(dma_reason); i++) {
for (i = 0; i < ARRAY_SIZE(dma_reason); i++) { 
buf : 		dma_reason[i] = dev->dma_reason[i];
buf : 		merged_dma_reason |= dma_reason[i];
buf : 	}
buf : 
buf : 	if (unlikely(reason & B43_IRQ_MAC_TXERR))
if (unlikely(reason & B43_IRQ_MAC_TXERR)) 
buf : 		b43err(dev->wl, "MAC transmission error\n");
buf : 
buf : 	if (unlikely(reason & B43_IRQ_PHY_TXERR)) {
if (unlikely(reason & B43_IRQ_PHY_TXERR)) { 
buf : 		b43err(dev->wl, "PHY transmission error\n");
buf : 		rmb();
buf : 		if (unlikely(atomic_dec_and_test(&dev->phy.txerr_cnt))) {
if (unlikely(atomic_dec_and_test(&dev->phy.txerr_cnt))) { 
buf : 			atomic_set(&dev->phy.txerr_cnt,
buf : 				   B43_PHY_TX_BADNESS_LIMIT);
buf : 			b43err(dev->wl, "Too many PHY TX errors, "
buf : 					"restarting the controller\n");
buf : 			b43_controller_restart(dev, "PHY TX errors");
buf : 		}
buf : 	}
buf : 
buf : 	if (unlikely(merged_dma_reason & (B43_DMAIRQ_FATALMASK))) {
if (unlikely(merged_dma_reason & (B43_DMAIRQ_FATALMASK))) { 
buf : 		b43err(dev->wl,
buf : 			"Fatal DMA error: 0x%08X, 0x%08X, 0x%08X, 0x%08X, 0x%08X, 0x%08X\n",
buf : 			dma_reason[0], dma_reason[1],
buf : 			dma_reason[2], dma_reason[3],
buf : 			dma_reason[4], dma_reason[5]);
buf : 		b43err(dev->wl, "This device does not support DMA "
buf : 			       "on your system. It will now be switched to PIO.\n");
buf : 		/* Fall back to PIO transfers if we get fatal DMA errors! */
if we get fatal DMA errors! */ 
buf : 		dev->use_pio = true;
buf : 		b43_controller_restart(dev, "DMA error");
buf : 		return;
buf : 	}
buf : 
buf : 	if (unlikely(reason & B43_IRQ_UCODE_DEBUG))
if (unlikely(reason & B43_IRQ_UCODE_DEBUG)) 
buf : 		handle_irq_ucode_debug(dev);
buf : 	if (reason & B43_IRQ_TBTT_INDI)
if (reason & B43_IRQ_TBTT_INDI) 
buf : 		handle_irq_tbtt_indication(dev);
buf : 	if (reason & B43_IRQ_ATIM_END)
if (reason & B43_IRQ_ATIM_END) 
buf : 		handle_irq_atim_end(dev);
buf : 	if (reason & B43_IRQ_BEACON)
if (reason & B43_IRQ_BEACON) 
buf : 		handle_irq_beacon(dev);
buf : 	if (reason & B43_IRQ_PMQ)
if (reason & B43_IRQ_PMQ) 
buf : 		handle_irq_pmq(dev);
buf : 	if (reason & B43_IRQ_TXFIFO_FLUSH_OK)
if (reason & B43_IRQ_TXFIFO_FLUSH_OK) 
buf : 		;/* TODO */
buf : 	if (reason & B43_IRQ_NOISESAMPLE_OK)
if (reason & B43_IRQ_NOISESAMPLE_OK) 
buf : 		handle_irq_noise(dev);
buf : 
buf : 	/* Check the DMA reason registers for received data. */
for received data. */ 
buf : 	if (dma_reason[0] & B43_DMAIRQ_RDESC_UFLOW) {
buf : 		if (B43_DEBUG)
if (B43_DEBUG) 
buf : 			b43warn(dev->wl, "RX descriptor underrun\n");
buf : 		b43_dma_handle_rx_overflow(dev->dma.rx_ring);
buf : 	}
buf : 	if (dma_reason[0] & B43_DMAIRQ_RX_DONE) {
if (dma_reason[0] & B43_DMAIRQ_RX_DONE) { 
buf : 		if (b43_using_pio_transfers(dev))
buf : 			b43_pio_rx(dev->pio.rx_queue);
buf : 		else
buf : 			b43_dma_rx(dev->dma.rx_ring);
buf : 	}
buf : 	B43_WARN_ON(dma_reason[1] & B43_DMAIRQ_RX_DONE);
buf : 	B43_WARN_ON(dma_reason[2] & B43_DMAIRQ_RX_DONE);
buf : 	B43_WARN_ON(dma_reason[3] & B43_DMAIRQ_RX_DONE);
buf : 	B43_WARN_ON(dma_reason[4] & B43_DMAIRQ_RX_DONE);
buf : 	B43_WARN_ON(dma_reason[5] & B43_DMAIRQ_RX_DONE);
buf : 
buf : 	if (reason & B43_IRQ_TX_OK)
if (reason & B43_IRQ_TX_OK) 
buf : 		handle_irq_transmit_status(dev);
buf : 
buf : 	/* Re-enable interrupts on the device by restoring the current interrupt mask. */
buf : 	b43_write32(dev, B43_MMIO_GEN_IRQ_MASK, dev->irq_mask);
buf : 
buf : #if B43_DEBUG
if B43_DEBUG 
buf : 	if (b43_debug(dev, B43_DBG_VERBOSESTATS)) {
buf : 		dev->irq_count++;
buf : 		for (i = 0; i < ARRAY_SIZE(dev->irq_bit_count); i++) {
for (i = 0; i < ARRAY_SIZE(dev->irq_bit_count); i++) { 
buf : 			if (reason & (1 << i))
buf : 				dev->irq_bit_count[i]++;
buf : 		}
buf : 	}
buf : #endif
if 
buf : }
buf : 
buf : /* Interrupt thread handler. Handles device interrupts in thread context. */
buf : static irqreturn_t b43_interrupt_thread_handler(int irq, void *dev_id)
buf : {
buf : 	struct b43_wldev *dev = dev_id;
buf : 
buf : 	mutex_lock(&dev->wl->mutex);
buf : 	b43_do_interrupt_thread(dev);
buf : 	mmiowb();
buf : 	mutex_unlock(&dev->wl->mutex);
buf : 
buf : 	return IRQ_HANDLED;
buf : }
buf : 
buf : static irqreturn_t b43_do_interrupt(struct b43_wldev *dev)
buf : {
buf : 	u32 reason;
buf : 
buf : 	/* This code runs under wl->hardirq_lock, but _only_ on non-SDIO busses.
buf : 	 * On SDIO, this runs under wl->mutex. */
buf : 
buf : 	reason = b43_read32(dev, B43_MMIO_GEN_IRQ_REASON);
buf : 	if (reason == 0xffffffff)	/* shared IRQ */
if (reason == 0xffffffff)	/* shared IRQ */ 
buf : 		return IRQ_NONE;
buf : 	reason &= dev->irq_mask;
buf : 	if (!reason)
if (!reason) 
buf : 		return IRQ_NONE;
buf : 
buf : 	dev->dma_reason[0] = b43_read32(dev, B43_MMIO_DMA0_REASON)
buf : 	    & 0x0001FC00;
buf : 	dev->dma_reason[1] = b43_read32(dev, B43_MMIO_DMA1_REASON)
buf : 	    & 0x0000DC00;
buf : 	dev->dma_reason[2] = b43_read32(dev, B43_MMIO_DMA2_REASON)
buf : 	    & 0x0000DC00;
buf : 	dev->dma_reason[3] = b43_read32(dev, B43_MMIO_DMA3_REASON)
buf : 	    & 0x0001DC00;
buf : 	dev->dma_reason[4] = b43_read32(dev, B43_MMIO_DMA4_REASON)
buf : 	    & 0x0000DC00;
buf : /* Unused ring
buf : 	dev->dma_reason[5] = b43_read32(dev, B43_MMIO_DMA5_REASON)
buf : 	    & 0x0000DC00;
buf : */
buf : 
buf : 	/* ACK the interrupt. */
buf : 	b43_write32(dev, B43_MMIO_GEN_IRQ_REASON, reason);
buf : 	b43_write32(dev, B43_MMIO_DMA0_REASON, dev->dma_reason[0]);
buf : 	b43_write32(dev, B43_MMIO_DMA1_REASON, dev->dma_reason[1]);
buf : 	b43_write32(dev, B43_MMIO_DMA2_REASON, dev->dma_reason[2]);
buf : 	b43_write32(dev, B43_MMIO_DMA3_REASON, dev->dma_reason[3]);
buf : 	b43_write32(dev, B43_MMIO_DMA4_REASON, dev->dma_reason[4]);
buf : /* Unused ring
buf : 	b43_write32(dev, B43_MMIO_DMA5_REASON, dev->dma_reason[5]);
buf : */
buf : 
buf : 	/* Disable IRQs on the device. The IRQ thread handler will re-enable them. */
buf : 	b43_write32(dev, B43_MMIO_GEN_IRQ_MASK, 0);
buf : 	/* Save the reason bitmasks for the IRQ thread handler. */
for the IRQ thread handler. */ 
buf : 	dev->irq_reason = reason;
buf : 
buf : 	return IRQ_WAKE_THREAD;
buf : }
buf : 
buf : /* Interrupt handler top-half. This runs with interrupts disabled. */
buf : static irqreturn_t b43_interrupt_handler(int irq, void *dev_id)
buf : {
buf : 	struct b43_wldev *dev = dev_id;
buf : 	irqreturn_t ret;
buf : 
buf : 	if (unlikely(b43_status(dev) < B43_STAT_STARTED))
if (unlikely(b43_status(dev) < B43_STAT_STARTED)) 
buf : 		return IRQ_NONE;
buf : 
buf : 	spin_lock(&dev->wl->hardirq_lock);
buf : 	ret = b43_do_interrupt(dev);
buf : 	mmiowb();
buf : 	spin_unlock(&dev->wl->hardirq_lock);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : /* SDIO interrupt handler. This runs in process context. */
buf : static void b43_sdio_interrupt_handler(struct b43_wldev *dev)
buf : {
buf : 	struct b43_wl *wl = dev->wl;
buf : 	irqreturn_t ret;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	ret = b43_do_interrupt(dev);
buf : 	if (ret == IRQ_WAKE_THREAD)
if (ret == IRQ_WAKE_THREAD) 
buf : 		b43_do_interrupt_thread(dev);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : void b43_do_release_fw(struct b43_firmware_file *fw)
buf : {
buf : 	release_firmware(fw->data);
buf : 	fw->data = NULL;
buf : 	fw->filename = NULL;
buf : }
buf : 
buf : static void b43_release_firmware(struct b43_wldev *dev)
buf : {
buf : 	complete(&dev->fw_load_complete);
buf : 	b43_do_release_fw(&dev->fw.ucode);
buf : 	b43_do_release_fw(&dev->fw.pcm);
buf : 	b43_do_release_fw(&dev->fw.initvals);
buf : 	b43_do_release_fw(&dev->fw.initvals_band);
buf : }
buf : 
buf : static void b43_print_fw_helptext(struct b43_wl *wl, bool error)
buf : {
buf : 	const char text[] =
buf : 		"You must go to " \
buf : 		"http://wireless.kernel.org/en/users/Drivers/b43#devicefirmware " \
buf : 		"and download the correct firmware for this driver version. " \
for this driver version. " \ 
buf : 		"Please carefully read all instructions on this website.\n";
buf : 
buf : 	if (error)
if (error) 
buf : 		b43err(wl, text);
buf : 	else
buf : 		b43warn(wl, text);
buf : }
buf : 
buf : static void b43_fw_cb(const struct firmware *firmware, void *context)
buf : {
buf : 	struct b43_request_fw_context *ctx = context;
buf : 
buf : 	ctx->blob = firmware;
buf : 	complete(&ctx->dev->fw_load_complete);
buf : }
buf : 
buf : int b43_do_request_fw(struct b43_request_fw_context *ctx,
buf : 		      const char *name,
buf : 		      struct b43_firmware_file *fw, bool async)
buf : {
buf : 	struct b43_fw_header *hdr;
buf : 	u32 size;
buf : 	int err;
buf : 
buf : 	if (!name) {
if (!name) { 
buf : 		/* Don't fetch anything. Free possibly cached firmware. */
buf : 		/* FIXME: We should probably keep it anyway, to save some headache
buf : 		 * on suspend/resume with multiband devices. */
buf : 		b43_do_release_fw(fw);
buf : 		return 0;
buf : 	}
buf : 	if (fw->filename) {
if (fw->filename) { 
buf : 		if ((fw->type == ctx->req_type) &&
buf : 		    (strcmp(fw->filename, name) == 0))
buf : 			return 0; /* Already have this fw. */
buf : 		/* Free the cached firmware first. */
buf : 		/* FIXME: We should probably do this later after we successfully
buf : 		 * got the new fw. This could reduce headache with multiband devices.
buf : 		 * We could also redesign this to cache the firmware for all possible
for all possible 
buf : 		 * bands all the time. */
buf : 		b43_do_release_fw(fw);
buf : 	}
buf : 
buf : 	switch (ctx->req_type) {
buf : 	case B43_FWTYPE_PROPRIETARY:
buf : 		snprintf(ctx->fwname, sizeof(ctx->fwname),
buf : 			 "b43%s/%s.fw",
buf : 			 modparam_fwpostfix, name);
buf : 		break;
buf : 	case B43_FWTYPE_OPENSOURCE:
buf : 		snprintf(ctx->fwname, sizeof(ctx->fwname),
buf : 			 "b43-open%s/%s.fw",
buf : 			 modparam_fwpostfix, name);
buf : 		break;
buf : 	default:
buf : 		B43_WARN_ON(1);
buf : 		return -ENOSYS;
buf : 	}
buf : 	if (async) {
if (async) { 
buf : 		/* do this part asynchronously */
buf : 		init_completion(&ctx->dev->fw_load_complete);
buf : 		err = request_firmware_nowait(THIS_MODULE, 1, ctx->fwname,
buf : 					      ctx->dev->dev->dev, GFP_KERNEL,
buf : 					      ctx, b43_fw_cb);
buf : 		if (err < 0) {
if (err < 0) { 
buf : 			pr_err("Unable to load firmware\n");
buf : 			return err;
buf : 		}
buf : 		wait_for_completion(&ctx->dev->fw_load_complete);
for_completion(&ctx->dev->fw_load_complete); 
buf : 		if (ctx->blob)
buf : 			goto fw_ready;
buf : 	/* On some ARM systems, the async request will fail, but the next sync
buf : 	 * request works. For this reason, we fall through here
buf : 	 */
buf : 	}
buf : 	err = request_firmware(&ctx->blob, ctx->fwname,
buf : 			       ctx->dev->dev->dev);
buf : 	if (err == -ENOENT) {
if (err == -ENOENT) { 
buf : 		snprintf(ctx->errors[ctx->req_type],
buf : 			 sizeof(ctx->errors[ctx->req_type]),
buf : 			 "Firmware file \"%s\" not found\n",
buf : 			 ctx->fwname);
buf : 		return err;
buf : 	} else if (err) {
if (err) { 
buf : 		snprintf(ctx->errors[ctx->req_type],
buf : 			 sizeof(ctx->errors[ctx->req_type]),
buf : 			 "Firmware file \"%s\" request failed (err=%d)\n",
buf : 			 ctx->fwname, err);
buf : 		return err;
buf : 	}
buf : fw_ready:
buf : 	if (ctx->blob->size < sizeof(struct b43_fw_header))
if (ctx->blob->size < sizeof(struct b43_fw_header)) 
buf : 		goto err_format;
format; 
buf : 	hdr = (struct b43_fw_header *)(ctx->blob->data);
buf : 	switch (hdr->type) {
buf : 	case B43_FW_TYPE_UCODE:
buf : 	case B43_FW_TYPE_PCM:
buf : 		size = be32_to_cpu(hdr->size);
buf : 		if (size != ctx->blob->size - sizeof(struct b43_fw_header))
if (size != ctx->blob->size - sizeof(struct b43_fw_header)) 
buf : 			goto err_format;
format; 
buf : 		/* fallthrough */
buf : 	case B43_FW_TYPE_IV:
buf : 		if (hdr->ver != 1)
if (hdr->ver != 1) 
buf : 			goto err_format;
format; 
buf : 		break;
buf : 	default:
buf : 		goto err_format;
format; 
buf : 	}
buf : 
buf : 	fw->data = ctx->blob;
buf : 	fw->filename = name;
buf : 	fw->type = ctx->req_type;
buf : 
buf : 	return 0;
buf : 
buf : err_format:
format: 
buf : 	snprintf(ctx->errors[ctx->req_type],
buf : 		 sizeof(ctx->errors[ctx->req_type]),
buf : 		 "Firmware file \"%s\" format error.\n", ctx->fwname);
format error.\n", ctx->fwname); 
buf : 	release_firmware(ctx->blob);
buf : 
buf : 	return -EPROTO;
buf : }
buf : 
buf : static int b43_try_request_fw(struct b43_request_fw_context *ctx)
buf : {
buf : 	struct b43_wldev *dev = ctx->dev;
buf : 	struct b43_firmware *fw = &ctx->dev->fw;
buf : 	const u8 rev = ctx->dev->dev->core_rev;
buf : 	const char *filename;
buf : 	u32 tmshigh;
buf : 	int err;
buf : 
buf : 	/* Files for HT and LCN were found by trying one by one */
for HT and LCN were found by trying one by one */ 
buf : 
buf : 	/* Get microcode */
buf : 	if ((rev >= 5) && (rev <= 10)) {
if ((rev >= 5) && (rev <= 10)) { 
buf : 		filename = "ucode5";
buf : 	} else if ((rev >= 11) && (rev <= 12)) {
if ((rev >= 11) && (rev <= 12)) { 
buf : 		filename = "ucode11";
buf : 	} else if (rev == 13) {
if (rev == 13) { 
buf : 		filename = "ucode13";
buf : 	} else if (rev == 14) {
if (rev == 14) { 
buf : 		filename = "ucode14";
buf : 	} else if (rev == 15) {
if (rev == 15) { 
buf : 		filename = "ucode15";
buf : 	} else {
buf : 		switch (dev->phy.type) {
buf : 		case B43_PHYTYPE_N:
buf : 			if (rev >= 16)
if (rev >= 16) 
buf : 				filename = "ucode16_mimo";
buf : 			else
buf : 				goto err_no_ucode;
buf : 			break;
buf : 		case B43_PHYTYPE_HT:
buf : 			if (rev == 29)
if (rev == 29) 
buf : 				filename = "ucode29_mimo";
buf : 			else
buf : 				goto err_no_ucode;
buf : 			break;
buf : 		case B43_PHYTYPE_LCN:
buf : 			if (rev == 24)
if (rev == 24) 
buf : 				filename = "ucode24_mimo";
buf : 			else
buf : 				goto err_no_ucode;
buf : 			break;
buf : 		default:
buf : 			goto err_no_ucode;
buf : 		}
buf : 	}
buf : 	err = b43_do_request_fw(ctx, filename, &fw->ucode, true);
buf : 	if (err)
if (err) 
buf : 		goto err_load;
buf : 
buf : 	/* Get PCM code */
buf : 	if ((rev >= 5) && (rev <= 10))
if ((rev >= 5) && (rev <= 10)) 
buf : 		filename = "pcm5";
buf : 	else if (rev >= 11)
if (rev >= 11) 
buf : 		filename = NULL;
buf : 	else
buf : 		goto err_no_pcm;
buf : 	fw->pcm_request_failed = false;
buf : 	err = b43_do_request_fw(ctx, filename, &fw->pcm, false);
buf : 	if (err == -ENOENT) {
if (err == -ENOENT) { 
buf : 		/* We did not find a PCM file? Not fatal, but
buf : 		 * core rev <= 10 must do without hwcrypto then. */
buf : 		fw->pcm_request_failed = true;
buf : 	} else if (err)
if (err) 
buf : 		goto err_load;
buf : 
buf : 	/* Get initvals */
buf : 	switch (dev->phy.type) {
buf : 	case B43_PHYTYPE_A:
buf : 		if ((rev >= 5) && (rev <= 10)) {
if ((rev >= 5) && (rev <= 10)) { 
buf : 			tmshigh = ssb_read32(dev->dev->sdev, SSB_TMSHIGH);
buf : 			if (tmshigh & B43_TMSHIGH_HAVE_2GHZ_PHY)
if (tmshigh & B43_TMSHIGH_HAVE_2GHZ_PHY) 
buf : 				filename = "a0g1initvals5";
buf : 			else
buf : 				filename = "a0g0initvals5";
buf : 		} else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_G:
buf : 		if ((rev >= 5) && (rev <= 10))
if ((rev >= 5) && (rev <= 10)) 
buf : 			filename = "b0g0initvals5";
buf : 		else if (rev >= 13)
if (rev >= 13) 
buf : 			filename = "b0g0initvals13";
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_N:
buf : 		if (rev >= 16)
if (rev >= 16) 
buf : 			filename = "n0initvals16";
buf : 		else if ((rev >= 11) && (rev <= 12))
if ((rev >= 11) && (rev <= 12)) 
buf : 			filename = "n0initvals11";
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_LP:
buf : 		if (rev == 13)
if (rev == 13) 
buf : 			filename = "lp0initvals13";
buf : 		else if (rev == 14)
if (rev == 14) 
buf : 			filename = "lp0initvals14";
buf : 		else if (rev >= 15)
if (rev >= 15) 
buf : 			filename = "lp0initvals15";
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_HT:
buf : 		if (rev == 29)
if (rev == 29) 
buf : 			filename = "ht0initvals29";
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_LCN:
buf : 		if (rev == 24)
if (rev == 24) 
buf : 			filename = "lcn0initvals24";
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	default:
buf : 		goto err_no_initvals;
buf : 	}
buf : 	err = b43_do_request_fw(ctx, filename, &fw->initvals, false);
buf : 	if (err)
if (err) 
buf : 		goto err_load;
buf : 
buf : 	/* Get bandswitch initvals */
buf : 	switch (dev->phy.type) {
buf : 	case B43_PHYTYPE_A:
buf : 		if ((rev >= 5) && (rev <= 10)) {
if ((rev >= 5) && (rev <= 10)) { 
buf : 			tmshigh = ssb_read32(dev->dev->sdev, SSB_TMSHIGH);
buf : 			if (tmshigh & B43_TMSHIGH_HAVE_2GHZ_PHY)
if (tmshigh & B43_TMSHIGH_HAVE_2GHZ_PHY) 
buf : 				filename = "a0g1bsinitvals5";
buf : 			else
buf : 				filename = "a0g0bsinitvals5";
buf : 		} else if (rev >= 11)
if (rev >= 11) 
buf : 			filename = NULL;
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_G:
buf : 		if ((rev >= 5) && (rev <= 10))
if ((rev >= 5) && (rev <= 10)) 
buf : 			filename = "b0g0bsinitvals5";
buf : 		else if (rev >= 11)
if (rev >= 11) 
buf : 			filename = NULL;
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_N:
buf : 		if (rev >= 16)
if (rev >= 16) 
buf : 			filename = "n0bsinitvals16";
buf : 		else if ((rev >= 11) && (rev <= 12))
if ((rev >= 11) && (rev <= 12)) 
buf : 			filename = "n0bsinitvals11";
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_LP:
buf : 		if (rev == 13)
if (rev == 13) 
buf : 			filename = "lp0bsinitvals13";
buf : 		else if (rev == 14)
if (rev == 14) 
buf : 			filename = "lp0bsinitvals14";
buf : 		else if (rev >= 15)
if (rev >= 15) 
buf : 			filename = "lp0bsinitvals15";
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_HT:
buf : 		if (rev == 29)
if (rev == 29) 
buf : 			filename = "ht0bsinitvals29";
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	case B43_PHYTYPE_LCN:
buf : 		if (rev == 24)
if (rev == 24) 
buf : 			filename = "lcn0bsinitvals24";
buf : 		else
buf : 			goto err_no_initvals;
buf : 		break;
buf : 	default:
buf : 		goto err_no_initvals;
buf : 	}
buf : 	err = b43_do_request_fw(ctx, filename, &fw->initvals_band, false);
buf : 	if (err)
if (err) 
buf : 		goto err_load;
buf : 
buf : 	fw->opensource = (ctx->req_type == B43_FWTYPE_OPENSOURCE);
buf : 
buf : 	return 0;
buf : 
buf : err_no_ucode:
buf : 	err = ctx->fatal_failure = -EOPNOTSUPP;
buf : 	b43err(dev->wl, "The driver does not know which firmware (ucode) "
buf : 	       "is required for your device (wl-core rev %u)\n", rev);
for your device (wl-core rev %u)\n", rev); 
buf : 	goto error;
buf : 
buf : err_no_pcm:
buf : 	err = ctx->fatal_failure = -EOPNOTSUPP;
buf : 	b43err(dev->wl, "The driver does not know which firmware (PCM) "
buf : 	       "is required for your device (wl-core rev %u)\n", rev);
for your device (wl-core rev %u)\n", rev); 
buf : 	goto error;
buf : 
buf : err_no_initvals:
buf : 	err = ctx->fatal_failure = -EOPNOTSUPP;
buf : 	b43err(dev->wl, "The driver does not know which firmware (initvals) "
buf : 	       "is required for your device (wl-core rev %u)\n", rev);
for your device (wl-core rev %u)\n", rev); 
buf : 	goto error;
buf : 
buf : err_load:
buf : 	/* We failed to load this firmware image. The error message
buf : 	 * already is in ctx->errors. Return and let our caller decide
buf : 	 * what to do. */
buf : 	goto error;
buf : 
buf : error:
buf : 	b43_release_firmware(dev);
buf : 	return err;
buf : }
buf : 
buf : static int b43_one_core_attach(struct b43_bus_dev *dev, struct b43_wl *wl);
buf : static void b43_one_core_detach(struct b43_bus_dev *dev);
buf : static int b43_rng_init(struct b43_wl *wl);
buf : 
buf : static void b43_request_firmware(struct work_struct *work)
buf : {
buf : 	struct b43_wl *wl = container_of(work,
buf : 			    struct b43_wl, firmware_load);
buf : 	struct b43_wldev *dev = wl->current_dev;
buf : 	struct b43_request_fw_context *ctx;
buf : 	unsigned int i;
buf : 	int err;
buf : 	const char *errmsg;
buf : 
buf : 	ctx = kzalloc(sizeof(*ctx), GFP_KERNEL);
buf : 	if (!ctx)
if (!ctx) 
buf : 		return;
buf : 	ctx->dev = dev;
buf : 
buf : 	ctx->req_type = B43_FWTYPE_PROPRIETARY;
buf : 	err = b43_try_request_fw(ctx);
buf : 	if (!err)
if (!err) 
buf : 		goto start_ieee80211; /* Successfully loaded it. */
buf : 	/* Was fw version known? */
buf : 	if (ctx->fatal_failure)
if (ctx->fatal_failure) 
buf : 		goto out;
buf : 
buf : 	/* proprietary fw not found, try open source */
buf : 	ctx->req_type = B43_FWTYPE_OPENSOURCE;
buf : 	err = b43_try_request_fw(ctx);
buf : 	if (!err)
if (!err) 
buf : 		goto start_ieee80211; /* Successfully loaded it. */
buf : 	if(ctx->fatal_failure)
if(ctx->fatal_failure) 
buf : 		goto out;
buf : 
buf : 	/* Could not find a usable firmware. Print the errors. */
buf : 	for (i = 0; i < B43_NR_FWTYPES; i++) {
for (i = 0; i < B43_NR_FWTYPES; i++) { 
buf : 		errmsg = ctx->errors[i];
buf : 		if (strlen(errmsg))
if (strlen(errmsg)) 
buf : 			b43err(dev->wl, "%s", errmsg);
buf : 	}
buf : 	b43_print_fw_helptext(dev->wl, 1);
buf : 	goto out;
buf : 
buf : start_ieee80211:
buf : 	wl->hw->queues = B43_QOS_QUEUE_NUM;
buf : 	if (!modparam_qos || dev->fw.opensource)
if (!modparam_qos || dev->fw.opensource) 
buf : 		wl->hw->queues = 1;
buf : 
buf : 	err = ieee80211_register_hw(wl->hw);
buf : 	if (err)
if (err) 
buf : 		goto err_one_core_detach;
buf : 	wl->hw_registred = true;
buf : 	b43_leds_register(wl->current_dev);
buf : 
buf : 	/* Register HW RNG driver */
buf : 	b43_rng_init(wl);
buf : 
buf : 	goto out;
buf : 
buf : err_one_core_detach:
buf : 	b43_one_core_detach(dev->dev);
buf : 
buf : out:
buf : 	kfree(ctx);
buf : }
buf : 
buf : static int b43_upload_microcode(struct b43_wldev *dev)
buf : {
buf : 	struct wiphy *wiphy = dev->wl->hw->wiphy;
buf : 	const size_t hdr_len = sizeof(struct b43_fw_header);
buf : 	const __be32 *data;
buf : 	unsigned int i, len;
buf : 	u16 fwrev, fwpatch, fwdate, fwtime;
buf : 	u32 tmp, macctl;
buf : 	int err = 0;
buf : 
buf : 	/* Jump the microcode PSM to offset 0 */
buf : 	macctl = b43_read32(dev, B43_MMIO_MACCTL);
buf : 	B43_WARN_ON(macctl & B43_MACCTL_PSM_RUN);
buf : 	macctl |= B43_MACCTL_PSM_JMP0;
buf : 	b43_write32(dev, B43_MMIO_MACCTL, macctl);
buf : 	/* Zero out all microcode PSM registers and shared memory. */
buf : 	for (i = 0; i < 64; i++)
for (i = 0; i < 64; i++) 
buf : 		b43_shm_write16(dev, B43_SHM_SCRATCH, i, 0);
buf : 	for (i = 0; i < 4096; i += 2)
for (i = 0; i < 4096; i += 2) 
buf : 		b43_shm_write16(dev, B43_SHM_SHARED, i, 0);
buf : 
buf : 	/* Upload Microcode. */
buf : 	data = (__be32 *) (dev->fw.ucode.data->data + hdr_len);
buf : 	len = (dev->fw.ucode.data->size - hdr_len) / sizeof(__be32);
buf : 	b43_shm_control_word(dev, B43_SHM_UCODE | B43_SHM_AUTOINC_W, 0x0000);
buf : 	for (i = 0; i < len; i++) {
for (i = 0; i < len; i++) { 
buf : 		b43_write32(dev, B43_MMIO_SHM_DATA, be32_to_cpu(data[i]));
buf : 		udelay(10);
buf : 	}
buf : 
buf : 	if (dev->fw.pcm.data) {
if (dev->fw.pcm.data) { 
buf : 		/* Upload PCM data. */
buf : 		data = (__be32 *) (dev->fw.pcm.data->data + hdr_len);
buf : 		len = (dev->fw.pcm.data->size - hdr_len) / sizeof(__be32);
buf : 		b43_shm_control_word(dev, B43_SHM_HW, 0x01EA);
buf : 		b43_write32(dev, B43_MMIO_SHM_DATA, 0x00004000);
buf : 		/* No need for autoinc bit in SHM_HW */
for autoinc bit in SHM_HW */ 
buf : 		b43_shm_control_word(dev, B43_SHM_HW, 0x01EB);
buf : 		for (i = 0; i < len; i++) {
for (i = 0; i < len; i++) { 
buf : 			b43_write32(dev, B43_MMIO_SHM_DATA, be32_to_cpu(data[i]));
buf : 			udelay(10);
buf : 		}
buf : 	}
buf : 
buf : 	b43_write32(dev, B43_MMIO_GEN_IRQ_REASON, B43_IRQ_ALL);
buf : 
buf : 	/* Start the microcode PSM */
buf : 	b43_maskset32(dev, B43_MMIO_MACCTL, ~B43_MACCTL_PSM_JMP0,
buf : 		      B43_MACCTL_PSM_RUN);
buf : 
buf : 	/* Wait for the microcode to load and respond */
for the microcode to load and respond */ 
buf : 	i = 0;
buf : 	while (1) {
while (1) { 
buf : 		tmp = b43_read32(dev, B43_MMIO_GEN_IRQ_REASON);
buf : 		if (tmp == B43_IRQ_MAC_SUSPENDED)
if (tmp == B43_IRQ_MAC_SUSPENDED) 
buf : 			break;
buf : 		i++;
buf : 		if (i >= 20) {
if (i >= 20) { 
buf : 			b43err(dev->wl, "Microcode not responding\n");
buf : 			b43_print_fw_helptext(dev->wl, 1);
buf : 			err = -ENODEV;
buf : 			goto error;
buf : 		}
buf : 		msleep(50);
buf : 	}
buf : 	b43_read32(dev, B43_MMIO_GEN_IRQ_REASON);	/* dummy read */
buf : 
buf : 	/* Get and check the revisions. */
buf : 	fwrev = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_UCODEREV);
buf : 	fwpatch = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_UCODEPATCH);
buf : 	fwdate = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_UCODEDATE);
buf : 	fwtime = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_UCODETIME);
buf : 
buf : 	if (fwrev <= 0x128) {
if (fwrev <= 0x128) { 
buf : 		b43err(dev->wl, "YOUR FIRMWARE IS TOO OLD. Firmware from "
buf : 		       "binary drivers older than version 4.x is unsupported. "
buf : 		       "You must upgrade your firmware files.\n");
buf : 		b43_print_fw_helptext(dev->wl, 1);
buf : 		err = -EOPNOTSUPP;
buf : 		goto error;
buf : 	}
buf : 	dev->fw.rev = fwrev;
buf : 	dev->fw.patch = fwpatch;
buf : 	if (dev->fw.rev >= 598)
if (dev->fw.rev >= 598) 
buf : 		dev->fw.hdr_format = B43_FW_HDR_598;
format = B43_FW_HDR_598; 
buf : 	else if (dev->fw.rev >= 410)
buf : 		dev->fw.hdr_format = B43_FW_HDR_410;
format = B43_FW_HDR_410; 
buf : 	else
buf : 		dev->fw.hdr_format = B43_FW_HDR_351;
format = B43_FW_HDR_351; 
buf : 	WARN_ON(dev->fw.opensource != (fwdate == 0xFFFF));
buf : 
buf : 	dev->qos_enabled = dev->wl->hw->queues > 1;
buf : 	/* Default to firmware/hardware crypto acceleration. */
buf : 	dev->hwcrypto_enabled = true;
buf : 
buf : 	if (dev->fw.opensource) {
if (dev->fw.opensource) { 
buf : 		u16 fwcapa;
buf : 
buf : 		/* Patchlevel info is encoded in the "time" field. */
buf : 		dev->fw.patch = fwtime;
buf : 		b43info(dev->wl, "Loading OpenSource firmware version %u.%u\n",
buf : 			dev->fw.rev, dev->fw.patch);
buf : 
buf : 		fwcapa = b43_fwcapa_read(dev);
buf : 		if (!(fwcapa & B43_FWCAPA_HWCRYPTO) || dev->fw.pcm_request_failed) {
if (!(fwcapa & B43_FWCAPA_HWCRYPTO) || dev->fw.pcm_request_failed) { 
buf : 			b43info(dev->wl, "Hardware crypto acceleration not supported by firmware\n");
buf : 			/* Disable hardware crypto and fall back to software crypto. */
buf : 			dev->hwcrypto_enabled = false;
buf : 		}
buf : 		/* adding QoS support should use an offline discovery mechanism */
buf : 		WARN(fwcapa & B43_FWCAPA_QOS, "QoS in OpenFW not supported\n");
buf : 	} else {
buf : 		b43info(dev->wl, "Loading firmware version %u.%u "
buf : 			"(20%.2i-%.2i-%.2i %.2i:%.2i:%.2i)\n",
buf : 			fwrev, fwpatch,
buf : 			(fwdate >> 12) & 0xF, (fwdate >> 8) & 0xF, fwdate & 0xFF,
buf : 			(fwtime >> 11) & 0x1F, (fwtime >> 5) & 0x3F, fwtime & 0x1F);
buf : 		if (dev->fw.pcm_request_failed) {
if (dev->fw.pcm_request_failed) { 
buf : 			b43warn(dev->wl, "No \"pcm5.fw\" firmware file found. "
buf : 				"Hardware accelerated cryptography is disabled.\n");
buf : 			b43_print_fw_helptext(dev->wl, 0);
buf : 		}
buf : 	}
buf : 
buf : 	snprintf(wiphy->fw_version, sizeof(wiphy->fw_version), "%u.%u",
buf : 			dev->fw.rev, dev->fw.patch);
buf : 	wiphy->hw_version = dev->dev->core_id;
buf : 
buf : 	if (dev->fw.hdr_format == B43_FW_HDR_351) {
if (dev->fw.hdr_format == B43_FW_HDR_351) { 
buf : 		/* We're over the deadline, but we keep support for old fw
for old fw 
buf : 		 * until it turns out to be in major conflict with something new. */
buf : 		b43warn(dev->wl, "You are using an old firmware image. "
buf : 			"Support for old firmware will be removed soon "
for old firmware will be removed soon " 
buf : 			"(official deadline was July 2008).\n");
buf : 		b43_print_fw_helptext(dev->wl, 0);
buf : 	}
buf : 
buf : 	return 0;
buf : 
buf : error:
buf : 	/* Stop the microcode PSM. */
buf : 	b43_maskset32(dev, B43_MMIO_MACCTL, ~B43_MACCTL_PSM_RUN,
buf : 		      B43_MACCTL_PSM_JMP0);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int b43_write_initvals(struct b43_wldev *dev,
buf : 			      const struct b43_iv *ivals,
buf : 			      size_t count,
buf : 			      size_t array_size)
buf : {
buf : 	const struct b43_iv *iv;
buf : 	u16 offset;
buf : 	size_t i;
buf : 	bool bit32;
buf : 
buf : 	BUILD_BUG_ON(sizeof(struct b43_iv) != 6);
buf : 	iv = ivals;
buf : 	for (i = 0; i < count; i++) {
for (i = 0; i < count; i++) { 
buf : 		if (array_size < sizeof(iv->offset_size))
buf : 			goto err_format;
format; 
buf : 		array_size -= sizeof(iv->offset_size);
buf : 		offset = be16_to_cpu(iv->offset_size);
buf : 		bit32 = !!(offset & B43_IV_32BIT);
buf : 		offset &= B43_IV_OFFSET_MASK;
buf : 		if (offset >= 0x1000)
if (offset >= 0x1000) 
buf : 			goto err_format;
format; 
buf : 		if (bit32) {
buf : 			u32 value;
buf : 
buf : 			if (array_size < sizeof(iv->data.d32))
if (array_size < sizeof(iv->data.d32)) 
buf : 				goto err_format;
format; 
buf : 			array_size -= sizeof(iv->data.d32);
buf : 
buf : 			value = get_unaligned_be32(&iv->data.d32);
buf : 			b43_write32(dev, offset, value);
buf : 
buf : 			iv = (const struct b43_iv *)((const uint8_t *)iv +
buf : 							sizeof(__be16) +
buf : 							sizeof(__be32));
buf : 		} else {
buf : 			u16 value;
buf : 
buf : 			if (array_size < sizeof(iv->data.d16))
if (array_size < sizeof(iv->data.d16)) 
buf : 				goto err_format;
format; 
buf : 			array_size -= sizeof(iv->data.d16);
buf : 
buf : 			value = be16_to_cpu(iv->data.d16);
buf : 			b43_write16(dev, offset, value);
buf : 
buf : 			iv = (const struct b43_iv *)((const uint8_t *)iv +
buf : 							sizeof(__be16) +
buf : 							sizeof(__be16));
buf : 		}
buf : 	}
buf : 	if (array_size)
if (array_size) 
buf : 		goto err_format;
format; 
buf : 
buf : 	return 0;
buf : 
buf : err_format:
format: 
buf : 	b43err(dev->wl, "Initial Values Firmware file-format error.\n");
buf : 	b43_print_fw_helptext(dev->wl, 1);
buf : 
buf : 	return -EPROTO;
buf : }
buf : 
buf : static int b43_upload_initvals(struct b43_wldev *dev)
buf : {
buf : 	const size_t hdr_len = sizeof(struct b43_fw_header);
buf : 	const struct b43_fw_header *hdr;
buf : 	struct b43_firmware *fw = &dev->fw;
buf : 	const struct b43_iv *ivals;
buf : 	size_t count;
buf : 
buf : 	hdr = (const struct b43_fw_header *)(fw->initvals.data->data);
buf : 	ivals = (const struct b43_iv *)(fw->initvals.data->data + hdr_len);
buf : 	count = be32_to_cpu(hdr->size);
buf : 	return b43_write_initvals(dev, ivals, count,
buf : 				 fw->initvals.data->size - hdr_len);
buf : }
buf : 
buf : static int b43_upload_initvals_band(struct b43_wldev *dev)
buf : {
buf : 	const size_t hdr_len = sizeof(struct b43_fw_header);
buf : 	const struct b43_fw_header *hdr;
buf : 	struct b43_firmware *fw = &dev->fw;
buf : 	const struct b43_iv *ivals;
buf : 	size_t count;
buf : 
buf : 	if (!fw->initvals_band.data)
if (!fw->initvals_band.data) 
buf : 		return 0;
buf : 
buf : 	hdr = (const struct b43_fw_header *)(fw->initvals_band.data->data);
buf : 	ivals = (const struct b43_iv *)(fw->initvals_band.data->data + hdr_len);
buf : 	count = be32_to_cpu(hdr->size);
buf : 	return b43_write_initvals(dev, ivals, count,
buf : 				  fw->initvals_band.data->size - hdr_len);
buf : }
buf : 
buf : /* Initialize the GPIOs
buf :  * http://bcm-specs.sipsolutions.net/GPIO
buf :  */
buf : 
buf : #ifdef CONFIG_B43_SSB
ifdef CONFIG_B43_SSB 
buf : static struct ssb_device *b43_ssb_gpio_dev(struct b43_wldev *dev)
buf : {
buf : 	struct ssb_bus *bus = dev->dev->sdev->bus;
buf : 
buf : #ifdef CONFIG_SSB_DRIVER_PCICORE
ifdef CONFIG_SSB_DRIVER_PCICORE 
buf : 	return (bus->chipco.dev ? bus->chipco.dev : bus->pcicore.dev);
buf : #else
buf : 	return bus->chipco.dev;
buf : #endif
if 
buf : }
buf : #endif
buf : 
buf : static int b43_gpio_init(struct b43_wldev *dev)
buf : {
buf : #ifdef CONFIG_B43_SSB
ifdef CONFIG_B43_SSB 
buf : 	struct ssb_device *gpiodev;
buf : #endif
if 
buf : 	u32 mask, set;
buf : 
buf : 	b43_maskset32(dev, B43_MMIO_MACCTL, ~B43_MACCTL_GPOUTSMSK, 0);
buf : 	b43_maskset16(dev, B43_MMIO_GPIO_MASK, ~0, 0xF);
buf : 
buf : 	mask = 0x0000001F;
buf : 	set = 0x0000000F;
buf : 	if (dev->dev->chip_id == 0x4301) {
if (dev->dev->chip_id == 0x4301) { 
buf : 		mask |= 0x0060;
buf : 		set |= 0x0060;
buf : 	} else if (dev->dev->chip_id == 0x5354) {
if (dev->dev->chip_id == 0x5354) { 
buf : 		/* Don't allow overtaking buttons GPIOs */
buf : 		set &= 0x2; /* 0x2 is LED GPIO on BCM5354 */
buf : 	}
buf : 
buf : 	if (0 /* FIXME: conditional unknown */ ) {
if (0 /* FIXME: conditional unknown */ ) { 
buf : 		b43_write16(dev, B43_MMIO_GPIO_MASK,
buf : 			    b43_read16(dev, B43_MMIO_GPIO_MASK)
buf : 			    | 0x0100);
buf : 		/* BT Coexistance Input */
buf : 		mask |= 0x0080;
buf : 		set |= 0x0080;
buf : 		/* BT Coexistance Out */
buf : 		mask |= 0x0100;
buf : 		set |= 0x0100;
buf : 	}
buf : 	if (dev->dev->bus_sprom->boardflags_lo & B43_BFL_PACTRL) {
if (dev->dev->bus_sprom->boardflags_lo & B43_BFL_PACTRL) { 
buf : 		/* PA is controlled by gpio 9, let ucode handle it */
buf : 		b43_write16(dev, B43_MMIO_GPIO_MASK,
buf : 			    b43_read16(dev, B43_MMIO_GPIO_MASK)
buf : 			    | 0x0200);
buf : 		mask |= 0x0200;
buf : 		set |= 0x0200;
buf : 	}
buf : 
buf : 	switch (dev->dev->bus_type) {
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	case B43_BUS_BCMA:
buf : 		bcma_chipco_gpio_control(&dev->dev->bdev->bus->drv_cc, mask, set);
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	case B43_BUS_SSB:
buf : 		gpiodev = b43_ssb_gpio_dev(dev);
buf : 		if (gpiodev)
if (gpiodev) 
buf : 			ssb_write32(gpiodev, B43_GPIO_CONTROL,
buf : 				    (ssb_read32(gpiodev, B43_GPIO_CONTROL)
buf : 				    & ~mask) | set);
buf : 		break;
buf : #endif
if 
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /* Turn off all GPIO stuff. Call this on module unload, for example. */
for example. */ 
buf : static void b43_gpio_cleanup(struct b43_wldev *dev)
buf : {
buf : #ifdef CONFIG_B43_SSB
ifdef CONFIG_B43_SSB 
buf : 	struct ssb_device *gpiodev;
buf : #endif
if 
buf : 
buf : 	switch (dev->dev->bus_type) {
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	case B43_BUS_BCMA:
buf : 		bcma_chipco_gpio_control(&dev->dev->bdev->bus->drv_cc, ~0, 0);
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	case B43_BUS_SSB:
buf : 		gpiodev = b43_ssb_gpio_dev(dev);
buf : 		if (gpiodev)
if (gpiodev) 
buf : 			ssb_write32(gpiodev, B43_GPIO_CONTROL, 0);
buf : 		break;
buf : #endif
if 
buf : 	}
buf : }
buf : 
buf : /* http://bcm-specs.sipsolutions.net/EnableMac */
buf : void b43_mac_enable(struct b43_wldev *dev)
buf : {
buf : 	if (b43_debug(dev, B43_DBG_FIRMWARE)) {
if (b43_debug(dev, B43_DBG_FIRMWARE)) { 
buf : 		u16 fwstate;
buf : 
buf : 		fwstate = b43_shm_read16(dev, B43_SHM_SHARED,
buf : 					 B43_SHM_SH_UCODESTAT);
buf : 		if ((fwstate != B43_SHM_SH_UCODESTAT_SUSP) &&
if ((fwstate != B43_SHM_SH_UCODESTAT_SUSP) && 
buf : 		    (fwstate != B43_SHM_SH_UCODESTAT_SLEEP)) {
buf : 			b43err(dev->wl, "b43_mac_enable(): The firmware "
buf : 			       "should be suspended, but current state is %u\n",
buf : 			       fwstate);
buf : 		}
buf : 	}
buf : 
buf : 	dev->mac_suspended--;
buf : 	B43_WARN_ON(dev->mac_suspended < 0);
buf : 	if (dev->mac_suspended == 0) {
if (dev->mac_suspended == 0) { 
buf : 		b43_maskset32(dev, B43_MMIO_MACCTL, ~0, B43_MACCTL_ENABLED);
buf : 		b43_write32(dev, B43_MMIO_GEN_IRQ_REASON,
buf : 			    B43_IRQ_MAC_SUSPENDED);
buf : 		/* Commit writes */
buf : 		b43_read32(dev, B43_MMIO_MACCTL);
buf : 		b43_read32(dev, B43_MMIO_GEN_IRQ_REASON);
buf : 		b43_power_saving_ctl_bits(dev, 0);
buf : 	}
buf : }
buf : 
buf : /* http://bcm-specs.sipsolutions.net/SuspendMAC */
buf : void b43_mac_suspend(struct b43_wldev *dev)
buf : {
buf : 	int i;
buf : 	u32 tmp;
buf : 
buf : 	might_sleep();
buf : 	B43_WARN_ON(dev->mac_suspended < 0);
buf : 
buf : 	if (dev->mac_suspended == 0) {
if (dev->mac_suspended == 0) { 
buf : 		b43_power_saving_ctl_bits(dev, B43_PS_AWAKE);
buf : 		b43_maskset32(dev, B43_MMIO_MACCTL, ~B43_MACCTL_ENABLED, 0);
buf : 		/* force pci to flush the write */
force pci to flush the write */ 
buf : 		b43_read32(dev, B43_MMIO_MACCTL);
buf : 		for (i = 35; i; i--) {
for (i = 35; i; i--) { 
buf : 			tmp = b43_read32(dev, B43_MMIO_GEN_IRQ_REASON);
buf : 			if (tmp & B43_IRQ_MAC_SUSPENDED)
if (tmp & B43_IRQ_MAC_SUSPENDED) 
buf : 				goto out;
buf : 			udelay(10);
buf : 		}
buf : 		/* Hm, it seems this will take some time. Use msleep(). */
buf : 		for (i = 40; i; i--) {
for (i = 40; i; i--) { 
buf : 			tmp = b43_read32(dev, B43_MMIO_GEN_IRQ_REASON);
buf : 			if (tmp & B43_IRQ_MAC_SUSPENDED)
if (tmp & B43_IRQ_MAC_SUSPENDED) 
buf : 				goto out;
buf : 			msleep(1);
buf : 		}
buf : 		b43err(dev->wl, "MAC suspend failed\n");
buf : 	}
buf : out:
buf : 	dev->mac_suspended++;
buf : }
buf : 
buf : /* http://bcm-v4.sipsolutions.net/802.11/PHY/N/MacPhyClkSet */
buf : void b43_mac_phy_clock_set(struct b43_wldev *dev, bool on)
buf : {
buf : 	u32 tmp;
buf : 
buf : 	switch (dev->dev->bus_type) {
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	case B43_BUS_BCMA:
buf : 		tmp = bcma_aread32(dev->dev->bdev, BCMA_IOCTL);
buf : 		if (on)
if (on) 
buf : 			tmp |= B43_BCMA_IOCTL_MACPHYCLKEN;
buf : 		else
buf : 			tmp &= ~B43_BCMA_IOCTL_MACPHYCLKEN;
buf : 		bcma_awrite32(dev->dev->bdev, BCMA_IOCTL, tmp);
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	case B43_BUS_SSB:
buf : 		tmp = ssb_read32(dev->dev->sdev, SSB_TMSLOW);
buf : 		if (on)
if (on) 
buf : 			tmp |= B43_TMSLOW_MACPHYCLKEN;
buf : 		else
buf : 			tmp &= ~B43_TMSLOW_MACPHYCLKEN;
buf : 		ssb_write32(dev->dev->sdev, SSB_TMSLOW, tmp);
buf : 		break;
buf : #endif
if 
buf : 	}
buf : }
buf : 
buf : static void b43_adjust_opmode(struct b43_wldev *dev)
buf : {
buf : 	struct b43_wl *wl = dev->wl;
buf : 	u32 ctl;
buf : 	u16 cfp_pretbtt;
buf : 
buf : 	ctl = b43_read32(dev, B43_MMIO_MACCTL);
buf : 	/* Reset status to STA infrastructure mode. */
buf : 	ctl &= ~B43_MACCTL_AP;
buf : 	ctl &= ~B43_MACCTL_KEEP_CTL;
buf : 	ctl &= ~B43_MACCTL_KEEP_BADPLCP;
buf : 	ctl &= ~B43_MACCTL_KEEP_BAD;
buf : 	ctl &= ~B43_MACCTL_PROMISC;
buf : 	ctl &= ~B43_MACCTL_BEACPROMISC;
buf : 	ctl |= B43_MACCTL_INFRA;
buf : 
buf : 	if (b43_is_mode(wl, NL80211_IFTYPE_AP) ||
if (b43_is_mode(wl, NL80211_IFTYPE_AP) || 
buf : 	    b43_is_mode(wl, NL80211_IFTYPE_MESH_POINT))
buf : 		ctl |= B43_MACCTL_AP;
buf : 	else if (b43_is_mode(wl, NL80211_IFTYPE_ADHOC))
if (b43_is_mode(wl, NL80211_IFTYPE_ADHOC)) 
buf : 		ctl &= ~B43_MACCTL_INFRA;
buf : 
buf : 	if (wl->filter_flags & FIF_CONTROL)
if (wl->filter_flags & FIF_CONTROL) 
buf : 		ctl |= B43_MACCTL_KEEP_CTL;
buf : 	if (wl->filter_flags & FIF_FCSFAIL)
if (wl->filter_flags & FIF_FCSFAIL) 
buf : 		ctl |= B43_MACCTL_KEEP_BAD;
buf : 	if (wl->filter_flags & FIF_PLCPFAIL)
if (wl->filter_flags & FIF_PLCPFAIL) 
buf : 		ctl |= B43_MACCTL_KEEP_BADPLCP;
buf : 	if (wl->filter_flags & FIF_PROMISC_IN_BSS)
if (wl->filter_flags & FIF_PROMISC_IN_BSS) 
buf : 		ctl |= B43_MACCTL_PROMISC;
buf : 	if (wl->filter_flags & FIF_BCN_PRBRESP_PROMISC)
if (wl->filter_flags & FIF_BCN_PRBRESP_PROMISC) 
buf : 		ctl |= B43_MACCTL_BEACPROMISC;
buf : 
buf : 	/* Workaround: On old hardware the HW-MAC-address-filter
buf : 	 * doesn't work properly, so always run promisc in filter
buf : 	 * it in software. */
buf : 	if (dev->dev->core_rev <= 4)
if (dev->dev->core_rev <= 4) 
buf : 		ctl |= B43_MACCTL_PROMISC;
buf : 
buf : 	b43_write32(dev, B43_MMIO_MACCTL, ctl);
buf : 
buf : 	cfp_pretbtt = 2;
buf : 	if ((ctl & B43_MACCTL_INFRA) && !(ctl & B43_MACCTL_AP)) {
if ((ctl & B43_MACCTL_INFRA) && !(ctl & B43_MACCTL_AP)) { 
buf : 		if (dev->dev->chip_id == 0x4306 &&
buf : 		    dev->dev->chip_rev == 3)
buf : 			cfp_pretbtt = 100;
buf : 		else
buf : 			cfp_pretbtt = 50;
buf : 	}
buf : 	b43_write16(dev, 0x612, cfp_pretbtt);
buf : 
buf : 	/* FIXME: We don't currently implement the PMQ mechanism,
buf : 	 *        so always disable it. If we want to implement PMQ,
buf : 	 *        we need to enable it here (clear DISCPMQ) in AP mode.
buf : 	 */
buf : 	if (0  /* ctl & B43_MACCTL_AP */)
if (0  /* ctl & B43_MACCTL_AP */) 
buf : 		b43_maskset32(dev, B43_MMIO_MACCTL, ~B43_MACCTL_DISCPMQ, 0);
buf : 	else
buf : 		b43_maskset32(dev, B43_MMIO_MACCTL, ~0, B43_MACCTL_DISCPMQ);
buf : }
buf : 
buf : static void b43_rate_memory_write(struct b43_wldev *dev, u16 rate, int is_ofdm)
buf : {
buf : 	u16 offset;
buf : 
buf : 	if (is_ofdm) {
if (is_ofdm) { 
buf : 		offset = 0x480;
buf : 		offset += (b43_plcp_get_ratecode_ofdm(rate) & 0x000F) * 2;
buf : 	} else {
buf : 		offset = 0x4C0;
buf : 		offset += (b43_plcp_get_ratecode_cck(rate) & 0x000F) * 2;
buf : 	}
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, offset + 0x20,
buf : 			b43_shm_read16(dev, B43_SHM_SHARED, offset));
buf : }
buf : 
buf : static void b43_rate_memory_init(struct b43_wldev *dev)
buf : {
buf : 	switch (dev->phy.type) {
buf : 	case B43_PHYTYPE_A:
buf : 	case B43_PHYTYPE_G:
buf : 	case B43_PHYTYPE_N:
buf : 	case B43_PHYTYPE_LP:
buf : 	case B43_PHYTYPE_HT:
buf : 	case B43_PHYTYPE_LCN:
buf : 		b43_rate_memory_write(dev, B43_OFDM_RATE_6MB, 1);
buf : 		b43_rate_memory_write(dev, B43_OFDM_RATE_12MB, 1);
buf : 		b43_rate_memory_write(dev, B43_OFDM_RATE_18MB, 1);
buf : 		b43_rate_memory_write(dev, B43_OFDM_RATE_24MB, 1);
buf : 		b43_rate_memory_write(dev, B43_OFDM_RATE_36MB, 1);
buf : 		b43_rate_memory_write(dev, B43_OFDM_RATE_48MB, 1);
buf : 		b43_rate_memory_write(dev, B43_OFDM_RATE_54MB, 1);
buf : 		if (dev->phy.type == B43_PHYTYPE_A)
if (dev->phy.type == B43_PHYTYPE_A) 
buf : 			break;
buf : 		/* fallthrough */
buf : 	case B43_PHYTYPE_B:
buf : 		b43_rate_memory_write(dev, B43_CCK_RATE_1MB, 0);
buf : 		b43_rate_memory_write(dev, B43_CCK_RATE_2MB, 0);
buf : 		b43_rate_memory_write(dev, B43_CCK_RATE_5MB, 0);
buf : 		b43_rate_memory_write(dev, B43_CCK_RATE_11MB, 0);
buf : 		break;
buf : 	default:
buf : 		B43_WARN_ON(1);
buf : 	}
buf : }
buf : 
buf : /* Set the default values for the PHY TX Control Words. */
for the PHY TX Control Words. */ 
buf : static void b43_set_phytxctl_defaults(struct b43_wldev *dev)
buf : {
buf : 	u16 ctl = 0;
buf : 
buf : 	ctl |= B43_TXH_PHY_ENC_CCK;
buf : 	ctl |= B43_TXH_PHY_ANT01AUTO;
buf : 	ctl |= B43_TXH_PHY_TXPWR;
buf : 
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_BEACPHYCTL, ctl);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_ACKCTSPHYCTL, ctl);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_PRPHYCTL, ctl);
buf : }
buf : 
buf : /* Set the TX-Antenna for management frames sent by firmware. */
for management frames sent by firmware. */ 
buf : static void b43_mgmtframe_txantenna(struct b43_wldev *dev, int antenna)
buf : {
buf : 	u16 ant;
buf : 	u16 tmp;
buf : 
buf : 	ant = b43_antenna_to_phyctl(antenna);
buf : 
buf : 	/* For ACK/CTS */
buf : 	tmp = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_ACKCTSPHYCTL);
buf : 	tmp = (tmp & ~B43_TXH_PHY_ANT) | ant;
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_ACKCTSPHYCTL, tmp);
buf : 	/* For Probe Resposes */
buf : 	tmp = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_PRPHYCTL);
buf : 	tmp = (tmp & ~B43_TXH_PHY_ANT) | ant;
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_PRPHYCTL, tmp);
buf : }
buf : 
buf : /* This is the opposite of b43_chip_init() */
buf : static void b43_chip_exit(struct b43_wldev *dev)
buf : {
buf : 	b43_phy_exit(dev);
buf : 	b43_gpio_cleanup(dev);
buf : 	/* firmware is released later */
buf : }
buf : 
buf : /* Initialize the chip
buf :  * http://bcm-specs.sipsolutions.net/ChipInit
buf :  */
buf : static int b43_chip_init(struct b43_wldev *dev)
buf : {
buf : 	struct b43_phy *phy = &dev->phy;
buf : 	int err;
buf : 	u32 macctl;
buf : 	u16 value16;
buf : 
buf : 	/* Initialize the MAC control */
buf : 	macctl = B43_MACCTL_IHR_ENABLED | B43_MACCTL_SHM_ENABLED;
buf : 	if (dev->phy.gmode)
if (dev->phy.gmode) 
buf : 		macctl |= B43_MACCTL_GMODE;
buf : 	macctl |= B43_MACCTL_INFRA;
buf : 	b43_write32(dev, B43_MMIO_MACCTL, macctl);
buf : 
buf : 	err = b43_upload_microcode(dev);
buf : 	if (err)
if (err) 
buf : 		goto out;	/* firmware is released later */
buf : 
buf : 	err = b43_gpio_init(dev);
buf : 	if (err)
if (err) 
buf : 		goto out;	/* firmware is released later */
buf : 
buf : 	err = b43_upload_initvals(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_gpio_clean;
buf : 
buf : 	err = b43_upload_initvals_band(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_gpio_clean;
buf : 
buf : 	/* Turn the Analog on and initialize the PHY. */
buf : 	phy->ops->switch_analog(dev, 1);
buf : 	err = b43_phy_init(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_gpio_clean;
buf : 
buf : 	/* Disable Interference Mitigation. */
buf : 	if (phy->ops->interf_mitigation)
if (phy->ops->interf_mitigation) 
buf : 		phy->ops->interf_mitigation(dev, B43_INTERFMODE_NONE);
buf : 
buf : 	/* Select the antennae */
buf : 	if (phy->ops->set_rx_antenna)
if (phy->ops->set_rx_antenna) 
buf : 		phy->ops->set_rx_antenna(dev, B43_ANTENNA_DEFAULT);
buf : 	b43_mgmtframe_txantenna(dev, B43_ANTENNA_DEFAULT);
buf : 
buf : 	if (phy->type == B43_PHYTYPE_B) {
if (phy->type == B43_PHYTYPE_B) { 
buf : 		value16 = b43_read16(dev, 0x005E);
buf : 		value16 |= 0x0004;
buf : 		b43_write16(dev, 0x005E, value16);
buf : 	}
buf : 	b43_write32(dev, 0x0100, 0x01000000);
buf : 	if (dev->dev->core_rev < 5)
if (dev->dev->core_rev < 5) 
buf : 		b43_write32(dev, 0x010C, 0x01000000);
buf : 
buf : 	b43_maskset32(dev, B43_MMIO_MACCTL, ~B43_MACCTL_INFRA, 0);
buf : 	b43_maskset32(dev, B43_MMIO_MACCTL, ~0, B43_MACCTL_INFRA);
buf : 
buf : 	/* Probe Response Timeout value */
buf : 	/* FIXME: Default to 0, has to be set by ioctl probably... :-/ */
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_PRMAXTIME, 0);
buf : 
buf : 	/* Initially set the wireless operation mode. */
buf : 	b43_adjust_opmode(dev);
buf : 
buf : 	if (dev->dev->core_rev < 3) {
if (dev->dev->core_rev < 3) { 
buf : 		b43_write16(dev, 0x060E, 0x0000);
buf : 		b43_write16(dev, 0x0610, 0x8000);
buf : 		b43_write16(dev, 0x0604, 0x0000);
buf : 		b43_write16(dev, 0x0606, 0x0200);
buf : 	} else {
buf : 		b43_write32(dev, 0x0188, 0x80000000);
buf : 		b43_write32(dev, 0x018C, 0x02000000);
buf : 	}
buf : 	b43_write32(dev, B43_MMIO_GEN_IRQ_REASON, 0x00004000);
buf : 	b43_write32(dev, B43_MMIO_DMA0_IRQ_MASK, 0x0001FC00);
buf : 	b43_write32(dev, B43_MMIO_DMA1_IRQ_MASK, 0x0000DC00);
buf : 	b43_write32(dev, B43_MMIO_DMA2_IRQ_MASK, 0x0000DC00);
buf : 	b43_write32(dev, B43_MMIO_DMA3_IRQ_MASK, 0x0001DC00);
buf : 	b43_write32(dev, B43_MMIO_DMA4_IRQ_MASK, 0x0000DC00);
buf : 	b43_write32(dev, B43_MMIO_DMA5_IRQ_MASK, 0x0000DC00);
buf : 
buf : 	b43_mac_phy_clock_set(dev, true);
buf : 
buf : 	switch (dev->dev->bus_type) {
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	case B43_BUS_BCMA:
buf : 		/* FIXME: 0xE74 is quite common, but should be read from CC */
buf : 		b43_write16(dev, B43_MMIO_POWERUP_DELAY, 0xE74);
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	case B43_BUS_SSB:
buf : 		b43_write16(dev, B43_MMIO_POWERUP_DELAY,
buf : 			    dev->dev->sdev->bus->chipco.fast_pwrup_delay);
buf : 		break;
buf : #endif
if 
buf : 	}
buf : 
buf : 	err = 0;
buf : 	b43dbg(dev->wl, "Chip initialized\n");
buf : out:
buf : 	return err;
buf : 
buf : err_gpio_clean:
buf : 	b43_gpio_cleanup(dev);
buf : 	return err;
buf : }
buf : 
buf : static void b43_periodic_every60sec(struct b43_wldev *dev)
buf : {
buf : 	const struct b43_phy_operations *ops = dev->phy.ops;
buf : 
buf : 	if (ops->pwork_60sec)
if (ops->pwork_60sec) 
buf : 		ops->pwork_60sec(dev);
buf : 
buf : 	/* Force check the TX power emission now. */
buf : 	b43_phy_txpower_check(dev, B43_TXPWR_IGNORE_TIME);
buf : }
buf : 
buf : static void b43_periodic_every30sec(struct b43_wldev *dev)
buf : {
buf : 	/* Update device statistics. */
buf : 	b43_calculate_link_quality(dev);
buf : }
buf : 
buf : static void b43_periodic_every15sec(struct b43_wldev *dev)
buf : {
buf : 	struct b43_phy *phy = &dev->phy;
buf : 	u16 wdr;
buf : 
buf : 	if (dev->fw.opensource) {
if (dev->fw.opensource) { 
buf : 		/* Check if the firmware is still alive.
buf : 		 * It will reset the watchdog counter to 0 in its idle loop. */
buf : 		wdr = b43_shm_read16(dev, B43_SHM_SCRATCH, B43_WATCHDOG_REG);
buf : 		if (unlikely(wdr)) {
if (unlikely(wdr)) { 
buf : 			b43err(dev->wl, "Firmware watchdog: The firmware died!\n");
buf : 			b43_controller_restart(dev, "Firmware watchdog");
buf : 			return;
buf : 		} else {
buf : 			b43_shm_write16(dev, B43_SHM_SCRATCH,
buf : 					B43_WATCHDOG_REG, 1);
buf : 		}
buf : 	}
buf : 
buf : 	if (phy->ops->pwork_15sec)
if (phy->ops->pwork_15sec) 
buf : 		phy->ops->pwork_15sec(dev);
buf : 
buf : 	atomic_set(&phy->txerr_cnt, B43_PHY_TX_BADNESS_LIMIT);
buf : 	wmb();
buf : 
buf : #if B43_DEBUG
if B43_DEBUG 
buf : 	if (b43_debug(dev, B43_DBG_VERBOSESTATS)) {
buf : 		unsigned int i;
buf : 
buf : 		b43dbg(dev->wl, "Stats: %7u IRQs/sec, %7u TX/sec, %7u RX/sec\n",
buf : 		       dev->irq_count / 15,
buf : 		       dev->tx_count / 15,
buf : 		       dev->rx_count / 15);
buf : 		dev->irq_count = 0;
buf : 		dev->tx_count = 0;
buf : 		dev->rx_count = 0;
buf : 		for (i = 0; i < ARRAY_SIZE(dev->irq_bit_count); i++) {
for (i = 0; i < ARRAY_SIZE(dev->irq_bit_count); i++) { 
buf : 			if (dev->irq_bit_count[i]) {
buf : 				b43dbg(dev->wl, "Stats: %7u IRQ-%02u/sec (0x%08X)\n",
buf : 				       dev->irq_bit_count[i] / 15, i, (1 << i));
buf : 				dev->irq_bit_count[i] = 0;
buf : 			}
buf : 		}
buf : 	}
buf : #endif
if 
buf : }
buf : 
buf : static void do_periodic_work(struct b43_wldev *dev)
buf : {
buf : 	unsigned int state;
buf : 
buf : 	state = dev->periodic_state;
buf : 	if (state % 4 == 0)
if (state % 4 == 0) 
buf : 		b43_periodic_every60sec(dev);
buf : 	if (state % 2 == 0)
if (state % 2 == 0) 
buf : 		b43_periodic_every30sec(dev);
buf : 	b43_periodic_every15sec(dev);
buf : }
buf : 
buf : /* Periodic work locking policy:
buf :  * 	The whole periodic work handler is protected by
buf :  * 	wl->mutex. If another lock is needed somewhere in the
buf :  * 	pwork callchain, it's acquired in-place, where it's needed.
buf :  */
buf : static void b43_periodic_work_handler(struct work_struct *work)
buf : {
buf : 	struct b43_wldev *dev = container_of(work, struct b43_wldev,
buf : 					     periodic_work.work);
buf : 	struct b43_wl *wl = dev->wl;
buf : 	unsigned long delay;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(b43_status(dev) != B43_STAT_STARTED))
if (unlikely(b43_status(dev) != B43_STAT_STARTED)) 
buf : 		goto out;
buf : 	if (b43_debug(dev, B43_DBG_PWORK_STOP))
if (b43_debug(dev, B43_DBG_PWORK_STOP)) 
buf : 		goto out_requeue;
buf : 
buf : 	do_periodic_work(dev);
buf : 
buf : 	dev->periodic_state++;
buf : out_requeue:
buf : 	if (b43_debug(dev, B43_DBG_PWORK_FAST))
if (b43_debug(dev, B43_DBG_PWORK_FAST)) 
buf : 		delay = msecs_to_jiffies(50);
buf : 	else
buf : 		delay = round_jiffies_relative(HZ * 15);
iffies_relative(HZ * 15); 
buf : 	ieee80211_queue_delayed_work(wl->hw, &dev->periodic_work, delay);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void b43_periodic_tasks_setup(struct b43_wldev *dev)
buf : {
buf : 	struct delayed_work *work = &dev->periodic_work;
buf : 
buf : 	dev->periodic_state = 0;
buf : 	INIT_DELAYED_WORK(work, b43_periodic_work_handler);
buf : 	ieee80211_queue_delayed_work(dev->wl->hw, work, 0);
buf : }
buf : 
buf : /* Check if communication with the device works correctly. */
if communication with the device works correctly. */ 
buf : static int b43_validate_chipaccess(struct b43_wldev *dev)
buf : {
buf : 	u32 v, backup0, backup4;
buf : 
buf : 	backup0 = b43_shm_read32(dev, B43_SHM_SHARED, 0);
buf : 	backup4 = b43_shm_read32(dev, B43_SHM_SHARED, 4);
buf : 
buf : 	/* Check for read/write and endianness problems. */
for read/write and endianness problems. */ 
buf : 	b43_shm_write32(dev, B43_SHM_SHARED, 0, 0x55AAAA55);
buf : 	if (b43_shm_read32(dev, B43_SHM_SHARED, 0) != 0x55AAAA55)
if (b43_shm_read32(dev, B43_SHM_SHARED, 0) != 0x55AAAA55) 
buf : 		goto error;
buf : 	b43_shm_write32(dev, B43_SHM_SHARED, 0, 0xAA5555AA);
buf : 	if (b43_shm_read32(dev, B43_SHM_SHARED, 0) != 0xAA5555AA)
if (b43_shm_read32(dev, B43_SHM_SHARED, 0) != 0xAA5555AA) 
buf : 		goto error;
buf : 
buf : 	/* Check if unaligned 32bit SHM_SHARED access works properly.
if unaligned 32bit SHM_SHARED access works properly. 
buf : 	 * However, don't bail out on failure, because it's noncritical. */
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, 0, 0x1122);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, 2, 0x3344);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, 4, 0x5566);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, 6, 0x7788);
buf : 	if (b43_shm_read32(dev, B43_SHM_SHARED, 2) != 0x55663344)
if (b43_shm_read32(dev, B43_SHM_SHARED, 2) != 0x55663344) 
buf : 		b43warn(dev->wl, "Unaligned 32bit SHM read access is broken\n");
buf : 	b43_shm_write32(dev, B43_SHM_SHARED, 2, 0xAABBCCDD);
buf : 	if (b43_shm_read16(dev, B43_SHM_SHARED, 0) != 0x1122 ||
if (b43_shm_read16(dev, B43_SHM_SHARED, 0) != 0x1122 || 
buf : 	    b43_shm_read16(dev, B43_SHM_SHARED, 2) != 0xCCDD ||
buf : 	    b43_shm_read16(dev, B43_SHM_SHARED, 4) != 0xAABB ||
buf : 	    b43_shm_read16(dev, B43_SHM_SHARED, 6) != 0x7788)
buf : 		b43warn(dev->wl, "Unaligned 32bit SHM write access is broken\n");
buf : 
buf : 	b43_shm_write32(dev, B43_SHM_SHARED, 0, backup0);
buf : 	b43_shm_write32(dev, B43_SHM_SHARED, 4, backup4);
buf : 
buf : 	if ((dev->dev->core_rev >= 3) && (dev->dev->core_rev <= 10)) {
if ((dev->dev->core_rev >= 3) && (dev->dev->core_rev <= 10)) { 
buf : 		/* The 32bit register shadows the two 16bit registers
buf : 		 * with update sideeffects. Validate this. */
buf : 		b43_write16(dev, B43_MMIO_TSF_CFP_START, 0xAAAA);
buf : 		b43_write32(dev, B43_MMIO_TSF_CFP_START, 0xCCCCBBBB);
buf : 		if (b43_read16(dev, B43_MMIO_TSF_CFP_START_LOW) != 0xBBBB)
if (b43_read16(dev, B43_MMIO_TSF_CFP_START_LOW) != 0xBBBB) 
buf : 			goto error;
buf : 		if (b43_read16(dev, B43_MMIO_TSF_CFP_START_HIGH) != 0xCCCC)
if (b43_read16(dev, B43_MMIO_TSF_CFP_START_HIGH) != 0xCCCC) 
buf : 			goto error;
buf : 	}
buf : 	b43_write32(dev, B43_MMIO_TSF_CFP_START, 0);
buf : 
buf : 	v = b43_read32(dev, B43_MMIO_MACCTL);
buf : 	v |= B43_MACCTL_GMODE;
buf : 	if (v != (B43_MACCTL_GMODE | B43_MACCTL_IHR_ENABLED))
if (v != (B43_MACCTL_GMODE | B43_MACCTL_IHR_ENABLED)) 
buf : 		goto error;
buf : 
buf : 	return 0;
buf : error:
buf : 	b43err(dev->wl, "Failed to validate the chipaccess\n");
buf : 	return -ENODEV;
buf : }
buf : 
buf : static void b43_security_init(struct b43_wldev *dev)
buf : {
buf : 	dev->ktp = b43_shm_read16(dev, B43_SHM_SHARED, B43_SHM_SH_KTP);
buf : 	/* KTP is a word address, but we address SHM bytewise.
buf : 	 * So multiply by two.
buf : 	 */
buf : 	dev->ktp *= 2;
buf : 	/* Number of RCMTA address slots */
buf : 	b43_write16(dev, B43_MMIO_RCMTA_COUNT, B43_NR_PAIRWISE_KEYS);
buf : 	/* Clear the key memory. */
buf : 	b43_clear_keys(dev);
buf : }
buf : 
buf : #ifdef CONFIG_B43_HWRNG
ifdef CONFIG_B43_HWRNG 
buf : static int b43_rng_read(struct hwrng *rng, u32 *data)
buf : {
buf : 	struct b43_wl *wl = (struct b43_wl *)rng->priv;
buf : 	struct b43_wldev *dev;
buf : 	int count = -ENODEV;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (likely(dev && b43_status(dev) >= B43_STAT_INITIALIZED)) {
if (likely(dev && b43_status(dev) >= B43_STAT_INITIALIZED)) { 
buf : 		*data = b43_read16(dev, B43_MMIO_RNG);
buf : 		count = sizeof(u16);
buf : 	}
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return count;
buf : }
buf : #endif /* CONFIG_B43_HWRNG */
if /* CONFIG_B43_HWRNG */ 
buf : 
buf : static void b43_rng_exit(struct b43_wl *wl)
buf : {
buf : #ifdef CONFIG_B43_HWRNG
ifdef CONFIG_B43_HWRNG 
buf : 	if (wl->rng_initialized)
buf : 		hwrng_unregister(&wl->rng);
buf : #endif /* CONFIG_B43_HWRNG */
if /* CONFIG_B43_HWRNG */ 
buf : }
buf : 
buf : static int b43_rng_init(struct b43_wl *wl)
buf : {
buf : 	int err = 0;
buf : 
buf : #ifdef CONFIG_B43_HWRNG
ifdef CONFIG_B43_HWRNG 
buf : 	snprintf(wl->rng_name, ARRAY_SIZE(wl->rng_name),
buf : 		 "%s_%s", KBUILD_MODNAME, wiphy_name(wl->hw->wiphy));
buf : 	wl->rng.name = wl->rng_name;
buf : 	wl->rng.data_read = b43_rng_read;
buf : 	wl->rng.priv = (unsigned long)wl;
buf : 	wl->rng_initialized = true;
buf : 	err = hwrng_register(&wl->rng);
buf : 	if (err) {
if (err) { 
buf : 		wl->rng_initialized = false;
buf : 		b43err(wl, "Failed to register the random "
buf : 		       "number generator (%d)\n", err);
buf : 	}
buf : #endif /* CONFIG_B43_HWRNG */
if /* CONFIG_B43_HWRNG */ 
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void b43_tx_work(struct work_struct *work)
buf : {
buf : 	struct b43_wl *wl = container_of(work, struct b43_wl, tx_work);
buf : 	struct b43_wldev *dev;
buf : 	struct sk_buff *skb;
buf : 	int queue_num;
buf : 	int err = 0;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (unlikely(!dev || b43_status(dev) < B43_STAT_STARTED)) {
if (unlikely(!dev || b43_status(dev) < B43_STAT_STARTED)) { 
buf : 		mutex_unlock(&wl->mutex);
buf : 		return;
buf : 	}
buf : 
buf : 	for (queue_num = 0; queue_num < B43_QOS_QUEUE_NUM; queue_num++) {
for (queue_num = 0; queue_num < B43_QOS_QUEUE_NUM; queue_num++) { 
buf : 		while (skb_queue_len(&wl->tx_queue[queue_num])) {
while (skb_queue_len(&wl->tx_queue[queue_num])) { 
buf : 			skb = skb_dequeue(&wl->tx_queue[queue_num]);
buf : 			if (b43_using_pio_transfers(dev))
if (b43_using_pio_transfers(dev)) 
buf : 				err = b43_pio_tx(dev, skb);
buf : 			else
buf : 				err = b43_dma_tx(dev, skb);
buf : 			if (err == -ENOSPC) {
if (err == -ENOSPC) { 
buf : 				wl->tx_queue_stopped[queue_num] = 1;
buf : 				ieee80211_stop_queue(wl->hw, queue_num);
buf : 				skb_queue_head(&wl->tx_queue[queue_num], skb);
buf : 				break;
buf : 			}
buf : 			if (unlikely(err))
if (unlikely(err)) 
buf : 				ieee80211_free_txskb(wl->hw, skb);
buf : 			err = 0;
buf : 		}
buf : 
buf : 		if (!err)
if (!err) 
buf : 			wl->tx_queue_stopped[queue_num] = 0;
buf : 	}
buf : 
buf : #if B43_DEBUG
if B43_DEBUG 
buf : 	dev->tx_count++;
buf : #endif
if 
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void b43_op_tx(struct ieee80211_hw *hw,
buf : 		      struct ieee80211_tx_control *control,
buf : 		      struct sk_buff *skb)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 
buf : 	if (unlikely(skb->len < 2 + 2 + 6)) {
if (unlikely(skb->len < 2 + 2 + 6)) { 
buf : 		/* Too short, this can't be a valid frame. */
buf : 		ieee80211_free_txskb(hw, skb);
buf : 		return;
buf : 	}
buf : 	B43_WARN_ON(skb_shinfo(skb)->nr_frags);
buf : 
buf : 	skb_queue_tail(&wl->tx_queue[skb->queue_mapping], skb);
buf : 	if (!wl->tx_queue_stopped[skb->queue_mapping]) {
if (!wl->tx_queue_stopped[skb->queue_mapping]) { 
buf : 		ieee80211_queue_work(wl->hw, &wl->tx_work);
buf : 	} else {
buf : 		ieee80211_stop_queue(wl->hw, skb->queue_mapping);
buf : 	}
buf : }
buf : 
buf : static void b43_qos_params_upload(struct b43_wldev *dev,
buf : 				  const struct ieee80211_tx_queue_params *p,
buf : 				  u16 shm_offset)
buf : {
buf : 	u16 params[B43_NR_QOSPARAMS];
buf : 	int bslots, tmp;
buf : 	unsigned int i;
buf : 
buf : 	if (!dev->qos_enabled)
if (!dev->qos_enabled) 
buf : 		return;
buf : 
buf : 	bslots = b43_read16(dev, B43_MMIO_RNG) & p->cw_min;
buf : 
buf : 	memset(&params, 0, sizeof(params));
buf : 
buf : 	params[B43_QOSPARAM_TXOP] = p->txop * 32;
buf : 	params[B43_QOSPARAM_CWMIN] = p->cw_min;
buf : 	params[B43_QOSPARAM_CWMAX] = p->cw_max;
buf : 	params[B43_QOSPARAM_CWCUR] = p->cw_min;
buf : 	params[B43_QOSPARAM_AIFS] = p->aifs;
ifs; 
buf : 	params[B43_QOSPARAM_BSLOTS] = bslots;
buf : 	params[B43_QOSPARAM_REGGAP] = bslots + p->aifs;
ifs; 
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(params); i++) {
for (i = 0; i < ARRAY_SIZE(params); i++) { 
buf : 		if (i == B43_QOSPARAM_STATUS) {
buf : 			tmp = b43_shm_read16(dev, B43_SHM_SHARED,
buf : 					     shm_offset + (i * 2));
buf : 			/* Mark the parameters as updated. */
buf : 			tmp |= 0x100;
buf : 			b43_shm_write16(dev, B43_SHM_SHARED,
buf : 					shm_offset + (i * 2),
buf : 					tmp);
buf : 		} else {
buf : 			b43_shm_write16(dev, B43_SHM_SHARED,
buf : 					shm_offset + (i * 2),
buf : 					params[i]);
buf : 		}
buf : 	}
buf : }
buf : 
buf : /* Mapping of mac80211 queue numbers to b43 QoS SHM offsets. */
buf : static const u16 b43_qos_shm_offsets[] = {
buf : 	/* [mac80211-queue-nr] = SHM_OFFSET, */
buf : 	[0] = B43_QOS_VOICE,
buf : 	[1] = B43_QOS_VIDEO,
buf : 	[2] = B43_QOS_BESTEFFORT,
buf : 	[3] = B43_QOS_BACKGROUND,
buf : };
buf : 
buf : /* Update all QOS parameters in hardware. */
buf : static void b43_qos_upload_all(struct b43_wldev *dev)
buf : {
buf : 	struct b43_wl *wl = dev->wl;
buf : 	struct b43_qos_params *params;
buf : 	unsigned int i;
buf : 
buf : 	if (!dev->qos_enabled)
if (!dev->qos_enabled) 
buf : 		return;
buf : 
buf : 	BUILD_BUG_ON(ARRAY_SIZE(b43_qos_shm_offsets) !=
buf : 		     ARRAY_SIZE(wl->qos_params));
buf : 
buf : 	b43_mac_suspend(dev);
buf : 	for (i = 0; i < ARRAY_SIZE(wl->qos_params); i++) {
for (i = 0; i < ARRAY_SIZE(wl->qos_params); i++) { 
buf : 		params = &(wl->qos_params[i]);
buf : 		b43_qos_params_upload(dev, &(params->p),
buf : 				      b43_qos_shm_offsets[i]);
buf : 	}
buf : 	b43_mac_enable(dev);
buf : }
buf : 
buf : static void b43_qos_clear(struct b43_wl *wl)
buf : {
buf : 	struct b43_qos_params *params;
buf : 	unsigned int i;
buf : 
buf : 	/* Initialize QoS parameters to sane defaults. */
buf : 
buf : 	BUILD_BUG_ON(ARRAY_SIZE(b43_qos_shm_offsets) !=
buf : 		     ARRAY_SIZE(wl->qos_params));
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(wl->qos_params); i++) {
for (i = 0; i < ARRAY_SIZE(wl->qos_params); i++) { 
buf : 		params = &(wl->qos_params[i]);
buf : 
buf : 		switch (b43_qos_shm_offsets[i]) {
buf : 		case B43_QOS_VOICE:
buf : 			params->p.txop = 0;
buf : 			params->p.aifs = 2;
ifs = 2; 
buf : 			params->p.cw_min = 0x0001;
buf : 			params->p.cw_max = 0x0001;
buf : 			break;
buf : 		case B43_QOS_VIDEO:
buf : 			params->p.txop = 0;
buf : 			params->p.aifs = 2;
ifs = 2; 
buf : 			params->p.cw_min = 0x0001;
buf : 			params->p.cw_max = 0x0001;
buf : 			break;
buf : 		case B43_QOS_BESTEFFORT:
buf : 			params->p.txop = 0;
buf : 			params->p.aifs = 3;
ifs = 3; 
buf : 			params->p.cw_min = 0x0001;
buf : 			params->p.cw_max = 0x03FF;
buf : 			break;
buf : 		case B43_QOS_BACKGROUND:
buf : 			params->p.txop = 0;
buf : 			params->p.aifs = 7;
ifs = 7; 
buf : 			params->p.cw_min = 0x0001;
buf : 			params->p.cw_max = 0x03FF;
buf : 			break;
buf : 		default:
buf : 			B43_WARN_ON(1);
buf : 		}
buf : 	}
buf : }
buf : 
buf : /* Initialize the core's QOS capabilities */
buf : static void b43_qos_init(struct b43_wldev *dev)
buf : {
buf : 	if (!dev->qos_enabled) {
if (!dev->qos_enabled) { 
buf : 		/* Disable QOS support. */
buf : 		b43_hf_write(dev, b43_hf_read(dev) & ~B43_HF_EDCF);
buf : 		b43_write16(dev, B43_MMIO_IFSCTL,
buf : 			    b43_read16(dev, B43_MMIO_IFSCTL)
buf : 			    & ~B43_MMIO_IFSCTL_USE_EDCF);
buf : 		b43dbg(dev->wl, "QoS disabled\n");
buf : 		return;
buf : 	}
buf : 
buf : 	/* Upload the current QOS parameters. */
buf : 	b43_qos_upload_all(dev);
buf : 
buf : 	/* Enable QOS support. */
buf : 	b43_hf_write(dev, b43_hf_read(dev) | B43_HF_EDCF);
buf : 	b43_write16(dev, B43_MMIO_IFSCTL,
buf : 		    b43_read16(dev, B43_MMIO_IFSCTL)
buf : 		    | B43_MMIO_IFSCTL_USE_EDCF);
buf : 	b43dbg(dev->wl, "QoS enabled\n");
buf : }
buf : 
buf : static int b43_op_conf_tx(struct ieee80211_hw *hw,
buf : 			  struct ieee80211_vif *vif, u16 _queue,
if *vif, u16 _queue, 
buf : 			  const struct ieee80211_tx_queue_params *params)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 	unsigned int queue = (unsigned int)_queue;
buf : 	int err = -ENODEV;
buf : 
buf : 	if (queue >= ARRAY_SIZE(wl->qos_params)) {
if (queue >= ARRAY_SIZE(wl->qos_params)) { 
buf : 		/* Queue not available or don't support setting
buf : 		 * params on this queue. Return success to not
buf : 		 * confuse mac80211. */
buf : 		return 0;
buf : 	}
buf : 	BUILD_BUG_ON(ARRAY_SIZE(b43_qos_shm_offsets) !=
buf : 		     ARRAY_SIZE(wl->qos_params));
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (unlikely(!dev || (b43_status(dev) < B43_STAT_INITIALIZED)))
if (unlikely(!dev || (b43_status(dev) < B43_STAT_INITIALIZED))) 
buf : 		goto out_unlock;
buf : 
buf : 	memcpy(&(wl->qos_params[queue].p), params, sizeof(*params));
buf : 	b43_mac_suspend(dev);
buf : 	b43_qos_params_upload(dev, &(wl->qos_params[queue].p),
buf : 			      b43_qos_shm_offsets[queue]);
buf : 	b43_mac_enable(dev);
buf : 	err = 0;
buf : 
buf : out_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int b43_op_get_stats(struct ieee80211_hw *hw,
buf : 			    struct ieee80211_low_level_stats *stats)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	memcpy(stats, &wl->ieee_stats, sizeof(*stats));
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static u64 b43_op_get_tsf(struct ieee80211_hw *hw, struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 	u64 tsf;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 
buf : 	if (dev && (b43_status(dev) >= B43_STAT_INITIALIZED))
if (dev && (b43_status(dev) >= B43_STAT_INITIALIZED)) 
buf : 		b43_tsf_read(dev, &tsf);
buf : 	else
buf : 		tsf = 0;
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return tsf;
buf : }
buf : 
buf : static void b43_op_set_tsf(struct ieee80211_hw *hw,
buf : 			   struct ieee80211_vif *vif, u64 tsf)
if *vif, u64 tsf) 
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 
buf : 	if (dev && (b43_status(dev) >= B43_STAT_INITIALIZED))
if (dev && (b43_status(dev) >= B43_STAT_INITIALIZED)) 
buf : 		b43_tsf_write(dev, tsf);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static const char *band_to_string(enum ieee80211_band band)
buf : {
buf : 	switch (band) {
buf : 	case IEEE80211_BAND_5GHZ:
buf : 		return "5";
buf : 	case IEEE80211_BAND_2GHZ:
buf : 		return "2.4";
buf : 	default:
buf : 		break;
buf : 	}
buf : 	B43_WARN_ON(1);
buf : 	return "";
buf : }
buf : 
buf : /* Expects wl->mutex locked */
buf : static int b43_switch_band(struct b43_wldev *dev,
buf : 			   struct ieee80211_channel *chan)
buf : {
buf : 	struct b43_phy *phy = &dev->phy;
buf : 	bool gmode;
buf : 	u32 tmp;
buf : 
buf : 	switch (chan->band) {
buf : 	case IEEE80211_BAND_5GHZ:
buf : 		gmode = false;
buf : 		break;
buf : 	case IEEE80211_BAND_2GHZ:
buf : 		gmode = true;
buf : 		break;
buf : 	default:
buf : 		B43_WARN_ON(1);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	if (!((gmode && phy->supports_2ghz) ||
if (!((gmode && phy->supports_2ghz) || 
buf : 	      (!gmode && phy->supports_5ghz))) {
buf : 		b43err(dev->wl, "This device doesn't support %s-GHz band\n",
buf : 		       band_to_string(chan->band));
buf : 		return -ENODEV;
buf : 	}
buf : 
buf : 	if (!!phy->gmode == !!gmode) {
if (!!phy->gmode == !!gmode) { 
buf : 		/* This device is already running. */
buf : 		return 0;
buf : 	}
buf : 
buf : 	b43dbg(dev->wl, "Switching to %s GHz band\n",
buf : 	       band_to_string(chan->band));
buf : 
buf : 	/* Some new devices don't need disabling radio for band switching */
for band switching */ 
buf : 	if (!(phy->type == B43_PHYTYPE_N && phy->rev >= 3))
buf : 		b43_software_rfkill(dev, true);
buf : 
buf : 	phy->gmode = gmode;
buf : 	b43_phy_put_into_reset(dev);
buf : 	switch (dev->dev->bus_type) {
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	case B43_BUS_BCMA:
buf : 		tmp = bcma_aread32(dev->dev->bdev, BCMA_IOCTL);
buf : 		if (gmode)
if (gmode) 
buf : 			tmp |= B43_BCMA_IOCTL_GMODE;
buf : 		else
buf : 			tmp &= ~B43_BCMA_IOCTL_GMODE;
buf : 		bcma_awrite32(dev->dev->bdev, BCMA_IOCTL, tmp);
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	case B43_BUS_SSB:
buf : 		tmp = ssb_read32(dev->dev->sdev, SSB_TMSLOW);
buf : 		if (gmode)
if (gmode) 
buf : 			tmp |= B43_TMSLOW_GMODE;
buf : 		else
buf : 			tmp &= ~B43_TMSLOW_GMODE;
buf : 		ssb_write32(dev->dev->sdev, SSB_TMSLOW, tmp);
buf : 		break;
buf : #endif
if 
buf : 	}
buf : 	b43_phy_take_out_of_reset(dev);
buf : 
buf : 	b43_upload_initvals_band(dev);
buf : 
buf : 	b43_phy_init(dev);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /* Write the short and long frame retry limit values. */
buf : static void b43_set_retry_limits(struct b43_wldev *dev,
buf : 				 unsigned int short_retry,
buf : 				 unsigned int long_retry)
buf : {
buf : 	/* The retry limit is a 4-bit counter. Enforce this to avoid overflowing
force this to avoid overflowing 
buf : 	 * the chip-internal counter. */
buf : 	short_retry = min(short_retry, (unsigned int)0xF);
buf : 	long_retry = min(long_retry, (unsigned int)0xF);
buf : 
buf : 	b43_shm_write16(dev, B43_SHM_SCRATCH, B43_SHM_SC_SRLIMIT,
buf : 			short_retry);
buf : 	b43_shm_write16(dev, B43_SHM_SCRATCH, B43_SHM_SC_LRLIMIT,
buf : 			long_retry);
buf : }
buf : 
buf : static int b43_op_config(struct ieee80211_hw *hw, u32 changed)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 	struct b43_phy *phy;
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 	int antenna;
buf : 	int err = 0;
buf : 	bool reload_bss = false;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	dev = wl->current_dev;
buf : 
buf : 	b43_mac_suspend(dev);
buf : 
buf : 	/* Switch the band (if necessary). This might change the active core. */
if necessary). This might change the active core. */ 
buf : 	err = b43_switch_band(dev, conf->chandef.chan);
buf : 	if (err)
if (err) 
buf : 		goto out_unlock_mutex;
buf : 
buf : 	/* Need to reload all settings if the core changed */
if the core changed */ 
buf : 	if (dev != wl->current_dev) {
buf : 		dev = wl->current_dev;
buf : 		changed = ~0;
buf : 		reload_bss = true;
buf : 	}
buf : 
buf : 	phy = &dev->phy;
buf : 
buf : 	if (conf_is_ht(conf))
if (conf_is_ht(conf)) 
buf : 		phy->is_40mhz =
buf : 			(conf_is_ht40_minus(conf) || conf_is_ht40_plus(conf));
buf : 	else
buf : 		phy->is_40mhz = false;
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_RETRY_LIMITS)
if (changed & IEEE80211_CONF_CHANGE_RETRY_LIMITS) 
buf : 		b43_set_retry_limits(dev, conf->short_frame_max_tx_count,
buf : 					  conf->long_frame_max_tx_count);
buf : 	changed &= ~IEEE80211_CONF_CHANGE_RETRY_LIMITS;
buf : 	if (!changed)
if (!changed) 
buf : 		goto out_mac_enable;
buf : 
buf : 	/* Switch to the requested channel.
buf : 	 * The firmware takes care of races with the TX handler. */
buf : 	if (conf->chandef.chan->hw_value != phy->channel)
if (conf->chandef.chan->hw_value != phy->channel) 
buf : 		b43_switch_channel(dev, conf->chandef.chan->hw_value);
buf : 
buf : 	dev->wl->radiotap_enabled = !!(conf->flags & IEEE80211_CONF_MONITOR);
buf : 
buf : 	/* Adjust the desired TX power level. */
buf : 	if (conf->power_level != 0) {
if (conf->power_level != 0) { 
buf : 		if (conf->power_level != phy->desired_txpower) {
buf : 			phy->desired_txpower = conf->power_level;
buf : 			b43_phy_txpower_check(dev, B43_TXPWR_IGNORE_TIME |
buf : 						   B43_TXPWR_IGNORE_TSSI);
buf : 		}
buf : 	}
buf : 
buf : 	/* Antennas for RX and management frame TX. */
for RX and management frame TX. */ 
buf : 	antenna = B43_ANTENNA_DEFAULT;
buf : 	b43_mgmtframe_txantenna(dev, antenna);
buf : 	antenna = B43_ANTENNA_DEFAULT;
buf : 	if (phy->ops->set_rx_antenna)
if (phy->ops->set_rx_antenna) 
buf : 		phy->ops->set_rx_antenna(dev, antenna);
buf : 
buf : 	if (wl->radio_enabled != phy->radio_on) {
if (wl->radio_enabled != phy->radio_on) { 
buf : 		if (wl->radio_enabled) {
buf : 			b43_software_rfkill(dev, false);
buf : 			b43info(dev->wl, "Radio turned on by software\n");
buf : 			if (!dev->radio_hw_enable) {
if (!dev->radio_hw_enable) { 
buf : 				b43info(dev->wl, "The hardware RF-kill button "
buf : 					"still turns the radio physically off. "
buf : 					"Press the button to turn it on.\n");
buf : 			}
buf : 		} else {
buf : 			b43_software_rfkill(dev, true);
buf : 			b43info(dev->wl, "Radio turned off by software\n");
buf : 		}
buf : 	}
buf : 
buf : out_mac_enable:
buf : 	b43_mac_enable(dev);
buf : out_unlock_mutex:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	if (wl->vif && reload_bss)
if (wl->vif && reload_bss) 
buf : 		b43_op_bss_info_changed(hw, wl->vif, &wl->vif->bss_conf, ~0);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void b43_update_basic_rates(struct b43_wldev *dev, u32 brates)
buf : {
buf : 	struct ieee80211_supported_band *sband =
buf : 		dev->wl->hw->wiphy->bands[b43_current_band(dev->wl)];
buf : 	struct ieee80211_rate *rate;
buf : 	int i;
buf : 	u16 basic, direct, offset, basic_offset, rateptr;
buf : 
buf : 	for (i = 0; i < sband->n_bitrates; i++) {
for (i = 0; i < sband->n_bitrates; i++) { 
buf : 		rate = &sband->bitrates[i];
buf : 
buf : 		if (b43_is_cck_rate(rate->hw_value)) {
if (b43_is_cck_rate(rate->hw_value)) { 
buf : 			direct = B43_SHM_SH_CCKDIRECT;
buf : 			basic = B43_SHM_SH_CCKBASIC;
buf : 			offset = b43_plcp_get_ratecode_cck(rate->hw_value);
buf : 			offset &= 0xF;
buf : 		} else {
buf : 			direct = B43_SHM_SH_OFDMDIRECT;
buf : 			basic = B43_SHM_SH_OFDMBASIC;
buf : 			offset = b43_plcp_get_ratecode_ofdm(rate->hw_value);
buf : 			offset &= 0xF;
buf : 		}
buf : 
buf : 		rate = ieee80211_get_response_rate(sband, brates, rate->bitrate);
buf : 
buf : 		if (b43_is_cck_rate(rate->hw_value)) {
if (b43_is_cck_rate(rate->hw_value)) { 
buf : 			basic_offset = b43_plcp_get_ratecode_cck(rate->hw_value);
buf : 			basic_offset &= 0xF;
buf : 		} else {
buf : 			basic_offset = b43_plcp_get_ratecode_ofdm(rate->hw_value);
buf : 			basic_offset &= 0xF;
buf : 		}
buf : 
buf : 		/*
buf : 		 * Get the pointer that we need to point to
buf : 		 * from the direct map
buf : 		 */
buf : 		rateptr = b43_shm_read16(dev, B43_SHM_SHARED,
buf : 					 direct + 2 * basic_offset);
buf : 		/* and write it to the basic map */
buf : 		b43_shm_write16(dev, B43_SHM_SHARED, basic + 2 * offset,
buf : 				rateptr);
buf : 	}
buf : }
buf : 
buf : static void b43_op_bss_info_changed(struct ieee80211_hw *hw,
buf : 				    struct ieee80211_vif *vif,
if *vif, 
buf : 				    struct ieee80211_bss_conf *conf,
buf : 				    u32 changed)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	dev = wl->current_dev;
buf : 	if (!dev || b43_status(dev) < B43_STAT_STARTED)
if (!dev || b43_status(dev) < B43_STAT_STARTED) 
buf : 		goto out_unlock_mutex;
buf : 
buf : 	B43_WARN_ON(wl->vif != vif);
if != vif); 
buf : 
buf : 	if (changed & BSS_CHANGED_BSSID) {
buf : 		if (conf->bssid)
if (conf->bssid) 
buf : 			memcpy(wl->bssid, conf->bssid, ETH_ALEN);
buf : 		else
buf : 			memset(wl->bssid, 0, ETH_ALEN);
buf : 	}
buf : 
buf : 	if (b43_status(dev) >= B43_STAT_INITIALIZED) {
if (b43_status(dev) >= B43_STAT_INITIALIZED) { 
buf : 		if (changed & BSS_CHANGED_BEACON &&
buf : 		    (b43_is_mode(wl, NL80211_IFTYPE_AP) ||
buf : 		     b43_is_mode(wl, NL80211_IFTYPE_MESH_POINT) ||
buf : 		     b43_is_mode(wl, NL80211_IFTYPE_ADHOC)))
buf : 			b43_update_templates(wl);
buf : 
buf : 		if (changed & BSS_CHANGED_BSSID)
if (changed & BSS_CHANGED_BSSID) 
buf : 			b43_write_mac_bssid_templates(dev);
buf : 	}
buf : 
buf : 	b43_mac_suspend(dev);
buf : 
buf : 	/* Update templates for AP/mesh mode. */
for AP/mesh mode. */ 
buf : 	if (changed & BSS_CHANGED_BEACON_INT &&
buf : 	    (b43_is_mode(wl, NL80211_IFTYPE_AP) ||
buf : 	     b43_is_mode(wl, NL80211_IFTYPE_MESH_POINT) ||
buf : 	     b43_is_mode(wl, NL80211_IFTYPE_ADHOC)) &&
buf : 	    conf->beacon_int)
buf : 		b43_set_beacon_int(dev, conf->beacon_int);
buf : 
buf : 	if (changed & BSS_CHANGED_BASIC_RATES)
if (changed & BSS_CHANGED_BASIC_RATES) 
buf : 		b43_update_basic_rates(dev, conf->basic_rates);
buf : 
buf : 	if (changed & BSS_CHANGED_ERP_SLOT) {
if (changed & BSS_CHANGED_ERP_SLOT) { 
buf : 		if (conf->use_short_slot)
buf : 			b43_short_slot_timing_enable(dev);
buf : 		else
buf : 			b43_short_slot_timing_disable(dev);
buf : 	}
buf : 
buf : 	b43_mac_enable(dev);
buf : out_unlock_mutex:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int b43_op_set_key(struct ieee80211_hw *hw, enum set_key_cmd cmd,
buf : 			  struct ieee80211_vif *vif, struct ieee80211_sta *sta,
if *vif, struct ieee80211_sta *sta, 
buf : 			  struct ieee80211_key_conf *key)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 	u8 algorithm;
buf : 	u8 index;
buf : 	int err;
buf : 	static const u8 bcast_addr[ETH_ALEN] = { 0xff, 0xff, 0xff, 0xff, 0xff, 0xff };
buf : 
buf : 	if (modparam_nohwcrypt)
if (modparam_nohwcrypt) 
buf : 		return -ENOSPC; /* User disabled HW-crypto */
buf : 
buf : 	if ((vif->type == NL80211_IFTYPE_ADHOC ||
if ((vif->type == NL80211_IFTYPE_ADHOC || 
buf : 	     vif->type == NL80211_IFTYPE_MESH_POINT) &&
buf : 	    (key->cipher == WLAN_CIPHER_SUITE_TKIP ||
buf : 	     key->cipher == WLAN_CIPHER_SUITE_CCMP) &&
buf : 	    !(key->flags & IEEE80211_KEY_FLAG_PAIRWISE)) {
buf : 		/*
buf : 		 * For now, disable hw crypto for the RSN IBSS group keys. This
for the RSN IBSS group keys. This 
buf : 		 * could be optimized in the future, but until that gets
buf : 		 * implemented, use of software crypto for group addressed
for group addressed 
buf : 		 * frames is a acceptable to allow RSN IBSS to be used.
buf : 		 */
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	dev = wl->current_dev;
buf : 	err = -ENODEV;
buf : 	if (!dev || b43_status(dev) < B43_STAT_INITIALIZED)
if (!dev || b43_status(dev) < B43_STAT_INITIALIZED) 
buf : 		goto out_unlock;
buf : 
buf : 	if (dev->fw.pcm_request_failed || !dev->hwcrypto_enabled) {
if (dev->fw.pcm_request_failed || !dev->hwcrypto_enabled) { 
buf : 		/* We don't have firmware for the crypto engine.
for the crypto engine. 
buf : 		 * Must use software-crypto. */
buf : 		err = -EOPNOTSUPP;
buf : 		goto out_unlock;
buf : 	}
buf : 
buf : 	err = -EINVAL;
buf : 	switch (key->cipher) {
buf : 	case WLAN_CIPHER_SUITE_WEP40:
buf : 		algorithm = B43_SEC_ALGO_WEP40;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_WEP104:
buf : 		algorithm = B43_SEC_ALGO_WEP104;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_TKIP:
buf : 		algorithm = B43_SEC_ALGO_TKIP;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_CCMP:
buf : 		algorithm = B43_SEC_ALGO_AES;
buf : 		break;
buf : 	default:
buf : 		B43_WARN_ON(1);
buf : 		goto out_unlock;
buf : 	}
buf : 	index = (u8) (key->keyidx);
buf : 	if (index > 3)
if (index > 3) 
buf : 		goto out_unlock;
buf : 
buf : 	switch (cmd) {
buf : 	case SET_KEY:
buf : 		if (algorithm == B43_SEC_ALGO_TKIP &&
if (algorithm == B43_SEC_ALGO_TKIP && 
buf : 		    (!(key->flags & IEEE80211_KEY_FLAG_PAIRWISE) ||
buf : 		    !modparam_hwtkip)) {
buf : 			/* We support only pairwise key */
buf : 			err = -EOPNOTSUPP;
buf : 			goto out_unlock;
buf : 		}
buf : 
buf : 		if (key->flags & IEEE80211_KEY_FLAG_PAIRWISE) {
if (key->flags & IEEE80211_KEY_FLAG_PAIRWISE) { 
buf : 			if (WARN_ON(!sta)) {
buf : 				err = -EOPNOTSUPP;
buf : 				goto out_unlock;
buf : 			}
buf : 			/* Pairwise key with an assigned MAC address. */
buf : 			err = b43_key_write(dev, -1, algorithm,
buf : 					    key->key, key->keylen,
buf : 					    sta->addr, key);
buf : 		} else {
buf : 			/* Group key */
buf : 			err = b43_key_write(dev, index, algorithm,
buf : 					    key->key, key->keylen, NULL, key);
buf : 		}
buf : 		if (err)
if (err) 
buf : 			goto out_unlock;
buf : 
buf : 		if (algorithm == B43_SEC_ALGO_WEP40 ||
if (algorithm == B43_SEC_ALGO_WEP40 || 
buf : 		    algorithm == B43_SEC_ALGO_WEP104) {
buf : 			b43_hf_write(dev, b43_hf_read(dev) | B43_HF_USEDEFKEYS);
buf : 		} else {
buf : 			b43_hf_write(dev,
buf : 				     b43_hf_read(dev) & ~B43_HF_USEDEFKEYS);
buf : 		}
buf : 		key->flags |= IEEE80211_KEY_FLAG_GENERATE_IV;
buf : 		if (algorithm == B43_SEC_ALGO_TKIP)
if (algorithm == B43_SEC_ALGO_TKIP) 
buf : 			key->flags |= IEEE80211_KEY_FLAG_GENERATE_MMIC;
buf : 		break;
buf : 	case DISABLE_KEY: {
buf : 		err = b43_key_clear(dev, key->hw_key_idx);
buf : 		if (err)
if (err) 
buf : 			goto out_unlock;
buf : 		break;
buf : 	}
buf : 	default:
buf : 		B43_WARN_ON(1);
buf : 	}
buf : 
buf : out_unlock:
buf : 	if (!err) {
if (!err) { 
buf : 		b43dbg(wl, "%s hardware based encryption for keyidx: %d, "
for keyidx: %d, " 
buf : 		       "mac: %pM\n",
buf : 		       cmd == SET_KEY ? "Using" : "Disabling", key->keyidx,
buf : 		       sta ? sta->addr : bcast_addr);
buf : 		b43_dump_keymemory(dev);
buf : 	}
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void b43_op_configure_filter(struct ieee80211_hw *hw,
buf : 				    unsigned int changed, unsigned int *fflags,
buf : 				    u64 multicast)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (!dev) {
if (!dev) { 
buf : 		*fflags = 0;
buf : 		goto out_unlock;
buf : 	}
buf : 
buf : 	*fflags &= FIF_PROMISC_IN_BSS |
buf : 		  FIF_ALLMULTI |
buf : 		  FIF_FCSFAIL |
buf : 		  FIF_PLCPFAIL |
buf : 		  FIF_CONTROL |
buf : 		  FIF_OTHER_BSS |
buf : 		  FIF_BCN_PRBRESP_PROMISC;
buf : 
buf : 	changed &= FIF_PROMISC_IN_BSS |
buf : 		   FIF_ALLMULTI |
buf : 		   FIF_FCSFAIL |
buf : 		   FIF_PLCPFAIL |
buf : 		   FIF_CONTROL |
buf : 		   FIF_OTHER_BSS |
buf : 		   FIF_BCN_PRBRESP_PROMISC;
buf : 
buf : 	wl->filter_flags = *fflags;
buf : 
buf : 	if (changed && b43_status(dev) >= B43_STAT_INITIALIZED)
if (changed && b43_status(dev) >= B43_STAT_INITIALIZED) 
buf : 		b43_adjust_opmode(dev);
buf : 
buf : out_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : /* Locking: wl->mutex
buf :  * Returns the current dev. This might be different from the passed in dev,
ifferent from the passed in dev, 
buf :  * because the core might be gone away while we unlocked the mutex. */
while we unlocked the mutex. */ 
buf : static struct b43_wldev * b43_wireless_core_stop(struct b43_wldev *dev)
buf : {
buf : 	struct b43_wl *wl;
buf : 	struct b43_wldev *orig_dev;
buf : 	u32 mask;
buf : 	int queue_num;
buf : 
buf : 	if (!dev)
if (!dev) 
buf : 		return NULL;
buf : 	wl = dev->wl;
buf : redo:
buf : 	if (!dev || b43_status(dev) < B43_STAT_STARTED)
if (!dev || b43_status(dev) < B43_STAT_STARTED) 
buf : 		return dev;
buf : 
buf : 	/* Cancel work. Unlock to avoid deadlocks. */
buf : 	mutex_unlock(&wl->mutex);
buf : 	cancel_delayed_work_sync(&dev->periodic_work);
buf : 	cancel_work_sync(&wl->tx_work);
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (!dev || b43_status(dev) < B43_STAT_STARTED) {
if (!dev || b43_status(dev) < B43_STAT_STARTED) { 
buf : 		/* Whoops, aliens ate up the device while we were unlocked. */
while we were unlocked. */ 
buf : 		return dev;
buf : 	}
buf : 
buf : 	/* Disable interrupts on the device. */
buf : 	b43_set_status(dev, B43_STAT_INITIALIZED);
buf : 	if (b43_bus_host_is_sdio(dev->dev)) {
if (b43_bus_host_is_sdio(dev->dev)) { 
buf : 		/* wl->mutex is locked. That is enough. */
buf : 		b43_write32(dev, B43_MMIO_GEN_IRQ_MASK, 0);
buf : 		b43_read32(dev, B43_MMIO_GEN_IRQ_MASK);	/* Flush */
buf : 	} else {
buf : 		spin_lock_irq(&wl->hardirq_lock);
buf : 		b43_write32(dev, B43_MMIO_GEN_IRQ_MASK, 0);
buf : 		b43_read32(dev, B43_MMIO_GEN_IRQ_MASK);	/* Flush */
buf : 		spin_unlock_irq(&wl->hardirq_lock);
buf : 	}
buf : 	/* Synchronize and free the interrupt handlers. Unlock to avoid deadlocks. */
buf : 	orig_dev = dev;
buf : 	mutex_unlock(&wl->mutex);
buf : 	if (b43_bus_host_is_sdio(dev->dev)) {
if (b43_bus_host_is_sdio(dev->dev)) { 
buf : 		b43_sdio_free_irq(dev);
buf : 	} else {
buf : 		synchronize_irq(dev->dev->irq);
buf : 		free_irq(dev->dev->irq, dev);
buf : 	}
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (!dev)
if (!dev) 
buf : 		return dev;
buf : 	if (dev != orig_dev) {
if (dev != orig_dev) { 
buf : 		if (b43_status(dev) >= B43_STAT_STARTED)
buf : 			goto redo;
buf : 		return dev;
buf : 	}
buf : 	mask = b43_read32(dev, B43_MMIO_GEN_IRQ_MASK);
buf : 	B43_WARN_ON(mask != 0xFFFFFFFF && mask);
buf : 
buf : 	/* Drain all TX queues. */
buf : 	for (queue_num = 0; queue_num < B43_QOS_QUEUE_NUM; queue_num++) {
for (queue_num = 0; queue_num < B43_QOS_QUEUE_NUM; queue_num++) { 
buf : 		while (skb_queue_len(&wl->tx_queue[queue_num])) {
while (skb_queue_len(&wl->tx_queue[queue_num])) { 
buf : 			struct sk_buff *skb;
buf : 
buf : 			skb = skb_dequeue(&wl->tx_queue[queue_num]);
buf : 			ieee80211_free_txskb(wl->hw, skb);
buf : 		}
buf : 	}
buf : 
buf : 	b43_mac_suspend(dev);
buf : 	b43_leds_exit(dev);
buf : 	b43dbg(wl, "Wireless interface stopped\n");
buf : 
buf : 	return dev;
buf : }
buf : 
buf : /* Locking: wl->mutex */
buf : static int b43_wireless_core_start(struct b43_wldev *dev)
buf : {
buf : 	int err;
buf : 
buf : 	B43_WARN_ON(b43_status(dev) != B43_STAT_INITIALIZED);
buf : 
buf : 	drain_txstatus_queue(dev);
buf : 	if (b43_bus_host_is_sdio(dev->dev)) {
if (b43_bus_host_is_sdio(dev->dev)) { 
buf : 		err = b43_sdio_request_irq(dev, b43_sdio_interrupt_handler);
buf : 		if (err) {
if (err) { 
buf : 			b43err(dev->wl, "Cannot request SDIO IRQ\n");
buf : 			goto out;
buf : 		}
buf : 	} else {
buf : 		err = request_threaded_irq(dev->dev->irq, b43_interrupt_handler,
buf : 					   b43_interrupt_thread_handler,
buf : 					   IRQF_SHARED, KBUILD_MODNAME, dev);
buf : 		if (err) {
if (err) { 
buf : 			b43err(dev->wl, "Cannot request IRQ-%d\n",
buf : 			       dev->dev->irq);
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : 	/* We are ready to run. */
buf : 	ieee80211_wake_queues(dev->wl->hw);
buf : 	b43_set_status(dev, B43_STAT_STARTED);
buf : 
buf : 	/* Start data flow (TX/RX). */
buf : 	b43_mac_enable(dev);
buf : 	b43_write32(dev, B43_MMIO_GEN_IRQ_MASK, dev->irq_mask);
buf : 
buf : 	/* Start maintenance work */
buf : 	b43_periodic_tasks_setup(dev);
buf : 
buf : 	b43_leds_init(dev);
buf : 
buf : 	b43dbg(dev->wl, "Wireless interface started\n");
buf : out:
buf : 	return err;
buf : }
buf : 
buf : static char *b43_phy_name(struct b43_wldev *dev, u8 phy_type)
buf : {
buf : 	switch (phy_type) {
buf : 	case B43_PHYTYPE_A:
buf : 		return "A";
buf : 	case B43_PHYTYPE_B:
buf : 		return "B";
buf : 	case B43_PHYTYPE_G:
buf : 		return "G";
buf : 	case B43_PHYTYPE_N:
buf : 		return "N";
buf : 	case B43_PHYTYPE_LP:
buf : 		return "LP";
buf : 	case B43_PHYTYPE_SSLPN:
buf : 		return "SSLPN";
buf : 	case B43_PHYTYPE_HT:
buf : 		return "HT";
buf : 	case B43_PHYTYPE_LCN:
buf : 		return "LCN";
buf : 	case B43_PHYTYPE_LCNXN:
buf : 		return "LCNXN";
buf : 	case B43_PHYTYPE_LCN40:
buf : 		return "LCN40";
buf : 	case B43_PHYTYPE_AC:
buf : 		return "AC";
buf : 	}
buf : 	return "UNKNOWN";
buf : }
buf : 
buf : /* Get PHY and RADIO versioning numbers */
buf : static int b43_phy_versioning(struct b43_wldev *dev)
buf : {
buf : 	struct b43_phy *phy = &dev->phy;
buf : 	u32 tmp;
buf : 	u8 analog_type;
buf : 	u8 phy_type;
buf : 	u8 phy_rev;
buf : 	u16 radio_manuf;
buf : 	u16 radio_ver;
buf : 	u16 radio_rev;
buf : 	int unsupported = 0;
buf : 
buf : 	/* Get PHY versioning */
buf : 	tmp = b43_read16(dev, B43_MMIO_PHY_VER);
buf : 	analog_type = (tmp & B43_PHYVER_ANALOG) >> B43_PHYVER_ANALOG_SHIFT;
buf : 	phy_type = (tmp & B43_PHYVER_TYPE) >> B43_PHYVER_TYPE_SHIFT;
buf : 	phy_rev = (tmp & B43_PHYVER_VERSION);
buf : 	switch (phy_type) {
buf : 	case B43_PHYTYPE_A:
buf : 		if (phy_rev >= 4)
if (phy_rev >= 4) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43_PHYTYPE_B:
buf : 		if (phy_rev != 2 && phy_rev != 4 && phy_rev != 6
if (phy_rev != 2 && phy_rev != 4 && phy_rev != 6 
buf : 		    && phy_rev != 7)
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43_PHYTYPE_G:
buf : 		if (phy_rev > 9)
if (phy_rev > 9) 
buf : 			unsupported = 1;
buf : 		break;
buf : #ifdef CONFIG_B43_PHY_N
ifdef CONFIG_B43_PHY_N 
buf : 	case B43_PHYTYPE_N:
buf : 		if (phy_rev > 9)
if (phy_rev > 9) 
buf : 			unsupported = 1;
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_PHY_LP
buf : 	case B43_PHYTYPE_LP:
buf : 		if (phy_rev > 2)
if (phy_rev > 2) 
buf : 			unsupported = 1;
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_PHY_HT
buf : 	case B43_PHYTYPE_HT:
buf : 		if (phy_rev > 1)
if (phy_rev > 1) 
buf : 			unsupported = 1;
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_PHY_LCN
buf : 	case B43_PHYTYPE_LCN:
buf : 		if (phy_rev > 1)
if (phy_rev > 1) 
buf : 			unsupported = 1;
buf : 		break;
buf : #endif
if 
buf : 	default:
buf : 		unsupported = 1;
buf : 	}
buf : 	if (unsupported) {
if (unsupported) { 
buf : 		b43err(dev->wl, "FOUND UNSUPPORTED PHY (Analog %u, Type %d (%s), Revision %u)\n",
buf : 		       analog_type, phy_type, b43_phy_name(dev, phy_type),
buf : 		       phy_rev);
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 	b43info(dev->wl, "Found PHY: Analog %u, Type %d (%s), Revision %u\n",
buf : 		analog_type, phy_type, b43_phy_name(dev, phy_type), phy_rev);
buf : 
buf : 	/* Get RADIO versioning */
buf : 	if (dev->dev->core_rev >= 24) {
if (dev->dev->core_rev >= 24) { 
buf : 		u16 radio24[3];
buf : 
buf : 		for (tmp = 0; tmp < 3; tmp++) {
for (tmp = 0; tmp < 3; tmp++) { 
buf : 			b43_write16(dev, B43_MMIO_RADIO24_CONTROL, tmp);
buf : 			radio24[tmp] = b43_read16(dev, B43_MMIO_RADIO24_DATA);
buf : 		}
buf : 
buf : 		/* Broadcom uses "id" for our "ver" and has separated "ver" */
for our "ver" and has separated "ver" */ 
buf : 		/* radio_ver = (radio24[0] & 0xF0) >> 4; */
buf : 
buf : 		radio_manuf = 0x17F;
buf : 		radio_ver = (radio24[2] << 8) | radio24[1];
buf : 		radio_rev = (radio24[0] & 0xF);
buf : 	} else {
buf : 		if (dev->dev->chip_id == 0x4317) {
if (dev->dev->chip_id == 0x4317) { 
buf : 			if (dev->dev->chip_rev == 0)
buf : 				tmp = 0x3205017F;
buf : 			else if (dev->dev->chip_rev == 1)
if (dev->dev->chip_rev == 1) 
buf : 				tmp = 0x4205017F;
buf : 			else
buf : 				tmp = 0x5205017F;
buf : 		} else {
buf : 			b43_write16(dev, B43_MMIO_RADIO_CONTROL,
buf : 				    B43_RADIOCTL_ID);
buf : 			tmp = b43_read16(dev, B43_MMIO_RADIO_DATA_LOW);
buf : 			b43_write16(dev, B43_MMIO_RADIO_CONTROL,
buf : 				    B43_RADIOCTL_ID);
buf : 			tmp |= (u32)b43_read16(dev, B43_MMIO_RADIO_DATA_HIGH)
buf : 				<< 16;
buf : 		}
buf : 		radio_manuf = (tmp & 0x00000FFF);
buf : 		radio_ver = (tmp & 0x0FFFF000) >> 12;
buf : 		radio_rev = (tmp & 0xF0000000) >> 28;
buf : 	}
buf : 
buf : 	if (radio_manuf != 0x17F /* Broadcom */)
if (radio_manuf != 0x17F /* Broadcom */) 
buf : 		unsupported = 1;
buf : 	switch (phy_type) {
buf : 	case B43_PHYTYPE_A:
buf : 		if (radio_ver != 0x2060)
if (radio_ver != 0x2060) 
buf : 			unsupported = 1;
buf : 		if (radio_rev != 1)
if (radio_rev != 1) 
buf : 			unsupported = 1;
buf : 		if (radio_manuf != 0x17F)
if (radio_manuf != 0x17F) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43_PHYTYPE_B:
buf : 		if ((radio_ver & 0xFFF0) != 0x2050)
if ((radio_ver & 0xFFF0) != 0x2050) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43_PHYTYPE_G:
buf : 		if (radio_ver != 0x2050)
if (radio_ver != 0x2050) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43_PHYTYPE_N:
buf : 		if (radio_ver != 0x2055 && radio_ver != 0x2056)
if (radio_ver != 0x2055 && radio_ver != 0x2056) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43_PHYTYPE_LP:
buf : 		if (radio_ver != 0x2062 && radio_ver != 0x2063)
if (radio_ver != 0x2062 && radio_ver != 0x2063) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43_PHYTYPE_HT:
buf : 		if (radio_ver != 0x2059)
if (radio_ver != 0x2059) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	case B43_PHYTYPE_LCN:
buf : 		if (radio_ver != 0x2064)
if (radio_ver != 0x2064) 
buf : 			unsupported = 1;
buf : 		break;
buf : 	default:
buf : 		B43_WARN_ON(1);
buf : 	}
buf : 	if (unsupported) {
if (unsupported) { 
buf : 		b43err(dev->wl, "FOUND UNSUPPORTED RADIO "
buf : 		       "(Manuf 0x%X, Version 0x%X, Revision %u)\n",
buf : 		       radio_manuf, radio_ver, radio_rev);
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 	b43dbg(dev->wl, "Found Radio: Manuf 0x%X, Version 0x%X, Revision %u\n",
buf : 	       radio_manuf, radio_ver, radio_rev);
buf : 
buf : 	phy->radio_manuf = radio_manuf;
buf : 	phy->radio_ver = radio_ver;
buf : 	phy->radio_rev = radio_rev;
buf : 
buf : 	phy->analog = analog_type;
buf : 	phy->type = phy_type;
buf : 	phy->rev = phy_rev;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void setup_struct_phy_for_init(struct b43_wldev *dev,
for_init(struct b43_wldev *dev, 
buf : 				      struct b43_phy *phy)
buf : {
buf : 	phy->hardware_power_control = !!modparam_hwpctl;
buf : 	phy->next_txpwr_check_time = jiffies;
iffies; 
buf : 	/* PHY TX errors counter. */
buf : 	atomic_set(&phy->txerr_cnt, B43_PHY_TX_BADNESS_LIMIT);
buf : 
buf : #if B43_DEBUG
if B43_DEBUG 
buf : 	phy->phy_locked = false;
buf : 	phy->radio_locked = false;
buf : #endif
if 
buf : }
buf : 
buf : static void setup_struct_wldev_for_init(struct b43_wldev *dev)
for_init(struct b43_wldev *dev) 
buf : {
buf : 	dev->dfq_valid = false;
buf : 
buf : 	/* Assume the radio is enabled. If it's not enabled, the state will
buf : 	 * immediately get fixed on the first periodic work run. */
buf : 	dev->radio_hw_enable = true;
buf : 
buf : 	/* Stats */
buf : 	memset(&dev->stats, 0, sizeof(dev->stats));
buf : 
buf : 	setup_struct_phy_for_init(dev, &dev->phy);
for_init(dev, &dev->phy); 
buf : 
buf : 	/* IRQ related flags */
buf : 	dev->irq_reason = 0;
buf : 	memset(dev->dma_reason, 0, sizeof(dev->dma_reason));
buf : 	dev->irq_mask = B43_IRQ_MASKTEMPLATE;
buf : 	if (b43_modparam_verbose < B43_VERBOSITY_DEBUG)
if (b43_modparam_verbose < B43_VERBOSITY_DEBUG) 
buf : 		dev->irq_mask &= ~B43_IRQ_PHY_TXERR;
buf : 
buf : 	dev->mac_suspended = 1;
buf : 
buf : 	/* Noise calculation context */
buf : 	memset(&dev->noisecalc, 0, sizeof(dev->noisecalc));
buf : }
buf : 
buf : static void b43_bluetooth_coext_enable(struct b43_wldev *dev)
buf : {
buf : 	struct ssb_sprom *sprom = dev->dev->bus_sprom;
buf : 	u64 hf;
buf : 
buf : 	if (!modparam_btcoex)
if (!modparam_btcoex) 
buf : 		return;
buf : 	if (!(sprom->boardflags_lo & B43_BFL_BTCOEXIST))
if (!(sprom->boardflags_lo & B43_BFL_BTCOEXIST)) 
buf : 		return;
buf : 	if (dev->phy.type != B43_PHYTYPE_B && !dev->phy.gmode)
if (dev->phy.type != B43_PHYTYPE_B && !dev->phy.gmode) 
buf : 		return;
buf : 
buf : 	hf = b43_hf_read(dev);
buf : 	if (sprom->boardflags_lo & B43_BFL_BTCMOD)
if (sprom->boardflags_lo & B43_BFL_BTCMOD) 
buf : 		hf |= B43_HF_BTCOEXALT;
buf : 	else
buf : 		hf |= B43_HF_BTCOEX;
buf : 	b43_hf_write(dev, hf);
buf : }
buf : 
buf : static void b43_bluetooth_coext_disable(struct b43_wldev *dev)
buf : {
buf : 	if (!modparam_btcoex)
if (!modparam_btcoex) 
buf : 		return;
buf : 	//TODO
buf : }
buf : 
buf : static void b43_imcfglo_timeouts_workaround(struct b43_wldev *dev)
buf : {
buf : 	struct ssb_bus *bus;
buf : 	u32 tmp;
buf : 
buf : #ifdef CONFIG_B43_SSB
ifdef CONFIG_B43_SSB 
buf : 	if (dev->dev->bus_type != B43_BUS_SSB)
buf : 		return;
buf : #else
buf : 	return;
buf : #endif
if 
buf : 
buf : 	bus = dev->dev->sdev->bus;
buf : 
buf : 	if ((bus->chip_id == 0x4311 && bus->chip_rev == 2) ||
if ((bus->chip_id == 0x4311 && bus->chip_rev == 2) || 
buf : 	    (bus->chip_id == 0x4312)) {
buf : 		tmp = ssb_read32(dev->dev->sdev, SSB_IMCFGLO);
buf : 		tmp &= ~SSB_IMCFGLO_REQTO;
buf : 		tmp &= ~SSB_IMCFGLO_SERTO;
buf : 		tmp |= 0x3;
buf : 		ssb_write32(dev->dev->sdev, SSB_IMCFGLO, tmp);
buf : 		ssb_commit_settings(bus);
buf : 	}
buf : }
buf : 
buf : static void b43_set_synth_pu_delay(struct b43_wldev *dev, bool idle)
buf : {
buf : 	u16 pu_delay;
buf : 
buf : 	/* The time value is in microseconds. */
buf : 	if (dev->phy.type == B43_PHYTYPE_A)
if (dev->phy.type == B43_PHYTYPE_A) 
buf : 		pu_delay = 3700;
buf : 	else
buf : 		pu_delay = 1050;
buf : 	if (b43_is_mode(dev->wl, NL80211_IFTYPE_ADHOC) || idle)
if (b43_is_mode(dev->wl, NL80211_IFTYPE_ADHOC) || idle) 
buf : 		pu_delay = 500;
buf : 	if ((dev->phy.radio_ver == 0x2050) && (dev->phy.radio_rev == 8))
if ((dev->phy.radio_ver == 0x2050) && (dev->phy.radio_rev == 8)) 
buf : 		pu_delay = max(pu_delay, (u16)2400);
buf : 
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_SPUWKUP, pu_delay);
buf : }
buf : 
buf : /* Set the TSF CFP pre-TargetBeaconTransmissionTime. */
buf : static void b43_set_pretbtt(struct b43_wldev *dev)
buf : {
buf : 	u16 pretbtt;
buf : 
buf : 	/* The time value is in microseconds. */
buf : 	if (b43_is_mode(dev->wl, NL80211_IFTYPE_ADHOC)) {
if (b43_is_mode(dev->wl, NL80211_IFTYPE_ADHOC)) { 
buf : 		pretbtt = 2;
buf : 	} else {
buf : 		if (dev->phy.type == B43_PHYTYPE_A)
if (dev->phy.type == B43_PHYTYPE_A) 
buf : 			pretbtt = 120;
buf : 		else
buf : 			pretbtt = 250;
buf : 	}
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_PRETBTT, pretbtt);
buf : 	b43_write16(dev, B43_MMIO_TSF_CFP_PRETBTT, pretbtt);
buf : }
buf : 
buf : /* Shutdown a wireless core */
buf : /* Locking: wl->mutex */
buf : static void b43_wireless_core_exit(struct b43_wldev *dev)
buf : {
buf : 	B43_WARN_ON(dev && b43_status(dev) > B43_STAT_INITIALIZED);
buf : 	if (!dev || b43_status(dev) != B43_STAT_INITIALIZED)
if (!dev || b43_status(dev) != B43_STAT_INITIALIZED) 
buf : 		return;
buf : 
buf : 	b43_set_status(dev, B43_STAT_UNINIT);
buf : 
buf : 	/* Stop the microcode PSM. */
buf : 	b43_maskset32(dev, B43_MMIO_MACCTL, ~B43_MACCTL_PSM_RUN,
buf : 		      B43_MACCTL_PSM_JMP0);
buf : 
buf : 	switch (dev->dev->bus_type) {
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	case B43_BUS_BCMA:
buf : 		bcma_core_pci_down(dev->dev->bdev->bus);
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	case B43_BUS_SSB:
buf : 		/* TODO */
buf : 		break;
buf : #endif
if 
buf : 	}
buf : 
buf : 	b43_dma_free(dev);
buf : 	b43_pio_free(dev);
buf : 	b43_chip_exit(dev);
buf : 	dev->phy.ops->switch_analog(dev, 0);
buf : 	if (dev->wl->current_beacon) {
if (dev->wl->current_beacon) { 
buf : 		dev_kfree_skb_any(dev->wl->current_beacon);
buf : 		dev->wl->current_beacon = NULL;
buf : 	}
buf : 
buf : 	b43_device_disable(dev, 0);
buf : 	b43_bus_may_powerdown(dev);
buf : }
buf : 
buf : /* Initialize a wireless core */
buf : static int b43_wireless_core_init(struct b43_wldev *dev)
buf : {
buf : 	struct ssb_sprom *sprom = dev->dev->bus_sprom;
buf : 	struct b43_phy *phy = &dev->phy;
buf : 	int err;
buf : 	u64 hf;
buf : 
buf : 	B43_WARN_ON(b43_status(dev) != B43_STAT_UNINIT);
buf : 
buf : 	err = b43_bus_powerup(dev, 0);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 	if (!b43_device_is_enabled(dev))
if (!b43_device_is_enabled(dev)) 
buf : 		b43_wireless_core_reset(dev, phy->gmode);
buf : 
buf : 	/* Reset all data structures. */
buf : 	setup_struct_wldev_for_init(dev);
for_init(dev); 
buf : 	phy->ops->prepare_structs(dev);
buf : 
buf : 	/* Enable IRQ routing to this device. */
buf : 	switch (dev->dev->bus_type) {
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	case B43_BUS_BCMA:
buf : 		bcma_core_pci_irq_ctl(&dev->dev->bdev->bus->drv_pci[0],
buf : 				      dev->dev->bdev, true);
buf : 		bcma_core_pci_up(dev->dev->bdev->bus);
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	case B43_BUS_SSB:
buf : 		ssb_pcicore_dev_irqvecs_enable(&dev->dev->sdev->bus->pcicore,
buf : 					       dev->dev->sdev);
buf : 		break;
buf : #endif
if 
buf : 	}
buf : 
buf : 	b43_imcfglo_timeouts_workaround(dev);
buf : 	b43_bluetooth_coext_disable(dev);
buf : 	if (phy->ops->prepare_hardware) {
if (phy->ops->prepare_hardware) { 
buf : 		err = phy->ops->prepare_hardware(dev);
buf : 		if (err)
if (err) 
buf : 			goto err_busdown;
buf : 	}
buf : 	err = b43_chip_init(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_busdown;
buf : 	b43_shm_write16(dev, B43_SHM_SHARED,
buf : 			B43_SHM_SH_WLCOREREV, dev->dev->core_rev);
buf : 	hf = b43_hf_read(dev);
buf : 	if (phy->type == B43_PHYTYPE_G) {
if (phy->type == B43_PHYTYPE_G) { 
buf : 		hf |= B43_HF_SYMW;
buf : 		if (phy->rev == 1)
if (phy->rev == 1) 
buf : 			hf |= B43_HF_GDCW;
buf : 		if (sprom->boardflags_lo & B43_BFL_PACTRL)
if (sprom->boardflags_lo & B43_BFL_PACTRL) 
buf : 			hf |= B43_HF_OFDMPABOOST;
buf : 	}
buf : 	if (phy->radio_ver == 0x2050) {
if (phy->radio_ver == 0x2050) { 
buf : 		if (phy->radio_rev == 6)
buf : 			hf |= B43_HF_4318TSSI;
buf : 		if (phy->radio_rev < 6)
if (phy->radio_rev < 6) 
buf : 			hf |= B43_HF_VCORECALC;
buf : 	}
buf : 	if (sprom->boardflags_lo & B43_BFL_XTAL_NOSLOW)
if (sprom->boardflags_lo & B43_BFL_XTAL_NOSLOW) 
buf : 		hf |= B43_HF_DSCRQ; /* Disable slowclock requests from ucode. */
buf : #if defined(CONFIG_B43_SSB) && defined(CONFIG_SSB_DRIVER_PCICORE)
if defined(CONFIG_B43_SSB) && defined(CONFIG_SSB_DRIVER_PCICORE) 
buf : 	if (dev->dev->bus_type == B43_BUS_SSB &&
buf : 	    dev->dev->sdev->bus->bustype == SSB_BUSTYPE_PCI &&
buf : 	    dev->dev->sdev->bus->pcicore.dev->id.revision <= 10)
buf : 		hf |= B43_HF_PCISCW; /* PCI slow clock workaround. */
buf : #endif
if 
buf : 	hf &= ~B43_HF_SKCFPUP;
buf : 	b43_hf_write(dev, hf);
buf : 
buf : 	b43_set_retry_limits(dev, B43_DEFAULT_SHORT_RETRY_LIMIT,
buf : 			     B43_DEFAULT_LONG_RETRY_LIMIT);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_SFFBLIM, 3);
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_LFFBLIM, 2);
buf : 
buf : 	/* Disable sending probe responses from firmware.
buf : 	 * Setting the MaxTime to one usec will always trigger
buf : 	 * a timeout, so we never send any probe resp.
buf : 	 * A timeout of zero is infinite. */
buf : 	b43_shm_write16(dev, B43_SHM_SHARED, B43_SHM_SH_PRMAXTIME, 1);
buf : 
buf : 	b43_rate_memory_init(dev);
buf : 	b43_set_phytxctl_defaults(dev);
buf : 
buf : 	/* Minimum Contention Window */
buf : 	if (phy->type == B43_PHYTYPE_B)
if (phy->type == B43_PHYTYPE_B) 
buf : 		b43_shm_write16(dev, B43_SHM_SCRATCH, B43_SHM_SC_MINCONT, 0x1F);
buf : 	else
buf : 		b43_shm_write16(dev, B43_SHM_SCRATCH, B43_SHM_SC_MINCONT, 0xF);
buf : 	/* Maximum Contention Window */
buf : 	b43_shm_write16(dev, B43_SHM_SCRATCH, B43_SHM_SC_MAXCONT, 0x3FF);
buf : 
buf : 	if (b43_bus_host_is_pcmcia(dev->dev) ||
if (b43_bus_host_is_pcmcia(dev->dev) || 
buf : 	    b43_bus_host_is_sdio(dev->dev)) {
buf : 		dev->__using_pio_transfers = true;
buf : 		err = b43_pio_init(dev);
buf : 	} else if (dev->use_pio) {
if (dev->use_pio) { 
buf : 		b43warn(dev->wl, "Forced PIO by use_pio module parameter. "
buf : 			"This should not be needed and will result in lower "
buf : 			"performance.\n");
formance.\n"); 
buf : 		dev->__using_pio_transfers = true;
buf : 		err = b43_pio_init(dev);
buf : 	} else {
buf : 		dev->__using_pio_transfers = false;
buf : 		err = b43_dma_init(dev);
buf : 	}
buf : 	if (err)
if (err) 
buf : 		goto err_chip_exit;
buf : 	b43_qos_init(dev);
buf : 	b43_set_synth_pu_delay(dev, 1);
buf : 	b43_bluetooth_coext_enable(dev);
buf : 
buf : 	b43_bus_powerup(dev, !(sprom->boardflags_lo & B43_BFL_XTAL_NOSLOW));
buf : 	b43_upload_card_macaddress(dev);
buf : 	b43_security_init(dev);
buf : 
buf : 	ieee80211_wake_queues(dev->wl->hw);
buf : 
buf : 	b43_set_status(dev, B43_STAT_INITIALIZED);
buf : 
buf : out:
buf : 	return err;
buf : 
buf : err_chip_exit:
buf : 	b43_chip_exit(dev);
buf : err_busdown:
buf : 	b43_bus_may_powerdown(dev);
buf : 	B43_WARN_ON(b43_status(dev) != B43_STAT_UNINIT);
buf : 	return err;
buf : }
buf : 
buf : static int b43_op_add_interface(struct ieee80211_hw *hw,
buf : 				struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 	int err = -EOPNOTSUPP;
buf : 
buf : 	/* TODO: allow WDS/AP devices to coexist */
buf : 
buf : 	if (vif->type != NL80211_IFTYPE_AP &&
if (vif->type != NL80211_IFTYPE_AP && 
buf : 	    vif->type != NL80211_IFTYPE_MESH_POINT &&
buf : 	    vif->type != NL80211_IFTYPE_STATION &&
if->type != NL80211_IFTYPE_STATION && 
buf : 	    vif->type != NL80211_IFTYPE_WDS &&
buf : 	    vif->type != NL80211_IFTYPE_ADHOC)
if->type != NL80211_IFTYPE_ADHOC) 
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	if (wl->operating)
if (wl->operating) 
buf : 		goto out_mutex_unlock;
buf : 
buf : 	b43dbg(wl, "Adding Interface type %d\n", vif->type);
if->type); 
buf : 
buf : 	dev = wl->current_dev;
buf : 	wl->operating = true;
buf : 	wl->vif = vif;
if = vif; 
buf : 	wl->if_type = vif->type;
buf : 	memcpy(wl->mac_addr, vif->addr, ETH_ALEN);
if->addr, ETH_ALEN); 
buf : 
buf : 	b43_adjust_opmode(dev);
buf : 	b43_set_pretbtt(dev);
buf : 	b43_set_synth_pu_delay(dev, 0);
buf : 	b43_upload_card_macaddress(dev);
buf : 
buf : 	err = 0;
buf :  out_mutex_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	if (err == 0)
if (err == 0) 
buf : 		b43_op_bss_info_changed(hw, vif, &vif->bss_conf, ~0);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void b43_op_remove_interface(struct ieee80211_hw *hw,
buf : 				    struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev = wl->current_dev;
buf : 
buf : 	b43dbg(wl, "Removing Interface type %d\n", vif->type);
if->type); 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	B43_WARN_ON(!wl->operating);
buf : 	B43_WARN_ON(wl->vif != vif);
if != vif); 
buf : 	wl->vif = NULL;
buf : 
buf : 	wl->operating = false;
buf : 
buf : 	b43_adjust_opmode(dev);
buf : 	memset(wl->mac_addr, 0, ETH_ALEN);
buf : 	b43_upload_card_macaddress(dev);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int b43_op_start(struct ieee80211_hw *hw)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev = wl->current_dev;
buf : 	int did_init = 0;
buf : 	int err = 0;
buf : 
buf : 	/* Kill all old instance specific information to make sure
ific information to make sure 
buf : 	 * the card won't use it in the short timeframe between start
buf : 	 * and mac80211 reconfiguring it. */
buf : 	memset(wl->bssid, 0, ETH_ALEN);
buf : 	memset(wl->mac_addr, 0, ETH_ALEN);
buf : 	wl->filter_flags = 0;
buf : 	wl->radiotap_enabled = false;
buf : 	b43_qos_clear(wl);
buf : 	wl->beacon0_uploaded = false;
buf : 	wl->beacon1_uploaded = false;
buf : 	wl->beacon_templates_virgin = true;
buf : 	wl->radio_enabled = true;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (b43_status(dev) < B43_STAT_INITIALIZED) {
if (b43_status(dev) < B43_STAT_INITIALIZED) { 
buf : 		err = b43_wireless_core_init(dev);
buf : 		if (err)
if (err) 
buf : 			goto out_mutex_unlock;
buf : 		did_init = 1;
buf : 	}
buf : 
buf : 	if (b43_status(dev) < B43_STAT_STARTED) {
if (b43_status(dev) < B43_STAT_STARTED) { 
buf : 		err = b43_wireless_core_start(dev);
buf : 		if (err) {
if (err) { 
buf : 			if (did_init)
buf : 				b43_wireless_core_exit(dev);
buf : 			goto out_mutex_unlock;
buf : 		}
buf : 	}
buf : 
buf : 	/* XXX: only do if device doesn't support rfkill irq */
if device doesn't support rfkill irq */ 
buf : 	wiphy_rfkill_start_polling(hw->wiphy);
buf : 
buf :  out_mutex_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	/*
buf : 	 * Configuration may have been overwritten during initialization.
buf : 	 * Reload the configuration, but only if initialization was
if initialization was 
buf : 	 * successful. Reloading the configuration after a failed init
buf : 	 * may hang the system.
buf : 	 */
buf : 	if (!err)
if (!err) 
buf : 		b43_op_config(hw, ~0);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void b43_op_stop(struct ieee80211_hw *hw)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev = wl->current_dev;
buf : 
buf : 	cancel_work_sync(&(wl->beacon_update_trigger));
buf : 
buf : 	if (!dev)
if (!dev) 
buf : 		goto out;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	if (b43_status(dev) >= B43_STAT_STARTED) {
if (b43_status(dev) >= B43_STAT_STARTED) { 
buf : 		dev = b43_wireless_core_stop(dev);
buf : 		if (!dev)
if (!dev) 
buf : 			goto out_unlock;
buf : 	}
buf : 	b43_wireless_core_exit(dev);
buf : 	wl->radio_enabled = false;
buf : 
buf : out_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : out:
buf : 	cancel_work_sync(&(wl->txpower_adjust_work));
buf : }
buf : 
buf : static int b43_op_beacon_set_tim(struct ieee80211_hw *hw,
buf : 				 struct ieee80211_sta *sta, bool set)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 
buf : 	/* FIXME: add locking */
buf : 	b43_update_templates(wl);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void b43_op_sta_notify(struct ieee80211_hw *hw,
ify(struct ieee80211_hw *hw, 
buf : 			      struct ieee80211_vif *vif,
buf : 			      enum sta_notify_cmd notify_cmd,
ify_cmd notify_cmd, 
buf : 			      struct ieee80211_sta *sta)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 
buf : 	B43_WARN_ON(!vif || wl->vif != vif);
if || wl->vif != vif); 
buf : }
buf : 
buf : static void b43_op_sw_scan_start_notifier(struct ieee80211_hw *hw)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (dev && (b43_status(dev) >= B43_STAT_INITIALIZED)) {
if (dev && (b43_status(dev) >= B43_STAT_INITIALIZED)) { 
buf : 		/* Disable CFP update during scan on other channels. */
buf : 		b43_hf_write(dev, b43_hf_read(dev) | B43_HF_SKCFPUP);
buf : 	}
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void b43_op_sw_scan_complete_notifier(struct ieee80211_hw *hw)
ifier(struct ieee80211_hw *hw) 
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	dev = wl->current_dev;
buf : 	if (dev && (b43_status(dev) >= B43_STAT_INITIALIZED)) {
if (dev && (b43_status(dev) >= B43_STAT_INITIALIZED)) { 
buf : 		/* Re-enable CFP update. */
buf : 		b43_hf_write(dev, b43_hf_read(dev) & ~B43_HF_SKCFPUP);
buf : 	}
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int b43_op_get_survey(struct ieee80211_hw *hw, int idx,
buf : 			     struct survey_info *survey)
buf : {
buf : 	struct b43_wl *wl = hw_to_b43_wl(hw);
buf : 	struct b43_wldev *dev = wl->current_dev;
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 
buf : 	if (idx != 0)
if (idx != 0) 
buf : 		return -ENOENT;
buf : 
buf : 	survey->channel = conf->chandef.chan;
buf : 	survey->filled = SURVEY_INFO_NOISE_DBM;
buf : 	survey->noise = dev->stats.link_noise;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static const struct ieee80211_ops b43_hw_ops = {
buf : 	.tx			= b43_op_tx,
buf : 	.conf_tx		= b43_op_conf_tx,
buf : 	.add_interface		= b43_op_add_interface,
buf : 	.remove_interface	= b43_op_remove_interface,
buf : 	.config			= b43_op_config,
buf : 	.bss_info_changed	= b43_op_bss_info_changed,
buf : 	.configure_filter	= b43_op_configure_filter,
buf : 	.set_key		= b43_op_set_key,
buf : 	.update_tkip_key	= b43_op_update_tkip_key,
buf : 	.get_stats		= b43_op_get_stats,
buf : 	.get_tsf		= b43_op_get_tsf,
buf : 	.set_tsf		= b43_op_set_tsf,
buf : 	.start			= b43_op_start,
buf : 	.stop			= b43_op_stop,
buf : 	.set_tim		= b43_op_beacon_set_tim,
buf : 	.sta_notify		= b43_op_sta_notify,
ify		= b43_op_sta_notify, 
buf : 	.sw_scan_start		= b43_op_sw_scan_start_notifier,
buf : 	.sw_scan_complete	= b43_op_sw_scan_complete_notifier,
ifier, 
buf : 	.get_survey		= b43_op_get_survey,
buf : 	.rfkill_poll		= b43_rfkill_poll,
buf : };
buf : 
buf : /* Hard-reset the chip. Do not call this directly.
buf :  * Use b43_controller_restart()
buf :  */
buf : static void b43_chip_reset(struct work_struct *work)
buf : {
buf : 	struct b43_wldev *dev =
buf : 	    container_of(work, struct b43_wldev, restart_work);
buf : 	struct b43_wl *wl = dev->wl;
buf : 	int err = 0;
buf : 	int prev_status;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	prev_status = b43_status(dev);
buf : 	/* Bring the device down... */
buf : 	if (prev_status >= B43_STAT_STARTED) {
if (prev_status >= B43_STAT_STARTED) { 
buf : 		dev = b43_wireless_core_stop(dev);
buf : 		if (!dev) {
if (!dev) { 
buf : 			err = -ENODEV;
buf : 			goto out;
buf : 		}
buf : 	}
buf : 	if (prev_status >= B43_STAT_INITIALIZED)
if (prev_status >= B43_STAT_INITIALIZED) 
buf : 		b43_wireless_core_exit(dev);
buf : 
buf : 	/* ...and up again. */
buf : 	if (prev_status >= B43_STAT_INITIALIZED) {
if (prev_status >= B43_STAT_INITIALIZED) { 
buf : 		err = b43_wireless_core_init(dev);
buf : 		if (err)
if (err) 
buf : 			goto out;
buf : 	}
buf : 	if (prev_status >= B43_STAT_STARTED) {
if (prev_status >= B43_STAT_STARTED) { 
buf : 		err = b43_wireless_core_start(dev);
buf : 		if (err) {
if (err) { 
buf : 			b43_wireless_core_exit(dev);
buf : 			goto out;
buf : 		}
buf : 	}
buf : out:
buf : 	if (err)
if (err) 
buf : 		wl->current_dev = NULL; /* Failed to init the dev. */
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	if (err) {
if (err) { 
buf : 		b43err(wl, "Controller restart FAILED\n");
buf : 		return;
buf : 	}
buf : 
buf : 	/* reload configuration */
buf : 	b43_op_config(wl->hw, ~0);
buf : 	if (wl->vif)
if (wl->vif) 
buf : 		b43_op_bss_info_changed(wl->hw, wl->vif, &wl->vif->bss_conf, ~0);
buf : 
buf : 	b43info(wl, "Controller restarted\n");
buf : }
buf : 
buf : static int b43_setup_bands(struct b43_wldev *dev,
buf : 			   bool have_2ghz_phy, bool have_5ghz_phy)
buf : {
buf : 	struct ieee80211_hw *hw = dev->wl->hw;
buf : 
buf : 	if (have_2ghz_phy)
if (have_2ghz_phy) 
buf : 		hw->wiphy->bands[IEEE80211_BAND_2GHZ] = &b43_band_2GHz;
buf : 	if (dev->phy.type == B43_PHYTYPE_N) {
if (dev->phy.type == B43_PHYTYPE_N) { 
buf : 		if (have_5ghz_phy)
buf : 			hw->wiphy->bands[IEEE80211_BAND_5GHZ] = &b43_band_5GHz_nphy;
buf : 	} else {
buf : 		if (have_5ghz_phy)
if (have_5ghz_phy) 
buf : 			hw->wiphy->bands[IEEE80211_BAND_5GHZ] = &b43_band_5GHz_aphy;
buf : 	}
buf : 
buf : 	dev->phy.supports_2ghz = have_2ghz_phy;
buf : 	dev->phy.supports_5ghz = have_5ghz_phy;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void b43_wireless_core_detach(struct b43_wldev *dev)
buf : {
buf : 	/* We release firmware that late to not be required to re-request
buf : 	 * is all the time when we reinit the core. */
buf : 	b43_release_firmware(dev);
buf : 	b43_phy_free(dev);
buf : }
buf : 
buf : static void b43_supported_bands(struct b43_wldev *dev, bool *have_2ghz_phy,
buf : 				bool *have_5ghz_phy)
buf : {
buf : 	u16 dev_id = 0;
buf : 
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	if (dev->dev->bus_type == B43_BUS_BCMA &&
buf : 	    dev->dev->bdev->bus->hosttype == BCMA_HOSTTYPE_PCI)
buf : 		dev_id = dev->dev->bdev->bus->host_pci->device;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	if (dev->dev->bus_type == B43_BUS_SSB &&
if (dev->dev->bus_type == B43_BUS_SSB && 
buf : 	    dev->dev->sdev->bus->bustype == SSB_BUSTYPE_PCI)
buf : 		dev_id = dev->dev->sdev->bus->host_pci->device;
buf : #endif
if 
buf : 	/* Override with SPROM value if available */
buf : 	if (dev->dev->bus_sprom->dev_id)
if (dev->dev->bus_sprom->dev_id) 
buf : 		dev_id = dev->dev->bus_sprom->dev_id;
buf : 
buf : 	/* Note: below IDs can be "virtual" (not maching e.g. real PCI ID) */
buf : 	switch (dev_id) {
buf : 	case 0x4324: /* BCM4306 */
buf : 	case 0x4312: /* BCM4311 */
buf : 	case 0x4319: /* BCM4318 */
buf : 	case 0x4328: /* BCM4321 */
buf : 	case 0x432b: /* BCM4322 */
buf : 	case 0x4350: /* BCM43222 */
buf : 	case 0x4353: /* BCM43224 */
buf : 	case 0x0576: /* BCM43224 */
buf : 	case 0x435f: /* BCM6362 */
buf : 	case 0x4331: /* BCM4331 */
buf : 	case 0x4359: /* BCM43228 */
buf : 	case 0x43a0: /* BCM4360 */
buf : 	case 0x43b1: /* BCM4352 */
buf : 		/* Dual band devices */
buf : 		*have_2ghz_phy = true;
buf : 		*have_5ghz_phy = true;
buf : 		return;
buf : 	case 0x4321: /* BCM4306 */
buf : 	case 0x4313: /* BCM4311 */
buf : 	case 0x431a: /* BCM4318 */
buf : 	case 0x432a: /* BCM4321 */
buf : 	case 0x432d: /* BCM4322 */
buf : 	case 0x4352: /* BCM43222 */
buf : 	case 0x4333: /* BCM4331 */
buf : 	case 0x43a2: /* BCM4360 */
buf : 	case 0x43b3: /* BCM4352 */
buf : 		/* 5 GHz only devices */
buf : 		*have_2ghz_phy = false;
buf : 		*have_5ghz_phy = true;
buf : 		return;
buf : 	}
buf : 
buf : 	/* As a fallback, try to guess using PHY type */
buf : 	switch (dev->phy.type) {
buf : 	case B43_PHYTYPE_A:
buf : 		*have_2ghz_phy = false;
buf : 		*have_5ghz_phy = true;
buf : 		return;
buf : 	case B43_PHYTYPE_G:
buf : 	case B43_PHYTYPE_N:
buf : 	case B43_PHYTYPE_LP:
buf : 	case B43_PHYTYPE_HT:
buf : 	case B43_PHYTYPE_LCN:
buf : 		*have_2ghz_phy = true;
buf : 		*have_5ghz_phy = false;
buf : 		return;
buf : 	}
buf : 
buf : 	B43_WARN_ON(1);
buf : }
buf : 
buf : static int b43_wireless_core_attach(struct b43_wldev *dev)
buf : {
buf : 	struct b43_wl *wl = dev->wl;
buf : 	struct b43_phy *phy = &dev->phy;
buf : 	int err;
buf : 	u32 tmp;
buf : 	bool have_2ghz_phy = false, have_5ghz_phy = false;
buf : 
buf : 	/* Do NOT do any device initialization here.
buf : 	 * Do it in wireless_core_init() instead.
buf : 	 * This function is for gathering basic information about the HW, only.
for gathering basic information about the HW, only. 
buf : 	 * Also some structs may be set up here. But most likely you want to have
buf : 	 * that in core_init(), too.
buf : 	 */
buf : 
buf : 	err = b43_bus_powerup(dev, 0);
buf : 	if (err) {
if (err) { 
buf : 		b43err(wl, "Bus powerup failed\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	phy->do_full_init = true;
buf : 
buf : 	/* Try to guess supported bands for the first init needs */
for the first init needs */ 
buf : 	switch (dev->dev->bus_type) {
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	case B43_BUS_BCMA:
buf : 		tmp = bcma_aread32(dev->dev->bdev, BCMA_IOST);
buf : 		have_2ghz_phy = !!(tmp & B43_BCMA_IOST_2G_PHY);
buf : 		have_5ghz_phy = !!(tmp & B43_BCMA_IOST_5G_PHY);
buf : 		break;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	case B43_BUS_SSB:
buf : 		if (dev->dev->core_rev >= 5) {
if (dev->dev->core_rev >= 5) { 
buf : 			tmp = ssb_read32(dev->dev->sdev, SSB_TMSHIGH);
buf : 			have_2ghz_phy = !!(tmp & B43_TMSHIGH_HAVE_2GHZ_PHY);
buf : 			have_5ghz_phy = !!(tmp & B43_TMSHIGH_HAVE_5GHZ_PHY);
buf : 		} else
buf : 			B43_WARN_ON(1);
buf : 		break;
buf : #endif
if 
buf : 	}
buf : 
buf : 	dev->phy.gmode = have_2ghz_phy;
buf : 	b43_wireless_core_reset(dev, dev->phy.gmode);
buf : 
buf : 	/* Get the PHY type. */
buf : 	err = b43_phy_versioning(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_powerdown;
buf : 
buf : 	/* Get real info about supported bands */
buf : 	b43_supported_bands(dev, &have_2ghz_phy, &have_5ghz_phy);
buf : 
buf : 	/* We don't support 5 GHz on some PHYs yet */
buf : 	switch (dev->phy.type) {
buf : 	case B43_PHYTYPE_A:
buf : 	case B43_PHYTYPE_G:
buf : 	case B43_PHYTYPE_N:
buf : 	case B43_PHYTYPE_LP:
buf : 	case B43_PHYTYPE_HT:
buf : 		b43warn(wl, "5 GHz band is unsupported on this PHY\n");
buf : 		have_5ghz_phy = false;
buf : 	}
buf : 
buf : 	if (!have_2ghz_phy && !have_5ghz_phy) {
if (!have_2ghz_phy && !have_5ghz_phy) { 
buf : 		b43err(wl, "b43 can't support any band on this device\n");
buf : 		err = -EOPNOTSUPP;
buf : 		goto err_powerdown;
buf : 	}
buf : 
buf : 	err = b43_phy_allocate(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_powerdown;
buf : 
buf : 	dev->phy.gmode = have_2ghz_phy;
buf : 	b43_wireless_core_reset(dev, dev->phy.gmode);
buf : 
buf : 	err = b43_validate_chipaccess(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_phy_free;
buf : 	err = b43_setup_bands(dev, have_2ghz_phy, have_5ghz_phy);
buf : 	if (err)
if (err) 
buf : 		goto err_phy_free;
buf : 
buf : 	/* Now set some default "current_dev" */
buf : 	if (!wl->current_dev)
if (!wl->current_dev) 
buf : 		wl->current_dev = dev;
buf : 	INIT_WORK(&dev->restart_work, b43_chip_reset);
buf : 
buf : 	dev->phy.ops->switch_analog(dev, 0);
buf : 	b43_device_disable(dev, 0);
buf : 	b43_bus_may_powerdown(dev);
buf : 
buf : out:
buf : 	return err;
buf : 
buf : err_phy_free:
buf : 	b43_phy_free(dev);
buf : err_powerdown:
buf : 	b43_bus_may_powerdown(dev);
buf : 	return err;
buf : }
buf : 
buf : static void b43_one_core_detach(struct b43_bus_dev *dev)
buf : {
buf : 	struct b43_wldev *wldev;
buf : 	struct b43_wl *wl;
buf : 
buf : 	/* Do not cancel ieee80211-workqueue based work here.
buf : 	 * See comment in b43_remove(). */
buf : 
buf : 	wldev = b43_bus_get_wldev(dev);
buf : 	wl = wldev->wl;
buf : 	b43_debugfs_remove_device(wldev);
buf : 	b43_wireless_core_detach(wldev);
buf : 	list_del(&wldev->list);
buf : 	b43_bus_set_wldev(dev, NULL);
buf : 	kfree(wldev);
buf : }
buf : 
buf : static int b43_one_core_attach(struct b43_bus_dev *dev, struct b43_wl *wl)
buf : {
buf : 	struct b43_wldev *wldev;
buf : 	int err = -ENOMEM;
buf : 
buf : 	wldev = kzalloc(sizeof(*wldev), GFP_KERNEL);
buf : 	if (!wldev)
if (!wldev) 
buf : 		goto out;
buf : 
buf : 	wldev->use_pio = b43_modparam_pio;
buf : 	wldev->dev = dev;
buf : 	wldev->wl = wl;
buf : 	b43_set_status(wldev, B43_STAT_UNINIT);
buf : 	wldev->bad_frames_preempt = modparam_bad_frames_preempt;
buf : 	INIT_LIST_HEAD(&wldev->list);
buf : 
buf : 	err = b43_wireless_core_attach(wldev);
buf : 	if (err)
if (err) 
buf : 		goto err_kfree_wldev;
buf : 
buf : 	b43_bus_set_wldev(dev, wldev);
buf : 	b43_debugfs_add_device(wldev);
buf : 
buf :       out:
buf : 	return err;
buf : 
buf :       err_kfree_wldev:
buf : 	kfree(wldev);
buf : 	return err;
buf : }
buf : 
buf : #define IS_PDEV(pdev, _vendor, _device, _subvendor, _subdevice)		( \
buf : 	(pdev->vendor == PCI_VENDOR_ID_##_vendor) &&			\
buf : 	(pdev->device == _device) &&					\
buf : 	(pdev->subsystem_vendor == PCI_VENDOR_ID_##_subvendor) &&	\
buf : 	(pdev->subsystem_device == _subdevice)				)
buf : 
buf : #ifdef CONFIG_B43_SSB
ifdef CONFIG_B43_SSB 
buf : static void b43_sprom_fixup(struct ssb_bus *bus)
buf : {
buf : 	struct pci_dev *pdev;
buf : 
buf : 	/* boardflags workarounds */
buf : 	if (bus->boardinfo.vendor == SSB_BOARDVENDOR_DELL &&
if (bus->boardinfo.vendor == SSB_BOARDVENDOR_DELL && 
buf : 	    bus->chip_id == 0x4301 && bus->sprom.board_rev == 0x74)
buf : 		bus->sprom.boardflags_lo |= B43_BFL_BTCOEXIST;
buf : 	if (bus->boardinfo.vendor == PCI_VENDOR_ID_APPLE &&
if (bus->boardinfo.vendor == PCI_VENDOR_ID_APPLE && 
buf : 	    bus->boardinfo.type == 0x4E && bus->sprom.board_rev > 0x40)
buf : 		bus->sprom.boardflags_lo |= B43_BFL_PACTRL;
buf : 	if (bus->bustype == SSB_BUSTYPE_PCI) {
if (bus->bustype == SSB_BUSTYPE_PCI) { 
buf : 		pdev = bus->host_pci;
buf : 		if (IS_PDEV(pdev, BROADCOM, 0x4318, ASUSTEK, 0x100F) ||
if (IS_PDEV(pdev, BROADCOM, 0x4318, ASUSTEK, 0x100F) || 
buf : 		    IS_PDEV(pdev, BROADCOM, 0x4320,    DELL, 0x0003) ||
buf : 		    IS_PDEV(pdev, BROADCOM, 0x4320,      HP, 0x12f8) ||
buf : 		    IS_PDEV(pdev, BROADCOM, 0x4320, LINKSYS, 0x0015) ||
buf : 		    IS_PDEV(pdev, BROADCOM, 0x4320, LINKSYS, 0x0014) ||
buf : 		    IS_PDEV(pdev, BROADCOM, 0x4320, LINKSYS, 0x0013) ||
buf : 		    IS_PDEV(pdev, BROADCOM, 0x4320, MOTOROLA, 0x7010))
buf : 			bus->sprom.boardflags_lo &= ~B43_BFL_BTCOEXIST;
buf : 	}
buf : }
buf : 
buf : static void b43_wireless_exit(struct b43_bus_dev *dev, struct b43_wl *wl)
buf : {
buf : 	struct ieee80211_hw *hw = wl->hw;
buf : 
buf : 	ssb_set_devtypedata(dev->sdev, NULL);
buf : 	ieee80211_free_hw(hw);
buf : }
buf : #endif
if 
buf : 
buf : static struct b43_wl *b43_wireless_init(struct b43_bus_dev *dev)
buf : {
buf : 	struct ssb_sprom *sprom = dev->bus_sprom;
buf : 	struct ieee80211_hw *hw;
buf : 	struct b43_wl *wl;
buf : 	char chip_name[6];
buf : 	int queue_num;
buf : 
buf : 	hw = ieee80211_alloc_hw(sizeof(*wl), &b43_hw_ops);
buf : 	if (!hw) {
if (!hw) { 
buf : 		b43err(NULL, "Could not allocate ieee80211 device\n");
buf : 		return ERR_PTR(-ENOMEM);
buf : 	}
buf : 	wl = hw_to_b43_wl(hw);
buf : 
buf : 	/* fill hw info */
buf : 	hw->flags = IEEE80211_HW_RX_INCLUDES_FCS |
buf : 		    IEEE80211_HW_SIGNAL_DBM;
buf : 
buf : 	hw->wiphy->interface_modes =
buf : 		BIT(NL80211_IFTYPE_AP) |
buf : 		BIT(NL80211_IFTYPE_MESH_POINT) |
buf : 		BIT(NL80211_IFTYPE_STATION) |
buf : 		BIT(NL80211_IFTYPE_WDS) |
buf : 		BIT(NL80211_IFTYPE_ADHOC);
buf : 
buf : 	hw->wiphy->flags |= WIPHY_FLAG_IBSS_RSN;
buf : 
buf : 	wl->hw_registred = false;
buf : 	hw->max_rates = 2;
buf : 	SET_IEEE80211_DEV(hw, dev->dev);
buf : 	if (is_valid_ether_addr(sprom->et1mac))
if (is_valid_ether_addr(sprom->et1mac)) 
buf : 		SET_IEEE80211_PERM_ADDR(hw, sprom->et1mac);
buf : 	else
buf : 		SET_IEEE80211_PERM_ADDR(hw, sprom->il0mac);
buf : 
buf : 	/* Initialize struct b43_wl */
buf : 	wl->hw = hw;
buf : 	mutex_init(&wl->mutex);
buf : 	spin_lock_init(&wl->hardirq_lock);
buf : 	INIT_WORK(&wl->beacon_update_trigger, b43_beacon_update_trigger_work);
buf : 	INIT_WORK(&wl->txpower_adjust_work, b43_phy_txpower_adjust_work);
buf : 	INIT_WORK(&wl->tx_work, b43_tx_work);
buf : 
buf : 	/* Initialize queues and flags. */
buf : 	for (queue_num = 0; queue_num < B43_QOS_QUEUE_NUM; queue_num++) {
for (queue_num = 0; queue_num < B43_QOS_QUEUE_NUM; queue_num++) { 
buf : 		skb_queue_head_init(&wl->tx_queue[queue_num]);
buf : 		wl->tx_queue_stopped[queue_num] = 0;
buf : 	}
buf : 
buf : 	snprintf(chip_name, ARRAY_SIZE(chip_name),
buf : 		 (dev->chip_id > 0x9999) ? "%d" : "%04X", dev->chip_id);
buf : 	b43info(wl, "Broadcom %s WLAN found (core revision %u)\n", chip_name,
buf : 		dev->core_rev);
buf : 	return wl;
buf : }
buf : 
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : static int b43_bcma_probe(struct bcma_device *core)
buf : {
buf : 	struct b43_bus_dev *dev;
buf : 	struct b43_wl *wl;
buf : 	int err;
buf : 
buf : 	if (!modparam_allhwsupport &&
if (!modparam_allhwsupport && 
buf : 	    (core->id.rev == 0x17 || core->id.rev == 0x18)) {
buf : 		pr_err("Support for cores revisions 0x17 and 0x18 disabled by module param allhwsupport=0. Try b43.allhwsupport=1\n");
for cores revisions 0x17 and 0x18 disabled by module param allhwsupport=0. Try b43.allhwsupport=1\n"); 
buf : 		return -ENOTSUPP;
buf : 	}
buf : 
buf : 	dev = b43_bus_dev_bcma_init(core);
buf : 	if (!dev)
if (!dev) 
buf : 		return -ENODEV;
buf : 
buf : 	wl = b43_wireless_init(dev);
buf : 	if (IS_ERR(wl)) {
if (IS_ERR(wl)) { 
buf : 		err = PTR_ERR(wl);
buf : 		goto bcma_out;
buf : 	}
buf : 
buf : 	err = b43_one_core_attach(dev, wl);
buf : 	if (err)
if (err) 
buf : 		goto bcma_err_wireless_exit;
buf : 
buf : 	/* setup and start work to load firmware */
buf : 	INIT_WORK(&wl->firmware_load, b43_request_firmware);
buf : 	schedule_work(&wl->firmware_load);
buf : 
buf : bcma_out:
buf : 	return err;
buf : 
buf : bcma_err_wireless_exit:
buf : 	ieee80211_free_hw(wl->hw);
buf : 	return err;
buf : }
buf : 
buf : static void b43_bcma_remove(struct bcma_device *core)
buf : {
buf : 	struct b43_wldev *wldev = bcma_get_drvdata(core);
buf : 	struct b43_wl *wl = wldev->wl;
buf : 
buf : 	/* We must cancel any work here before unregistering from ieee80211,
fore unregistering from ieee80211, 
buf : 	 * as the ieee80211 unreg will destroy the workqueue. */
buf : 	cancel_work_sync(&wldev->restart_work);
buf : 	cancel_work_sync(&wl->firmware_load);
buf : 
buf : 	B43_WARN_ON(!wl);
buf : 	if (!wldev->fw.ucode.data)
if (!wldev->fw.ucode.data) 
buf : 		return;			/* NULL if firmware never loaded */
buf : 	if (wl->current_dev == wldev && wl->hw_registred) {
if (wl->current_dev == wldev && wl->hw_registred) { 
buf : 		b43_leds_stop(wldev);
buf : 		ieee80211_unregister_hw(wl->hw);
buf : 	}
buf : 
buf : 	b43_one_core_detach(wldev->dev);
buf : 
buf : 	/* Unregister HW RNG driver */
buf : 	b43_rng_exit(wl);
buf : 
buf : 	b43_leds_unregister(wl);
buf : 
buf : 	ieee80211_free_hw(wl->hw);
buf : }
buf : 
buf : static struct bcma_driver b43_bcma_driver = {
buf : 	.name		= KBUILD_MODNAME,
buf : 	.id_table	= b43_bcma_tbl,
buf : 	.probe		= b43_bcma_probe,
buf : 	.remove		= b43_bcma_remove,
buf : };
buf : #endif
if 
buf : 
buf : #ifdef CONFIG_B43_SSB
buf : static
buf : int b43_ssb_probe(struct ssb_device *sdev, const struct ssb_device_id *id)
buf : {
buf : 	struct b43_bus_dev *dev;
buf : 	struct b43_wl *wl;
buf : 	int err;
buf : 
buf : 	dev = b43_bus_dev_ssb_init(sdev);
buf : 	if (!dev)
if (!dev) 
buf : 		return -ENOMEM;
buf : 
buf : 	wl = ssb_get_devtypedata(sdev);
buf : 	if (wl) {
if (wl) { 
buf : 		b43err(NULL, "Dual-core devices are not supported\n");
buf : 		err = -ENOTSUPP;
buf : 		goto err_ssb_kfree_dev;
buf : 	}
buf : 
buf : 	b43_sprom_fixup(sdev->bus);
buf : 
buf : 	wl = b43_wireless_init(dev);
buf : 	if (IS_ERR(wl)) {
if (IS_ERR(wl)) { 
buf : 		err = PTR_ERR(wl);
buf : 		goto err_ssb_kfree_dev;
buf : 	}
buf : 	ssb_set_devtypedata(sdev, wl);
buf : 	B43_WARN_ON(ssb_get_devtypedata(sdev) != wl);
buf : 
buf : 	err = b43_one_core_attach(dev, wl);
buf : 	if (err)
if (err) 
buf : 		goto err_ssb_wireless_exit;
buf : 
buf : 	/* setup and start work to load firmware */
buf : 	INIT_WORK(&wl->firmware_load, b43_request_firmware);
buf : 	schedule_work(&wl->firmware_load);
buf : 
buf : 	return err;
buf : 
buf : err_ssb_wireless_exit:
buf : 	b43_wireless_exit(dev, wl);
buf : err_ssb_kfree_dev:
buf : 	kfree(dev);
buf : 	return err;
buf : }
buf : 
buf : static void b43_ssb_remove(struct ssb_device *sdev)
buf : {
buf : 	struct b43_wl *wl = ssb_get_devtypedata(sdev);
buf : 	struct b43_wldev *wldev = ssb_get_drvdata(sdev);
buf : 	struct b43_bus_dev *dev = wldev->dev;
buf : 
buf : 	/* We must cancel any work here before unregistering from ieee80211,
fore unregistering from ieee80211, 
buf : 	 * as the ieee80211 unreg will destroy the workqueue. */
buf : 	cancel_work_sync(&wldev->restart_work);
buf : 	cancel_work_sync(&wl->firmware_load);
buf : 
buf : 	B43_WARN_ON(!wl);
buf : 	if (!wldev->fw.ucode.data)
if (!wldev->fw.ucode.data) 
buf : 		return;			/* NULL if firmware never loaded */
buf : 	if (wl->current_dev == wldev && wl->hw_registred) {
if (wl->current_dev == wldev && wl->hw_registred) { 
buf : 		b43_leds_stop(wldev);
buf : 		ieee80211_unregister_hw(wl->hw);
buf : 	}
buf : 
buf : 	b43_one_core_detach(dev);
buf : 
buf : 	/* Unregister HW RNG driver */
buf : 	b43_rng_exit(wl);
buf : 
buf : 	b43_leds_unregister(wl);
buf : 	b43_wireless_exit(dev, wl);
buf : }
buf : 
buf : static struct ssb_driver b43_ssb_driver = {
buf : 	.name		= KBUILD_MODNAME,
buf : 	.id_table	= b43_ssb_tbl,
buf : 	.probe		= b43_ssb_probe,
buf : 	.remove		= b43_ssb_remove,
buf : };
buf : #endif /* CONFIG_B43_SSB */
if /* CONFIG_B43_SSB */ 
buf : 
buf : /* Perform a hardware reset. This can be called from any context. */
form a hardware reset. This can be called from any context. */ 
buf : void b43_controller_restart(struct b43_wldev *dev, const char *reason)
buf : {
buf : 	/* Must avoid requeueing, if we are in shutdown. */
if we are in shutdown. */ 
buf : 	if (b43_status(dev) < B43_STAT_INITIALIZED)
buf : 		return;
buf : 	b43info(dev->wl, "Controller RESET (%s) ...\n", reason);
buf : 	ieee80211_queue_work(dev->wl->hw, &dev->restart_work);
buf : }
buf : 
buf : static void b43_print_driverinfo(void)
buf : {
buf : 	const char *feat_pci = "", *feat_pcmcia = "", *feat_nphy = "",
buf : 		   *feat_leds = "", *feat_sdio = "";
buf : 
buf : #ifdef CONFIG_B43_PCI_AUTOSELECT
ifdef CONFIG_B43_PCI_AUTOSELECT 
buf : 	feat_pci = "P";
buf : #endif
if 
buf : #ifdef CONFIG_B43_PCMCIA
buf : 	feat_pcmcia = "M";
buf : #endif
if 
buf : #ifdef CONFIG_B43_PHY_N
buf : 	feat_nphy = "N";
buf : #endif
if 
buf : #ifdef CONFIG_B43_LEDS
buf : 	feat_leds = "L";
buf : #endif
if 
buf : #ifdef CONFIG_B43_SDIO
buf : 	feat_sdio = "S";
buf : #endif
if 
buf : 	printk(KERN_INFO "Broadcom 43xx driver loaded "
buf : 	       "[ Features: %s%s%s%s%s ]\n",
buf : 	       feat_pci, feat_pcmcia, feat_nphy,
buf : 	       feat_leds, feat_sdio);
buf : }
buf : 
buf : static int __init b43_init(void)
buf : {
buf : 	int err;
buf : 
buf : 	b43_debugfs_init();
buf : 	err = b43_pcmcia_init();
buf : 	if (err)
if (err) 
buf : 		goto err_dfs_exit;
buf : 	err = b43_sdio_init();
buf : 	if (err)
if (err) 
buf : 		goto err_pcmcia_exit;
buf : #ifdef CONFIG_B43_BCMA
ifdef CONFIG_B43_BCMA 
buf : 	err = bcma_driver_register(&b43_bcma_driver);
buf : 	if (err)
if (err) 
buf : 		goto err_sdio_exit;
buf : #endif
if 
buf : #ifdef CONFIG_B43_SSB
buf : 	err = ssb_driver_register(&b43_ssb_driver);
buf : 	if (err)
if (err) 
buf : 		goto err_bcma_driver_exit;
buf : #endif
if 
buf : 	b43_print_driverinfo();
buf : 
buf : 	return err;
buf : 
buf : #ifdef CONFIG_B43_SSB
ifdef CONFIG_B43_SSB 
buf : err_bcma_driver_exit:
buf : #endif
if 
buf : #ifdef CONFIG_B43_BCMA
buf : 	bcma_driver_unregister(&b43_bcma_driver);
buf : err_sdio_exit:
buf : #endif
if 
buf : 	b43_sdio_exit();
buf : err_pcmcia_exit:
buf : 	b43_pcmcia_exit();
buf : err_dfs_exit:
buf : 	b43_debugfs_exit();
buf : 	return err;
buf : }
buf : 
buf : static void __exit b43_exit(void)
buf : {
buf : #ifdef CONFIG_B43_SSB
ifdef CONFIG_B43_SSB 
buf : 	ssb_driver_unregister(&b43_ssb_driver);
buf : #endif
if 
buf : #ifdef CONFIG_B43_BCMA
buf : 	bcma_driver_unregister(&b43_bcma_driver);
buf : #endif
if 
buf : 	b43_sdio_exit();
buf : 	b43_pcmcia_exit();
buf : 	b43_debugfs_exit();
buf : }
buf : 
buf : module_init(b43_init)
buf : module_exit(b43_exit)
file : ./test/kernel/drivers/net/wireless/ti/wl12xx/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * This file is part of wl1271
buf :  *
buf :  * Copyright (C) 2008-2010 Nokia Corporation
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of the GNU General Public License
ify it under the terms of the GNU General Public License 
buf :  * version 2 as published by the Free Software Foundation.
buf :  *
buf :  * This program is distributed in the hope that it will be useful, but
buf :  * WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
buf :  * General Public License for more details.
for more details. 
buf :  *
buf :  * You should have received a copy of the GNU General Public License
buf :  * along with this program; if not, write to the Free Software
if not, write to the Free Software 
buf :  * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
buf :  * 02110-1301 USA
buf :  *
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/platform_device.h>
form_device.h> 
buf : 
buf : #include <linux/err.h>
buf : 
buf : #include <linux/wl12xx.h>
buf : 
buf : #include "../wlcore/wlcore.h"
buf : #include "../wlcore/debug.h"
buf : #include "../wlcore/io.h"
buf : #include "../wlcore/acx.h"
buf : #include "../wlcore/tx.h"
buf : #include "../wlcore/rx.h"
buf : #include "../wlcore/boot.h"
buf : 
buf : #include "wl12xx.h"
buf : #include "reg.h"
buf : #include "cmd.h"
buf : #include "acx.h"
buf : #include "scan.h"
buf : #include "event.h"
buf : #include "debugfs.h"
buf : 
buf : static char *fref_param;
buf : static char *tcxo_param;
buf : 
buf : static struct wlcore_conf wl12xx_conf = {
buf : 	.sg = {
buf : 		.params = {
buf : 			[CONF_SG_ACL_BT_MASTER_MIN_BR] = 10,
buf : 			[CONF_SG_ACL_BT_MASTER_MAX_BR] = 180,
buf : 			[CONF_SG_ACL_BT_SLAVE_MIN_BR] = 10,
buf : 			[CONF_SG_ACL_BT_SLAVE_MAX_BR] = 180,
buf : 			[CONF_SG_ACL_BT_MASTER_MIN_EDR] = 10,
buf : 			[CONF_SG_ACL_BT_MASTER_MAX_EDR] = 80,
buf : 			[CONF_SG_ACL_BT_SLAVE_MIN_EDR] = 10,
buf : 			[CONF_SG_ACL_BT_SLAVE_MAX_EDR] = 80,
buf : 			[CONF_SG_ACL_WLAN_PS_MASTER_BR] = 8,
buf : 			[CONF_SG_ACL_WLAN_PS_SLAVE_BR] = 8,
buf : 			[CONF_SG_ACL_WLAN_PS_MASTER_EDR] = 20,
buf : 			[CONF_SG_ACL_WLAN_PS_SLAVE_EDR] = 20,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_MASTER_MIN_BR] = 20,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_MASTER_MAX_BR] = 35,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_SLAVE_MIN_BR] = 16,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_SLAVE_MAX_BR] = 35,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_MASTER_MIN_EDR] = 32,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_MASTER_MAX_EDR] = 50,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_SLAVE_MIN_EDR] = 28,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_SLAVE_MAX_EDR] = 50,
buf : 			[CONF_SG_ACL_ACTIVE_SCAN_WLAN_BR] = 10,
buf : 			[CONF_SG_ACL_ACTIVE_SCAN_WLAN_EDR] = 20,
buf : 			[CONF_SG_ACL_PASSIVE_SCAN_BT_BR] = 75,
buf : 			[CONF_SG_ACL_PASSIVE_SCAN_WLAN_BR] = 15,
buf : 			[CONF_SG_ACL_PASSIVE_SCAN_BT_EDR] = 27,
buf : 			[CONF_SG_ACL_PASSIVE_SCAN_WLAN_EDR] = 17,
buf : 			/* active scan params */
buf : 			[CONF_SG_AUTO_SCAN_PROBE_REQ] = 170,
buf : 			[CONF_SG_ACTIVE_SCAN_DURATION_FACTOR_HV3] = 50,
buf : 			[CONF_SG_ACTIVE_SCAN_DURATION_FACTOR_A2DP] = 100,
buf : 			/* passive scan params */
buf : 			[CONF_SG_PASSIVE_SCAN_DURATION_FACTOR_A2DP_BR] = 800,
buf : 			[CONF_SG_PASSIVE_SCAN_DURATION_FACTOR_A2DP_EDR] = 200,
buf : 			[CONF_SG_PASSIVE_SCAN_DURATION_FACTOR_HV3] = 200,
buf : 			/* passive scan in dual antenna params */
buf : 			[CONF_SG_CONSECUTIVE_HV3_IN_PASSIVE_SCAN] = 0,
buf : 			[CONF_SG_BCN_HV3_COLLISION_THRESH_IN_PASSIVE_SCAN] = 0,
buf : 			[CONF_SG_TX_RX_PROTECTION_BWIDTH_IN_PASSIVE_SCAN] = 0,
buf : 			/* general params */
buf : 			[CONF_SG_STA_FORCE_PS_IN_BT_SCO] = 1,
buf : 			[CONF_SG_ANTENNA_CONFIGURATION] = 0,
buf : 			[CONF_SG_BEACON_MISS_PERCENT] = 60,
buf : 			[CONF_SG_DHCP_TIME] = 5000,
buf : 			[CONF_SG_RXT] = 1200,
buf : 			[CONF_SG_TXT] = 1000,
buf : 			[CONF_SG_ADAPTIVE_RXT_TXT] = 1,
buf : 			[CONF_SG_GENERAL_USAGE_BIT_MAP] = 3,
buf : 			[CONF_SG_HV3_MAX_SERVED] = 6,
buf : 			[CONF_SG_PS_POLL_TIMEOUT] = 10,
buf : 			[CONF_SG_UPSD_TIMEOUT] = 10,
buf : 			[CONF_SG_CONSECUTIVE_CTS_THRESHOLD] = 2,
buf : 			[CONF_SG_STA_RX_WINDOW_AFTER_DTIM] = 5,
buf : 			[CONF_SG_STA_CONNECTION_PROTECTION_TIME] = 30,
buf : 			/* AP params */
buf : 			[CONF_AP_BEACON_MISS_TX] = 3,
buf : 			[CONF_AP_RX_WINDOW_AFTER_BEACON] = 10,
buf : 			[CONF_AP_BEACON_WINDOW_INTERVAL] = 2,
buf : 			[CONF_AP_CONNECTION_PROTECTION_TIME] = 0,
buf : 			[CONF_AP_BT_ACL_VAL_BT_SERVE_TIME] = 25,
buf : 			[CONF_AP_BT_ACL_VAL_WL_SERVE_TIME] = 25,
buf : 			/* CTS Diluting params */
buf : 			[CONF_SG_CTS_DILUTED_BAD_RX_PACKETS_TH] = 0,
buf : 			[CONF_SG_CTS_CHOP_IN_DUAL_ANT_SCO_MASTER] = 0,
buf : 		},
buf : 		.state = CONF_SG_PROTECTIVE,
buf : 	},
buf : 	.rx = {
buf : 		.rx_msdu_life_time           = 512000,
ife_time           = 512000, 
buf : 		.packet_detection_threshold  = 0,
buf : 		.ps_poll_timeout             = 15,
buf : 		.upsd_timeout                = 15,
buf : 		.rts_threshold               = IEEE80211_MAX_RTS_THRESHOLD,
buf : 		.rx_cca_threshold            = 0,
buf : 		.irq_blk_threshold           = 0xFFFF,
buf : 		.irq_pkt_threshold           = 0,
buf : 		.irq_timeout                 = 600,
buf : 		.queue_type                  = CONF_RX_QUEUE_TYPE_LOW_PRIORITY,
buf : 	},
buf : 	.tx = {
buf : 		.tx_energy_detection         = 0,
buf : 		.sta_rc_conf                 = {
buf : 			.enabled_rates       = 0,
buf : 			.short_retry_limit   = 10,
buf : 			.long_retry_limit    = 10,
buf : 			.aflags              = 0,
buf : 		},
buf : 		.ac_conf_count               = 4,
buf : 		.ac_conf                     = {
buf : 			[CONF_TX_AC_BE] = {
buf : 				.ac          = CONF_TX_AC_BE,
buf : 				.cw_min      = 15,
buf : 				.cw_max      = 63,
buf : 				.aifsn       = 3,
ifsn       = 3, 
buf : 				.tx_op_limit = 0,
buf : 			},
buf : 			[CONF_TX_AC_BK] = {
buf : 				.ac          = CONF_TX_AC_BK,
buf : 				.cw_min      = 15,
buf : 				.cw_max      = 63,
buf : 				.aifsn       = 7,
ifsn       = 7, 
buf : 				.tx_op_limit = 0,
buf : 			},
buf : 			[CONF_TX_AC_VI] = {
buf : 				.ac          = CONF_TX_AC_VI,
buf : 				.cw_min      = 15,
buf : 				.cw_max      = 63,
buf : 				.aifsn       = CONF_TX_AIFS_PIFS,
ifsn       = CONF_TX_AIFS_PIFS, 
buf : 				.tx_op_limit = 3008,
buf : 			},
buf : 			[CONF_TX_AC_VO] = {
buf : 				.ac          = CONF_TX_AC_VO,
buf : 				.cw_min      = 15,
buf : 				.cw_max      = 63,
buf : 				.aifsn       = CONF_TX_AIFS_PIFS,
ifsn       = CONF_TX_AIFS_PIFS, 
buf : 				.tx_op_limit = 1504,
buf : 			},
buf : 		},
buf : 		.max_tx_retries = 100,
buf : 		.ap_aging_period = 300,
buf : 		.tid_conf_count = 4,
buf : 		.tid_conf = {
buf : 			[CONF_TX_AC_BE] = {
buf : 				.queue_id    = CONF_TX_AC_BE,
buf : 				.channel_type = CONF_CHANNEL_TYPE_EDCF,
buf : 				.tsid        = CONF_TX_AC_BE,
buf : 				.ps_scheme   = CONF_PS_SCHEME_LEGACY,
buf : 				.ack_policy  = CONF_ACK_POLICY_LEGACY,
buf : 				.apsd_conf   = {0, 0},
buf : 			},
buf : 			[CONF_TX_AC_BK] = {
buf : 				.queue_id    = CONF_TX_AC_BK,
buf : 				.channel_type = CONF_CHANNEL_TYPE_EDCF,
buf : 				.tsid        = CONF_TX_AC_BK,
buf : 				.ps_scheme   = CONF_PS_SCHEME_LEGACY,
buf : 				.ack_policy  = CONF_ACK_POLICY_LEGACY,
buf : 				.apsd_conf   = {0, 0},
buf : 			},
buf : 			[CONF_TX_AC_VI] = {
buf : 				.queue_id    = CONF_TX_AC_VI,
buf : 				.channel_type = CONF_CHANNEL_TYPE_EDCF,
buf : 				.tsid        = CONF_TX_AC_VI,
buf : 				.ps_scheme   = CONF_PS_SCHEME_LEGACY,
buf : 				.ack_policy  = CONF_ACK_POLICY_LEGACY,
buf : 				.apsd_conf   = {0, 0},
buf : 			},
buf : 			[CONF_TX_AC_VO] = {
buf : 				.queue_id    = CONF_TX_AC_VO,
buf : 				.channel_type = CONF_CHANNEL_TYPE_EDCF,
buf : 				.tsid        = CONF_TX_AC_VO,
buf : 				.ps_scheme   = CONF_PS_SCHEME_LEGACY,
buf : 				.ack_policy  = CONF_ACK_POLICY_LEGACY,
buf : 				.apsd_conf   = {0, 0},
buf : 			},
buf : 		},
buf : 		.frag_threshold              = IEEE80211_MAX_FRAG_THRESHOLD,
buf : 		.tx_compl_timeout            = 700,
buf : 		.tx_compl_threshold          = 4,
buf : 		.basic_rate                  = CONF_HW_BIT_RATE_1MBPS,
buf : 		.basic_rate_5                = CONF_HW_BIT_RATE_6MBPS,
buf : 		.tmpl_short_retry_limit      = 10,
buf : 		.tmpl_long_retry_limit       = 10,
buf : 		.tx_watchdog_timeout         = 5000,
buf : 		.slow_link_thold             = 3,
buf : 		.fast_link_thold             = 10,
buf : 	},
buf : 	.conn = {
buf : 		.wake_up_event               = CONF_WAKE_UP_EVENT_DTIM,
buf : 		.listen_interval             = 1,
buf : 		.suspend_wake_up_event       = CONF_WAKE_UP_EVENT_N_DTIM,
buf : 		.suspend_listen_interval     = 3,
buf : 		.bcn_filt_mode               = CONF_BCN_FILT_MODE_ENABLED,
buf : 		.bcn_filt_ie_count           = 3,
buf : 		.bcn_filt_ie = {
buf : 			[0] = {
buf : 				.ie          = WLAN_EID_CHANNEL_SWITCH,
buf : 				.rule        = CONF_BCN_RULE_PASS_ON_APPEARANCE,
buf : 			},
buf : 			[1] = {
buf : 				.ie          = WLAN_EID_HT_OPERATION,
buf : 				.rule        = CONF_BCN_RULE_PASS_ON_CHANGE,
buf : 			},
buf : 			[2] = {
buf : 				.ie	     = WLAN_EID_ERP_INFO,
buf : 				.rule	     = CONF_BCN_RULE_PASS_ON_CHANGE,
buf : 			},
buf : 		},
buf : 		.synch_fail_thold            = 12,
buf : 		.bss_lose_timeout            = 400,
buf : 		.beacon_rx_timeout           = 10000,
buf : 		.broadcast_timeout           = 20000,
buf : 		.rx_broadcast_in_ps          = 1,
buf : 		.ps_poll_threshold           = 10,
buf : 		.bet_enable                  = CONF_BET_MODE_ENABLE,
buf : 		.bet_max_consecutive         = 50,
buf : 		.psm_entry_retries           = 8,
buf : 		.psm_exit_retries            = 16,
buf : 		.psm_entry_nullfunc_retries  = 3,
buf : 		.dynamic_ps_timeout          = 1500,
buf : 		.forced_ps                   = false,
forced_ps                   = false, 
buf : 		.keep_alive_interval         = 55000,
buf : 		.max_listen_interval         = 20,
buf : 		.sta_sleep_auth              = WL1271_PSM_ILLEGAL,
buf : 	},
buf : 	.itrim = {
buf : 		.enable = false,
buf : 		.timeout = 50000,
buf : 	},
buf : 	.pm_config = {
buf : 		.host_clk_settling_time = 5000,
buf : 		.host_fast_wakeup_support = CONF_FAST_WAKEUP_DISABLE,
buf : 	},
buf : 	.roam_trigger = {
buf : 		.trigger_pacing               = 1,
buf : 		.avg_weight_rssi_beacon       = 20,
buf : 		.avg_weight_rssi_data         = 10,
buf : 		.avg_weight_snr_beacon        = 20,
buf : 		.avg_weight_snr_data          = 10,
buf : 	},
buf : 	.scan = {
buf : 		.min_dwell_time_active        = 7500,
buf : 		.max_dwell_time_active        = 30000,
buf : 		.min_dwell_time_active_long   = 25000,
buf : 		.max_dwell_time_active_long   = 50000,
buf : 		.dwell_time_passive           = 100000,
buf : 		.dwell_time_dfs               = 150000,
buf : 		.num_probe_reqs               = 2,
buf : 		.split_scan_timeout           = 50000,
buf : 	},
buf : 	.sched_scan = {
buf : 		/*
buf : 		 * Values are in TU/1000 but since sched scan FW command
buf : 		 * params are in TUs rounding up may occur.
buf : 		 */
buf : 		.base_dwell_time		= 7500,
buf : 		.max_dwell_time_delta		= 22500,
buf : 		/* based on 250bits per probe @1Mbps */
buf : 		.dwell_time_delta_per_probe	= 2000,
buf : 		/* based on 250bits per probe @6Mbps (plus a bit more) */
buf : 		.dwell_time_delta_per_probe_5	= 350,
buf : 		.dwell_time_passive		= 100000,
buf : 		.dwell_time_dfs			= 150000,
buf : 		.num_probe_reqs			= 2,
buf : 		.rssi_threshold			= -90,
buf : 		.snr_threshold			= 0,
buf : 	},
buf : 	.ht = {
buf : 		.rx_ba_win_size = 8,
buf : 		.tx_ba_win_size = 64,
buf : 		.inactivity_timeout = 10000,
buf : 		.tx_ba_tid_bitmap = CONF_TX_BA_ENABLED_TID_BITMAP,
buf : 	},
buf : 	/*
buf : 	 * Memory config for wl127x chips is given in the
for wl127x chips is given in the 
buf : 	 * wl12xx_default_priv_conf struct. The below configuration is
buf : 	 * for wl128x chips.
for wl128x chips. 
buf : 	 */
buf : 	.mem = {
buf : 		.num_stations                 = 1,
buf : 		.ssid_profiles                = 1,
buf : 		.rx_block_num                 = 40,
buf : 		.tx_min_block_num             = 40,
buf : 		.dynamic_memory               = 1,
buf : 		.min_req_tx_blocks            = 45,
buf : 		.min_req_rx_blocks            = 22,
buf : 		.tx_min                       = 27,
buf : 	},
buf : 	.fm_coex = {
buf : 		.enable                       = true,
buf : 		.swallow_period               = 5,
buf : 		.n_divider_fref_set_1         = 0xff,       /* default */
buf : 		.n_divider_fref_set_2         = 12,
buf : 		.m_divider_fref_set_1         = 0xffff,
buf : 		.m_divider_fref_set_2         = 148,	    /* default */
buf : 		.coex_pll_stabilization_time  = 0xffffffff, /* default */
buf : 		.ldo_stabilization_time       = 0xffff,     /* default */
buf : 		.fm_disturbed_band_margin     = 0xff,       /* default */
buf : 		.swallow_clk_diff             = 0xff,       /* default */
iff             = 0xff,       /* default */ 
buf : 	},
buf : 	.rx_streaming = {
buf : 		.duration                      = 150,
buf : 		.queues                        = 0x1,
buf : 		.interval                      = 20,
buf : 		.always                        = 0,
buf : 	},
buf : 	.fwlog = {
buf : 		.mode                         = WL12XX_FWLOG_CONTINUOUS,
buf : 		.mem_blocks                   = 2,
buf : 		.severity                     = 0,
buf : 		.timestamp                    = WL12XX_FWLOG_TIMESTAMP_DISABLED,
buf : 		.output                       = WL12XX_FWLOG_OUTPUT_DBG_PINS,
buf : 		.threshold                    = 0,
buf : 	},
buf : 	.rate = {
buf : 		.rate_retry_score = 32000,
buf : 		.per_add = 8192,
buf : 		.per_th1 = 2048,
buf : 		.per_th2 = 4096,
buf : 		.max_per = 8100,
buf : 		.inverse_curiosity_factor = 5,
buf : 		.tx_fail_low_th = 4,
buf : 		.tx_fail_high_th = 10,
buf : 		.per_alpha_shift = 4,
ift = 4, 
buf : 		.per_add_shift = 13,
buf : 		.per_beta1_shift = 10,
ift = 10, 
buf : 		.per_beta2_shift = 8,
buf : 		.rate_check_up = 2,
buf : 		.rate_check_down = 12,
buf : 		.rate_retry_policy = {
buf : 			0x00, 0x00, 0x00, 0x00, 0x00,
buf : 			0x00, 0x00, 0x00, 0x00, 0x00,
buf : 			0x00, 0x00, 0x00,
buf : 		},
buf : 	},
buf : 	.hangover = {
buf : 		.recover_time               = 0,
buf : 		.hangover_period            = 20,
buf : 		.dynamic_mode               = 1,
buf : 		.early_termination_mode     = 1,
buf : 		.max_period                 = 20,
buf : 		.min_period                 = 1,
buf : 		.increase_delta             = 1,
buf : 		.decrease_delta             = 2,
buf : 		.quiet_time                 = 4,
buf : 		.increase_time              = 1,
buf : 		.window_size                = 16,
buf : 	},
buf : 	.recovery = {
buf : 		.bug_on_recovery	    = 0,
buf : 		.no_recovery		    = 0,
buf : 	},
buf : };
buf : 
buf : static struct wl12xx_priv_conf wl12xx_default_priv_conf = {
buf : 	.rf = {
buf : 		.tx_per_channel_power_compensation_2 = {
buf : 			0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
buf : 		},
buf : 		.tx_per_channel_power_compensation_5 = {
buf : 			0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
buf : 			0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
buf : 			0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
buf : 		},
buf : 	},
buf : 	.mem_wl127x = {
buf : 		.num_stations                 = 1,
buf : 		.ssid_profiles                = 1,
buf : 		.rx_block_num                 = 70,
buf : 		.tx_min_block_num             = 40,
buf : 		.dynamic_memory               = 1,
buf : 		.min_req_tx_blocks            = 100,
buf : 		.min_req_rx_blocks            = 22,
buf : 		.tx_min                       = 27,
buf : 	},
buf : 
buf : };
buf : 
buf : #define WL12XX_TX_HW_BLOCK_SPARE_DEFAULT        1
buf : #define WL12XX_TX_HW_BLOCK_GEM_SPARE            2
buf : #define WL12XX_TX_HW_BLOCK_SIZE                 252
buf : 
buf : static const u8 wl12xx_rate_to_idx_2ghz[] = {
buf : 	/* MCS rates are used only with 11n */
buf : 	7,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS7_SGI */
buf : 	7,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS7 */
buf : 	6,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS6 */
buf : 	5,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS5 */
buf : 	4,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS4 */
buf : 	3,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS3 */
buf : 	2,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS2 */
buf : 	1,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS1 */
buf : 	0,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS0 */
buf : 
buf : 	11,                            /* WL12XX_CONF_HW_RXTX_RATE_54   */
buf : 	10,                            /* WL12XX_CONF_HW_RXTX_RATE_48   */
buf : 	9,                             /* WL12XX_CONF_HW_RXTX_RATE_36   */
buf : 	8,                             /* WL12XX_CONF_HW_RXTX_RATE_24   */
buf : 
buf : 	/* TI-specific rate */
ific rate */ 
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL12XX_CONF_HW_RXTX_RATE_22   */
buf : 
buf : 	7,                             /* WL12XX_CONF_HW_RXTX_RATE_18   */
buf : 	6,                             /* WL12XX_CONF_HW_RXTX_RATE_12   */
buf : 	3,                             /* WL12XX_CONF_HW_RXTX_RATE_11   */
buf : 	5,                             /* WL12XX_CONF_HW_RXTX_RATE_9    */
buf : 	4,                             /* WL12XX_CONF_HW_RXTX_RATE_6    */
buf : 	2,                             /* WL12XX_CONF_HW_RXTX_RATE_5_5  */
buf : 	1,                             /* WL12XX_CONF_HW_RXTX_RATE_2    */
buf : 	0                              /* WL12XX_CONF_HW_RXTX_RATE_1    */
buf : };
buf : 
buf : static const u8 wl12xx_rate_to_idx_5ghz[] = {
buf : 	/* MCS rates are used only with 11n */
buf : 	7,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS7_SGI */
buf : 	7,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS7 */
buf : 	6,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS6 */
buf : 	5,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS5 */
buf : 	4,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS4 */
buf : 	3,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS3 */
buf : 	2,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS2 */
buf : 	1,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS1 */
buf : 	0,                             /* WL12XX_CONF_HW_RXTX_RATE_MCS0 */
buf : 
buf : 	7,                             /* WL12XX_CONF_HW_RXTX_RATE_54   */
buf : 	6,                             /* WL12XX_CONF_HW_RXTX_RATE_48   */
buf : 	5,                             /* WL12XX_CONF_HW_RXTX_RATE_36   */
buf : 	4,                             /* WL12XX_CONF_HW_RXTX_RATE_24   */
buf : 
buf : 	/* TI-specific rate */
ific rate */ 
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL12XX_CONF_HW_RXTX_RATE_22   */
buf : 
buf : 	3,                             /* WL12XX_CONF_HW_RXTX_RATE_18   */
buf : 	2,                             /* WL12XX_CONF_HW_RXTX_RATE_12   */
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL12XX_CONF_HW_RXTX_RATE_11   */
buf : 	1,                             /* WL12XX_CONF_HW_RXTX_RATE_9    */
buf : 	0,                             /* WL12XX_CONF_HW_RXTX_RATE_6    */
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL12XX_CONF_HW_RXTX_RATE_5_5  */
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL12XX_CONF_HW_RXTX_RATE_2    */
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED  /* WL12XX_CONF_HW_RXTX_RATE_1    */
buf : };
buf : 
buf : static const u8 *wl12xx_band_rate_to_idx[] = {
buf : 	[IEEE80211_BAND_2GHZ] = wl12xx_rate_to_idx_2ghz,
buf : 	[IEEE80211_BAND_5GHZ] = wl12xx_rate_to_idx_5ghz
buf : };
buf : 
buf : enum wl12xx_hw_rates {
buf : 	WL12XX_CONF_HW_RXTX_RATE_MCS7_SGI = 0,
buf : 	WL12XX_CONF_HW_RXTX_RATE_MCS7,
buf : 	WL12XX_CONF_HW_RXTX_RATE_MCS6,
buf : 	WL12XX_CONF_HW_RXTX_RATE_MCS5,
buf : 	WL12XX_CONF_HW_RXTX_RATE_MCS4,
buf : 	WL12XX_CONF_HW_RXTX_RATE_MCS3,
buf : 	WL12XX_CONF_HW_RXTX_RATE_MCS2,
buf : 	WL12XX_CONF_HW_RXTX_RATE_MCS1,
buf : 	WL12XX_CONF_HW_RXTX_RATE_MCS0,
buf : 	WL12XX_CONF_HW_RXTX_RATE_54,
buf : 	WL12XX_CONF_HW_RXTX_RATE_48,
buf : 	WL12XX_CONF_HW_RXTX_RATE_36,
buf : 	WL12XX_CONF_HW_RXTX_RATE_24,
buf : 	WL12XX_CONF_HW_RXTX_RATE_22,
buf : 	WL12XX_CONF_HW_RXTX_RATE_18,
buf : 	WL12XX_CONF_HW_RXTX_RATE_12,
buf : 	WL12XX_CONF_HW_RXTX_RATE_11,
buf : 	WL12XX_CONF_HW_RXTX_RATE_9,
buf : 	WL12XX_CONF_HW_RXTX_RATE_6,
buf : 	WL12XX_CONF_HW_RXTX_RATE_5_5,
buf : 	WL12XX_CONF_HW_RXTX_RATE_2,
buf : 	WL12XX_CONF_HW_RXTX_RATE_1,
buf : 	WL12XX_CONF_HW_RXTX_RATE_MAX,
buf : };
buf : 
buf : static struct wlcore_partition_set wl12xx_ptable[PART_TABLE_LEN] = {
buf : 	[PART_DOWN] = {
buf : 		.mem = {
buf : 			.start = 0x00000000,
buf : 			.size  = 0x000177c0
buf : 		},
buf : 		.reg = {
buf : 			.start = REGISTERS_BASE,
buf : 			.size  = 0x00008800
buf : 		},
buf : 		.mem2 = {
buf : 			.start = 0x00000000,
buf : 			.size  = 0x00000000
buf : 		},
buf : 		.mem3 = {
buf : 			.start = 0x00000000,
buf : 			.size  = 0x00000000
buf : 		},
buf : 	},
buf : 
buf : 	[PART_BOOT] = { /* in wl12xx we can use a mix of work and down
buf : 			 * partition here */
buf : 		.mem = {
buf : 			.start = 0x00040000,
buf : 			.size  = 0x00014fc0
buf : 		},
buf : 		.reg = {
buf : 			.start = REGISTERS_BASE,
buf : 			.size  = 0x00008800
buf : 		},
buf : 		.mem2 = {
buf : 			.start = 0x00000000,
buf : 			.size  = 0x00000000
buf : 		},
buf : 		.mem3 = {
buf : 			.start = 0x00000000,
buf : 			.size  = 0x00000000
buf : 		},
buf : 	},
buf : 
buf : 	[PART_WORK] = {
buf : 		.mem = {
buf : 			.start = 0x00040000,
buf : 			.size  = 0x00014fc0
buf : 		},
buf : 		.reg = {
buf : 			.start = REGISTERS_BASE,
buf : 			.size  = 0x0000a000
buf : 		},
buf : 		.mem2 = {
buf : 			.start = 0x003004f8,
buf : 			.size  = 0x00000004
buf : 		},
buf : 		.mem3 = {
buf : 			.start = 0x00040404,
buf : 			.size  = 0x00000000
buf : 		},
buf : 	},
buf : 
buf : 	[PART_DRPW] = {
buf : 		.mem = {
buf : 			.start = 0x00040000,
buf : 			.size  = 0x00014fc0
buf : 		},
buf : 		.reg = {
buf : 			.start = DRPW_BASE,
buf : 			.size  = 0x00006000
buf : 		},
buf : 		.mem2 = {
buf : 			.start = 0x00000000,
buf : 			.size  = 0x00000000
buf : 		},
buf : 		.mem3 = {
buf : 			.start = 0x00000000,
buf : 			.size  = 0x00000000
buf : 		}
buf : 	}
buf : };
buf : 
buf : static const int wl12xx_rtable[REG_TABLE_LEN] = {
buf : 	[REG_ECPU_CONTROL]		= WL12XX_REG_ECPU_CONTROL,
buf : 	[REG_INTERRUPT_NO_CLEAR]	= WL12XX_REG_INTERRUPT_NO_CLEAR,
buf : 	[REG_INTERRUPT_ACK]		= WL12XX_REG_INTERRUPT_ACK,
buf : 	[REG_COMMAND_MAILBOX_PTR]	= WL12XX_REG_COMMAND_MAILBOX_PTR,
buf : 	[REG_EVENT_MAILBOX_PTR]		= WL12XX_REG_EVENT_MAILBOX_PTR,
buf : 	[REG_INTERRUPT_TRIG]		= WL12XX_REG_INTERRUPT_TRIG,
buf : 	[REG_INTERRUPT_MASK]		= WL12XX_REG_INTERRUPT_MASK,
buf : 	[REG_PC_ON_RECOVERY]		= WL12XX_SCR_PAD4,
buf : 	[REG_CHIP_ID_B]			= WL12XX_CHIP_ID_B,
buf : 	[REG_CMD_MBOX_ADDRESS]		= WL12XX_CMD_MBOX_ADDRESS,
buf : 
buf : 	/* data access memory addresses, used with partition translation */
buf : 	[REG_SLV_MEM_DATA]		= WL1271_SLV_MEM_DATA,
buf : 	[REG_SLV_REG_DATA]		= WL1271_SLV_REG_DATA,
buf : 
buf : 	/* raw data access memory addresses */
buf : 	[REG_RAW_FW_STATUS_ADDR]	= FW_STATUS_ADDR,
buf : };
buf : 
buf : /* TODO: maybe move to a new header file? */
buf : #define WL127X_FW_NAME_MULTI	"ti-connectivity/wl127x-fw-5-mr.bin"
buf : #define WL127X_FW_NAME_SINGLE	"ti-connectivity/wl127x-fw-5-sr.bin"
buf : #define WL127X_PLT_FW_NAME	"ti-connectivity/wl127x-fw-5-plt.bin"
buf : 
buf : #define WL128X_FW_NAME_MULTI	"ti-connectivity/wl128x-fw-5-mr.bin"
buf : #define WL128X_FW_NAME_SINGLE	"ti-connectivity/wl128x-fw-5-sr.bin"
buf : #define WL128X_PLT_FW_NAME	"ti-connectivity/wl128x-fw-5-plt.bin"
buf : 
buf : static int wl127x_prepare_read(struct wl1271 *wl, u32 rx_desc, u32 len)
buf : {
buf : 	int ret;
buf : 
buf : 	if (wl->chip.id != CHIP_ID_128X_PG20) {
if (wl->chip.id != CHIP_ID_128X_PG20) { 
buf : 		struct wl1271_acx_mem_map *wl_mem_map = wl->target_mem_map;
buf : 		struct wl12xx_priv *priv = wl->priv;
buf : 
buf : 		/*
buf : 		 * Choose the block we want to read
buf : 		 * For aggregated packets, only the first memory block
buf : 		 * should be retrieved. The FW takes care of the rest.
buf : 		 */
buf : 		u32 mem_block = rx_desc & RX_MEM_BLOCK_MASK;
buf : 
buf : 		priv->rx_mem_addr->addr = (mem_block << 8) +
buf : 			le32_to_cpu(wl_mem_map->packet_memory_pool_start);
buf : 
buf : 		priv->rx_mem_addr->addr_extra = priv->rx_mem_addr->addr + 4;
buf : 
buf : 		ret = wlcore_write(wl, WL1271_SLV_REG_DATA, priv->rx_mem_addr,
buf : 				   sizeof(*priv->rx_mem_addr), false);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			return ret;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl12xx_identify_chip(struct wl1271 *wl)
ify_chip(struct wl1271 *wl) 
buf : {
buf : 	int ret = 0;
buf : 
buf : 	switch (wl->chip.id) {
buf : 	case CHIP_ID_127X_PG10:
buf : 		wl1271_warning("chip id 0x%x (1271 PG10) support is obsolete",
buf : 			       wl->chip.id);
buf : 
buf : 		wl->quirks |= WLCORE_QUIRK_LEGACY_NVS |
buf : 			      WLCORE_QUIRK_DUAL_PROBE_TMPL |
buf : 			      WLCORE_QUIRK_TKIP_HEADER_SPACE |
buf : 			      WLCORE_QUIRK_START_STA_FAILS |
buf : 			      WLCORE_QUIRK_AP_ZERO_SESSION_ID;
buf : 		wl->sr_fw_name = WL127X_FW_NAME_SINGLE;
buf : 		wl->mr_fw_name = WL127X_FW_NAME_MULTI;
buf : 		memcpy(&wl->conf.mem, &wl12xx_default_priv_conf.mem_wl127x,
buf : 		       sizeof(wl->conf.mem));
buf : 
buf : 		/* read data preparation is only needed by wl127x */
buf : 		wl->ops->prepare_read = wl127x_prepare_read;
buf : 
buf : 		wlcore_set_min_fw_ver(wl, WL127X_CHIP_VER,
buf : 			      WL127X_IFTYPE_SR_VER,  WL127X_MAJOR_SR_VER,
buf : 			      WL127X_SUBTYPE_SR_VER, WL127X_MINOR_SR_VER,
buf : 			      WL127X_IFTYPE_MR_VER,  WL127X_MAJOR_MR_VER,
buf : 			      WL127X_SUBTYPE_MR_VER, WL127X_MINOR_MR_VER);
buf : 		break;
buf : 
buf : 	case CHIP_ID_127X_PG20:
buf : 		wl1271_debug(DEBUG_BOOT, "chip id 0x%x (1271 PG20)",
buf : 			     wl->chip.id);
buf : 
buf : 		wl->quirks |= WLCORE_QUIRK_LEGACY_NVS |
buf : 			      WLCORE_QUIRK_DUAL_PROBE_TMPL |
buf : 			      WLCORE_QUIRK_TKIP_HEADER_SPACE |
buf : 			      WLCORE_QUIRK_START_STA_FAILS |
buf : 			      WLCORE_QUIRK_AP_ZERO_SESSION_ID;
buf : 		wl->plt_fw_name = WL127X_PLT_FW_NAME;
buf : 		wl->sr_fw_name = WL127X_FW_NAME_SINGLE;
buf : 		wl->mr_fw_name = WL127X_FW_NAME_MULTI;
buf : 		memcpy(&wl->conf.mem, &wl12xx_default_priv_conf.mem_wl127x,
buf : 		       sizeof(wl->conf.mem));
buf : 
buf : 		/* read data preparation is only needed by wl127x */
buf : 		wl->ops->prepare_read = wl127x_prepare_read;
buf : 
buf : 		wlcore_set_min_fw_ver(wl, WL127X_CHIP_VER,
buf : 			      WL127X_IFTYPE_SR_VER,  WL127X_MAJOR_SR_VER,
buf : 			      WL127X_SUBTYPE_SR_VER, WL127X_MINOR_SR_VER,
buf : 			      WL127X_IFTYPE_MR_VER,  WL127X_MAJOR_MR_VER,
buf : 			      WL127X_SUBTYPE_MR_VER, WL127X_MINOR_MR_VER);
buf : 		break;
buf : 
buf : 	case CHIP_ID_128X_PG20:
buf : 		wl1271_debug(DEBUG_BOOT, "chip id 0x%x (1283 PG20)",
buf : 			     wl->chip.id);
buf : 		wl->plt_fw_name = WL128X_PLT_FW_NAME;
buf : 		wl->sr_fw_name = WL128X_FW_NAME_SINGLE;
buf : 		wl->mr_fw_name = WL128X_FW_NAME_MULTI;
buf : 
buf : 		/* wl128x requires TX blocksize alignment */
buf : 		wl->quirks |= WLCORE_QUIRK_TX_BLOCKSIZE_ALIGN |
buf : 			      WLCORE_QUIRK_DUAL_PROBE_TMPL |
buf : 			      WLCORE_QUIRK_TKIP_HEADER_SPACE |
buf : 			      WLCORE_QUIRK_START_STA_FAILS |
buf : 			      WLCORE_QUIRK_AP_ZERO_SESSION_ID;
buf : 
buf : 		wlcore_set_min_fw_ver(wl, WL128X_CHIP_VER,
buf : 			      WL128X_IFTYPE_SR_VER,  WL128X_MAJOR_SR_VER,
buf : 			      WL128X_SUBTYPE_SR_VER, WL128X_MINOR_SR_VER,
buf : 			      WL128X_IFTYPE_MR_VER,  WL128X_MAJOR_MR_VER,
buf : 			      WL128X_SUBTYPE_MR_VER, WL128X_MINOR_MR_VER);
buf : 		break;
buf : 	case CHIP_ID_128X_PG10:
buf : 	default:
buf : 		wl1271_warning("unsupported chip id: 0x%x", wl->chip.id);
buf : 		ret = -ENODEV;
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl->fw_mem_block_size = 256;
buf : 	wl->fwlog_end = 0x2000000;
buf : 
buf : 	/* common settings */
buf : 	wl->scan_templ_id_2_4 = CMD_TEMPL_APP_PROBE_REQ_2_4_LEGACY;
buf : 	wl->scan_templ_id_5 = CMD_TEMPL_APP_PROBE_REQ_5_LEGACY;
buf : 	wl->sched_scan_templ_id_2_4 = CMD_TEMPL_CFG_PROBE_REQ_2_4;
buf : 	wl->sched_scan_templ_id_5 = CMD_TEMPL_CFG_PROBE_REQ_5;
buf : 	wl->max_channels_5 = WL12XX_MAX_CHANNELS_5GHZ;
buf : 	wl->ba_rx_session_count_max = WL12XX_RX_BA_MAX_SESSIONS;
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int __must_check wl12xx_top_reg_write(struct wl1271 *wl, int addr,
buf : 					     u16 val)
buf : {
buf : 	int ret;
buf : 
buf : 	/* write address >> 1 + 0x30000 to OCP_POR_CTR */
buf : 	addr = (addr >> 1) + 0x30000;
buf : 	ret = wlcore_write32(wl, WL12XX_OCP_POR_CTR, addr);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* write value to OCP_POR_WDATA */
buf : 	ret = wlcore_write32(wl, WL12XX_OCP_DATA_WRITE, val);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* write 1 to OCP_CMD */
buf : 	ret = wlcore_write32(wl, WL12XX_OCP_CMD, OCP_CMD_WRITE);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int __must_check wl12xx_top_reg_read(struct wl1271 *wl, int addr,
buf : 					    u16 *out)
buf : {
buf : 	u32 val;
buf : 	int timeout = OCP_CMD_LOOP;
buf : 	int ret;
buf : 
buf : 	/* write address >> 1 + 0x30000 to OCP_POR_CTR */
buf : 	addr = (addr >> 1) + 0x30000;
buf : 	ret = wlcore_write32(wl, WL12XX_OCP_POR_CTR, addr);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	/* write 2 to OCP_CMD */
buf : 	ret = wlcore_write32(wl, WL12XX_OCP_CMD, OCP_CMD_READ);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	/* poll for data ready */
for data ready */ 
buf : 	do {
buf : 		ret = wlcore_read32(wl, WL12XX_OCP_DATA_READ, &val);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			return ret;
buf : 	} while (!(val & OCP_READY_MASK) && --timeout);
while (!(val & OCP_READY_MASK) && --timeout); 
buf : 
buf : 	if (!timeout) {
buf : 		wl1271_warning("Top register access timed out.");
buf : 		return -ETIMEDOUT;
buf : 	}
buf : 
buf : 	/* check data status and return if OK */
if OK */ 
buf : 	if ((val & OCP_STATUS_MASK) != OCP_STATUS_OK) {
buf : 		wl1271_warning("Top register access returned error.");
buf : 		return -EIO;
buf : 	}
buf : 
buf : 	if (out)
if (out) 
buf : 		*out = val & 0xffff;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl128x_switch_tcxo_to_fref(struct wl1271 *wl)
buf : {
buf : 	u16 spare_reg;
buf : 	int ret;
buf : 
buf : 	/* Mask bits [2] & [8:4] in the sys_clk_cfg register */
buf : 	ret = wl12xx_top_reg_read(wl, WL_SPARE_REG, &spare_reg);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	if (spare_reg == 0xFFFF)
if (spare_reg == 0xFFFF) 
buf : 		return -EFAULT;
buf : 	spare_reg |= (BIT(3) | BIT(5) | BIT(6));
buf : 	ret = wl12xx_top_reg_write(wl, WL_SPARE_REG, spare_reg);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	/* Enable FREF_CLK_REQ & mux MCS and coex PLLs to FREF */
buf : 	ret = wl12xx_top_reg_write(wl, SYS_CLK_CFG_REG,
buf : 				   WL_CLK_REQ_TYPE_PG2 | MCS_PLL_CLK_SEL_FREF);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	/* Delay execution for 15msec, to let the HW settle */
for 15msec, to let the HW settle */ 
buf : 	mdelay(15);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static bool wl128x_is_tcxo_valid(struct wl1271 *wl)
buf : {
buf : 	u16 tcxo_detection;
buf : 	int ret;
buf : 
buf : 	ret = wl12xx_top_reg_read(wl, TCXO_CLK_DETECT_REG, &tcxo_detection);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return false;
buf : 
buf : 	if (tcxo_detection & TCXO_DET_FAILED)
if (tcxo_detection & TCXO_DET_FAILED) 
buf : 		return false;
buf : 
buf : 	return true;
buf : }
buf : 
buf : static bool wl128x_is_fref_valid(struct wl1271 *wl)
buf : {
buf : 	u16 fref_detection;
buf : 	int ret;
buf : 
buf : 	ret = wl12xx_top_reg_read(wl, FREF_CLK_DETECT_REG, &fref_detection);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return false;
buf : 
buf : 	if (fref_detection & FREF_CLK_DETECT_FAIL)
if (fref_detection & FREF_CLK_DETECT_FAIL) 
buf : 		return false;
buf : 
buf : 	return true;
buf : }
buf : 
buf : static int wl128x_manually_configure_mcs_pll(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wl12xx_top_reg_write(wl, MCS_PLL_M_REG, MCS_PLL_M_REG_VAL);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl12xx_top_reg_write(wl, MCS_PLL_N_REG, MCS_PLL_N_REG_VAL);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl12xx_top_reg_write(wl, MCS_PLL_CONFIG_REG,
buf : 				   MCS_PLL_CONFIG_REG_VAL);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl128x_configure_mcs_pll(struct wl1271 *wl, int clk)
buf : {
buf : 	u16 spare_reg;
buf : 	u16 pll_config;
buf : 	u8 input_freq;
buf : 	struct wl12xx_priv *priv = wl->priv;
buf : 	int ret;
buf : 
buf : 	/* Mask bits [3:1] in the sys_clk_cfg register */
buf : 	ret = wl12xx_top_reg_read(wl, WL_SPARE_REG, &spare_reg);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	if (spare_reg == 0xFFFF)
if (spare_reg == 0xFFFF) 
buf : 		return -EFAULT;
buf : 	spare_reg |= BIT(2);
buf : 	ret = wl12xx_top_reg_write(wl, WL_SPARE_REG, spare_reg);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	/* Handle special cases of the TCXO clock */
buf : 	if (priv->tcxo_clock == WL12XX_TCXOCLOCK_16_8 ||
if (priv->tcxo_clock == WL12XX_TCXOCLOCK_16_8 || 
buf : 	    priv->tcxo_clock == WL12XX_TCXOCLOCK_33_6)
buf : 		return wl128x_manually_configure_mcs_pll(wl);
buf : 
buf : 	/* Set the input frequency according to the selected clock source */
buf : 	input_freq = (clk & 1) + 1;
buf : 
buf : 	ret = wl12xx_top_reg_read(wl, MCS_PLL_CONFIG_REG, &pll_config);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	if (pll_config == 0xFFFF)
if (pll_config == 0xFFFF) 
buf : 		return -EFAULT;
buf : 	pll_config |= (input_freq << MCS_SEL_IN_FREQ_SHIFT);
buf : 	pll_config |= MCS_PLL_ENABLE_HP;
buf : 	ret = wl12xx_top_reg_write(wl, MCS_PLL_CONFIG_REG, pll_config);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : /*
buf :  * WL128x has two clocks input - TCXO and FREF.
buf :  * TCXO is the main clock of the device, while FREF is used to sync
while FREF is used to sync 
buf :  * between the GPS and the cellular modem.
buf :  * In cases where TCXO is 32.736MHz or 16.368MHz, the FREF will be used
buf :  * as the WLAN/BT main clock.
buf :  */
buf : static int wl128x_boot_clk(struct wl1271 *wl, int *selected_clock)
buf : {
buf : 	struct wl12xx_priv *priv = wl->priv;
buf : 	u16 sys_clk_cfg;
buf : 	int ret;
buf : 
buf : 	/* For XTAL-only modes, FREF will be used after switching from TCXO */
buf : 	if (priv->ref_clock == WL12XX_REFCLOCK_26_XTAL ||
if (priv->ref_clock == WL12XX_REFCLOCK_26_XTAL || 
buf : 	    priv->ref_clock == WL12XX_REFCLOCK_38_XTAL) {
buf : 		if (!wl128x_switch_tcxo_to_fref(wl))
if (!wl128x_switch_tcxo_to_fref(wl)) 
buf : 			return -EINVAL;
buf : 		goto fref_clk;
buf : 	}
buf : 
buf : 	/* Query the HW, to determine which clock source we should use */
buf : 	ret = wl12xx_top_reg_read(wl, SYS_CLK_CFG_REG, &sys_clk_cfg);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	if (sys_clk_cfg == 0xFFFF)
if (sys_clk_cfg == 0xFFFF) 
buf : 		return -EINVAL;
buf : 	if (sys_clk_cfg & PRCM_CM_EN_MUX_WLAN_FREF)
if (sys_clk_cfg & PRCM_CM_EN_MUX_WLAN_FREF) 
buf : 		goto fref_clk;
buf : 
buf : 	/* If TCXO is either 32.736MHz or 16.368MHz, switch to FREF */
buf : 	if (priv->tcxo_clock == WL12XX_TCXOCLOCK_16_368 ||
if (priv->tcxo_clock == WL12XX_TCXOCLOCK_16_368 || 
buf : 	    priv->tcxo_clock == WL12XX_TCXOCLOCK_32_736) {
buf : 		if (!wl128x_switch_tcxo_to_fref(wl))
if (!wl128x_switch_tcxo_to_fref(wl)) 
buf : 			return -EINVAL;
buf : 		goto fref_clk;
buf : 	}
buf : 
buf : 	/* TCXO clock is selected */
buf : 	if (!wl128x_is_tcxo_valid(wl))
if (!wl128x_is_tcxo_valid(wl)) 
buf : 		return -EINVAL;
buf : 	*selected_clock = priv->tcxo_clock;
buf : 	goto config_mcs_pll;
buf : 
buf : fref_clk:
buf : 	/* FREF clock is selected */
buf : 	if (!wl128x_is_fref_valid(wl))
if (!wl128x_is_fref_valid(wl)) 
buf : 		return -EINVAL;
buf : 	*selected_clock = priv->ref_clock;
buf : 
buf : config_mcs_pll:
buf : 	return wl128x_configure_mcs_pll(wl, *selected_clock);
buf : }
buf : 
buf : static int wl127x_boot_clk(struct wl1271 *wl)
buf : {
buf : 	struct wl12xx_priv *priv = wl->priv;
buf : 	u32 pause;
buf : 	u32 clk;
buf : 	int ret;
buf : 
buf : 	if (WL127X_PG_GET_MAJOR(wl->hw_pg_ver) < 3)
if (WL127X_PG_GET_MAJOR(wl->hw_pg_ver) < 3) 
buf : 		wl->quirks |= WLCORE_QUIRK_END_OF_TRANSACTION;
buf : 
buf : 	if (priv->ref_clock == CONF_REF_CLK_19_2_E ||
if (priv->ref_clock == CONF_REF_CLK_19_2_E || 
buf : 	    priv->ref_clock == CONF_REF_CLK_38_4_E ||
buf : 	    priv->ref_clock == CONF_REF_CLK_38_4_M_XTAL)
buf : 		/* ref clk: 19.2/38.4/38.4-XTAL */
buf : 		clk = 0x3;
buf : 	else if (priv->ref_clock == CONF_REF_CLK_26_E ||
if (priv->ref_clock == CONF_REF_CLK_26_E || 
buf : 		 priv->ref_clock == CONF_REF_CLK_26_M_XTAL ||
buf : 		 priv->ref_clock == CONF_REF_CLK_52_E)
buf : 		/* ref clk: 26/52 */
buf : 		clk = 0x5;
buf : 	else
buf : 		return -EINVAL;
buf : 
buf : 	if (priv->ref_clock != CONF_REF_CLK_19_2_E) {
if (priv->ref_clock != CONF_REF_CLK_19_2_E) { 
buf : 		u16 val;
buf : 		/* Set clock type (open drain) */
buf : 		ret = wl12xx_top_reg_read(wl, OCP_REG_CLK_TYPE, &val);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		val &= FREF_CLK_TYPE_BITS;
buf : 		ret = wl12xx_top_reg_write(wl, OCP_REG_CLK_TYPE, val);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		/* Set clock pull mode (no pull) */
buf : 		ret = wl12xx_top_reg_read(wl, OCP_REG_CLK_PULL, &val);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		val |= NO_PULL;
buf : 		ret = wl12xx_top_reg_write(wl, OCP_REG_CLK_PULL, val);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	} else {
buf : 		u16 val;
buf : 		/* Set clock polarity */
buf : 		ret = wl12xx_top_reg_read(wl, OCP_REG_CLK_POLARITY, &val);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		val &= FREF_CLK_POLARITY_BITS;
buf : 		val |= CLK_REQ_OUTN_SEL;
buf : 		ret = wl12xx_top_reg_write(wl, OCP_REG_CLK_POLARITY, val);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	ret = wlcore_write32(wl, WL12XX_PLL_PARAMETERS, clk);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_read32(wl, WL12XX_PLL_PARAMETERS, &pause);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl1271_debug(DEBUG_BOOT, "pause1 0x%x", pause);
buf : 
buf : 	pause &= ~(WU_COUNTER_PAUSE_VAL);
buf : 	pause |= WU_COUNTER_PAUSE_VAL;
buf : 	ret = wlcore_write32(wl, WL12XX_WU_COUNTER_PAUSE, pause);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_boot_soft_reset(struct wl1271 *wl)
buf : {
buf : 	unsigned long timeout;
buf : 	u32 boot_data;
buf : 	int ret = 0;
buf : 
buf : 	/* perform soft reset */
form soft reset */ 
buf : 	ret = wlcore_write32(wl, WL12XX_SLV_SOFT_RESET, ACX_SLV_SOFT_RESET_BIT);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* SOFT_RESET is self clearing */
buf : 	timeout = jiffies + usecs_to_jiffies(SOFT_RESET_MAX_TIME);
iffies + usecs_to_jiffies(SOFT_RESET_MAX_TIME); 
buf : 	while (1) {
while (1) { 
buf : 		ret = wlcore_read32(wl, WL12XX_SLV_SOFT_RESET, &boot_data);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		wl1271_debug(DEBUG_BOOT, "soft reset bootdata 0x%x", boot_data);
buf : 		if ((boot_data & ACX_SLV_SOFT_RESET_BIT) == 0)
if ((boot_data & ACX_SLV_SOFT_RESET_BIT) == 0) 
buf : 			break;
buf : 
buf : 		if (time_after(jiffies, timeout)) {
if (time_after(jiffies, timeout)) { 
buf : 			/* 1.2 check pWhalBus->uSelfClearTime if the
buf : 			 * timeout was reached */
buf : 			wl1271_error("soft reset timeout");
buf : 			return -1;
buf : 		}
buf : 
buf : 		udelay(SOFT_RESET_STALL_TIME);
buf : 	}
buf : 
buf : 	/* disable Rx/Tx */
buf : 	ret = wlcore_write32(wl, WL12XX_ENABLE, 0x0);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* disable auto calibration on start*/
buf : 	ret = wlcore_write32(wl, WL12XX_SPARE_A2, 0xffff);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_pre_boot(struct wl1271 *wl)
buf : {
buf : 	struct wl12xx_priv *priv = wl->priv;
buf : 	int ret = 0;
buf : 	u32 clk;
buf : 	int selected_clock = -1;
buf : 
buf : 	if (wl->chip.id == CHIP_ID_128X_PG20) {
if (wl->chip.id == CHIP_ID_128X_PG20) { 
buf : 		ret = wl128x_boot_clk(wl, &selected_clock);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	} else {
buf : 		ret = wl127x_boot_clk(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	/* Continue the ELP wake up sequence */
buf : 	ret = wlcore_write32(wl, WL12XX_WELP_ARM_COMMAND, WELP_ARM_COMMAND_VAL);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	udelay(500);
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_DRPW]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* Read-modify-write DRPW_SCRATCH_START register (see next state)
ify-write DRPW_SCRATCH_START register (see next state) 
buf : 	   to be used by DRPw FW. The RTRIM value will be added by the FW
buf : 	   before taking DRPw out of reset */
fore taking DRPw out of reset */ 
buf : 
buf : 	ret = wlcore_read32(wl, WL12XX_DRPW_SCRATCH_START, &clk);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl1271_debug(DEBUG_BOOT, "clk2 0x%x", clk);
buf : 
buf : 	if (wl->chip.id == CHIP_ID_128X_PG20)
if (wl->chip.id == CHIP_ID_128X_PG20) 
buf : 		clk |= ((selected_clock & 0x3) << 1) << 4;
buf : 	else
buf : 		clk |= (priv->ref_clock << 1) << 4;
buf : 
buf : 	ret = wlcore_write32(wl, WL12XX_DRPW_SCRATCH_START, clk);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_WORK]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* Disable interrupts */
buf : 	ret = wlcore_write_reg(wl, REG_INTERRUPT_MASK, WL1271_ACX_INTR_ALL);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_boot_soft_reset(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_pre_upload(struct wl1271 *wl)
buf : {
buf : 	u32 tmp;
buf : 	u16 polarity;
buf : 	int ret;
buf : 
buf : 	/* write firmware's last address (ie. it's length) to
buf : 	 * ACX_EEPROMLESS_IND_REG */
buf : 	wl1271_debug(DEBUG_BOOT, "ACX_EEPROMLESS_IND_REG");
buf : 
buf : 	ret = wlcore_write32(wl, WL12XX_EEPROMLESS_IND, WL12XX_EEPROMLESS_IND);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_read_reg(wl, REG_CHIP_ID_B, &tmp);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl1271_debug(DEBUG_BOOT, "chip id 0x%x", tmp);
buf : 
buf : 	/* 6. read the EEPROM parameters */
buf : 	ret = wlcore_read32(wl, WL12XX_SCR_PAD2, &tmp);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* WL1271: The reference driver skips steps 7 to 10 (jumps directly
buf : 	 * to upload_fw) */
buf : 
buf : 	if (wl->chip.id == CHIP_ID_128X_PG20) {
if (wl->chip.id == CHIP_ID_128X_PG20) { 
buf : 		ret = wl12xx_top_reg_write(wl, SDIO_IO_DS, HCI_IO_DS_6MA);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	/* polarity must be set before the firmware is loaded */
fore the firmware is loaded */ 
buf : 	ret = wl12xx_top_reg_read(wl, OCP_REG_POLARITY, &polarity);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* We use HIGH polarity, so unset the LOW bit */
buf : 	polarity &= ~POLARITY_LOW;
buf : 	ret = wl12xx_top_reg_write(wl, OCP_REG_POLARITY, polarity);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_enable_interrupts(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wlcore_write_reg(wl, REG_INTERRUPT_MASK,
buf : 			       WL12XX_ACX_ALL_EVENTS_VECTOR);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wlcore_enable_interrupts(wl);
buf : 	ret = wlcore_write_reg(wl, REG_INTERRUPT_MASK,
buf : 			       WL1271_ACX_INTR_ALL & ~(WL12XX_INTR_MASK));
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto disable_interrupts;
buf : 
buf : 	ret = wlcore_write32(wl, WL12XX_HI_CFG, HI_CFG_DEF_VAL);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto disable_interrupts;
buf : 
buf : 	return ret;
buf : 
buf : disable_interrupts:
buf : 	wlcore_disable_interrupts(wl);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_boot(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wl12xx_pre_boot(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_boot_upload_nvs(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl12xx_pre_upload(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_boot_upload_firmware(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl->event_mask = BSS_LOSE_EVENT_ID |
buf : 		REGAINED_BSS_EVENT_ID |
buf : 		SCAN_COMPLETE_EVENT_ID |
buf : 		ROLE_STOP_COMPLETE_EVENT_ID |
buf : 		RSSI_SNR_TRIGGER_0_EVENT_ID |
buf : 		PSPOLL_DELIVERY_FAILURE_EVENT_ID |
buf : 		SOFT_GEMINI_SENSE_EVENT_ID |
buf : 		PERIODIC_SCAN_REPORT_EVENT_ID |
buf : 		PERIODIC_SCAN_COMPLETE_EVENT_ID |
buf : 		DUMMY_PACKET_EVENT_ID |
buf : 		PEER_REMOVE_COMPLETE_EVENT_ID |
buf : 		BA_SESSION_RX_CONSTRAINT_EVENT_ID |
buf : 		REMAIN_ON_CHANNEL_COMPLETE_EVENT_ID |
buf : 		INACTIVE_STA_EVENT_ID |
buf : 		CHANNEL_SWITCH_COMPLETE_EVENT_ID;
buf : 
buf : 	wl->ap_event_mask = MAX_TX_RETRY_EVENT_ID;
buf : 
buf : 	ret = wlcore_boot_run_firmware(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl12xx_enable_interrupts(wl);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_trigger_cmd(struct wl1271 *wl, int cmd_box_addr,
buf : 			       void *buf, size_t len)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wlcore_write(wl, cmd_box_addr, buf, len, false);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	ret = wlcore_write_reg(wl, REG_INTERRUPT_TRIG, WL12XX_INTR_TRIG_CMD);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_ack_event(struct wl1271 *wl)
buf : {
buf : 	return wlcore_write_reg(wl, REG_INTERRUPT_TRIG,
buf : 				WL12XX_INTR_TRIG_EVENT_ACK);
buf : }
buf : 
buf : static u32 wl12xx_calc_tx_blocks(struct wl1271 *wl, u32 len, u32 spare_blks)
buf : {
buf : 	u32 blk_size = WL12XX_TX_HW_BLOCK_SIZE;
buf : 	u32 align_len = wlcore_calc_packet_alignment(wl, len);
buf : 
buf : 	return (align_len + blk_size - 1) / blk_size + spare_blks;
buf : }
buf : 
buf : static void
buf : wl12xx_set_tx_desc_blocks(struct wl1271 *wl, struct wl1271_tx_hw_descr *desc,
buf : 			  u32 blks, u32 spare_blks)
buf : {
buf : 	if (wl->chip.id == CHIP_ID_128X_PG20) {
if (wl->chip.id == CHIP_ID_128X_PG20) { 
buf : 		desc->wl128x_mem.total_mem_blocks = blks;
buf : 	} else {
buf : 		desc->wl127x_mem.extra_blocks = spare_blks;
buf : 		desc->wl127x_mem.total_mem_blocks = blks;
buf : 	}
buf : }
buf : 
buf : static void
buf : wl12xx_set_tx_desc_data_len(struct wl1271 *wl, struct wl1271_tx_hw_descr *desc,
buf : 			    struct sk_buff *skb)
buf : {
buf : 	u32 aligned_len = wlcore_calc_packet_alignment(wl, skb->len);
buf : 
buf : 	if (wl->chip.id == CHIP_ID_128X_PG20) {
if (wl->chip.id == CHIP_ID_128X_PG20) { 
buf : 		desc->wl128x_mem.extra_bytes = aligned_len - skb->len;
buf : 		desc->length = cpu_to_le16(aligned_len >> 2);
buf : 
buf : 		wl1271_debug(DEBUG_TX,
buf : 			     "tx_fill_hdr: hlid: %d len: %d life: %d mem: %d extra: %d",
ife: %d mem: %d extra: %d", 
buf : 			     desc->hlid,
buf : 			     le16_to_cpu(desc->length),
buf : 			     le16_to_cpu(desc->life_time),
ife_time), 
buf : 			     desc->wl128x_mem.total_mem_blocks,
buf : 			     desc->wl128x_mem.extra_bytes);
buf : 	} else {
buf : 		/* calculate number of padding bytes */
buf : 		int pad = aligned_len - skb->len;
buf : 		desc->tx_attr |=
buf : 			cpu_to_le16(pad << TX_HW_ATTR_OFST_LAST_WORD_PAD);
buf : 
buf : 		/* Store the aligned length in terms of words */
buf : 		desc->length = cpu_to_le16(aligned_len >> 2);
buf : 
buf : 		wl1271_debug(DEBUG_TX,
buf : 			     "tx_fill_hdr: pad: %d hlid: %d len: %d life: %d mem: %d",
ife: %d mem: %d", 
buf : 			     pad, desc->hlid,
buf : 			     le16_to_cpu(desc->length),
buf : 			     le16_to_cpu(desc->life_time),
ife_time), 
buf : 			     desc->wl127x_mem.total_mem_blocks);
buf : 	}
buf : }
buf : 
buf : static enum wl_rx_buf_align
buf : wl12xx_get_rx_buf_align(struct wl1271 *wl, u32 rx_desc)
buf : {
buf : 	if (rx_desc & RX_BUF_UNALIGNED_PAYLOAD)
if (rx_desc & RX_BUF_UNALIGNED_PAYLOAD) 
buf : 		return WLCORE_RX_BUF_UNALIGNED;
buf : 
buf : 	return WLCORE_RX_BUF_ALIGNED;
buf : }
buf : 
buf : static u32 wl12xx_get_rx_packet_len(struct wl1271 *wl, void *rx_data,
buf : 				    u32 data_len)
buf : {
buf : 	struct wl1271_rx_descriptor *desc = rx_data;
buf : 
buf : 	/* invalid packet */
buf : 	if (data_len < sizeof(*desc) ||
if (data_len < sizeof(*desc) || 
buf : 	    data_len < sizeof(*desc) + desc->pad_len)
buf : 		return 0;
buf : 
buf : 	return data_len - sizeof(*desc) - desc->pad_len;
buf : }
buf : 
buf : static int wl12xx_tx_delayed_compl(struct wl1271 *wl)
buf : {
buf : 	if (wl->fw_status->tx_results_counter ==
if (wl->fw_status->tx_results_counter == 
buf : 	    (wl->tx_results_count & 0xff))
buf : 		return 0;
buf : 
buf : 	return wlcore_tx_complete(wl);
buf : }
buf : 
buf : static int wl12xx_hw_init(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	if (wl->chip.id == CHIP_ID_128X_PG20) {
if (wl->chip.id == CHIP_ID_128X_PG20) { 
buf : 		u32 host_cfg_bitmap = HOST_IF_CFG_RX_FIFO_ENABLE;
buf : 
buf : 		ret = wl128x_cmd_general_parms(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		/*
buf : 		 * If we are in calibrator based auto detect then we got the FEM nr
buf : 		 * in wl->fem_manuf. No need to continue further
buf : 		 */
buf : 		if (wl->plt_mode == PLT_FEM_DETECT)
if (wl->plt_mode == PLT_FEM_DETECT) 
buf : 			goto out;
buf : 
buf : 		ret = wl128x_cmd_radio_parms(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		if (wl->quirks & WLCORE_QUIRK_TX_BLOCKSIZE_ALIGN)
if (wl->quirks & WLCORE_QUIRK_TX_BLOCKSIZE_ALIGN) 
buf : 			/* Enable SDIO padding */
buf : 			host_cfg_bitmap |= HOST_IF_CFG_TX_PAD_TO_SDIO_BLK;
buf : 
buf : 		/* Must be before wl1271_acx_init_mem_config() */
fore wl1271_acx_init_mem_config() */ 
buf : 		ret = wl1271_acx_host_if_cfg_bitmap(wl, host_cfg_bitmap);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	} else {
buf : 		ret = wl1271_cmd_general_parms(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		/*
buf : 		 * If we are in calibrator based auto detect then we got the FEM nr
buf : 		 * in wl->fem_manuf. No need to continue further
buf : 		 */
buf : 		if (wl->plt_mode == PLT_FEM_DETECT)
if (wl->plt_mode == PLT_FEM_DETECT) 
buf : 			goto out;
buf : 
buf : 		ret = wl1271_cmd_radio_parms(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 		ret = wl1271_cmd_ext_radio_parms(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static void wl12xx_convert_fw_status(struct wl1271 *wl, void *raw_fw_status,
buf : 				     struct wl_fw_status *fw_status)
buf : {
buf : 	struct wl12xx_fw_status *int_fw_status = raw_fw_status;
buf : 
buf : 	fw_status->intr = le32_to_cpu(int_fw_status->intr);
buf : 	fw_status->fw_rx_counter = int_fw_status->fw_rx_counter;
buf : 	fw_status->drv_rx_counter = int_fw_status->drv_rx_counter;
buf : 	fw_status->tx_results_counter = int_fw_status->tx_results_counter;
buf : 	fw_status->rx_pkt_descs = int_fw_status->rx_pkt_descs;
buf : 
buf : 	fw_status->fw_localtime = le32_to_cpu(int_fw_status->fw_localtime);
buf : 	fw_status->link_ps_bitmap = le32_to_cpu(int_fw_status->link_ps_bitmap);
buf : 	fw_status->link_fast_bitmap =
buf : 			le32_to_cpu(int_fw_status->link_fast_bitmap);
buf : 	fw_status->total_released_blks =
buf : 			le32_to_cpu(int_fw_status->total_released_blks);
buf : 	fw_status->tx_total = le32_to_cpu(int_fw_status->tx_total);
buf : 
buf : 	fw_status->counters.tx_released_pkts =
buf : 			int_fw_status->counters.tx_released_pkts;
buf : 	fw_status->counters.tx_lnk_free_pkts =
buf : 			int_fw_status->counters.tx_lnk_free_pkts;
buf : 	fw_status->counters.tx_voice_released_blks =
buf : 			int_fw_status->counters.tx_voice_released_blks;
buf : 	fw_status->counters.tx_last_rate =
buf : 			int_fw_status->counters.tx_last_rate;
buf : 
buf : 	fw_status->log_start_addr = le32_to_cpu(int_fw_status->log_start_addr);
buf : }
buf : 
buf : static u32 wl12xx_sta_get_ap_rate_mask(struct wl1271 *wl,
buf : 				       struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	return wlvif->rate_set;
buf : }
buf : 
buf : static void wl12xx_conf_init(struct wl1271 *wl)
buf : {
buf : 	struct wl12xx_priv *priv = wl->priv;
buf : 
buf : 	/* apply driver default configuration */
buf : 	memcpy(&wl->conf, &wl12xx_conf, sizeof(wl12xx_conf));
buf : 
buf : 	/* apply default private configuration */
buf : 	memcpy(&priv->conf, &wl12xx_default_priv_conf, sizeof(priv->conf));
buf : }
buf : 
buf : static bool wl12xx_mac_in_fuse(struct wl1271 *wl)
buf : {
buf : 	bool supported = false;
buf : 	u8 major, minor;
buf : 
buf : 	if (wl->chip.id == CHIP_ID_128X_PG20) {
if (wl->chip.id == CHIP_ID_128X_PG20) { 
buf : 		major = WL128X_PG_GET_MAJOR(wl->hw_pg_ver);
buf : 		minor = WL128X_PG_GET_MINOR(wl->hw_pg_ver);
buf : 
buf : 		/* in wl128x we have the MAC address if the PG is >= (2, 1) */
if the PG is >= (2, 1) */ 
buf : 		if (major > 2 || (major == 2 && minor >= 1))
buf : 			supported = true;
buf : 	} else {
buf : 		major = WL127X_PG_GET_MAJOR(wl->hw_pg_ver);
buf : 		minor = WL127X_PG_GET_MINOR(wl->hw_pg_ver);
buf : 
buf : 		/* in wl127x we have the MAC address if the PG is >= (3, 1) */
if the PG is >= (3, 1) */ 
buf : 		if (major == 3 && minor >= 1)
buf : 			supported = true;
buf : 	}
buf : 
buf : 	wl1271_debug(DEBUG_PROBE,
buf : 		     "PG Ver major = %d minor = %d, MAC %s present",
buf : 		     major, minor, supported ? "is" : "is not");
buf : 
buf : 	return supported;
buf : }
buf : 
buf : static int wl12xx_get_fuse_mac(struct wl1271 *wl)
buf : {
buf : 	u32 mac1, mac2;
buf : 	int ret;
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_DRPW]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_read32(wl, WL12XX_REG_FUSE_BD_ADDR_1, &mac1);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_read32(wl, WL12XX_REG_FUSE_BD_ADDR_2, &mac2);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* these are the two parts of the BD_ADDR */
buf : 	wl->fuse_oui_addr = ((mac2 & 0xffff) << 8) +
buf : 		((mac1 & 0xff000000) >> 24);
buf : 	wl->fuse_nic_addr = mac1 & 0xffffff;
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_DOWN]);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_get_pg_ver(struct wl1271 *wl, s8 *ver)
buf : {
buf : 	u16 die_info;
buf : 	int ret;
buf : 
buf : 	if (wl->chip.id == CHIP_ID_128X_PG20)
if (wl->chip.id == CHIP_ID_128X_PG20) 
buf : 		ret = wl12xx_top_reg_read(wl, WL128X_REG_FUSE_DATA_2_1,
buf : 					  &die_info);
buf : 	else
buf : 		ret = wl12xx_top_reg_read(wl, WL127X_REG_FUSE_DATA_2_1,
buf : 					  &die_info);
buf : 
buf : 	if (ret >= 0 && ver)
if (ret >= 0 && ver) 
buf : 		*ver = (s8)((die_info & PG_VER_MASK) >> PG_VER_OFFSET);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_get_mac(struct wl1271 *wl)
buf : {
buf : 	if (wl12xx_mac_in_fuse(wl))
if (wl12xx_mac_in_fuse(wl)) 
buf : 		return wl12xx_get_fuse_mac(wl);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void wl12xx_set_tx_desc_csum(struct wl1271 *wl,
buf : 				    struct wl1271_tx_hw_descr *desc,
buf : 				    struct sk_buff *skb)
buf : {
buf : 	desc->wl12xx_reserved = 0;
buf : }
buf : 
buf : static int wl12xx_plt_init(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wl->ops->boot(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl->ops->hw_init(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_irq_disable;
buf : 
buf : 	/*
buf : 	 * If we are in calibrator based auto detect then we got the FEM nr
buf : 	 * in wl->fem_manuf. No need to continue further
buf : 	 */
buf : 	if (wl->plt_mode == PLT_FEM_DETECT)
if (wl->plt_mode == PLT_FEM_DETECT) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_acx_init_mem_config(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_irq_disable;
buf : 
buf : 	ret = wl12xx_acx_mem_cfg(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_free_memmap;
buf : 
buf : 	/* Enable data path */
buf : 	ret = wl1271_cmd_data_path(wl, 1);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_free_memmap;
buf : 
buf : 	/* Configure for CAM power saving (ie. always active) */
for CAM power saving (ie. always active) */ 
buf : 	ret = wl1271_acx_sleep_auth(wl, WL1271_PSM_CAM);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_free_memmap;
buf : 
buf : 	/* configure PM */
buf : 	ret = wl1271_acx_pm_config(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_free_memmap;
buf : 
buf : 	goto out;
buf : 
buf : out_free_memmap:
buf : 	kfree(wl->target_mem_map);
buf : 	wl->target_mem_map = NULL;
buf : 
buf : out_irq_disable:
buf : 	mutex_unlock(&wl->mutex);
buf : 	/* Unlocking the mutex in the middle of handling is
buf : 	   inherently unsafe. In this case we deem it safe to do,
buf : 	   because we need to let any possibly pending IRQ out of
buf : 	   the system (and while we are WL1271_STATE_OFF the IRQ
while we are WL1271_STATE_OFF the IRQ 
buf : 	   work function will not do anything.) Also, any other
buf : 	   possible concurrent operations will fail due to the
buf : 	   current state, hence the wl1271 struct should be safe. */
buf : 	wlcore_disable_interrupts(wl);
buf : 	mutex_lock(&wl->mutex);
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_get_spare_blocks(struct wl1271 *wl, bool is_gem)
buf : {
buf : 	if (is_gem)
if (is_gem) 
buf : 		return WL12XX_TX_HW_BLOCK_GEM_SPARE;
buf : 
buf : 	return WL12XX_TX_HW_BLOCK_SPARE_DEFAULT;
buf : }
buf : 
buf : static int wl12xx_set_key(struct wl1271 *wl, enum set_key_cmd cmd,
buf : 			  struct ieee80211_vif *vif,
if *vif, 
buf : 			  struct ieee80211_sta *sta,
buf : 			  struct ieee80211_key_conf *key_conf)
buf : {
buf : 	return wlcore_set_key(wl, cmd, vif, sta, key_conf);
if, sta, key_conf); 
buf : }
buf : 
buf : static int wl12xx_set_peer_cap(struct wl1271 *wl,
buf : 			       struct ieee80211_sta_ht_cap *ht_cap,
buf : 			       bool allow_ht_operation,
buf : 			       u32 rate_set, u8 hlid)
buf : {
buf : 	return wl1271_acx_set_ht_capabilities(wl, ht_cap, allow_ht_operation,
buf : 					      hlid);
buf : }
buf : 
buf : static bool wl12xx_lnk_high_prio(struct wl1271 *wl, u8 hlid,
buf : 				 struct wl1271_link *lnk)
buf : {
buf : 	u8 thold;
buf : 
buf : 	if (test_bit(hlid, (unsigned long *)&wl->fw_fast_lnk_map))
if (test_bit(hlid, (unsigned long *)&wl->fw_fast_lnk_map)) 
buf : 		thold = wl->conf.tx.fast_link_thold;
buf : 	else
buf : 		thold = wl->conf.tx.slow_link_thold;
buf : 
buf : 	return lnk->allocated_pkts < thold;
buf : }
buf : 
buf : static bool wl12xx_lnk_low_prio(struct wl1271 *wl, u8 hlid,
buf : 				struct wl1271_link *lnk)
buf : {
buf : 	/* any link is good for low priority */
for low priority */ 
buf : 	return true;
buf : }
buf : 
buf : static u32 wl12xx_convert_hwaddr(struct wl1271 *wl, u32 hwaddr)
buf : {
buf : 	return hwaddr << 5;
buf : }
buf : 
buf : static int wl12xx_setup(struct wl1271 *wl);
buf : 
buf : static struct wlcore_ops wl12xx_ops = {
buf : 	.setup			= wl12xx_setup,
buf : 	.identify_chip		= wl12xx_identify_chip,
ify_chip		= wl12xx_identify_chip, 
buf : 	.boot			= wl12xx_boot,
buf : 	.plt_init		= wl12xx_plt_init,
buf : 	.trigger_cmd		= wl12xx_trigger_cmd,
buf : 	.ack_event		= wl12xx_ack_event,
buf : 	.wait_for_event		= wl12xx_wait_for_event,
for_event		= wl12xx_wait_for_event, 
buf : 	.process_mailbox_events	= wl12xx_process_mailbox_events,
buf : 	.calc_tx_blocks		= wl12xx_calc_tx_blocks,
buf : 	.set_tx_desc_blocks	= wl12xx_set_tx_desc_blocks,
buf : 	.set_tx_desc_data_len	= wl12xx_set_tx_desc_data_len,
buf : 	.get_rx_buf_align	= wl12xx_get_rx_buf_align,
buf : 	.get_rx_packet_len	= wl12xx_get_rx_packet_len,
buf : 	.tx_immediate_compl	= NULL,
buf : 	.tx_delayed_compl	= wl12xx_tx_delayed_compl,
buf : 	.hw_init		= wl12xx_hw_init,
buf : 	.init_vif		= NULL,
if		= NULL, 
buf : 	.convert_fw_status	= wl12xx_convert_fw_status,
buf : 	.sta_get_ap_rate_mask	= wl12xx_sta_get_ap_rate_mask,
buf : 	.get_pg_ver		= wl12xx_get_pg_ver,
buf : 	.get_mac		= wl12xx_get_mac,
buf : 	.set_tx_desc_csum	= wl12xx_set_tx_desc_csum,
buf : 	.set_rx_csum		= NULL,
buf : 	.ap_get_mimo_wide_rate_mask = NULL,
buf : 	.debugfs_init		= wl12xx_debugfs_add_files,
buf : 	.scan_start		= wl12xx_scan_start,
buf : 	.scan_stop		= wl12xx_scan_stop,
buf : 	.sched_scan_start	= wl12xx_sched_scan_start,
buf : 	.sched_scan_stop	= wl12xx_scan_sched_scan_stop,
buf : 	.get_spare_blocks	= wl12xx_get_spare_blocks,
buf : 	.set_key		= wl12xx_set_key,
buf : 	.channel_switch		= wl12xx_cmd_channel_switch,
buf : 	.pre_pkt_send		= NULL,
buf : 	.set_peer_cap		= wl12xx_set_peer_cap,
buf : 	.convert_hwaddr		= wl12xx_convert_hwaddr,
buf : 	.lnk_high_prio		= wl12xx_lnk_high_prio,
buf : 	.lnk_low_prio		= wl12xx_lnk_low_prio,
buf : };
buf : 
buf : static struct ieee80211_sta_ht_cap wl12xx_ht_cap = {
buf : 	.cap = IEEE80211_HT_CAP_GRN_FLD | IEEE80211_HT_CAP_SGI_20 |
buf : 	       (1 << IEEE80211_HT_CAP_RX_STBC_SHIFT),
buf : 	.ht_supported = true,
buf : 	.ampdu_factor = IEEE80211_HT_MAX_AMPDU_8K,
buf : 	.ampdu_density = IEEE80211_HT_MPDU_DENSITY_8,
buf : 	.mcs = {
buf : 		.rx_mask = { 0xff, 0, 0, 0, 0, 0, 0, 0, 0, 0, },
buf : 		.rx_highest = cpu_to_le16(72),
buf : 		.tx_params = IEEE80211_HT_MCS_TX_DEFINED,
buf : 		},
buf : };
buf : 
buf : static const struct ieee80211_iface_limit wl12xx_iface_limits[] = {
iface_limit wl12xx_iface_limits[] = { 
buf : 	{
buf : 		.max = 3,
buf : 		.types = BIT(NL80211_IFTYPE_STATION),
buf : 	},
buf : 	{
buf : 		.max = 1,
buf : 		.types = BIT(NL80211_IFTYPE_AP) |
buf : 			 BIT(NL80211_IFTYPE_P2P_GO) |
buf : 			 BIT(NL80211_IFTYPE_P2P_CLIENT),
buf : 	},
buf : };
buf : 
buf : static const struct ieee80211_iface_combination
iface_combination 
buf : wl12xx_iface_combinations[] = {
buf : 	{
buf : 		.max_interfaces = 3,
buf : 		.limits = wl12xx_iface_limits,
iface_limits, 
buf : 		.n_limits = ARRAY_SIZE(wl12xx_iface_limits),
buf : 		.num_different_channels = 1,
ifferent_channels = 1, 
buf : 	},
buf : };
buf : 
buf : static int wl12xx_setup(struct wl1271 *wl)
buf : {
buf : 	struct wl12xx_priv *priv = wl->priv;
buf : 	struct wlcore_platdev_data *pdev_data = dev_get_platdata(&wl->pdev->dev);
buf : 	struct wl12xx_platform_data *pdata = pdev_data->pdata;
form_data *pdata = pdev_data->pdata; 
buf : 
buf : 	BUILD_BUG_ON(WL12XX_MAX_LINKS > WLCORE_MAX_LINKS);
buf : 	BUILD_BUG_ON(WL12XX_MAX_AP_STATIONS > WL12XX_MAX_LINKS);
buf : 
buf : 	wl->rtable = wl12xx_rtable;
buf : 	wl->num_tx_desc = WL12XX_NUM_TX_DESCRIPTORS;
buf : 	wl->num_rx_desc = WL12XX_NUM_RX_DESCRIPTORS;
buf : 	wl->num_links = WL12XX_MAX_LINKS;
buf : 	wl->max_ap_stations = WL12XX_MAX_AP_STATIONS;
buf : 	wl->iface_combinations = wl12xx_iface_combinations;
iface_combinations = wl12xx_iface_combinations; 
buf : 	wl->n_iface_combinations = ARRAY_SIZE(wl12xx_iface_combinations);
buf : 	wl->num_mac_addr = WL12XX_NUM_MAC_ADDRESSES;
buf : 	wl->band_rate_to_idx = wl12xx_band_rate_to_idx;
buf : 	wl->hw_tx_rate_tbl_size = WL12XX_CONF_HW_RXTX_RATE_MAX;
buf : 	wl->hw_min_ht_rate = WL12XX_CONF_HW_RXTX_RATE_MCS0;
buf : 	wl->fw_status_len = sizeof(struct wl12xx_fw_status);
buf : 	wl->fw_status_priv_len = 0;
buf : 	wl->stats.fw_stats_len = sizeof(struct wl12xx_acx_statistics);
buf : 	wl->ofdm_only_ap = true;
buf : 	wlcore_set_ht_cap(wl, IEEE80211_BAND_2GHZ, &wl12xx_ht_cap);
buf : 	wlcore_set_ht_cap(wl, IEEE80211_BAND_5GHZ, &wl12xx_ht_cap);
buf : 	wl12xx_conf_init(wl);
buf : 
buf : 	if (!fref_param) {
if (!fref_param) { 
buf : 		priv->ref_clock = pdata->board_ref_clock;
buf : 	} else {
buf : 		if (!strcmp(fref_param, "19.2"))
if (!strcmp(fref_param, "19.2")) 
buf : 			priv->ref_clock = WL12XX_REFCLOCK_19;
buf : 		else if (!strcmp(fref_param, "26"))
if (!strcmp(fref_param, "26")) 
buf : 			priv->ref_clock = WL12XX_REFCLOCK_26;
buf : 		else if (!strcmp(fref_param, "26x"))
if (!strcmp(fref_param, "26x")) 
buf : 			priv->ref_clock = WL12XX_REFCLOCK_26_XTAL;
buf : 		else if (!strcmp(fref_param, "38.4"))
if (!strcmp(fref_param, "38.4")) 
buf : 			priv->ref_clock = WL12XX_REFCLOCK_38;
buf : 		else if (!strcmp(fref_param, "38.4x"))
if (!strcmp(fref_param, "38.4x")) 
buf : 			priv->ref_clock = WL12XX_REFCLOCK_38_XTAL;
buf : 		else if (!strcmp(fref_param, "52"))
if (!strcmp(fref_param, "52")) 
buf : 			priv->ref_clock = WL12XX_REFCLOCK_52;
buf : 		else
buf : 			wl1271_error("Invalid fref parameter %s", fref_param);
buf : 	}
buf : 
buf : 	if (!tcxo_param) {
if (!tcxo_param) { 
buf : 		priv->tcxo_clock = pdata->board_tcxo_clock;
buf : 	} else {
buf : 		if (!strcmp(tcxo_param, "19.2"))
if (!strcmp(tcxo_param, "19.2")) 
buf : 			priv->tcxo_clock = WL12XX_TCXOCLOCK_19_2;
buf : 		else if (!strcmp(tcxo_param, "26"))
if (!strcmp(tcxo_param, "26")) 
buf : 			priv->tcxo_clock = WL12XX_TCXOCLOCK_26;
buf : 		else if (!strcmp(tcxo_param, "38.4"))
if (!strcmp(tcxo_param, "38.4")) 
buf : 			priv->tcxo_clock = WL12XX_TCXOCLOCK_38_4;
buf : 		else if (!strcmp(tcxo_param, "52"))
if (!strcmp(tcxo_param, "52")) 
buf : 			priv->tcxo_clock = WL12XX_TCXOCLOCK_52;
buf : 		else if (!strcmp(tcxo_param, "16.368"))
if (!strcmp(tcxo_param, "16.368")) 
buf : 			priv->tcxo_clock = WL12XX_TCXOCLOCK_16_368;
buf : 		else if (!strcmp(tcxo_param, "32.736"))
if (!strcmp(tcxo_param, "32.736")) 
buf : 			priv->tcxo_clock = WL12XX_TCXOCLOCK_32_736;
buf : 		else if (!strcmp(tcxo_param, "16.8"))
if (!strcmp(tcxo_param, "16.8")) 
buf : 			priv->tcxo_clock = WL12XX_TCXOCLOCK_16_8;
buf : 		else if (!strcmp(tcxo_param, "33.6"))
if (!strcmp(tcxo_param, "33.6")) 
buf : 			priv->tcxo_clock = WL12XX_TCXOCLOCK_33_6;
buf : 		else
buf : 			wl1271_error("Invalid tcxo parameter %s", tcxo_param);
buf : 	}
buf : 
buf : 	priv->rx_mem_addr = kmalloc(sizeof(*priv->rx_mem_addr), GFP_KERNEL);
buf : 	if (!priv->rx_mem_addr)
if (!priv->rx_mem_addr) 
buf : 		return -ENOMEM;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl12xx_probe(struct platform_device *pdev)
form_device *pdev) 
buf : {
buf : 	struct wl1271 *wl;
buf : 	struct ieee80211_hw *hw;
buf : 	int ret;
buf : 
buf : 	hw = wlcore_alloc_hw(sizeof(struct wl12xx_priv),
buf : 			     WL12XX_AGGR_BUFFER_SIZE,
buf : 			     sizeof(struct wl12xx_event_mailbox));
buf : 	if (IS_ERR(hw)) {
if (IS_ERR(hw)) { 
buf : 		wl1271_error("can't allocate hw");
buf : 		ret = PTR_ERR(hw);
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl = hw->priv;
buf : 	wl->ops = &wl12xx_ops;
buf : 	wl->ptable = wl12xx_ptable;
buf : 	ret = wlcore_probe(wl, pdev);
buf : 	if (ret)
if (ret) 
buf : 		goto out_free;
buf : 
buf : 	return ret;
buf : 
buf : out_free:
buf : 	wlcore_free_hw(wl);
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_remove(struct platform_device *pdev)
form_device *pdev) 
buf : {
buf : 	struct wl1271 *wl = platform_get_drvdata(pdev);
buf : 	struct wl12xx_priv *priv;
buf : 
buf : 	if (!wl)
if (!wl) 
buf : 		goto out;
buf : 	priv = wl->priv;
buf : 
buf : 	kfree(priv->rx_mem_addr);
buf : 
buf : out:
buf : 	return wlcore_remove(pdev);
buf : }
buf : 
buf : static const struct platform_device_id wl12xx_id_table[] = {
form_device_id wl12xx_id_table[] = { 
buf : 	{ "wl12xx", 0 },
buf : 	{  } /* Terminating Entry */
buf : };
buf : MODULE_DEVICE_TABLE(platform, wl12xx_id_table);
form, wl12xx_id_table); 
buf : 
buf : static struct platform_driver wl12xx_driver = {
buf : 	.probe		= wl12xx_probe,
buf : 	.remove		= wl12xx_remove,
buf : 	.id_table	= wl12xx_id_table,
buf : 	.driver = {
buf : 		.name	= "wl12xx_driver",
buf : 		.owner	= THIS_MODULE,
buf : 	}
buf : };
buf : 
buf : module_platform_driver(wl12xx_driver);
form_driver(wl12xx_driver); 
buf : 
buf : module_param_named(fref, fref_param, charp, 0);
buf : MODULE_PARM_DESC(fref, "FREF clock: 19.2, 26, 26x, 38.4, 38.4x, 52");
buf : 
buf : module_param_named(tcxo, tcxo_param, charp, 0);
buf : MODULE_PARM_DESC(tcxo,
buf : 		 "TCXO clock: 19.2, 26, 38.4, 52, 16.368, 32.736, 16.8, 33.6");
buf : 
buf : MODULE_LICENSE("GPL v2");
buf : MODULE_AUTHOR("Luciano Coelho <coelho@ti.com>");
buf : MODULE_FIRMWARE(WL127X_FW_NAME_SINGLE);
buf : MODULE_FIRMWARE(WL127X_FW_NAME_MULTI);
buf : MODULE_FIRMWARE(WL127X_PLT_FW_NAME);
buf : MODULE_FIRMWARE(WL128X_FW_NAME_SINGLE);
buf : MODULE_FIRMWARE(WL128X_FW_NAME_MULTI);
buf : MODULE_FIRMWARE(WL128X_PLT_FW_NAME);
file : ./test/kernel/drivers/net/wireless/ti/wl18xx/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * This file is part of wl18xx
buf :  *
buf :  * Copyright (C) 2011 Texas Instruments
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of the GNU General Public License
ify it under the terms of the GNU General Public License 
buf :  * version 2 as published by the Free Software Foundation.
buf :  *
buf :  * This program is distributed in the hope that it will be useful, but
buf :  * WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
buf :  * General Public License for more details.
for more details. 
buf :  *
buf :  * You should have received a copy of the GNU General Public License
buf :  * along with this program; if not, write to the Free Software
if not, write to the Free Software 
buf :  * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
buf :  * 02110-1301 USA
buf :  *
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/platform_device.h>
form_device.h> 
buf : #include <linux/ip.h>
buf : #include <linux/firmware.h>
buf : #include <linux/etherdevice.h>
buf : 
buf : #include "../wlcore/wlcore.h"
buf : #include "../wlcore/debug.h"
buf : #include "../wlcore/io.h"
buf : #include "../wlcore/acx.h"
buf : #include "../wlcore/tx.h"
buf : #include "../wlcore/rx.h"
buf : #include "../wlcore/boot.h"
buf : 
buf : #include "reg.h"
buf : #include "conf.h"
buf : #include "cmd.h"
buf : #include "acx.h"
buf : #include "tx.h"
buf : #include "wl18xx.h"
buf : #include "io.h"
buf : #include "scan.h"
buf : #include "event.h"
buf : #include "debugfs.h"
buf : 
buf : #define WL18XX_RX_CHECKSUM_MASK      0x40
buf : 
buf : static char *ht_mode_param = NULL;
buf : static char *board_type_param = NULL;
buf : static bool checksum_param = false;
buf : static int num_rx_desc_param = -1;
buf : 
buf : /* phy paramters */
buf : static int dc2dc_param = -1;
buf : static int n_antennas_2_param = -1;
buf : static int n_antennas_5_param = -1;
buf : static int low_band_component_param = -1;
buf : static int low_band_component_type_param = -1;
buf : static int high_band_component_param = -1;
buf : static int high_band_component_type_param = -1;
buf : static int pwr_limit_reference_11_abg_param = -1;
buf : 
buf : static const u8 wl18xx_rate_to_idx_2ghz[] = {
buf : 	/* MCS rates are used only with 11n */
buf : 	15,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS15 */
buf : 	14,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS14 */
buf : 	13,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS13 */
buf : 	12,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS12 */
buf : 	11,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS11 */
buf : 	10,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS10 */
buf : 	9,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS9 */
buf : 	8,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS8 */
buf : 	7,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS7 */
buf : 	6,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS6 */
buf : 	5,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS5 */
buf : 	4,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS4 */
buf : 	3,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS3 */
buf : 	2,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS2 */
buf : 	1,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS1 */
buf : 	0,                             /* WL18XX_CONF_HW_RXTX_RATE_MCS0 */
buf : 
buf : 	11,                            /* WL18XX_CONF_HW_RXTX_RATE_54   */
buf : 	10,                            /* WL18XX_CONF_HW_RXTX_RATE_48   */
buf : 	9,                             /* WL18XX_CONF_HW_RXTX_RATE_36   */
buf : 	8,                             /* WL18XX_CONF_HW_RXTX_RATE_24   */
buf : 
buf : 	/* TI-specific rate */
ific rate */ 
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL18XX_CONF_HW_RXTX_RATE_22   */
buf : 
buf : 	7,                             /* WL18XX_CONF_HW_RXTX_RATE_18   */
buf : 	6,                             /* WL18XX_CONF_HW_RXTX_RATE_12   */
buf : 	3,                             /* WL18XX_CONF_HW_RXTX_RATE_11   */
buf : 	5,                             /* WL18XX_CONF_HW_RXTX_RATE_9    */
buf : 	4,                             /* WL18XX_CONF_HW_RXTX_RATE_6    */
buf : 	2,                             /* WL18XX_CONF_HW_RXTX_RATE_5_5  */
buf : 	1,                             /* WL18XX_CONF_HW_RXTX_RATE_2    */
buf : 	0                              /* WL18XX_CONF_HW_RXTX_RATE_1    */
buf : };
buf : 
buf : static const u8 wl18xx_rate_to_idx_5ghz[] = {
buf : 	/* MCS rates are used only with 11n */
buf : 	15,                           /* WL18XX_CONF_HW_RXTX_RATE_MCS15 */
buf : 	14,                           /* WL18XX_CONF_HW_RXTX_RATE_MCS14 */
buf : 	13,                           /* WL18XX_CONF_HW_RXTX_RATE_MCS13 */
buf : 	12,                           /* WL18XX_CONF_HW_RXTX_RATE_MCS12 */
buf : 	11,                           /* WL18XX_CONF_HW_RXTX_RATE_MCS11 */
buf : 	10,                           /* WL18XX_CONF_HW_RXTX_RATE_MCS10 */
buf : 	9,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS9 */
buf : 	8,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS8 */
buf : 	7,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS7 */
buf : 	6,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS6 */
buf : 	5,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS5 */
buf : 	4,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS4 */
buf : 	3,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS3 */
buf : 	2,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS2 */
buf : 	1,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS1 */
buf : 	0,                            /* WL18XX_CONF_HW_RXTX_RATE_MCS0 */
buf : 
buf : 	7,                             /* WL18XX_CONF_HW_RXTX_RATE_54   */
buf : 	6,                             /* WL18XX_CONF_HW_RXTX_RATE_48   */
buf : 	5,                             /* WL18XX_CONF_HW_RXTX_RATE_36   */
buf : 	4,                             /* WL18XX_CONF_HW_RXTX_RATE_24   */
buf : 
buf : 	/* TI-specific rate */
ific rate */ 
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL18XX_CONF_HW_RXTX_RATE_22   */
buf : 
buf : 	3,                             /* WL18XX_CONF_HW_RXTX_RATE_18   */
buf : 	2,                             /* WL18XX_CONF_HW_RXTX_RATE_12   */
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL18XX_CONF_HW_RXTX_RATE_11   */
buf : 	1,                             /* WL18XX_CONF_HW_RXTX_RATE_9    */
buf : 	0,                             /* WL18XX_CONF_HW_RXTX_RATE_6    */
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL18XX_CONF_HW_RXTX_RATE_5_5  */
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL18XX_CONF_HW_RXTX_RATE_2    */
buf : 	CONF_HW_RXTX_RATE_UNSUPPORTED, /* WL18XX_CONF_HW_RXTX_RATE_1    */
buf : };
buf : 
buf : static const u8 *wl18xx_band_rate_to_idx[] = {
buf : 	[IEEE80211_BAND_2GHZ] = wl18xx_rate_to_idx_2ghz,
buf : 	[IEEE80211_BAND_5GHZ] = wl18xx_rate_to_idx_5ghz
buf : };
buf : 
buf : enum wl18xx_hw_rates {
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS15 = 0,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS14,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS13,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS12,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS11,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS10,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS9,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS8,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS7,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS6,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS5,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS4,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS3,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS2,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS1,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MCS0,
buf : 	WL18XX_CONF_HW_RXTX_RATE_54,
buf : 	WL18XX_CONF_HW_RXTX_RATE_48,
buf : 	WL18XX_CONF_HW_RXTX_RATE_36,
buf : 	WL18XX_CONF_HW_RXTX_RATE_24,
buf : 	WL18XX_CONF_HW_RXTX_RATE_22,
buf : 	WL18XX_CONF_HW_RXTX_RATE_18,
buf : 	WL18XX_CONF_HW_RXTX_RATE_12,
buf : 	WL18XX_CONF_HW_RXTX_RATE_11,
buf : 	WL18XX_CONF_HW_RXTX_RATE_9,
buf : 	WL18XX_CONF_HW_RXTX_RATE_6,
buf : 	WL18XX_CONF_HW_RXTX_RATE_5_5,
buf : 	WL18XX_CONF_HW_RXTX_RATE_2,
buf : 	WL18XX_CONF_HW_RXTX_RATE_1,
buf : 	WL18XX_CONF_HW_RXTX_RATE_MAX,
buf : };
buf : 
buf : static struct wlcore_conf wl18xx_conf = {
buf : 	.sg = {
buf : 		.params = {
buf : 			[CONF_SG_ACL_BT_MASTER_MIN_BR] = 10,
buf : 			[CONF_SG_ACL_BT_MASTER_MAX_BR] = 180,
buf : 			[CONF_SG_ACL_BT_SLAVE_MIN_BR] = 10,
buf : 			[CONF_SG_ACL_BT_SLAVE_MAX_BR] = 180,
buf : 			[CONF_SG_ACL_BT_MASTER_MIN_EDR] = 10,
buf : 			[CONF_SG_ACL_BT_MASTER_MAX_EDR] = 80,
buf : 			[CONF_SG_ACL_BT_SLAVE_MIN_EDR] = 10,
buf : 			[CONF_SG_ACL_BT_SLAVE_MAX_EDR] = 80,
buf : 			[CONF_SG_ACL_WLAN_PS_MASTER_BR] = 8,
buf : 			[CONF_SG_ACL_WLAN_PS_SLAVE_BR] = 8,
buf : 			[CONF_SG_ACL_WLAN_PS_MASTER_EDR] = 20,
buf : 			[CONF_SG_ACL_WLAN_PS_SLAVE_EDR] = 20,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_MASTER_MIN_BR] = 20,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_MASTER_MAX_BR] = 35,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_SLAVE_MIN_BR] = 16,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_SLAVE_MAX_BR] = 35,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_MASTER_MIN_EDR] = 32,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_MASTER_MAX_EDR] = 50,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_SLAVE_MIN_EDR] = 28,
buf : 			[CONF_SG_ACL_WLAN_ACTIVE_SLAVE_MAX_EDR] = 50,
buf : 			[CONF_SG_ACL_ACTIVE_SCAN_WLAN_BR] = 10,
buf : 			[CONF_SG_ACL_ACTIVE_SCAN_WLAN_EDR] = 20,
buf : 			[CONF_SG_ACL_PASSIVE_SCAN_BT_BR] = 75,
buf : 			[CONF_SG_ACL_PASSIVE_SCAN_WLAN_BR] = 15,
buf : 			[CONF_SG_ACL_PASSIVE_SCAN_BT_EDR] = 27,
buf : 			[CONF_SG_ACL_PASSIVE_SCAN_WLAN_EDR] = 17,
buf : 			/* active scan params */
buf : 			[CONF_SG_AUTO_SCAN_PROBE_REQ] = 170,
buf : 			[CONF_SG_ACTIVE_SCAN_DURATION_FACTOR_HV3] = 50,
buf : 			[CONF_SG_ACTIVE_SCAN_DURATION_FACTOR_A2DP] = 100,
buf : 			/* passive scan params */
buf : 			[CONF_SG_PASSIVE_SCAN_DURATION_FACTOR_A2DP_BR] = 800,
buf : 			[CONF_SG_PASSIVE_SCAN_DURATION_FACTOR_A2DP_EDR] = 200,
buf : 			[CONF_SG_PASSIVE_SCAN_DURATION_FACTOR_HV3] = 200,
buf : 			/* passive scan in dual antenna params */
buf : 			[CONF_SG_CONSECUTIVE_HV3_IN_PASSIVE_SCAN] = 0,
buf : 			[CONF_SG_BCN_HV3_COLLISION_THRESH_IN_PASSIVE_SCAN] = 0,
buf : 			[CONF_SG_TX_RX_PROTECTION_BWIDTH_IN_PASSIVE_SCAN] = 0,
buf : 			/* general params */
buf : 			[CONF_SG_STA_FORCE_PS_IN_BT_SCO] = 1,
buf : 			[CONF_SG_ANTENNA_CONFIGURATION] = 0,
buf : 			[CONF_SG_BEACON_MISS_PERCENT] = 60,
buf : 			[CONF_SG_DHCP_TIME] = 5000,
buf : 			[CONF_SG_RXT] = 1200,
buf : 			[CONF_SG_TXT] = 1000,
buf : 			[CONF_SG_ADAPTIVE_RXT_TXT] = 1,
buf : 			[CONF_SG_GENERAL_USAGE_BIT_MAP] = 3,
buf : 			[CONF_SG_HV3_MAX_SERVED] = 6,
buf : 			[CONF_SG_PS_POLL_TIMEOUT] = 10,
buf : 			[CONF_SG_UPSD_TIMEOUT] = 10,
buf : 			[CONF_SG_CONSECUTIVE_CTS_THRESHOLD] = 2,
buf : 			[CONF_SG_STA_RX_WINDOW_AFTER_DTIM] = 5,
buf : 			[CONF_SG_STA_CONNECTION_PROTECTION_TIME] = 30,
buf : 			/* AP params */
buf : 			[CONF_AP_BEACON_MISS_TX] = 3,
buf : 			[CONF_AP_RX_WINDOW_AFTER_BEACON] = 10,
buf : 			[CONF_AP_BEACON_WINDOW_INTERVAL] = 2,
buf : 			[CONF_AP_CONNECTION_PROTECTION_TIME] = 0,
buf : 			[CONF_AP_BT_ACL_VAL_BT_SERVE_TIME] = 25,
buf : 			[CONF_AP_BT_ACL_VAL_WL_SERVE_TIME] = 25,
buf : 			/* CTS Diluting params */
buf : 			[CONF_SG_CTS_DILUTED_BAD_RX_PACKETS_TH] = 0,
buf : 			[CONF_SG_CTS_CHOP_IN_DUAL_ANT_SCO_MASTER] = 0,
buf : 		},
buf : 		.state = CONF_SG_PROTECTIVE,
buf : 	},
buf : 	.rx = {
buf : 		.rx_msdu_life_time           = 512000,
ife_time           = 512000, 
buf : 		.packet_detection_threshold  = 0,
buf : 		.ps_poll_timeout             = 15,
buf : 		.upsd_timeout                = 15,
buf : 		.rts_threshold               = IEEE80211_MAX_RTS_THRESHOLD,
buf : 		.rx_cca_threshold            = 0,
buf : 		.irq_blk_threshold           = 0xFFFF,
buf : 		.irq_pkt_threshold           = 0,
buf : 		.irq_timeout                 = 600,
buf : 		.queue_type                  = CONF_RX_QUEUE_TYPE_LOW_PRIORITY,
buf : 	},
buf : 	.tx = {
buf : 		.tx_energy_detection         = 0,
buf : 		.sta_rc_conf                 = {
buf : 			.enabled_rates       = 0,
buf : 			.short_retry_limit   = 10,
buf : 			.long_retry_limit    = 10,
buf : 			.aflags              = 0,
buf : 		},
buf : 		.ac_conf_count               = 4,
buf : 		.ac_conf                     = {
buf : 			[CONF_TX_AC_BE] = {
buf : 				.ac          = CONF_TX_AC_BE,
buf : 				.cw_min      = 15,
buf : 				.cw_max      = 63,
buf : 				.aifsn       = 3,
ifsn       = 3, 
buf : 				.tx_op_limit = 0,
buf : 			},
buf : 			[CONF_TX_AC_BK] = {
buf : 				.ac          = CONF_TX_AC_BK,
buf : 				.cw_min      = 15,
buf : 				.cw_max      = 63,
buf : 				.aifsn       = 7,
ifsn       = 7, 
buf : 				.tx_op_limit = 0,
buf : 			},
buf : 			[CONF_TX_AC_VI] = {
buf : 				.ac          = CONF_TX_AC_VI,
buf : 				.cw_min      = 15,
buf : 				.cw_max      = 63,
buf : 				.aifsn       = CONF_TX_AIFS_PIFS,
ifsn       = CONF_TX_AIFS_PIFS, 
buf : 				.tx_op_limit = 3008,
buf : 			},
buf : 			[CONF_TX_AC_VO] = {
buf : 				.ac          = CONF_TX_AC_VO,
buf : 				.cw_min      = 15,
buf : 				.cw_max      = 63,
buf : 				.aifsn       = CONF_TX_AIFS_PIFS,
ifsn       = CONF_TX_AIFS_PIFS, 
buf : 				.tx_op_limit = 1504,
buf : 			},
buf : 		},
buf : 		.max_tx_retries = 100,
buf : 		.ap_aging_period = 300,
buf : 		.tid_conf_count = 4,
buf : 		.tid_conf = {
buf : 			[CONF_TX_AC_BE] = {
buf : 				.queue_id    = CONF_TX_AC_BE,
buf : 				.channel_type = CONF_CHANNEL_TYPE_EDCF,
buf : 				.tsid        = CONF_TX_AC_BE,
buf : 				.ps_scheme   = CONF_PS_SCHEME_LEGACY,
buf : 				.ack_policy  = CONF_ACK_POLICY_LEGACY,
buf : 				.apsd_conf   = {0, 0},
buf : 			},
buf : 			[CONF_TX_AC_BK] = {
buf : 				.queue_id    = CONF_TX_AC_BK,
buf : 				.channel_type = CONF_CHANNEL_TYPE_EDCF,
buf : 				.tsid        = CONF_TX_AC_BK,
buf : 				.ps_scheme   = CONF_PS_SCHEME_LEGACY,
buf : 				.ack_policy  = CONF_ACK_POLICY_LEGACY,
buf : 				.apsd_conf   = {0, 0},
buf : 			},
buf : 			[CONF_TX_AC_VI] = {
buf : 				.queue_id    = CONF_TX_AC_VI,
buf : 				.channel_type = CONF_CHANNEL_TYPE_EDCF,
buf : 				.tsid        = CONF_TX_AC_VI,
buf : 				.ps_scheme   = CONF_PS_SCHEME_LEGACY,
buf : 				.ack_policy  = CONF_ACK_POLICY_LEGACY,
buf : 				.apsd_conf   = {0, 0},
buf : 			},
buf : 			[CONF_TX_AC_VO] = {
buf : 				.queue_id    = CONF_TX_AC_VO,
buf : 				.channel_type = CONF_CHANNEL_TYPE_EDCF,
buf : 				.tsid        = CONF_TX_AC_VO,
buf : 				.ps_scheme   = CONF_PS_SCHEME_LEGACY,
buf : 				.ack_policy  = CONF_ACK_POLICY_LEGACY,
buf : 				.apsd_conf   = {0, 0},
buf : 			},
buf : 		},
buf : 		.frag_threshold              = IEEE80211_MAX_FRAG_THRESHOLD,
buf : 		.tx_compl_timeout            = 350,
buf : 		.tx_compl_threshold          = 10,
buf : 		.basic_rate                  = CONF_HW_BIT_RATE_1MBPS,
buf : 		.basic_rate_5                = CONF_HW_BIT_RATE_6MBPS,
buf : 		.tmpl_short_retry_limit      = 10,
buf : 		.tmpl_long_retry_limit       = 10,
buf : 		.tx_watchdog_timeout         = 5000,
buf : 		.slow_link_thold             = 3,
buf : 		.fast_link_thold             = 30,
buf : 	},
buf : 	.conn = {
buf : 		.wake_up_event               = CONF_WAKE_UP_EVENT_DTIM,
buf : 		.listen_interval             = 1,
buf : 		.suspend_wake_up_event       = CONF_WAKE_UP_EVENT_N_DTIM,
buf : 		.suspend_listen_interval     = 3,
buf : 		.bcn_filt_mode               = CONF_BCN_FILT_MODE_ENABLED,
buf : 		.bcn_filt_ie_count           = 3,
buf : 		.bcn_filt_ie = {
buf : 			[0] = {
buf : 				.ie          = WLAN_EID_CHANNEL_SWITCH,
buf : 				.rule        = CONF_BCN_RULE_PASS_ON_APPEARANCE,
buf : 			},
buf : 			[1] = {
buf : 				.ie          = WLAN_EID_HT_OPERATION,
buf : 				.rule        = CONF_BCN_RULE_PASS_ON_CHANGE,
buf : 			},
buf : 			[2] = {
buf : 				.ie	     = WLAN_EID_ERP_INFO,
buf : 				.rule	     = CONF_BCN_RULE_PASS_ON_CHANGE,
buf : 			},
buf : 		},
buf : 		.synch_fail_thold            = 12,
buf : 		.bss_lose_timeout            = 400,
buf : 		.beacon_rx_timeout           = 10000,
buf : 		.broadcast_timeout           = 20000,
buf : 		.rx_broadcast_in_ps          = 1,
buf : 		.ps_poll_threshold           = 10,
buf : 		.bet_enable                  = CONF_BET_MODE_ENABLE,
buf : 		.bet_max_consecutive         = 50,
buf : 		.psm_entry_retries           = 8,
buf : 		.psm_exit_retries            = 16,
buf : 		.psm_entry_nullfunc_retries  = 3,
buf : 		.dynamic_ps_timeout          = 1500,
buf : 		.forced_ps                   = false,
forced_ps                   = false, 
buf : 		.keep_alive_interval         = 55000,
buf : 		.max_listen_interval         = 20,
buf : 		.sta_sleep_auth              = WL1271_PSM_ILLEGAL,
buf : 	},
buf : 	.itrim = {
buf : 		.enable = false,
buf : 		.timeout = 50000,
buf : 	},
buf : 	.pm_config = {
buf : 		.host_clk_settling_time = 5000,
buf : 		.host_fast_wakeup_support = CONF_FAST_WAKEUP_DISABLE,
buf : 	},
buf : 	.roam_trigger = {
buf : 		.trigger_pacing               = 1,
buf : 		.avg_weight_rssi_beacon       = 20,
buf : 		.avg_weight_rssi_data         = 10,
buf : 		.avg_weight_snr_beacon        = 20,
buf : 		.avg_weight_snr_data          = 10,
buf : 	},
buf : 	.scan = {
buf : 		.min_dwell_time_active        = 7500,
buf : 		.max_dwell_time_active        = 30000,
buf : 		.min_dwell_time_active_long   = 25000,
buf : 		.max_dwell_time_active_long   = 50000,
buf : 		.dwell_time_passive           = 100000,
buf : 		.dwell_time_dfs               = 150000,
buf : 		.num_probe_reqs               = 2,
buf : 		.split_scan_timeout           = 50000,
buf : 	},
buf : 	.sched_scan = {
buf : 		/*
buf : 		 * Values are in TU/1000 but since sched scan FW command
buf : 		 * params are in TUs rounding up may occur.
buf : 		 */
buf : 		.base_dwell_time		= 7500,
buf : 		.max_dwell_time_delta		= 22500,
buf : 		/* based on 250bits per probe @1Mbps */
buf : 		.dwell_time_delta_per_probe	= 2000,
buf : 		/* based on 250bits per probe @6Mbps (plus a bit more) */
buf : 		.dwell_time_delta_per_probe_5	= 350,
buf : 		.dwell_time_passive		= 100000,
buf : 		.dwell_time_dfs			= 150000,
buf : 		.num_probe_reqs			= 2,
buf : 		.rssi_threshold			= -90,
buf : 		.snr_threshold			= 0,
buf : 	},
buf : 	.ht = {
buf : 		.rx_ba_win_size = 32,
buf : 		.tx_ba_win_size = 64,
buf : 		.inactivity_timeout = 10000,
buf : 		.tx_ba_tid_bitmap = CONF_TX_BA_ENABLED_TID_BITMAP,
buf : 	},
buf : 	.mem = {
buf : 		.num_stations                 = 1,
buf : 		.ssid_profiles                = 1,
buf : 		.rx_block_num                 = 40,
buf : 		.tx_min_block_num             = 40,
buf : 		.dynamic_memory               = 1,
buf : 		.min_req_tx_blocks            = 45,
buf : 		.min_req_rx_blocks            = 22,
buf : 		.tx_min                       = 27,
buf : 	},
buf : 	.fm_coex = {
buf : 		.enable                       = true,
buf : 		.swallow_period               = 5,
buf : 		.n_divider_fref_set_1         = 0xff,       /* default */
buf : 		.n_divider_fref_set_2         = 12,
buf : 		.m_divider_fref_set_1         = 0xffff,
buf : 		.m_divider_fref_set_2         = 148,        /* default */
buf : 		.coex_pll_stabilization_time  = 0xffffffff, /* default */
buf : 		.ldo_stabilization_time       = 0xffff,     /* default */
buf : 		.fm_disturbed_band_margin     = 0xff,       /* default */
buf : 		.swallow_clk_diff             = 0xff,       /* default */
iff             = 0xff,       /* default */ 
buf : 	},
buf : 	.rx_streaming = {
buf : 		.duration                      = 150,
buf : 		.queues                        = 0x1,
buf : 		.interval                      = 20,
buf : 		.always                        = 0,
buf : 	},
buf : 	.fwlog = {
buf : 		.mode                         = WL12XX_FWLOG_CONTINUOUS,
buf : 		.mem_blocks                   = 2,
buf : 		.severity                     = 0,
buf : 		.timestamp                    = WL12XX_FWLOG_TIMESTAMP_DISABLED,
buf : 		.output                       = WL12XX_FWLOG_OUTPUT_DBG_PINS,
buf : 		.threshold                    = 0,
buf : 	},
buf : 	.rate = {
buf : 		.rate_retry_score = 32000,
buf : 		.per_add = 8192,
buf : 		.per_th1 = 2048,
buf : 		.per_th2 = 4096,
buf : 		.max_per = 8100,
buf : 		.inverse_curiosity_factor = 5,
buf : 		.tx_fail_low_th = 4,
buf : 		.tx_fail_high_th = 10,
buf : 		.per_alpha_shift = 4,
ift = 4, 
buf : 		.per_add_shift = 13,
buf : 		.per_beta1_shift = 10,
ift = 10, 
buf : 		.per_beta2_shift = 8,
buf : 		.rate_check_up = 2,
buf : 		.rate_check_down = 12,
buf : 		.rate_retry_policy = {
buf : 			0x00, 0x00, 0x00, 0x00, 0x00,
buf : 			0x00, 0x00, 0x00, 0x00, 0x00,
buf : 			0x00, 0x00, 0x00,
buf : 		},
buf : 	},
buf : 	.hangover = {
buf : 		.recover_time               = 0,
buf : 		.hangover_period            = 20,
buf : 		.dynamic_mode               = 1,
buf : 		.early_termination_mode     = 1,
buf : 		.max_period                 = 20,
buf : 		.min_period                 = 1,
buf : 		.increase_delta             = 1,
buf : 		.decrease_delta             = 2,
buf : 		.quiet_time                 = 4,
buf : 		.increase_time              = 1,
buf : 		.window_size                = 16,
buf : 	},
buf : 	.recovery = {
buf : 		.bug_on_recovery	    = 0,
buf : 		.no_recovery		    = 0,
buf : 	},
buf : };
buf : 
buf : static struct wl18xx_priv_conf wl18xx_default_priv_conf = {
buf : 	.ht = {
buf : 		.mode				= HT_MODE_WIDE,
buf : 	},
buf : 	.phy = {
buf : 		.phy_standalone			= 0x00,
buf : 		.primary_clock_setting_time	= 0x05,
buf : 		.clock_valid_on_wake_up		= 0x00,
buf : 		.secondary_clock_setting_time	= 0x05,
buf : 		.board_type 			= BOARD_TYPE_HDK_18XX,
buf : 		.auto_detect			= 0x00,
buf : 		.dedicated_fem			= FEM_NONE,
buf : 		.low_band_component		= COMPONENT_3_WAY_SWITCH,
buf : 		.low_band_component_type	= 0x05,
buf : 		.high_band_component		= COMPONENT_2_WAY_SWITCH,
buf : 		.high_band_component_type	= 0x09,
buf : 		.tcxo_ldo_voltage		= 0x00,
buf : 		.xtal_itrim_val			= 0x04,
buf : 		.srf_state			= 0x00,
buf : 		.io_configuration		= 0x01,
buf : 		.sdio_configuration		= 0x00,
buf : 		.settings			= 0x00,
buf : 		.enable_clpc			= 0x00,
buf : 		.enable_tx_low_pwr_on_siso_rdl	= 0x00,
buf : 		.rx_profile			= 0x00,
buf : 		.pwr_limit_reference_11_abg	= 0x64,
buf : 		.per_chan_pwr_limit_arr_11abg	= {
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff },
buf : 		.pwr_limit_reference_11p	= 0x64,
buf : 		.per_chan_bo_mode_11_abg	= { 0x00, 0x00, 0x00, 0x00,
buf : 						    0x00, 0x00, 0x00, 0x00,
buf : 						    0x00, 0x00, 0x00, 0x00,
buf : 						    0x00 },
buf : 		.per_chan_bo_mode_11_p		= { 0x00, 0x00, 0x00, 0x00 },
buf : 		.per_chan_pwr_limit_arr_11p	= { 0xff, 0xff, 0xff, 0xff,
buf : 						    0xff, 0xff, 0xff },
buf : 		.psat				= 0,
buf : 		.external_pa_dc2dc		= 0,
buf : 		.number_of_assembled_ant2_4	= 2,
buf : 		.number_of_assembled_ant5	= 1,
buf : 		.low_power_val			= 0xff,
buf : 		.med_power_val			= 0xff,
buf : 		.high_power_val			= 0xff,
buf : 		.low_power_val_2nd		= 0xff,
buf : 		.med_power_val_2nd		= 0xff,
buf : 		.high_power_val_2nd		= 0xff,
buf : 		.tx_rf_margin			= 1,
buf : 	},
buf : };
buf : 
buf : static const struct wlcore_partition_set wl18xx_ptable[PART_TABLE_LEN] = {
buf : 	[PART_TOP_PRCM_ELP_SOC] = {
buf : 		.mem  = { .start = 0x00A02000, .size  = 0x00010000 },
buf : 		.reg  = { .start = 0x00807000, .size  = 0x00005000 },
buf : 		.mem2 = { .start = 0x00800000, .size  = 0x0000B000 },
buf : 		.mem3 = { .start = 0x00000000, .size  = 0x00000000 },
buf : 	},
buf : 	[PART_DOWN] = {
buf : 		.mem  = { .start = 0x00000000, .size  = 0x00014000 },
buf : 		.reg  = { .start = 0x00810000, .size  = 0x0000BFFF },
buf : 		.mem2 = { .start = 0x00000000, .size  = 0x00000000 },
buf : 		.mem3 = { .start = 0x00000000, .size  = 0x00000000 },
buf : 	},
buf : 	[PART_BOOT] = {
buf : 		.mem  = { .start = 0x00700000, .size = 0x0000030c },
buf : 		.reg  = { .start = 0x00802000, .size = 0x00014578 },
buf : 		.mem2 = { .start = 0x00B00404, .size = 0x00001000 },
buf : 		.mem3 = { .start = 0x00C00000, .size = 0x00000400 },
buf : 	},
buf : 	[PART_WORK] = {
buf : 		.mem  = { .start = 0x00800000, .size  = 0x000050FC },
buf : 		.reg  = { .start = 0x00B00404, .size  = 0x00001000 },
buf : 		.mem2 = { .start = 0x00C00000, .size  = 0x00000400 },
buf : 		.mem3 = { .start = 0x00000000, .size  = 0x00000000 },
buf : 	},
buf : 	[PART_PHY_INIT] = {
buf : 		.mem  = { .start = WL18XX_PHY_INIT_MEM_ADDR,
buf : 			  .size  = WL18XX_PHY_INIT_MEM_SIZE },
buf : 		.reg  = { .start = 0x00000000, .size = 0x00000000 },
buf : 		.mem2 = { .start = 0x00000000, .size = 0x00000000 },
buf : 		.mem3 = { .start = 0x00000000, .size = 0x00000000 },
buf : 	},
buf : };
buf : 
buf : static const int wl18xx_rtable[REG_TABLE_LEN] = {
buf : 	[REG_ECPU_CONTROL]		= WL18XX_REG_ECPU_CONTROL,
buf : 	[REG_INTERRUPT_NO_CLEAR]	= WL18XX_REG_INTERRUPT_NO_CLEAR,
buf : 	[REG_INTERRUPT_ACK]		= WL18XX_REG_INTERRUPT_ACK,
buf : 	[REG_COMMAND_MAILBOX_PTR]	= WL18XX_REG_COMMAND_MAILBOX_PTR,
buf : 	[REG_EVENT_MAILBOX_PTR]		= WL18XX_REG_EVENT_MAILBOX_PTR,
buf : 	[REG_INTERRUPT_TRIG]		= WL18XX_REG_INTERRUPT_TRIG_H,
buf : 	[REG_INTERRUPT_MASK]		= WL18XX_REG_INTERRUPT_MASK,
buf : 	[REG_PC_ON_RECOVERY]		= WL18XX_SCR_PAD4,
buf : 	[REG_CHIP_ID_B]			= WL18XX_REG_CHIP_ID_B,
buf : 	[REG_CMD_MBOX_ADDRESS]		= WL18XX_CMD_MBOX_ADDRESS,
buf : 
buf : 	/* data access memory addresses, used with partition translation */
buf : 	[REG_SLV_MEM_DATA]		= WL18XX_SLV_MEM_DATA,
buf : 	[REG_SLV_REG_DATA]		= WL18XX_SLV_REG_DATA,
buf : 
buf : 	/* raw data access memory addresses */
buf : 	[REG_RAW_FW_STATUS_ADDR]	= WL18XX_FW_STATUS_ADDR,
buf : };
buf : 
buf : static const struct wl18xx_clk_cfg wl18xx_clk_table_coex[NUM_CLOCK_CONFIGS] = {
buf : 	[CLOCK_CONFIG_16_2_M]	= { 8,  121, 0, 0, false },
buf : 	[CLOCK_CONFIG_16_368_M]	= { 8,  120, 0, 0, false },
buf : 	[CLOCK_CONFIG_16_8_M]	= { 8,  117, 0, 0, false },
buf : 	[CLOCK_CONFIG_19_2_M]	= { 10, 128, 0, 0, false },
buf : 	[CLOCK_CONFIG_26_M]	= { 11, 104, 0, 0, false },
buf : 	[CLOCK_CONFIG_32_736_M]	= { 8,  120, 0, 0, false },
buf : 	[CLOCK_CONFIG_33_6_M]	= { 8,  117, 0, 0, false },
buf : 	[CLOCK_CONFIG_38_468_M]	= { 10, 128, 0, 0, false },
buf : 	[CLOCK_CONFIG_52_M]	= { 11, 104, 0, 0, false },
buf : };
buf : 
buf : static const struct wl18xx_clk_cfg wl18xx_clk_table[NUM_CLOCK_CONFIGS] = {
buf : 	[CLOCK_CONFIG_16_2_M]	= { 7,  104,  801, 4,  true },
buf : 	[CLOCK_CONFIG_16_368_M]	= { 9,  132, 3751, 4,  true },
buf : 	[CLOCK_CONFIG_16_8_M]	= { 7,  100,    0, 0, false },
buf : 	[CLOCK_CONFIG_19_2_M]	= { 8,  100,    0, 0, false },
buf : 	[CLOCK_CONFIG_26_M]	= { 13, 120,    0, 0, false },
buf : 	[CLOCK_CONFIG_32_736_M]	= { 9,  132, 3751, 4,  true },
buf : 	[CLOCK_CONFIG_33_6_M]	= { 7,  100,    0, 0, false },
buf : 	[CLOCK_CONFIG_38_468_M]	= { 8,  100,    0, 0, false },
buf : 	[CLOCK_CONFIG_52_M]	= { 13, 120,    0, 0, false },
buf : };
buf : 
buf : /* TODO: maybe move to a new header file? */
buf : #define WL18XX_FW_NAME "ti-connectivity/wl18xx-fw-3.bin"
buf : 
buf : static int wl18xx_identify_chip(struct wl1271 *wl)
ify_chip(struct wl1271 *wl) 
buf : {
buf : 	int ret = 0;
buf : 
buf : 	switch (wl->chip.id) {
buf : 	case CHIP_ID_185x_PG20:
buf : 		wl1271_debug(DEBUG_BOOT, "chip id 0x%x (185x PG20)",
buf : 				 wl->chip.id);
buf : 		wl->sr_fw_name = WL18XX_FW_NAME;
buf : 		/* wl18xx uses the same firmware for PLT */
for PLT */ 
buf : 		wl->plt_fw_name = WL18XX_FW_NAME;
buf : 		wl->quirks |= WLCORE_QUIRK_RX_BLOCKSIZE_ALIGN |
buf : 			      WLCORE_QUIRK_TX_BLOCKSIZE_ALIGN |
buf : 			      WLCORE_QUIRK_NO_SCHED_SCAN_WHILE_CONN |
buf : 			      WLCORE_QUIRK_TX_PAD_LAST_FRAME |
buf : 			      WLCORE_QUIRK_REGDOMAIN_CONF |
buf : 			      WLCORE_QUIRK_DUAL_PROBE_TMPL;
buf : 
buf : 		wlcore_set_min_fw_ver(wl, WL18XX_CHIP_VER,
buf : 				      WL18XX_IFTYPE_VER,  WL18XX_MAJOR_VER,
buf : 				      WL18XX_SUBTYPE_VER, WL18XX_MINOR_VER,
buf : 				      /* there's no separate multi-role FW */
buf : 				      0, 0, 0, 0);
buf : 		break;
buf : 	case CHIP_ID_185x_PG10:
buf : 		wl1271_warning("chip id 0x%x (185x PG10) is deprecated",
buf : 			       wl->chip.id);
buf : 		ret = -ENODEV;
buf : 		goto out;
buf : 
buf : 	default:
buf : 		wl1271_warning("unsupported chip id: 0x%x", wl->chip.id);
buf : 		ret = -ENODEV;
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl->fw_mem_block_size = 272;
buf : 	wl->fwlog_end = 0x40000000;
buf : 
buf : 	wl->scan_templ_id_2_4 = CMD_TEMPL_CFG_PROBE_REQ_2_4;
buf : 	wl->scan_templ_id_5 = CMD_TEMPL_CFG_PROBE_REQ_5;
buf : 	wl->sched_scan_templ_id_2_4 = CMD_TEMPL_PROBE_REQ_2_4_PERIODIC;
buf : 	wl->sched_scan_templ_id_5 = CMD_TEMPL_PROBE_REQ_5_PERIODIC;
buf : 	wl->max_channels_5 = WL18XX_MAX_CHANNELS_5GHZ;
buf : 	wl->ba_rx_session_count_max = WL18XX_RX_BA_MAX_SESSIONS;
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_set_clk(struct wl1271 *wl)
buf : {
buf : 	u16 clk_freq;
buf : 	int ret;
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_TOP_PRCM_ELP_SOC]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* TODO: PG2: apparently we need to read the clk type */
buf : 
buf : 	ret = wl18xx_top_reg_read(wl, PRIMARY_CLK_DETECT, &clk_freq);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl1271_debug(DEBUG_BOOT, "clock freq %d (%d, %d, %d, %d, %s)", clk_freq,
buf : 		     wl18xx_clk_table[clk_freq].n, wl18xx_clk_table[clk_freq].m,
buf : 		     wl18xx_clk_table[clk_freq].p, wl18xx_clk_table[clk_freq].q,
buf : 		     wl18xx_clk_table[clk_freq].swallow ? "swallow" : "spit");
buf : 
buf : 	/* coex PLL configuration */
buf : 	ret = wl18xx_top_reg_write(wl, PLLSH_COEX_PLL_N,
buf : 				   wl18xx_clk_table_coex[clk_freq].n);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl18xx_top_reg_write(wl, PLLSH_COEX_PLL_M,
buf : 				   wl18xx_clk_table_coex[clk_freq].m);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* bypass the swallowing logic */
buf : 	ret = wl18xx_top_reg_write(wl, PLLSH_COEX_PLL_SWALLOW_EN,
buf : 				   PLLSH_COEX_PLL_SWALLOW_EN_VAL1);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl18xx_top_reg_write(wl, PLLSH_WCS_PLL_N,
buf : 				   wl18xx_clk_table[clk_freq].n);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl18xx_top_reg_write(wl, PLLSH_WCS_PLL_M,
buf : 				   wl18xx_clk_table[clk_freq].m);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	if (wl18xx_clk_table[clk_freq].swallow) {
if (wl18xx_clk_table[clk_freq].swallow) { 
buf : 		/* first the 16 lower bits */
buf : 		ret = wl18xx_top_reg_write(wl, PLLSH_WCS_PLL_Q_FACTOR_CFG_1,
buf : 					   wl18xx_clk_table[clk_freq].q &
buf : 					   PLLSH_WCS_PLL_Q_FACTOR_CFG_1_MASK);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		/* then the 16 higher bits, masked out */
buf : 		ret = wl18xx_top_reg_write(wl, PLLSH_WCS_PLL_Q_FACTOR_CFG_2,
buf : 					(wl18xx_clk_table[clk_freq].q >> 16) &
buf : 					PLLSH_WCS_PLL_Q_FACTOR_CFG_2_MASK);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		/* first the 16 lower bits */
buf : 		ret = wl18xx_top_reg_write(wl, PLLSH_WCS_PLL_P_FACTOR_CFG_1,
buf : 					   wl18xx_clk_table[clk_freq].p &
buf : 					   PLLSH_WCS_PLL_P_FACTOR_CFG_1_MASK);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		/* then the 16 higher bits, masked out */
buf : 		ret = wl18xx_top_reg_write(wl, PLLSH_WCS_PLL_P_FACTOR_CFG_2,
buf : 					(wl18xx_clk_table[clk_freq].p >> 16) &
buf : 					PLLSH_WCS_PLL_P_FACTOR_CFG_2_MASK);
buf : 	} else {
buf : 		ret = wl18xx_top_reg_write(wl, PLLSH_WCS_PLL_SWALLOW_EN,
buf : 					   PLLSH_WCS_PLL_SWALLOW_EN_VAL2);
buf : 	}
buf : 
buf : 	/* choose WCS PLL */
buf : 	ret = wl18xx_top_reg_write(wl, PLLSH_WL_PLL_SEL,
buf : 				   PLLSH_WL_PLL_SEL_WCS_PLL);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* enable both PLLs */
buf : 	ret = wl18xx_top_reg_write(wl, PLLSH_WL_PLL_EN, PLLSH_WL_PLL_EN_VAL1);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	udelay(1000);
buf : 
buf : 	/* disable coex PLL */
buf : 	ret = wl18xx_top_reg_write(wl, PLLSH_WL_PLL_EN, PLLSH_WL_PLL_EN_VAL2);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* reset the swallowing logic */
buf : 	ret = wl18xx_top_reg_write(wl, PLLSH_COEX_PLL_SWALLOW_EN,
buf : 				   PLLSH_COEX_PLL_SWALLOW_EN_VAL2);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_boot_soft_reset(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	/* disable Rx/Tx */
buf : 	ret = wlcore_write32(wl, WL18XX_ENABLE, 0x0);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* disable auto calibration on start*/
buf : 	ret = wlcore_write32(wl, WL18XX_SPARE_A2, 0xffff);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_pre_boot(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wl18xx_set_clk(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* Continue the ELP wake up sequence */
buf : 	ret = wlcore_write32(wl, WL18XX_WELP_ARM_COMMAND, WELP_ARM_COMMAND_VAL);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	udelay(500);
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_BOOT]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* Disable interrupts */
buf : 	ret = wlcore_write_reg(wl, REG_INTERRUPT_MASK, WL1271_ACX_INTR_ALL);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl18xx_boot_soft_reset(wl);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_pre_upload(struct wl1271 *wl)
buf : {
buf : 	u32 tmp;
buf : 	int ret;
buf : 
buf : 	BUILD_BUG_ON(sizeof(struct wl18xx_mac_and_phy_params) >
buf : 		WL18XX_PHY_INIT_MEM_SIZE);
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_BOOT]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* TODO: check if this is all needed */
if this is all needed */ 
buf : 	ret = wlcore_write32(wl, WL18XX_EEPROMLESS_IND, WL18XX_EEPROMLESS_IND);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_read_reg(wl, REG_CHIP_ID_B, &tmp);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl1271_debug(DEBUG_BOOT, "chip id 0x%x", tmp);
buf : 
buf : 	ret = wlcore_read32(wl, WL18XX_SCR_PAD2, &tmp);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * Workaround for FDSP code RAM corruption (needed for PG2.1
for FDSP code RAM corruption (needed for PG2.1 
buf : 	 * and newer; for older chips it's a NOP).  Change FDSP clock
buf : 	 * settings so that it's muxed to the ATGP clock instead of
buf : 	 * its own clock.
buf : 	 */
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_PHY_INIT]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* disable FDSP clock */
buf : 	ret = wlcore_write32(wl, WL18XX_PHY_FPGA_SPARE_1,
buf : 			     MEM_FDSP_CLK_120_DISABLE);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* set ATPG clock toward FDSP Code RAM rather than its own clock */
buf : 	ret = wlcore_write32(wl, WL18XX_PHY_FPGA_SPARE_1,
buf : 			     MEM_FDSP_CODERAM_FUNC_CLK_SEL);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* re-enable FDSP clock */
buf : 	ret = wlcore_write32(wl, WL18XX_PHY_FPGA_SPARE_1,
buf : 			     MEM_FDSP_CLK_120_ENABLE);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_set_mac_and_phy(struct wl1271 *wl)
buf : {
buf : 	struct wl18xx_priv *priv = wl->priv;
buf : 	struct wl18xx_mac_and_phy_params *params;
buf : 	int ret;
buf : 
buf : 	params = kmemdup(&priv->conf.phy, sizeof(*params), GFP_KERNEL);
buf : 	if (!params) {
if (!params) { 
buf : 		ret = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_PHY_INIT]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_write(wl, WL18XX_PHY_INIT_MEM_ADDR, params,
buf : 			   sizeof(*params), false);
buf : 
buf : out:
buf : 	kfree(params);
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_enable_interrupts(struct wl1271 *wl)
buf : {
buf : 	u32 event_mask, intr_mask;
buf : 	int ret;
buf : 
buf : 	event_mask = WL18XX_ACX_EVENTS_VECTOR;
buf : 	intr_mask = WL18XX_INTR_MASK;
buf : 
buf : 	ret = wlcore_write_reg(wl, REG_INTERRUPT_MASK, event_mask);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wlcore_enable_interrupts(wl);
buf : 
buf : 	ret = wlcore_write_reg(wl, REG_INTERRUPT_MASK,
buf : 			       WL1271_ACX_INTR_ALL & ~intr_mask);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto disable_interrupts;
buf : 
buf : 	return ret;
buf : 
buf : disable_interrupts:
buf : 	wlcore_disable_interrupts(wl);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_boot(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wl18xx_pre_boot(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl18xx_pre_upload(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_boot_upload_firmware(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl18xx_set_mac_and_phy(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl->event_mask = BSS_LOSS_EVENT_ID |
buf : 		SCAN_COMPLETE_EVENT_ID |
buf : 		RSSI_SNR_TRIGGER_0_EVENT_ID |
buf : 		PERIODIC_SCAN_COMPLETE_EVENT_ID |
buf : 		PERIODIC_SCAN_REPORT_EVENT_ID |
buf : 		DUMMY_PACKET_EVENT_ID |
buf : 		PEER_REMOVE_COMPLETE_EVENT_ID |
buf : 		BA_SESSION_RX_CONSTRAINT_EVENT_ID |
buf : 		REMAIN_ON_CHANNEL_COMPLETE_EVENT_ID |
buf : 		INACTIVE_STA_EVENT_ID |
buf : 		CHANNEL_SWITCH_COMPLETE_EVENT_ID |
buf : 		DFS_CHANNELS_CONFIG_COMPLETE_EVENT;
buf : 
buf : 	wl->ap_event_mask = MAX_TX_FAILURE_EVENT_ID;
buf : 
buf : 	ret = wlcore_boot_run_firmware(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl18xx_enable_interrupts(wl);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_trigger_cmd(struct wl1271 *wl, int cmd_box_addr,
buf : 			       void *buf, size_t len)
buf : {
buf : 	struct wl18xx_priv *priv = wl->priv;
buf : 
buf : 	memcpy(priv->cmd_buf, buf, len);
buf : 	memset(priv->cmd_buf + len, 0, WL18XX_CMD_MAX_SIZE - len);
buf : 
buf : 	return wlcore_write(wl, cmd_box_addr, priv->cmd_buf,
buf : 			    WL18XX_CMD_MAX_SIZE, false);
buf : }
buf : 
buf : static int wl18xx_ack_event(struct wl1271 *wl)
buf : {
buf : 	return wlcore_write_reg(wl, REG_INTERRUPT_TRIG,
buf : 				WL18XX_INTR_TRIG_EVENT_ACK);
buf : }
buf : 
buf : static u32 wl18xx_calc_tx_blocks(struct wl1271 *wl, u32 len, u32 spare_blks)
buf : {
buf : 	u32 blk_size = WL18XX_TX_HW_BLOCK_SIZE;
buf : 	return (len + blk_size - 1) / blk_size + spare_blks;
buf : }
buf : 
buf : static void
buf : wl18xx_set_tx_desc_blocks(struct wl1271 *wl, struct wl1271_tx_hw_descr *desc,
buf : 			  u32 blks, u32 spare_blks)
buf : {
buf : 	desc->wl18xx_mem.total_mem_blocks = blks;
buf : }
buf : 
buf : static void
buf : wl18xx_set_tx_desc_data_len(struct wl1271 *wl, struct wl1271_tx_hw_descr *desc,
buf : 			    struct sk_buff *skb)
buf : {
buf : 	desc->length = cpu_to_le16(skb->len);
buf : 
buf : 	/* if only the last frame is to be padded, we unset this bit on Tx */
if only the last frame is to be padded, we unset this bit on Tx */ 
buf : 	if (wl->quirks & WLCORE_QUIRK_TX_PAD_LAST_FRAME)
buf : 		desc->wl18xx_mem.ctrl = WL18XX_TX_CTRL_NOT_PADDED;
buf : 	else
buf : 		desc->wl18xx_mem.ctrl = 0;
buf : 
buf : 	wl1271_debug(DEBUG_TX, "tx_fill_hdr: hlid: %d "
buf : 		     "len: %d life: %d mem: %d", desc->hlid,
ife: %d mem: %d", desc->hlid, 
buf : 		     le16_to_cpu(desc->length),
buf : 		     le16_to_cpu(desc->life_time),
ife_time), 
buf : 		     desc->wl18xx_mem.total_mem_blocks);
buf : }
buf : 
buf : static enum wl_rx_buf_align
buf : wl18xx_get_rx_buf_align(struct wl1271 *wl, u32 rx_desc)
buf : {
buf : 	if (rx_desc & RX_BUF_PADDED_PAYLOAD)
if (rx_desc & RX_BUF_PADDED_PAYLOAD) 
buf : 		return WLCORE_RX_BUF_PADDED;
buf : 
buf : 	return WLCORE_RX_BUF_ALIGNED;
buf : }
buf : 
buf : static u32 wl18xx_get_rx_packet_len(struct wl1271 *wl, void *rx_data,
buf : 				    u32 data_len)
buf : {
buf : 	struct wl1271_rx_descriptor *desc = rx_data;
buf : 
buf : 	/* invalid packet */
buf : 	if (data_len < sizeof(*desc))
if (data_len < sizeof(*desc)) 
buf : 		return 0;
buf : 
buf : 	return data_len - sizeof(*desc);
buf : }
buf : 
buf : static void wl18xx_tx_immediate_completion(struct wl1271 *wl)
buf : {
buf : 	wl18xx_tx_immediate_complete(wl);
buf : }
buf : 
buf : static int wl18xx_set_host_cfg_bitmap(struct wl1271 *wl, u32 extra_mem_blk)
buf : {
buf : 	int ret;
buf : 	u32 sdio_align_size = 0;
buf : 	u32 host_cfg_bitmap = HOST_IF_CFG_RX_FIFO_ENABLE |
buf : 			      HOST_IF_CFG_ADD_RX_ALIGNMENT;
buf : 
buf : 	/* Enable Tx SDIO padding */
buf : 	if (wl->quirks & WLCORE_QUIRK_TX_BLOCKSIZE_ALIGN) {
if (wl->quirks & WLCORE_QUIRK_TX_BLOCKSIZE_ALIGN) { 
buf : 		host_cfg_bitmap |= HOST_IF_CFG_TX_PAD_TO_SDIO_BLK;
buf : 		sdio_align_size = WL12XX_BUS_BLOCK_SIZE;
buf : 	}
buf : 
buf : 	/* Enable Rx SDIO padding */
buf : 	if (wl->quirks & WLCORE_QUIRK_RX_BLOCKSIZE_ALIGN) {
if (wl->quirks & WLCORE_QUIRK_RX_BLOCKSIZE_ALIGN) { 
buf : 		host_cfg_bitmap |= HOST_IF_CFG_RX_PAD_TO_SDIO_BLK;
buf : 		sdio_align_size = WL12XX_BUS_BLOCK_SIZE;
buf : 	}
buf : 
buf : 	ret = wl18xx_acx_host_if_cfg_bitmap(wl, host_cfg_bitmap,
if_cfg_bitmap(wl, host_cfg_bitmap, 
buf : 					    sdio_align_size, extra_mem_blk,
buf : 					    WL18XX_HOST_IF_LEN_SIZE_FIELD);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl18xx_hw_init(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 	struct wl18xx_priv *priv = wl->priv;
buf : 
buf : 	/* (re)init private structures. Relevant on recovery as well. */
buf : 	priv->last_fw_rls_idx = 0;
buf : 	priv->extra_spare_key_count = 0;
buf : 
buf : 	/* set the default amount of spare blocks in the bitmap */
buf : 	ret = wl18xx_set_host_cfg_bitmap(wl, WL18XX_TX_HW_BLOCK_SPARE);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	if (checksum_param) {
if (checksum_param) { 
buf : 		ret = wl18xx_acx_set_checksum_state(wl);
buf : 		if (ret != 0)
if (ret != 0) 
buf : 			return ret;
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void wl18xx_convert_fw_status(struct wl1271 *wl, void *raw_fw_status,
buf : 				     struct wl_fw_status *fw_status)
buf : {
buf : 	struct wl18xx_fw_status *int_fw_status = raw_fw_status;
buf : 
buf : 	fw_status->intr = le32_to_cpu(int_fw_status->intr);
buf : 	fw_status->fw_rx_counter = int_fw_status->fw_rx_counter;
buf : 	fw_status->drv_rx_counter = int_fw_status->drv_rx_counter;
buf : 	fw_status->tx_results_counter = int_fw_status->tx_results_counter;
buf : 	fw_status->rx_pkt_descs = int_fw_status->rx_pkt_descs;
buf : 
buf : 	fw_status->fw_localtime = le32_to_cpu(int_fw_status->fw_localtime);
buf : 	fw_status->link_ps_bitmap = le32_to_cpu(int_fw_status->link_ps_bitmap);
buf : 	fw_status->link_fast_bitmap =
buf : 			le32_to_cpu(int_fw_status->link_fast_bitmap);
buf : 	fw_status->total_released_blks =
buf : 			le32_to_cpu(int_fw_status->total_released_blks);
buf : 	fw_status->tx_total = le32_to_cpu(int_fw_status->tx_total);
buf : 
buf : 	fw_status->counters.tx_released_pkts =
buf : 			int_fw_status->counters.tx_released_pkts;
buf : 	fw_status->counters.tx_lnk_free_pkts =
buf : 			int_fw_status->counters.tx_lnk_free_pkts;
buf : 	fw_status->counters.tx_voice_released_blks =
buf : 			int_fw_status->counters.tx_voice_released_blks;
buf : 	fw_status->counters.tx_last_rate =
buf : 			int_fw_status->counters.tx_last_rate;
buf : 
buf : 	fw_status->log_start_addr = le32_to_cpu(int_fw_status->log_start_addr);
buf : 
buf : 	fw_status->priv = &int_fw_status->priv;
buf : }
buf : 
buf : static void wl18xx_set_tx_desc_csum(struct wl1271 *wl,
buf : 				    struct wl1271_tx_hw_descr *desc,
buf : 				    struct sk_buff *skb)
buf : {
buf : 	u32 ip_hdr_offset;
buf : 	struct iphdr *ip_hdr;
buf : 
buf : 	if (!checksum_param) {
if (!checksum_param) { 
buf : 		desc->wl18xx_checksum_data = 0;
buf : 		return;
buf : 	}
buf : 
buf : 	if (skb->ip_summed != CHECKSUM_PARTIAL) {
if (skb->ip_summed != CHECKSUM_PARTIAL) { 
buf : 		desc->wl18xx_checksum_data = 0;
buf : 		return;
buf : 	}
buf : 
buf : 	ip_hdr_offset = skb_network_header(skb) - skb_mac_header(skb);
buf : 	if (WARN_ON(ip_hdr_offset >= (1<<7))) {
if (WARN_ON(ip_hdr_offset >= (1<<7))) { 
buf : 		desc->wl18xx_checksum_data = 0;
buf : 		return;
buf : 	}
buf : 
buf : 	desc->wl18xx_checksum_data = ip_hdr_offset << 1;
buf : 
buf : 	/* FW is interested only in the LSB of the protocol  TCP=0 UDP=1 */
buf : 	ip_hdr = (void *)skb_network_header(skb);
buf : 	desc->wl18xx_checksum_data |= (ip_hdr->protocol & 0x01);
buf : }
buf : 
buf : static void wl18xx_set_rx_csum(struct wl1271 *wl,
buf : 			       struct wl1271_rx_descriptor *desc,
buf : 			       struct sk_buff *skb)
buf : {
buf : 	if (desc->status & WL18XX_RX_CHECKSUM_MASK)
if (desc->status & WL18XX_RX_CHECKSUM_MASK) 
buf : 		skb->ip_summed = CHECKSUM_UNNECESSARY;
buf : }
buf : 
buf : static bool wl18xx_is_mimo_supported(struct wl1271 *wl)
buf : {
buf : 	struct wl18xx_priv *priv = wl->priv;
buf : 
buf : 	/* only support MIMO with multiple antennas, and when SISO
buf : 	 * is not forced through config
forced through config 
buf : 	 */
buf : 	return (priv->conf.phy.number_of_assembled_ant2_4 >= 2) &&
buf : 	       (priv->conf.ht.mode != HT_MODE_WIDE) &&
buf : 	       (priv->conf.ht.mode != HT_MODE_SISO20);
buf : }
buf : 
buf : /*
buf :  * TODO: instead of having these two functions to get the rate mask,
buf :  * we should modify the wlvif->rate_set instead
ify the wlvif->rate_set instead 
buf :  */
buf : static u32 wl18xx_sta_get_ap_rate_mask(struct wl1271 *wl,
buf : 				       struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	u32 hw_rate_set = wlvif->rate_set;
buf : 
buf : 	if (wlvif->channel_type == NL80211_CHAN_HT40MINUS ||
if (wlvif->channel_type == NL80211_CHAN_HT40MINUS || 
buf : 	    wlvif->channel_type == NL80211_CHAN_HT40PLUS) {
buf : 		wl1271_debug(DEBUG_ACX, "using wide channel rate mask");
buf : 		hw_rate_set |= CONF_TX_RATE_USE_WIDE_CHAN;
buf : 
buf : 		/* we don't support MIMO in wide-channel mode */
buf : 		hw_rate_set &= ~CONF_TX_MIMO_RATES;
buf : 	} else if (wl18xx_is_mimo_supported(wl)) {
if (wl18xx_is_mimo_supported(wl)) { 
buf : 		wl1271_debug(DEBUG_ACX, "using MIMO channel rate mask");
buf : 		hw_rate_set |= CONF_TX_MIMO_RATES;
buf : 	}
buf : 
buf : 	return hw_rate_set;
buf : }
buf : 
buf : static u32 wl18xx_ap_get_mimo_wide_rate_mask(struct wl1271 *wl,
buf : 					     struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	if (wlvif->channel_type == NL80211_CHAN_HT40MINUS ||
buf : 	    wlvif->channel_type == NL80211_CHAN_HT40PLUS) {
if->channel_type == NL80211_CHAN_HT40PLUS) { 
buf : 		wl1271_debug(DEBUG_ACX, "using wide channel rate mask");
buf : 
buf : 		/* sanity check - we don't support this */
buf : 		if (WARN_ON(wlvif->band != IEEE80211_BAND_5GHZ))
if (WARN_ON(wlvif->band != IEEE80211_BAND_5GHZ)) 
buf : 			return 0;
buf : 
buf : 		return CONF_TX_RATE_USE_WIDE_CHAN;
buf : 	} else if (wl18xx_is_mimo_supported(wl) &&
if (wl18xx_is_mimo_supported(wl) && 
buf : 		   wlvif->band == IEEE80211_BAND_2GHZ) {
buf : 		wl1271_debug(DEBUG_ACX, "using MIMO rate mask");
buf : 		/*
buf : 		 * we don't care about HT channel here - if a peer doesn't
if a peer doesn't 
buf : 		 * support MIMO, we won't enable it in its rates
buf : 		 */
buf : 		return CONF_TX_MIMO_RATES;
buf : 	} else {
buf : 		return 0;
buf : 	}
buf : }
buf : 
buf : static const char *wl18xx_rdl_name(enum wl18xx_rdl_num rdl_num)
buf : {
buf : 	switch (rdl_num) {
buf : 	case RDL_1_HP:
buf : 		return "183xH";
buf : 	case RDL_2_SP:
buf : 		return "183x or 180x";
buf : 	case RDL_3_HP:
buf : 		return "187xH";
buf : 	case RDL_4_SP:
buf : 		return "187x";
buf : 	case RDL_5_SP:
buf : 		return "RDL11 - Not Supported";
buf : 	case RDL_6_SP:
buf : 		return "180xD";
buf : 	case RDL_7_SP:
buf : 		return "RDL13 - Not Supported (1893Q)";
buf : 	case RDL_8_SP:
buf : 		return "18xxQ";
buf : 	case RDL_NONE:
buf : 		return "UNTRIMMED";
buf : 	default:
buf : 		return "UNKNOWN";
buf : 	}
buf : }
buf : 
buf : static int wl18xx_get_pg_ver(struct wl1271 *wl, s8 *ver)
buf : {
buf : 	u32 fuse;
buf : 	s8 rom = 0, metal = 0, pg_ver = 0, rdl_ver = 0, package_type = 0;
buf : 	int ret;
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_TOP_PRCM_ELP_SOC]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_read32(wl, WL18XX_REG_FUSE_DATA_2_3, &fuse);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	package_type = (fuse >> WL18XX_PACKAGE_TYPE_OFFSET) & 1;
buf : 
buf : 	ret = wlcore_read32(wl, WL18XX_REG_FUSE_DATA_1_3, &fuse);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	pg_ver = (fuse & WL18XX_PG_VER_MASK) >> WL18XX_PG_VER_OFFSET;
buf : 	rom = (fuse & WL18XX_ROM_VER_MASK) >> WL18XX_ROM_VER_OFFSET;
buf : 
buf : 	if ((rom <= 0xE) && (package_type == WL18XX_PACKAGE_TYPE_WSP))
if ((rom <= 0xE) && (package_type == WL18XX_PACKAGE_TYPE_WSP)) 
buf : 		metal = (fuse & WL18XX_METAL_VER_MASK) >>
buf : 			WL18XX_METAL_VER_OFFSET;
buf : 	else
buf : 		metal = (fuse & WL18XX_NEW_METAL_VER_MASK) >>
buf : 			WL18XX_NEW_METAL_VER_OFFSET;
buf : 
buf : 	ret = wlcore_read32(wl, WL18XX_REG_FUSE_DATA_2_3, &fuse);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	rdl_ver = (fuse & WL18XX_RDL_VER_MASK) >> WL18XX_RDL_VER_OFFSET;
buf : 
buf : 	wl1271_info("wl18xx HW: %s, PG %d.%d (ROM 0x%x)",
buf : 		    wl18xx_rdl_name(rdl_ver), pg_ver, metal, rom);
buf : 
buf : 	if (ver)
if (ver) 
buf : 		*ver = pg_ver;
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_BOOT]);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : #define WL18XX_CONF_FILE_NAME "ti-connectivity/wl18xx-conf.bin"
buf : static int wl18xx_conf_init(struct wl1271 *wl, struct device *dev)
buf : {
buf : 	struct wl18xx_priv *priv = wl->priv;
buf : 	struct wlcore_conf_file *conf_file;
buf : 	const struct firmware *fw;
buf : 	int ret;
buf : 
buf : 	ret = request_firmware(&fw, WL18XX_CONF_FILE_NAME, dev);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1271_error("could not get configuration binary %s: %d",
buf : 			     WL18XX_CONF_FILE_NAME, ret);
buf : 		goto out_fallback;
buf : 	}
buf : 
buf : 	if (fw->size != WL18XX_CONF_SIZE) {
if (fw->size != WL18XX_CONF_SIZE) { 
buf : 		wl1271_error("configuration binary file size is wrong, expected %zu got %zu",
buf : 			     WL18XX_CONF_SIZE, fw->size);
buf : 		ret = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	conf_file = (struct wlcore_conf_file *) fw->data;
buf : 
buf : 	if (conf_file->header.magic != cpu_to_le32(WL18XX_CONF_MAGIC)) {
if (conf_file->header.magic != cpu_to_le32(WL18XX_CONF_MAGIC)) { 
buf : 		wl1271_error("configuration binary file magic number mismatch, "
buf : 			     "expected 0x%0x got 0x%0x", WL18XX_CONF_MAGIC,
buf : 			     conf_file->header.magic);
buf : 		ret = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (conf_file->header.version != cpu_to_le32(WL18XX_CONF_VERSION)) {
if (conf_file->header.version != cpu_to_le32(WL18XX_CONF_VERSION)) { 
buf : 		wl1271_error("configuration binary file version not supported, "
buf : 			     "expected 0x%08x got 0x%08x",
buf : 			     WL18XX_CONF_VERSION, conf_file->header.version);
buf : 		ret = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	memcpy(&wl->conf, &conf_file->core, sizeof(wl18xx_conf));
buf : 	memcpy(&priv->conf, &conf_file->priv, sizeof(priv->conf));
buf : 
buf : 	goto out;
buf : 
buf : out_fallback:
buf : 	wl1271_warning("falling back to default config");
buf : 
buf : 	/* apply driver default configuration */
buf : 	memcpy(&wl->conf, &wl18xx_conf, sizeof(wl18xx_conf));
buf : 	/* apply default private configuration */
buf : 	memcpy(&priv->conf, &wl18xx_default_priv_conf, sizeof(priv->conf));
buf : 
buf : 	/* For now we just fallback */
buf : 	return 0;
buf : 
buf : out:
buf : 	release_firmware(fw);
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_plt_init(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	/* calibrator based auto/fem detect not supported for 18xx */
for 18xx */ 
buf : 	if (wl->plt_mode == PLT_FEM_DETECT) {
buf : 		wl1271_error("wl18xx_plt_init: PLT FEM_DETECT not supported");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	ret = wlcore_write32(wl, WL18XX_SCR_PAD8, WL18XX_SCR_PAD8_PLT);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	return wl->ops->boot(wl);
buf : }
buf : 
buf : static int wl18xx_get_mac(struct wl1271 *wl)
buf : {
buf : 	u32 mac1, mac2;
buf : 	int ret;
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_TOP_PRCM_ELP_SOC]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_read32(wl, WL18XX_REG_FUSE_BD_ADDR_1, &mac1);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_read32(wl, WL18XX_REG_FUSE_BD_ADDR_2, &mac2);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* these are the two parts of the BD_ADDR */
buf : 	wl->fuse_oui_addr = ((mac2 & 0xffff) << 8) +
buf : 		((mac1 & 0xff000000) >> 24);
buf : 	wl->fuse_nic_addr = (mac1 & 0xffffff);
buf : 
buf : 	if (!wl->fuse_oui_addr && !wl->fuse_nic_addr) {
if (!wl->fuse_oui_addr && !wl->fuse_nic_addr) { 
buf : 		u8 mac[ETH_ALEN];
buf : 
buf : 		eth_random_addr(mac);
buf : 
buf : 		wl->fuse_oui_addr = (mac[0] << 16) + (mac[1] << 8) + mac[2];
buf : 		wl->fuse_nic_addr = (mac[3] << 16) + (mac[4] << 8) + mac[5];
buf : 		wl1271_warning("MAC address from fuse not available, using random locally administered addresses.");
buf : 	}
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_DOWN]);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl18xx_handle_static_data(struct wl1271 *wl,
buf : 				     struct wl1271_static_data *static_data)
buf : {
buf : 	struct wl18xx_static_data_priv *static_data_priv =
buf : 		(struct wl18xx_static_data_priv *) static_data->priv;
buf : 
buf : 	strncpy(wl->chip.phy_fw_ver_str, static_data_priv->phy_version,
buf : 		sizeof(wl->chip.phy_fw_ver_str));
buf : 
buf : 	/* make sure the string is NULL-terminated */
buf : 	wl->chip.phy_fw_ver_str[sizeof(wl->chip.phy_fw_ver_str) - 1] = '\0';
buf : 
buf : 	wl1271_info("PHY firmware version: %s", static_data_priv->phy_version);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl18xx_get_spare_blocks(struct wl1271 *wl, bool is_gem)
buf : {
buf : 	struct wl18xx_priv *priv = wl->priv;
buf : 
buf : 	/* If we have keys requiring extra spare, indulge them */
buf : 	if (priv->extra_spare_key_count)
if (priv->extra_spare_key_count) 
buf : 		return WL18XX_TX_HW_EXTRA_BLOCK_SPARE;
buf : 
buf : 	return WL18XX_TX_HW_BLOCK_SPARE;
buf : }
buf : 
buf : static int wl18xx_set_key(struct wl1271 *wl, enum set_key_cmd cmd,
buf : 			  struct ieee80211_vif *vif,
if *vif, 
buf : 			  struct ieee80211_sta *sta,
buf : 			  struct ieee80211_key_conf *key_conf)
buf : {
buf : 	struct wl18xx_priv *priv = wl->priv;
buf : 	bool change_spare = false, special_enc;
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_CRYPT, "extra spare keys before: %d",
fore: %d", 
buf : 		     priv->extra_spare_key_count);
buf : 
buf : 	special_enc = key_conf->cipher == WL1271_CIPHER_SUITE_GEM ||
buf : 		      key_conf->cipher == WLAN_CIPHER_SUITE_TKIP;
buf : 
buf : 	ret = wlcore_set_key(wl, cmd, vif, sta, key_conf);
if, sta, key_conf); 
buf : 	if (ret < 0)
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * when adding the first or removing the last GEM/TKIP key,
buf : 	 * we have to adjust the number of spare blocks.
buf : 	 */
buf : 	if (special_enc) {
if (special_enc) { 
buf : 		if (cmd == SET_KEY) {
buf : 			/* first key */
buf : 			change_spare = (priv->extra_spare_key_count == 0);
buf : 			priv->extra_spare_key_count++;
buf : 		} else if (cmd == DISABLE_KEY) {
if (cmd == DISABLE_KEY) { 
buf : 			/* last key */
buf : 			change_spare = (priv->extra_spare_key_count == 1);
buf : 			priv->extra_spare_key_count--;
buf : 		}
buf : 	}
buf : 
buf : 	wl1271_debug(DEBUG_CRYPT, "extra spare keys after: %d",
buf : 		     priv->extra_spare_key_count);
buf : 
buf : 	if (!change_spare)
if (!change_spare) 
buf : 		goto out;
buf : 
buf : 	/* key is now set, change the spare blocks */
buf : 	if (priv->extra_spare_key_count)
if (priv->extra_spare_key_count) 
buf : 		ret = wl18xx_set_host_cfg_bitmap(wl,
buf : 					WL18XX_TX_HW_EXTRA_BLOCK_SPARE);
buf : 	else
buf : 		ret = wl18xx_set_host_cfg_bitmap(wl,
buf : 					WL18XX_TX_HW_BLOCK_SPARE);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static u32 wl18xx_pre_pkt_send(struct wl1271 *wl,
buf : 			       u32 buf_offset, u32 last_len)
buf : {
buf : 	if (wl->quirks & WLCORE_QUIRK_TX_PAD_LAST_FRAME) {
if (wl->quirks & WLCORE_QUIRK_TX_PAD_LAST_FRAME) { 
buf : 		struct wl1271_tx_hw_descr *last_desc;
buf : 
buf : 		/* get the last TX HW descriptor written to the aggr buf */
buf : 		last_desc = (struct wl1271_tx_hw_descr *)(wl->aggr_buf +
buf : 							buf_offset - last_len);
buf : 
buf : 		/* the last frame is padded up to an SDIO block */
buf : 		last_desc->wl18xx_mem.ctrl &= ~WL18XX_TX_CTRL_NOT_PADDED;
buf : 		return ALIGN(buf_offset, WL12XX_BUS_BLOCK_SIZE);
buf : 	}
buf : 
buf : 	/* no modifications */
ifications */ 
buf : 	return buf_offset;
buf : }
buf : 
buf : static void wl18xx_sta_rc_update(struct wl1271 *wl,
buf : 				 struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 				 struct ieee80211_sta *sta,
buf : 				 u32 changed)
buf : {
buf : 	bool wide = sta->bandwidth >= IEEE80211_STA_RX_BW_40;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 sta_rc_update wide %d", wide);
buf : 
buf : 	if (!(changed & IEEE80211_RC_BW_CHANGED))
if (!(changed & IEEE80211_RC_BW_CHANGED)) 
buf : 		return;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	/* sanity */
buf : 	if (WARN_ON(wlvif->bss_type != BSS_TYPE_STA_BSS))
if (WARN_ON(wlvif->bss_type != BSS_TYPE_STA_BSS)) 
buf : 		goto out;
buf : 
buf : 	/* ignore the change before association */
fore association */ 
buf : 	if (!test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags))
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * If we started out as wide, we can change the operation mode. If we
buf : 	 * thought this was a 20mhz AP, we have to reconnect
buf : 	 */
buf : 	if (wlvif->sta.role_chan_type == NL80211_CHAN_HT40MINUS ||
if (wlvif->sta.role_chan_type == NL80211_CHAN_HT40MINUS || 
buf : 	    wlvif->sta.role_chan_type == NL80211_CHAN_HT40PLUS)
buf : 		wl18xx_acx_peer_ht_operation_mode(wl, wlvif->sta.hlid, wide);
if->sta.hlid, wide); 
buf : 	else
buf : 		ieee80211_connection_loss(wl12xx_wlvif_to_vif(wlvif));
if_to_vif(wlvif)); 
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int wl18xx_set_peer_cap(struct wl1271 *wl,
buf : 			       struct ieee80211_sta_ht_cap *ht_cap,
buf : 			       bool allow_ht_operation,
buf : 			       u32 rate_set, u8 hlid)
buf : {
buf : 	return wl18xx_acx_set_peer_cap(wl, ht_cap, allow_ht_operation,
buf : 				       rate_set, hlid);
buf : }
buf : 
buf : static bool wl18xx_lnk_high_prio(struct wl1271 *wl, u8 hlid,
buf : 				 struct wl1271_link *lnk)
buf : {
buf : 	u8 thold;
buf : 	struct wl18xx_fw_status_priv *status_priv =
buf : 		(struct wl18xx_fw_status_priv *)wl->fw_status->priv;
buf : 	u32 suspend_bitmap = le32_to_cpu(status_priv->link_suspend_bitmap);
buf : 
buf : 	/* suspended links are never high priority */
buf : 	if (test_bit(hlid, (unsigned long *)&suspend_bitmap))
if (test_bit(hlid, (unsigned long *)&suspend_bitmap)) 
buf : 		return false;
buf : 
buf : 	/* the priority thresholds are taken from FW */
buf : 	if (test_bit(hlid, (unsigned long *)&wl->fw_fast_lnk_map) &&
if (test_bit(hlid, (unsigned long *)&wl->fw_fast_lnk_map) && 
buf : 	    !test_bit(hlid, (unsigned long *)&wl->ap_fw_ps_map))
buf : 		thold = status_priv->tx_fast_link_prio_threshold;
buf : 	else
buf : 		thold = status_priv->tx_slow_link_prio_threshold;
buf : 
buf : 	return lnk->allocated_pkts < thold;
buf : }
buf : 
buf : static bool wl18xx_lnk_low_prio(struct wl1271 *wl, u8 hlid,
buf : 				struct wl1271_link *lnk)
buf : {
buf : 	u8 thold;
buf : 	struct wl18xx_fw_status_priv *status_priv =
buf : 		(struct wl18xx_fw_status_priv *)wl->fw_status->priv;
buf : 	u32 suspend_bitmap = le32_to_cpu(status_priv->link_suspend_bitmap);
buf : 
buf : 	if (test_bit(hlid, (unsigned long *)&suspend_bitmap))
if (test_bit(hlid, (unsigned long *)&suspend_bitmap)) 
buf : 		thold = status_priv->tx_suspend_threshold;
buf : 	else if (test_bit(hlid, (unsigned long *)&wl->fw_fast_lnk_map) &&
if (test_bit(hlid, (unsigned long *)&wl->fw_fast_lnk_map) && 
buf : 		 !test_bit(hlid, (unsigned long *)&wl->ap_fw_ps_map))
buf : 		thold = status_priv->tx_fast_stop_threshold;
buf : 	else
buf : 		thold = status_priv->tx_slow_stop_threshold;
buf : 
buf : 	return lnk->allocated_pkts < thold;
buf : }
buf : 
buf : static u32 wl18xx_convert_hwaddr(struct wl1271 *wl, u32 hwaddr)
buf : {
buf : 	return hwaddr & ~0x80000000;
buf : }
buf : 
buf : static int wl18xx_setup(struct wl1271 *wl);
buf : 
buf : static struct wlcore_ops wl18xx_ops = {
buf : 	.setup		= wl18xx_setup,
buf : 	.identify_chip	= wl18xx_identify_chip,
ify_chip	= wl18xx_identify_chip, 
buf : 	.boot		= wl18xx_boot,
buf : 	.plt_init	= wl18xx_plt_init,
buf : 	.trigger_cmd	= wl18xx_trigger_cmd,
buf : 	.ack_event	= wl18xx_ack_event,
buf : 	.wait_for_event	= wl18xx_wait_for_event,
for_event	= wl18xx_wait_for_event, 
buf : 	.process_mailbox_events = wl18xx_process_mailbox_events,
buf : 	.calc_tx_blocks = wl18xx_calc_tx_blocks,
buf : 	.set_tx_desc_blocks = wl18xx_set_tx_desc_blocks,
buf : 	.set_tx_desc_data_len = wl18xx_set_tx_desc_data_len,
buf : 	.get_rx_buf_align = wl18xx_get_rx_buf_align,
buf : 	.get_rx_packet_len = wl18xx_get_rx_packet_len,
buf : 	.tx_immediate_compl = wl18xx_tx_immediate_completion,
buf : 	.tx_delayed_compl = NULL,
buf : 	.hw_init	= wl18xx_hw_init,
buf : 	.convert_fw_status = wl18xx_convert_fw_status,
buf : 	.set_tx_desc_csum = wl18xx_set_tx_desc_csum,
buf : 	.get_pg_ver	= wl18xx_get_pg_ver,
buf : 	.set_rx_csum = wl18xx_set_rx_csum,
buf : 	.sta_get_ap_rate_mask = wl18xx_sta_get_ap_rate_mask,
buf : 	.ap_get_mimo_wide_rate_mask = wl18xx_ap_get_mimo_wide_rate_mask,
buf : 	.get_mac	= wl18xx_get_mac,
buf : 	.debugfs_init	= wl18xx_debugfs_add_files,
buf : 	.scan_start	= wl18xx_scan_start,
buf : 	.scan_stop	= wl18xx_scan_stop,
buf : 	.sched_scan_start	= wl18xx_sched_scan_start,
buf : 	.sched_scan_stop	= wl18xx_scan_sched_scan_stop,
buf : 	.handle_static_data	= wl18xx_handle_static_data,
buf : 	.get_spare_blocks = wl18xx_get_spare_blocks,
buf : 	.set_key	= wl18xx_set_key,
buf : 	.channel_switch	= wl18xx_cmd_channel_switch,
buf : 	.pre_pkt_send	= wl18xx_pre_pkt_send,
buf : 	.sta_rc_update	= wl18xx_sta_rc_update,
buf : 	.set_peer_cap	= wl18xx_set_peer_cap,
buf : 	.convert_hwaddr = wl18xx_convert_hwaddr,
buf : 	.lnk_high_prio	= wl18xx_lnk_high_prio,
buf : 	.lnk_low_prio	= wl18xx_lnk_low_prio,
buf : };
buf : 
buf : /* HT cap appropriate for wide channels in 2Ghz */
for wide channels in 2Ghz */ 
buf : static struct ieee80211_sta_ht_cap wl18xx_siso40_ht_cap_2ghz = {
buf : 	.cap = IEEE80211_HT_CAP_SGI_20 | IEEE80211_HT_CAP_SGI_40 |
buf : 	       IEEE80211_HT_CAP_SUP_WIDTH_20_40 | IEEE80211_HT_CAP_DSSSCCK40 |
buf : 	       IEEE80211_HT_CAP_GRN_FLD,
buf : 	.ht_supported = true,
buf : 	.ampdu_factor = IEEE80211_HT_MAX_AMPDU_16K,
buf : 	.ampdu_density = IEEE80211_HT_MPDU_DENSITY_16,
buf : 	.mcs = {
buf : 		.rx_mask = { 0xff, 0, 0, 0, 0, 0, 0, 0, 0, 0, },
buf : 		.rx_highest = cpu_to_le16(150),
buf : 		.tx_params = IEEE80211_HT_MCS_TX_DEFINED,
buf : 		},
buf : };
buf : 
buf : /* HT cap appropriate for wide channels in 5Ghz */
for wide channels in 5Ghz */ 
buf : static struct ieee80211_sta_ht_cap wl18xx_siso40_ht_cap_5ghz = {
buf : 	.cap = IEEE80211_HT_CAP_SGI_20 | IEEE80211_HT_CAP_SGI_40 |
buf : 	       IEEE80211_HT_CAP_SUP_WIDTH_20_40 |
buf : 	       IEEE80211_HT_CAP_GRN_FLD,
buf : 	.ht_supported = true,
buf : 	.ampdu_factor = IEEE80211_HT_MAX_AMPDU_16K,
buf : 	.ampdu_density = IEEE80211_HT_MPDU_DENSITY_16,
buf : 	.mcs = {
buf : 		.rx_mask = { 0xff, 0, 0, 0, 0, 0, 0, 0, 0, 0, },
buf : 		.rx_highest = cpu_to_le16(150),
buf : 		.tx_params = IEEE80211_HT_MCS_TX_DEFINED,
buf : 		},
buf : };
buf : 
buf : /* HT cap appropriate for SISO 20 */
for SISO 20 */ 
buf : static struct ieee80211_sta_ht_cap wl18xx_siso20_ht_cap = {
buf : 	.cap = IEEE80211_HT_CAP_SGI_20 |
buf : 	       IEEE80211_HT_CAP_GRN_FLD,
buf : 	.ht_supported = true,
buf : 	.ampdu_factor = IEEE80211_HT_MAX_AMPDU_16K,
buf : 	.ampdu_density = IEEE80211_HT_MPDU_DENSITY_16,
buf : 	.mcs = {
buf : 		.rx_mask = { 0xff, 0, 0, 0, 0, 0, 0, 0, 0, 0, },
buf : 		.rx_highest = cpu_to_le16(72),
buf : 		.tx_params = IEEE80211_HT_MCS_TX_DEFINED,
buf : 		},
buf : };
buf : 
buf : /* HT cap appropriate for MIMO rates in 20mhz channel */
for MIMO rates in 20mhz channel */ 
buf : static struct ieee80211_sta_ht_cap wl18xx_mimo_ht_cap_2ghz = {
buf : 	.cap = IEEE80211_HT_CAP_SGI_20 |
buf : 	       IEEE80211_HT_CAP_GRN_FLD,
buf : 	.ht_supported = true,
buf : 	.ampdu_factor = IEEE80211_HT_MAX_AMPDU_16K,
buf : 	.ampdu_density = IEEE80211_HT_MPDU_DENSITY_16,
buf : 	.mcs = {
buf : 		.rx_mask = { 0xff, 0xff, 0, 0, 0, 0, 0, 0, 0, 0, },
buf : 		.rx_highest = cpu_to_le16(144),
buf : 		.tx_params = IEEE80211_HT_MCS_TX_DEFINED,
buf : 		},
buf : };
buf : 
buf : static const struct ieee80211_iface_limit wl18xx_iface_limits[] = {
iface_limit wl18xx_iface_limits[] = { 
buf : 	{
buf : 		.max = 3,
buf : 		.types = BIT(NL80211_IFTYPE_STATION),
buf : 	},
buf : 	{
buf : 		.max = 1,
buf : 		.types = BIT(NL80211_IFTYPE_AP) |
buf : 			 BIT(NL80211_IFTYPE_P2P_GO) |
buf : 			 BIT(NL80211_IFTYPE_P2P_CLIENT),
buf : 	},
buf : };
buf : 
buf : static const struct ieee80211_iface_limit wl18xx_iface_ap_limits[] = {
iface_limit wl18xx_iface_ap_limits[] = { 
buf : 	{
buf : 		.max = 2,
buf : 		.types = BIT(NL80211_IFTYPE_AP),
buf : 	},
buf : };
buf : 
buf : static const struct ieee80211_iface_combination
iface_combination 
buf : wl18xx_iface_combinations[] = {
buf : 	{
buf : 		.max_interfaces = 3,
buf : 		.limits = wl18xx_iface_limits,
iface_limits, 
buf : 		.n_limits = ARRAY_SIZE(wl18xx_iface_limits),
buf : 		.num_different_channels = 2,
ifferent_channels = 2, 
buf : 	},
buf : 	{
buf : 		.max_interfaces = 2,
buf : 		.limits = wl18xx_iface_ap_limits,
iface_ap_limits, 
buf : 		.n_limits = ARRAY_SIZE(wl18xx_iface_ap_limits),
buf : 		.num_different_channels = 1,
ifferent_channels = 1, 
buf : 	}
buf : };
buf : 
buf : static int wl18xx_setup(struct wl1271 *wl)
buf : {
buf : 	struct wl18xx_priv *priv = wl->priv;
buf : 	int ret;
buf : 
buf : 	BUILD_BUG_ON(WL18XX_MAX_LINKS > WLCORE_MAX_LINKS);
buf : 	BUILD_BUG_ON(WL18XX_MAX_AP_STATIONS > WL18XX_MAX_LINKS);
buf : 
buf : 	wl->rtable = wl18xx_rtable;
buf : 	wl->num_tx_desc = WL18XX_NUM_TX_DESCRIPTORS;
buf : 	wl->num_rx_desc = WL18XX_NUM_RX_DESCRIPTORS;
buf : 	wl->num_links = WL18XX_MAX_LINKS;
buf : 	wl->max_ap_stations = WL18XX_MAX_AP_STATIONS;
buf : 	wl->iface_combinations = wl18xx_iface_combinations;
iface_combinations = wl18xx_iface_combinations; 
buf : 	wl->n_iface_combinations = ARRAY_SIZE(wl18xx_iface_combinations);
buf : 	wl->num_mac_addr = WL18XX_NUM_MAC_ADDRESSES;
buf : 	wl->band_rate_to_idx = wl18xx_band_rate_to_idx;
buf : 	wl->hw_tx_rate_tbl_size = WL18XX_CONF_HW_RXTX_RATE_MAX;
buf : 	wl->hw_min_ht_rate = WL18XX_CONF_HW_RXTX_RATE_MCS0;
buf : 	wl->fw_status_len = sizeof(struct wl18xx_fw_status);
buf : 	wl->fw_status_priv_len = sizeof(struct wl18xx_fw_status_priv);
buf : 	wl->stats.fw_stats_len = sizeof(struct wl18xx_acx_statistics);
buf : 	wl->static_data_priv_len = sizeof(struct wl18xx_static_data_priv);
buf : 
buf : 	if (num_rx_desc_param != -1)
if (num_rx_desc_param != -1) 
buf : 		wl->num_rx_desc = num_rx_desc_param;
buf : 
buf : 	ret = wl18xx_conf_init(wl, wl->dev);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	/* If the module param is set, update it in conf */
buf : 	if (board_type_param) {
if (board_type_param) { 
buf : 		if (!strcmp(board_type_param, "fpga")) {
buf : 			priv->conf.phy.board_type = BOARD_TYPE_FPGA_18XX;
buf : 		} else if (!strcmp(board_type_param, "hdk")) {
if (!strcmp(board_type_param, "hdk")) { 
buf : 			priv->conf.phy.board_type = BOARD_TYPE_HDK_18XX;
buf : 		} else if (!strcmp(board_type_param, "dvp")) {
if (!strcmp(board_type_param, "dvp")) { 
buf : 			priv->conf.phy.board_type = BOARD_TYPE_DVP_18XX;
buf : 		} else if (!strcmp(board_type_param, "evb")) {
if (!strcmp(board_type_param, "evb")) { 
buf : 			priv->conf.phy.board_type = BOARD_TYPE_EVB_18XX;
buf : 		} else if (!strcmp(board_type_param, "com8")) {
if (!strcmp(board_type_param, "com8")) { 
buf : 			priv->conf.phy.board_type = BOARD_TYPE_COM8_18XX;
buf : 		} else {
buf : 			wl1271_error("invalid board type '%s'",
buf : 				board_type_param);
buf : 			return -EINVAL;
buf : 		}
buf : 	}
buf : 
buf : 	if (priv->conf.phy.board_type >= NUM_BOARD_TYPES) {
if (priv->conf.phy.board_type >= NUM_BOARD_TYPES) { 
buf : 		wl1271_error("invalid board type '%d'",
buf : 			priv->conf.phy.board_type);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	if (low_band_component_param != -1)
if (low_band_component_param != -1) 
buf : 		priv->conf.phy.low_band_component = low_band_component_param;
buf : 	if (low_band_component_type_param != -1)
if (low_band_component_type_param != -1) 
buf : 		priv->conf.phy.low_band_component_type =
buf : 			low_band_component_type_param;
buf : 	if (high_band_component_param != -1)
if (high_band_component_param != -1) 
buf : 		priv->conf.phy.high_band_component = high_band_component_param;
buf : 	if (high_band_component_type_param != -1)
if (high_band_component_type_param != -1) 
buf : 		priv->conf.phy.high_band_component_type =
buf : 			high_band_component_type_param;
buf : 	if (pwr_limit_reference_11_abg_param != -1)
if (pwr_limit_reference_11_abg_param != -1) 
buf : 		priv->conf.phy.pwr_limit_reference_11_abg =
buf : 			pwr_limit_reference_11_abg_param;
buf : 	if (n_antennas_2_param != -1)
if (n_antennas_2_param != -1) 
buf : 		priv->conf.phy.number_of_assembled_ant2_4 = n_antennas_2_param;
buf : 	if (n_antennas_5_param != -1)
if (n_antennas_5_param != -1) 
buf : 		priv->conf.phy.number_of_assembled_ant5 = n_antennas_5_param;
buf : 	if (dc2dc_param != -1)
if (dc2dc_param != -1) 
buf : 		priv->conf.phy.external_pa_dc2dc = dc2dc_param;
buf : 
buf : 	if (ht_mode_param) {
if (ht_mode_param) { 
buf : 		if (!strcmp(ht_mode_param, "default"))
buf : 			priv->conf.ht.mode = HT_MODE_DEFAULT;
buf : 		else if (!strcmp(ht_mode_param, "wide"))
if (!strcmp(ht_mode_param, "wide")) 
buf : 			priv->conf.ht.mode = HT_MODE_WIDE;
buf : 		else if (!strcmp(ht_mode_param, "siso20"))
if (!strcmp(ht_mode_param, "siso20")) 
buf : 			priv->conf.ht.mode = HT_MODE_SISO20;
buf : 		else {
buf : 			wl1271_error("invalid ht_mode '%s'", ht_mode_param);
buf : 			return -EINVAL;
buf : 		}
buf : 	}
buf : 
buf : 	if (priv->conf.ht.mode == HT_MODE_DEFAULT) {
if (priv->conf.ht.mode == HT_MODE_DEFAULT) { 
buf : 		/*
buf : 		 * Only support mimo with multiple antennas. Fall back to
buf : 		 * siso40.
buf : 		 */
buf : 		if (wl18xx_is_mimo_supported(wl))
if (wl18xx_is_mimo_supported(wl)) 
buf : 			wlcore_set_ht_cap(wl, IEEE80211_BAND_2GHZ,
buf : 					  &wl18xx_mimo_ht_cap_2ghz);
buf : 		else
buf : 			wlcore_set_ht_cap(wl, IEEE80211_BAND_2GHZ,
buf : 					  &wl18xx_siso40_ht_cap_2ghz);
buf : 
buf : 		/* 5Ghz is always wide */
buf : 		wlcore_set_ht_cap(wl, IEEE80211_BAND_5GHZ,
buf : 				  &wl18xx_siso40_ht_cap_5ghz);
buf : 	} else if (priv->conf.ht.mode == HT_MODE_WIDE) {
if (priv->conf.ht.mode == HT_MODE_WIDE) { 
buf : 		wlcore_set_ht_cap(wl, IEEE80211_BAND_2GHZ,
buf : 				  &wl18xx_siso40_ht_cap_2ghz);
buf : 		wlcore_set_ht_cap(wl, IEEE80211_BAND_5GHZ,
buf : 				  &wl18xx_siso40_ht_cap_5ghz);
buf : 	} else if (priv->conf.ht.mode == HT_MODE_SISO20) {
if (priv->conf.ht.mode == HT_MODE_SISO20) { 
buf : 		wlcore_set_ht_cap(wl, IEEE80211_BAND_2GHZ,
buf : 				  &wl18xx_siso20_ht_cap);
buf : 		wlcore_set_ht_cap(wl, IEEE80211_BAND_5GHZ,
buf : 				  &wl18xx_siso20_ht_cap);
buf : 	}
buf : 
buf : 	if (!checksum_param) {
if (!checksum_param) { 
buf : 		wl18xx_ops.set_rx_csum = NULL;
buf : 		wl18xx_ops.init_vif = NULL;
if = NULL; 
buf : 	}
buf : 
buf : 	/* Enable 11a Band only if we have 5G antennas */
buf : 	wl->enable_11a = (priv->conf.phy.number_of_assembled_ant5 != 0);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl18xx_probe(struct platform_device *pdev)
form_device *pdev) 
buf : {
buf : 	struct wl1271 *wl;
buf : 	struct ieee80211_hw *hw;
buf : 	int ret;
buf : 
buf : 	hw = wlcore_alloc_hw(sizeof(struct wl18xx_priv),
buf : 			     WL18XX_AGGR_BUFFER_SIZE,
buf : 			     sizeof(struct wl18xx_event_mailbox));
buf : 	if (IS_ERR(hw)) {
if (IS_ERR(hw)) { 
buf : 		wl1271_error("can't allocate hw");
buf : 		ret = PTR_ERR(hw);
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl = hw->priv;
buf : 	wl->ops = &wl18xx_ops;
buf : 	wl->ptable = wl18xx_ptable;
buf : 	ret = wlcore_probe(wl, pdev);
buf : 	if (ret)
if (ret) 
buf : 		goto out_free;
buf : 
buf : 	return ret;
buf : 
buf : out_free:
buf : 	wlcore_free_hw(wl);
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static const struct platform_device_id wl18xx_id_table[] = {
form_device_id wl18xx_id_table[] = { 
buf : 	{ "wl18xx", 0 },
buf : 	{  } /* Terminating Entry */
buf : };
buf : MODULE_DEVICE_TABLE(platform, wl18xx_id_table);
form, wl18xx_id_table); 
buf : 
buf : static struct platform_driver wl18xx_driver = {
buf : 	.probe		= wl18xx_probe,
buf : 	.remove		= wlcore_remove,
buf : 	.id_table	= wl18xx_id_table,
buf : 	.driver = {
buf : 		.name	= "wl18xx_driver",
buf : 		.owner	= THIS_MODULE,
buf : 	}
buf : };
buf : 
buf : module_platform_driver(wl18xx_driver);
form_driver(wl18xx_driver); 
buf : module_param_named(ht_mode, ht_mode_param, charp, S_IRUSR);
buf : MODULE_PARM_DESC(ht_mode, "Force HT mode: wide or siso20");
buf : 
buf : module_param_named(board_type, board_type_param, charp, S_IRUSR);
buf : MODULE_PARM_DESC(board_type, "Board type: fpga, hdk (default), evb, com8 or "
buf : 		 "dvp");
buf : 
buf : module_param_named(checksum, checksum_param, bool, S_IRUSR);
buf : MODULE_PARM_DESC(checksum, "Enable TCP checksum: boolean (defaults to false)");
buf : 
buf : module_param_named(dc2dc, dc2dc_param, int, S_IRUSR);
buf : MODULE_PARM_DESC(dc2dc, "External DC2DC: u8 (defaults to 0)");
buf : 
buf : module_param_named(n_antennas_2, n_antennas_2_param, int, S_IRUSR);
buf : MODULE_PARM_DESC(n_antennas_2,
buf : 		 "Number of installed 2.4GHz antennas: 1 (default) or 2");
buf : 
buf : module_param_named(n_antennas_5, n_antennas_5_param, int, S_IRUSR);
buf : MODULE_PARM_DESC(n_antennas_5,
buf : 		 "Number of installed 5GHz antennas: 1 (default) or 2");
buf : 
buf : module_param_named(low_band_component, low_band_component_param, int,
buf : 		   S_IRUSR);
buf : MODULE_PARM_DESC(low_band_component, "Low band component: u8 "
buf : 		 "(default is 0x01)");
buf : 
buf : module_param_named(low_band_component_type, low_band_component_type_param,
buf : 		   int, S_IRUSR);
buf : MODULE_PARM_DESC(low_band_component_type, "Low band component type: u8 "
buf : 		 "(default is 0x05 or 0x06 depending on the board_type)");
buf : 
buf : module_param_named(high_band_component, high_band_component_param, int,
buf : 		   S_IRUSR);
buf : MODULE_PARM_DESC(high_band_component, "High band component: u8, "
buf : 		 "(default is 0x01)");
buf : 
buf : module_param_named(high_band_component_type, high_band_component_type_param,
buf : 		   int, S_IRUSR);
buf : MODULE_PARM_DESC(high_band_component_type, "High band component type: u8 "
buf : 		 "(default is 0x09)");
buf : 
buf : module_param_named(pwr_limit_reference_11_abg,
buf : 		   pwr_limit_reference_11_abg_param, int, S_IRUSR);
buf : MODULE_PARM_DESC(pwr_limit_reference_11_abg, "Power limit reference: u8 "
buf : 		 "(default is 0xc8)");
buf : 
buf : module_param_named(num_rx_desc,
buf : 		   num_rx_desc_param, int, S_IRUSR);
buf : MODULE_PARM_DESC(num_rx_desc_param,
buf : 		 "Number of Rx descriptors: u8 (default is 32)");
buf : 
buf : MODULE_LICENSE("GPL v2");
buf : MODULE_AUTHOR("Luciano Coelho <coelho@ti.com>");
buf : MODULE_FIRMWARE(WL18XX_FW_NAME);
file : ./test/kernel/drivers/net/wireless/ti/wlcore/main.c 
[ OK ] open : 4 ok... 
buf : 
buf : /*
buf :  * This file is part of wlcore
buf :  *
buf :  * Copyright (C) 2008-2010 Nokia Corporation
buf :  * Copyright (C) 2011-2013 Texas Instruments Inc.
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of the GNU General Public License
ify it under the terms of the GNU General Public License 
buf :  * version 2 as published by the Free Software Foundation.
buf :  *
buf :  * This program is distributed in the hope that it will be useful, but
buf :  * WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
buf :  * General Public License for more details.
for more details. 
buf :  *
buf :  * You should have received a copy of the GNU General Public License
buf :  * along with this program; if not, write to the Free Software
if not, write to the Free Software 
buf :  * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
buf :  * 02110-1301 USA
buf :  *
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/firmware.h>
buf : #include <linux/etherdevice.h>
buf : #include <linux/vmalloc.h>
buf : #include <linux/wl12xx.h>
buf : #include <linux/interrupt.h>
buf : 
buf : #include "wlcore.h"
buf : #include "debug.h"
buf : #include "wl12xx_80211.h"
buf : #include "io.h"
buf : #include "tx.h"
buf : #include "ps.h"
buf : #include "init.h"
buf : #include "debugfs.h"
buf : #include "testmode.h"
buf : #include "scan.h"
buf : #include "hw_ops.h"
buf : #include "sysfs.h"
buf : 
buf : #define WL1271_BOOT_RETRIES 3
buf : 
buf : static char *fwlog_param;
buf : static int fwlog_mem_blocks = -1;
buf : static int bug_on_recovery = -1;
buf : static int no_recovery     = -1;
buf : 
buf : static void __wl1271_op_remove_interface(struct wl1271 *wl,
buf : 					 struct ieee80211_vif *vif,
if *vif, 
buf : 					 bool reset_tx_queues);
buf : static void wlcore_op_stop_locked(struct wl1271 *wl);
buf : static void wl1271_free_ap_keys(struct wl1271 *wl, struct wl12xx_vif *wlvif);
if *wlvif); 
buf : 
buf : static int wl12xx_set_authorized(struct wl1271 *wl, struct wl12xx_vif *wlvif)
buf : {
buf : 	int ret;
buf : 
buf : 	if (WARN_ON(wlvif->bss_type != BSS_TYPE_STA_BSS))
if (WARN_ON(wlvif->bss_type != BSS_TYPE_STA_BSS)) 
buf : 		return -EINVAL;
buf : 
buf : 	if (!test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags))
if (!test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags)) 
buf : 		return 0;
buf : 
buf : 	if (test_and_set_bit(WLVIF_FLAG_STA_STATE_SENT, &wlvif->flags))
if (test_and_set_bit(WLVIF_FLAG_STA_STATE_SENT, &wlvif->flags)) 
buf : 		return 0;
buf : 
buf : 	ret = wl12xx_cmd_set_peer_state(wl, wlvif, wlvif->sta.hlid);
if, wlvif->sta.hlid); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	wl1271_info("Association completed.");
buf : 	return 0;
buf : }
buf : 
buf : static void wl1271_reg_notify(struct wiphy *wiphy,
ify(struct wiphy *wiphy, 
buf : 			      struct regulatory_request *request)
buf : {
buf : 	struct ieee80211_supported_band *band;
buf : 	struct ieee80211_channel *ch;
buf : 	int i;
buf : 	struct ieee80211_hw *hw = wiphy_to_ieee80211_hw(wiphy);
buf : 	struct wl1271 *wl = hw->priv;
buf : 
buf : 	band = wiphy->bands[IEEE80211_BAND_5GHZ];
buf : 	for (i = 0; i < band->n_channels; i++) {
for (i = 0; i < band->n_channels; i++) { 
buf : 		ch = &band->channels[i];
buf : 		if (ch->flags & IEEE80211_CHAN_DISABLED)
if (ch->flags & IEEE80211_CHAN_DISABLED) 
buf : 			continue;
buf : 
buf : 		if (ch->flags & IEEE80211_CHAN_RADAR)
if (ch->flags & IEEE80211_CHAN_RADAR) 
buf : 			ch->flags |= IEEE80211_CHAN_NO_IR;
buf : 
buf : 	}
buf : 
buf : 	wlcore_regdomain_config(wl);
buf : }
buf : 
buf : static int wl1271_set_rx_streaming(struct wl1271 *wl, struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 				   bool enable)
buf : {
buf : 	int ret = 0;
buf : 
buf : 	/* we should hold wl->mutex */
buf : 	ret = wl1271_acx_ps_rx_streaming(wl, wlvif, enable);
if, enable); 
buf : 	if (ret < 0)
buf : 		goto out;
buf : 
buf : 	if (enable)
if (enable) 
buf : 		set_bit(WLVIF_FLAG_RX_STREAMING_STARTED, &wlvif->flags);
buf : 	else
buf : 		clear_bit(WLVIF_FLAG_RX_STREAMING_STARTED, &wlvif->flags);
if->flags); 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : /*
buf :  * this function is being called when the rx_streaming interval
buf :  * has beed changed or rx_streaming should be disabled
buf :  */
buf : int wl1271_recalc_rx_streaming(struct wl1271 *wl, struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	int ret = 0;
buf : 	int period = wl->conf.rx_streaming.interval;
buf : 
buf : 	/* don't reconfigure if rx_streaming is disabled */
if rx_streaming is disabled */ 
buf : 	if (!test_bit(WLVIF_FLAG_RX_STREAMING_STARTED, &wlvif->flags))
buf : 		goto out;
buf : 
buf : 	/* reconfigure/disable according to new streaming_period */
buf : 	if (period &&
if (period && 
buf : 	    test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags) &&
buf : 	    (wl->conf.rx_streaming.always ||
buf : 	     test_bit(WL1271_FLAG_SOFT_GEMINI, &wl->flags)))
buf : 		ret = wl1271_set_rx_streaming(wl, wlvif, true);
if, true); 
buf : 	else {
buf : 		ret = wl1271_set_rx_streaming(wl, wlvif, false);
if, false); 
buf : 		/* don't cancel_work_sync since we might deadlock */
buf : 		del_timer_sync(&wlvif->rx_streaming_timer);
if->rx_streaming_timer); 
buf : 	}
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static void wl1271_rx_streaming_enable_work(struct work_struct *work)
buf : {
buf : 	int ret;
buf : 	struct wl12xx_vif *wlvif = container_of(work, struct wl12xx_vif,
if *wlvif = container_of(work, struct wl12xx_vif, 
buf : 						rx_streaming_enable_work);
buf : 	struct wl1271 *wl = wlvif->wl;
if->wl; 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (test_bit(WLVIF_FLAG_RX_STREAMING_STARTED, &wlvif->flags) ||
if (test_bit(WLVIF_FLAG_RX_STREAMING_STARTED, &wlvif->flags) || 
buf : 	    !test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags) ||
buf : 	    (!wl->conf.rx_streaming.always &&
buf : 	     !test_bit(WL1271_FLAG_SOFT_GEMINI, &wl->flags)))
buf : 		goto out;
buf : 
buf : 	if (!wl->conf.rx_streaming.interval)
if (!wl->conf.rx_streaming.interval) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_set_rx_streaming(wl, wlvif, true);
if, true); 
buf : 	if (ret < 0)
buf : 		goto out_sleep;
buf : 
buf : 	/* stop it after some time of inactivity */
buf : 	mod_timer(&wlvif->rx_streaming_timer,
if->rx_streaming_timer, 
buf : 		  jiffies + msecs_to_jiffies(wl->conf.rx_streaming.duration));
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void wl1271_rx_streaming_disable_work(struct work_struct *work)
buf : {
buf : 	int ret;
buf : 	struct wl12xx_vif *wlvif = container_of(work, struct wl12xx_vif,
if *wlvif = container_of(work, struct wl12xx_vif, 
buf : 						rx_streaming_disable_work);
buf : 	struct wl1271 *wl = wlvif->wl;
if->wl; 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (!test_bit(WLVIF_FLAG_RX_STREAMING_STARTED, &wlvif->flags))
if (!test_bit(WLVIF_FLAG_RX_STREAMING_STARTED, &wlvif->flags)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_set_rx_streaming(wl, wlvif, false);
if, false); 
buf : 	if (ret)
buf : 		goto out_sleep;
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void wl1271_rx_streaming_timer(unsigned long data)
buf : {
buf : 	struct wl12xx_vif *wlvif = (struct wl12xx_vif *)data;
if *wlvif = (struct wl12xx_vif *)data; 
buf : 	struct wl1271 *wl = wlvif->wl;
buf : 	ieee80211_queue_work(wl->hw, &wlvif->rx_streaming_disable_work);
if->rx_streaming_disable_work); 
buf : }
buf : 
buf : /* wl->mutex must be taken */
buf : void wl12xx_rearm_tx_watchdog_locked(struct wl1271 *wl)
buf : {
buf : 	/* if the watchdog is not armed, don't do anything */
if the watchdog is not armed, don't do anything */ 
buf : 	if (wl->tx_allocated_blocks == 0)
buf : 		return;
buf : 
buf : 	cancel_delayed_work(&wl->tx_watchdog_work);
buf : 	ieee80211_queue_delayed_work(wl->hw, &wl->tx_watchdog_work,
buf : 		msecs_to_jiffies(wl->conf.tx.tx_watchdog_timeout));
iffies(wl->conf.tx.tx_watchdog_timeout)); 
buf : }
buf : 
buf : static void wl12xx_tx_watchdog_work(struct work_struct *work)
buf : {
buf : 	struct delayed_work *dwork;
buf : 	struct wl1271 *wl;
buf : 
buf : 	dwork = container_of(work, struct delayed_work, work);
buf : 	wl = container_of(dwork, struct wl1271, tx_watchdog_work);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	/* Tx went out in the meantime - everything is ok */
buf : 	if (unlikely(wl->tx_allocated_blocks == 0))
if (unlikely(wl->tx_allocated_blocks == 0)) 
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * if a ROC is in progress, we might not have any Tx for a long
if a ROC is in progress, we might not have any Tx for a long 
buf : 	 * time (e.g. pending Tx on the non-ROC channels)
buf : 	 */
buf : 	if (find_first_bit(wl->roc_map, WL12XX_MAX_ROLES) < WL12XX_MAX_ROLES) {
if (find_first_bit(wl->roc_map, WL12XX_MAX_ROLES) < WL12XX_MAX_ROLES) { 
buf : 		wl1271_debug(DEBUG_TX, "No Tx (in FW) for %d ms due to ROC",
for %d ms due to ROC", 
buf : 			     wl->conf.tx.tx_watchdog_timeout);
buf : 		wl12xx_rearm_tx_watchdog_locked(wl);
buf : 		goto out;
buf : 	}
buf : 
buf : 	/*
buf : 	 * if a scan is in progress, we might not have any Tx for a long
if a scan is in progress, we might not have any Tx for a long 
buf : 	 * time
buf : 	 */
buf : 	if (wl->scan.state != WL1271_SCAN_STATE_IDLE) {
if (wl->scan.state != WL1271_SCAN_STATE_IDLE) { 
buf : 		wl1271_debug(DEBUG_TX, "No Tx (in FW) for %d ms due to scan",
for %d ms due to scan", 
buf : 			     wl->conf.tx.tx_watchdog_timeout);
buf : 		wl12xx_rearm_tx_watchdog_locked(wl);
buf : 		goto out;
buf : 	}
buf : 
buf : 	/*
buf : 	* AP might cache a frame for a long time for a sleeping station,
for a long time for a sleeping station, 
buf : 	* so rearm the timer if there's an AP interface with stations. If
buf : 	* Tx is genuinely stuck we will most hopefully discover it when all
buf : 	* stations are removed due to inactivity.
buf : 	*/
buf : 	if (wl->active_sta_count) {
if (wl->active_sta_count) { 
buf : 		wl1271_debug(DEBUG_TX, "No Tx (in FW) for %d ms. AP has "
for %d ms. AP has " 
buf : 			     " %d stations",
buf : 			      wl->conf.tx.tx_watchdog_timeout,
buf : 			      wl->active_sta_count);
buf : 		wl12xx_rearm_tx_watchdog_locked(wl);
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl1271_error("Tx stuck (in FW) for %d ms. Starting recovery",
for %d ms. Starting recovery", 
buf : 		     wl->conf.tx.tx_watchdog_timeout);
buf : 	wl12xx_queue_recovery_work(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void wlcore_adjust_conf(struct wl1271 *wl)
buf : {
buf : 	/* Adjust settings according to optional module parameters */
buf : 
buf : 	/* Firmware Logger params */
buf : 	if (fwlog_mem_blocks != -1) {
if (fwlog_mem_blocks != -1) { 
buf : 		if (fwlog_mem_blocks >= CONF_FWLOG_MIN_MEM_BLOCKS &&
buf : 		    fwlog_mem_blocks <= CONF_FWLOG_MAX_MEM_BLOCKS) {
buf : 			wl->conf.fwlog.mem_blocks = fwlog_mem_blocks;
buf : 		} else {
buf : 			wl1271_error(
buf : 				"Illegal fwlog_mem_blocks=%d using default %d",
buf : 				fwlog_mem_blocks, wl->conf.fwlog.mem_blocks);
buf : 		}
buf : 	}
buf : 
buf : 	if (fwlog_param) {
if (fwlog_param) { 
buf : 		if (!strcmp(fwlog_param, "continuous")) {
buf : 			wl->conf.fwlog.mode = WL12XX_FWLOG_CONTINUOUS;
buf : 		} else if (!strcmp(fwlog_param, "ondemand")) {
if (!strcmp(fwlog_param, "ondemand")) { 
buf : 			wl->conf.fwlog.mode = WL12XX_FWLOG_ON_DEMAND;
buf : 		} else if (!strcmp(fwlog_param, "dbgpins")) {
if (!strcmp(fwlog_param, "dbgpins")) { 
buf : 			wl->conf.fwlog.mode = WL12XX_FWLOG_CONTINUOUS;
buf : 			wl->conf.fwlog.output = WL12XX_FWLOG_OUTPUT_DBG_PINS;
buf : 		} else if (!strcmp(fwlog_param, "disable")) {
if (!strcmp(fwlog_param, "disable")) { 
buf : 			wl->conf.fwlog.mem_blocks = 0;
buf : 			wl->conf.fwlog.output = WL12XX_FWLOG_OUTPUT_NONE;
buf : 		} else {
buf : 			wl1271_error("Unknown fwlog parameter %s", fwlog_param);
buf : 		}
buf : 	}
buf : 
buf : 	if (bug_on_recovery != -1)
if (bug_on_recovery != -1) 
buf : 		wl->conf.recovery.bug_on_recovery = (u8) bug_on_recovery;
buf : 
buf : 	if (no_recovery != -1)
if (no_recovery != -1) 
buf : 		wl->conf.recovery.no_recovery = (u8) no_recovery;
buf : }
buf : 
buf : static void wl12xx_irq_ps_regulate_link(struct wl1271 *wl,
buf : 					struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 					u8 hlid, u8 tx_pkts)
buf : {
buf : 	bool fw_ps;
buf : 
buf : 	fw_ps = test_bit(hlid, (unsigned long *)&wl->ap_fw_ps_map);
buf : 
buf : 	/*
buf : 	 * Wake up from high level PS if the STA is asleep with too little
if the STA is asleep with too little 
buf : 	 * packets in FW or if the STA is awake.
buf : 	 */
buf : 	if (!fw_ps || tx_pkts < WL1271_PS_STA_MAX_PACKETS)
if (!fw_ps || tx_pkts < WL1271_PS_STA_MAX_PACKETS) 
buf : 		wl12xx_ps_link_end(wl, wlvif, hlid);
buf : 
buf : 	/*
buf : 	 * Start high-level PS if the STA is asleep with enough blocks in FW.
if the STA is asleep with enough blocks in FW. 
buf : 	 * Make an exception if this is the only connected link. In this
buf : 	 * case FW-memory congestion is less of a problem.
buf : 	 * Note that a single connected STA means 2*ap_count + 1 active links,
buf : 	 * since we must account for the global and broadcast AP links
for the global and broadcast AP links 
buf : 	 * for each AP. The "fw_ps" check assures us the other link is a STA
buf : 	 * connected to the AP. Otherwise the FW would not set the PSM bit.
buf : 	 */
buf : 	else if (wl->active_link_count > (wl->ap_count*2 + 1) && fw_ps &&
if (wl->active_link_count > (wl->ap_count*2 + 1) && fw_ps && 
buf : 		 tx_pkts >= WL1271_PS_STA_MAX_PACKETS)
buf : 		wl12xx_ps_link_start(wl, wlvif, hlid, true);
if, hlid, true); 
buf : }
buf : 
buf : static void wl12xx_irq_update_links_status(struct wl1271 *wl,
buf : 					   struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 					   struct wl_fw_status *status)
buf : {
buf : 	u32 cur_fw_ps_map;
buf : 	u8 hlid;
buf : 
buf : 	cur_fw_ps_map = status->link_ps_bitmap;
buf : 	if (wl->ap_fw_ps_map != cur_fw_ps_map) {
if (wl->ap_fw_ps_map != cur_fw_ps_map) { 
buf : 		wl1271_debug(DEBUG_PSM,
buf : 			     "link ps prev 0x%x cur 0x%x changed 0x%x",
buf : 			     wl->ap_fw_ps_map, cur_fw_ps_map,
buf : 			     wl->ap_fw_ps_map ^ cur_fw_ps_map);
buf : 
buf : 		wl->ap_fw_ps_map = cur_fw_ps_map;
buf : 	}
buf : 
buf : 	for_each_set_bit(hlid, wlvif->ap.sta_hlid_map, wl->num_links)
if->ap.sta_hlid_map, wl->num_links) 
buf : 		wl12xx_irq_ps_regulate_link(wl, wlvif, hlid,
buf : 					    wl->links[hlid].allocated_pkts);
buf : }
buf : 
buf : static int wlcore_fw_status(struct wl1271 *wl, struct wl_fw_status *status)
buf : {
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 	struct timespec ts;
buf : 	u32 old_tx_blk_count = wl->tx_blocks_available;
buf : 	int avail, freed_blocks;
buf : 	int i;
buf : 	int ret;
buf : 	struct wl1271_link *lnk;
buf : 
buf : 	ret = wlcore_raw_read_data(wl, REG_RAW_FW_STATUS_ADDR,
buf : 				   wl->raw_fw_status,
buf : 				   wl->fw_status_len, false);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	wlcore_hw_convert_fw_status(wl, wl->raw_fw_status, wl->fw_status);
buf : 
buf : 	wl1271_debug(DEBUG_IRQ, "intr: 0x%x (fw_rx_counter = %d, "
buf : 		     "drv_rx_counter = %d, tx_results_counter = %d)",
buf : 		     status->intr,
buf : 		     status->fw_rx_counter,
buf : 		     status->drv_rx_counter,
buf : 		     status->tx_results_counter);
buf : 
buf : 	for (i = 0; i < NUM_TX_QUEUES; i++) {
for (i = 0; i < NUM_TX_QUEUES; i++) { 
buf : 		/* prevent wrap-around in freed-packets counter */
buf : 		wl->tx_allocated_pkts[i] -=
buf : 				(status->counters.tx_released_pkts[i] -
buf : 				wl->tx_pkts_freed[i]) & 0xff;
buf : 
buf : 		wl->tx_pkts_freed[i] = status->counters.tx_released_pkts[i];
buf : 	}
buf : 
buf : 
buf : 	for_each_set_bit(i, wl->links_map, wl->num_links) {
for_each_set_bit(i, wl->links_map, wl->num_links) { 
buf : 		u8 diff;
buf : 		lnk = &wl->links[i];
buf : 
buf : 		/* prevent wrap-around in freed-packets counter */
buf : 		diff = (status->counters.tx_lnk_free_pkts[i] -
iff = (status->counters.tx_lnk_free_pkts[i] - 
buf : 		       lnk->prev_freed_pkts) & 0xff;
buf : 
buf : 		if (diff == 0)
if (diff == 0) 
buf : 			continue;
buf : 
buf : 		lnk->allocated_pkts -= diff;
iff; 
buf : 		lnk->prev_freed_pkts = status->counters.tx_lnk_free_pkts[i];
buf : 
buf : 		/* accumulate the prev_freed_pkts counter */
buf : 		lnk->total_freed_pkts += diff;
iff; 
buf : 	}
buf : 
buf : 	/* prevent wrap-around in total blocks counter */
buf : 	if (likely(wl->tx_blocks_freed <= status->total_released_blks))
if (likely(wl->tx_blocks_freed <= status->total_released_blks)) 
buf : 		freed_blocks = status->total_released_blks -
buf : 			       wl->tx_blocks_freed;
buf : 	else
buf : 		freed_blocks = 0x100000000LL - wl->tx_blocks_freed +
buf : 			       status->total_released_blks;
buf : 
buf : 	wl->tx_blocks_freed = status->total_released_blks;
buf : 
buf : 	wl->tx_allocated_blocks -= freed_blocks;
buf : 
buf : 	/*
buf : 	 * If the FW freed some blocks:
buf : 	 * If we still have allocated blocks - re-arm the timer, Tx is
buf : 	 * not stuck. Otherwise, cancel the timer (no Tx currently).
buf : 	 */
buf : 	if (freed_blocks) {
if (freed_blocks) { 
buf : 		if (wl->tx_allocated_blocks)
buf : 			wl12xx_rearm_tx_watchdog_locked(wl);
buf : 		else
buf : 			cancel_delayed_work(&wl->tx_watchdog_work);
buf : 	}
buf : 
buf : 	avail = status->tx_total - wl->tx_allocated_blocks;
buf : 
buf : 	/*
buf : 	 * The FW might change the total number of TX memblocks before
fore 
buf : 	 * we get a notification about blocks being released. Thus, the
buf : 	 * available blocks calculation might yield a temporary result
buf : 	 * which is lower than the actual available blocks. Keeping in
buf : 	 * mind that only blocks that were allocated can be moved from
buf : 	 * TX to RX, tx_blocks_available should never decrease here.
buf : 	 */
buf : 	wl->tx_blocks_available = max((int)wl->tx_blocks_available,
buf : 				      avail);
buf : 
buf : 	/* if more blocks are available now, tx work can be scheduled */
if more blocks are available now, tx work can be scheduled */ 
buf : 	if (wl->tx_blocks_available > old_tx_blk_count)
buf : 		clear_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags);
buf : 
buf : 	/* for AP update num of allocated TX blocks per link and ps status */
for AP update num of allocated TX blocks per link and ps status */ 
buf : 	wl12xx_for_each_wlvif_ap(wl, wlvif) {
buf : 		wl12xx_irq_update_links_status(wl, wlvif, status);
if, status); 
buf : 	}
buf : 
buf : 	/* update the host-chipset time offset */
buf : 	getnstimeofday(&ts);
buf : 	wl->time_offset = (timespec_to_ns(&ts) >> 10) -
buf : 		(s64)(status->fw_localtime);
buf : 
buf : 	wl->fw_fast_lnk_map = status->link_fast_bitmap;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void wl1271_flush_deferred_work(struct wl1271 *wl)
buf : {
buf : 	struct sk_buff *skb;
buf : 
buf : 	/* Pass all received frames to the network stack */
buf : 	while ((skb = skb_dequeue(&wl->deferred_rx_queue)))
while ((skb = skb_dequeue(&wl->deferred_rx_queue))) 
buf : 		ieee80211_rx_ni(wl->hw, skb);
buf : 
buf : 	/* Return sent skbs to the network stack */
buf : 	while ((skb = skb_dequeue(&wl->deferred_tx_queue)))
while ((skb = skb_dequeue(&wl->deferred_tx_queue))) 
buf : 		ieee80211_tx_status_ni(wl->hw, skb);
buf : }
buf : 
buf : static void wl1271_netstack_work(struct work_struct *work)
buf : {
buf : 	struct wl1271 *wl =
buf : 		container_of(work, struct wl1271, netstack_work);
buf : 
buf : 	do {
buf : 		wl1271_flush_deferred_work(wl);
buf : 	} while (skb_queue_len(&wl->deferred_rx_queue));
while (skb_queue_len(&wl->deferred_rx_queue)); 
buf : }
buf : 
buf : #define WL1271_IRQ_MAX_LOOPS 256
buf : 
buf : static int wlcore_irq_locked(struct wl1271 *wl)
buf : {
buf : 	int ret = 0;
buf : 	u32 intr;
buf : 	int loopcount = WL1271_IRQ_MAX_LOOPS;
buf : 	bool done = false;
buf : 	unsigned int defer_count;
buf : 	unsigned long flags;
buf : 
buf : 	/*
buf : 	 * In case edge triggered interrupt must be used, we cannot iterate
buf : 	 * more than once without introducing race conditions with the hardirq.
buf : 	 */
buf : 	if (wl->platform_quirks & WL12XX_PLATFORM_QUIRK_EDGE_IRQ)
if (wl->platform_quirks & WL12XX_PLATFORM_QUIRK_EDGE_IRQ) 
buf : 		loopcount = 1;
buf : 
buf : 	wl1271_debug(DEBUG_IRQ, "IRQ work");
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	while (!done && loopcount--) {
while (!done && loopcount--) { 
buf : 		/*
buf : 		 * In order to avoid a race with the hardirq, clear the flag
buf : 		 * before acknowledging the chip. Since the mutex is held,
fore acknowledging the chip. Since the mutex is held, 
buf : 		 * wl1271_ps_elp_wakeup cannot be called concurrently.
buf : 		 */
buf : 		clear_bit(WL1271_FLAG_IRQ_RUNNING, &wl->flags);
buf : 		smp_mb__after_atomic();
buf : 
buf : 		ret = wlcore_fw_status(wl, wl->fw_status);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		wlcore_hw_tx_immediate_compl(wl);
buf : 
buf : 		intr = wl->fw_status->intr;
buf : 		intr &= WLCORE_ALL_INTR_MASK;
buf : 		if (!intr) {
if (!intr) { 
buf : 			done = true;
buf : 			continue;
buf : 		}
buf : 
buf : 		if (unlikely(intr & WL1271_ACX_INTR_WATCHDOG)) {
if (unlikely(intr & WL1271_ACX_INTR_WATCHDOG)) { 
buf : 			wl1271_error("HW watchdog interrupt received! starting recovery.");
buf : 			wl->watchdog_recovery = true;
buf : 			ret = -EIO;
buf : 
buf : 			/* restarting the chip. ignore any other interrupt. */
buf : 			goto out;
buf : 		}
buf : 
buf : 		if (unlikely(intr & WL1271_ACX_SW_INTR_WATCHDOG)) {
if (unlikely(intr & WL1271_ACX_SW_INTR_WATCHDOG)) { 
buf : 			wl1271_error("SW watchdog interrupt received! "
buf : 				     "starting recovery.");
buf : 			wl->watchdog_recovery = true;
buf : 			ret = -EIO;
buf : 
buf : 			/* restarting the chip. ignore any other interrupt. */
buf : 			goto out;
buf : 		}
buf : 
buf : 		if (likely(intr & WL1271_ACX_INTR_DATA)) {
if (likely(intr & WL1271_ACX_INTR_DATA)) { 
buf : 			wl1271_debug(DEBUG_IRQ, "WL1271_ACX_INTR_DATA");
buf : 
buf : 			ret = wlcore_rx(wl, wl->fw_status);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out;
buf : 
buf : 			/* Check if any tx blocks were freed */
if any tx blocks were freed */ 
buf : 			spin_lock_irqsave(&wl->wl_lock, flags);
buf : 			if (!test_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags) &&
if (!test_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags) && 
buf : 			    wl1271_tx_total_queue_count(wl) > 0) {
buf : 				spin_unlock_irqrestore(&wl->wl_lock, flags);
buf : 				/*
buf : 				 * In order to avoid starvation of the TX path,
buf : 				 * call the work function directly.
buf : 				 */
buf : 				ret = wlcore_tx_work_locked(wl);
buf : 				if (ret < 0)
if (ret < 0) 
buf : 					goto out;
buf : 			} else {
buf : 				spin_unlock_irqrestore(&wl->wl_lock, flags);
buf : 			}
buf : 
buf : 			/* check for tx results */
for tx results */ 
buf : 			ret = wlcore_hw_tx_delayed_compl(wl);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out;
buf : 
buf : 			/* Make sure the deferred queues don't get too long */
buf : 			defer_count = skb_queue_len(&wl->deferred_tx_queue) +
buf : 				      skb_queue_len(&wl->deferred_rx_queue);
buf : 			if (defer_count > WL1271_DEFERRED_QUEUE_LIMIT)
if (defer_count > WL1271_DEFERRED_QUEUE_LIMIT) 
buf : 				wl1271_flush_deferred_work(wl);
buf : 		}
buf : 
buf : 		if (intr & WL1271_ACX_INTR_EVENT_A) {
if (intr & WL1271_ACX_INTR_EVENT_A) { 
buf : 			wl1271_debug(DEBUG_IRQ, "WL1271_ACX_INTR_EVENT_A");
buf : 			ret = wl1271_event_handle(wl, 0);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out;
buf : 		}
buf : 
buf : 		if (intr & WL1271_ACX_INTR_EVENT_B) {
if (intr & WL1271_ACX_INTR_EVENT_B) { 
buf : 			wl1271_debug(DEBUG_IRQ, "WL1271_ACX_INTR_EVENT_B");
buf : 			ret = wl1271_event_handle(wl, 1);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out;
buf : 		}
buf : 
buf : 		if (intr & WL1271_ACX_INTR_INIT_COMPLETE)
if (intr & WL1271_ACX_INTR_INIT_COMPLETE) 
buf : 			wl1271_debug(DEBUG_IRQ,
buf : 				     "WL1271_ACX_INTR_INIT_COMPLETE");
buf : 
buf : 		if (intr & WL1271_ACX_INTR_HW_AVAILABLE)
if (intr & WL1271_ACX_INTR_HW_AVAILABLE) 
buf : 			wl1271_debug(DEBUG_IRQ, "WL1271_ACX_INTR_HW_AVAILABLE");
buf : 	}
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static irqreturn_t wlcore_irq(int irq, void *cookie)
buf : {
buf : 	int ret;
buf : 	unsigned long flags;
buf : 	struct wl1271 *wl = cookie;
buf : 
buf : 	/* complete the ELP completion */
buf : 	spin_lock_irqsave(&wl->wl_lock, flags);
buf : 	set_bit(WL1271_FLAG_IRQ_RUNNING, &wl->flags);
buf : 	if (wl->elp_compl) {
if (wl->elp_compl) { 
buf : 		complete(wl->elp_compl);
buf : 		wl->elp_compl = NULL;
buf : 	}
buf : 
buf : 	if (test_bit(WL1271_FLAG_SUSPENDED, &wl->flags)) {
if (test_bit(WL1271_FLAG_SUSPENDED, &wl->flags)) { 
buf : 		/* don't enqueue a work right now. mark it as pending */
buf : 		set_bit(WL1271_FLAG_PENDING_WORK, &wl->flags);
buf : 		wl1271_debug(DEBUG_IRQ, "should not enqueue work");
buf : 		disable_irq_nosync(wl->irq);
buf : 		pm_wakeup_event(wl->dev, 0);
buf : 		spin_unlock_irqrestore(&wl->wl_lock, flags);
buf : 		return IRQ_HANDLED;
buf : 	}
buf : 	spin_unlock_irqrestore(&wl->wl_lock, flags);
buf : 
buf : 	/* TX might be handled here, avoid redundant work */
buf : 	set_bit(WL1271_FLAG_TX_PENDING, &wl->flags);
buf : 	cancel_work_sync(&wl->tx_work);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	ret = wlcore_irq_locked(wl);
buf : 	if (ret)
if (ret) 
buf : 		wl12xx_queue_recovery_work(wl);
buf : 
buf : 	spin_lock_irqsave(&wl->wl_lock, flags);
buf : 	/* In case TX was not handled here, queue TX work */
buf : 	clear_bit(WL1271_FLAG_TX_PENDING, &wl->flags);
buf : 	if (!test_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags) &&
if (!test_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags) && 
buf : 	    wl1271_tx_total_queue_count(wl) > 0)
buf : 		ieee80211_queue_work(wl->hw, &wl->tx_work);
buf : 	spin_unlock_irqrestore(&wl->wl_lock, flags);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return IRQ_HANDLED;
buf : }
buf : 
buf : struct vif_counter_data {
if_counter_data { 
buf : 	u8 counter;
buf : 
buf : 	struct ieee80211_vif *cur_vif;
if *cur_vif; 
buf : 	bool cur_vif_running;
buf : };
buf : 
buf : static void wl12xx_vif_count_iter(void *data, u8 *mac,
if_count_iter(void *data, u8 *mac, 
buf : 				  struct ieee80211_vif *vif)
buf : {
buf : 	struct vif_counter_data *counter = data;
if_counter_data *counter = data; 
buf : 
buf : 	counter->counter++;
buf : 	if (counter->cur_vif == vif)
if (counter->cur_vif == vif) 
buf : 		counter->cur_vif_running = true;
buf : }
buf : 
buf : /* caller must not hold wl->mutex, as it might deadlock */
buf : static void wl12xx_get_vif_count(struct ieee80211_hw *hw,
if_count(struct ieee80211_hw *hw, 
buf : 			       struct ieee80211_vif *cur_vif,
buf : 			       struct vif_counter_data *data)
if_counter_data *data) 
buf : {
buf : 	memset(data, 0, sizeof(*data));
buf : 	data->cur_vif = cur_vif;
if = cur_vif; 
buf : 
buf : 	ieee80211_iterate_active_interfaces(hw, IEEE80211_IFACE_ITER_RESUME_ALL,
buf : 					    wl12xx_vif_count_iter, data);
if_count_iter, data); 
buf : }
buf : 
buf : static int wl12xx_fetch_firmware(struct wl1271 *wl, bool plt)
buf : {
buf : 	const struct firmware *fw;
buf : 	const char *fw_name;
buf : 	enum wl12xx_fw_type fw_type;
buf : 	int ret;
buf : 
buf : 	if (plt) {
if (plt) { 
buf : 		fw_type = WL12XX_FW_TYPE_PLT;
buf : 		fw_name = wl->plt_fw_name;
buf : 	} else {
buf : 		/*
buf : 		 * we can't call wl12xx_get_vif_count() here because
if_count() here because 
buf : 		 * wl->mutex is taken, so use the cached last_vif_count value
buf : 		 */
buf : 		if (wl->last_vif_count > 1 && wl->mr_fw_name) {
if (wl->last_vif_count > 1 && wl->mr_fw_name) { 
buf : 			fw_type = WL12XX_FW_TYPE_MULTI;
buf : 			fw_name = wl->mr_fw_name;
buf : 		} else {
buf : 			fw_type = WL12XX_FW_TYPE_NORMAL;
buf : 			fw_name = wl->sr_fw_name;
buf : 		}
buf : 	}
buf : 
buf : 	if (wl->fw_type == fw_type)
if (wl->fw_type == fw_type) 
buf : 		return 0;
buf : 
buf : 	wl1271_debug(DEBUG_BOOT, "booting firmware %s", fw_name);
buf : 
buf : 	ret = request_firmware(&fw, fw_name, wl->dev);
buf : 
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1271_error("could not get firmware %s: %d", fw_name, ret);
buf : 		return ret;
buf : 	}
buf : 
buf : 	if (fw->size % 4) {
if (fw->size % 4) { 
buf : 		wl1271_error("firmware size is not multiple of 32 bits: %zu",
buf : 			     fw->size);
buf : 		ret = -EILSEQ;
buf : 		goto out;
buf : 	}
buf : 
buf : 	vfree(wl->fw);
buf : 	wl->fw_type = WL12XX_FW_TYPE_NONE;
buf : 	wl->fw_len = fw->size;
buf : 	wl->fw = vmalloc(wl->fw_len);
buf : 
buf : 	if (!wl->fw) {
if (!wl->fw) { 
buf : 		wl1271_error("could not allocate memory for the firmware");
for the firmware"); 
buf : 		ret = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 
buf : 	memcpy(wl->fw, fw->data, wl->fw_len);
buf : 	ret = 0;
buf : 	wl->fw_type = fw_type;
buf : out:
buf : 	release_firmware(fw);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : void wl12xx_queue_recovery_work(struct wl1271 *wl)
buf : {
buf : 	/* Avoid a recursive recovery */
buf : 	if (wl->state == WLCORE_STATE_ON) {
if (wl->state == WLCORE_STATE_ON) { 
buf : 		WARN_ON(!test_bit(WL1271_FLAG_INTENDED_FW_RECOVERY,
buf : 				  &wl->flags));
buf : 
buf : 		wl->state = WLCORE_STATE_RESTARTING;
buf : 		set_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags);
buf : 		wl1271_ps_elp_wakeup(wl);
buf : 		wlcore_disable_interrupts_nosync(wl);
buf : 		ieee80211_queue_work(wl->hw, &wl->recovery_work);
buf : 	}
buf : }
buf : 
buf : size_t wl12xx_copy_fwlog(struct wl1271 *wl, u8 *memblock, size_t maxlen)
buf : {
buf : 	size_t len;
buf : 
buf : 	/* Make sure we have enough room */
buf : 	len = min_t(size_t, maxlen, PAGE_SIZE - wl->fwlog_size);
buf : 
buf : 	/* Fill the FW log file, consumed by the sysfs fwlog entry */
buf : 	memcpy(wl->fwlog + wl->fwlog_size, memblock, len);
buf : 	wl->fwlog_size += len;
buf : 
buf : 	return len;
buf : }
buf : 
buf : static void wl12xx_read_fwlog_panic(struct wl1271 *wl)
buf : {
buf : 	struct wlcore_partition_set part, old_part;
buf : 	u32 addr;
buf : 	u32 offset;
buf : 	u32 end_of_log;
buf : 	u8 *block;
buf : 	int ret;
buf : 
buf : 	if ((wl->quirks & WLCORE_QUIRK_FWLOG_NOT_IMPLEMENTED) ||
if ((wl->quirks & WLCORE_QUIRK_FWLOG_NOT_IMPLEMENTED) || 
buf : 	    (wl->conf.fwlog.mem_blocks == 0))
buf : 		return;
buf : 
buf : 	wl1271_info("Reading FW panic log");
buf : 
buf : 	block = kmalloc(wl->fw_mem_block_size, GFP_KERNEL);
buf : 	if (!block)
if (!block) 
buf : 		return;
buf : 
buf : 	/*
buf : 	 * Make sure the chip is awake and the logger isn't active.
buf : 	 * Do not send a stop fwlog command if the fw is hanged or if
if the fw is hanged or if 
buf : 	 * dbgpins are used (due to some fw bug).
buf : 	 */
buf : 	if (wl1271_ps_elp_wakeup(wl))
if (wl1271_ps_elp_wakeup(wl)) 
buf : 		goto out;
buf : 	if (!wl->watchdog_recovery &&
if (!wl->watchdog_recovery && 
buf : 	    wl->conf.fwlog.output != WL12XX_FWLOG_OUTPUT_DBG_PINS)
buf : 		wl12xx_cmd_stop_fwlog(wl);
buf : 
buf : 	/* Read the first memory block address */
buf : 	ret = wlcore_fw_status(wl, wl->fw_status);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	addr = wl->fw_status->log_start_addr;
buf : 	if (!addr)
if (!addr) 
buf : 		goto out;
buf : 
buf : 	if (wl->conf.fwlog.mode == WL12XX_FWLOG_CONTINUOUS) {
if (wl->conf.fwlog.mode == WL12XX_FWLOG_CONTINUOUS) { 
buf : 		offset = sizeof(addr) + sizeof(struct wl1271_rx_descriptor);
buf : 		end_of_log = wl->fwlog_end;
buf : 	} else {
buf : 		offset = sizeof(addr);
buf : 		end_of_log = addr;
buf : 	}
buf : 
buf : 	old_part = wl->curr_part;
buf : 	memset(&part, 0, sizeof(part));
buf : 
buf : 	/* Traverse the memory blocks linked list */
buf : 	do {
buf : 		part.mem.start = wlcore_hw_convert_hwaddr(wl, addr);
buf : 		part.mem.size  = PAGE_SIZE;
buf : 
buf : 		ret = wlcore_set_partition(wl, &part);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			wl1271_error("%s: set_partition start=0x%X size=%d",
buf : 				__func__, part.mem.start, part.mem.size);
buf : 			goto out;
buf : 		}
buf : 
buf : 		memset(block, 0, wl->fw_mem_block_size);
buf : 		ret = wlcore_read_hwaddr(wl, addr, block,
buf : 					wl->fw_mem_block_size, false);
buf : 
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		/*
buf : 		 * Memory blocks are linked to one another. The first 4 bytes
buf : 		 * of each memory block hold the hardware address of the next
buf : 		 * one. The last memory block points to the first one in
buf : 		 * on demand mode and is equal to 0x2000000 in continuous mode.
buf : 		 */
buf : 		addr = le32_to_cpup((__le32 *)block);
buf : 
buf : 		if (!wl12xx_copy_fwlog(wl, block + offset,
if (!wl12xx_copy_fwlog(wl, block + offset, 
buf : 					wl->fw_mem_block_size - offset))
buf : 			break;
buf : 	} while (addr && (addr != end_of_log));
while (addr && (addr != end_of_log)); 
buf : 
buf : 	wake_up_interruptible(&wl->fwlog_waitq);
buf : 
buf : out:
buf : 	kfree(block);
buf : 	wlcore_set_partition(wl, &old_part);
buf : }
buf : 
buf : static void wlcore_print_recovery(struct wl1271 *wl)
buf : {
buf : 	u32 pc = 0;
buf : 	u32 hint_sts = 0;
buf : 	int ret;
buf : 
buf : 	wl1271_info("Hardware recovery in progress. FW ver: %s",
buf : 		    wl->chip.fw_ver_str);
buf : 
buf : 	/* change partitions momentarily so we can read the FW pc */
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_BOOT]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return;
buf : 
buf : 	ret = wlcore_read_reg(wl, REG_PC_ON_RECOVERY, &pc);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return;
buf : 
buf : 	ret = wlcore_read_reg(wl, REG_INTERRUPT_NO_CLEAR, &hint_sts);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return;
buf : 
buf : 	wl1271_info("pc: 0x%x, hint_sts: 0x%08x count: %d",
buf : 				pc, hint_sts, ++wl->recovery_count);
buf : 
buf : 	wlcore_set_partition(wl, &wl->ptable[PART_WORK]);
buf : }
buf : 
buf : 
buf : static void wl1271_recovery_work(struct work_struct *work)
buf : {
buf : 	struct wl1271 *wl =
buf : 		container_of(work, struct wl1271, recovery_work);
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 	struct ieee80211_vif *vif;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (wl->state == WLCORE_STATE_OFF || wl->plt)
if (wl->state == WLCORE_STATE_OFF || wl->plt) 
buf : 		goto out_unlock;
buf : 
buf : 	if (!test_bit(WL1271_FLAG_INTENDED_FW_RECOVERY, &wl->flags)) {
if (!test_bit(WL1271_FLAG_INTENDED_FW_RECOVERY, &wl->flags)) { 
buf : 		if (wl->conf.fwlog.output == WL12XX_FWLOG_OUTPUT_HOST)
buf : 			wl12xx_read_fwlog_panic(wl);
buf : 		wlcore_print_recovery(wl);
buf : 	}
buf : 
buf : 	BUG_ON(wl->conf.recovery.bug_on_recovery &&
buf : 	       !test_bit(WL1271_FLAG_INTENDED_FW_RECOVERY, &wl->flags));
buf : 
buf : 	if (wl->conf.recovery.no_recovery) {
if (wl->conf.recovery.no_recovery) { 
buf : 		wl1271_info("No recovery (chosen on module load). Fw will remain stuck.");
buf : 		goto out_unlock;
buf : 	}
buf : 
buf : 	/* Prevent spurious TX during FW restart */
buf : 	wlcore_stop_queues(wl, WLCORE_QUEUE_STOP_REASON_FW_RESTART);
buf : 
buf : 	/* reboot the chipset */
buf : 	while (!list_empty(&wl->wlvif_list)) {
if_list)) { 
buf : 		wlvif = list_first_entry(&wl->wlvif_list,
buf : 				       struct wl12xx_vif, list);
if, list); 
buf : 		vif = wl12xx_wlvif_to_vif(wlvif);
buf : 		__wl1271_op_remove_interface(wl, vif, false);
if, false); 
buf : 	}
buf : 
buf : 	wlcore_op_stop_locked(wl);
buf : 
buf : 	ieee80211_restart_hw(wl->hw);
buf : 
buf : 	/*
buf : 	 * Its safe to enable TX now - the queues are stopped after a request
buf : 	 * to restart the HW.
buf : 	 */
buf : 	wlcore_wake_queues(wl, WLCORE_QUEUE_STOP_REASON_FW_RESTART);
buf : 
buf : out_unlock:
buf : 	wl->watchdog_recovery = false;
buf : 	clear_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags);
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int wlcore_fw_wakeup(struct wl1271 *wl)
buf : {
buf : 	return wlcore_raw_write32(wl, HW_ACCESS_ELP_CTRL_REG, ELPCTRL_WAKE_UP);
buf : }
buf : 
buf : static int wl1271_setup(struct wl1271 *wl)
buf : {
buf : 	wl->raw_fw_status = kzalloc(wl->fw_status_len, GFP_KERNEL);
buf : 	if (!wl->raw_fw_status)
if (!wl->raw_fw_status) 
buf : 		goto err;
buf : 
buf : 	wl->fw_status = kzalloc(sizeof(*wl->fw_status), GFP_KERNEL);
buf : 	if (!wl->fw_status)
if (!wl->fw_status) 
buf : 		goto err;
buf : 
buf : 	wl->tx_res_if = kzalloc(sizeof(*wl->tx_res_if), GFP_KERNEL);
if = kzalloc(sizeof(*wl->tx_res_if), GFP_KERNEL); 
buf : 	if (!wl->tx_res_if)
buf : 		goto err;
buf : 
buf : 	return 0;
buf : err:
buf : 	kfree(wl->fw_status);
buf : 	kfree(wl->raw_fw_status);
buf : 	return -ENOMEM;
buf : }
buf : 
buf : static int wl12xx_set_power_on(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	msleep(WL1271_PRE_POWER_ON_SLEEP);
buf : 	ret = wl1271_power_on(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 	msleep(WL1271_POWER_ON_SLEEP);
buf : 	wl1271_io_reset(wl);
buf : 	wl1271_io_init(wl);
buf : 
buf : 	ret = wlcore_set_partition(wl, &wl->ptable[PART_BOOT]);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto fail;
buf : 
buf : 	/* ELP module wake up */
buf : 	ret = wlcore_fw_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto fail;
buf : 
buf : out:
buf : 	return ret;
buf : 
buf : fail:
buf : 	wl1271_power_off(wl);
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_chip_wakeup(struct wl1271 *wl, bool plt)
buf : {
buf : 	int ret = 0;
buf : 
buf : 	ret = wl12xx_set_power_on(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * For wl127x based devices we could use the default block
buf : 	 * size (512 bytes), but due to a bug in the sdio driver, we
buf : 	 * need to set it explicitly after the chip is powered on.  To
buf : 	 * simplify the code and since the performance impact is
ify the code and since the performance impact is 
buf : 	 * negligible, we use the same block size for all different
for all different 
buf : 	 * chip types.
buf : 	 *
buf : 	 * Check if the bus supports blocksize alignment and, if it
if the bus supports blocksize alignment and, if it 
buf : 	 * doesn't, make sure we don't have the quirk.
buf : 	 */
buf : 	if (!wl1271_set_block_size(wl))
if (!wl1271_set_block_size(wl)) 
buf : 		wl->quirks &= ~WLCORE_QUIRK_TX_BLOCKSIZE_ALIGN;
buf : 
buf : 	/* TODO: make sure the lower driver has set things up correctly */
buf : 
buf : 	ret = wl1271_setup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl12xx_fetch_firmware(wl, plt);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : int wl1271_plt_start(struct wl1271 *wl, const enum plt_mode plt_mode)
buf : {
buf : 	int retries = WL1271_BOOT_RETRIES;
buf : 	struct wiphy *wiphy = wl->hw->wiphy;
buf : 
buf : 	static const char* const PLT_MODE[] = {
buf : 		"PLT_OFF",
buf : 		"PLT_ON",
buf : 		"PLT_FEM_DETECT",
buf : 		"PLT_CHIP_AWAKE"
buf : 	};
buf : 
buf : 	int ret;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	wl1271_notice("power up");
buf : 
buf : 	if (wl->state != WLCORE_STATE_OFF) {
if (wl->state != WLCORE_STATE_OFF) { 
buf : 		wl1271_error("cannot go into PLT state because not "
buf : 			     "in off state: %d", wl->state);
buf : 		ret = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	/* Indicate to lower levels that we are now in PLT mode */
buf : 	wl->plt = true;
buf : 	wl->plt_mode = plt_mode;
buf : 
buf : 	while (retries) {
while (retries) { 
buf : 		retries--;
buf : 		ret = wl12xx_chip_wakeup(wl, true);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto power_off;
buf : 
buf : 		if (plt_mode != PLT_CHIP_AWAKE) {
if (plt_mode != PLT_CHIP_AWAKE) { 
buf : 			ret = wl->ops->plt_init(wl);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto power_off;
buf : 		}
buf : 
buf : 		wl->state = WLCORE_STATE_ON;
buf : 		wl1271_notice("firmware booted in PLT mode %s (%s)",
buf : 			      PLT_MODE[plt_mode],
buf : 			      wl->chip.fw_ver_str);
buf : 
buf : 		/* update hw/fw version info in wiphy struct */
buf : 		wiphy->hw_version = wl->chip.id;
buf : 		strncpy(wiphy->fw_version, wl->chip.fw_ver_str,
buf : 			sizeof(wiphy->fw_version));
buf : 
buf : 		goto out;
buf : 
buf : power_off:
buf : 		wl1271_power_off(wl);
buf : 	}
buf : 
buf : 	wl->plt = false;
buf : 	wl->plt_mode = PLT_OFF;
buf : 
buf : 	wl1271_error("firmware boot in PLT mode failed despite %d retries",
buf : 		     WL1271_BOOT_RETRIES);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : int wl1271_plt_stop(struct wl1271 *wl)
buf : {
buf : 	int ret = 0;
buf : 
buf : 	wl1271_notice("power down");
buf : 
buf : 	/*
buf : 	 * Interrupts must be disabled before setting the state to OFF.
fore setting the state to OFF. 
buf : 	 * Otherwise, the interrupt handler might be called and exit without
buf : 	 * reading the interrupt status.
buf : 	 */
buf : 	wlcore_disable_interrupts(wl);
buf : 	mutex_lock(&wl->mutex);
buf : 	if (!wl->plt) {
if (!wl->plt) { 
buf : 		mutex_unlock(&wl->mutex);
buf : 
buf : 		/*
buf : 		 * This will not necessarily enable interrupts as interrupts
buf : 		 * may have been disabled when op_stop was called. It will,
buf : 		 * however, balance the above call to disable_interrupts().
buf : 		 */
buf : 		wlcore_enable_interrupts(wl);
buf : 
buf : 		wl1271_error("cannot power down because not in PLT "
buf : 			     "state: %d", wl->state);
buf : 		ret = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	wl1271_flush_deferred_work(wl);
buf : 	cancel_work_sync(&wl->netstack_work);
buf : 	cancel_work_sync(&wl->recovery_work);
buf : 	cancel_delayed_work_sync(&wl->elp_work);
buf : 	cancel_delayed_work_sync(&wl->tx_watchdog_work);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	wl1271_power_off(wl);
buf : 	wl->flags = 0;
buf : 	wl->sleep_auth = WL1271_PSM_ILLEGAL;
buf : 	wl->state = WLCORE_STATE_OFF;
buf : 	wl->plt = false;
buf : 	wl->plt_mode = PLT_OFF;
buf : 	wl->rx_counter = 0;
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static void wl1271_op_tx(struct ieee80211_hw *hw,
buf : 			 struct ieee80211_tx_control *control,
buf : 			 struct sk_buff *skb)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);
buf : 	struct ieee80211_vif *vif = info->control.vif;
if *vif = info->control.vif; 
buf : 	struct wl12xx_vif *wlvif = NULL;
buf : 	unsigned long flags;
buf : 	int q, mapping;
buf : 	u8 hlid;
buf : 
buf : 	if (!vif) {
if (!vif) { 
buf : 		wl1271_debug(DEBUG_TX, "DROP skb with no vif");
buf : 		ieee80211_free_txskb(hw, skb);
buf : 		return;
buf : 	}
buf : 
buf : 	wlvif = wl12xx_vif_to_data(vif);
if = wl12xx_vif_to_data(vif); 
buf : 	mapping = skb_get_queue_mapping(skb);
buf : 	q = wl1271_tx_get_queue(mapping);
buf : 
buf : 	hlid = wl12xx_tx_get_hlid(wl, wlvif, skb, control->sta);
if, skb, control->sta); 
buf : 
buf : 	spin_lock_irqsave(&wl->wl_lock, flags);
buf : 
buf : 	/*
buf : 	 * drop the packet if the link is invalid or the queue is stopped
if the link is invalid or the queue is stopped 
buf : 	 * for any reason but watermark. Watermark is a "soft"-stop so we
for any reason but watermark. Watermark is a "soft"-stop so we 
buf : 	 * allow these packets through.
buf : 	 */
buf : 	if (hlid == WL12XX_INVALID_LINK_ID ||
if (hlid == WL12XX_INVALID_LINK_ID || 
buf : 	    (!test_bit(hlid, wlvif->links_map)) ||
buf : 	     (wlcore_is_queue_stopped_locked(wl, wlvif, q) &&
if, q) && 
buf : 	      !wlcore_is_queue_stopped_by_reason_locked(wl, wlvif, q,
buf : 			WLCORE_QUEUE_STOP_REASON_WATERMARK))) {
buf : 		wl1271_debug(DEBUG_TX, "DROP skb hlid %d q %d", hlid, q);
buf : 		ieee80211_free_txskb(hw, skb);
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl1271_debug(DEBUG_TX, "queue skb hlid %d q %d len %d",
buf : 		     hlid, q, skb->len);
buf : 	skb_queue_tail(&wl->links[hlid].tx_queue[q], skb);
buf : 
buf : 	wl->tx_queue_count[q]++;
buf : 	wlvif->tx_queue_count[q]++;
if->tx_queue_count[q]++; 
buf : 
buf : 	/*
buf : 	 * The workqueue is slow to process the tx_queue and we need stop
buf : 	 * the queue here, otherwise the queue will get too long.
buf : 	 */
buf : 	if (wlvif->tx_queue_count[q] >= WL1271_TX_QUEUE_HIGH_WATERMARK &&
if (wlvif->tx_queue_count[q] >= WL1271_TX_QUEUE_HIGH_WATERMARK && 
buf : 	    !wlcore_is_queue_stopped_by_reason_locked(wl, wlvif, q,
buf : 					WLCORE_QUEUE_STOP_REASON_WATERMARK)) {
buf : 		wl1271_debug(DEBUG_TX, "op_tx: stopping queues for q %d", q);
for q %d", q); 
buf : 		wlcore_stop_queue_locked(wl, wlvif, q,
buf : 					 WLCORE_QUEUE_STOP_REASON_WATERMARK);
buf : 	}
buf : 
buf : 	/*
buf : 	 * The chip specific setup must run before the first TX packet -
ific setup must run before the first TX packet - 
buf : 	 * before that, the tx_work will not be initialized!
fore that, the tx_work will not be initialized! 
buf : 	 */
buf : 
buf : 	if (!test_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags) &&
if (!test_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags) && 
buf : 	    !test_bit(WL1271_FLAG_TX_PENDING, &wl->flags))
buf : 		ieee80211_queue_work(wl->hw, &wl->tx_work);
buf : 
buf : out:
buf : 	spin_unlock_irqrestore(&wl->wl_lock, flags);
buf : }
buf : 
buf : int wl1271_tx_dummy_packet(struct wl1271 *wl)
buf : {
buf : 	unsigned long flags;
buf : 	int q;
buf : 
buf : 	/* no need to queue a new dummy packet if one is already pending */
if one is already pending */ 
buf : 	if (test_bit(WL1271_FLAG_DUMMY_PACKET_PENDING, &wl->flags))
buf : 		return 0;
buf : 
buf : 	q = wl1271_tx_get_queue(skb_get_queue_mapping(wl->dummy_packet));
buf : 
buf : 	spin_lock_irqsave(&wl->wl_lock, flags);
buf : 	set_bit(WL1271_FLAG_DUMMY_PACKET_PENDING, &wl->flags);
buf : 	wl->tx_queue_count[q]++;
buf : 	spin_unlock_irqrestore(&wl->wl_lock, flags);
buf : 
buf : 	/* The FW is low on RX memory blocks, so send the dummy packet asap */
buf : 	if (!test_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags))
if (!test_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags)) 
buf : 		return wlcore_tx_work_locked(wl);
buf : 
buf : 	/*
buf : 	 * If the FW TX is busy, TX work will be scheduled by the threaded
buf : 	 * interrupt handler function
buf : 	 */
buf : 	return 0;
buf : }
buf : 
buf : /*
buf :  * The size of the dummy packet should be at least 1400 bytes. However, in
buf :  * order to minimize the number of bus transactions, aligning it to 512 bytes
buf :  * boundaries could be beneficial, performance wise
formance wise 
buf :  */
buf : #define TOTAL_TX_DUMMY_PACKET_SIZE (ALIGN(1400, 512))
buf : 
buf : static struct sk_buff *wl12xx_alloc_dummy_packet(struct wl1271 *wl)
buf : {
buf : 	struct sk_buff *skb;
buf : 	struct ieee80211_hdr_3addr *hdr;
buf : 	unsigned int dummy_packet_size;
buf : 
buf : 	dummy_packet_size = TOTAL_TX_DUMMY_PACKET_SIZE -
buf : 			    sizeof(struct wl1271_tx_hw_descr) - sizeof(*hdr);
buf : 
buf : 	skb = dev_alloc_skb(TOTAL_TX_DUMMY_PACKET_SIZE);
buf : 	if (!skb) {
if (!skb) { 
buf : 		wl1271_warning("Failed to allocate a dummy packet skb");
buf : 		return NULL;
buf : 	}
buf : 
buf : 	skb_reserve(skb, sizeof(struct wl1271_tx_hw_descr));
buf : 
buf : 	hdr = (struct ieee80211_hdr_3addr *) skb_put(skb, sizeof(*hdr));
buf : 	memset(hdr, 0, sizeof(*hdr));
buf : 	hdr->frame_control = cpu_to_le16(IEEE80211_FTYPE_DATA |
buf : 					 IEEE80211_STYPE_NULLFUNC |
buf : 					 IEEE80211_FCTL_TODS);
buf : 
buf : 	memset(skb_put(skb, dummy_packet_size), 0, dummy_packet_size);
buf : 
buf : 	/* Dummy packets require the TID to be management */
buf : 	skb->priority = WL1271_TID_MGMT;
buf : 
buf : 	/* Initialize all fields that might be used */
buf : 	skb_set_queue_mapping(skb, 0);
buf : 	memset(IEEE80211_SKB_CB(skb), 0, sizeof(struct ieee80211_tx_info));
buf : 
buf : 	return skb;
buf : }
buf : 
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : static int
buf : wl1271_validate_wowlan_pattern(struct cfg80211_pkt_pattern *p)
buf : {
buf : 	int num_fields = 0, in_field = 0, fields_size = 0;
buf : 	int i, pattern_len = 0;
buf : 
buf : 	if (!p->mask) {
if (!p->mask) { 
buf : 		wl1271_warning("No mask in WoWLAN pattern");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	/*
buf : 	 * The pattern is broken up into segments of bytes at different offsets
ifferent offsets 
buf : 	 * that need to be checked by the FW filter. Each segment is called
buf : 	 * a field in the FW API. We verify that the total number of fields
ify that the total number of fields 
buf : 	 * required for this pattern won't exceed FW limits (8)
for this pattern won't exceed FW limits (8) 
buf : 	 * as well as the total fields buffer won't exceed the FW limit.
buf : 	 * Note that if there's a pattern which crosses Ethernet/IP header
if there's a pattern which crosses Ethernet/IP header 
buf : 	 * boundary a new field is required.
buf : 	 */
buf : 	for (i = 0; i < p->pattern_len; i++) {
for (i = 0; i < p->pattern_len; i++) { 
buf : 		if (test_bit(i, (unsigned long *)p->mask)) {
buf : 			if (!in_field) {
if (!in_field) { 
buf : 				in_field = 1;
buf : 				pattern_len = 1;
buf : 			} else {
buf : 				if (i == WL1271_RX_FILTER_ETH_HEADER_SIZE) {
if (i == WL1271_RX_FILTER_ETH_HEADER_SIZE) { 
buf : 					num_fields++;
buf : 					fields_size += pattern_len +
buf : 						RX_FILTER_FIELD_OVERHEAD;
buf : 					pattern_len = 1;
buf : 				} else
buf : 					pattern_len++;
buf : 			}
buf : 		} else {
buf : 			if (in_field) {
if (in_field) { 
buf : 				in_field = 0;
buf : 				fields_size += pattern_len +
buf : 					RX_FILTER_FIELD_OVERHEAD;
buf : 				num_fields++;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	if (in_field) {
if (in_field) { 
buf : 		fields_size += pattern_len + RX_FILTER_FIELD_OVERHEAD;
buf : 		num_fields++;
buf : 	}
buf : 
buf : 	if (num_fields > WL1271_RX_FILTER_MAX_FIELDS) {
if (num_fields > WL1271_RX_FILTER_MAX_FIELDS) { 
buf : 		wl1271_warning("RX Filter too complex. Too many segments");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	if (fields_size > WL1271_RX_FILTER_MAX_FIELDS_SIZE) {
if (fields_size > WL1271_RX_FILTER_MAX_FIELDS_SIZE) { 
buf : 		wl1271_warning("RX filter pattern is too big");
buf : 		return -E2BIG;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : struct wl12xx_rx_filter *wl1271_rx_filter_alloc(void)
buf : {
buf : 	return kzalloc(sizeof(struct wl12xx_rx_filter), GFP_KERNEL);
buf : }
buf : 
buf : void wl1271_rx_filter_free(struct wl12xx_rx_filter *filter)
buf : {
buf : 	int i;
buf : 
buf : 	if (filter == NULL)
if (filter == NULL) 
buf : 		return;
buf : 
buf : 	for (i = 0; i < filter->num_fields; i++)
for (i = 0; i < filter->num_fields; i++) 
buf : 		kfree(filter->fields[i].pattern);
buf : 
buf : 	kfree(filter);
buf : }
buf : 
buf : int wl1271_rx_filter_alloc_field(struct wl12xx_rx_filter *filter,
buf : 				 u16 offset, u8 flags,
buf : 				 const u8 *pattern, u8 len)
buf : {
buf : 	struct wl12xx_rx_filter_field *field;
buf : 
buf : 	if (filter->num_fields == WL1271_RX_FILTER_MAX_FIELDS) {
if (filter->num_fields == WL1271_RX_FILTER_MAX_FIELDS) { 
buf : 		wl1271_warning("Max fields per RX filter. can't alloc another");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	field = &filter->fields[filter->num_fields];
buf : 
buf : 	field->pattern = kzalloc(len, GFP_KERNEL);
buf : 	if (!field->pattern) {
if (!field->pattern) { 
buf : 		wl1271_warning("Failed to allocate RX filter pattern");
buf : 		return -ENOMEM;
buf : 	}
buf : 
buf : 	filter->num_fields++;
buf : 
buf : 	field->offset = cpu_to_le16(offset);
buf : 	field->flags = flags;
buf : 	field->len = len;
buf : 	memcpy(field->pattern, pattern, len);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int wl1271_rx_filter_get_fields_size(struct wl12xx_rx_filter *filter)
buf : {
buf : 	int i, fields_size = 0;
buf : 
buf : 	for (i = 0; i < filter->num_fields; i++)
for (i = 0; i < filter->num_fields; i++) 
buf : 		fields_size += filter->fields[i].len +
buf : 			sizeof(struct wl12xx_rx_filter_field) -
buf : 			sizeof(u8 *);
buf : 
buf : 	return fields_size;
buf : }
buf : 
buf : void wl1271_rx_filter_flatten_fields(struct wl12xx_rx_filter *filter,
buf : 				    u8 *buf)
buf : {
buf : 	int i;
buf : 	struct wl12xx_rx_filter_field *field;
buf : 
buf : 	for (i = 0; i < filter->num_fields; i++) {
for (i = 0; i < filter->num_fields; i++) { 
buf : 		field = (struct wl12xx_rx_filter_field *)buf;
buf : 
buf : 		field->offset = filter->fields[i].offset;
buf : 		field->flags = filter->fields[i].flags;
buf : 		field->len = filter->fields[i].len;
buf : 
buf : 		memcpy(&field->pattern, filter->fields[i].pattern, field->len);
buf : 		buf += sizeof(struct wl12xx_rx_filter_field) -
buf : 			sizeof(u8 *) + field->len;
buf : 	}
buf : }
buf : 
buf : /*
buf :  * Allocates an RX filter returned through f
buf :  * which needs to be freed using rx_filter_free()
buf :  */
buf : static int
buf : wl1271_convert_wowlan_pattern_to_rx_filter(struct cfg80211_pkt_pattern *p,
buf : 					   struct wl12xx_rx_filter **f)
buf : {
buf : 	int i, j, ret = 0;
buf : 	struct wl12xx_rx_filter *filter;
buf : 	u16 offset;
buf : 	u8 flags, len;
buf : 
buf : 	filter = wl1271_rx_filter_alloc();
buf : 	if (!filter) {
if (!filter) { 
buf : 		wl1271_warning("Failed to alloc rx filter");
buf : 		ret = -ENOMEM;
buf : 		goto err;
buf : 	}
buf : 
buf : 	i = 0;
buf : 	while (i < p->pattern_len) {
while (i < p->pattern_len) { 
buf : 		if (!test_bit(i, (unsigned long *)p->mask)) {
buf : 			i++;
buf : 			continue;
buf : 		}
buf : 
buf : 		for (j = i; j < p->pattern_len; j++) {
for (j = i; j < p->pattern_len; j++) { 
buf : 			if (!test_bit(j, (unsigned long *)p->mask))
buf : 				break;
buf : 
buf : 			if (i < WL1271_RX_FILTER_ETH_HEADER_SIZE &&
if (i < WL1271_RX_FILTER_ETH_HEADER_SIZE && 
buf : 			    j >= WL1271_RX_FILTER_ETH_HEADER_SIZE)
buf : 				break;
buf : 		}
buf : 
buf : 		if (i < WL1271_RX_FILTER_ETH_HEADER_SIZE) {
if (i < WL1271_RX_FILTER_ETH_HEADER_SIZE) { 
buf : 			offset = i;
buf : 			flags = WL1271_RX_FILTER_FLAG_ETHERNET_HEADER;
buf : 		} else {
buf : 			offset = i - WL1271_RX_FILTER_ETH_HEADER_SIZE;
buf : 			flags = WL1271_RX_FILTER_FLAG_IP_HEADER;
buf : 		}
buf : 
buf : 		len = j - i;
buf : 
buf : 		ret = wl1271_rx_filter_alloc_field(filter,
buf : 						   offset,
buf : 						   flags,
buf : 						   &p->pattern[i], len);
buf : 		if (ret)
if (ret) 
buf : 			goto err;
buf : 
buf : 		i = j;
buf : 	}
buf : 
buf : 	filter->action = FILTER_SIGNAL;
buf : 
buf : 	*f = filter;
buf : 	return 0;
buf : 
buf : err:
buf : 	wl1271_rx_filter_free(filter);
buf : 	*f = NULL;
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_configure_wowlan(struct wl1271 *wl,
buf : 				   struct cfg80211_wowlan *wow)
buf : {
buf : 	int i, ret;
buf : 
buf : 	if (!wow || wow->any || !wow->n_patterns) {
if (!wow || wow->any || !wow->n_patterns) { 
buf : 		ret = wl1271_acx_default_rx_filter_enable(wl, 0,
buf : 							  FILTER_SIGNAL);
buf : 		if (ret)
if (ret) 
buf : 			goto out;
buf : 
buf : 		ret = wl1271_rx_filter_clear_all(wl);
buf : 		if (ret)
if (ret) 
buf : 			goto out;
buf : 
buf : 		return 0;
buf : 	}
buf : 
buf : 	if (WARN_ON(wow->n_patterns > WL1271_MAX_RX_FILTERS))
if (WARN_ON(wow->n_patterns > WL1271_MAX_RX_FILTERS)) 
buf : 		return -EINVAL;
buf : 
buf : 	/* Validate all incoming patterns before clearing current FW state */
fore clearing current FW state */ 
buf : 	for (i = 0; i < wow->n_patterns; i++) {
buf : 		ret = wl1271_validate_wowlan_pattern(&wow->patterns[i]);
buf : 		if (ret) {
if (ret) { 
buf : 			wl1271_warning("Bad wowlan pattern %d", i);
buf : 			return ret;
buf : 		}
buf : 	}
buf : 
buf : 	ret = wl1271_acx_default_rx_filter_enable(wl, 0, FILTER_SIGNAL);
buf : 	if (ret)
if (ret) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_rx_filter_clear_all(wl);
buf : 	if (ret)
if (ret) 
buf : 		goto out;
buf : 
buf : 	/* Translate WoWLAN patterns into filters */
buf : 	for (i = 0; i < wow->n_patterns; i++) {
for (i = 0; i < wow->n_patterns; i++) { 
buf : 		struct cfg80211_pkt_pattern *p;
buf : 		struct wl12xx_rx_filter *filter = NULL;
buf : 
buf : 		p = &wow->patterns[i];
buf : 
buf : 		ret = wl1271_convert_wowlan_pattern_to_rx_filter(p, &filter);
buf : 		if (ret) {
if (ret) { 
buf : 			wl1271_warning("Failed to create an RX filter from "
buf : 				       "wowlan pattern %d", i);
buf : 			goto out;
buf : 		}
buf : 
buf : 		ret = wl1271_rx_filter_enable(wl, i, 1, filter);
buf : 
buf : 		wl1271_rx_filter_free(filter);
buf : 		if (ret)
if (ret) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_acx_default_rx_filter_enable(wl, 1, FILTER_DROP);
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_configure_suspend_sta(struct wl1271 *wl,
buf : 					struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 					struct cfg80211_wowlan *wow)
buf : {
buf : 	int ret = 0;
buf : 
buf : 	if (!test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags))
if (!test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_configure_wowlan(wl, wow);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_sleep;
buf : 
buf : 	if ((wl->conf.conn.suspend_wake_up_event ==
if ((wl->conf.conn.suspend_wake_up_event == 
buf : 	     wl->conf.conn.wake_up_event) &&
buf : 	    (wl->conf.conn.suspend_listen_interval ==
buf : 	     wl->conf.conn.listen_interval))
buf : 		goto out_sleep;
buf : 
buf : 	ret = wl1271_acx_wake_up_conditions(wl, wlvif,
if, 
buf : 				    wl->conf.conn.suspend_wake_up_event,
buf : 				    wl->conf.conn.suspend_listen_interval);
buf : 
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		wl1271_error("suspend: set wake up conditions failed: %d", ret);
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	return ret;
buf : 
buf : }
buf : 
buf : static int wl1271_configure_suspend_ap(struct wl1271 *wl,
buf : 				       struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	int ret = 0;
buf : 
buf : 	if (!test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags))
if (!test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_acx_beacon_filter_opt(wl, wlvif, true);
if, true); 
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	return ret;
buf : 
buf : }
buf : 
buf : static int wl1271_configure_suspend(struct wl1271 *wl,
buf : 				    struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 				    struct cfg80211_wowlan *wow)
buf : {
buf : 	if (wlvif->bss_type == BSS_TYPE_STA_BSS)
if (wlvif->bss_type == BSS_TYPE_STA_BSS) 
buf : 		return wl1271_configure_suspend_sta(wl, wlvif, wow);
buf : 	if (wlvif->bss_type == BSS_TYPE_AP_BSS)
if (wlvif->bss_type == BSS_TYPE_AP_BSS) 
buf : 		return wl1271_configure_suspend_ap(wl, wlvif);
buf : 	return 0;
buf : }
buf : 
buf : static void wl1271_configure_resume(struct wl1271 *wl, struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	int ret = 0;
buf : 	bool is_ap = wlvif->bss_type == BSS_TYPE_AP_BSS;
if->bss_type == BSS_TYPE_AP_BSS; 
buf : 	bool is_sta = wlvif->bss_type == BSS_TYPE_STA_BSS;
buf : 
buf : 	if ((!is_ap) && (!is_sta))
if ((!is_ap) && (!is_sta)) 
buf : 		return;
buf : 
buf : 	if (is_sta && !test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags))
if (is_sta && !test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags)) 
buf : 		return;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return;
buf : 
buf : 	if (is_sta) {
if (is_sta) { 
buf : 		wl1271_configure_wowlan(wl, NULL);
buf : 
buf : 		if ((wl->conf.conn.suspend_wake_up_event ==
if ((wl->conf.conn.suspend_wake_up_event == 
buf : 		     wl->conf.conn.wake_up_event) &&
buf : 		    (wl->conf.conn.suspend_listen_interval ==
buf : 		     wl->conf.conn.listen_interval))
buf : 			goto out_sleep;
buf : 
buf : 		ret = wl1271_acx_wake_up_conditions(wl, wlvif,
if, 
buf : 				    wl->conf.conn.wake_up_event,
buf : 				    wl->conf.conn.listen_interval);
buf : 
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			wl1271_error("resume: wake up conditions failed: %d",
buf : 				     ret);
buf : 
buf : 	} else if (is_ap) {
if (is_ap) { 
buf : 		ret = wl1271_acx_beacon_filter_opt(wl, wlvif, false);
buf : 	}
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : }
buf : 
buf : static int wl1271_op_suspend(struct ieee80211_hw *hw,
buf : 			    struct cfg80211_wowlan *wow)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 suspend wow=%d", !!wow);
buf : 	WARN_ON(!wow);
buf : 
buf : 	/* we want to perform the recovery before suspending */
form the recovery before suspending */ 
buf : 	if (test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags)) {
buf : 		wl1271_warning("postponing suspend to perform recovery");
form recovery"); 
buf : 		return -EBUSY;
buf : 	}
buf : 
buf : 	wl1271_tx_flush(wl);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	wl->wow_enabled = true;
buf : 	wl12xx_for_each_wlvif(wl, wlvif) {
if(wl, wlvif) { 
buf : 		ret = wl1271_configure_suspend(wl, wlvif, wow);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			mutex_unlock(&wl->mutex);
buf : 			wl1271_warning("couldn't prepare device to suspend");
buf : 			return ret;
buf : 		}
buf : 	}
buf : 	mutex_unlock(&wl->mutex);
buf : 	/* flush any remaining work */
buf : 	wl1271_debug(DEBUG_MAC80211, "flushing remaining works");
buf : 
buf : 	/*
buf : 	 * disable and re-enable interrupts in order to flush
buf : 	 * the threaded_irq
buf : 	 */
buf : 	wlcore_disable_interrupts(wl);
buf : 
buf : 	/*
buf : 	 * set suspended flag to avoid triggering a new threaded_irq
buf : 	 * work. no need for spinlock as interrupts are disabled.
for spinlock as interrupts are disabled. 
buf : 	 */
buf : 	set_bit(WL1271_FLAG_SUSPENDED, &wl->flags);
buf : 
buf : 	wlcore_enable_interrupts(wl);
buf : 	flush_work(&wl->tx_work);
buf : 	flush_delayed_work(&wl->elp_work);
buf : 
buf : 	/*
buf : 	 * Cancel the watchdog even if above tx_flush failed. We will detect
if above tx_flush failed. We will detect 
buf : 	 * it on resume anyway.
buf : 	 */
buf : 	cancel_delayed_work(&wl->tx_watchdog_work);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl1271_op_resume(struct ieee80211_hw *hw)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 	unsigned long flags;
buf : 	bool run_irq_work = false, pending_recovery;
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 resume wow=%d",
buf : 		     wl->wow_enabled);
buf : 	WARN_ON(!wl->wow_enabled);
buf : 
buf : 	/*
buf : 	 * re-enable irq_work enqueuing, and call irq_work directly if
if 
buf : 	 * there is a pending work.
buf : 	 */
buf : 	spin_lock_irqsave(&wl->wl_lock, flags);
buf : 	clear_bit(WL1271_FLAG_SUSPENDED, &wl->flags);
buf : 	if (test_and_clear_bit(WL1271_FLAG_PENDING_WORK, &wl->flags))
if (test_and_clear_bit(WL1271_FLAG_PENDING_WORK, &wl->flags)) 
buf : 		run_irq_work = true;
buf : 	spin_unlock_irqrestore(&wl->wl_lock, flags);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	/* test the recovery flag before calling any SDIO functions */
fore calling any SDIO functions */ 
buf : 	pending_recovery = test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS,
buf : 				    &wl->flags);
buf : 
buf : 	if (run_irq_work) {
if (run_irq_work) { 
buf : 		wl1271_debug(DEBUG_MAC80211,
buf : 			     "run postponed irq_work directly");
buf : 
buf : 		/* don't talk to the HW if recovery is pending */
if recovery is pending */ 
buf : 		if (!pending_recovery) {
buf : 			ret = wlcore_irq_locked(wl);
buf : 			if (ret)
if (ret) 
buf : 				wl12xx_queue_recovery_work(wl);
buf : 		}
buf : 
buf : 		wlcore_enable_interrupts(wl);
buf : 	}
buf : 
buf : 	if (pending_recovery) {
if (pending_recovery) { 
buf : 		wl1271_warning("queuing forgotten recovery on resume");
forgotten recovery on resume"); 
buf : 		ieee80211_queue_work(wl->hw, &wl->recovery_work);
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl12xx_for_each_wlvif(wl, wlvif) {
if(wl, wlvif) { 
buf : 		wl1271_configure_resume(wl, wlvif);
buf : 	}
buf : 
buf : out:
buf : 	wl->wow_enabled = false;
buf : 
buf : 	/*
buf : 	 * Set a flag to re-init the watchdog on the first Tx after resume.
buf : 	 * That way we avoid possible conditions where Tx-complete interrupts
buf : 	 * fail to arrive and we perform a spurious recovery.
form a spurious recovery. 
buf : 	 */
buf : 	set_bit(WL1271_FLAG_REINIT_TX_WDOG, &wl->flags);
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return 0;
buf : }
buf : #endif
if 
buf : 
buf : static int wl1271_op_start(struct ieee80211_hw *hw)
buf : {
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 start");
buf : 
buf : 	/*
buf : 	 * We have to delay the booting of the hardware because
buf : 	 * we need to know the local MAC address before downloading and
fore downloading and 
buf : 	 * initializing the firmware. The MAC address cannot be changed
buf : 	 * after boot, and without the proper MAC address, the firmware
buf : 	 * will not function properly.
buf : 	 *
buf : 	 * The MAC address is first known when the corresponding interface
buf : 	 * is added. That is where we will initialize the hardware.
buf : 	 */
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void wlcore_op_stop_locked(struct wl1271 *wl)
buf : {
buf : 	int i;
buf : 
buf : 	if (wl->state == WLCORE_STATE_OFF) {
if (wl->state == WLCORE_STATE_OFF) { 
buf : 		if (test_and_clear_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS,
buf : 					&wl->flags))
buf : 			wlcore_enable_interrupts(wl);
buf : 
buf : 		return;
buf : 	}
buf : 
buf : 	/*
buf : 	 * this must be before the cancel_work calls below, so that the work
fore the cancel_work calls below, so that the work 
buf : 	 * functions don't perform further work.
buf : 	 */
buf : 	wl->state = WLCORE_STATE_OFF;
buf : 
buf : 	/*
buf : 	 * Use the nosync variant to disable interrupts, so the mutex could be
buf : 	 * held while doing so without deadlocking.
while doing so without deadlocking. 
buf : 	 */
buf : 	wlcore_disable_interrupts_nosync(wl);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	wlcore_synchronize_interrupts(wl);
buf : 	if (!test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags))
if (!test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags)) 
buf : 		cancel_work_sync(&wl->recovery_work);
buf : 	wl1271_flush_deferred_work(wl);
buf : 	cancel_delayed_work_sync(&wl->scan_complete_work);
buf : 	cancel_work_sync(&wl->netstack_work);
buf : 	cancel_work_sync(&wl->tx_work);
buf : 	cancel_delayed_work_sync(&wl->elp_work);
buf : 	cancel_delayed_work_sync(&wl->tx_watchdog_work);
buf : 
buf : 	/* let's notify MAC80211 about the remaining pending TX frames */
ify MAC80211 about the remaining pending TX frames */ 
buf : 	mutex_lock(&wl->mutex);
buf : 	wl12xx_tx_reset(wl);
buf : 
buf : 	wl1271_power_off(wl);
buf : 	/*
buf : 	 * In case a recovery was scheduled, interrupts were disabled to avoid
buf : 	 * an interrupt storm. Now that the power is down, it is safe to
buf : 	 * re-enable interrupts to balance the disable depth
buf : 	 */
buf : 	if (test_and_clear_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags))
if (test_and_clear_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags)) 
buf : 		wlcore_enable_interrupts(wl);
buf : 
buf : 	wl->band = IEEE80211_BAND_2GHZ;
buf : 
buf : 	wl->rx_counter = 0;
buf : 	wl->power_level = WL1271_DEFAULT_POWER_LEVEL;
buf : 	wl->channel_type = NL80211_CHAN_NO_HT;
buf : 	wl->tx_blocks_available = 0;
buf : 	wl->tx_allocated_blocks = 0;
buf : 	wl->tx_results_count = 0;
buf : 	wl->tx_packets_count = 0;
buf : 	wl->time_offset = 0;
buf : 	wl->ap_fw_ps_map = 0;
buf : 	wl->ap_ps_map = 0;
buf : 	wl->sleep_auth = WL1271_PSM_ILLEGAL;
buf : 	memset(wl->roles_map, 0, sizeof(wl->roles_map));
buf : 	memset(wl->links_map, 0, sizeof(wl->links_map));
buf : 	memset(wl->roc_map, 0, sizeof(wl->roc_map));
buf : 	memset(wl->session_ids, 0, sizeof(wl->session_ids));
buf : 	memset(wl->rx_filter_enabled, 0, sizeof(wl->rx_filter_enabled));
buf : 	wl->active_sta_count = 0;
buf : 	wl->active_link_count = 0;
buf : 
buf : 	/* The system link is always allocated */
buf : 	wl->links[WL12XX_SYSTEM_HLID].allocated_pkts = 0;
buf : 	wl->links[WL12XX_SYSTEM_HLID].prev_freed_pkts = 0;
buf : 	__set_bit(WL12XX_SYSTEM_HLID, wl->links_map);
buf : 
buf : 	/*
buf : 	 * this is performed after the cancel_work calls and the associated
formed after the cancel_work calls and the associated 
buf : 	 * mutex_lock, so that wl1271_op_add_interface does not accidentally
buf : 	 * get executed before all these vars have been reset.
fore all these vars have been reset. 
buf : 	 */
buf : 	wl->flags = 0;
buf : 
buf : 	wl->tx_blocks_freed = 0;
buf : 
buf : 	for (i = 0; i < NUM_TX_QUEUES; i++) {
for (i = 0; i < NUM_TX_QUEUES; i++) { 
buf : 		wl->tx_pkts_freed[i] = 0;
buf : 		wl->tx_allocated_pkts[i] = 0;
buf : 	}
buf : 
buf : 	wl1271_debugfs_reset(wl);
buf : 
buf : 	kfree(wl->raw_fw_status);
buf : 	wl->raw_fw_status = NULL;
buf : 	kfree(wl->fw_status);
buf : 	wl->fw_status = NULL;
buf : 	kfree(wl->tx_res_if);
if); 
buf : 	wl->tx_res_if = NULL;
buf : 	kfree(wl->target_mem_map);
buf : 	wl->target_mem_map = NULL;
buf : 
buf : 	/*
buf : 	 * FW channels must be re-calibrated after recovery,
buf : 	 * save current Reg-Domain channel configuration and clear it.
buf : 	 */
buf : 	memcpy(wl->reg_ch_conf_pending, wl->reg_ch_conf_last,
buf : 	       sizeof(wl->reg_ch_conf_pending));
buf : 	memset(wl->reg_ch_conf_last, 0, sizeof(wl->reg_ch_conf_last));
buf : }
buf : 
buf : static void wlcore_op_stop(struct ieee80211_hw *hw)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 stop");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	wlcore_op_stop_locked(wl);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void wlcore_channel_switch_work(struct work_struct *work)
buf : {
buf : 	struct delayed_work *dwork;
buf : 	struct wl1271 *wl;
buf : 	struct ieee80211_vif *vif;
if *vif; 
buf : 	struct wl12xx_vif *wlvif;
buf : 	int ret;
buf : 
buf : 	dwork = container_of(work, struct delayed_work, work);
buf : 	wlvif = container_of(dwork, struct wl12xx_vif, channel_switch_work);
if = container_of(dwork, struct wl12xx_vif, channel_switch_work); 
buf : 	wl = wlvif->wl;
buf : 
buf : 	wl1271_info("channel switch failed (role_id: %d).", wlvif->role_id);
if->role_id); 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	/* check the channel switch is still ongoing */
buf : 	if (!test_and_clear_bit(WLVIF_FLAG_CS_PROGRESS, &wlvif->flags))
if (!test_and_clear_bit(WLVIF_FLAG_CS_PROGRESS, &wlvif->flags)) 
buf : 		goto out;
buf : 
buf : 	vif = wl12xx_wlvif_to_vif(wlvif);
if = wl12xx_wlvif_to_vif(wlvif); 
buf : 	ieee80211_chswitch_done(vif, false);
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl12xx_cmd_stop_channel_switch(wl, wlvif);
if); 
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void wlcore_connection_loss_work(struct work_struct *work)
buf : {
buf : 	struct delayed_work *dwork;
buf : 	struct wl1271 *wl;
buf : 	struct ieee80211_vif *vif;
if *vif; 
buf : 	struct wl12xx_vif *wlvif;
buf : 
buf : 	dwork = container_of(work, struct delayed_work, work);
buf : 	wlvif = container_of(dwork, struct wl12xx_vif, connection_loss_work);
if = container_of(dwork, struct wl12xx_vif, connection_loss_work); 
buf : 	wl = wlvif->wl;
buf : 
buf : 	wl1271_info("Connection loss work (role_id: %d).", wlvif->role_id);
if->role_id); 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	/* Call mac80211 connection loss */
buf : 	if (!test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags))
if (!test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags)) 
buf : 		goto out;
buf : 
buf : 	vif = wl12xx_wlvif_to_vif(wlvif);
if = wl12xx_wlvif_to_vif(wlvif); 
buf : 	ieee80211_connection_loss(vif);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void wlcore_pending_auth_complete_work(struct work_struct *work)
buf : {
buf : 	struct delayed_work *dwork;
buf : 	struct wl1271 *wl;
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 	unsigned long time_spare;
buf : 	int ret;
buf : 
buf : 	dwork = container_of(work, struct delayed_work, work);
buf : 	wlvif = container_of(dwork, struct wl12xx_vif,
if = container_of(dwork, struct wl12xx_vif, 
buf : 			     pending_auth_complete_work);
buf : 	wl = wlvif->wl;
if->wl; 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * Make sure a second really passed since the last auth reply. Maybe
buf : 	 * a second auth reply arrived while we were stuck on the mutex.
while we were stuck on the mutex. 
buf : 	 * Check for a little less than the timeout to protect from scheduler
buf : 	 * irregularities.
buf : 	 */
buf : 	time_spare = jiffies +
iffies + 
buf : 			msecs_to_jiffies(WLCORE_PEND_AUTH_ROC_TIMEOUT - 50);
buf : 	if (!time_after(time_spare, wlvif->pending_auth_reply_time))
if (!time_after(time_spare, wlvif->pending_auth_reply_time)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* cancel the ROC if active */
if active */ 
buf : 	wlcore_update_inconn_sta(wl, wlvif, NULL, false);
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int wl12xx_allocate_rate_policy(struct wl1271 *wl, u8 *idx)
buf : {
buf : 	u8 policy = find_first_zero_bit(wl->rate_policies_map,
buf : 					WL12XX_MAX_RATE_POLICIES);
buf : 	if (policy >= WL12XX_MAX_RATE_POLICIES)
if (policy >= WL12XX_MAX_RATE_POLICIES) 
buf : 		return -EBUSY;
buf : 
buf : 	__set_bit(policy, wl->rate_policies_map);
buf : 	*idx = policy;
buf : 	return 0;
buf : }
buf : 
buf : static void wl12xx_free_rate_policy(struct wl1271 *wl, u8 *idx)
buf : {
buf : 	if (WARN_ON(*idx >= WL12XX_MAX_RATE_POLICIES))
if (WARN_ON(*idx >= WL12XX_MAX_RATE_POLICIES)) 
buf : 		return;
buf : 
buf : 	__clear_bit(*idx, wl->rate_policies_map);
buf : 	*idx = WL12XX_MAX_RATE_POLICIES;
buf : }
buf : 
buf : static int wlcore_allocate_klv_template(struct wl1271 *wl, u8 *idx)
buf : {
buf : 	u8 policy = find_first_zero_bit(wl->klv_templates_map,
buf : 					WLCORE_MAX_KLV_TEMPLATES);
buf : 	if (policy >= WLCORE_MAX_KLV_TEMPLATES)
if (policy >= WLCORE_MAX_KLV_TEMPLATES) 
buf : 		return -EBUSY;
buf : 
buf : 	__set_bit(policy, wl->klv_templates_map);
buf : 	*idx = policy;
buf : 	return 0;
buf : }
buf : 
buf : static void wlcore_free_klv_template(struct wl1271 *wl, u8 *idx)
buf : {
buf : 	if (WARN_ON(*idx >= WLCORE_MAX_KLV_TEMPLATES))
if (WARN_ON(*idx >= WLCORE_MAX_KLV_TEMPLATES)) 
buf : 		return;
buf : 
buf : 	__clear_bit(*idx, wl->klv_templates_map);
buf : 	*idx = WLCORE_MAX_KLV_TEMPLATES;
buf : }
buf : 
buf : static u8 wl12xx_get_role_type(struct wl1271 *wl, struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	switch (wlvif->bss_type) {
buf : 	case BSS_TYPE_AP_BSS:
buf : 		if (wlvif->p2p)
if (wlvif->p2p) 
buf : 			return WL1271_ROLE_P2P_GO;
buf : 		else
buf : 			return WL1271_ROLE_AP;
buf : 
buf : 	case BSS_TYPE_STA_BSS:
buf : 		if (wlvif->p2p)
if (wlvif->p2p) 
buf : 			return WL1271_ROLE_P2P_CL;
buf : 		else
buf : 			return WL1271_ROLE_STA;
buf : 
buf : 	case BSS_TYPE_IBSS:
buf : 		return WL1271_ROLE_IBSS;
buf : 
buf : 	default:
buf : 		wl1271_error("invalid bss_type: %d", wlvif->bss_type);
if->bss_type); 
buf : 	}
buf : 	return WL12XX_INVALID_ROLE_TYPE;
buf : }
buf : 
buf : static int wl12xx_init_vif_data(struct wl1271 *wl, struct ieee80211_vif *vif)
if_data(struct wl1271 *wl, struct ieee80211_vif *vif) 
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
buf : 	int i;
buf : 
buf : 	/* clear everything but the persistent data */
buf : 	memset(wlvif, 0, offsetof(struct wl12xx_vif, persistent));
if, 0, offsetof(struct wl12xx_vif, persistent)); 
buf : 
buf : 	switch (ieee80211_vif_type_p2p(vif)) {
buf : 	case NL80211_IFTYPE_P2P_CLIENT:
buf : 		wlvif->p2p = 1;
if->p2p = 1; 
buf : 		/* fall-through */
buf : 	case NL80211_IFTYPE_STATION:
buf : 		wlvif->bss_type = BSS_TYPE_STA_BSS;
if->bss_type = BSS_TYPE_STA_BSS; 
buf : 		break;
buf : 	case NL80211_IFTYPE_ADHOC:
buf : 		wlvif->bss_type = BSS_TYPE_IBSS;
if->bss_type = BSS_TYPE_IBSS; 
buf : 		break;
buf : 	case NL80211_IFTYPE_P2P_GO:
buf : 		wlvif->p2p = 1;
if->p2p = 1; 
buf : 		/* fall-through */
buf : 	case NL80211_IFTYPE_AP:
buf : 		wlvif->bss_type = BSS_TYPE_AP_BSS;
if->bss_type = BSS_TYPE_AP_BSS; 
buf : 		break;
buf : 	default:
buf : 		wlvif->bss_type = MAX_BSS_TYPE;
if->bss_type = MAX_BSS_TYPE; 
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	wlvif->role_id = WL12XX_INVALID_ROLE_ID;
if->role_id = WL12XX_INVALID_ROLE_ID; 
buf : 	wlvif->dev_role_id = WL12XX_INVALID_ROLE_ID;
buf : 	wlvif->dev_hlid = WL12XX_INVALID_LINK_ID;
if->dev_hlid = WL12XX_INVALID_LINK_ID; 
buf : 
buf : 	if (wlvif->bss_type == BSS_TYPE_STA_BSS ||
buf : 	    wlvif->bss_type == BSS_TYPE_IBSS) {
if->bss_type == BSS_TYPE_IBSS) { 
buf : 		/* init sta/ibss data */
buf : 		wlvif->sta.hlid = WL12XX_INVALID_LINK_ID;
if->sta.hlid = WL12XX_INVALID_LINK_ID; 
buf : 		wl12xx_allocate_rate_policy(wl, &wlvif->sta.basic_rate_idx);
buf : 		wl12xx_allocate_rate_policy(wl, &wlvif->sta.ap_rate_idx);
if->sta.ap_rate_idx); 
buf : 		wl12xx_allocate_rate_policy(wl, &wlvif->sta.p2p_rate_idx);
buf : 		wlcore_allocate_klv_template(wl, &wlvif->sta.klv_template_id);
if->sta.klv_template_id); 
buf : 		wlvif->basic_rate_set = CONF_TX_RATE_MASK_BASIC;
buf : 		wlvif->basic_rate = CONF_TX_RATE_MASK_BASIC;
if->basic_rate = CONF_TX_RATE_MASK_BASIC; 
buf : 		wlvif->rate_set = CONF_TX_RATE_MASK_BASIC;
buf : 	} else {
buf : 		/* init ap data */
buf : 		wlvif->ap.bcast_hlid = WL12XX_INVALID_LINK_ID;
if->ap.bcast_hlid = WL12XX_INVALID_LINK_ID; 
buf : 		wlvif->ap.global_hlid = WL12XX_INVALID_LINK_ID;
buf : 		wl12xx_allocate_rate_policy(wl, &wlvif->ap.mgmt_rate_idx);
if->ap.mgmt_rate_idx); 
buf : 		wl12xx_allocate_rate_policy(wl, &wlvif->ap.bcast_rate_idx);
buf : 		for (i = 0; i < CONF_TX_MAX_AC_COUNT; i++)
for (i = 0; i < CONF_TX_MAX_AC_COUNT; i++) 
buf : 			wl12xx_allocate_rate_policy(wl,
buf : 						&wlvif->ap.ucast_rate_idx[i]);
if->ap.ucast_rate_idx[i]); 
buf : 		wlvif->basic_rate_set = CONF_TX_ENABLED_RATES;
buf : 		/*
buf : 		 * TODO: check if basic_rate shouldn't be
if basic_rate shouldn't be 
buf : 		 * wl1271_tx_min_rate_get(wl, wlvif->basic_rate_set);
buf : 		 * instead (the same thing for STA above).
for STA above). 
buf : 		*/
buf : 		wlvif->basic_rate = CONF_TX_ENABLED_RATES;
if->basic_rate = CONF_TX_ENABLED_RATES; 
buf : 		/* TODO: this seems to be used only for STA, check it */
for STA, check it */ 
buf : 		wlvif->rate_set = CONF_TX_ENABLED_RATES;
buf : 	}
buf : 
buf : 	wlvif->bitrate_masks[IEEE80211_BAND_2GHZ] = wl->conf.tx.basic_rate;
if->bitrate_masks[IEEE80211_BAND_2GHZ] = wl->conf.tx.basic_rate; 
buf : 	wlvif->bitrate_masks[IEEE80211_BAND_5GHZ] = wl->conf.tx.basic_rate_5;
buf : 	wlvif->beacon_int = WL1271_DEFAULT_BEACON_INT;
if->beacon_int = WL1271_DEFAULT_BEACON_INT; 
buf : 
buf : 	/*
buf : 	 * mac80211 configures some values globally, while we treat them
while we treat them 
buf : 	 * per-interface. thus, on init, we have to copy them from wl
buf : 	 */
buf : 	wlvif->band = wl->band;
if->band = wl->band; 
buf : 	wlvif->channel = wl->channel;
buf : 	wlvif->power_level = wl->power_level;
if->power_level = wl->power_level; 
buf : 	wlvif->channel_type = wl->channel_type;
buf : 
buf : 	INIT_WORK(&wlvif->rx_streaming_enable_work,
if->rx_streaming_enable_work, 
buf : 		  wl1271_rx_streaming_enable_work);
buf : 	INIT_WORK(&wlvif->rx_streaming_disable_work,
if->rx_streaming_disable_work, 
buf : 		  wl1271_rx_streaming_disable_work);
buf : 	INIT_DELAYED_WORK(&wlvif->channel_switch_work,
if->channel_switch_work, 
buf : 			  wlcore_channel_switch_work);
buf : 	INIT_DELAYED_WORK(&wlvif->connection_loss_work,
if->connection_loss_work, 
buf : 			  wlcore_connection_loss_work);
buf : 	INIT_DELAYED_WORK(&wlvif->pending_auth_complete_work,
if->pending_auth_complete_work, 
buf : 			  wlcore_pending_auth_complete_work);
buf : 	INIT_LIST_HEAD(&wlvif->list);
if->list); 
buf : 
buf : 	setup_timer(&wlvif->rx_streaming_timer, wl1271_rx_streaming_timer,
buf : 		    (unsigned long) wlvif);
if); 
buf : 	return 0;
buf : }
buf : 
buf : static int wl12xx_init_fw(struct wl1271 *wl)
buf : {
buf : 	int retries = WL1271_BOOT_RETRIES;
buf : 	bool booted = false;
buf : 	struct wiphy *wiphy = wl->hw->wiphy;
buf : 	int ret;
buf : 
buf : 	while (retries) {
while (retries) { 
buf : 		retries--;
buf : 		ret = wl12xx_chip_wakeup(wl, false);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto power_off;
buf : 
buf : 		ret = wl->ops->boot(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto power_off;
buf : 
buf : 		ret = wl1271_hw_init(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto irq_disable;
buf : 
buf : 		booted = true;
buf : 		break;
buf : 
buf : irq_disable:
buf : 		mutex_unlock(&wl->mutex);
buf : 		/* Unlocking the mutex in the middle of handling is
buf : 		   inherently unsafe. In this case we deem it safe to do,
buf : 		   because we need to let any possibly pending IRQ out of
buf : 		   the system (and while we are WLCORE_STATE_OFF the IRQ
while we are WLCORE_STATE_OFF the IRQ 
buf : 		   work function will not do anything.) Also, any other
buf : 		   possible concurrent operations will fail due to the
buf : 		   current state, hence the wl1271 struct should be safe. */
buf : 		wlcore_disable_interrupts(wl);
buf : 		wl1271_flush_deferred_work(wl);
buf : 		cancel_work_sync(&wl->netstack_work);
buf : 		mutex_lock(&wl->mutex);
buf : power_off:
buf : 		wl1271_power_off(wl);
buf : 	}
buf : 
buf : 	if (!booted) {
if (!booted) { 
buf : 		wl1271_error("firmware boot failed despite %d retries",
buf : 			     WL1271_BOOT_RETRIES);
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl1271_info("firmware booted (%s)", wl->chip.fw_ver_str);
buf : 
buf : 	/* update hw/fw version info in wiphy struct */
buf : 	wiphy->hw_version = wl->chip.id;
buf : 	strncpy(wiphy->fw_version, wl->chip.fw_ver_str,
buf : 		sizeof(wiphy->fw_version));
buf : 
buf : 	/*
buf : 	 * Now we know if 11a is supported (info from the NVS), so disable
if 11a is supported (info from the NVS), so disable 
buf : 	 * 11a channels if not supported
buf : 	 */
buf : 	if (!wl->enable_11a)
if (!wl->enable_11a) 
buf : 		wiphy->bands[IEEE80211_BAND_5GHZ]->n_channels = 0;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "11a is %ssupported",
buf : 		     wl->enable_11a ? "" : "not ");
buf : 
buf : 	wl->state = WLCORE_STATE_ON;
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static bool wl12xx_dev_role_started(struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	return wlvif->dev_hlid != WL12XX_INVALID_LINK_ID;
buf : }
buf : 
buf : /*
buf :  * Check whether a fw switch (i.e. moving from one loaded
buf :  * fw to another) is needed. This function is also responsible
buf :  * for updating wl->last_vif_count, so it must be called before
if_count, so it must be called before 
buf :  * loading a non-plt fw (so the correct fw (single-role/multi-role)
buf :  * will be used).
buf :  */
buf : static bool wl12xx_need_fw_change(struct wl1271 *wl,
buf : 				  struct vif_counter_data vif_counter_data,
if_counter_data vif_counter_data, 
buf : 				  bool add)
buf : {
buf : 	enum wl12xx_fw_type current_fw = wl->fw_type;
buf : 	u8 vif_count = vif_counter_data.counter;
if_count = vif_counter_data.counter; 
buf : 
buf : 	if (test_bit(WL1271_FLAG_VIF_CHANGE_IN_PROGRESS, &wl->flags))
buf : 		return false;
buf : 
buf : 	/* increase the vif count if this is a new vif */
if count if this is a new vif */ 
buf : 	if (add && !vif_counter_data.cur_vif_running)
buf : 		vif_count++;
if_count++; 
buf : 
buf : 	wl->last_vif_count = vif_count;
buf : 
buf : 	/* no need for fw change if the device is OFF */
if the device is OFF */ 
buf : 	if (wl->state == WLCORE_STATE_OFF)
buf : 		return false;
buf : 
buf : 	/* no need for fw change if a single fw is used */
if a single fw is used */ 
buf : 	if (!wl->mr_fw_name)
buf : 		return false;
buf : 
buf : 	if (vif_count > 1 && current_fw == WL12XX_FW_TYPE_NORMAL)
if (vif_count > 1 && current_fw == WL12XX_FW_TYPE_NORMAL) 
buf : 		return true;
buf : 	if (vif_count <= 1 && current_fw == WL12XX_FW_TYPE_MULTI)
if (vif_count <= 1 && current_fw == WL12XX_FW_TYPE_MULTI) 
buf : 		return true;
buf : 
buf : 	return false;
buf : }
buf : 
buf : /*
buf :  * Enter "forced psm". Make sure the sta is in psm against the ap,
forced psm". Make sure the sta is in psm against the ap, 
buf :  * to make the fw switch a bit more disconnection-persistent.
buf :  */
buf : static void wl12xx_force_active_psm(struct wl1271 *wl)
force_active_psm(struct wl1271 *wl) 
buf : {
buf : 	struct wl12xx_vif *wlvif;
buf : 
buf : 	wl12xx_for_each_wlvif_sta(wl, wlvif) {
if_sta(wl, wlvif) { 
buf : 		wl1271_ps_set_mode(wl, wlvif, STATION_POWER_SAVE_MODE);
buf : 	}
buf : }
buf : 
buf : struct wlcore_hw_queue_iter_data {
buf : 	unsigned long hw_queue_map[BITS_TO_LONGS(WLCORE_NUM_MAC_ADDRESSES)];
buf : 	/* current vif */
if */ 
buf : 	struct ieee80211_vif *vif;
buf : 	/* is the current vif among those iterated */
if among those iterated */ 
buf : 	bool cur_running;
buf : };
buf : 
buf : static void wlcore_hw_queue_iter(void *data, u8 *mac,
buf : 				 struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wlcore_hw_queue_iter_data *iter_data = data;
buf : 
buf : 	if (WARN_ON_ONCE(vif->hw_queue[0] == IEEE80211_INVAL_HW_QUEUE))
if (WARN_ON_ONCE(vif->hw_queue[0] == IEEE80211_INVAL_HW_QUEUE)) 
buf : 		return;
buf : 
buf : 	if (iter_data->cur_running || vif == iter_data->vif) {
if (iter_data->cur_running || vif == iter_data->vif) { 
buf : 		iter_data->cur_running = true;
buf : 		return;
buf : 	}
buf : 
buf : 	__set_bit(vif->hw_queue[0] / NUM_TX_QUEUES, iter_data->hw_queue_map);
if->hw_queue[0] / NUM_TX_QUEUES, iter_data->hw_queue_map); 
buf : }
buf : 
buf : static int wlcore_allocate_hw_queue_base(struct wl1271 *wl,
buf : 					 struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	struct ieee80211_vif *vif = wl12xx_wlvif_to_vif(wlvif);
buf : 	struct wlcore_hw_queue_iter_data iter_data = {};
buf : 	int i, q_base;
buf : 
buf : 	iter_data.vif = vif;
if = vif; 
buf : 
buf : 	/* mark all bits taken by active interfaces */
buf : 	ieee80211_iterate_active_interfaces_atomic(wl->hw,
buf : 					IEEE80211_IFACE_ITER_RESUME_ALL,
buf : 					wlcore_hw_queue_iter, &iter_data);
buf : 
buf : 	/* the current vif is already running in mac80211 (resume/recovery) */
if is already running in mac80211 (resume/recovery) */ 
buf : 	if (iter_data.cur_running) {
buf : 		wlvif->hw_queue_base = vif->hw_queue[0];
if->hw_queue_base = vif->hw_queue[0]; 
buf : 		wl1271_debug(DEBUG_MAC80211,
buf : 			     "using pre-allocated hw queue base %d",
buf : 			     wlvif->hw_queue_base);
if->hw_queue_base); 
buf : 
buf : 		/* interface type might have changed type */
buf : 		goto adjust_cab_queue;
buf : 	}
buf : 
buf : 	q_base = find_first_zero_bit(iter_data.hw_queue_map,
buf : 				     WLCORE_NUM_MAC_ADDRESSES);
buf : 	if (q_base >= WLCORE_NUM_MAC_ADDRESSES)
if (q_base >= WLCORE_NUM_MAC_ADDRESSES) 
buf : 		return -EBUSY;
buf : 
buf : 	wlvif->hw_queue_base = q_base * NUM_TX_QUEUES;
if->hw_queue_base = q_base * NUM_TX_QUEUES; 
buf : 	wl1271_debug(DEBUG_MAC80211, "allocating hw queue base: %d",
buf : 		     wlvif->hw_queue_base);
if->hw_queue_base); 
buf : 
buf : 	for (i = 0; i < NUM_TX_QUEUES; i++) {
for (i = 0; i < NUM_TX_QUEUES; i++) { 
buf : 		wl->queue_stop_reasons[wlvif->hw_queue_base + i] = 0;
buf : 		/* register hw queues in mac80211 */
buf : 		vif->hw_queue[i] = wlvif->hw_queue_base + i;
if->hw_queue[i] = wlvif->hw_queue_base + i; 
buf : 	}
buf : 
buf : adjust_cab_queue:
buf : 	/* the last places are reserved for cab queues per interface */
for cab queues per interface */ 
buf : 	if (wlvif->bss_type == BSS_TYPE_AP_BSS)
buf : 		vif->cab_queue = NUM_TX_QUEUES * WLCORE_NUM_MAC_ADDRESSES +
if->cab_queue = NUM_TX_QUEUES * WLCORE_NUM_MAC_ADDRESSES + 
buf : 				 wlvif->hw_queue_base / NUM_TX_QUEUES;
buf : 	else
buf : 		vif->cab_queue = IEEE80211_INVAL_HW_QUEUE;
if->cab_queue = IEEE80211_INVAL_HW_QUEUE; 
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl1271_op_add_interface(struct ieee80211_hw *hw,
buf : 				   struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	struct vif_counter_data vif_count;
buf : 	int ret = 0;
buf : 	u8 role_type;
buf : 
buf : 	if (wl->plt) {
if (wl->plt) { 
buf : 		wl1271_error("Adding Interface not allowed while in PLT mode");
while in PLT mode"); 
buf : 		return -EBUSY;
buf : 	}
buf : 
buf : 	vif->driver_flags |= IEEE80211_VIF_BEACON_FILTER |
if->driver_flags |= IEEE80211_VIF_BEACON_FILTER | 
buf : 			     IEEE80211_VIF_SUPPORTS_CQM_RSSI;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 add interface type %d mac %pM",
buf : 		     ieee80211_vif_type_p2p(vif), vif->addr);
if_type_p2p(vif), vif->addr); 
buf : 
buf : 	wl12xx_get_vif_count(hw, vif, &vif_count);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_unlock;
buf : 
buf : 	/*
buf : 	 * in some very corner case HW recovery scenarios its possible to
buf : 	 * get here before __wl1271_op_remove_interface is complete, so
fore __wl1271_op_remove_interface is complete, so 
buf : 	 * opt out if that is the case.
buf : 	 */
buf : 	if (test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags) ||
if (test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags) || 
buf : 	    test_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags)) {
buf : 		ret = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 
buf : 	ret = wl12xx_init_vif_data(wl, vif);
if_data(wl, vif); 
buf : 	if (ret < 0)
buf : 		goto out;
buf : 
buf : 	wlvif->wl = wl;
if->wl = wl; 
buf : 	role_type = wl12xx_get_role_type(wl, wlvif);
buf : 	if (role_type == WL12XX_INVALID_ROLE_TYPE) {
if (role_type == WL12XX_INVALID_ROLE_TYPE) { 
buf : 		ret = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wlcore_allocate_hw_queue_base(wl, wlvif);
if); 
buf : 	if (ret < 0)
buf : 		goto out;
buf : 
buf : 	if (wl12xx_need_fw_change(wl, vif_count, true)) {
if (wl12xx_need_fw_change(wl, vif_count, true)) { 
buf : 		wl12xx_force_active_psm(wl);
force_active_psm(wl); 
buf : 		set_bit(WL1271_FLAG_INTENDED_FW_RECOVERY, &wl->flags);
buf : 		mutex_unlock(&wl->mutex);
buf : 		wl1271_recovery_work(&wl->recovery_work);
buf : 		return 0;
buf : 	}
buf : 
buf : 	/*
buf : 	 * TODO: after the nvs issue will be solved, move this block
buf : 	 * to start(), and make sure here the driver is ON.
buf : 	 */
buf : 	if (wl->state == WLCORE_STATE_OFF) {
if (wl->state == WLCORE_STATE_OFF) { 
buf : 		/*
buf : 		 * we still need this in order to configure the fw
buf : 		 * while uploading the nvs
while uploading the nvs 
buf : 		 */
buf : 		memcpy(wl->addresses[0].addr, vif->addr, ETH_ALEN);
if->addr, ETH_ALEN); 
buf : 
buf : 		ret = wl12xx_init_fw(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	ret = wl12xx_cmd_role_enable(wl, vif->addr,
if->addr, 
buf : 				     role_type, &wlvif->role_id);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_init_vif_specific(wl, vif);
if_specific(wl, vif); 
buf : 	if (ret < 0)
buf : 		goto out;
buf : 
buf : 	list_add(&wlvif->list, &wl->wlvif_list);
if->list, &wl->wlvif_list); 
buf : 	set_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags);
buf : 
buf : 	if (wlvif->bss_type == BSS_TYPE_AP_BSS)
if (wlvif->bss_type == BSS_TYPE_AP_BSS) 
buf : 		wl->ap_count++;
buf : 	else
buf : 		wl->sta_count++;
buf : out:
buf : 	wl1271_ps_elp_sleep(wl);
buf : out_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void __wl1271_op_remove_interface(struct wl1271 *wl,
buf : 					 struct ieee80211_vif *vif,
if *vif, 
buf : 					 bool reset_tx_queues)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int i, ret;
buf : 	bool is_ap = (wlvif->bss_type == BSS_TYPE_AP_BSS);
if->bss_type == BSS_TYPE_AP_BSS); 
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 remove interface");
buf : 
buf : 	if (!test_and_clear_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags))
if (!test_and_clear_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags)) 
buf : 		return;
buf : 
buf : 	/* because of hardware recovery, we may get here twice */
buf : 	if (wl->state == WLCORE_STATE_OFF)
if (wl->state == WLCORE_STATE_OFF) 
buf : 		return;
buf : 
buf : 	wl1271_info("down");
buf : 
buf : 	if (wl->scan.state != WL1271_SCAN_STATE_IDLE &&
if (wl->scan.state != WL1271_SCAN_STATE_IDLE && 
buf : 	    wl->scan_wlvif == wlvif) {
buf : 		/*
buf : 		 * Rearm the tx watchdog just before idling scan. This
fore idling scan. This 
buf : 		 * prevents just-finished scans from triggering the watchdog
buf : 		 */
buf : 		wl12xx_rearm_tx_watchdog_locked(wl);
buf : 
buf : 		wl->scan.state = WL1271_SCAN_STATE_IDLE;
buf : 		memset(wl->scan.scanned_ch, 0, sizeof(wl->scan.scanned_ch));
buf : 		wl->scan_wlvif = NULL;
if = NULL; 
buf : 		wl->scan.req = NULL;
buf : 		ieee80211_scan_completed(wl->hw, true);
buf : 	}
buf : 
buf : 	if (wl->sched_vif == wlvif)
if (wl->sched_vif == wlvif) 
buf : 		wl->sched_vif = NULL;
buf : 
buf : 	if (wl->roc_vif == vif) {
if (wl->roc_vif == vif) { 
buf : 		wl->roc_vif = NULL;
buf : 		ieee80211_remain_on_channel_expired(wl->hw);
buf : 	}
buf : 
buf : 	if (!test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags)) {
if (!test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags)) { 
buf : 		/* disable active roles */
buf : 		ret = wl1271_ps_elp_wakeup(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto deinit;
buf : 
buf : 		if (wlvif->bss_type == BSS_TYPE_STA_BSS ||
if (wlvif->bss_type == BSS_TYPE_STA_BSS || 
buf : 		    wlvif->bss_type == BSS_TYPE_IBSS) {
buf : 			if (wl12xx_dev_role_started(wlvif))
if (wl12xx_dev_role_started(wlvif)) 
buf : 				wl12xx_stop_dev(wl, wlvif);
buf : 		}
buf : 
buf : 		ret = wl12xx_cmd_role_disable(wl, &wlvif->role_id);
if->role_id); 
buf : 		if (ret < 0)
buf : 			goto deinit;
buf : 
buf : 		wl1271_ps_elp_sleep(wl);
buf : 	}
buf : deinit:
buf : 	wl12xx_tx_reset_wlvif(wl, wlvif);
if(wl, wlvif); 
buf : 
buf : 	/* clear all hlids (except system_hlid) */
buf : 	wlvif->dev_hlid = WL12XX_INVALID_LINK_ID;
if->dev_hlid = WL12XX_INVALID_LINK_ID; 
buf : 
buf : 	if (wlvif->bss_type == BSS_TYPE_STA_BSS ||
buf : 	    wlvif->bss_type == BSS_TYPE_IBSS) {
if->bss_type == BSS_TYPE_IBSS) { 
buf : 		wlvif->sta.hlid = WL12XX_INVALID_LINK_ID;
buf : 		wl12xx_free_rate_policy(wl, &wlvif->sta.basic_rate_idx);
if->sta.basic_rate_idx); 
buf : 		wl12xx_free_rate_policy(wl, &wlvif->sta.ap_rate_idx);
buf : 		wl12xx_free_rate_policy(wl, &wlvif->sta.p2p_rate_idx);
if->sta.p2p_rate_idx); 
buf : 		wlcore_free_klv_template(wl, &wlvif->sta.klv_template_id);
buf : 	} else {
buf : 		wlvif->ap.bcast_hlid = WL12XX_INVALID_LINK_ID;
if->ap.bcast_hlid = WL12XX_INVALID_LINK_ID; 
buf : 		wlvif->ap.global_hlid = WL12XX_INVALID_LINK_ID;
buf : 		wl12xx_free_rate_policy(wl, &wlvif->ap.mgmt_rate_idx);
if->ap.mgmt_rate_idx); 
buf : 		wl12xx_free_rate_policy(wl, &wlvif->ap.bcast_rate_idx);
buf : 		for (i = 0; i < CONF_TX_MAX_AC_COUNT; i++)
for (i = 0; i < CONF_TX_MAX_AC_COUNT; i++) 
buf : 			wl12xx_free_rate_policy(wl,
buf : 						&wlvif->ap.ucast_rate_idx[i]);
if->ap.ucast_rate_idx[i]); 
buf : 		wl1271_free_ap_keys(wl, wlvif);
buf : 	}
buf : 
buf : 	dev_kfree_skb(wlvif->probereq);
if->probereq); 
buf : 	wlvif->probereq = NULL;
buf : 	if (wl->last_wlvif == wlvif)
if (wl->last_wlvif == wlvif) 
buf : 		wl->last_wlvif = NULL;
buf : 	list_del(&wlvif->list);
if->list); 
buf : 	memset(wlvif->ap.sta_hlid_map, 0, sizeof(wlvif->ap.sta_hlid_map));
buf : 	wlvif->role_id = WL12XX_INVALID_ROLE_ID;
if->role_id = WL12XX_INVALID_ROLE_ID; 
buf : 	wlvif->dev_role_id = WL12XX_INVALID_ROLE_ID;
buf : 
buf : 	if (is_ap)
if (is_ap) 
buf : 		wl->ap_count--;
buf : 	else
buf : 		wl->sta_count--;
buf : 
buf : 	/*
buf : 	 * Last AP, have more stations. Configure sleep auth according to STA.
buf : 	 * Don't do thin on unintended recovery.
buf : 	 */
buf : 	if (test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags) &&
if (test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags) && 
buf : 	    !test_bit(WL1271_FLAG_INTENDED_FW_RECOVERY, &wl->flags))
buf : 		goto unlock;
buf : 
buf : 	if (wl->ap_count == 0 && is_ap) {
if (wl->ap_count == 0 && is_ap) { 
buf : 		/* mask ap events */
buf : 		wl->event_mask &= ~wl->ap_event_mask;
buf : 		wl1271_event_unmask(wl);
buf : 	}
buf : 
buf : 	if (wl->ap_count == 0 && is_ap && wl->sta_count) {
if (wl->ap_count == 0 && is_ap && wl->sta_count) { 
buf : 		u8 sta_auth = wl->conf.conn.sta_sleep_auth;
buf : 		/* Configure for power according to debugfs */
for power according to debugfs */ 
buf : 		if (sta_auth != WL1271_PSM_ILLEGAL)
buf : 			wl1271_acx_sleep_auth(wl, sta_auth);
buf : 		/* Configure for ELP power saving */
for ELP power saving */ 
buf : 		else
buf : 			wl1271_acx_sleep_auth(wl, WL1271_PSM_ELP);
buf : 	}
buf : 
buf : unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	del_timer_sync(&wlvif->rx_streaming_timer);
if->rx_streaming_timer); 
buf : 	cancel_work_sync(&wlvif->rx_streaming_enable_work);
buf : 	cancel_work_sync(&wlvif->rx_streaming_disable_work);
if->rx_streaming_disable_work); 
buf : 	cancel_delayed_work_sync(&wlvif->connection_loss_work);
buf : 	cancel_delayed_work_sync(&wlvif->channel_switch_work);
if->channel_switch_work); 
buf : 	cancel_delayed_work_sync(&wlvif->pending_auth_complete_work);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : }
buf : 
buf : static void wl1271_op_remove_interface(struct ieee80211_hw *hw,
buf : 				       struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	struct wl12xx_vif *iter;
buf : 	struct vif_counter_data vif_count;
if_counter_data vif_count; 
buf : 
buf : 	wl12xx_get_vif_count(hw, vif, &vif_count);
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (wl->state == WLCORE_STATE_OFF ||
if (wl->state == WLCORE_STATE_OFF || 
buf : 	    !test_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags))
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * wl->vif can be null here if someone shuts down the interface
if can be null here if someone shuts down the interface 
buf : 	 * just when hardware recovery has been started.
buf : 	 */
buf : 	wl12xx_for_each_wlvif(wl, iter) {
if(wl, iter) { 
buf : 		if (iter != wlvif)
buf : 			continue;
buf : 
buf : 		__wl1271_op_remove_interface(wl, vif, true);
if, true); 
buf : 		break;
buf : 	}
buf : 	WARN_ON(iter != wlvif);
if); 
buf : 	if (wl12xx_need_fw_change(wl, vif_count, false)) {
buf : 		wl12xx_force_active_psm(wl);
force_active_psm(wl); 
buf : 		set_bit(WL1271_FLAG_INTENDED_FW_RECOVERY, &wl->flags);
buf : 		wl12xx_queue_recovery_work(wl);
buf : 	}
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int wl12xx_op_change_interface(struct ieee80211_hw *hw,
buf : 				      struct ieee80211_vif *vif,
if *vif, 
buf : 				      enum nl80211_iftype new_type, bool p2p)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	int ret;
buf : 
buf : 	set_bit(WL1271_FLAG_VIF_CHANGE_IN_PROGRESS, &wl->flags);
buf : 	wl1271_op_remove_interface(hw, vif);
if); 
buf : 
buf : 	vif->type = new_type;
buf : 	vif->p2p = p2p;
if->p2p = p2p; 
buf : 	ret = wl1271_op_add_interface(hw, vif);
buf : 
buf : 	clear_bit(WL1271_FLAG_VIF_CHANGE_IN_PROGRESS, &wl->flags);
buf : 	return ret;
buf : }
buf : 
buf : static int wlcore_join(struct wl1271 *wl, struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	int ret;
buf : 	bool is_ibss = (wlvif->bss_type == BSS_TYPE_IBSS);
if->bss_type == BSS_TYPE_IBSS); 
buf : 
buf : 	/*
buf : 	 * One of the side effects of the JOIN command is that is clears
buf : 	 * WPA/WPA2 keys from the chipset. Performing a JOIN while associated
forming a JOIN while associated 
buf : 	 * to a WPA/WPA2 access point will therefore kill the data-path.
buf : 	 * Currently the only valid scenario for JOIN during association
for JOIN during association 
buf : 	 * is on roaming, in which case we will also be given new keys.
buf : 	 * Keep the below message for now, unless it starts bothering
for now, unless it starts bothering 
buf : 	 * users who really like to roam a lot :)
buf : 	 */
buf : 	if (test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags))
if (test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags)) 
buf : 		wl1271_info("JOIN while associated.");
while associated."); 
buf : 
buf : 	/* clear encryption type */
buf : 	wlvif->encryption_type = KEY_NONE;
if->encryption_type = KEY_NONE; 
buf : 
buf : 	if (is_ibss)
buf : 		ret = wl12xx_cmd_role_start_ibss(wl, wlvif);
if); 
buf : 	else {
buf : 		if (wl->quirks & WLCORE_QUIRK_START_STA_FAILS) {
if (wl->quirks & WLCORE_QUIRK_START_STA_FAILS) { 
buf : 			/*
buf : 			 * TODO: this is an ugly workaround for wl12xx fw
for wl12xx fw 
buf : 			 * bug - we are not able to tx/rx after the first
buf : 			 * start_sta, so make dummy start+stop calls,
buf : 			 * and then call start_sta again.
buf : 			 * this should be fixed in the fw.
buf : 			 */
buf : 			wl12xx_cmd_role_start_sta(wl, wlvif);
if); 
buf : 			wl12xx_cmd_role_stop_sta(wl, wlvif);
buf : 		}
buf : 
buf : 		ret = wl12xx_cmd_role_start_sta(wl, wlvif);
if); 
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_ssid_set(struct wl12xx_vif *wlvif, struct sk_buff *skb,
if *wlvif, struct sk_buff *skb, 
buf : 			    int offset)
buf : {
buf : 	u8 ssid_len;
buf : 	const u8 *ptr = cfg80211_find_ie(WLAN_EID_SSID, skb->data + offset,
buf : 					 skb->len - offset);
buf : 
buf : 	if (!ptr) {
if (!ptr) { 
buf : 		wl1271_error("No SSID in IEs!");
buf : 		return -ENOENT;
buf : 	}
buf : 
buf : 	ssid_len = ptr[1];
buf : 	if (ssid_len > IEEE80211_MAX_SSID_LEN) {
if (ssid_len > IEEE80211_MAX_SSID_LEN) { 
buf : 		wl1271_error("SSID is too long!");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	wlvif->ssid_len = ssid_len;
if->ssid_len = ssid_len; 
buf : 	memcpy(wlvif->ssid, ptr+2, ssid_len);
buf : 	return 0;
buf : }
buf : 
buf : static int wlcore_set_ssid(struct wl1271 *wl, struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	struct ieee80211_vif *vif = wl12xx_wlvif_to_vif(wlvif);
buf : 	struct sk_buff *skb;
buf : 	int ieoffset;
buf : 
buf : 	/* we currently only support setting the ssid from the ap probe req */
buf : 	if (wlvif->bss_type != BSS_TYPE_STA_BSS)
if (wlvif->bss_type != BSS_TYPE_STA_BSS) 
buf : 		return -EINVAL;
buf : 
buf : 	skb = ieee80211_ap_probereq_get(wl->hw, vif);
if); 
buf : 	if (!skb)
buf : 		return -EINVAL;
buf : 
buf : 	ieoffset = offsetof(struct ieee80211_mgmt,
buf : 			    u.probe_req.variable);
buf : 	wl1271_ssid_set(wlvif, skb, ieoffset);
if, skb, ieoffset); 
buf : 	dev_kfree_skb(skb);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wlcore_set_assoc(struct wl1271 *wl, struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 			    struct ieee80211_bss_conf *bss_conf,
buf : 			    u32 sta_rate_set)
buf : {
buf : 	int ieoffset;
buf : 	int ret;
buf : 
buf : 	wlvif->aid = bss_conf->aid;
if->aid = bss_conf->aid; 
buf : 	wlvif->channel_type = cfg80211_get_chandef_type(&bss_conf->chandef);
buf : 	wlvif->beacon_int = bss_conf->beacon_int;
if->beacon_int = bss_conf->beacon_int; 
buf : 	wlvif->wmm_enabled = bss_conf->qos;
buf : 
buf : 	set_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags);
if->flags); 
buf : 
buf : 	/*
buf : 	 * with wl1271, we don't need to update the
buf : 	 * beacon_int and dtim_period, because the firmware
buf : 	 * updates it by itself when the first beacon is
buf : 	 * received after a join.
buf : 	 */
buf : 	ret = wl1271_cmd_build_ps_poll(wl, wlvif, wlvif->aid);
if, wlvif->aid); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	/*
buf : 	 * Get a template for hardware connection maintenance
for hardware connection maintenance 
buf : 	 */
buf : 	dev_kfree_skb(wlvif->probereq);
if->probereq); 
buf : 	wlvif->probereq = wl1271_cmd_build_ap_probe_req(wl,
buf : 							wlvif,
if, 
buf : 							NULL);
buf : 	ieoffset = offsetof(struct ieee80211_mgmt,
buf : 			    u.probe_req.variable);
buf : 	wl1271_ssid_set(wlvif, wlvif->probereq, ieoffset);
if, wlvif->probereq, ieoffset); 
buf : 
buf : 	/* enable the connection monitoring feature */
buf : 	ret = wl1271_acx_conn_monit_params(wl, wlvif, true);
if, true); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	/*
buf : 	 * The join command disable the keep-alive mode, shut down its process,
buf : 	 * and also clear the template config, so we need to reset it all after
buf : 	 * the join. The acx_aid starts the keep-alive process, and the order
buf : 	 * of the commands below is relevant.
buf : 	 */
buf : 	ret = wl1271_acx_keep_alive_mode(wl, wlvif, true);
if, true); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	ret = wl1271_acx_aid(wl, wlvif, wlvif->aid);
if, wlvif->aid); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	ret = wl12xx_cmd_build_klv_null_data(wl, wlvif);
if); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	ret = wl1271_acx_keep_alive_config(wl, wlvif,
if, 
buf : 					   wlvif->sta.klv_template_id,
buf : 					   ACX_KEEP_ALIVE_TPL_VALID);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	/*
buf : 	 * The default fw psm configuration is AUTO, while mac80211 default
while mac80211 default 
buf : 	 * setting is off (ACTIVE), so sync the fw with the correct value.
buf : 	 */
buf : 	ret = wl1271_ps_set_mode(wl, wlvif, STATION_ACTIVE_MODE);
if, STATION_ACTIVE_MODE); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	if (sta_rate_set) {
if (sta_rate_set) { 
buf : 		wlvif->rate_set =
buf : 			wl1271_tx_enabled_rates_get(wl,
buf : 						    sta_rate_set,
buf : 						    wlvif->band);
if->band); 
buf : 		ret = wl1271_acx_sta_rate_policies(wl, wlvif);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			return ret;
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wlcore_unset_assoc(struct wl1271 *wl, struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	int ret;
buf : 	bool sta = wlvif->bss_type == BSS_TYPE_STA_BSS;
if->bss_type == BSS_TYPE_STA_BSS; 
buf : 
buf : 	/* make sure we are connected (sta) joined */
buf : 	if (sta &&
if (sta && 
buf : 	    !test_and_clear_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags))
buf : 		return false;
buf : 
buf : 	/* make sure we are joined (ibss) */
buf : 	if (!sta &&
if (!sta && 
buf : 	    test_and_clear_bit(WLVIF_FLAG_IBSS_JOINED, &wlvif->flags))
buf : 		return false;
buf : 
buf : 	if (sta) {
if (sta) { 
buf : 		/* use defaults when not associated */
buf : 		wlvif->aid = 0;
if->aid = 0; 
buf : 
buf : 		/* free probe-request template */
buf : 		dev_kfree_skb(wlvif->probereq);
if->probereq); 
buf : 		wlvif->probereq = NULL;
buf : 
buf : 		/* disable connection monitor features */
buf : 		ret = wl1271_acx_conn_monit_params(wl, wlvif, false);
if, false); 
buf : 		if (ret < 0)
buf : 			return ret;
buf : 
buf : 		/* Disable the keep-alive feature */
buf : 		ret = wl1271_acx_keep_alive_mode(wl, wlvif, false);
if, false); 
buf : 		if (ret < 0)
buf : 			return ret;
buf : 
buf : 		/* disable beacon filtering */
buf : 		ret = wl1271_acx_beacon_filter_opt(wl, wlvif, false);
if, false); 
buf : 		if (ret < 0)
buf : 			return ret;
buf : 	}
buf : 
buf : 	if (test_and_clear_bit(WLVIF_FLAG_CS_PROGRESS, &wlvif->flags)) {
if (test_and_clear_bit(WLVIF_FLAG_CS_PROGRESS, &wlvif->flags)) { 
buf : 		struct ieee80211_vif *vif = wl12xx_wlvif_to_vif(wlvif);
buf : 
buf : 		wl12xx_cmd_stop_channel_switch(wl, wlvif);
if); 
buf : 		ieee80211_chswitch_done(vif, false);
buf : 		cancel_delayed_work(&wlvif->channel_switch_work);
if->channel_switch_work); 
buf : 	}
buf : 
buf : 	/* invalidate keep-alive template */
buf : 	wl1271_acx_keep_alive_config(wl, wlvif,
if, 
buf : 				     wlvif->sta.klv_template_id,
buf : 				     ACX_KEEP_ALIVE_TPL_INVALID);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void wl1271_set_band_rate(struct wl1271 *wl, struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	wlvif->basic_rate_set = wlvif->bitrate_masks[wlvif->band];
buf : 	wlvif->rate_set = wlvif->basic_rate_set;
if->rate_set = wlvif->basic_rate_set; 
buf : }
buf : 
buf : static void wl1271_sta_handle_idle(struct wl1271 *wl, struct wl12xx_vif *wlvif,
buf : 				   bool idle)
buf : {
buf : 	bool cur_idle = !test_bit(WLVIF_FLAG_ACTIVE, &wlvif->flags);
if->flags); 
buf : 
buf : 	if (idle == cur_idle)
buf : 		return;
buf : 
buf : 	if (idle) {
if (idle) { 
buf : 		clear_bit(WLVIF_FLAG_ACTIVE, &wlvif->flags);
buf : 	} else {
buf : 		/* The current firmware only supports sched_scan in idle */
buf : 		if (wl->sched_vif == wlvif)
if (wl->sched_vif == wlvif) 
buf : 			wl->ops->sched_scan_stop(wl, wlvif);
buf : 
buf : 		set_bit(WLVIF_FLAG_ACTIVE, &wlvif->flags);
if->flags); 
buf : 	}
buf : }
buf : 
buf : static int wl12xx_config_vif(struct wl1271 *wl, struct wl12xx_vif *wlvif,
buf : 			     struct ieee80211_conf *conf, u32 changed)
buf : {
buf : 	int ret;
buf : 
buf : 	if (conf->power_level != wlvif->power_level) {
if (conf->power_level != wlvif->power_level) { 
buf : 		ret = wl1271_acx_tx_power(wl, wlvif, conf->power_level);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			return ret;
buf : 
buf : 		wlvif->power_level = conf->power_level;
if->power_level = conf->power_level; 
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl1271_op_config(struct ieee80211_hw *hw, u32 changed)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 	int ret = 0;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 config psm %s power %d %s"
buf : 		     " changed 0x%x",
buf : 		     conf->flags & IEEE80211_CONF_PS ? "on" : "off",
buf : 		     conf->power_level,
buf : 		     conf->flags & IEEE80211_CONF_IDLE ? "idle" : "in use",
buf : 			 changed);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_POWER)
if (changed & IEEE80211_CONF_CHANGE_POWER) 
buf : 		wl->power_level = conf->power_level;
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* configure each interface */
buf : 	wl12xx_for_each_wlvif(wl, wlvif) {
if(wl, wlvif) { 
buf : 		ret = wl12xx_config_vif(wl, wlvif, conf, changed);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 	}
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : struct wl1271_filter_params {
buf : 	bool enabled;
buf : 	int mc_list_length;
buf : 	u8 mc_list[ACX_MC_ADDRESS_GROUP_MAX][ETH_ALEN];
buf : };
buf : 
buf : static u64 wl1271_op_prepare_multicast(struct ieee80211_hw *hw,
buf : 				       struct netdev_hw_addr_list *mc_list)
buf : {
buf : 	struct wl1271_filter_params *fp;
buf : 	struct netdev_hw_addr *ha;
buf : 
buf : 	fp = kzalloc(sizeof(*fp), GFP_ATOMIC);
buf : 	if (!fp) {
if (!fp) { 
buf : 		wl1271_error("Out of memory setting filters.");
buf : 		return 0;
buf : 	}
buf : 
buf : 	/* update multicast filtering parameters */
buf : 	fp->mc_list_length = 0;
buf : 	if (netdev_hw_addr_list_count(mc_list) > ACX_MC_ADDRESS_GROUP_MAX) {
if (netdev_hw_addr_list_count(mc_list) > ACX_MC_ADDRESS_GROUP_MAX) { 
buf : 		fp->enabled = false;
buf : 	} else {
buf : 		fp->enabled = true;
buf : 		netdev_hw_addr_list_for_each(ha, mc_list) {
for_each(ha, mc_list) { 
buf : 			memcpy(fp->mc_list[fp->mc_list_length],
buf : 					ha->addr, ETH_ALEN);
buf : 			fp->mc_list_length++;
buf : 		}
buf : 	}
buf : 
buf : 	return (u64)(unsigned long)fp;
buf : }
buf : 
buf : #define WL1271_SUPPORTED_FILTERS (FIF_PROMISC_IN_BSS | \
buf : 				  FIF_ALLMULTI | \
buf : 				  FIF_FCSFAIL | \
buf : 				  FIF_BCN_PRBRESP_PROMISC | \
buf : 				  FIF_CONTROL | \
buf : 				  FIF_OTHER_BSS)
buf : 
buf : static void wl1271_op_configure_filter(struct ieee80211_hw *hw,
buf : 				       unsigned int changed,
buf : 				       unsigned int *total, u64 multicast)
buf : {
buf : 	struct wl1271_filter_params *fp = (void *)(unsigned long)multicast;
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 configure filter changed %x"
buf : 		     " total %x", changed, *total);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	*total &= WL1271_SUPPORTED_FILTERS;
buf : 	changed &= WL1271_SUPPORTED_FILTERS;
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl12xx_for_each_wlvif(wl, wlvif) {
if(wl, wlvif) { 
buf : 		if (wlvif->bss_type != BSS_TYPE_AP_BSS) {
buf : 			if (*total & FIF_ALLMULTI)
if (*total & FIF_ALLMULTI) 
buf : 				ret = wl1271_acx_group_address_tbl(wl, wlvif,
buf : 								   false,
buf : 								   NULL, 0);
buf : 			else if (fp)
if (fp) 
buf : 				ret = wl1271_acx_group_address_tbl(wl, wlvif,
buf : 							fp->enabled,
buf : 							fp->mc_list,
buf : 							fp->mc_list_length);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 		}
buf : 	}
buf : 
buf : 	/*
buf : 	 * the fw doesn't provide an api to configure the filters. instead,
buf : 	 * the filters configuration is based on the active roles / ROC
buf : 	 * state.
buf : 	 */
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 	kfree(fp);
buf : }
buf : 
buf : static int wl1271_record_ap_key(struct wl1271 *wl, struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 				u8 id, u8 key_type, u8 key_size,
buf : 				const u8 *key, u8 hlid, u32 tx_seq_32,
buf : 				u16 tx_seq_16)
buf : {
buf : 	struct wl1271_ap_key *ap_key;
buf : 	int i;
buf : 
buf : 	wl1271_debug(DEBUG_CRYPT, "record ap key id %d", (int)id);
buf : 
buf : 	if (key_size > MAX_KEY_SIZE)
if (key_size > MAX_KEY_SIZE) 
buf : 		return -EINVAL;
buf : 
buf : 	/*
buf : 	 * Find next free entry in ap_keys. Also check we are not replacing
buf : 	 * an existing key.
buf : 	 */
buf : 	for (i = 0; i < MAX_NUM_KEYS; i++) {
for (i = 0; i < MAX_NUM_KEYS; i++) { 
buf : 		if (wlvif->ap.recorded_keys[i] == NULL)
buf : 			break;
buf : 
buf : 		if (wlvif->ap.recorded_keys[i]->id == id) {
if (wlvif->ap.recorded_keys[i]->id == id) { 
buf : 			wl1271_warning("trying to record key replacement");
buf : 			return -EINVAL;
buf : 		}
buf : 	}
buf : 
buf : 	if (i == MAX_NUM_KEYS)
if (i == MAX_NUM_KEYS) 
buf : 		return -EBUSY;
buf : 
buf : 	ap_key = kzalloc(sizeof(*ap_key), GFP_KERNEL);
buf : 	if (!ap_key)
if (!ap_key) 
buf : 		return -ENOMEM;
buf : 
buf : 	ap_key->id = id;
buf : 	ap_key->key_type = key_type;
buf : 	ap_key->key_size = key_size;
buf : 	memcpy(ap_key->key, key, key_size);
buf : 	ap_key->hlid = hlid;
buf : 	ap_key->tx_seq_32 = tx_seq_32;
buf : 	ap_key->tx_seq_16 = tx_seq_16;
buf : 
buf : 	wlvif->ap.recorded_keys[i] = ap_key;
if->ap.recorded_keys[i] = ap_key; 
buf : 	return 0;
buf : }
buf : 
buf : static void wl1271_free_ap_keys(struct wl1271 *wl, struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 0; i < MAX_NUM_KEYS; i++) {
for (i = 0; i < MAX_NUM_KEYS; i++) { 
buf : 		kfree(wlvif->ap.recorded_keys[i]);
buf : 		wlvif->ap.recorded_keys[i] = NULL;
if->ap.recorded_keys[i] = NULL; 
buf : 	}
buf : }
buf : 
buf : static int wl1271_ap_init_hwenc(struct wl1271 *wl, struct wl12xx_vif *wlvif)
buf : {
buf : 	int i, ret = 0;
buf : 	struct wl1271_ap_key *key;
buf : 	bool wep_key_added = false;
buf : 
buf : 	for (i = 0; i < MAX_NUM_KEYS; i++) {
for (i = 0; i < MAX_NUM_KEYS; i++) { 
buf : 		u8 hlid;
buf : 		if (wlvif->ap.recorded_keys[i] == NULL)
if (wlvif->ap.recorded_keys[i] == NULL) 
buf : 			break;
buf : 
buf : 		key = wlvif->ap.recorded_keys[i];
if->ap.recorded_keys[i]; 
buf : 		hlid = key->hlid;
buf : 		if (hlid == WL12XX_INVALID_LINK_ID)
if (hlid == WL12XX_INVALID_LINK_ID) 
buf : 			hlid = wlvif->ap.bcast_hlid;
buf : 
buf : 		ret = wl1271_cmd_set_ap_key(wl, wlvif, KEY_ADD_OR_REPLACE,
if, KEY_ADD_OR_REPLACE, 
buf : 					    key->id, key->key_type,
buf : 					    key->key_size, key->key,
buf : 					    hlid, key->tx_seq_32,
buf : 					    key->tx_seq_16);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		if (key->key_type == KEY_WEP)
if (key->key_type == KEY_WEP) 
buf : 			wep_key_added = true;
buf : 	}
buf : 
buf : 	if (wep_key_added) {
if (wep_key_added) { 
buf : 		ret = wl12xx_cmd_set_default_wep_key(wl, wlvif->default_key,
buf : 						     wlvif->ap.bcast_hlid);
if->ap.bcast_hlid); 
buf : 		if (ret < 0)
buf : 			goto out;
buf : 	}
buf : 
buf : out:
buf : 	wl1271_free_ap_keys(wl, wlvif);
if); 
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_set_key(struct wl1271 *wl, struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 		       u16 action, u8 id, u8 key_type,
buf : 		       u8 key_size, const u8 *key, u32 tx_seq_32,
buf : 		       u16 tx_seq_16, struct ieee80211_sta *sta)
buf : {
buf : 	int ret;
buf : 	bool is_ap = (wlvif->bss_type == BSS_TYPE_AP_BSS);
if->bss_type == BSS_TYPE_AP_BSS); 
buf : 
buf : 	if (is_ap) {
buf : 		struct wl1271_station *wl_sta;
buf : 		u8 hlid;
buf : 
buf : 		if (sta) {
if (sta) { 
buf : 			wl_sta = (struct wl1271_station *)sta->drv_priv;
buf : 			hlid = wl_sta->hlid;
buf : 		} else {
buf : 			hlid = wlvif->ap.bcast_hlid;
if->ap.bcast_hlid; 
buf : 		}
buf : 
buf : 		if (!test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags)) {
if (!test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags)) { 
buf : 			/*
buf : 			 * We do not support removing keys after AP shutdown.
buf : 			 * Pretend we do to make mac80211 happy.
buf : 			 */
buf : 			if (action != KEY_ADD_OR_REPLACE)
if (action != KEY_ADD_OR_REPLACE) 
buf : 				return 0;
buf : 
buf : 			ret = wl1271_record_ap_key(wl, wlvif, id,
if, id, 
buf : 					     key_type, key_size,
buf : 					     key, hlid, tx_seq_32,
buf : 					     tx_seq_16);
buf : 		} else {
buf : 			ret = wl1271_cmd_set_ap_key(wl, wlvif, action,
if, action, 
buf : 					     id, key_type, key_size,
buf : 					     key, hlid, tx_seq_32,
buf : 					     tx_seq_16);
buf : 		}
buf : 
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			return ret;
buf : 	} else {
buf : 		const u8 *addr;
buf : 		static const u8 bcast_addr[ETH_ALEN] = {
buf : 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff
buf : 		};
buf : 
buf : 		addr = sta ? sta->addr : bcast_addr;
buf : 
buf : 		if (is_zero_ether_addr(addr)) {
if (is_zero_ether_addr(addr)) { 
buf : 			/* We dont support TX only encryption */
buf : 			return -EOPNOTSUPP;
buf : 		}
buf : 
buf : 		/* The wl1271 does not allow to remove unicast keys - they
buf : 		   will be cleared automatically on next CMD_JOIN. Ignore the
buf : 		   request silently, as we dont want the mac80211 to emit
buf : 		   an error message. */
buf : 		if (action == KEY_REMOVE && !is_broadcast_ether_addr(addr))
if (action == KEY_REMOVE && !is_broadcast_ether_addr(addr)) 
buf : 			return 0;
buf : 
buf : 		/* don't remove key if hlid was already deleted */
if hlid was already deleted */ 
buf : 		if (action == KEY_REMOVE &&
buf : 		    wlvif->sta.hlid == WL12XX_INVALID_LINK_ID)
if->sta.hlid == WL12XX_INVALID_LINK_ID) 
buf : 			return 0;
buf : 
buf : 		ret = wl1271_cmd_set_sta_key(wl, wlvif, action,
if, action, 
buf : 					     id, key_type, key_size,
buf : 					     key, addr, tx_seq_32,
buf : 					     tx_seq_16);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			return ret;
buf : 
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wlcore_op_set_key(struct ieee80211_hw *hw, enum set_key_cmd cmd,
buf : 			     struct ieee80211_vif *vif,
if *vif, 
buf : 			     struct ieee80211_sta *sta,
buf : 			     struct ieee80211_key_conf *key_conf)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	int ret;
buf : 	bool might_change_spare =
buf : 		key_conf->cipher == WL1271_CIPHER_SUITE_GEM ||
buf : 		key_conf->cipher == WLAN_CIPHER_SUITE_TKIP;
buf : 
buf : 	if (might_change_spare) {
if (might_change_spare) { 
buf : 		/*
buf : 		 * stop the queues and flush to ensure the next packets are
buf : 		 * in sync with FW spare block accounting
buf : 		 */
buf : 		wlcore_stop_queues(wl, WLCORE_QUEUE_STOP_REASON_SPARE_BLK);
buf : 		wl1271_tx_flush(wl);
buf : 	}
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		ret = -EAGAIN;
buf : 		goto out_wake_queues;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_wake_queues;
buf : 
buf : 	ret = wlcore_hw_set_key(wl, cmd, vif, sta, key_conf);
if, sta, key_conf); 
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out_wake_queues:
buf : 	if (might_change_spare)
if (might_change_spare) 
buf : 		wlcore_wake_queues(wl, WLCORE_QUEUE_STOP_REASON_SPARE_BLK);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : int wlcore_set_key(struct wl1271 *wl, enum set_key_cmd cmd,
buf : 		   struct ieee80211_vif *vif,
if *vif, 
buf : 		   struct ieee80211_sta *sta,
buf : 		   struct ieee80211_key_conf *key_conf)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret;
buf : 	u32 tx_seq_32 = 0;
buf : 	u16 tx_seq_16 = 0;
buf : 	u8 key_type;
buf : 	u8 hlid;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 set key");
buf : 
buf : 	wl1271_debug(DEBUG_CRYPT, "CMD: 0x%x sta: %p", cmd, sta);
buf : 	wl1271_debug(DEBUG_CRYPT, "Key: algo:0x%x, id:%d, len:%d flags 0x%x",
buf : 		     key_conf->cipher, key_conf->keyidx,
buf : 		     key_conf->keylen, key_conf->flags);
buf : 	wl1271_dump(DEBUG_CRYPT, "KEY: ", key_conf->key, key_conf->keylen);
buf : 
buf : 	if (wlvif->bss_type == BSS_TYPE_AP_BSS)
if (wlvif->bss_type == BSS_TYPE_AP_BSS) 
buf : 		if (sta) {
buf : 			struct wl1271_station *wl_sta = (void *)sta->drv_priv;
buf : 			hlid = wl_sta->hlid;
buf : 		} else {
buf : 			hlid = wlvif->ap.bcast_hlid;
if->ap.bcast_hlid; 
buf : 		}
buf : 	else
buf : 		hlid = wlvif->sta.hlid;
if->sta.hlid; 
buf : 
buf : 	if (hlid != WL12XX_INVALID_LINK_ID) {
buf : 		u64 tx_seq = wl->links[hlid].total_freed_pkts;
buf : 		tx_seq_32 = WL1271_TX_SECURITY_HI32(tx_seq);
buf : 		tx_seq_16 = WL1271_TX_SECURITY_LO16(tx_seq);
buf : 	}
buf : 
buf : 	switch (key_conf->cipher) {
buf : 	case WLAN_CIPHER_SUITE_WEP40:
buf : 	case WLAN_CIPHER_SUITE_WEP104:
buf : 		key_type = KEY_WEP;
buf : 
buf : 		key_conf->hw_key_idx = key_conf->keyidx;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_TKIP:
buf : 		key_type = KEY_TKIP;
buf : 		key_conf->hw_key_idx = key_conf->keyidx;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_CCMP:
buf : 		key_type = KEY_AES;
buf : 		key_conf->flags |= IEEE80211_KEY_FLAG_PUT_IV_SPACE;
buf : 		break;
buf : 	case WL1271_CIPHER_SUITE_GEM:
buf : 		key_type = KEY_GEM;
buf : 		break;
buf : 	default:
buf : 		wl1271_error("Unknown key algo 0x%x", key_conf->cipher);
buf : 
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	switch (cmd) {
buf : 	case SET_KEY:
buf : 		ret = wl1271_set_key(wl, wlvif, KEY_ADD_OR_REPLACE,
if, KEY_ADD_OR_REPLACE, 
buf : 				 key_conf->keyidx, key_type,
buf : 				 key_conf->keylen, key_conf->key,
buf : 				 tx_seq_32, tx_seq_16, sta);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			wl1271_error("Could not add or replace key");
buf : 			return ret;
buf : 		}
buf : 
buf : 		/*
buf : 		 * reconfiguring arp response if the unicast (or common)
if the unicast (or common) 
buf : 		 * encryption key type was changed
buf : 		 */
buf : 		if (wlvif->bss_type == BSS_TYPE_STA_BSS &&
if (wlvif->bss_type == BSS_TYPE_STA_BSS && 
buf : 		    (sta || key_type == KEY_WEP) &&
buf : 		    wlvif->encryption_type != key_type) {
if->encryption_type != key_type) { 
buf : 			wlvif->encryption_type = key_type;
buf : 			ret = wl1271_cmd_build_arp_rsp(wl, wlvif);
if); 
buf : 			if (ret < 0) {
buf : 				wl1271_warning("build arp rsp failed: %d", ret);
buf : 				return ret;
buf : 			}
buf : 		}
buf : 		break;
buf : 
buf : 	case DISABLE_KEY:
buf : 		ret = wl1271_set_key(wl, wlvif, KEY_REMOVE,
if, KEY_REMOVE, 
buf : 				     key_conf->keyidx, key_type,
buf : 				     key_conf->keylen, key_conf->key,
buf : 				     0, 0, sta);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			wl1271_error("Could not remove key");
buf : 			return ret;
buf : 		}
buf : 		break;
buf : 
buf : 	default:
buf : 		wl1271_error("Unsupported key cmd 0x%x", cmd);
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : EXPORT_SYMBOL_GPL(wlcore_set_key);
buf : 
buf : static void wl1271_op_set_default_key_idx(struct ieee80211_hw *hw,
buf : 					  struct ieee80211_vif *vif,
if *vif, 
buf : 					  int key_idx)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 set default key idx %d",
buf : 		     key_idx);
buf : 
buf : 	/* we don't handle unsetting of default key */
buf : 	if (key_idx == -1)
if (key_idx == -1) 
buf : 		return;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		ret = -EAGAIN;
buf : 		goto out_unlock;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_unlock;
buf : 
buf : 	wlvif->default_key = key_idx;
if->default_key = key_idx; 
buf : 
buf : 	/* the default WEP key needs to be configured at least once */
buf : 	if (wlvif->encryption_type == KEY_WEP) {
if (wlvif->encryption_type == KEY_WEP) { 
buf : 		ret = wl12xx_cmd_set_default_wep_key(wl,
buf : 				key_idx,
buf : 				wlvif->sta.hlid);
if->sta.hlid); 
buf : 		if (ret < 0)
buf : 			goto out_sleep;
buf : 	}
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : void wlcore_regdomain_config(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	if (!(wl->quirks & WLCORE_QUIRK_REGDOMAIN_CONF))
if (!(wl->quirks & WLCORE_QUIRK_REGDOMAIN_CONF)) 
buf : 		return;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wlcore_cmd_regdomain_config_locked(wl);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl12xx_queue_recovery_work(wl);
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int wl1271_op_hw_scan(struct ieee80211_hw *hw,
buf : 			     struct ieee80211_vif *vif,
if *vif, 
buf : 			     struct cfg80211_scan_request *req)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	int ret;
buf : 	u8 *ssid = NULL;
buf : 	size_t len = 0;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 hw scan");
buf : 
buf : 	if (req->n_ssids) {
if (req->n_ssids) { 
buf : 		ssid = req->ssids[0].ssid;
buf : 		len = req->ssids[0].ssid_len;
buf : 	}
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		/*
buf : 		 * We cannot return -EBUSY here because cfg80211 will expect
buf : 		 * a call to ieee80211_scan_completed if we do - in this case
if we do - in this case 
buf : 		 * there won't be any call.
buf : 		 */
buf : 		ret = -EAGAIN;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* fail if there is any role in ROC */
if there is any role in ROC */ 
buf : 	if (find_first_bit(wl->roc_map, WL12XX_MAX_ROLES) < WL12XX_MAX_ROLES) {
buf : 		/* don't allow scanning right now */
buf : 		ret = -EBUSY;
buf : 		goto out_sleep;
buf : 	}
buf : 
buf : 	ret = wlcore_scan(hw->priv, vif, ssid, len, req);
if, ssid, len, req); 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void wl1271_op_cancel_hw_scan(struct ieee80211_hw *hw,
buf : 				     struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 cancel hw scan");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	if (wl->scan.state == WL1271_SCAN_STATE_IDLE)
if (wl->scan.state == WL1271_SCAN_STATE_IDLE) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	if (wl->scan.state != WL1271_SCAN_STATE_DONE) {
if (wl->scan.state != WL1271_SCAN_STATE_DONE) { 
buf : 		ret = wl->ops->scan_stop(wl, wlvif);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 	}
buf : 
buf : 	/*
buf : 	 * Rearm the tx watchdog just before idling scan. This
fore idling scan. This 
buf : 	 * prevents just-finished scans from triggering the watchdog
buf : 	 */
buf : 	wl12xx_rearm_tx_watchdog_locked(wl);
buf : 
buf : 	wl->scan.state = WL1271_SCAN_STATE_IDLE;
buf : 	memset(wl->scan.scanned_ch, 0, sizeof(wl->scan.scanned_ch));
buf : 	wl->scan_wlvif = NULL;
if = NULL; 
buf : 	wl->scan.req = NULL;
buf : 	ieee80211_scan_completed(wl->hw, true);
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	cancel_delayed_work_sync(&wl->scan_complete_work);
buf : }
buf : 
buf : static int wl1271_op_sched_scan_start(struct ieee80211_hw *hw,
buf : 				      struct ieee80211_vif *vif,
if *vif, 
buf : 				      struct cfg80211_sched_scan_request *req,
buf : 				      struct ieee80211_sched_scan_ies *ies)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "wl1271_op_sched_scan_start");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		ret = -EAGAIN;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl->ops->sched_scan_start(wl, wlvif, req, ies);
if, req, ies); 
buf : 	if (ret < 0)
buf : 		goto out_sleep;
buf : 
buf : 	wl->sched_vif = wlvif;
if = wlvif; 
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_op_sched_scan_stop(struct ieee80211_hw *hw,
buf : 				     struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "wl1271_op_sched_scan_stop");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl->ops->sched_scan_stop(wl, wlvif);
if); 
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl1271_op_set_frag_threshold(struct ieee80211_hw *hw, u32 value)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	int ret = 0;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		ret = -EAGAIN;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_acx_frag_threshold(wl, value);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		wl1271_warning("wl1271_op_set_frag_threshold failed: %d", ret);
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_op_set_rts_threshold(struct ieee80211_hw *hw, u32 value)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 	int ret = 0;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		ret = -EAGAIN;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl12xx_for_each_wlvif(wl, wlvif) {
if(wl, wlvif) { 
buf : 		ret = wl1271_acx_rts_threshold(wl, wlvif, value);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			wl1271_warning("set rts threshold failed: %d", ret);
buf : 	}
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void wl12xx_remove_ie(struct sk_buff *skb, u8 eid, int ieoffset)
buf : {
buf : 	int len;
buf : 	const u8 *next, *end = skb->data + skb->len;
buf : 	u8 *ie = (u8 *)cfg80211_find_ie(eid, skb->data + ieoffset,
buf : 					skb->len - ieoffset);
buf : 	if (!ie)
if (!ie) 
buf : 		return;
buf : 	len = ie[1] + 2;
buf : 	next = ie + len;
buf : 	memmove(ie, next, end - next);
buf : 	skb_trim(skb, skb->len - len);
buf : }
buf : 
buf : static void wl12xx_remove_vendor_ie(struct sk_buff *skb,
buf : 					    unsigned int oui, u8 oui_type,
buf : 					    int ieoffset)
buf : {
buf : 	int len;
buf : 	const u8 *next, *end = skb->data + skb->len;
buf : 	u8 *ie = (u8 *)cfg80211_find_vendor_ie(oui, oui_type,
buf : 					       skb->data + ieoffset,
buf : 					       skb->len - ieoffset);
buf : 	if (!ie)
if (!ie) 
buf : 		return;
buf : 	len = ie[1] + 2;
buf : 	next = ie + len;
buf : 	memmove(ie, next, end - next);
buf : 	skb_trim(skb, skb->len - len);
buf : }
buf : 
buf : static int wl1271_ap_set_probe_resp_tmpl(struct wl1271 *wl, u32 rates,
buf : 					 struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
buf : 	struct sk_buff *skb;
buf : 	int ret;
buf : 
buf : 	skb = ieee80211_proberesp_get(wl->hw, vif);
if); 
buf : 	if (!skb)
buf : 		return -EOPNOTSUPP;
buf : 
buf : 	ret = wl1271_cmd_template_set(wl, wlvif->role_id,
if->role_id, 
buf : 				      CMD_TEMPL_AP_PROBE_RESPONSE,
buf : 				      skb->data,
buf : 				      skb->len, 0,
buf : 				      rates);
buf : 	dev_kfree_skb(skb);
buf : 
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl1271_debug(DEBUG_AP, "probe response updated");
buf : 	set_bit(WLVIF_FLAG_AP_PROBE_RESP_SET, &wlvif->flags);
if->flags); 
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_ap_set_probe_resp_tmpl_legacy(struct wl1271 *wl,
buf : 					     struct ieee80211_vif *vif,
if *vif, 
buf : 					     u8 *probe_rsp_data,
buf : 					     size_t probe_rsp_len,
buf : 					     u32 rates)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	struct ieee80211_bss_conf *bss_conf = &vif->bss_conf;
buf : 	u8 probe_rsp_templ[WL1271_CMD_TEMPL_MAX_SIZE];
buf : 	int ssid_ie_offset, ie_offset, templ_len;
buf : 	const u8 *ptr;
buf : 
buf : 	/* no need to change probe response if the SSID is set correctly */
if the SSID is set correctly */ 
buf : 	if (wlvif->ssid_len > 0)
buf : 		return wl1271_cmd_template_set(wl, wlvif->role_id,
if->role_id, 
buf : 					       CMD_TEMPL_AP_PROBE_RESPONSE,
buf : 					       probe_rsp_data,
buf : 					       probe_rsp_len, 0,
buf : 					       rates);
buf : 
buf : 	if (probe_rsp_len + bss_conf->ssid_len > WL1271_CMD_TEMPL_MAX_SIZE) {
if (probe_rsp_len + bss_conf->ssid_len > WL1271_CMD_TEMPL_MAX_SIZE) { 
buf : 		wl1271_error("probe_rsp template too big");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	/* start searching from IE offset */
buf : 	ie_offset = offsetof(struct ieee80211_mgmt, u.probe_resp.variable);
buf : 
buf : 	ptr = cfg80211_find_ie(WLAN_EID_SSID, probe_rsp_data + ie_offset,
buf : 			       probe_rsp_len - ie_offset);
buf : 	if (!ptr) {
if (!ptr) { 
buf : 		wl1271_error("No SSID in beacon!");
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	ssid_ie_offset = ptr - probe_rsp_data;
buf : 	ptr += (ptr[1] + 2);
buf : 
buf : 	memcpy(probe_rsp_templ, probe_rsp_data, ssid_ie_offset);
buf : 
buf : 	/* insert SSID from bss_conf */
buf : 	probe_rsp_templ[ssid_ie_offset] = WLAN_EID_SSID;
buf : 	probe_rsp_templ[ssid_ie_offset + 1] = bss_conf->ssid_len;
buf : 	memcpy(probe_rsp_templ + ssid_ie_offset + 2,
buf : 	       bss_conf->ssid, bss_conf->ssid_len);
buf : 	templ_len = ssid_ie_offset + 2 + bss_conf->ssid_len;
buf : 
buf : 	memcpy(probe_rsp_templ + ssid_ie_offset + 2 + bss_conf->ssid_len,
buf : 	       ptr, probe_rsp_len - (ptr - probe_rsp_data));
buf : 	templ_len += probe_rsp_len - (ptr - probe_rsp_data);
buf : 
buf : 	return wl1271_cmd_template_set(wl, wlvif->role_id,
if->role_id, 
buf : 				       CMD_TEMPL_AP_PROBE_RESPONSE,
buf : 				       probe_rsp_templ,
buf : 				       templ_len, 0,
buf : 				       rates);
buf : }
buf : 
buf : static int wl1271_bss_erp_info_changed(struct wl1271 *wl,
buf : 				       struct ieee80211_vif *vif,
if *vif, 
buf : 				       struct ieee80211_bss_conf *bss_conf,
buf : 				       u32 changed)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret = 0;
buf : 
buf : 	if (changed & BSS_CHANGED_ERP_SLOT) {
if (changed & BSS_CHANGED_ERP_SLOT) { 
buf : 		if (bss_conf->use_short_slot)
buf : 			ret = wl1271_acx_slot(wl, wlvif, SLOT_TIME_SHORT);
if, SLOT_TIME_SHORT); 
buf : 		else
buf : 			ret = wl1271_acx_slot(wl, wlvif, SLOT_TIME_LONG);
if, SLOT_TIME_LONG); 
buf : 		if (ret < 0) {
buf : 			wl1271_warning("Set slot time failed %d", ret);
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ERP_PREAMBLE) {
if (changed & BSS_CHANGED_ERP_PREAMBLE) { 
buf : 		if (bss_conf->use_short_preamble)
buf : 			wl1271_acx_set_preamble(wl, wlvif, ACX_PREAMBLE_SHORT);
if, ACX_PREAMBLE_SHORT); 
buf : 		else
buf : 			wl1271_acx_set_preamble(wl, wlvif, ACX_PREAMBLE_LONG);
if, ACX_PREAMBLE_LONG); 
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ERP_CTS_PROT) {
buf : 		if (bss_conf->use_cts_prot)
if (bss_conf->use_cts_prot) 
buf : 			ret = wl1271_acx_cts_protect(wl, wlvif,
buf : 						     CTSPROTECT_ENABLE);
buf : 		else
buf : 			ret = wl1271_acx_cts_protect(wl, wlvif,
if, 
buf : 						     CTSPROTECT_DISABLE);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			wl1271_warning("Set ctsprotect failed %d", ret);
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wlcore_set_beacon_template(struct wl1271 *wl,
buf : 				      struct ieee80211_vif *vif,
if *vif, 
buf : 				      bool is_ap)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	struct ieee80211_hdr *hdr;
buf : 	u32 min_rate;
buf : 	int ret;
buf : 	int ieoffset = offsetof(struct ieee80211_mgmt, u.beacon.variable);
buf : 	struct sk_buff *beacon = ieee80211_beacon_get(wl->hw, vif);
if); 
buf : 	u16 tmpl_id;
buf : 
buf : 	if (!beacon) {
if (!beacon) { 
buf : 		ret = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl1271_debug(DEBUG_MASTER, "beacon updated");
buf : 
buf : 	ret = wl1271_ssid_set(wlvif, beacon, ieoffset);
if, beacon, ieoffset); 
buf : 	if (ret < 0) {
buf : 		dev_kfree_skb(beacon);
buf : 		goto out;
buf : 	}
buf : 	min_rate = wl1271_tx_min_rate_get(wl, wlvif->basic_rate_set);
if->basic_rate_set); 
buf : 	tmpl_id = is_ap ? CMD_TEMPL_AP_BEACON :
buf : 		CMD_TEMPL_BEACON;
buf : 	ret = wl1271_cmd_template_set(wl, wlvif->role_id, tmpl_id,
if->role_id, tmpl_id, 
buf : 				      beacon->data,
buf : 				      beacon->len, 0,
buf : 				      min_rate);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		dev_kfree_skb(beacon);
buf : 		goto out;
buf : 	}
buf : 
buf : 	wlvif->wmm_enabled =
if->wmm_enabled = 
buf : 		cfg80211_find_vendor_ie(WLAN_OUI_MICROSOFT,
buf : 					WLAN_OUI_TYPE_MICROSOFT_WMM,
buf : 					beacon->data + ieoffset,
buf : 					beacon->len - ieoffset);
buf : 
buf : 	/*
buf : 	 * In case we already have a probe-resp beacon set explicitly
buf : 	 * by usermode, don't use the beacon data.
buf : 	 */
buf : 	if (test_bit(WLVIF_FLAG_AP_PROBE_RESP_SET, &wlvif->flags))
if (test_bit(WLVIF_FLAG_AP_PROBE_RESP_SET, &wlvif->flags)) 
buf : 		goto end_bcn;
buf : 
buf : 	/* remove TIM ie from probe response */
buf : 	wl12xx_remove_ie(beacon, WLAN_EID_TIM, ieoffset);
buf : 
buf : 	/*
buf : 	 * remove p2p ie from probe response.
buf : 	 * the fw reponds to probe requests that don't include
buf : 	 * the p2p ie. probe requests with p2p ie will be passed,
buf : 	 * and will be responded by the supplicant (the spec
buf : 	 * forbids including the p2p ie when responding to probe
forbids including the p2p ie when responding to probe 
buf : 	 * requests that didn't include it).
buf : 	 */
buf : 	wl12xx_remove_vendor_ie(beacon, WLAN_OUI_WFA,
buf : 				WLAN_OUI_TYPE_WFA_P2P, ieoffset);
buf : 
buf : 	hdr = (struct ieee80211_hdr *) beacon->data;
buf : 	hdr->frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
buf : 					 IEEE80211_STYPE_PROBE_RESP);
buf : 	if (is_ap)
if (is_ap) 
buf : 		ret = wl1271_ap_set_probe_resp_tmpl_legacy(wl, vif,
buf : 							   beacon->data,
buf : 							   beacon->len,
buf : 							   min_rate);
buf : 	else
buf : 		ret = wl1271_cmd_template_set(wl, wlvif->role_id,
if->role_id, 
buf : 					      CMD_TEMPL_PROBE_RESPONSE,
buf : 					      beacon->data,
buf : 					      beacon->len, 0,
buf : 					      min_rate);
buf : end_bcn:
buf : 	dev_kfree_skb(beacon);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_bss_beacon_info_changed(struct wl1271 *wl,
buf : 					  struct ieee80211_vif *vif,
if *vif, 
buf : 					  struct ieee80211_bss_conf *bss_conf,
buf : 					  u32 changed)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	bool is_ap = (wlvif->bss_type == BSS_TYPE_AP_BSS);
buf : 	int ret = 0;
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON_INT) {
if (changed & BSS_CHANGED_BEACON_INT) { 
buf : 		wl1271_debug(DEBUG_MASTER, "beacon interval updated: %d",
buf : 			bss_conf->beacon_int);
buf : 
buf : 		wlvif->beacon_int = bss_conf->beacon_int;
if->beacon_int = bss_conf->beacon_int; 
buf : 	}
buf : 
buf : 	if ((changed & BSS_CHANGED_AP_PROBE_RESP) && is_ap) {
buf : 		u32 rate = wl1271_tx_min_rate_get(wl, wlvif->basic_rate_set);
if->basic_rate_set); 
buf : 
buf : 		wl1271_ap_set_probe_resp_tmpl(wl, rate, vif);
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON) {
if (changed & BSS_CHANGED_BEACON) { 
buf : 		ret = wlcore_set_beacon_template(wl, vif, is_ap);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : out:
buf : 	if (ret != 0)
if (ret != 0) 
buf : 		wl1271_error("beacon info change failed: %d", ret);
buf : 	return ret;
buf : }
buf : 
buf : /* AP mode changes */
buf : static void wl1271_bss_info_changed_ap(struct wl1271 *wl,
buf : 				       struct ieee80211_vif *vif,
if *vif, 
buf : 				       struct ieee80211_bss_conf *bss_conf,
buf : 				       u32 changed)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret = 0;
buf : 
buf : 	if (changed & BSS_CHANGED_BASIC_RATES) {
if (changed & BSS_CHANGED_BASIC_RATES) { 
buf : 		u32 rates = bss_conf->basic_rates;
buf : 
buf : 		wlvif->basic_rate_set = wl1271_tx_enabled_rates_get(wl, rates,
if->basic_rate_set = wl1271_tx_enabled_rates_get(wl, rates, 
buf : 								 wlvif->band);
buf : 		wlvif->basic_rate = wl1271_tx_min_rate_get(wl,
if->basic_rate = wl1271_tx_min_rate_get(wl, 
buf : 							wlvif->basic_rate_set);
buf : 
buf : 		ret = wl1271_init_ap_rates(wl, wlvif);
if); 
buf : 		if (ret < 0) {
buf : 			wl1271_error("AP rate policy change failed %d", ret);
buf : 			goto out;
buf : 		}
buf : 
buf : 		ret = wl1271_ap_init_templates(wl, vif);
if); 
buf : 		if (ret < 0)
buf : 			goto out;
buf : 
buf : 		ret = wl1271_ap_set_probe_resp_tmpl(wl, wlvif->basic_rate, vif);
if->basic_rate, vif); 
buf : 		if (ret < 0)
buf : 			goto out;
buf : 
buf : 		ret = wlcore_set_beacon_template(wl, vif, true);
if, true); 
buf : 		if (ret < 0)
buf : 			goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_bss_beacon_info_changed(wl, vif, bss_conf, changed);
if, bss_conf, changed); 
buf : 	if (ret < 0)
buf : 		goto out;
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON_ENABLED) {
if (changed & BSS_CHANGED_BEACON_ENABLED) { 
buf : 		if (bss_conf->enable_beacon) {
buf : 			if (!test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags)) {
if (!test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags)) { 
buf : 				ret = wl12xx_cmd_role_start_ap(wl, wlvif);
buf : 				if (ret < 0)
if (ret < 0) 
buf : 					goto out;
buf : 
buf : 				ret = wl1271_ap_init_hwenc(wl, wlvif);
if); 
buf : 				if (ret < 0)
buf : 					goto out;
buf : 
buf : 				set_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags);
if->flags); 
buf : 				wl1271_debug(DEBUG_AP, "started AP");
buf : 			}
buf : 		} else {
buf : 			if (test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags)) {
if (test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags)) { 
buf : 				/*
buf : 				 * AP might be in ROC in case we have just
buf : 				 * sent auth reply. handle it.
buf : 				 */
buf : 				if (test_bit(wlvif->role_id, wl->roc_map))
if (test_bit(wlvif->role_id, wl->roc_map)) 
buf : 					wl12xx_croc(wl, wlvif->role_id);
buf : 
buf : 				ret = wl12xx_cmd_role_stop_ap(wl, wlvif);
if); 
buf : 				if (ret < 0)
buf : 					goto out;
buf : 
buf : 				clear_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags);
if->flags); 
buf : 				clear_bit(WLVIF_FLAG_AP_PROBE_RESP_SET,
buf : 					  &wlvif->flags);
if->flags); 
buf : 				wl1271_debug(DEBUG_AP, "stopped AP");
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	ret = wl1271_bss_erp_info_changed(wl, vif, bss_conf, changed);
if, bss_conf, changed); 
buf : 	if (ret < 0)
buf : 		goto out;
buf : 
buf : 	/* Handle HT information change */
formation change */ 
buf : 	if ((changed & BSS_CHANGED_HT) &&
buf : 	    (bss_conf->chandef.width != NL80211_CHAN_WIDTH_20_NOHT)) {
buf : 		ret = wl1271_acx_set_ht_information(wl, wlvif,
if, 
buf : 					bss_conf->ht_operation_mode);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			wl1271_warning("Set ht information failed %d", ret);
formation failed %d", ret); 
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : out:
buf : 	return;
buf : }
buf : 
buf : static int wlcore_set_bssid(struct wl1271 *wl, struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 			    struct ieee80211_bss_conf *bss_conf,
buf : 			    u32 sta_rate_set)
buf : {
buf : 	u32 rates;
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211,
buf : 	     "changed_bssid: %pM, aid: %d, bcn_int: %d, brates: 0x%x sta_rate_set: 0x%x",
buf : 	     bss_conf->bssid, bss_conf->aid,
buf : 	     bss_conf->beacon_int,
buf : 	     bss_conf->basic_rates, sta_rate_set);
buf : 
buf : 	wlvif->beacon_int = bss_conf->beacon_int;
if->beacon_int = bss_conf->beacon_int; 
buf : 	rates = bss_conf->basic_rates;
buf : 	wlvif->basic_rate_set =
if->basic_rate_set = 
buf : 		wl1271_tx_enabled_rates_get(wl, rates,
buf : 					    wlvif->band);
if->band); 
buf : 	wlvif->basic_rate =
buf : 		wl1271_tx_min_rate_get(wl,
buf : 				       wlvif->basic_rate_set);
if->basic_rate_set); 
buf : 
buf : 	if (sta_rate_set)
buf : 		wlvif->rate_set =
if->rate_set = 
buf : 			wl1271_tx_enabled_rates_get(wl,
buf : 						sta_rate_set,
buf : 						wlvif->band);
if->band); 
buf : 
buf : 	/* we only support sched_scan while not connected */
while not connected */ 
buf : 	if (wl->sched_vif == wlvif)
buf : 		wl->ops->sched_scan_stop(wl, wlvif);
if); 
buf : 
buf : 	ret = wl1271_acx_sta_rate_policies(wl, wlvif);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	ret = wl12xx_cmd_build_null_data(wl, wlvif);
if); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	ret = wl1271_build_qos_null_data(wl, wl12xx_wlvif_to_vif(wlvif));
if_to_vif(wlvif)); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	wlcore_set_ssid(wl, wlvif);
if); 
buf : 
buf : 	set_bit(WLVIF_FLAG_IN_USE, &wlvif->flags);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wlcore_clear_bssid(struct wl1271 *wl, struct wl12xx_vif *wlvif)
if *wlvif) 
buf : {
buf : 	int ret;
buf : 
buf : 	/* revert back to minimum rates for the current band */
for the current band */ 
buf : 	wl1271_set_band_rate(wl, wlvif);
buf : 	wlvif->basic_rate = wl1271_tx_min_rate_get(wl, wlvif->basic_rate_set);
if->basic_rate = wl1271_tx_min_rate_get(wl, wlvif->basic_rate_set); 
buf : 
buf : 	ret = wl1271_acx_sta_rate_policies(wl, wlvif);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	if (wlvif->bss_type == BSS_TYPE_STA_BSS &&
if (wlvif->bss_type == BSS_TYPE_STA_BSS && 
buf : 	    test_bit(WLVIF_FLAG_IN_USE, &wlvif->flags)) {
buf : 		ret = wl12xx_cmd_role_stop_sta(wl, wlvif);
if); 
buf : 		if (ret < 0)
buf : 			return ret;
buf : 	}
buf : 
buf : 	clear_bit(WLVIF_FLAG_IN_USE, &wlvif->flags);
if->flags); 
buf : 	return 0;
buf : }
buf : /* STA/IBSS mode changes */
buf : static void wl1271_bss_info_changed_sta(struct wl1271 *wl,
buf : 					struct ieee80211_vif *vif,
if *vif, 
buf : 					struct ieee80211_bss_conf *bss_conf,
buf : 					u32 changed)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	bool do_join = false;
buf : 	bool is_ibss = (wlvif->bss_type == BSS_TYPE_IBSS);
if->bss_type == BSS_TYPE_IBSS); 
buf : 	bool ibss_joined = false;
buf : 	u32 sta_rate_set = 0;
buf : 	int ret;
buf : 	struct ieee80211_sta *sta;
buf : 	bool sta_exists = false;
buf : 	struct ieee80211_sta_ht_cap sta_ht_cap;
buf : 
buf : 	if (is_ibss) {
if (is_ibss) { 
buf : 		ret = wl1271_bss_beacon_info_changed(wl, vif, bss_conf,
buf : 						     changed);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_IBSS) {
if (changed & BSS_CHANGED_IBSS) { 
buf : 		if (bss_conf->ibss_joined) {
buf : 			set_bit(WLVIF_FLAG_IBSS_JOINED, &wlvif->flags);
if->flags); 
buf : 			ibss_joined = true;
buf : 		} else {
buf : 			wlcore_unset_assoc(wl, wlvif);
if); 
buf : 			wl12xx_cmd_role_stop_sta(wl, wlvif);
buf : 		}
buf : 	}
buf : 
buf : 	if ((changed & BSS_CHANGED_BEACON_INT) && ibss_joined)
if ((changed & BSS_CHANGED_BEACON_INT) && ibss_joined) 
buf : 		do_join = true;
buf : 
buf : 	/* Need to update the SSID (for filtering etc) */
for filtering etc) */ 
buf : 	if ((changed & BSS_CHANGED_BEACON) && ibss_joined)
buf : 		do_join = true;
buf : 
buf : 	if ((changed & BSS_CHANGED_BEACON_ENABLED) && ibss_joined) {
if ((changed & BSS_CHANGED_BEACON_ENABLED) && ibss_joined) { 
buf : 		wl1271_debug(DEBUG_ADHOC, "ad-hoc beaconing: %s",
buf : 			     bss_conf->enable_beacon ? "enabled" : "disabled");
buf : 
buf : 		do_join = true;
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_IDLE && !is_ibss)
if (changed & BSS_CHANGED_IDLE && !is_ibss) 
buf : 		wl1271_sta_handle_idle(wl, wlvif, bss_conf->idle);
buf : 
buf : 	if (changed & BSS_CHANGED_CQM) {
if (changed & BSS_CHANGED_CQM) { 
buf : 		bool enable = false;
buf : 		if (bss_conf->cqm_rssi_thold)
if (bss_conf->cqm_rssi_thold) 
buf : 			enable = true;
buf : 		ret = wl1271_acx_rssi_snr_trigger(wl, wlvif, enable,
if, enable, 
buf : 						  bss_conf->cqm_rssi_thold,
buf : 						  bss_conf->cqm_rssi_hyst);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 		wlvif->rssi_thold = bss_conf->cqm_rssi_thold;
if->rssi_thold = bss_conf->cqm_rssi_thold; 
buf : 	}
buf : 
buf : 	if (changed & (BSS_CHANGED_BSSID | BSS_CHANGED_HT |
buf : 		       BSS_CHANGED_ASSOC)) {
buf : 		rcu_read_lock();
buf : 		sta = ieee80211_find_sta(vif, bss_conf->bssid);
if, bss_conf->bssid); 
buf : 		if (sta) {
buf : 			u8 *rx_mask = sta->ht_cap.mcs.rx_mask;
buf : 
buf : 			/* save the supp_rates of the ap */
buf : 			sta_rate_set = sta->supp_rates[wlvif->band];
if->band]; 
buf : 			if (sta->ht_cap.ht_supported)
buf : 				sta_rate_set |=
buf : 					(rx_mask[0] << HW_HT_RATES_OFFSET) |
buf : 					(rx_mask[1] << HW_MIMO_RATES_OFFSET);
buf : 			sta_ht_cap = sta->ht_cap;
buf : 			sta_exists = true;
buf : 		}
buf : 
buf : 		rcu_read_unlock();
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_BSSID) {
if (changed & BSS_CHANGED_BSSID) { 
buf : 		if (!is_zero_ether_addr(bss_conf->bssid)) {
buf : 			ret = wlcore_set_bssid(wl, wlvif, bss_conf,
if, bss_conf, 
buf : 					       sta_rate_set);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out;
buf : 
buf : 			/* Need to update the BSSID (for filtering etc) */
for filtering etc) */ 
buf : 			do_join = true;
buf : 		} else {
buf : 			ret = wlcore_clear_bssid(wl, wlvif);
if); 
buf : 			if (ret < 0)
buf : 				goto out;
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_IBSS) {
if (changed & BSS_CHANGED_IBSS) { 
buf : 		wl1271_debug(DEBUG_ADHOC, "ibss_joined: %d",
buf : 			     bss_conf->ibss_joined);
buf : 
buf : 		if (bss_conf->ibss_joined) {
if (bss_conf->ibss_joined) { 
buf : 			u32 rates = bss_conf->basic_rates;
buf : 			wlvif->basic_rate_set =
if->basic_rate_set = 
buf : 				wl1271_tx_enabled_rates_get(wl, rates,
buf : 							    wlvif->band);
if->band); 
buf : 			wlvif->basic_rate =
buf : 				wl1271_tx_min_rate_get(wl,
buf : 						       wlvif->basic_rate_set);
if->basic_rate_set); 
buf : 
buf : 			/* by default, use 11b + OFDM rates */
buf : 			wlvif->rate_set = CONF_TX_IBSS_DEFAULT_RATES;
if->rate_set = CONF_TX_IBSS_DEFAULT_RATES; 
buf : 			ret = wl1271_acx_sta_rate_policies(wl, wlvif);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out;
buf : 		}
buf : 	}
buf : 
buf : 	if ((changed & BSS_CHANGED_BEACON_INFO) && bss_conf->dtim_period) {
if ((changed & BSS_CHANGED_BEACON_INFO) && bss_conf->dtim_period) { 
buf : 		/* enable beacon filtering */
buf : 		ret = wl1271_acx_beacon_filter_opt(wl, wlvif, true);
if, true); 
buf : 		if (ret < 0)
buf : 			goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_bss_erp_info_changed(wl, vif, bss_conf, changed);
if, bss_conf, changed); 
buf : 	if (ret < 0)
buf : 		goto out;
buf : 
buf : 	if (do_join) {
if (do_join) { 
buf : 		ret = wlcore_join(wl, wlvif);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			wl1271_warning("cmd join failed %d", ret);
buf : 			goto out;
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ASSOC) {
if (changed & BSS_CHANGED_ASSOC) { 
buf : 		if (bss_conf->assoc) {
buf : 			ret = wlcore_set_assoc(wl, wlvif, bss_conf,
if, bss_conf, 
buf : 					       sta_rate_set);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out;
buf : 
buf : 			if (test_bit(WLVIF_FLAG_STA_AUTHORIZED, &wlvif->flags))
if (test_bit(WLVIF_FLAG_STA_AUTHORIZED, &wlvif->flags)) 
buf : 				wl12xx_set_authorized(wl, wlvif);
buf : 		} else {
buf : 			wlcore_unset_assoc(wl, wlvif);
if); 
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_PS) {
if (changed & BSS_CHANGED_PS) { 
buf : 		if ((bss_conf->ps) &&
buf : 		    test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags) &&
if->flags) && 
buf : 		    !test_bit(WLVIF_FLAG_IN_PS, &wlvif->flags)) {
buf : 			int ps_mode;
buf : 			char *ps_mode_str;
buf : 
buf : 			if (wl->conf.conn.forced_ps) {
if (wl->conf.conn.forced_ps) { 
buf : 				ps_mode = STATION_POWER_SAVE_MODE;
buf : 				ps_mode_str = "forced";
forced"; 
buf : 			} else {
buf : 				ps_mode = STATION_AUTO_PS_MODE;
buf : 				ps_mode_str = "auto";
buf : 			}
buf : 
buf : 			wl1271_debug(DEBUG_PSM, "%s ps enabled", ps_mode_str);
buf : 
buf : 			ret = wl1271_ps_set_mode(wl, wlvif, ps_mode);
if, ps_mode); 
buf : 			if (ret < 0)
buf : 				wl1271_warning("enter %s ps failed %d",
buf : 					       ps_mode_str, ret);
buf : 		} else if (!bss_conf->ps &&
if (!bss_conf->ps && 
buf : 			   test_bit(WLVIF_FLAG_IN_PS, &wlvif->flags)) {
buf : 			wl1271_debug(DEBUG_PSM, "auto ps disabled");
buf : 
buf : 			ret = wl1271_ps_set_mode(wl, wlvif,
if, 
buf : 						 STATION_ACTIVE_MODE);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				wl1271_warning("exit auto ps failed %d", ret);
buf : 		}
buf : 	}
buf : 
buf : 	/* Handle new association with HT. Do this after join. */
buf : 	if (sta_exists) {
if (sta_exists) { 
buf : 		bool enabled =
buf : 			bss_conf->chandef.width != NL80211_CHAN_WIDTH_20_NOHT;
buf : 
buf : 		ret = wlcore_hw_set_peer_cap(wl,
buf : 					     &sta_ht_cap,
buf : 					     enabled,
buf : 					     wlvif->rate_set,
if->rate_set, 
buf : 					     wlvif->sta.hlid);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			wl1271_warning("Set ht cap failed %d", ret);
buf : 			goto out;
buf : 
buf : 		}
buf : 
buf : 		if (enabled) {
if (enabled) { 
buf : 			ret = wl1271_acx_set_ht_information(wl, wlvif,
formation(wl, wlvif, 
buf : 						bss_conf->ht_operation_mode);
buf : 			if (ret < 0) {
if (ret < 0) { 
buf : 				wl1271_warning("Set ht information failed %d",
formation failed %d", 
buf : 					       ret);
buf : 				goto out;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	/* Handle arp filtering. Done after join. */
buf : 	if ((changed & BSS_CHANGED_ARP_FILTER) ||
if ((changed & BSS_CHANGED_ARP_FILTER) || 
buf : 	    (!is_ibss && (changed & BSS_CHANGED_QOS))) {
buf : 		__be32 addr = bss_conf->arp_addr_list[0];
buf : 		wlvif->sta.qos = bss_conf->qos;
if->sta.qos = bss_conf->qos; 
buf : 		WARN_ON(wlvif->bss_type != BSS_TYPE_STA_BSS);
buf : 
buf : 		if (bss_conf->arp_addr_cnt == 1 && bss_conf->assoc) {
if (bss_conf->arp_addr_cnt == 1 && bss_conf->assoc) { 
buf : 			wlvif->ip_addr = addr;
buf : 			/*
buf : 			 * The template should have been configured only upon
buf : 			 * association. however, it seems that the correct ip
buf : 			 * isn't being set (when sending), so we have to
buf : 			 * reconfigure the template upon every ip change.
buf : 			 */
buf : 			ret = wl1271_cmd_build_arp_rsp(wl, wlvif);
if); 
buf : 			if (ret < 0) {
buf : 				wl1271_warning("build arp rsp failed: %d", ret);
buf : 				goto out;
buf : 			}
buf : 
buf : 			ret = wl1271_acx_arp_ip_filter(wl, wlvif,
if, 
buf : 				(ACX_ARP_FILTER_ARP_FILTERING |
buf : 				 ACX_ARP_FILTER_AUTO_ARP),
buf : 				addr);
buf : 		} else {
buf : 			wlvif->ip_addr = 0;
if->ip_addr = 0; 
buf : 			ret = wl1271_acx_arp_ip_filter(wl, wlvif, 0, addr);
buf : 		}
buf : 
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : out:
buf : 	return;
buf : }
buf : 
buf : static void wl1271_op_bss_info_changed(struct ieee80211_hw *hw,
buf : 				       struct ieee80211_vif *vif,
if *vif, 
buf : 				       struct ieee80211_bss_conf *bss_conf,
buf : 				       u32 changed)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	bool is_ap = (wlvif->bss_type == BSS_TYPE_AP_BSS);
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 bss info role %d changed 0x%x",
buf : 		     wlvif->role_id, (int)changed);
if->role_id, (int)changed); 
buf : 
buf : 	/*
buf : 	 * make sure to cancel pending disconnections if our association
if our association 
buf : 	 * state changed
buf : 	 */
buf : 	if (!is_ap && (changed & BSS_CHANGED_ASSOC))
if (!is_ap && (changed & BSS_CHANGED_ASSOC)) 
buf : 		cancel_delayed_work_sync(&wlvif->connection_loss_work);
buf : 
buf : 	if (is_ap && (changed & BSS_CHANGED_BEACON_ENABLED) &&
if (is_ap && (changed & BSS_CHANGED_BEACON_ENABLED) && 
buf : 	    !bss_conf->enable_beacon)
buf : 		wl1271_tx_flush(wl);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	if (unlikely(!test_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags)))
if (unlikely(!test_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags))) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	if ((changed & BSS_CHANGED_TXPOWER) &&
if ((changed & BSS_CHANGED_TXPOWER) && 
buf : 	    bss_conf->txpower != wlvif->power_level) {
buf : 
buf : 		ret = wl1271_acx_tx_power(wl, wlvif, bss_conf->txpower);
if, bss_conf->txpower); 
buf : 		if (ret < 0)
buf : 			goto out;
buf : 
buf : 		wlvif->power_level = bss_conf->txpower;
if->power_level = bss_conf->txpower; 
buf : 	}
buf : 
buf : 	if (is_ap)
buf : 		wl1271_bss_info_changed_ap(wl, vif, bss_conf, changed);
if, bss_conf, changed); 
buf : 	else
buf : 		wl1271_bss_info_changed_sta(wl, vif, bss_conf, changed);
if, bss_conf, changed); 
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int wlcore_op_add_chanctx(struct ieee80211_hw *hw,
buf : 				 struct ieee80211_chanctx_conf *ctx)
buf : {
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 add chanctx %d (type %d)",
buf : 		     ieee80211_frequency_to_channel(ctx->def.chan->center_freq),
buf : 		     cfg80211_get_chandef_type(&ctx->def));
buf : 	return 0;
buf : }
buf : 
buf : static void wlcore_op_remove_chanctx(struct ieee80211_hw *hw,
buf : 				     struct ieee80211_chanctx_conf *ctx)
buf : {
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 remove chanctx %d (type %d)",
buf : 		     ieee80211_frequency_to_channel(ctx->def.chan->center_freq),
buf : 		     cfg80211_get_chandef_type(&ctx->def));
buf : }
buf : 
buf : static void wlcore_op_change_chanctx(struct ieee80211_hw *hw,
buf : 				     struct ieee80211_chanctx_conf *ctx,
buf : 				     u32 changed)
buf : {
buf : 	wl1271_debug(DEBUG_MAC80211,
buf : 		     "mac80211 change chanctx %d (type %d) changed 0x%x",
buf : 		     ieee80211_frequency_to_channel(ctx->def.chan->center_freq),
buf : 		     cfg80211_get_chandef_type(&ctx->def), changed);
buf : }
buf : 
buf : static int wlcore_op_assign_vif_chanctx(struct ieee80211_hw *hw,
if_chanctx(struct ieee80211_hw *hw, 
buf : 					struct ieee80211_vif *vif,
buf : 					struct ieee80211_chanctx_conf *ctx)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int channel = ieee80211_frequency_to_channel(
buf : 		ctx->def.chan->center_freq);
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211,
buf : 		     "mac80211 assign chanctx (role %d) %d (type %d)",
buf : 		     wlvif->role_id, channel, cfg80211_get_chandef_type(&ctx->def));
if->role_id, channel, cfg80211_get_chandef_type(&ctx->def)); 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	wlvif->band = ctx->def.chan->band;
if->band = ctx->def.chan->band; 
buf : 	wlvif->channel = channel;
buf : 	wlvif->channel_type = cfg80211_get_chandef_type(&ctx->def);
if->channel_type = cfg80211_get_chandef_type(&ctx->def); 
buf : 
buf : 	/* update default rates according to the band */
buf : 	wl1271_set_band_rate(wl, wlvif);
if); 
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void wlcore_op_unassign_vif_chanctx(struct ieee80211_hw *hw,
if_chanctx(struct ieee80211_hw *hw, 
buf : 					   struct ieee80211_vif *vif,
buf : 					   struct ieee80211_chanctx_conf *ctx)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211,
buf : 		     "mac80211 unassign chanctx (role %d) %d (type %d)",
buf : 		     wlvif->role_id,
if->role_id, 
buf : 		     ieee80211_frequency_to_channel(ctx->def.chan->center_freq),
buf : 		     cfg80211_get_chandef_type(&ctx->def));
buf : 
buf : 	wl1271_tx_flush(wl);
buf : }
buf : 
buf : static int wl1271_op_conf_tx(struct ieee80211_hw *hw,
buf : 			     struct ieee80211_vif *vif, u16 queue,
if *vif, u16 queue, 
buf : 			     const struct ieee80211_tx_queue_params *params)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	u8 ps_scheme;
buf : 	int ret = 0;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 conf tx %d", queue);
buf : 
buf : 	if (params->uapsd)
if (params->uapsd) 
buf : 		ps_scheme = CONF_PS_SCHEME_UPSD_TRIGGER;
buf : 	else
buf : 		ps_scheme = CONF_PS_SCHEME_LEGACY;
buf : 
buf : 	if (!test_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags))
if (!test_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * the txop is confed in units of 32us by the mac80211,
buf : 	 * we need us
buf : 	 */
buf : 	ret = wl1271_acx_ac_cfg(wl, wlvif, wl1271_tx_get_queue(queue),
if, wl1271_tx_get_queue(queue), 
buf : 				params->cw_min, params->cw_max,
buf : 				params->aifs, params->txop << 5);
ifs, params->txop << 5); 
buf : 	if (ret < 0)
buf : 		goto out_sleep;
buf : 
buf : 	ret = wl1271_acx_tid_cfg(wl, wlvif, wl1271_tx_get_queue(queue),
if, wl1271_tx_get_queue(queue), 
buf : 				 CONF_CHANNEL_TYPE_EDCF,
buf : 				 wl1271_tx_get_queue(queue),
buf : 				 ps_scheme, CONF_ACK_POLICY_LEGACY,
buf : 				 0, 0);
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static u64 wl1271_op_get_tsf(struct ieee80211_hw *hw,
buf : 			     struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	u64 mactime = ULLONG_MAX;
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 get tsf");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl12xx_acx_tsf_info(wl, wlvif, &mactime);
if, &mactime); 
buf : 	if (ret < 0)
buf : 		goto out_sleep;
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 	return mactime;
buf : }
buf : 
buf : static int wl1271_op_get_survey(struct ieee80211_hw *hw, int idx,
buf : 				struct survey_info *survey)
buf : {
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 
buf : 	if (idx != 0)
if (idx != 0) 
buf : 		return -ENOENT;
buf : 
buf : 	survey->channel = conf->chandef.chan;
buf : 	survey->filled = 0;
buf : 	return 0;
buf : }
buf : 
buf : static int wl1271_allocate_sta(struct wl1271 *wl,
buf : 			     struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 			     struct ieee80211_sta *sta)
buf : {
buf : 	struct wl1271_station *wl_sta;
buf : 	int ret;
buf : 
buf : 
buf : 	if (wl->active_sta_count >= wl->max_ap_stations) {
if (wl->active_sta_count >= wl->max_ap_stations) { 
buf : 		wl1271_warning("could not allocate HLID - too much stations");
buf : 		return -EBUSY;
buf : 	}
buf : 
buf : 	wl_sta = (struct wl1271_station *)sta->drv_priv;
buf : 	ret = wl12xx_allocate_link(wl, wlvif, &wl_sta->hlid);
if, &wl_sta->hlid); 
buf : 	if (ret < 0) {
buf : 		wl1271_warning("could not allocate HLID - too many links");
buf : 		return -EBUSY;
buf : 	}
buf : 
buf : 	/* use the previous security seq, if this is a recovery/resume */
if this is a recovery/resume */ 
buf : 	wl->links[wl_sta->hlid].total_freed_pkts = wl_sta->total_freed_pkts;
buf : 
buf : 	set_bit(wl_sta->hlid, wlvif->ap.sta_hlid_map);
if->ap.sta_hlid_map); 
buf : 	memcpy(wl->links[wl_sta->hlid].addr, sta->addr, ETH_ALEN);
buf : 	wl->active_sta_count++;
buf : 	return 0;
buf : }
buf : 
buf : void wl1271_free_sta(struct wl1271 *wl, struct wl12xx_vif *wlvif, u8 hlid)
if *wlvif, u8 hlid) 
buf : {
buf : 	struct wl1271_station *wl_sta;
buf : 	struct ieee80211_sta *sta;
buf : 	struct ieee80211_vif *vif = wl12xx_wlvif_to_vif(wlvif);
if *vif = wl12xx_wlvif_to_vif(wlvif); 
buf : 
buf : 	if (!test_bit(hlid, wlvif->ap.sta_hlid_map))
buf : 		return;
buf : 
buf : 	clear_bit(hlid, wlvif->ap.sta_hlid_map);
if->ap.sta_hlid_map); 
buf : 	__clear_bit(hlid, &wl->ap_ps_map);
buf : 	__clear_bit(hlid, (unsigned long *)&wl->ap_fw_ps_map);
buf : 
buf : 	/*
buf : 	 * save the last used PN in the private part of iee80211_sta,
buf : 	 * in case of recovery/suspend
buf : 	 */
buf : 	rcu_read_lock();
buf : 	sta = ieee80211_find_sta(vif, wl->links[hlid].addr);
if, wl->links[hlid].addr); 
buf : 	if (sta) {
buf : 		wl_sta = (void *)sta->drv_priv;
buf : 		wl_sta->total_freed_pkts = wl->links[hlid].total_freed_pkts;
buf : 
buf : 		/*
buf : 		 * increment the initial seq number on recovery to account for
for 
buf : 		 * transmitted packets that we haven't yet got in the FW status
buf : 		 */
buf : 		if (test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags))
if (test_bit(WL1271_FLAG_RECOVERY_IN_PROGRESS, &wl->flags)) 
buf : 			wl_sta->total_freed_pkts +=
buf : 					WL1271_TX_SQN_POST_RECOVERY_PADDING;
buf : 	}
buf : 	rcu_read_unlock();
buf : 
buf : 	wl12xx_free_link(wl, wlvif, &hlid);
if, &hlid); 
buf : 	wl->active_sta_count--;
buf : 
buf : 	/*
buf : 	 * rearm the tx watchdog when the last STA is freed - give the FW a
buf : 	 * chance to return STA-buffered packets before complaining.
fore complaining. 
buf : 	 */
buf : 	if (wl->active_sta_count == 0)
if (wl->active_sta_count == 0) 
buf : 		wl12xx_rearm_tx_watchdog_locked(wl);
buf : }
buf : 
buf : static int wl12xx_sta_add(struct wl1271 *wl,
buf : 			  struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 			  struct ieee80211_sta *sta)
buf : {
buf : 	struct wl1271_station *wl_sta;
buf : 	int ret = 0;
buf : 	u8 hlid;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 add sta %d", (int)sta->aid);
buf : 
buf : 	ret = wl1271_allocate_sta(wl, wlvif, sta);
if, sta); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	wl_sta = (struct wl1271_station *)sta->drv_priv;
buf : 	hlid = wl_sta->hlid;
buf : 
buf : 	ret = wl12xx_cmd_add_peer(wl, wlvif, sta, hlid);
if, sta, hlid); 
buf : 	if (ret < 0)
buf : 		wl1271_free_sta(wl, wlvif, hlid);
if, hlid); 
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_sta_remove(struct wl1271 *wl,
buf : 			     struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 			     struct ieee80211_sta *sta)
buf : {
buf : 	struct wl1271_station *wl_sta;
buf : 	int ret = 0, id;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 remove sta %d", (int)sta->aid);
buf : 
buf : 	wl_sta = (struct wl1271_station *)sta->drv_priv;
buf : 	id = wl_sta->hlid;
buf : 	if (WARN_ON(!test_bit(id, wlvif->ap.sta_hlid_map)))
if (WARN_ON(!test_bit(id, wlvif->ap.sta_hlid_map))) 
buf : 		return -EINVAL;
buf : 
buf : 	ret = wl12xx_cmd_remove_peer(wl, wlvif, wl_sta->hlid);
if, wl_sta->hlid); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	wl1271_free_sta(wl, wlvif, wl_sta->hlid);
if, wl_sta->hlid); 
buf : 	return ret;
buf : }
buf : 
buf : static void wlcore_roc_if_possible(struct wl1271 *wl,
if_possible(struct wl1271 *wl, 
buf : 				   struct wl12xx_vif *wlvif)
buf : {
buf : 	if (find_first_bit(wl->roc_map,
if (find_first_bit(wl->roc_map, 
buf : 			   WL12XX_MAX_ROLES) < WL12XX_MAX_ROLES)
buf : 		return;
buf : 
buf : 	if (WARN_ON(wlvif->role_id == WL12XX_INVALID_ROLE_ID))
if (WARN_ON(wlvif->role_id == WL12XX_INVALID_ROLE_ID)) 
buf : 		return;
buf : 
buf : 	wl12xx_roc(wl, wlvif, wlvif->role_id, wlvif->band, wlvif->channel);
if, wlvif->role_id, wlvif->band, wlvif->channel); 
buf : }
buf : 
buf : /*
buf :  * when wl_sta is NULL, we treat this call as if coming from a
buf :  * pending auth reply.
buf :  * wl->mutex must be taken and the FW must be awake when the call
buf :  * takes place.
buf :  */
buf : void wlcore_update_inconn_sta(struct wl1271 *wl, struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 			      struct wl1271_station *wl_sta, bool in_conn)
buf : {
buf : 	if (in_conn) {
if (in_conn) { 
buf : 		if (WARN_ON(wl_sta && wl_sta->in_connection))
buf : 			return;
buf : 
buf : 		if (!wlvif->ap_pending_auth_reply &&
if (!wlvif->ap_pending_auth_reply && 
buf : 		    !wlvif->inconn_count)
buf : 			wlcore_roc_if_possible(wl, wlvif);
if_possible(wl, wlvif); 
buf : 
buf : 		if (wl_sta) {
buf : 			wl_sta->in_connection = true;
buf : 			wlvif->inconn_count++;
if->inconn_count++; 
buf : 		} else {
buf : 			wlvif->ap_pending_auth_reply = true;
if->ap_pending_auth_reply = true; 
buf : 		}
buf : 	} else {
buf : 		if (wl_sta && !wl_sta->in_connection)
if (wl_sta && !wl_sta->in_connection) 
buf : 			return;
buf : 
buf : 		if (WARN_ON(!wl_sta && !wlvif->ap_pending_auth_reply))
if (WARN_ON(!wl_sta && !wlvif->ap_pending_auth_reply)) 
buf : 			return;
buf : 
buf : 		if (WARN_ON(wl_sta && !wlvif->inconn_count))
if (WARN_ON(wl_sta && !wlvif->inconn_count)) 
buf : 			return;
buf : 
buf : 		if (wl_sta) {
if (wl_sta) { 
buf : 			wl_sta->in_connection = false;
buf : 			wlvif->inconn_count--;
if->inconn_count--; 
buf : 		} else {
buf : 			wlvif->ap_pending_auth_reply = false;
if->ap_pending_auth_reply = false; 
buf : 		}
buf : 
buf : 		if (!wlvif->inconn_count && !wlvif->ap_pending_auth_reply &&
if (!wlvif->inconn_count && !wlvif->ap_pending_auth_reply && 
buf : 		    test_bit(wlvif->role_id, wl->roc_map))
buf : 			wl12xx_croc(wl, wlvif->role_id);
if->role_id); 
buf : 	}
buf : }
buf : 
buf : static int wl12xx_update_sta_state(struct wl1271 *wl,
buf : 				   struct wl12xx_vif *wlvif,
if *wlvif, 
buf : 				   struct ieee80211_sta *sta,
buf : 				   enum ieee80211_sta_state old_state,
buf : 				   enum ieee80211_sta_state new_state)
buf : {
buf : 	struct wl1271_station *wl_sta;
buf : 	bool is_ap = wlvif->bss_type == BSS_TYPE_AP_BSS;
if->bss_type == BSS_TYPE_AP_BSS; 
buf : 	bool is_sta = wlvif->bss_type == BSS_TYPE_STA_BSS;
buf : 	int ret;
buf : 
buf : 	wl_sta = (struct wl1271_station *)sta->drv_priv;
buf : 
buf : 	/* Add station (AP mode) */
buf : 	if (is_ap &&
if (is_ap && 
buf : 	    old_state == IEEE80211_STA_NOTEXIST &&
buf : 	    new_state == IEEE80211_STA_NONE) {
buf : 		ret = wl12xx_sta_add(wl, wlvif, sta);
if, sta); 
buf : 		if (ret)
buf : 			return ret;
buf : 
buf : 		wlcore_update_inconn_sta(wl, wlvif, wl_sta, true);
if, wl_sta, true); 
buf : 	}
buf : 
buf : 	/* Remove station (AP mode) */
buf : 	if (is_ap &&
if (is_ap && 
buf : 	    old_state == IEEE80211_STA_NONE &&
buf : 	    new_state == IEEE80211_STA_NOTEXIST) {
buf : 		/* must not fail */
buf : 		wl12xx_sta_remove(wl, wlvif, sta);
if, sta); 
buf : 
buf : 		wlcore_update_inconn_sta(wl, wlvif, wl_sta, false);
buf : 	}
buf : 
buf : 	/* Authorize station (AP mode) */
buf : 	if (is_ap &&
if (is_ap && 
buf : 	    new_state == IEEE80211_STA_AUTHORIZED) {
buf : 		ret = wl12xx_cmd_set_peer_state(wl, wlvif, wl_sta->hlid);
if, wl_sta->hlid); 
buf : 		if (ret < 0)
buf : 			return ret;
buf : 
buf : 		ret = wl1271_acx_set_ht_capabilities(wl, &sta->ht_cap, true,
buf : 						     wl_sta->hlid);
buf : 		if (ret)
if (ret) 
buf : 			return ret;
buf : 
buf : 		wlcore_update_inconn_sta(wl, wlvif, wl_sta, false);
if, wl_sta, false); 
buf : 	}
buf : 
buf : 	/* Authorize station */
buf : 	if (is_sta &&
if (is_sta && 
buf : 	    new_state == IEEE80211_STA_AUTHORIZED) {
buf : 		set_bit(WLVIF_FLAG_STA_AUTHORIZED, &wlvif->flags);
if->flags); 
buf : 		ret = wl12xx_set_authorized(wl, wlvif);
buf : 		if (ret)
if (ret) 
buf : 			return ret;
buf : 	}
buf : 
buf : 	if (is_sta &&
if (is_sta && 
buf : 	    old_state == IEEE80211_STA_AUTHORIZED &&
buf : 	    new_state == IEEE80211_STA_ASSOC) {
buf : 		clear_bit(WLVIF_FLAG_STA_AUTHORIZED, &wlvif->flags);
if->flags); 
buf : 		clear_bit(WLVIF_FLAG_STA_STATE_SENT, &wlvif->flags);
buf : 	}
buf : 
buf : 	/* clear ROCs on failure or authorization */
buf : 	if (is_sta &&
if (is_sta && 
buf : 	    (new_state == IEEE80211_STA_AUTHORIZED ||
buf : 	     new_state == IEEE80211_STA_NOTEXIST)) {
buf : 		if (test_bit(wlvif->role_id, wl->roc_map))
if (test_bit(wlvif->role_id, wl->roc_map)) 
buf : 			wl12xx_croc(wl, wlvif->role_id);
buf : 	}
buf : 
buf : 	if (is_sta &&
if (is_sta && 
buf : 	    old_state == IEEE80211_STA_NOTEXIST &&
buf : 	    new_state == IEEE80211_STA_NONE) {
buf : 		if (find_first_bit(wl->roc_map,
if (find_first_bit(wl->roc_map, 
buf : 				   WL12XX_MAX_ROLES) >= WL12XX_MAX_ROLES) {
buf : 			WARN_ON(wlvif->role_id == WL12XX_INVALID_ROLE_ID);
if->role_id == WL12XX_INVALID_ROLE_ID); 
buf : 			wl12xx_roc(wl, wlvif, wlvif->role_id,
buf : 				   wlvif->band, wlvif->channel);
if->band, wlvif->channel); 
buf : 		}
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static int wl12xx_op_sta_state(struct ieee80211_hw *hw,
buf : 			       struct ieee80211_vif *vif,
if *vif, 
buf : 			       struct ieee80211_sta *sta,
buf : 			       enum ieee80211_sta_state old_state,
buf : 			       enum ieee80211_sta_state new_state)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 sta %d state=%d->%d",
buf : 		     sta->aid, old_state, new_state);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		ret = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl12xx_update_sta_state(wl, wlvif, sta, old_state, new_state);
if, sta, old_state, new_state); 
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 	if (new_state < old_state)
if (new_state < old_state) 
buf : 		return 0;
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_op_ampdu_action(struct ieee80211_hw *hw,
buf : 				  struct ieee80211_vif *vif,
if *vif, 
buf : 				  enum ieee80211_ampdu_mlme_action action,
buf : 				  struct ieee80211_sta *sta, u16 tid, u16 *ssn,
buf : 				  u8 buf_size)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret;
buf : 	u8 hlid, *ba_bitmap;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 ampdu action %d tid %d", action,
buf : 		     tid);
buf : 
buf : 	/* sanity check - the fields in FW are only 8bits wide */
buf : 	if (WARN_ON(tid > 0xFF))
if (WARN_ON(tid > 0xFF)) 
buf : 		return -ENOTSUPP;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		ret = -EAGAIN;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (wlvif->bss_type == BSS_TYPE_STA_BSS) {
if (wlvif->bss_type == BSS_TYPE_STA_BSS) { 
buf : 		hlid = wlvif->sta.hlid;
buf : 	} else if (wlvif->bss_type == BSS_TYPE_AP_BSS) {
if (wlvif->bss_type == BSS_TYPE_AP_BSS) { 
buf : 		struct wl1271_station *wl_sta;
buf : 
buf : 		wl_sta = (struct wl1271_station *)sta->drv_priv;
buf : 		hlid = wl_sta->hlid;
buf : 	} else {
buf : 		ret = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ba_bitmap = &wl->links[hlid].ba_bitmap;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 ampdu: Rx tid %d action %d",
buf : 		     tid, action);
buf : 
buf : 	switch (action) {
buf : 	case IEEE80211_AMPDU_RX_START:
buf : 		if (!wlvif->ba_support || !wlvif->ba_allowed) {
if (!wlvif->ba_support || !wlvif->ba_allowed) { 
buf : 			ret = -ENOTSUPP;
buf : 			break;
buf : 		}
buf : 
buf : 		if (wl->ba_rx_session_count >= wl->ba_rx_session_count_max) {
if (wl->ba_rx_session_count >= wl->ba_rx_session_count_max) { 
buf : 			ret = -EBUSY;
buf : 			wl1271_error("exceeded max RX BA sessions");
buf : 			break;
buf : 		}
buf : 
buf : 		if (*ba_bitmap & BIT(tid)) {
if (*ba_bitmap & BIT(tid)) { 
buf : 			ret = -EINVAL;
buf : 			wl1271_error("cannot enable RX BA session on active "
buf : 				     "tid: %d", tid);
buf : 			break;
buf : 		}
buf : 
buf : 		ret = wl12xx_acx_set_ba_receiver_session(wl, tid, *ssn, true,
buf : 							 hlid);
buf : 		if (!ret) {
if (!ret) { 
buf : 			*ba_bitmap |= BIT(tid);
buf : 			wl->ba_rx_session_count++;
buf : 		}
buf : 		break;
buf : 
buf : 	case IEEE80211_AMPDU_RX_STOP:
buf : 		if (!(*ba_bitmap & BIT(tid))) {
if (!(*ba_bitmap & BIT(tid))) { 
buf : 			/*
buf : 			 * this happens on reconfig - so only output a debug
buf : 			 * message for now, and don't fail the function.
for now, and don't fail the function. 
buf : 			 */
buf : 			wl1271_debug(DEBUG_MAC80211,
buf : 				     "no active RX BA session on tid: %d",
buf : 				     tid);
buf : 			ret = 0;
buf : 			break;
buf : 		}
buf : 
buf : 		ret = wl12xx_acx_set_ba_receiver_session(wl, tid, 0, false,
buf : 							 hlid);
buf : 		if (!ret) {
if (!ret) { 
buf : 			*ba_bitmap &= ~BIT(tid);
buf : 			wl->ba_rx_session_count--;
buf : 		}
buf : 		break;
buf : 
buf : 	/*
buf : 	 * The BA initiator session management in FW independently.
buf : 	 * Falling break here on purpose for all TX APDU commands.
for all TX APDU commands. 
buf : 	 */
buf : 	case IEEE80211_AMPDU_TX_START:
buf : 	case IEEE80211_AMPDU_TX_STOP_CONT:
buf : 	case IEEE80211_AMPDU_TX_STOP_FLUSH:
buf : 	case IEEE80211_AMPDU_TX_STOP_FLUSH_CONT:
buf : 	case IEEE80211_AMPDU_TX_OPERATIONAL:
buf : 		ret = -EINVAL;
buf : 		break;
buf : 
buf : 	default:
buf : 		wl1271_error("Incorrect ampdu action id=%x\n", action);
buf : 		ret = -EINVAL;
buf : 	}
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl12xx_set_bitrate_mask(struct ieee80211_hw *hw,
buf : 				   struct ieee80211_vif *vif,
if *vif, 
buf : 				   const struct cfg80211_bitrate_mask *mask)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	struct wl1271 *wl = hw->priv;
buf : 	int i, ret = 0;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 set_bitrate_mask 0x%x 0x%x",
buf : 		mask->control[NL80211_BAND_2GHZ].legacy,
buf : 		mask->control[NL80211_BAND_5GHZ].legacy);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	for (i = 0; i < WLCORE_NUM_BANDS; i++)
for (i = 0; i < WLCORE_NUM_BANDS; i++) 
buf : 		wlvif->bitrate_masks[i] =
buf : 			wl1271_tx_enabled_rates_get(wl,
buf : 						    mask->control[i].legacy,
buf : 						    i);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	if (wlvif->bss_type == BSS_TYPE_STA_BSS &&
if (wlvif->bss_type == BSS_TYPE_STA_BSS && 
buf : 	    !test_bit(WLVIF_FLAG_STA_ASSOCIATED, &wlvif->flags)) {
buf : 
buf : 		ret = wl1271_ps_elp_wakeup(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 
buf : 		wl1271_set_band_rate(wl, wlvif);
if); 
buf : 		wlvif->basic_rate =
buf : 			wl1271_tx_min_rate_get(wl, wlvif->basic_rate_set);
if->basic_rate_set); 
buf : 		ret = wl1271_acx_sta_rate_policies(wl, wlvif);
buf : 
buf : 		wl1271_ps_elp_sleep(wl);
buf : 	}
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void wl12xx_op_channel_switch(struct ieee80211_hw *hw,
buf : 				     struct ieee80211_channel_switch *ch_switch)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 channel switch");
buf : 
buf : 	wl1271_tx_flush(wl);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state == WLCORE_STATE_OFF)) {
if (unlikely(wl->state == WLCORE_STATE_OFF)) { 
buf : 		wl12xx_for_each_wlvif_sta(wl, wlvif) {
for_each_wlvif_sta(wl, wlvif) { 
buf : 			struct ieee80211_vif *vif = wl12xx_wlvif_to_vif(wlvif);
buf : 			ieee80211_chswitch_done(vif, false);
if, false); 
buf : 		}
buf : 		goto out;
buf : 	} else if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* TODO: change mac80211 to pass vif as param */
if as param */ 
buf : 	wl12xx_for_each_wlvif_sta(wl, wlvif) {
for_each_wlvif_sta(wl, wlvif) { 
buf : 		unsigned long delay_usec;
buf : 
buf : 		ret = wl->ops->channel_switch(wl, wlvif, ch_switch);
if, ch_switch); 
buf : 		if (ret)
buf : 			goto out_sleep;
buf : 
buf : 		set_bit(WLVIF_FLAG_CS_PROGRESS, &wlvif->flags);
if->flags); 
buf : 
buf : 		/* indicate failure 5 seconds after channel switch time */
buf : 		delay_usec = ieee80211_tu_to_usec(wlvif->beacon_int) *
if->beacon_int) * 
buf : 			     ch_switch->count;
buf : 		ieee80211_queue_delayed_work(hw, &wlvif->channel_switch_work,
if->channel_switch_work, 
buf : 				usecs_to_jiffies(delay_usec) +
buf : 				msecs_to_jiffies(5000));
iffies(5000)); 
buf : 	}
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static void wlcore_op_flush(struct ieee80211_hw *hw, struct ieee80211_vif *vif,
if *vif, 
buf : 			    u32 queues, bool drop)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 
buf : 	wl1271_tx_flush(wl);
buf : }
buf : 
buf : static int wlcore_op_remain_on_channel(struct ieee80211_hw *hw,
buf : 				       struct ieee80211_vif *vif,
if *vif, 
buf : 				       struct ieee80211_channel *chan,
buf : 				       int duration,
buf : 				       enum ieee80211_roc_type type)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	struct wl1271 *wl = hw->priv;
buf : 	int channel, ret = 0;
buf : 
buf : 	channel = ieee80211_frequency_to_channel(chan->center_freq);
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 roc %d (%d)",
buf : 		     channel, wlvif->role_id);
if->role_id); 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	/* return EBUSY if we can't ROC right now */
if we can't ROC right now */ 
buf : 	if (WARN_ON(wl->roc_vif ||
buf : 		    find_first_bit(wl->roc_map,
buf : 				   WL12XX_MAX_ROLES) < WL12XX_MAX_ROLES)) {
buf : 		ret = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl12xx_start_dev(wl, wlvif, chan->band, channel);
if, chan->band, channel); 
buf : 	if (ret < 0)
buf : 		goto out_sleep;
buf : 
buf : 	wl->roc_vif = vif;
if = vif; 
buf : 	ieee80211_queue_delayed_work(hw, &wl->roc_complete_work,
buf : 				     msecs_to_jiffies(duration));
iffies(duration)); 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 	return ret;
buf : }
buf : 
buf : static int __wlcore_roc_completed(struct wl1271 *wl)
buf : {
buf : 	struct wl12xx_vif *wlvif;
if *wlvif; 
buf : 	int ret;
buf : 
buf : 	/* already completed */
buf : 	if (unlikely(!wl->roc_vif))
if (unlikely(!wl->roc_vif)) 
buf : 		return 0;
buf : 
buf : 	wlvif = wl12xx_vif_to_data(wl->roc_vif);
if = wl12xx_vif_to_data(wl->roc_vif); 
buf : 
buf : 	if (!test_bit(WLVIF_FLAG_INITIALIZED, &wlvif->flags))
buf : 		return -EBUSY;
buf : 
buf : 	ret = wl12xx_stop_dev(wl, wlvif);
if); 
buf : 	if (ret < 0)
buf : 		return ret;
buf : 
buf : 	wl->roc_vif = NULL;
if = NULL; 
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wlcore_roc_completed(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "roc complete");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON)) {
if (unlikely(wl->state != WLCORE_STATE_ON)) { 
buf : 		ret = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = __wlcore_roc_completed(wl);
buf : 
buf : 	wl1271_ps_elp_sleep(wl);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void wlcore_roc_complete_work(struct work_struct *work)
buf : {
buf : 	struct delayed_work *dwork;
buf : 	struct wl1271 *wl;
buf : 	int ret;
buf : 
buf : 	dwork = container_of(work, struct delayed_work, work);
buf : 	wl = container_of(dwork, struct wl1271, roc_complete_work);
buf : 
buf : 	ret = wlcore_roc_completed(wl);
buf : 	if (!ret)
if (!ret) 
buf : 		ieee80211_remain_on_channel_expired(wl->hw);
buf : }
buf : 
buf : static int wlcore_op_cancel_remain_on_channel(struct ieee80211_hw *hw)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 croc");
buf : 
buf : 	/* TODO: per-vif */
if */ 
buf : 	wl1271_tx_flush(wl);
buf : 
buf : 	/*
buf : 	 * we can't just flush_work here, because it might deadlock
buf : 	 * (as we might get called from the same workqueue)
buf : 	 */
buf : 	cancel_delayed_work_sync(&wl->roc_complete_work);
buf : 	wlcore_roc_completed(wl);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void wlcore_op_sta_rc_update(struct ieee80211_hw *hw,
buf : 				    struct ieee80211_vif *vif,
if *vif, 
buf : 				    struct ieee80211_sta *sta,
buf : 				    u32 changed)
buf : {
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	struct wl1271 *wl = hw->priv;
buf : 
buf : 	wlcore_hw_sta_rc_update(wl, wlvif, sta, changed);
if, sta, changed); 
buf : }
buf : 
buf : static int wlcore_op_get_rssi(struct ieee80211_hw *hw,
buf : 			       struct ieee80211_vif *vif,
if *vif, 
buf : 			       struct ieee80211_sta *sta,
buf : 			       s8 *rssi_dbm)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	struct wl12xx_vif *wlvif = wl12xx_vif_to_data(vif);
if *wlvif = wl12xx_vif_to_data(vif); 
buf : 	int ret = 0;
buf : 
buf : 	wl1271_debug(DEBUG_MAC80211, "mac80211 get_rssi");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	ret = wl1271_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_sleep;
buf : 
buf : 	ret = wlcore_acx_average_rssi(wl, wlvif, rssi_dbm);
if, rssi_dbm); 
buf : 	if (ret < 0)
buf : 		goto out_sleep;
buf : 
buf : out_sleep:
buf : 	wl1271_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static bool wl1271_tx_frames_pending(struct ieee80211_hw *hw)
buf : {
buf : 	struct wl1271 *wl = hw->priv;
buf : 	bool ret = false;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (unlikely(wl->state != WLCORE_STATE_ON))
if (unlikely(wl->state != WLCORE_STATE_ON)) 
buf : 		goto out;
buf : 
buf : 	/* packets are considered pending if in the TX queue or the FW */
if in the TX queue or the FW */ 
buf : 	ret = (wl1271_tx_total_queue_count(wl) > 0) || (wl->tx_frames_cnt > 0);
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : /* can't be const, mac80211 writes to this */
buf : static struct ieee80211_rate wl1271_rates[] = {
buf : 	{ .bitrate = 10,
buf : 	  .hw_value = CONF_HW_BIT_RATE_1MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_1MBPS, },
buf : 	{ .bitrate = 20,
buf : 	  .hw_value = CONF_HW_BIT_RATE_2MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_2MBPS,
buf : 	  .flags = IEEE80211_RATE_SHORT_PREAMBLE },
buf : 	{ .bitrate = 55,
buf : 	  .hw_value = CONF_HW_BIT_RATE_5_5MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_5_5MBPS,
buf : 	  .flags = IEEE80211_RATE_SHORT_PREAMBLE },
buf : 	{ .bitrate = 110,
buf : 	  .hw_value = CONF_HW_BIT_RATE_11MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_11MBPS,
buf : 	  .flags = IEEE80211_RATE_SHORT_PREAMBLE },
buf : 	{ .bitrate = 60,
buf : 	  .hw_value = CONF_HW_BIT_RATE_6MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_6MBPS, },
buf : 	{ .bitrate = 90,
buf : 	  .hw_value = CONF_HW_BIT_RATE_9MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_9MBPS, },
buf : 	{ .bitrate = 120,
buf : 	  .hw_value = CONF_HW_BIT_RATE_12MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_12MBPS, },
buf : 	{ .bitrate = 180,
buf : 	  .hw_value = CONF_HW_BIT_RATE_18MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_18MBPS, },
buf : 	{ .bitrate = 240,
buf : 	  .hw_value = CONF_HW_BIT_RATE_24MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_24MBPS, },
buf : 	{ .bitrate = 360,
buf : 	 .hw_value = CONF_HW_BIT_RATE_36MBPS,
buf : 	 .hw_value_short = CONF_HW_BIT_RATE_36MBPS, },
buf : 	{ .bitrate = 480,
buf : 	  .hw_value = CONF_HW_BIT_RATE_48MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_48MBPS, },
buf : 	{ .bitrate = 540,
buf : 	  .hw_value = CONF_HW_BIT_RATE_54MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_54MBPS, },
buf : };
buf : 
buf : /* can't be const, mac80211 writes to this */
buf : static struct ieee80211_channel wl1271_channels[] = {
buf : 	{ .hw_value = 1, .center_freq = 2412, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 2, .center_freq = 2417, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 3, .center_freq = 2422, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 4, .center_freq = 2427, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 5, .center_freq = 2432, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 6, .center_freq = 2437, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 7, .center_freq = 2442, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 8, .center_freq = 2447, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 9, .center_freq = 2452, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 10, .center_freq = 2457, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 11, .center_freq = 2462, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 12, .center_freq = 2467, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 13, .center_freq = 2472, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 14, .center_freq = 2484, .max_power = WLCORE_MAX_TXPWR },
buf : };
buf : 
buf : /* can't be const, mac80211 writes to this */
buf : static struct ieee80211_supported_band wl1271_band_2ghz = {
buf : 	.channels = wl1271_channels,
buf : 	.n_channels = ARRAY_SIZE(wl1271_channels),
buf : 	.bitrates = wl1271_rates,
buf : 	.n_bitrates = ARRAY_SIZE(wl1271_rates),
buf : };
buf : 
buf : /* 5 GHz data rates for WL1273 */
for WL1273 */ 
buf : static struct ieee80211_rate wl1271_rates_5ghz[] = {
buf : 	{ .bitrate = 60,
buf : 	  .hw_value = CONF_HW_BIT_RATE_6MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_6MBPS, },
buf : 	{ .bitrate = 90,
buf : 	  .hw_value = CONF_HW_BIT_RATE_9MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_9MBPS, },
buf : 	{ .bitrate = 120,
buf : 	  .hw_value = CONF_HW_BIT_RATE_12MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_12MBPS, },
buf : 	{ .bitrate = 180,
buf : 	  .hw_value = CONF_HW_BIT_RATE_18MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_18MBPS, },
buf : 	{ .bitrate = 240,
buf : 	  .hw_value = CONF_HW_BIT_RATE_24MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_24MBPS, },
buf : 	{ .bitrate = 360,
buf : 	 .hw_value = CONF_HW_BIT_RATE_36MBPS,
buf : 	 .hw_value_short = CONF_HW_BIT_RATE_36MBPS, },
buf : 	{ .bitrate = 480,
buf : 	  .hw_value = CONF_HW_BIT_RATE_48MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_48MBPS, },
buf : 	{ .bitrate = 540,
buf : 	  .hw_value = CONF_HW_BIT_RATE_54MBPS,
buf : 	  .hw_value_short = CONF_HW_BIT_RATE_54MBPS, },
buf : };
buf : 
buf : /* 5 GHz band channels for WL1273 */
for WL1273 */ 
buf : static struct ieee80211_channel wl1271_channels_5ghz[] = {
buf : 	{ .hw_value = 8, .center_freq = 5040, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 12, .center_freq = 5060, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 16, .center_freq = 5080, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 34, .center_freq = 5170, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 36, .center_freq = 5180, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 38, .center_freq = 5190, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 40, .center_freq = 5200, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 42, .center_freq = 5210, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 44, .center_freq = 5220, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 46, .center_freq = 5230, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 48, .center_freq = 5240, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 52, .center_freq = 5260, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 56, .center_freq = 5280, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 60, .center_freq = 5300, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 64, .center_freq = 5320, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 100, .center_freq = 5500, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 104, .center_freq = 5520, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 108, .center_freq = 5540, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 112, .center_freq = 5560, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 116, .center_freq = 5580, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 120, .center_freq = 5600, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 124, .center_freq = 5620, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 128, .center_freq = 5640, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 132, .center_freq = 5660, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 136, .center_freq = 5680, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 140, .center_freq = 5700, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 149, .center_freq = 5745, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 153, .center_freq = 5765, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 157, .center_freq = 5785, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 161, .center_freq = 5805, .max_power = WLCORE_MAX_TXPWR },
buf : 	{ .hw_value = 165, .center_freq = 5825, .max_power = WLCORE_MAX_TXPWR },
buf : };
buf : 
buf : static struct ieee80211_supported_band wl1271_band_5ghz = {
buf : 	.channels = wl1271_channels_5ghz,
buf : 	.n_channels = ARRAY_SIZE(wl1271_channels_5ghz),
buf : 	.bitrates = wl1271_rates_5ghz,
buf : 	.n_bitrates = ARRAY_SIZE(wl1271_rates_5ghz),
buf : };
buf : 
buf : static const struct ieee80211_ops wl1271_ops = {
buf : 	.start = wl1271_op_start,
buf : 	.stop = wlcore_op_stop,
buf : 	.add_interface = wl1271_op_add_interface,
buf : 	.remove_interface = wl1271_op_remove_interface,
buf : 	.change_interface = wl12xx_op_change_interface,
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 	.suspend = wl1271_op_suspend,
buf : 	.resume = wl1271_op_resume,
buf : #endif
if 
buf : 	.config = wl1271_op_config,
buf : 	.prepare_multicast = wl1271_op_prepare_multicast,
buf : 	.configure_filter = wl1271_op_configure_filter,
buf : 	.tx = wl1271_op_tx,
buf : 	.set_key = wlcore_op_set_key,
buf : 	.hw_scan = wl1271_op_hw_scan,
buf : 	.cancel_hw_scan = wl1271_op_cancel_hw_scan,
buf : 	.sched_scan_start = wl1271_op_sched_scan_start,
buf : 	.sched_scan_stop = wl1271_op_sched_scan_stop,
buf : 	.bss_info_changed = wl1271_op_bss_info_changed,
buf : 	.set_frag_threshold = wl1271_op_set_frag_threshold,
buf : 	.set_rts_threshold = wl1271_op_set_rts_threshold,
buf : 	.conf_tx = wl1271_op_conf_tx,
buf : 	.get_tsf = wl1271_op_get_tsf,
buf : 	.get_survey = wl1271_op_get_survey,
buf : 	.sta_state = wl12xx_op_sta_state,
buf : 	.ampdu_action = wl1271_op_ampdu_action,
buf : 	.tx_frames_pending = wl1271_tx_frames_pending,
buf : 	.set_bitrate_mask = wl12xx_set_bitrate_mask,
buf : 	.set_default_unicast_key = wl1271_op_set_default_key_idx,
buf : 	.channel_switch = wl12xx_op_channel_switch,
buf : 	.flush = wlcore_op_flush,
buf : 	.remain_on_channel = wlcore_op_remain_on_channel,
buf : 	.cancel_remain_on_channel = wlcore_op_cancel_remain_on_channel,
buf : 	.add_chanctx = wlcore_op_add_chanctx,
buf : 	.remove_chanctx = wlcore_op_remove_chanctx,
buf : 	.change_chanctx = wlcore_op_change_chanctx,
buf : 	.assign_vif_chanctx = wlcore_op_assign_vif_chanctx,
if_chanctx = wlcore_op_assign_vif_chanctx, 
buf : 	.unassign_vif_chanctx = wlcore_op_unassign_vif_chanctx,
buf : 	.sta_rc_update = wlcore_op_sta_rc_update,
buf : 	.get_rssi = wlcore_op_get_rssi,
buf : 	CFG80211_TESTMODE_CMD(wl1271_tm_cmd)
buf : };
buf : 
buf : 
buf : u8 wlcore_rate_to_idx(struct wl1271 *wl, u8 rate, enum ieee80211_band band)
buf : {
buf : 	u8 idx;
buf : 
buf : 	BUG_ON(band >= 2);
buf : 
buf : 	if (unlikely(rate >= wl->hw_tx_rate_tbl_size)) {
if (unlikely(rate >= wl->hw_tx_rate_tbl_size)) { 
buf : 		wl1271_error("Illegal RX rate from HW: %d", rate);
buf : 		return 0;
buf : 	}
buf : 
buf : 	idx = wl->band_rate_to_idx[band][rate];
buf : 	if (unlikely(idx == CONF_HW_RXTX_RATE_UNSUPPORTED)) {
if (unlikely(idx == CONF_HW_RXTX_RATE_UNSUPPORTED)) { 
buf : 		wl1271_error("Unsupported RX rate from HW: %d", rate);
buf : 		return 0;
buf : 	}
buf : 
buf : 	return idx;
buf : }
buf : 
buf : static void wl12xx_derive_mac_addresses(struct wl1271 *wl, u32 oui, u32 nic)
buf : {
buf : 	int i;
buf : 
buf : 	wl1271_debug(DEBUG_PROBE, "base address: oui %06x nic %06x",
buf : 		     oui, nic);
buf : 
buf : 	if (nic + WLCORE_NUM_MAC_ADDRESSES - wl->num_mac_addr > 0xffffff)
if (nic + WLCORE_NUM_MAC_ADDRESSES - wl->num_mac_addr > 0xffffff) 
buf : 		wl1271_warning("NIC part of the MAC address wraps around!");
buf : 
buf : 	for (i = 0; i < wl->num_mac_addr; i++) {
for (i = 0; i < wl->num_mac_addr; i++) { 
buf : 		wl->addresses[i].addr[0] = (u8)(oui >> 16);
buf : 		wl->addresses[i].addr[1] = (u8)(oui >> 8);
buf : 		wl->addresses[i].addr[2] = (u8) oui;
buf : 		wl->addresses[i].addr[3] = (u8)(nic >> 16);
buf : 		wl->addresses[i].addr[4] = (u8)(nic >> 8);
buf : 		wl->addresses[i].addr[5] = (u8) nic;
buf : 		nic++;
buf : 	}
buf : 
buf : 	/* we may be one address short at the most */
buf : 	WARN_ON(wl->num_mac_addr + 1 < WLCORE_NUM_MAC_ADDRESSES);
buf : 
buf : 	/*
buf : 	 * turn on the LAA bit in the first address and use it as
buf : 	 * the last address.
buf : 	 */
buf : 	if (wl->num_mac_addr < WLCORE_NUM_MAC_ADDRESSES) {
if (wl->num_mac_addr < WLCORE_NUM_MAC_ADDRESSES) { 
buf : 		int idx = WLCORE_NUM_MAC_ADDRESSES - 1;
buf : 		memcpy(&wl->addresses[idx], &wl->addresses[0],
buf : 		       sizeof(wl->addresses[0]));
buf : 		/* LAA bit */
buf : 		wl->addresses[idx].addr[2] |= BIT(1);
buf : 	}
buf : 
buf : 	wl->hw->wiphy->n_addresses = WLCORE_NUM_MAC_ADDRESSES;
buf : 	wl->hw->wiphy->addresses = wl->addresses;
buf : }
buf : 
buf : static int wl12xx_get_hw_info(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wl12xx_set_power_on(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	ret = wlcore_read_reg(wl, REG_CHIP_ID_B, &wl->chip.id);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl->fuse_oui_addr = 0;
buf : 	wl->fuse_nic_addr = 0;
buf : 
buf : 	ret = wl->ops->get_pg_ver(wl, &wl->hw_pg_ver);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	if (wl->ops->get_mac)
if (wl->ops->get_mac) 
buf : 		ret = wl->ops->get_mac(wl);
buf : 
buf : out:
buf : 	wl1271_power_off(wl);
buf : 	return ret;
buf : }
buf : 
buf : static int wl1271_register_hw(struct wl1271 *wl)
buf : {
buf : 	int ret;
buf : 	u32 oui_addr = 0, nic_addr = 0;
buf : 
buf : 	if (wl->mac80211_registered)
if (wl->mac80211_registered) 
buf : 		return 0;
buf : 
buf : 	if (wl->nvs_len >= 12) {
if (wl->nvs_len >= 12) { 
buf : 		/* NOTE: The wl->nvs->nvs element must be first, in
buf : 		 * order to simplify the casting, we assume it is at
ify the casting, we assume it is at 
buf : 		 * the beginning of the wl->nvs structure.
buf : 		 */
buf : 		u8 *nvs_ptr = (u8 *)wl->nvs;
buf : 
buf : 		oui_addr =
buf : 			(nvs_ptr[11] << 16) + (nvs_ptr[10] << 8) + nvs_ptr[6];
buf : 		nic_addr =
buf : 			(nvs_ptr[5] << 16) + (nvs_ptr[4] << 8) + nvs_ptr[3];
buf : 	}
buf : 
buf : 	/* if the MAC address is zeroed in the NVS derive from fuse */
if the MAC address is zeroed in the NVS derive from fuse */ 
buf : 	if (oui_addr == 0 && nic_addr == 0) {
buf : 		oui_addr = wl->fuse_oui_addr;
buf : 		/* fuse has the BD_ADDR, the WLAN addresses are the next two */
buf : 		nic_addr = wl->fuse_nic_addr + 1;
buf : 	}
buf : 
buf : 	wl12xx_derive_mac_addresses(wl, oui_addr, nic_addr);
buf : 
buf : 	ret = ieee80211_register_hw(wl->hw);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1271_error("unable to register mac80211 hw: %d", ret);
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl->mac80211_registered = true;
buf : 
buf : 	wl1271_debugfs_init(wl);
buf : 
buf : 	wl1271_notice("loaded");
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static void wl1271_unregister_hw(struct wl1271 *wl)
buf : {
buf : 	if (wl->plt)
if (wl->plt) 
buf : 		wl1271_plt_stop(wl);
buf : 
buf : 	ieee80211_unregister_hw(wl->hw);
buf : 	wl->mac80211_registered = false;
buf : 
buf : }
buf : 
buf : static int wl1271_init_ieee80211(struct wl1271 *wl)
buf : {
buf : 	int i;
buf : 	static const u32 cipher_suites[] = {
buf : 		WLAN_CIPHER_SUITE_WEP40,
buf : 		WLAN_CIPHER_SUITE_WEP104,
buf : 		WLAN_CIPHER_SUITE_TKIP,
buf : 		WLAN_CIPHER_SUITE_CCMP,
buf : 		WL1271_CIPHER_SUITE_GEM,
buf : 	};
buf : 
buf : 	/* The tx descriptor buffer */
buf : 	wl->hw->extra_tx_headroom = sizeof(struct wl1271_tx_hw_descr);
buf : 
buf : 	if (wl->quirks & WLCORE_QUIRK_TKIP_HEADER_SPACE)
if (wl->quirks & WLCORE_QUIRK_TKIP_HEADER_SPACE) 
buf : 		wl->hw->extra_tx_headroom += WL1271_EXTRA_SPACE_TKIP;
buf : 
buf : 	/* unit us */
buf : 	/* FIXME: find a proper value */
buf : 	wl->hw->max_listen_interval = wl->conf.conn.max_listen_interval;
buf : 
buf : 	wl->hw->flags = IEEE80211_HW_SIGNAL_DBM |
buf : 		IEEE80211_HW_SUPPORTS_PS |
buf : 		IEEE80211_HW_SUPPORTS_DYNAMIC_PS |
buf : 		IEEE80211_HW_SUPPORTS_UAPSD |
buf : 		IEEE80211_HW_HAS_RATE_CONTROL |
buf : 		IEEE80211_HW_CONNECTION_MONITOR |
buf : 		IEEE80211_HW_REPORTS_TX_ACK_STATUS |
buf : 		IEEE80211_HW_SPECTRUM_MGMT |
buf : 		IEEE80211_HW_AP_LINK_PS |
buf : 		IEEE80211_HW_AMPDU_AGGREGATION |
buf : 		IEEE80211_HW_TX_AMPDU_SETUP_IN_HW |
buf : 		IEEE80211_HW_QUEUE_CONTROL |
buf : 		IEEE80211_HW_CHANCTX_STA_CSA;
buf : 
buf : 	wl->hw->wiphy->cipher_suites = cipher_suites;
buf : 	wl->hw->wiphy->n_cipher_suites = ARRAY_SIZE(cipher_suites);
buf : 
buf : 	wl->hw->wiphy->interface_modes = BIT(NL80211_IFTYPE_STATION) |
buf : 		BIT(NL80211_IFTYPE_ADHOC) | BIT(NL80211_IFTYPE_AP) |
buf : 		BIT(NL80211_IFTYPE_P2P_CLIENT) | BIT(NL80211_IFTYPE_P2P_GO);
buf : 	wl->hw->wiphy->max_scan_ssids = 1;
buf : 	wl->hw->wiphy->max_sched_scan_ssids = 16;
buf : 	wl->hw->wiphy->max_match_sets = 16;
buf : 	/*
buf : 	 * Maximum length of elements in scanning probe request templates
buf : 	 * should be the maximum length possible for a template, without
for a template, without 
buf : 	 * the IEEE80211 header of the template
buf : 	 */
buf : 	wl->hw->wiphy->max_scan_ie_len = WL1271_CMD_TEMPL_MAX_SIZE -
buf : 			sizeof(struct ieee80211_header);
buf : 
buf : 	wl->hw->wiphy->max_sched_scan_ie_len = WL1271_CMD_TEMPL_MAX_SIZE -
buf : 		sizeof(struct ieee80211_header);
buf : 
buf : 	wl->hw->wiphy->max_remain_on_channel_duration = 5000;
buf : 
buf : 	wl->hw->wiphy->flags |= WIPHY_FLAG_AP_UAPSD |
buf : 				WIPHY_FLAG_HAS_REMAIN_ON_CHANNEL |
buf : 				WIPHY_FLAG_SUPPORTS_SCHED_SCAN;
buf : 
buf : 	/* make sure all our channels fit in the scanned_ch bitmask */
buf : 	BUILD_BUG_ON(ARRAY_SIZE(wl1271_channels) +
buf : 		     ARRAY_SIZE(wl1271_channels_5ghz) >
buf : 		     WL1271_MAX_CHANNELS);
buf : 	/*
buf : 	* clear channel flags from the previous usage
buf : 	* and restore max_power & max_antenna_gain values.
buf : 	*/
buf : 	for (i = 0; i < ARRAY_SIZE(wl1271_channels); i++) {
for (i = 0; i < ARRAY_SIZE(wl1271_channels); i++) { 
buf : 		wl1271_band_2ghz.channels[i].flags = 0;
buf : 		wl1271_band_2ghz.channels[i].max_power = WLCORE_MAX_TXPWR;
buf : 		wl1271_band_2ghz.channels[i].max_antenna_gain = 0;
buf : 	}
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(wl1271_channels_5ghz); i++) {
for (i = 0; i < ARRAY_SIZE(wl1271_channels_5ghz); i++) { 
buf : 		wl1271_band_5ghz.channels[i].flags = 0;
buf : 		wl1271_band_5ghz.channels[i].max_power = WLCORE_MAX_TXPWR;
buf : 		wl1271_band_5ghz.channels[i].max_antenna_gain = 0;
buf : 	}
buf : 
buf : 	/*
buf : 	 * We keep local copies of the band structs because we need to
buf : 	 * modify them on a per-device basis.
ify them on a per-device basis. 
buf : 	 */
buf : 	memcpy(&wl->bands[IEEE80211_BAND_2GHZ], &wl1271_band_2ghz,
buf : 	       sizeof(wl1271_band_2ghz));
buf : 	memcpy(&wl->bands[IEEE80211_BAND_2GHZ].ht_cap,
buf : 	       &wl->ht_cap[IEEE80211_BAND_2GHZ],
buf : 	       sizeof(*wl->ht_cap));
buf : 	memcpy(&wl->bands[IEEE80211_BAND_5GHZ], &wl1271_band_5ghz,
buf : 	       sizeof(wl1271_band_5ghz));
buf : 	memcpy(&wl->bands[IEEE80211_BAND_5GHZ].ht_cap,
buf : 	       &wl->ht_cap[IEEE80211_BAND_5GHZ],
buf : 	       sizeof(*wl->ht_cap));
buf : 
buf : 	wl->hw->wiphy->bands[IEEE80211_BAND_2GHZ] =
buf : 		&wl->bands[IEEE80211_BAND_2GHZ];
buf : 	wl->hw->wiphy->bands[IEEE80211_BAND_5GHZ] =
buf : 		&wl->bands[IEEE80211_BAND_5GHZ];
buf : 
buf : 	/*
buf : 	 * allow 4 queues per mac address we support +
buf : 	 * 1 cab queue per mac + one global offchannel Tx queue
buf : 	 */
buf : 	wl->hw->queues = (NUM_TX_QUEUES + 1) * WLCORE_NUM_MAC_ADDRESSES + 1;
buf : 
buf : 	/* the last queue is the offchannel queue */
buf : 	wl->hw->offchannel_tx_hw_queue = wl->hw->queues - 1;
buf : 	wl->hw->max_rates = 1;
buf : 
buf : 	wl->hw->wiphy->reg_notifier = wl1271_reg_notify;
ifier = wl1271_reg_notify; 
buf : 
buf : 	/* the FW answers probe-requests in AP-mode */
buf : 	wl->hw->wiphy->flags |= WIPHY_FLAG_AP_PROBE_RESP_OFFLOAD;
buf : 	wl->hw->wiphy->probe_resp_offload =
buf : 		NL80211_PROBE_RESP_OFFLOAD_SUPPORT_WPS |
buf : 		NL80211_PROBE_RESP_OFFLOAD_SUPPORT_WPS2 |
buf : 		NL80211_PROBE_RESP_OFFLOAD_SUPPORT_P2P;
buf : 
buf : 	/* allowed interface combinations */
buf : 	wl->hw->wiphy->iface_combinations = wl->iface_combinations;
iface_combinations = wl->iface_combinations; 
buf : 	wl->hw->wiphy->n_iface_combinations = wl->n_iface_combinations;
buf : 
buf : 	SET_IEEE80211_DEV(wl->hw, wl->dev);
buf : 
buf : 	wl->hw->sta_data_size = sizeof(struct wl1271_station);
buf : 	wl->hw->vif_data_size = sizeof(struct wl12xx_vif);
if_data_size = sizeof(struct wl12xx_vif); 
buf : 
buf : 	wl->hw->max_rx_aggregation_subframes = wl->conf.ht.rx_ba_win_size;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : struct ieee80211_hw *wlcore_alloc_hw(size_t priv_size, u32 aggr_buf_size,
buf : 				     u32 mbox_size)
buf : {
buf : 	struct ieee80211_hw *hw;
buf : 	struct wl1271 *wl;
buf : 	int i, j, ret;
buf : 	unsigned int order;
buf : 
buf : 	hw = ieee80211_alloc_hw(sizeof(*wl), &wl1271_ops);
buf : 	if (!hw) {
if (!hw) { 
buf : 		wl1271_error("could not alloc ieee80211_hw");
buf : 		ret = -ENOMEM;
buf : 		goto err_hw_alloc;
buf : 	}
buf : 
buf : 	wl = hw->priv;
buf : 	memset(wl, 0, sizeof(*wl));
buf : 
buf : 	wl->priv = kzalloc(priv_size, GFP_KERNEL);
buf : 	if (!wl->priv) {
if (!wl->priv) { 
buf : 		wl1271_error("could not alloc wl priv");
buf : 		ret = -ENOMEM;
buf : 		goto err_priv_alloc;
buf : 	}
buf : 
buf : 	INIT_LIST_HEAD(&wl->wlvif_list);
if_list); 
buf : 
buf : 	wl->hw = hw;
buf : 
buf : 	/*
buf : 	 * wl->num_links is not configured yet, so just use WLCORE_MAX_LINKS.
buf : 	 * we don't allocate any additional resource here, so that's fine.
buf : 	 */
buf : 	for (i = 0; i < NUM_TX_QUEUES; i++)
for (i = 0; i < NUM_TX_QUEUES; i++) 
buf : 		for (j = 0; j < WLCORE_MAX_LINKS; j++)
buf : 			skb_queue_head_init(&wl->links[j].tx_queue[i]);
buf : 
buf : 	skb_queue_head_init(&wl->deferred_rx_queue);
buf : 	skb_queue_head_init(&wl->deferred_tx_queue);
buf : 
buf : 	INIT_DELAYED_WORK(&wl->elp_work, wl1271_elp_work);
buf : 	INIT_WORK(&wl->netstack_work, wl1271_netstack_work);
buf : 	INIT_WORK(&wl->tx_work, wl1271_tx_work);
buf : 	INIT_WORK(&wl->recovery_work, wl1271_recovery_work);
buf : 	INIT_DELAYED_WORK(&wl->scan_complete_work, wl1271_scan_complete_work);
buf : 	INIT_DELAYED_WORK(&wl->roc_complete_work, wlcore_roc_complete_work);
buf : 	INIT_DELAYED_WORK(&wl->tx_watchdog_work, wl12xx_tx_watchdog_work);
buf : 
buf : 	wl->freezable_wq = create_freezable_workqueue("wl12xx_wq");
buf : 	if (!wl->freezable_wq) {
if (!wl->freezable_wq) { 
buf : 		ret = -ENOMEM;
buf : 		goto err_hw;
buf : 	}
buf : 
buf : 	wl->channel = 0;
buf : 	wl->rx_counter = 0;
buf : 	wl->power_level = WL1271_DEFAULT_POWER_LEVEL;
buf : 	wl->band = IEEE80211_BAND_2GHZ;
buf : 	wl->channel_type = NL80211_CHAN_NO_HT;
buf : 	wl->flags = 0;
buf : 	wl->sg_enabled = true;
buf : 	wl->sleep_auth = WL1271_PSM_ILLEGAL;
buf : 	wl->recovery_count = 0;
buf : 	wl->hw_pg_ver = -1;
buf : 	wl->ap_ps_map = 0;
buf : 	wl->ap_fw_ps_map = 0;
buf : 	wl->quirks = 0;
buf : 	wl->platform_quirks = 0;
form_quirks = 0; 
buf : 	wl->system_hlid = WL12XX_SYSTEM_HLID;
buf : 	wl->active_sta_count = 0;
buf : 	wl->active_link_count = 0;
buf : 	wl->fwlog_size = 0;
buf : 	init_waitqueue_head(&wl->fwlog_waitq);
buf : 
buf : 	/* The system link is always allocated */
buf : 	__set_bit(WL12XX_SYSTEM_HLID, wl->links_map);
buf : 
buf : 	memset(wl->tx_frames_map, 0, sizeof(wl->tx_frames_map));
buf : 	for (i = 0; i < wl->num_tx_desc; i++)
for (i = 0; i < wl->num_tx_desc; i++) 
buf : 		wl->tx_frames[i] = NULL;
buf : 
buf : 	spin_lock_init(&wl->wl_lock);
buf : 
buf : 	wl->state = WLCORE_STATE_OFF;
buf : 	wl->fw_type = WL12XX_FW_TYPE_NONE;
buf : 	mutex_init(&wl->mutex);
buf : 	mutex_init(&wl->flush_mutex);
buf : 	init_completion(&wl->nvs_loading_complete);
buf : 
buf : 	order = get_order(aggr_buf_size);
buf : 	wl->aggr_buf = (u8 *)__get_free_pages(GFP_KERNEL, order);
buf : 	if (!wl->aggr_buf) {
if (!wl->aggr_buf) { 
buf : 		ret = -ENOMEM;
buf : 		goto err_wq;
buf : 	}
buf : 	wl->aggr_buf_size = aggr_buf_size;
buf : 
buf : 	wl->dummy_packet = wl12xx_alloc_dummy_packet(wl);
buf : 	if (!wl->dummy_packet) {
if (!wl->dummy_packet) { 
buf : 		ret = -ENOMEM;
buf : 		goto err_aggr;
buf : 	}
buf : 
buf : 	/* Allocate one page for the FW log */
for the FW log */ 
buf : 	wl->fwlog = (u8 *)get_zeroed_page(GFP_KERNEL);
buf : 	if (!wl->fwlog) {
if (!wl->fwlog) { 
buf : 		ret = -ENOMEM;
buf : 		goto err_dummy_packet;
buf : 	}
buf : 
buf : 	wl->mbox_size = mbox_size;
buf : 	wl->mbox = kmalloc(wl->mbox_size, GFP_KERNEL | GFP_DMA);
buf : 	if (!wl->mbox) {
if (!wl->mbox) { 
buf : 		ret = -ENOMEM;
buf : 		goto err_fwlog;
buf : 	}
buf : 
buf : 	wl->buffer_32 = kmalloc(sizeof(*wl->buffer_32), GFP_KERNEL);
buf : 	if (!wl->buffer_32) {
if (!wl->buffer_32) { 
buf : 		ret = -ENOMEM;
buf : 		goto err_mbox;
buf : 	}
buf : 
buf : 	return hw;
buf : 
buf : err_mbox:
buf : 	kfree(wl->mbox);
buf : 
buf : err_fwlog:
buf : 	free_page((unsigned long)wl->fwlog);
buf : 
buf : err_dummy_packet:
buf : 	dev_kfree_skb(wl->dummy_packet);
buf : 
buf : err_aggr:
buf : 	free_pages((unsigned long)wl->aggr_buf, order);
buf : 
buf : err_wq:
buf : 	destroy_workqueue(wl->freezable_wq);
buf : 
buf : err_hw:
buf : 	wl1271_debugfs_exit(wl);
buf : 	kfree(wl->priv);
buf : 
buf : err_priv_alloc:
buf : 	ieee80211_free_hw(hw);
buf : 
buf : err_hw_alloc:
buf : 
buf : 	return ERR_PTR(ret);
buf : }
buf : EXPORT_SYMBOL_GPL(wlcore_alloc_hw);
buf : 
buf : int wlcore_free_hw(struct wl1271 *wl)
buf : {
buf : 	/* Unblock any fwlog readers */
buf : 	mutex_lock(&wl->mutex);
buf : 	wl->fwlog_size = -1;
buf : 	wake_up_interruptible_all(&wl->fwlog_waitq);
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	wlcore_sysfs_free(wl);
buf : 
buf : 	kfree(wl->buffer_32);
buf : 	kfree(wl->mbox);
buf : 	free_page((unsigned long)wl->fwlog);
buf : 	dev_kfree_skb(wl->dummy_packet);
buf : 	free_pages((unsigned long)wl->aggr_buf, get_order(wl->aggr_buf_size));
buf : 
buf : 	wl1271_debugfs_exit(wl);
buf : 
buf : 	vfree(wl->fw);
buf : 	wl->fw = NULL;
buf : 	wl->fw_type = WL12XX_FW_TYPE_NONE;
buf : 	kfree(wl->nvs);
buf : 	wl->nvs = NULL;
buf : 
buf : 	kfree(wl->raw_fw_status);
buf : 	kfree(wl->fw_status);
buf : 	kfree(wl->tx_res_if);
if); 
buf : 	destroy_workqueue(wl->freezable_wq);
buf : 
buf : 	kfree(wl->priv);
buf : 	ieee80211_free_hw(wl->hw);
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL_GPL(wlcore_free_hw);
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : static const struct wiphy_wowlan_support wlcore_wowlan_support = {
buf : 	.flags = WIPHY_WOWLAN_ANY,
buf : 	.n_patterns = WL1271_MAX_RX_FILTERS,
buf : 	.pattern_min_len = 1,
buf : 	.pattern_max_len = WL1271_RX_FILTER_MAX_PATTERN_SIZE,
buf : };
buf : #endif
if 
buf : 
buf : static irqreturn_t wlcore_hardirq(int irq, void *cookie)
buf : {
buf : 	return IRQ_WAKE_THREAD;
buf : }
buf : 
buf : static void wlcore_nvs_cb(const struct firmware *fw, void *context)
buf : {
buf : 	struct wl1271 *wl = context;
buf : 	struct platform_device *pdev = wl->pdev;
form_device *pdev = wl->pdev; 
buf : 	struct wlcore_platdev_data *pdev_data = dev_get_platdata(&pdev->dev);
buf : 	struct wl12xx_platform_data *pdata = pdev_data->pdata;
form_data *pdata = pdev_data->pdata; 
buf : 	unsigned long irqflags;
buf : 	int ret;
buf : 	irq_handler_t hardirq_fn = NULL;
buf : 
buf : 	if (fw) {
if (fw) { 
buf : 		wl->nvs = kmemdup(fw->data, fw->size, GFP_KERNEL);
buf : 		if (!wl->nvs) {
if (!wl->nvs) { 
buf : 			wl1271_error("Could not allocate nvs data");
buf : 			goto out;
buf : 		}
buf : 		wl->nvs_len = fw->size;
buf : 	} else {
buf : 		wl1271_debug(DEBUG_BOOT, "Could not get nvs file %s",
buf : 			     WL12XX_NVS_NAME);
buf : 		wl->nvs = NULL;
buf : 		wl->nvs_len = 0;
buf : 	}
buf : 
buf : 	ret = wl->ops->setup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_free_nvs;
buf : 
buf : 	BUG_ON(wl->num_tx_desc > WLCORE_MAX_TX_DESCRIPTORS);
buf : 
buf : 	/* adjust some runtime configuration parameters */
buf : 	wlcore_adjust_conf(wl);
buf : 
buf : 	wl->irq = platform_get_irq(pdev, 0);
form_get_irq(pdev, 0); 
buf : 	wl->platform_quirks = pdata->platform_quirks;
buf : 	wl->if_ops = pdev_data->if_ops;
if_ops = pdev_data->if_ops; 
buf : 
buf : 	if (wl->platform_quirks & WL12XX_PLATFORM_QUIRK_EDGE_IRQ) {
form_quirks & WL12XX_PLATFORM_QUIRK_EDGE_IRQ) { 
buf : 		irqflags = IRQF_TRIGGER_RISING;
buf : 		hardirq_fn = wlcore_hardirq;
buf : 	} else {
buf : 		irqflags = IRQF_TRIGGER_HIGH | IRQF_ONESHOT;
buf : 	}
buf : 
buf : 	ret = request_threaded_irq(wl->irq, hardirq_fn, wlcore_irq,
buf : 				   irqflags, pdev->name, wl);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1271_error("request_irq() failed: %d", ret);
buf : 		goto out_free_nvs;
buf : 	}
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 	ret = enable_irq_wake(wl->irq);
buf : 	if (!ret) {
if (!ret) { 
buf : 		wl->irq_wake_enabled = true;
buf : 		device_init_wakeup(wl->dev, 1);
buf : 		if (pdata->pwr_in_suspend)
if (pdata->pwr_in_suspend) 
buf : 			wl->hw->wiphy->wowlan = &wlcore_wowlan_support;
buf : 	}
buf : #endif
if 
buf : 	disable_irq(wl->irq);
buf : 
buf : 	ret = wl12xx_get_hw_info(wl);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1271_error("couldn't get hw info");
buf : 		goto out_irq;
buf : 	}
buf : 
buf : 	ret = wl->ops->identify_chip(wl);
ify_chip(wl); 
buf : 	if (ret < 0)
buf : 		goto out_irq;
buf : 
buf : 	ret = wl1271_init_ieee80211(wl);
buf : 	if (ret)
if (ret) 
buf : 		goto out_irq;
buf : 
buf : 	ret = wl1271_register_hw(wl);
buf : 	if (ret)
if (ret) 
buf : 		goto out_irq;
buf : 
buf : 	ret = wlcore_sysfs_init(wl);
buf : 	if (ret)
if (ret) 
buf : 		goto out_unreg;
buf : 
buf : 	wl->initialized = true;
buf : 	goto out;
buf : 
buf : out_unreg:
buf : 	wl1271_unregister_hw(wl);
buf : 
buf : out_irq:
buf : 	free_irq(wl->irq, wl);
buf : 
buf : out_free_nvs:
buf : 	kfree(wl->nvs);
buf : 
buf : out:
buf : 	release_firmware(fw);
buf : 	complete_all(&wl->nvs_loading_complete);
buf : }
buf : 
buf : int wlcore_probe(struct wl1271 *wl, struct platform_device *pdev)
form_device *pdev) 
buf : {
buf : 	int ret;
buf : 
buf : 	if (!wl->ops || !wl->ptable)
if (!wl->ops || !wl->ptable) 
buf : 		return -EINVAL;
buf : 
buf : 	wl->dev = &pdev->dev;
buf : 	wl->pdev = pdev;
buf : 	platform_set_drvdata(pdev, wl);
form_set_drvdata(pdev, wl); 
buf : 
buf : 	ret = request_firmware_nowait(THIS_MODULE, FW_ACTION_HOTPLUG,
buf : 				      WL12XX_NVS_NAME, &pdev->dev, GFP_KERNEL,
buf : 				      wl, wlcore_nvs_cb);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1271_error("request_firmware_nowait failed: %d", ret);
buf : 		complete_all(&wl->nvs_loading_complete);
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : EXPORT_SYMBOL_GPL(wlcore_probe);
buf : 
buf : int wlcore_remove(struct platform_device *pdev)
form_device *pdev) 
buf : {
buf : 	struct wl1271 *wl = platform_get_drvdata(pdev);
buf : 
buf : 	wait_for_completion(&wl->nvs_loading_complete);
for_completion(&wl->nvs_loading_complete); 
buf : 	if (!wl->initialized)
buf : 		return 0;
buf : 
buf : 	if (wl->irq_wake_enabled) {
if (wl->irq_wake_enabled) { 
buf : 		device_init_wakeup(wl->dev, 0);
buf : 		disable_irq_wake(wl->irq);
buf : 	}
buf : 	wl1271_unregister_hw(wl);
buf : 	free_irq(wl->irq, wl);
buf : 	wlcore_free_hw(wl);
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL_GPL(wlcore_remove);
buf : 
buf : u32 wl12xx_debug_level = DEBUG_NONE;
buf : EXPORT_SYMBOL_GPL(wl12xx_debug_level);
buf : module_param_named(debug_level, wl12xx_debug_level, uint, S_IRUSR | S_IWUSR);
buf : MODULE_PARM_DESC(debug_level, "wl12xx debugging level");
buf : 
buf : module_param_named(fwlog, fwlog_param, charp, 0);
buf : MODULE_PARM_DESC(fwlog,
buf : 		 "FW logger options: continuous, ondemand, dbgpins or disable");
buf : 
buf : module_param(fwlog_mem_blocks, int, S_IRUSR | S_IWUSR);
buf : MODULE_PARM_DESC(fwlog_mem_blocks, "fwlog mem_blocks");
buf : 
buf : module_param(bug_on_recovery, int, S_IRUSR | S_IWUSR);
buf : MODULE_PARM_DESC(bug_on_recovery, "BUG() on fw recovery");
buf : 
buf : module_param(no_recovery, int, S_IRUSR | S_IWUSR);
buf : MODULE_PARM_DESC(no_recovery, "Prevent HW recovery. FW will remain stuck.");
buf : 
buf : MODULE_LICENSE("GPL");
buf : MODULE_AUTHOR("Luciano Coelho <coelho@ti.com>");
buf : MODULE_AUTHOR("Juuso Oikarinen <juuso.oikarinen@nokia.com>");
buf : MODULE_FIRMWARE(WL12XX_NVS_NAME);
file : ./test/kernel/drivers/net/wireless/ti/wl1251/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * This file is part of wl1251
buf :  *
buf :  * Copyright (C) 2008-2009 Nokia Corporation
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of the GNU General Public License
ify it under the terms of the GNU General Public License 
buf :  * version 2 as published by the Free Software Foundation.
buf :  *
buf :  * This program is distributed in the hope that it will be useful, but
buf :  * WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
buf :  * General Public License for more details.
for more details. 
buf :  *
buf :  * You should have received a copy of the GNU General Public License
buf :  * along with this program; if not, write to the Free Software
if not, write to the Free Software 
buf :  * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
buf :  * 02110-1301 USA
buf :  *
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/interrupt.h>
buf : #include <linux/firmware.h>
buf : #include <linux/delay.h>
buf : #include <linux/irq.h>
buf : #include <linux/crc32.h>
buf : #include <linux/etherdevice.h>
buf : #include <linux/vmalloc.h>
buf : #include <linux/slab.h>
buf : #include <linux/netdevice.h>
buf : 
buf : #include "wl1251.h"
buf : #include "wl12xx_80211.h"
buf : #include "reg.h"
buf : #include "io.h"
buf : #include "cmd.h"
buf : #include "event.h"
buf : #include "tx.h"
buf : #include "rx.h"
buf : #include "ps.h"
buf : #include "init.h"
buf : #include "debugfs.h"
buf : #include "boot.h"
buf : 
buf : void wl1251_enable_interrupts(struct wl1251 *wl)
buf : {
buf : 	wl->if_ops->enable_irq(wl);
if_ops->enable_irq(wl); 
buf : }
buf : 
buf : void wl1251_disable_interrupts(struct wl1251 *wl)
buf : {
buf : 	wl->if_ops->disable_irq(wl);
if_ops->disable_irq(wl); 
buf : }
buf : 
buf : static int wl1251_power_off(struct wl1251 *wl)
buf : {
buf : 	return wl->if_ops->power(wl, false);
if_ops->power(wl, false); 
buf : }
buf : 
buf : static int wl1251_power_on(struct wl1251 *wl)
buf : {
buf : 	return wl->if_ops->power(wl, true);
if_ops->power(wl, true); 
buf : }
buf : 
buf : static int wl1251_fetch_firmware(struct wl1251 *wl)
buf : {
buf : 	const struct firmware *fw;
buf : 	struct device *dev = wiphy_dev(wl->hw->wiphy);
buf : 	int ret;
buf : 
buf : 	ret = request_firmware(&fw, WL1251_FW_NAME, dev);
buf : 
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1251_error("could not get firmware: %d", ret);
buf : 		return ret;
buf : 	}
buf : 
buf : 	if (fw->size % 4) {
if (fw->size % 4) { 
buf : 		wl1251_error("firmware size is not multiple of 32 bits: %zu",
buf : 			     fw->size);
buf : 		ret = -EILSEQ;
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl->fw_len = fw->size;
buf : 	wl->fw = vmalloc(wl->fw_len);
buf : 
buf : 	if (!wl->fw) {
if (!wl->fw) { 
buf : 		wl1251_error("could not allocate memory for the firmware");
for the firmware"); 
buf : 		ret = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 
buf : 	memcpy(wl->fw, fw->data, wl->fw_len);
buf : 
buf : 	ret = 0;
buf : 
buf : out:
buf : 	release_firmware(fw);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl1251_fetch_nvs(struct wl1251 *wl)
buf : {
buf : 	const struct firmware *fw;
buf : 	struct device *dev = wiphy_dev(wl->hw->wiphy);
buf : 	int ret;
buf : 
buf : 	ret = request_firmware(&fw, WL1251_NVS_NAME, dev);
buf : 
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1251_error("could not get nvs file: %d", ret);
buf : 		return ret;
buf : 	}
buf : 
buf : 	if (fw->size % 4) {
if (fw->size % 4) { 
buf : 		wl1251_error("nvs size is not multiple of 32 bits: %zu",
buf : 			     fw->size);
buf : 		ret = -EILSEQ;
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl->nvs_len = fw->size;
buf : 	wl->nvs = kmemdup(fw->data, wl->nvs_len, GFP_KERNEL);
buf : 
buf : 	if (!wl->nvs) {
if (!wl->nvs) { 
buf : 		wl1251_error("could not allocate memory for the nvs file");
for the nvs file"); 
buf : 		ret = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = 0;
buf : 
buf : out:
buf : 	release_firmware(fw);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void wl1251_fw_wakeup(struct wl1251 *wl)
buf : {
buf : 	u32 elp_reg;
buf : 
buf : 	elp_reg = ELPCTRL_WAKE_UP;
buf : 	wl1251_write_elp(wl, HW_ACCESS_ELP_CTRL_REG_ADDR, elp_reg);
buf : 	elp_reg = wl1251_read_elp(wl, HW_ACCESS_ELP_CTRL_REG_ADDR);
buf : 
buf : 	if (!(elp_reg & ELPCTRL_WLAN_READY))
if (!(elp_reg & ELPCTRL_WLAN_READY)) 
buf : 		wl1251_warning("WLAN not ready");
buf : }
buf : 
buf : static int wl1251_chip_wakeup(struct wl1251 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wl1251_power_on(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		return ret;
buf : 
buf : 	msleep(WL1251_POWER_ON_SLEEP);
buf : 	wl->if_ops->reset(wl);
if_ops->reset(wl); 
buf : 
buf : 	/* We don't need a real memory partition here, because we only want
buf : 	 * to use the registers at this point. */
buf : 	wl1251_set_partition(wl,
buf : 			     0x00000000,
buf : 			     0x00000000,
buf : 			     REGISTERS_BASE,
buf : 			     REGISTERS_DOWN_SIZE);
buf : 
buf : 	/* ELP module wake up */
buf : 	wl1251_fw_wakeup(wl);
buf : 
buf : 	/* whal_FwCtrl_BootSm() */
buf : 
buf : 	/* 0. read chip id from CHIP_ID */
buf : 	wl->chip_id = wl1251_reg_read32(wl, CHIP_ID_B);
buf : 
buf : 	/* 1. check if chip id is valid */
if chip id is valid */ 
buf : 
buf : 	switch (wl->chip_id) {
buf : 	case CHIP_ID_1251_PG12:
buf : 		wl1251_debug(DEBUG_BOOT, "chip id 0x%x (1251 PG12)",
buf : 			     wl->chip_id);
buf : 		break;
buf : 	case CHIP_ID_1251_PG11:
buf : 		wl1251_debug(DEBUG_BOOT, "chip id 0x%x (1251 PG11)",
buf : 			     wl->chip_id);
buf : 		break;
buf : 	case CHIP_ID_1251_PG10:
buf : 	default:
buf : 		wl1251_error("unsupported chip id: 0x%x", wl->chip_id);
buf : 		ret = -ENODEV;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (wl->fw == NULL) {
if (wl->fw == NULL) { 
buf : 		ret = wl1251_fetch_firmware(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : 	if (wl->nvs == NULL && !wl->use_eeprom) {
if (wl->nvs == NULL && !wl->use_eeprom) { 
buf : 		/* No NVS from netlink, try to get it from the filesystem */
buf : 		ret = wl1251_fetch_nvs(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : #define WL1251_IRQ_LOOP_COUNT 10
buf : static void wl1251_irq_work(struct work_struct *work)
buf : {
buf : 	u32 intr, ctr = WL1251_IRQ_LOOP_COUNT;
buf : 	struct wl1251 *wl =
buf : 		container_of(work, struct wl1251, irq_work);
buf : 	int ret;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	wl1251_debug(DEBUG_IRQ, "IRQ work");
buf : 
buf : 	if (wl->state == WL1251_STATE_OFF)
if (wl->state == WL1251_STATE_OFF) 
buf : 		goto out;
buf : 
buf : 	ret = wl1251_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl1251_reg_write32(wl, ACX_REG_INTERRUPT_MASK, WL1251_ACX_INTR_ALL);
buf : 
buf : 	intr = wl1251_reg_read32(wl, ACX_REG_INTERRUPT_CLEAR);
buf : 	wl1251_debug(DEBUG_IRQ, "intr: 0x%x", intr);
buf : 
buf : 	do {
buf : 		if (wl->data_path) {
if (wl->data_path) { 
buf : 			wl->rx_counter = wl1251_mem_read32(
buf : 				wl, wl->data_path->rx_control_addr);
buf : 
buf : 			/* We handle a frmware bug here */
buf : 			switch ((wl->rx_counter - wl->rx_handled) & 0xf) {
buf : 			case 0:
buf : 				wl1251_debug(DEBUG_IRQ,
buf : 					     "RX: FW and host in sync");
buf : 				intr &= ~WL1251_ACX_INTR_RX0_DATA;
buf : 				intr &= ~WL1251_ACX_INTR_RX1_DATA;
buf : 				break;
buf : 			case 1:
buf : 				wl1251_debug(DEBUG_IRQ, "RX: FW +1");
buf : 				intr |= WL1251_ACX_INTR_RX0_DATA;
buf : 				intr &= ~WL1251_ACX_INTR_RX1_DATA;
buf : 				break;
buf : 			case 2:
buf : 				wl1251_debug(DEBUG_IRQ, "RX: FW +2");
buf : 				intr |= WL1251_ACX_INTR_RX0_DATA;
buf : 				intr |= WL1251_ACX_INTR_RX1_DATA;
buf : 				break;
buf : 			default:
buf : 				wl1251_warning(
buf : 					"RX: FW and host out of sync: %d",
buf : 					wl->rx_counter - wl->rx_handled);
buf : 				break;
buf : 			}
buf : 
buf : 			wl->rx_handled = wl->rx_counter;
buf : 
buf : 			wl1251_debug(DEBUG_IRQ, "RX counter: %d",
buf : 				     wl->rx_counter);
buf : 		}
buf : 
buf : 		intr &= wl->intr_mask;
buf : 
buf : 		if (intr == 0) {
if (intr == 0) { 
buf : 			wl1251_debug(DEBUG_IRQ, "INTR is 0");
buf : 			goto out_sleep;
buf : 		}
buf : 
buf : 		if (intr & WL1251_ACX_INTR_RX0_DATA) {
if (intr & WL1251_ACX_INTR_RX0_DATA) { 
buf : 			wl1251_debug(DEBUG_IRQ, "WL1251_ACX_INTR_RX0_DATA");
buf : 			wl1251_rx(wl);
buf : 		}
buf : 
buf : 		if (intr & WL1251_ACX_INTR_RX1_DATA) {
if (intr & WL1251_ACX_INTR_RX1_DATA) { 
buf : 			wl1251_debug(DEBUG_IRQ, "WL1251_ACX_INTR_RX1_DATA");
buf : 			wl1251_rx(wl);
buf : 		}
buf : 
buf : 		if (intr & WL1251_ACX_INTR_TX_RESULT) {
if (intr & WL1251_ACX_INTR_TX_RESULT) { 
buf : 			wl1251_debug(DEBUG_IRQ, "WL1251_ACX_INTR_TX_RESULT");
buf : 			wl1251_tx_complete(wl);
buf : 		}
buf : 
buf : 		if (intr & WL1251_ACX_INTR_EVENT_A) {
if (intr & WL1251_ACX_INTR_EVENT_A) { 
buf : 			wl1251_debug(DEBUG_IRQ, "WL1251_ACX_INTR_EVENT_A");
buf : 			wl1251_event_handle(wl, 0);
buf : 		}
buf : 
buf : 		if (intr & WL1251_ACX_INTR_EVENT_B) {
if (intr & WL1251_ACX_INTR_EVENT_B) { 
buf : 			wl1251_debug(DEBUG_IRQ, "WL1251_ACX_INTR_EVENT_B");
buf : 			wl1251_event_handle(wl, 1);
buf : 		}
buf : 
buf : 		if (intr & WL1251_ACX_INTR_INIT_COMPLETE)
if (intr & WL1251_ACX_INTR_INIT_COMPLETE) 
buf : 			wl1251_debug(DEBUG_IRQ,
buf : 				     "WL1251_ACX_INTR_INIT_COMPLETE");
buf : 
buf : 		if (--ctr == 0)
if (--ctr == 0) 
buf : 			break;
buf : 
buf : 		intr = wl1251_reg_read32(wl, ACX_REG_INTERRUPT_CLEAR);
buf : 	} while (intr);
while (intr); 
buf : 
buf : out_sleep:
buf : 	wl1251_reg_write32(wl, ACX_REG_INTERRUPT_MASK, ~(wl->intr_mask));
buf : 	wl1251_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int wl1251_join(struct wl1251 *wl, u8 bss_type, u8 channel,
buf : 		       u16 beacon_interval, u8 dtim_period)
buf : {
buf : 	int ret;
buf : 
buf : 	ret = wl1251_acx_frame_rates(wl, DEFAULT_HW_GEN_TX_RATE,
buf : 				     DEFAULT_HW_GEN_MODULATION_TYPE,
buf : 				     wl->tx_mgmt_frm_rate,
buf : 				     wl->tx_mgmt_frm_mod);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/*
buf : 	 * Join command applies filters, and if we are not associated,
if we are not associated, 
buf : 	 * BSSID filter must be disabled for association to work.
for association to work. 
buf : 	 */
buf : 	if (is_zero_ether_addr(wl->bssid))
if (is_zero_ether_addr(wl->bssid)) 
buf : 		wl->rx_config &= ~CFG_BSSID_FILTER_EN;
buf : 
buf : 	ret = wl1251_cmd_join(wl, bss_type, channel, beacon_interval,
buf : 			      dtim_period);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1251_event_wait(wl, JOIN_EVENT_COMPLETE_ID, 100);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		wl1251_warning("join timeout");
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : static void wl1251_op_tx(struct ieee80211_hw *hw,
buf : 			 struct ieee80211_tx_control *control,
buf : 			 struct sk_buff *skb)
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 	unsigned long flags;
buf : 
buf : 	skb_queue_tail(&wl->tx_queue, skb);
buf : 
buf : 	/*
buf : 	 * The chip specific setup must run before the first TX packet -
ific setup must run before the first TX packet - 
buf : 	 * before that, the tx_work will not be initialized!
fore that, the tx_work will not be initialized! 
buf : 	 */
buf : 
buf : 	ieee80211_queue_work(wl->hw, &wl->tx_work);
buf : 
buf : 	/*
buf : 	 * The workqueue is slow to process the tx_queue and we need stop
buf : 	 * the queue here, otherwise the queue will get too long.
buf : 	 */
buf : 	if (skb_queue_len(&wl->tx_queue) >= WL1251_TX_QUEUE_HIGH_WATERMARK) {
if (skb_queue_len(&wl->tx_queue) >= WL1251_TX_QUEUE_HIGH_WATERMARK) { 
buf : 		wl1251_debug(DEBUG_TX, "op_tx: tx_queue full, stop queues");
buf : 
buf : 		spin_lock_irqsave(&wl->wl_lock, flags);
buf : 		ieee80211_stop_queues(wl->hw);
buf : 		wl->tx_queue_stopped = true;
buf : 		spin_unlock_irqrestore(&wl->wl_lock, flags);
buf : 	}
buf : }
buf : 
buf : static int wl1251_op_start(struct ieee80211_hw *hw)
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 	struct wiphy *wiphy = hw->wiphy;
buf : 	int ret = 0;
buf : 
buf : 	wl1251_debug(DEBUG_MAC80211, "mac80211 start");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (wl->state != WL1251_STATE_OFF) {
if (wl->state != WL1251_STATE_OFF) { 
buf : 		wl1251_error("cannot start because not in off state: %d",
buf : 			     wl->state);
buf : 		ret = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1251_chip_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1251_boot(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1251_hw_init(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1251_acx_station_id(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	wl->state = WL1251_STATE_ON;
buf : 
buf : 	wl1251_info("firmware booted (%s)", wl->fw_ver);
buf : 
buf : 	/* update hw/fw version info in wiphy struct */
buf : 	wiphy->hw_version = wl->chip_id;
buf : 	strncpy(wiphy->fw_version, wl->fw_ver, sizeof(wiphy->fw_version));
buf : 
buf : out:
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		wl1251_power_off(wl);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void wl1251_op_stop(struct ieee80211_hw *hw)
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 
buf : 	wl1251_info("down");
buf : 
buf : 	wl1251_debug(DEBUG_MAC80211, "mac80211 stop");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	WARN_ON(wl->state != WL1251_STATE_ON);
buf : 
buf : 	if (wl->scanning) {
if (wl->scanning) { 
buf : 		ieee80211_scan_completed(wl->hw, true);
buf : 		wl->scanning = false;
buf : 	}
buf : 
buf : 	wl->state = WL1251_STATE_OFF;
buf : 
buf : 	wl1251_disable_interrupts(wl);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	cancel_work_sync(&wl->irq_work);
buf : 	cancel_work_sync(&wl->tx_work);
buf : 	cancel_delayed_work_sync(&wl->elp_work);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	/* let's notify MAC80211 about the remaining pending TX frames */
ify MAC80211 about the remaining pending TX frames */ 
buf : 	wl1251_tx_flush(wl);
buf : 	wl1251_power_off(wl);
buf : 
buf : 	memset(wl->bssid, 0, ETH_ALEN);
buf : 	wl->listen_int = 1;
buf : 	wl->bss_type = MAX_BSS_TYPE;
buf : 
buf : 	wl->data_in_count = 0;
buf : 	wl->rx_counter = 0;
buf : 	wl->rx_handled = 0;
buf : 	wl->rx_current_buffer = 0;
buf : 	wl->rx_last_id = 0;
buf : 	wl->next_tx_complete = 0;
buf : 	wl->elp = false;
buf : 	wl->station_mode = STATION_ACTIVE_MODE;
buf : 	wl->psm_entry_retry = 0;
buf : 	wl->tx_queue_stopped = false;
buf : 	wl->power_level = WL1251_DEFAULT_POWER_LEVEL;
buf : 	wl->rssi_thold = 0;
buf : 	wl->channel = WL1251_DEFAULT_CHANNEL;
buf : 	wl->monitor_present = false;
buf : 	wl->joined = false;
buf : 
buf : 	wl1251_debugfs_reset(wl);
buf : 
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int wl1251_op_add_interface(struct ieee80211_hw *hw,
buf : 				   struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 	int ret = 0;
buf : 
buf : 	vif->driver_flags |= IEEE80211_VIF_BEACON_FILTER |
if->driver_flags |= IEEE80211_VIF_BEACON_FILTER | 
buf : 			     IEEE80211_VIF_SUPPORTS_CQM_RSSI;
buf : 
buf : 	wl1251_debug(DEBUG_MAC80211, "mac80211 add interface type %d mac %pM",
buf : 		     vif->type, vif->addr);
if->type, vif->addr); 
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	if (wl->vif) {
if (wl->vif) { 
buf : 		ret = -EBUSY;
buf : 		goto out;
buf : 	}
buf : 
buf : 	wl->vif = vif;
if = vif; 
buf : 
buf : 	switch (vif->type) {
buf : 	case NL80211_IFTYPE_STATION:
buf : 		wl->bss_type = BSS_TYPE_STA_BSS;
buf : 		break;
buf : 	case NL80211_IFTYPE_ADHOC:
buf : 		wl->bss_type = BSS_TYPE_IBSS;
buf : 		break;
buf : 	default:
buf : 		ret = -EOPNOTSUPP;
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (!ether_addr_equal_unaligned(wl->mac_addr, vif->addr)) {
if (!ether_addr_equal_unaligned(wl->mac_addr, vif->addr)) { 
buf : 		memcpy(wl->mac_addr, vif->addr, ETH_ALEN);
buf : 		SET_IEEE80211_PERM_ADDR(wl->hw, wl->mac_addr);
buf : 		ret = wl1251_acx_station_id(wl);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 	}
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 	return ret;
buf : }
buf : 
buf : static void wl1251_op_remove_interface(struct ieee80211_hw *hw,
buf : 					 struct ieee80211_vif *vif)
if *vif) 
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 	wl1251_debug(DEBUG_MAC80211, "mac80211 remove interface");
buf : 	wl->vif = NULL;
if = NULL; 
buf : 	memset(wl->bssid, 0, ETH_ALEN);
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : static int wl1251_build_null_data(struct wl1251 *wl)
buf : {
buf : 	struct sk_buff *skb = NULL;
buf : 	int size;
buf : 	void *ptr;
buf : 	int ret = -ENOMEM;
buf : 
buf : 	if (wl->bss_type == BSS_TYPE_IBSS) {
if (wl->bss_type == BSS_TYPE_IBSS) { 
buf : 		size = sizeof(struct wl12xx_null_data_template);
buf : 		ptr = NULL;
buf : 	} else {
buf : 		skb = ieee80211_nullfunc_get(wl->hw, wl->vif);
if); 
buf : 		if (!skb)
buf : 			goto out;
buf : 		size = skb->len;
buf : 		ptr = skb->data;
buf : 	}
buf : 
buf : 	ret = wl1251_cmd_template_set(wl, CMD_NULL_DATA, ptr, size);
buf : 
buf : out:
buf : 	dev_kfree_skb(skb);
buf : 	if (ret)
if (ret) 
buf : 		wl1251_warning("cmd buld null data failed: %d", ret);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl1251_build_qos_null_data(struct wl1251 *wl)
buf : {
buf : 	struct ieee80211_qos_hdr template;
buf : 
buf : 	memset(&template, 0, sizeof(template));
buf : 
buf : 	memcpy(template.addr1, wl->bssid, ETH_ALEN);
buf : 	memcpy(template.addr2, wl->mac_addr, ETH_ALEN);
buf : 	memcpy(template.addr3, wl->bssid, ETH_ALEN);
buf : 
buf : 	template.frame_control = cpu_to_le16(IEEE80211_FTYPE_DATA |
buf : 					     IEEE80211_STYPE_QOS_NULLFUNC |
buf : 					     IEEE80211_FCTL_TODS);
buf : 
buf : 	/* FIXME: not sure what priority to use here */
buf : 	template.qos_ctrl = cpu_to_le16(0);
buf : 
buf : 	return wl1251_cmd_template_set(wl, CMD_QOS_NULL_DATA, &template,
buf : 				       sizeof(template));
buf : }
buf : 
buf : static bool wl1251_can_do_pm(struct ieee80211_conf *conf, struct wl1251 *wl)
buf : {
buf : 	return (conf->flags & IEEE80211_CONF_PS) && !wl->monitor_present;
buf : }
buf : 
buf : static int wl1251_op_config(struct ieee80211_hw *hw, u32 changed)
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf : 	int channel, ret = 0;
buf : 
buf : 	channel = ieee80211_frequency_to_channel(
buf : 			conf->chandef.chan->center_freq);
buf : 
buf : 	wl1251_debug(DEBUG_MAC80211,
buf : 		     "mac80211 config ch %d monitor %s psm %s power %d",
buf : 		     channel,
buf : 		     conf->flags & IEEE80211_CONF_MONITOR ? "on" : "off",
buf : 		     conf->flags & IEEE80211_CONF_PS ? "on" : "off",
buf : 		     conf->power_level);
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	ret = wl1251_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_MONITOR) {
if (changed & IEEE80211_CONF_CHANGE_MONITOR) { 
buf : 		u32 mode;
buf : 
buf : 		if (conf->flags & IEEE80211_CONF_MONITOR) {
if (conf->flags & IEEE80211_CONF_MONITOR) { 
buf : 			wl->monitor_present = true;
buf : 			mode = DF_SNIFF_MODE_ENABLE | DF_ENCRYPTION_DISABLE;
buf : 		} else {
buf : 			wl->monitor_present = false;
buf : 			mode = 0;
buf : 		}
buf : 
buf : 		ret = wl1251_acx_feature_cfg(wl, mode);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 	}
buf : 
buf : 	if (channel != wl->channel) {
if (channel != wl->channel) { 
buf : 		wl->channel = channel;
buf : 
buf : 		/*
buf : 		 * Use ENABLE_RX command for channel switching when no
for channel switching when no 
buf : 		 * interface is present (monitor mode only).
buf : 		 * This leaves the tx path disabled in firmware, whereas
buf : 		 * the usual JOIN command seems to transmit some frames
buf : 		 * at firmware level.
buf : 		 */
buf : 		if (wl->vif == NULL) {
if (wl->vif == NULL) { 
buf : 			wl->joined = false;
buf : 			ret = wl1251_cmd_data_path_rx(wl, wl->channel, 1);
buf : 		} else {
buf : 			ret = wl1251_join(wl, wl->bss_type, wl->channel,
buf : 					  wl->beacon_int, wl->dtim_period);
buf : 		}
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 	}
buf : 
buf : 	if (wl1251_can_do_pm(conf, wl) && !wl->psm_requested) {
if (wl1251_can_do_pm(conf, wl) && !wl->psm_requested) { 
buf : 		wl1251_debug(DEBUG_PSM, "psm enabled");
buf : 
buf : 		wl->psm_requested = true;
buf : 
buf : 		wl->dtim_period = conf->ps_dtim_period;
buf : 
buf : 		ret = wl1251_acx_wr_tbtt_and_dtim(wl, wl->beacon_int,
buf : 						  wl->dtim_period);
buf : 
buf : 		/*
buf : 		 * mac80211 enables PSM only if we're already associated.
if we're already associated. 
buf : 		 */
buf : 		ret = wl1251_ps_set_mode(wl, STATION_POWER_SAVE_MODE);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 	} else if (!wl1251_can_do_pm(conf, wl) && wl->psm_requested) {
if (!wl1251_can_do_pm(conf, wl) && wl->psm_requested) { 
buf : 		wl1251_debug(DEBUG_PSM, "psm disabled");
buf : 
buf : 		wl->psm_requested = false;
buf : 
buf : 		if (wl->station_mode != STATION_ACTIVE_MODE) {
if (wl->station_mode != STATION_ACTIVE_MODE) { 
buf : 			ret = wl1251_ps_set_mode(wl, STATION_ACTIVE_MODE);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & IEEE80211_CONF_CHANGE_IDLE && !wl->scanning) {
if (changed & IEEE80211_CONF_CHANGE_IDLE && !wl->scanning) { 
buf : 		if (conf->flags & IEEE80211_CONF_IDLE) {
buf : 			ret = wl1251_ps_set_mode(wl, STATION_IDLE);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 		} else {
buf : 			ret = wl1251_ps_set_mode(wl, STATION_ACTIVE_MODE);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 			ret = wl1251_join(wl, wl->bss_type, wl->channel,
buf : 					  wl->beacon_int, wl->dtim_period);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 		}
buf : 	}
buf : 
buf : 	if (conf->power_level != wl->power_level) {
if (conf->power_level != wl->power_level) { 
buf : 		ret = wl1251_acx_tx_power(wl, conf->power_level);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 
buf : 		wl->power_level = conf->power_level;
buf : 	}
buf : 
buf : out_sleep:
buf : 	wl1251_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : struct wl1251_filter_params {
buf : 	bool enabled;
buf : 	int mc_list_length;
buf : 	u8 mc_list[ACX_MC_ADDRESS_GROUP_MAX][ETH_ALEN];
buf : };
buf : 
buf : static u64 wl1251_op_prepare_multicast(struct ieee80211_hw *hw,
buf : 				       struct netdev_hw_addr_list *mc_list)
buf : {
buf : 	struct wl1251_filter_params *fp;
buf : 	struct netdev_hw_addr *ha;
buf : 	struct wl1251 *wl = hw->priv;
buf : 
buf : 	if (unlikely(wl->state == WL1251_STATE_OFF))
if (unlikely(wl->state == WL1251_STATE_OFF)) 
buf : 		return 0;
buf : 
buf : 	fp = kzalloc(sizeof(*fp), GFP_ATOMIC);
buf : 	if (!fp) {
if (!fp) { 
buf : 		wl1251_error("Out of memory setting filters.");
buf : 		return 0;
buf : 	}
buf : 
buf : 	/* update multicast filtering parameters */
buf : 	fp->mc_list_length = 0;
buf : 	if (netdev_hw_addr_list_count(mc_list) > ACX_MC_ADDRESS_GROUP_MAX) {
if (netdev_hw_addr_list_count(mc_list) > ACX_MC_ADDRESS_GROUP_MAX) { 
buf : 		fp->enabled = false;
buf : 	} else {
buf : 		fp->enabled = true;
buf : 		netdev_hw_addr_list_for_each(ha, mc_list) {
for_each(ha, mc_list) { 
buf : 			memcpy(fp->mc_list[fp->mc_list_length],
buf : 					ha->addr, ETH_ALEN);
buf : 			fp->mc_list_length++;
buf : 		}
buf : 	}
buf : 
buf : 	return (u64)(unsigned long)fp;
buf : }
buf : 
buf : #define WL1251_SUPPORTED_FILTERS (FIF_PROMISC_IN_BSS | \
buf : 				  FIF_ALLMULTI | \
buf : 				  FIF_FCSFAIL | \
buf : 				  FIF_BCN_PRBRESP_PROMISC | \
buf : 				  FIF_CONTROL | \
buf : 				  FIF_OTHER_BSS | \
buf : 				  FIF_PROBE_REQ)
buf : 
buf : static void wl1251_op_configure_filter(struct ieee80211_hw *hw,
buf : 				       unsigned int changed,
buf : 				       unsigned int *total, u64 multicast)
buf : {
buf : 	struct wl1251_filter_params *fp = (void *)(unsigned long)multicast;
buf : 	struct wl1251 *wl = hw->priv;
buf : 	int ret;
buf : 
buf : 	wl1251_debug(DEBUG_MAC80211, "mac80211 configure filter");
buf : 
buf : 	*total &= WL1251_SUPPORTED_FILTERS;
buf : 	changed &= WL1251_SUPPORTED_FILTERS;
buf : 
buf : 	if (changed == 0) {
if (changed == 0) { 
buf : 		/* no filters which we support changed */
buf : 		kfree(fp);
buf : 		return;
buf : 	}
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	wl->rx_config = WL1251_DEFAULT_RX_CONFIG;
buf : 	wl->rx_filter = WL1251_DEFAULT_RX_FILTER;
buf : 
buf : 	if (*total & FIF_PROMISC_IN_BSS) {
if (*total & FIF_PROMISC_IN_BSS) { 
buf : 		wl->rx_config |= CFG_BSSID_FILTER_EN;
buf : 		wl->rx_config |= CFG_RX_ALL_GOOD;
buf : 	}
buf : 	if (*total & FIF_ALLMULTI)
if (*total & FIF_ALLMULTI) 
buf : 		/*
buf : 		 * CFG_MC_FILTER_EN in rx_config needs to be 0 to receive
buf : 		 * all multicast frames
buf : 		 */
buf : 		wl->rx_config &= ~CFG_MC_FILTER_EN;
buf : 	if (*total & FIF_FCSFAIL)
if (*total & FIF_FCSFAIL) 
buf : 		wl->rx_filter |= CFG_RX_FCS_ERROR;
buf : 	if (*total & FIF_BCN_PRBRESP_PROMISC) {
if (*total & FIF_BCN_PRBRESP_PROMISC) { 
buf : 		wl->rx_config &= ~CFG_BSSID_FILTER_EN;
buf : 		wl->rx_config &= ~CFG_SSID_FILTER_EN;
buf : 	}
buf : 	if (*total & FIF_CONTROL)
if (*total & FIF_CONTROL) 
buf : 		wl->rx_filter |= CFG_RX_CTL_EN;
buf : 	if (*total & FIF_OTHER_BSS || is_zero_ether_addr(wl->bssid))
if (*total & FIF_OTHER_BSS || is_zero_ether_addr(wl->bssid)) 
buf : 		wl->rx_config &= ~CFG_BSSID_FILTER_EN;
buf : 	if (*total & FIF_PROBE_REQ)
if (*total & FIF_PROBE_REQ) 
buf : 		wl->rx_filter |= CFG_RX_PREQ_EN;
buf : 
buf : 	if (wl->state == WL1251_STATE_OFF)
if (wl->state == WL1251_STATE_OFF) 
buf : 		goto out;
buf : 
buf : 	ret = wl1251_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	if (*total & FIF_ALLMULTI || *total & FIF_PROMISC_IN_BSS)
if (*total & FIF_ALLMULTI || *total & FIF_PROMISC_IN_BSS) 
buf : 		ret = wl1251_acx_group_address_tbl(wl, false, NULL, 0);
buf : 	else if (fp)
if (fp) 
buf : 		ret = wl1251_acx_group_address_tbl(wl, fp->enabled,
buf : 						   fp->mc_list,
buf : 						   fp->mc_list_length);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* send filters to firmware */
buf : 	wl1251_acx_rx_config(wl, wl->rx_config, wl->rx_filter);
buf : 
buf : 	wl1251_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 	kfree(fp);
buf : }
buf : 
buf : /* HW encryption */
buf : static int wl1251_set_key_type(struct wl1251 *wl,
buf : 			       struct wl1251_cmd_set_keys *key,
buf : 			       enum set_key_cmd cmd,
buf : 			       struct ieee80211_key_conf *mac80211_key,
buf : 			       const u8 *addr)
buf : {
buf : 	switch (mac80211_key->cipher) {
buf : 	case WLAN_CIPHER_SUITE_WEP40:
buf : 	case WLAN_CIPHER_SUITE_WEP104:
buf : 		if (is_broadcast_ether_addr(addr))
if (is_broadcast_ether_addr(addr)) 
buf : 			key->key_type = KEY_WEP_DEFAULT;
buf : 		else
buf : 			key->key_type = KEY_WEP_ADDR;
buf : 
buf : 		mac80211_key->hw_key_idx = mac80211_key->keyidx;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_TKIP:
buf : 		if (is_broadcast_ether_addr(addr))
if (is_broadcast_ether_addr(addr)) 
buf : 			key->key_type = KEY_TKIP_MIC_GROUP;
buf : 		else
buf : 			key->key_type = KEY_TKIP_MIC_PAIRWISE;
buf : 
buf : 		mac80211_key->hw_key_idx = mac80211_key->keyidx;
buf : 		break;
buf : 	case WLAN_CIPHER_SUITE_CCMP:
buf : 		if (is_broadcast_ether_addr(addr))
if (is_broadcast_ether_addr(addr)) 
buf : 			key->key_type = KEY_AES_GROUP;
buf : 		else
buf : 			key->key_type = KEY_AES_PAIRWISE;
buf : 		mac80211_key->flags |= IEEE80211_KEY_FLAG_GENERATE_IV;
buf : 		break;
buf : 	default:
buf : 		wl1251_error("Unknown key cipher 0x%x", mac80211_key->cipher);
buf : 		return -EOPNOTSUPP;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl1251_op_set_key(struct ieee80211_hw *hw, enum set_key_cmd cmd,
buf : 			     struct ieee80211_vif *vif,
if *vif, 
buf : 			     struct ieee80211_sta *sta,
buf : 			     struct ieee80211_key_conf *key)
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 	struct wl1251_cmd_set_keys *wl_cmd;
buf : 	const u8 *addr;
buf : 	int ret;
buf : 
buf : 	static const u8 bcast_addr[ETH_ALEN] =
buf : 		{ 0xff, 0xff, 0xff, 0xff, 0xff, 0xff };
buf : 
buf : 	wl1251_debug(DEBUG_MAC80211, "mac80211 set key");
buf : 
buf : 	wl_cmd = kzalloc(sizeof(*wl_cmd), GFP_KERNEL);
buf : 	if (!wl_cmd) {
if (!wl_cmd) { 
buf : 		ret = -ENOMEM;
buf : 		goto out;
buf : 	}
buf : 
buf : 	addr = sta ? sta->addr : bcast_addr;
buf : 
buf : 	wl1251_debug(DEBUG_CRYPT, "CMD: 0x%x", cmd);
buf : 	wl1251_dump(DEBUG_CRYPT, "ADDR: ", addr, ETH_ALEN);
buf : 	wl1251_debug(DEBUG_CRYPT, "Key: algo:0x%x, id:%d, len:%d flags 0x%x",
buf : 		     key->cipher, key->keyidx, key->keylen, key->flags);
buf : 	wl1251_dump(DEBUG_CRYPT, "KEY: ", key->key, key->keylen);
buf : 
buf : 	if (is_zero_ether_addr(addr)) {
if (is_zero_ether_addr(addr)) { 
buf : 		/* We dont support TX only encryption */
buf : 		ret = -EOPNOTSUPP;
buf : 		goto out;
buf : 	}
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	switch (cmd) {
buf : 	case SET_KEY:
buf : 		if (wl->monitor_present) {
if (wl->monitor_present) { 
buf : 			ret = -EOPNOTSUPP;
buf : 			goto out_unlock;
buf : 		}
buf : 		wl_cmd->key_action = KEY_ADD_OR_REPLACE;
buf : 		break;
buf : 	case DISABLE_KEY:
buf : 		wl_cmd->key_action = KEY_REMOVE;
buf : 		break;
buf : 	default:
buf : 		wl1251_error("Unsupported key cmd 0x%x", cmd);
buf : 		break;
buf : 	}
buf : 
buf : 	ret = wl1251_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_unlock;
buf : 
buf : 	ret = wl1251_set_key_type(wl, wl_cmd, cmd, key, addr);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1251_error("Set KEY type failed");
buf : 		goto out_sleep;
buf : 	}
buf : 
buf : 	if (wl_cmd->key_type != KEY_WEP_DEFAULT)
if (wl_cmd->key_type != KEY_WEP_DEFAULT) 
buf : 		memcpy(wl_cmd->addr, addr, ETH_ALEN);
buf : 
buf : 	if ((wl_cmd->key_type == KEY_TKIP_MIC_GROUP) ||
if ((wl_cmd->key_type == KEY_TKIP_MIC_GROUP) || 
buf : 	    (wl_cmd->key_type == KEY_TKIP_MIC_PAIRWISE)) {
buf : 		/*
buf : 		 * We get the key in the following form:
form: 
buf : 		 * TKIP (16 bytes) - TX MIC (8 bytes) - RX MIC (8 bytes)
buf : 		 * but the target is expecting:
buf : 		 * TKIP - RX MIC - TX MIC
buf : 		 */
buf : 		memcpy(wl_cmd->key, key->key, 16);
buf : 		memcpy(wl_cmd->key + 16, key->key + 24, 8);
buf : 		memcpy(wl_cmd->key + 24, key->key + 16, 8);
buf : 
buf : 	} else {
buf : 		memcpy(wl_cmd->key, key->key, key->keylen);
buf : 	}
buf : 	wl_cmd->key_size = key->keylen;
buf : 
buf : 	wl_cmd->id = key->keyidx;
buf : 	wl_cmd->ssid_profile = 0;
buf : 
buf : 	wl1251_dump(DEBUG_CRYPT, "TARGET KEY: ", wl_cmd, sizeof(*wl_cmd));
buf : 
buf : 	ret = wl1251_cmd_send(wl, CMD_SET_KEYS, wl_cmd, sizeof(*wl_cmd));
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1251_warning("could not set keys");
buf : 		goto out_sleep;
buf : 	}
buf : 
buf : out_sleep:
buf : 	wl1251_ps_elp_sleep(wl);
buf : 
buf : out_unlock:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : out:
buf : 	kfree(wl_cmd);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl1251_op_hw_scan(struct ieee80211_hw *hw,
buf : 			     struct ieee80211_vif *vif,
if *vif, 
buf : 			     struct cfg80211_scan_request *req)
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 	struct sk_buff *skb;
buf : 	size_t ssid_len = 0;
buf : 	u8 *ssid = NULL;
buf : 	int ret;
buf : 
buf : 	wl1251_debug(DEBUG_MAC80211, "mac80211 hw scan");
buf : 
buf : 	if (req->n_ssids) {
if (req->n_ssids) { 
buf : 		ssid = req->ssids[0].ssid;
buf : 		ssid_len = req->ssids[0].ssid_len;
buf : 	}
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	if (wl->scanning) {
if (wl->scanning) { 
buf : 		wl1251_debug(DEBUG_SCAN, "scan already in progress");
buf : 		ret = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	ret = wl1251_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	if (hw->conf.flags & IEEE80211_CONF_IDLE) {
if (hw->conf.flags & IEEE80211_CONF_IDLE) { 
buf : 		ret = wl1251_ps_set_mode(wl, STATION_ACTIVE_MODE);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 		ret = wl1251_join(wl, wl->bss_type, wl->channel,
buf : 				  wl->beacon_int, wl->dtim_period);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 	}
buf : 
buf : 	skb = ieee80211_probereq_get(wl->hw, wl->vif, ssid, ssid_len,
if, ssid, ssid_len, 
buf : 				     req->ie_len);
buf : 	if (!skb) {
if (!skb) { 
buf : 		ret = -ENOMEM;
buf : 		goto out_idle;
buf : 	}
buf : 	if (req->ie_len)
if (req->ie_len) 
buf : 		memcpy(skb_put(skb, req->ie_len), req->ie, req->ie_len);
buf : 
buf : 	ret = wl1251_cmd_template_set(wl, CMD_PROBE_REQ, skb->data,
buf : 				      skb->len);
buf : 	dev_kfree_skb(skb);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_idle;
buf : 
buf : 	ret = wl1251_cmd_trigger_scan_to(wl, 0);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_idle;
buf : 
buf : 	wl->scanning = true;
buf : 
buf : 	ret = wl1251_cmd_scan(wl, ssid, ssid_len, req->channels,
buf : 			      req->n_channels, WL1251_SCAN_NUM_PROBES);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1251_debug(DEBUG_SCAN, "scan failed %d", ret);
buf : 		wl->scanning = false;
buf : 		goto out_idle;
buf : 	}
buf : 	goto out_sleep;
buf : 
buf : out_idle:
buf : 	if (hw->conf.flags & IEEE80211_CONF_IDLE)
if (hw->conf.flags & IEEE80211_CONF_IDLE) 
buf : 		ret = wl1251_ps_set_mode(wl, STATION_IDLE);
buf : out_sleep:
buf : 	wl1251_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl1251_op_set_rts_threshold(struct ieee80211_hw *hw, u32 value)
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 	int ret;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	ret = wl1251_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	ret = wl1251_acx_rts_threshold(wl, (u16) value);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		wl1251_warning("wl1251_op_set_rts_threshold failed: %d", ret);
buf : 
buf : 	wl1251_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void wl1251_op_bss_info_changed(struct ieee80211_hw *hw,
buf : 				       struct ieee80211_vif *vif,
if *vif, 
buf : 				       struct ieee80211_bss_conf *bss_conf,
buf : 				       u32 changed)
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 	struct sk_buff *beacon, *skb;
buf : 	bool enable;
buf : 	int ret;
buf : 
buf : 	wl1251_debug(DEBUG_MAC80211, "mac80211 bss info changed");
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	ret = wl1251_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	if (changed & BSS_CHANGED_CQM) {
if (changed & BSS_CHANGED_CQM) { 
buf : 		ret = wl1251_acx_low_rssi(wl, bss_conf->cqm_rssi_thold,
buf : 					  WL1251_DEFAULT_LOW_RSSI_WEIGHT,
buf : 					  WL1251_DEFAULT_LOW_RSSI_DEPTH,
buf : 					  WL1251_ACX_LOW_RSSI_TYPE_EDGE);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out;
buf : 		wl->rssi_thold = bss_conf->cqm_rssi_thold;
buf : 	}
buf : 
buf : 	if ((changed & BSS_CHANGED_BSSID) &&
if ((changed & BSS_CHANGED_BSSID) && 
buf : 	    memcmp(wl->bssid, bss_conf->bssid, ETH_ALEN)) {
buf : 		memcpy(wl->bssid, bss_conf->bssid, ETH_ALEN);
buf : 
buf : 		if (!is_zero_ether_addr(wl->bssid)) {
if (!is_zero_ether_addr(wl->bssid)) { 
buf : 			ret = wl1251_build_null_data(wl);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 
buf : 			ret = wl1251_build_qos_null_data(wl);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 
buf : 			ret = wl1251_join(wl, wl->bss_type, wl->channel,
buf : 					  wl->beacon_int, wl->dtim_period);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ASSOC) {
if (changed & BSS_CHANGED_ASSOC) { 
buf : 		if (bss_conf->assoc) {
buf : 			wl->beacon_int = bss_conf->beacon_int;
buf : 
buf : 			skb = ieee80211_pspoll_get(wl->hw, wl->vif);
if); 
buf : 			if (!skb)
buf : 				goto out_sleep;
buf : 
buf : 			ret = wl1251_cmd_template_set(wl, CMD_PS_POLL,
buf : 						      skb->data,
buf : 						      skb->len);
buf : 			dev_kfree_skb(skb);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 
buf : 			ret = wl1251_acx_aid(wl, bss_conf->aid);
buf : 			if (ret < 0)
if (ret < 0) 
buf : 				goto out_sleep;
buf : 		} else {
buf : 			/* use defaults when not associated */
buf : 			wl->beacon_int = WL1251_DEFAULT_BEACON_INT;
buf : 			wl->dtim_period = WL1251_DEFAULT_DTIM_PERIOD;
buf : 		}
buf : 	}
buf : 	if (changed & BSS_CHANGED_ERP_SLOT) {
if (changed & BSS_CHANGED_ERP_SLOT) { 
buf : 		if (bss_conf->use_short_slot)
buf : 			ret = wl1251_acx_slot(wl, SLOT_TIME_SHORT);
buf : 		else
buf : 			ret = wl1251_acx_slot(wl, SLOT_TIME_LONG);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			wl1251_warning("Set slot time failed %d", ret);
buf : 			goto out_sleep;
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ERP_PREAMBLE) {
if (changed & BSS_CHANGED_ERP_PREAMBLE) { 
buf : 		if (bss_conf->use_short_preamble)
buf : 			wl1251_acx_set_preamble(wl, ACX_PREAMBLE_SHORT);
buf : 		else
buf : 			wl1251_acx_set_preamble(wl, ACX_PREAMBLE_LONG);
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ERP_CTS_PROT) {
if (changed & BSS_CHANGED_ERP_CTS_PROT) { 
buf : 		if (bss_conf->use_cts_prot)
buf : 			ret = wl1251_acx_cts_protect(wl, CTSPROTECT_ENABLE);
buf : 		else
buf : 			ret = wl1251_acx_cts_protect(wl, CTSPROTECT_DISABLE);
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			wl1251_warning("Set ctsprotect failed %d", ret);
buf : 			goto out_sleep;
buf : 		}
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_ARP_FILTER) {
if (changed & BSS_CHANGED_ARP_FILTER) { 
buf : 		__be32 addr = bss_conf->arp_addr_list[0];
buf : 		WARN_ON(wl->bss_type != BSS_TYPE_STA_BSS);
buf : 
buf : 		enable = bss_conf->arp_addr_cnt == 1 && bss_conf->assoc;
buf : 		wl1251_acx_arp_ip_filter(wl, enable, addr);
buf : 
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 	}
buf : 
buf : 	if (changed & BSS_CHANGED_BEACON) {
if (changed & BSS_CHANGED_BEACON) { 
buf : 		beacon = ieee80211_beacon_get(hw, vif);
buf : 		if (!beacon)
if (!beacon) 
buf : 			goto out_sleep;
buf : 
buf : 		ret = wl1251_cmd_template_set(wl, CMD_BEACON, beacon->data,
buf : 					      beacon->len);
buf : 
buf : 		if (ret < 0) {
if (ret < 0) { 
buf : 			dev_kfree_skb(beacon);
buf : 			goto out_sleep;
buf : 		}
buf : 
buf : 		ret = wl1251_cmd_template_set(wl, CMD_PROBE_RESP, beacon->data,
buf : 					      beacon->len);
buf : 
buf : 		dev_kfree_skb(beacon);
buf : 
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 
buf : 		ret = wl1251_join(wl, wl->bss_type, wl->channel,
buf : 				  wl->beacon_int, wl->dtim_period);
buf : 
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			goto out_sleep;
buf : 	}
buf : 
buf : out_sleep:
buf : 	wl1251_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : }
buf : 
buf : 
buf : /* can't be const, mac80211 writes to this */
buf : static struct ieee80211_rate wl1251_rates[] = {
buf : 	{ .bitrate = 10,
buf : 	  .hw_value = 0x1,
buf : 	  .hw_value_short = 0x1, },
buf : 	{ .bitrate = 20,
buf : 	  .hw_value = 0x2,
buf : 	  .hw_value_short = 0x2,
buf : 	  .flags = IEEE80211_RATE_SHORT_PREAMBLE },
buf : 	{ .bitrate = 55,
buf : 	  .hw_value = 0x4,
buf : 	  .hw_value_short = 0x4,
buf : 	  .flags = IEEE80211_RATE_SHORT_PREAMBLE },
buf : 	{ .bitrate = 110,
buf : 	  .hw_value = 0x20,
buf : 	  .hw_value_short = 0x20,
buf : 	  .flags = IEEE80211_RATE_SHORT_PREAMBLE },
buf : 	{ .bitrate = 60,
buf : 	  .hw_value = 0x8,
buf : 	  .hw_value_short = 0x8, },
buf : 	{ .bitrate = 90,
buf : 	  .hw_value = 0x10,
buf : 	  .hw_value_short = 0x10, },
buf : 	{ .bitrate = 120,
buf : 	  .hw_value = 0x40,
buf : 	  .hw_value_short = 0x40, },
buf : 	{ .bitrate = 180,
buf : 	  .hw_value = 0x80,
buf : 	  .hw_value_short = 0x80, },
buf : 	{ .bitrate = 240,
buf : 	  .hw_value = 0x200,
buf : 	  .hw_value_short = 0x200, },
buf : 	{ .bitrate = 360,
buf : 	 .hw_value = 0x400,
buf : 	 .hw_value_short = 0x400, },
buf : 	{ .bitrate = 480,
buf : 	  .hw_value = 0x800,
buf : 	  .hw_value_short = 0x800, },
buf : 	{ .bitrate = 540,
buf : 	  .hw_value = 0x1000,
buf : 	  .hw_value_short = 0x1000, },
buf : };
buf : 
buf : /* can't be const, mac80211 writes to this */
buf : static struct ieee80211_channel wl1251_channels[] = {
buf : 	{ .hw_value = 1, .center_freq = 2412},
buf : 	{ .hw_value = 2, .center_freq = 2417},
buf : 	{ .hw_value = 3, .center_freq = 2422},
buf : 	{ .hw_value = 4, .center_freq = 2427},
buf : 	{ .hw_value = 5, .center_freq = 2432},
buf : 	{ .hw_value = 6, .center_freq = 2437},
buf : 	{ .hw_value = 7, .center_freq = 2442},
buf : 	{ .hw_value = 8, .center_freq = 2447},
buf : 	{ .hw_value = 9, .center_freq = 2452},
buf : 	{ .hw_value = 10, .center_freq = 2457},
buf : 	{ .hw_value = 11, .center_freq = 2462},
buf : 	{ .hw_value = 12, .center_freq = 2467},
buf : 	{ .hw_value = 13, .center_freq = 2472},
buf : };
buf : 
buf : static int wl1251_op_conf_tx(struct ieee80211_hw *hw,
buf : 			     struct ieee80211_vif *vif, u16 queue,
if *vif, u16 queue, 
buf : 			     const struct ieee80211_tx_queue_params *params)
buf : {
buf : 	enum wl1251_acx_ps_scheme ps_scheme;
buf : 	struct wl1251 *wl = hw->priv;
buf : 	int ret;
buf : 
buf : 	mutex_lock(&wl->mutex);
buf : 
buf : 	wl1251_debug(DEBUG_MAC80211, "mac80211 conf tx %d", queue);
buf : 
buf : 	ret = wl1251_ps_elp_wakeup(wl);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out;
buf : 
buf : 	/* mac80211 uses units of 32 usec */
buf : 	ret = wl1251_acx_ac_cfg(wl, wl1251_tx_get_queue(queue),
buf : 				params->cw_min, params->cw_max,
buf : 				params->aifs, params->txop * 32);
ifs, params->txop * 32); 
buf : 	if (ret < 0)
buf : 		goto out_sleep;
buf : 
buf : 	if (params->uapsd)
if (params->uapsd) 
buf : 		ps_scheme = WL1251_ACX_PS_SCHEME_UPSD_TRIGGER;
buf : 	else
buf : 		ps_scheme = WL1251_ACX_PS_SCHEME_LEGACY;
buf : 
buf : 	ret = wl1251_acx_tid_cfg(wl, wl1251_tx_get_queue(queue),
buf : 				 CHANNEL_TYPE_EDCF,
buf : 				 wl1251_tx_get_queue(queue), ps_scheme,
buf : 				 WL1251_ACX_ACK_POLICY_LEGACY);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto out_sleep;
buf : 
buf : out_sleep:
buf : 	wl1251_ps_elp_sleep(wl);
buf : 
buf : out:
buf : 	mutex_unlock(&wl->mutex);
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static int wl1251_op_get_survey(struct ieee80211_hw *hw, int idx,
buf : 				struct survey_info *survey)
buf : {
buf : 	struct wl1251 *wl = hw->priv;
buf : 	struct ieee80211_conf *conf = &hw->conf;
buf :  
buf : 	if (idx != 0)
if (idx != 0) 
buf : 		return -ENOENT;
buf :  
buf : 	survey->channel = conf->chandef.chan;
buf : 	survey->filled = SURVEY_INFO_NOISE_DBM;
buf : 	survey->noise = wl->noise;
buf :  
buf : 	return 0;
buf : }
buf : 
buf : /* can't be const, mac80211 writes to this */
buf : static struct ieee80211_supported_band wl1251_band_2ghz = {
buf : 	.channels = wl1251_channels,
buf : 	.n_channels = ARRAY_SIZE(wl1251_channels),
buf : 	.bitrates = wl1251_rates,
buf : 	.n_bitrates = ARRAY_SIZE(wl1251_rates),
buf : };
buf : 
buf : static const struct ieee80211_ops wl1251_ops = {
buf : 	.start = wl1251_op_start,
buf : 	.stop = wl1251_op_stop,
buf : 	.add_interface = wl1251_op_add_interface,
buf : 	.remove_interface = wl1251_op_remove_interface,
buf : 	.config = wl1251_op_config,
buf : 	.prepare_multicast = wl1251_op_prepare_multicast,
buf : 	.configure_filter = wl1251_op_configure_filter,
buf : 	.tx = wl1251_op_tx,
buf : 	.set_key = wl1251_op_set_key,
buf : 	.hw_scan = wl1251_op_hw_scan,
buf : 	.bss_info_changed = wl1251_op_bss_info_changed,
buf : 	.set_rts_threshold = wl1251_op_set_rts_threshold,
buf : 	.conf_tx = wl1251_op_conf_tx,
buf : 	.get_survey = wl1251_op_get_survey,
buf : };
buf : 
buf : static int wl1251_read_eeprom_byte(struct wl1251 *wl, off_t offset, u8 *data)
buf : {
buf : 	unsigned long timeout;
buf : 
buf : 	wl1251_reg_write32(wl, EE_ADDR, offset);
buf : 	wl1251_reg_write32(wl, EE_CTL, EE_CTL_READ);
buf : 
buf : 	/* EE_CTL_READ clears when data is ready */
buf : 	timeout = jiffies + msecs_to_jiffies(100);
iffies + msecs_to_jiffies(100); 
buf : 	while (1) {
while (1) { 
buf : 		if (!(wl1251_reg_read32(wl, EE_CTL) & EE_CTL_READ))
buf : 			break;
buf : 
buf : 		if (time_after(jiffies, timeout))
if (time_after(jiffies, timeout)) 
buf : 			return -ETIMEDOUT;
buf : 
buf : 		msleep(1);
buf : 	}
buf : 
buf : 	*data = wl1251_reg_read32(wl, EE_DATA);
buf : 	return 0;
buf : }
buf : 
buf : static int wl1251_read_eeprom(struct wl1251 *wl, off_t offset,
buf : 			      u8 *data, size_t len)
buf : {
buf : 	size_t i;
buf : 	int ret;
buf : 
buf : 	wl1251_reg_write32(wl, EE_START, 0);
buf : 
buf : 	for (i = 0; i < len; i++) {
for (i = 0; i < len; i++) { 
buf : 		ret = wl1251_read_eeprom_byte(wl, offset + i, &data[i]);
buf : 		if (ret < 0)
if (ret < 0) 
buf : 			return ret;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl1251_read_eeprom_mac(struct wl1251 *wl)
buf : {
buf : 	u8 mac[ETH_ALEN];
buf : 	int i, ret;
buf : 
buf : 	wl1251_set_partition(wl, 0, 0, REGISTERS_BASE, REGISTERS_DOWN_SIZE);
buf : 
buf : 	ret = wl1251_read_eeprom(wl, 0x1c, mac, sizeof(mac));
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1251_warning("failed to read MAC address from EEPROM");
buf : 		return ret;
buf : 	}
buf : 
buf : 	/* MAC is stored in reverse order */
buf : 	for (i = 0; i < ETH_ALEN; i++)
for (i = 0; i < ETH_ALEN; i++) 
buf : 		wl->mac_addr[i] = mac[ETH_ALEN - i - 1];
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int wl1251_register_hw(struct wl1251 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	if (wl->mac80211_registered)
if (wl->mac80211_registered) 
buf : 		return 0;
buf : 
buf : 	SET_IEEE80211_PERM_ADDR(wl->hw, wl->mac_addr);
buf : 
buf : 	ret = ieee80211_register_hw(wl->hw);
buf : 	if (ret < 0) {
if (ret < 0) { 
buf : 		wl1251_error("unable to register mac80211 hw: %d", ret);
buf : 		return ret;
buf : 	}
buf : 
buf : 	wl->mac80211_registered = true;
buf : 
buf : 	wl1251_notice("loaded");
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int wl1251_init_ieee80211(struct wl1251 *wl)
buf : {
buf : 	int ret;
buf : 
buf : 	/* The tx descriptor buffer and the TKIP space */
buf : 	wl->hw->extra_tx_headroom = sizeof(struct tx_double_buffer_desc)
buf : 		+ WL1251_TKIP_IV_SPACE;
buf : 
buf : 	/* unit us */
buf : 	/* FIXME: find a proper value */
buf : 
buf : 	wl->hw->flags = IEEE80211_HW_SIGNAL_DBM |
buf : 		IEEE80211_HW_SUPPORTS_PS |
buf : 		IEEE80211_HW_SUPPORTS_UAPSD;
buf : 
buf : 	wl->hw->wiphy->interface_modes = BIT(NL80211_IFTYPE_STATION) |
buf : 					 BIT(NL80211_IFTYPE_ADHOC);
buf : 	wl->hw->wiphy->max_scan_ssids = 1;
buf : 	wl->hw->wiphy->bands[IEEE80211_BAND_2GHZ] = &wl1251_band_2ghz;
buf : 
buf : 	wl->hw->queues = 4;
buf : 
buf : 	if (wl->use_eeprom)
if (wl->use_eeprom) 
buf : 		wl1251_read_eeprom_mac(wl);
buf : 
buf : 	ret = wl1251_register_hw(wl);
buf : 	if (ret)
if (ret) 
buf : 		goto out;
buf : 
buf : 	wl1251_debugfs_init(wl);
buf : 	wl1251_notice("initialized");
buf : 
buf : 	ret = 0;
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : EXPORT_SYMBOL_GPL(wl1251_init_ieee80211);
buf : 
buf : struct ieee80211_hw *wl1251_alloc_hw(void)
buf : {
buf : 	struct ieee80211_hw *hw;
buf : 	struct wl1251 *wl;
buf : 	int i;
buf : 	static const u8 nokia_oui[3] = {0x00, 0x1f, 0xdf};
buf : 
buf : 	hw = ieee80211_alloc_hw(sizeof(*wl), &wl1251_ops);
buf : 	if (!hw) {
if (!hw) { 
buf : 		wl1251_error("could not alloc ieee80211_hw");
buf : 		return ERR_PTR(-ENOMEM);
buf : 	}
buf : 
buf : 	wl = hw->priv;
buf : 	memset(wl, 0, sizeof(*wl));
buf : 
buf : 	wl->hw = hw;
buf : 
buf : 	wl->data_in_count = 0;
buf : 
buf : 	skb_queue_head_init(&wl->tx_queue);
buf : 
buf : 	INIT_DELAYED_WORK(&wl->elp_work, wl1251_elp_work);
buf : 	wl->channel = WL1251_DEFAULT_CHANNEL;
buf : 	wl->monitor_present = false;
buf : 	wl->joined = false;
buf : 	wl->scanning = false;
buf : 	wl->bss_type = MAX_BSS_TYPE;
buf : 	wl->default_key = 0;
buf : 	wl->listen_int = 1;
buf : 	wl->rx_counter = 0;
buf : 	wl->rx_handled = 0;
buf : 	wl->rx_current_buffer = 0;
buf : 	wl->rx_last_id = 0;
buf : 	wl->rx_config = WL1251_DEFAULT_RX_CONFIG;
buf : 	wl->rx_filter = WL1251_DEFAULT_RX_FILTER;
buf : 	wl->elp = false;
buf : 	wl->station_mode = STATION_ACTIVE_MODE;
buf : 	wl->psm_requested = false;
buf : 	wl->psm_entry_retry = 0;
buf : 	wl->tx_queue_stopped = false;
buf : 	wl->power_level = WL1251_DEFAULT_POWER_LEVEL;
buf : 	wl->rssi_thold = 0;
buf : 	wl->beacon_int = WL1251_DEFAULT_BEACON_INT;
buf : 	wl->dtim_period = WL1251_DEFAULT_DTIM_PERIOD;
buf : 	wl->vif = NULL;
if = NULL; 
buf : 
buf : 	for (i = 0; i < FW_TX_CMPLT_BLOCK_SIZE; i++)
for (i = 0; i < FW_TX_CMPLT_BLOCK_SIZE; i++) 
buf : 		wl->tx_frames[i] = NULL;
buf : 
buf : 	wl->next_tx_complete = 0;
buf : 
buf : 	INIT_WORK(&wl->irq_work, wl1251_irq_work);
buf : 	INIT_WORK(&wl->tx_work, wl1251_tx_work);
buf : 
buf : 	/*
buf : 	 * In case our MAC address is not correctly set,
buf : 	 * we use a random but Nokia MAC.
buf : 	 */
buf : 	memcpy(wl->mac_addr, nokia_oui, 3);
buf : 	get_random_bytes(wl->mac_addr + 3, 3);
buf : 
buf : 	wl->state = WL1251_STATE_OFF;
buf : 	mutex_init(&wl->mutex);
buf : 
buf : 	wl->tx_mgmt_frm_rate = DEFAULT_HW_GEN_TX_RATE;
buf : 	wl->tx_mgmt_frm_mod = DEFAULT_HW_GEN_MODULATION_TYPE;
buf : 
buf : 	wl->rx_descriptor = kmalloc(sizeof(*wl->rx_descriptor), GFP_KERNEL);
buf : 	if (!wl->rx_descriptor) {
if (!wl->rx_descriptor) { 
buf : 		wl1251_error("could not allocate memory for rx descriptor");
for rx descriptor"); 
buf : 		ieee80211_free_hw(hw);
buf : 		return ERR_PTR(-ENOMEM);
buf : 	}
buf : 
buf : 	return hw;
buf : }
buf : EXPORT_SYMBOL_GPL(wl1251_alloc_hw);
buf : 
buf : int wl1251_free_hw(struct wl1251 *wl)
buf : {
buf : 	ieee80211_unregister_hw(wl->hw);
buf : 
buf : 	wl1251_debugfs_exit(wl);
buf : 
buf : 	kfree(wl->target_mem_map);
buf : 	kfree(wl->data_path);
buf : 	vfree(wl->fw);
buf : 	wl->fw = NULL;
buf : 	kfree(wl->nvs);
buf : 	wl->nvs = NULL;
buf : 
buf : 	kfree(wl->rx_descriptor);
buf : 	wl->rx_descriptor = NULL;
buf : 
buf : 	ieee80211_free_hw(wl->hw);
buf : 
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL_GPL(wl1251_free_hw);
buf : 
buf : MODULE_DESCRIPTION("TI wl1251 Wireles LAN Driver Core");
buf : MODULE_LICENSE("GPL");
buf : MODULE_AUTHOR("Kalle Valo <kvalo@adurom.com>");
buf : MODULE_FIRMWARE(WL1251_FW_NAME);
buf : MODULE_FIRMWARE(WL1251_NVS_NAME);
file : ./test/kernel/drivers/net/ethernet/atheros/alx/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2013 Johannes Berg <johannes@sipsolutions.net>
buf :  *
buf :  *  This file is free software: you may copy, redistribute and/or modify it
ify it 
buf :  *  under the terms of the GNU General Public License as published by the
buf :  *  Free Software Foundation, either version 2 of the License, or (at your
buf :  *  option) any later version.
buf :  *
buf :  *  This file is distributed in the hope that it will be useful, but
buf :  *  WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
buf :  *  General Public License for more details.
for more details. 
buf :  *
buf :  *  You should have received a copy of the GNU General Public License
buf :  *  along with this program.  If not, see <http://www.gnu.org/licenses/>.
buf :  *
buf :  * This file incorporates work covered by the following copyright and
buf :  * permission notice:
buf :  *
buf :  * Copyright (c) 2012 Qualcomm Atheros, Inc.
buf :  *
buf :  * Permission to use, copy, modify, and/or distribute this software for any
ify, and/or distribute this software for any 
buf :  * purpose with or without fee is hereby granted, provided that the above
buf :  * copyright notice and this permission notice appear in all copies.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
buf :  * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
buf :  * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
buf :  * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
buf :  * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
buf :  * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
buf :  * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/pci.h>
buf : #include <linux/interrupt.h>
buf : #include <linux/ip.h>
buf : #include <linux/ipv6.h>
buf : #include <linux/if_vlan.h>
if_vlan.h> 
buf : #include <linux/mdio.h>
buf : #include <linux/aer.h>
buf : #include <linux/bitops.h>
buf : #include <linux/netdevice.h>
buf : #include <linux/etherdevice.h>
buf : #include <net/ip6_checksum.h>
buf : #include <linux/crc32.h>
buf : #include "alx.h"
buf : #include "hw.h"
buf : #include "reg.h"
buf : 
buf : const char alx_drv_name[] = "alx";
buf : 
buf : 
buf : static void alx_free_txbuf(struct alx_priv *alx, int entry)
buf : {
buf : 	struct alx_buffer *txb = &alx->txq.bufs[entry];
buf : 
buf : 	if (dma_unmap_len(txb, size)) {
if (dma_unmap_len(txb, size)) { 
buf : 		dma_unmap_single(&alx->hw.pdev->dev,
buf : 				 dma_unmap_addr(txb, dma),
buf : 				 dma_unmap_len(txb, size),
buf : 				 DMA_TO_DEVICE);
buf : 		dma_unmap_len_set(txb, size, 0);
buf : 	}
buf : 
buf : 	if (txb->skb) {
if (txb->skb) { 
buf : 		dev_kfree_skb_any(txb->skb);
buf : 		txb->skb = NULL;
buf : 	}
buf : }
buf : 
buf : static int alx_refill_rx_ring(struct alx_priv *alx, gfp_t gfp)
buf : {
buf : 	struct alx_rx_queue *rxq = &alx->rxq;
buf : 	struct sk_buff *skb;
buf : 	struct alx_buffer *cur_buf;
buf : 	dma_addr_t dma;
buf : 	u16 cur, next, count = 0;
buf : 
buf : 	next = cur = rxq->write_idx;
buf : 	if (++next == alx->rx_ringsz)
if (++next == alx->rx_ringsz) 
buf : 		next = 0;
buf : 	cur_buf = &rxq->bufs[cur];
buf : 
buf : 	while (!cur_buf->skb && next != rxq->read_idx) {
while (!cur_buf->skb && next != rxq->read_idx) { 
buf : 		struct alx_rfd *rfd = &rxq->rfd[cur];
buf : 
buf : 		skb = __netdev_alloc_skb(alx->dev, alx->rxbuf_size, gfp);
buf : 		if (!skb)
if (!skb) 
buf : 			break;
buf : 		dma = dma_map_single(&alx->hw.pdev->dev,
buf : 				     skb->data, alx->rxbuf_size,
buf : 				     DMA_FROM_DEVICE);
buf : 		if (dma_mapping_error(&alx->hw.pdev->dev, dma)) {
if (dma_mapping_error(&alx->hw.pdev->dev, dma)) { 
buf : 			dev_kfree_skb(skb);
buf : 			break;
buf : 		}
buf : 
buf : 		/* Unfortunately, RX descriptor buffers must be 4-byte
fortunately, RX descriptor buffers must be 4-byte 
buf : 		 * aligned, so we can't use IP alignment.
buf : 		 */
buf : 		if (WARN_ON(dma & 3)) {
if (WARN_ON(dma & 3)) { 
buf : 			dev_kfree_skb(skb);
buf : 			break;
buf : 		}
buf : 
buf : 		cur_buf->skb = skb;
buf : 		dma_unmap_len_set(cur_buf, size, alx->rxbuf_size);
buf : 		dma_unmap_addr_set(cur_buf, dma, dma);
buf : 		rfd->addr = cpu_to_le64(dma);
buf : 
buf : 		cur = next;
buf : 		if (++next == alx->rx_ringsz)
if (++next == alx->rx_ringsz) 
buf : 			next = 0;
buf : 		cur_buf = &rxq->bufs[cur];
buf : 		count++;
buf : 	}
buf : 
buf : 	if (count) {
if (count) { 
buf : 		/* flush all updates before updating hardware */
fore updating hardware */ 
buf : 		wmb();
buf : 		rxq->write_idx = cur;
buf : 		alx_write_mem16(&alx->hw, ALX_RFD_PIDX, cur);
buf : 	}
buf : 
buf : 	return count;
buf : }
buf : 
buf : static inline int alx_tpd_avail(struct alx_priv *alx)
buf : {
buf : 	struct alx_tx_queue *txq = &alx->txq;
buf : 
buf : 	if (txq->write_idx >= txq->read_idx)
if (txq->write_idx >= txq->read_idx) 
buf : 		return alx->tx_ringsz + txq->read_idx - txq->write_idx - 1;
buf : 	return txq->read_idx - txq->write_idx - 1;
buf : }
buf : 
buf : static bool alx_clean_tx_irq(struct alx_priv *alx)
buf : {
buf : 	struct alx_tx_queue *txq = &alx->txq;
buf : 	u16 hw_read_idx, sw_read_idx;
buf : 	unsigned int total_bytes = 0, total_packets = 0;
buf : 	int budget = ALX_DEFAULT_TX_WORK;
buf : 
buf : 	sw_read_idx = txq->read_idx;
buf : 	hw_read_idx = alx_read_mem16(&alx->hw, ALX_TPD_PRI0_CIDX);
buf : 
buf : 	if (sw_read_idx != hw_read_idx) {
if (sw_read_idx != hw_read_idx) { 
buf : 		while (sw_read_idx != hw_read_idx && budget > 0) {
while (sw_read_idx != hw_read_idx && budget > 0) { 
buf : 			struct sk_buff *skb;
buf : 
buf : 			skb = txq->bufs[sw_read_idx].skb;
buf : 			if (skb) {
if (skb) { 
buf : 				total_bytes += skb->len;
buf : 				total_packets++;
buf : 				budget--;
buf : 			}
buf : 
buf : 			alx_free_txbuf(alx, sw_read_idx);
buf : 
buf : 			if (++sw_read_idx == alx->tx_ringsz)
if (++sw_read_idx == alx->tx_ringsz) 
buf : 				sw_read_idx = 0;
buf : 		}
buf : 		txq->read_idx = sw_read_idx;
buf : 
buf : 		netdev_completed_queue(alx->dev, total_packets, total_bytes);
buf : 	}
buf : 
buf : 	if (netif_queue_stopped(alx->dev) && netif_carrier_ok(alx->dev) &&
if (netif_queue_stopped(alx->dev) && netif_carrier_ok(alx->dev) && 
buf : 	    alx_tpd_avail(alx) > alx->tx_ringsz/4)
buf : 		netif_wake_queue(alx->dev);
if_wake_queue(alx->dev); 
buf : 
buf : 	return sw_read_idx == hw_read_idx;
buf : }
buf : 
buf : static void alx_schedule_link_check(struct alx_priv *alx)
buf : {
buf : 	schedule_work(&alx->link_check_wk);
buf : }
buf : 
buf : static void alx_schedule_reset(struct alx_priv *alx)
buf : {
buf : 	schedule_work(&alx->reset_wk);
buf : }
buf : 
buf : static bool alx_clean_rx_irq(struct alx_priv *alx, int budget)
buf : {
buf : 	struct alx_rx_queue *rxq = &alx->rxq;
buf : 	struct alx_rrd *rrd;
buf : 	struct alx_buffer *rxb;
buf : 	struct sk_buff *skb;
buf : 	u16 length, rfd_cleaned = 0;
buf : 
buf : 	while (budget > 0) {
while (budget > 0) { 
buf : 		rrd = &rxq->rrd[rxq->rrd_read_idx];
buf : 		if (!(rrd->word3 & cpu_to_le32(1 << RRD_UPDATED_SHIFT)))
if (!(rrd->word3 & cpu_to_le32(1 << RRD_UPDATED_SHIFT))) 
buf : 			break;
buf : 		rrd->word3 &= ~cpu_to_le32(1 << RRD_UPDATED_SHIFT);
buf : 
buf : 		if (ALX_GET_FIELD(le32_to_cpu(rrd->word0),
if (ALX_GET_FIELD(le32_to_cpu(rrd->word0), 
buf : 				  RRD_SI) != rxq->read_idx ||
buf : 		    ALX_GET_FIELD(le32_to_cpu(rrd->word0),
buf : 				  RRD_NOR) != 1) {
buf : 			alx_schedule_reset(alx);
buf : 			return 0;
buf : 		}
buf : 
buf : 		rxb = &rxq->bufs[rxq->read_idx];
buf : 		dma_unmap_single(&alx->hw.pdev->dev,
buf : 				 dma_unmap_addr(rxb, dma),
buf : 				 dma_unmap_len(rxb, size),
buf : 				 DMA_FROM_DEVICE);
buf : 		dma_unmap_len_set(rxb, size, 0);
buf : 		skb = rxb->skb;
buf : 		rxb->skb = NULL;
buf : 
buf : 		if (rrd->word3 & cpu_to_le32(1 << RRD_ERR_RES_SHIFT) ||
if (rrd->word3 & cpu_to_le32(1 << RRD_ERR_RES_SHIFT) || 
buf : 		    rrd->word3 & cpu_to_le32(1 << RRD_ERR_LEN_SHIFT)) {
buf : 			rrd->word3 = 0;
buf : 			dev_kfree_skb_any(skb);
buf : 			goto next_pkt;
buf : 		}
buf : 
buf : 		length = ALX_GET_FIELD(le32_to_cpu(rrd->word3),
buf : 				       RRD_PKTLEN) - ETH_FCS_LEN;
buf : 		skb_put(skb, length);
buf : 		skb->protocol = eth_type_trans(skb, alx->dev);
buf : 
buf : 		skb_checksum_none_assert(skb);
buf : 		if (alx->dev->features & NETIF_F_RXCSUM &&
if (alx->dev->features & NETIF_F_RXCSUM && 
buf : 		    !(rrd->word3 & (cpu_to_le32(1 << RRD_ERR_L4_SHIFT) |
buf : 				    cpu_to_le32(1 << RRD_ERR_IPV4_SHIFT)))) {
buf : 			switch (ALX_GET_FIELD(le32_to_cpu(rrd->word2),
buf : 					      RRD_PID)) {
buf : 			case RRD_PID_IPV6UDP:
buf : 			case RRD_PID_IPV4UDP:
buf : 			case RRD_PID_IPV4TCP:
buf : 			case RRD_PID_IPV6TCP:
buf : 				skb->ip_summed = CHECKSUM_UNNECESSARY;
buf : 				break;
buf : 			}
buf : 		}
buf : 
buf : 		napi_gro_receive(&alx->napi, skb);
buf : 		budget--;
buf : 
buf : next_pkt:
buf : 		if (++rxq->read_idx == alx->rx_ringsz)
if (++rxq->read_idx == alx->rx_ringsz) 
buf : 			rxq->read_idx = 0;
buf : 		if (++rxq->rrd_read_idx == alx->rx_ringsz)
if (++rxq->rrd_read_idx == alx->rx_ringsz) 
buf : 			rxq->rrd_read_idx = 0;
buf : 
buf : 		if (++rfd_cleaned > ALX_RX_ALLOC_THRESH)
if (++rfd_cleaned > ALX_RX_ALLOC_THRESH) 
buf : 			rfd_cleaned -= alx_refill_rx_ring(alx, GFP_ATOMIC);
buf : 	}
buf : 
buf : 	if (rfd_cleaned)
if (rfd_cleaned) 
buf : 		alx_refill_rx_ring(alx, GFP_ATOMIC);
buf : 
buf : 	return budget > 0;
buf : }
buf : 
buf : static int alx_poll(struct napi_struct *napi, int budget)
buf : {
buf : 	struct alx_priv *alx = container_of(napi, struct alx_priv, napi);
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	bool complete = true;
buf : 	unsigned long flags;
buf : 
buf : 	complete = alx_clean_tx_irq(alx) &&
buf : 		   alx_clean_rx_irq(alx, budget);
buf : 
buf : 	if (!complete)
if (!complete) 
buf : 		return 1;
buf : 
buf : 	napi_complete(&alx->napi);
buf : 
buf : 	/* enable interrupt */
buf : 	spin_lock_irqsave(&alx->irq_lock, flags);
buf : 	alx->int_mask |= ALX_ISR_TX_Q0 | ALX_ISR_RX_Q0;
buf : 	alx_write_mem32(hw, ALX_IMR, alx->int_mask);
buf : 	spin_unlock_irqrestore(&alx->irq_lock, flags);
buf : 
buf : 	alx_post_write(hw);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static irqreturn_t alx_intr_handle(struct alx_priv *alx, u32 intr)
buf : {
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	bool write_int_mask = false;
buf : 
buf : 	spin_lock(&alx->irq_lock);
buf : 
buf : 	/* ACK interrupt */
buf : 	alx_write_mem32(hw, ALX_ISR, intr | ALX_ISR_DIS);
buf : 	intr &= alx->int_mask;
buf : 
buf : 	if (intr & ALX_ISR_FATAL) {
if (intr & ALX_ISR_FATAL) { 
buf : 		netif_warn(alx, hw, alx->dev,
buf : 			   "fatal interrupt 0x%x, resetting\n", intr);
buf : 		alx_schedule_reset(alx);
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (intr & ALX_ISR_ALERT)
if (intr & ALX_ISR_ALERT) 
buf : 		netdev_warn(alx->dev, "alert interrupt: 0x%x\n", intr);
buf : 
buf : 	if (intr & ALX_ISR_PHY) {
if (intr & ALX_ISR_PHY) { 
buf : 		/* suppress PHY interrupt, because the source
buf : 		 * is from PHY internal. only the internal status
buf : 		 * is cleared, the interrupt status could be cleared.
buf : 		 */
buf : 		alx->int_mask &= ~ALX_ISR_PHY;
buf : 		write_int_mask = true;
buf : 		alx_schedule_link_check(alx);
buf : 	}
buf : 
buf : 	if (intr & (ALX_ISR_TX_Q0 | ALX_ISR_RX_Q0)) {
if (intr & (ALX_ISR_TX_Q0 | ALX_ISR_RX_Q0)) { 
buf : 		napi_schedule(&alx->napi);
buf : 		/* mask rx/tx interrupt, enable them when napi complete */
buf : 		alx->int_mask &= ~ALX_ISR_ALL_QUEUES;
buf : 		write_int_mask = true;
buf : 	}
buf : 
buf : 	if (write_int_mask)
if (write_int_mask) 
buf : 		alx_write_mem32(hw, ALX_IMR, alx->int_mask);
buf : 
buf : 	alx_write_mem32(hw, ALX_ISR, 0);
buf : 
buf :  out:
buf : 	spin_unlock(&alx->irq_lock);
buf : 	return IRQ_HANDLED;
buf : }
buf : 
buf : static irqreturn_t alx_intr_msi(int irq, void *data)
buf : {
buf : 	struct alx_priv *alx = data;
buf : 
buf : 	return alx_intr_handle(alx, alx_read_mem32(&alx->hw, ALX_ISR));
buf : }
buf : 
buf : static irqreturn_t alx_intr_legacy(int irq, void *data)
buf : {
buf : 	struct alx_priv *alx = data;
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	u32 intr;
buf : 
buf : 	intr = alx_read_mem32(hw, ALX_ISR);
buf : 
buf : 	if (intr & ALX_ISR_DIS || !(intr & alx->int_mask))
if (intr & ALX_ISR_DIS || !(intr & alx->int_mask)) 
buf : 		return IRQ_NONE;
buf : 
buf : 	return alx_intr_handle(alx, intr);
buf : }
buf : 
buf : static void alx_init_ring_ptrs(struct alx_priv *alx)
buf : {
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	u32 addr_hi = ((u64)alx->descmem.dma) >> 32;
buf : 
buf : 	alx->rxq.read_idx = 0;
buf : 	alx->rxq.write_idx = 0;
buf : 	alx->rxq.rrd_read_idx = 0;
buf : 	alx_write_mem32(hw, ALX_RX_BASE_ADDR_HI, addr_hi);
buf : 	alx_write_mem32(hw, ALX_RRD_ADDR_LO, alx->rxq.rrd_dma);
buf : 	alx_write_mem32(hw, ALX_RRD_RING_SZ, alx->rx_ringsz);
buf : 	alx_write_mem32(hw, ALX_RFD_ADDR_LO, alx->rxq.rfd_dma);
buf : 	alx_write_mem32(hw, ALX_RFD_RING_SZ, alx->rx_ringsz);
buf : 	alx_write_mem32(hw, ALX_RFD_BUF_SZ, alx->rxbuf_size);
buf : 
buf : 	alx->txq.read_idx = 0;
buf : 	alx->txq.write_idx = 0;
buf : 	alx_write_mem32(hw, ALX_TX_BASE_ADDR_HI, addr_hi);
buf : 	alx_write_mem32(hw, ALX_TPD_PRI0_ADDR_LO, alx->txq.tpd_dma);
buf : 	alx_write_mem32(hw, ALX_TPD_RING_SZ, alx->tx_ringsz);
buf : 
buf : 	/* load these pointers into the chip */
buf : 	alx_write_mem32(hw, ALX_SRAM9, ALX_SRAM_LOAD_PTR);
buf : }
buf : 
buf : static void alx_free_txring_buf(struct alx_priv *alx)
buf : {
buf : 	struct alx_tx_queue *txq = &alx->txq;
buf : 	int i;
buf : 
buf : 	if (!txq->bufs)
if (!txq->bufs) 
buf : 		return;
buf : 
buf : 	for (i = 0; i < alx->tx_ringsz; i++)
for (i = 0; i < alx->tx_ringsz; i++) 
buf : 		alx_free_txbuf(alx, i);
buf : 
buf : 	memset(txq->bufs, 0, alx->tx_ringsz * sizeof(struct alx_buffer));
buf : 	memset(txq->tpd, 0, alx->tx_ringsz * sizeof(struct alx_txd));
buf : 	txq->write_idx = 0;
buf : 	txq->read_idx = 0;
buf : 
buf : 	netdev_reset_queue(alx->dev);
buf : }
buf : 
buf : static void alx_free_rxring_buf(struct alx_priv *alx)
buf : {
buf : 	struct alx_rx_queue *rxq = &alx->rxq;
buf : 	struct alx_buffer *cur_buf;
buf : 	u16 i;
buf : 
buf : 	if (rxq == NULL)
if (rxq == NULL) 
buf : 		return;
buf : 
buf : 	for (i = 0; i < alx->rx_ringsz; i++) {
for (i = 0; i < alx->rx_ringsz; i++) { 
buf : 		cur_buf = rxq->bufs + i;
buf : 		if (cur_buf->skb) {
if (cur_buf->skb) { 
buf : 			dma_unmap_single(&alx->hw.pdev->dev,
buf : 					 dma_unmap_addr(cur_buf, dma),
buf : 					 dma_unmap_len(cur_buf, size),
buf : 					 DMA_FROM_DEVICE);
buf : 			dev_kfree_skb(cur_buf->skb);
buf : 			cur_buf->skb = NULL;
buf : 			dma_unmap_len_set(cur_buf, size, 0);
buf : 			dma_unmap_addr_set(cur_buf, dma, 0);
buf : 		}
buf : 	}
buf : 
buf : 	rxq->write_idx = 0;
buf : 	rxq->read_idx = 0;
buf : 	rxq->rrd_read_idx = 0;
buf : }
buf : 
buf : static void alx_free_buffers(struct alx_priv *alx)
buf : {
buf : 	alx_free_txring_buf(alx);
buf : 	alx_free_rxring_buf(alx);
buf : }
buf : 
buf : static int alx_reinit_rings(struct alx_priv *alx)
buf : {
buf : 	alx_free_buffers(alx);
buf : 
buf : 	alx_init_ring_ptrs(alx);
buf : 
buf : 	if (!alx_refill_rx_ring(alx, GFP_KERNEL))
if (!alx_refill_rx_ring(alx, GFP_KERNEL)) 
buf : 		return -ENOMEM;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void alx_add_mc_addr(struct alx_hw *hw, const u8 *addr, u32 *mc_hash)
buf : {
buf : 	u32 crc32, bit, reg;
buf : 
buf : 	crc32 = ether_crc(ETH_ALEN, addr);
buf : 	reg = (crc32 >> 31) & 0x1;
buf : 	bit = (crc32 >> 26) & 0x1F;
buf : 
buf : 	mc_hash[reg] |= BIT(bit);
buf : }
buf : 
buf : static void __alx_set_rx_mode(struct net_device *netdev)
buf : {
buf : 	struct alx_priv *alx = netdev_priv(netdev);
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	struct netdev_hw_addr *ha;
buf : 	u32 mc_hash[2] = {};
buf : 
buf : 	if (!(netdev->flags & IFF_ALLMULTI)) {
if (!(netdev->flags & IFF_ALLMULTI)) { 
buf : 		netdev_for_each_mc_addr(ha, netdev)
for_each_mc_addr(ha, netdev) 
buf : 			alx_add_mc_addr(hw, ha->addr, mc_hash);
buf : 
buf : 		alx_write_mem32(hw, ALX_HASH_TBL0, mc_hash[0]);
buf : 		alx_write_mem32(hw, ALX_HASH_TBL1, mc_hash[1]);
buf : 	}
buf : 
buf : 	hw->rx_ctrl &= ~(ALX_MAC_CTRL_MULTIALL_EN | ALX_MAC_CTRL_PROMISC_EN);
buf : 	if (netdev->flags & IFF_PROMISC)
if (netdev->flags & IFF_PROMISC) 
buf : 		hw->rx_ctrl |= ALX_MAC_CTRL_PROMISC_EN;
buf : 	if (netdev->flags & IFF_ALLMULTI)
if (netdev->flags & IFF_ALLMULTI) 
buf : 		hw->rx_ctrl |= ALX_MAC_CTRL_MULTIALL_EN;
buf : 
buf : 	alx_write_mem32(hw, ALX_MAC_CTRL, hw->rx_ctrl);
buf : }
buf : 
buf : static void alx_set_rx_mode(struct net_device *netdev)
buf : {
buf : 	__alx_set_rx_mode(netdev);
buf : }
buf : 
buf : static int alx_set_mac_address(struct net_device *netdev, void *data)
buf : {
buf : 	struct alx_priv *alx = netdev_priv(netdev);
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	struct sockaddr *addr = data;
buf : 
buf : 	if (!is_valid_ether_addr(addr->sa_data))
if (!is_valid_ether_addr(addr->sa_data)) 
buf : 		return -EADDRNOTAVAIL;
buf : 
buf : 	if (netdev->addr_assign_type & NET_ADDR_RANDOM)
if (netdev->addr_assign_type & NET_ADDR_RANDOM) 
buf : 		netdev->addr_assign_type ^= NET_ADDR_RANDOM;
buf : 
buf : 	memcpy(netdev->dev_addr, addr->sa_data, netdev->addr_len);
buf : 	memcpy(hw->mac_addr, addr->sa_data, netdev->addr_len);
buf : 	alx_set_macaddr(hw, hw->mac_addr);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int alx_alloc_descriptors(struct alx_priv *alx)
buf : {
buf : 	alx->txq.bufs = kcalloc(alx->tx_ringsz,
buf : 				sizeof(struct alx_buffer),
buf : 				GFP_KERNEL);
buf : 	if (!alx->txq.bufs)
if (!alx->txq.bufs) 
buf : 		return -ENOMEM;
buf : 
buf : 	alx->rxq.bufs = kcalloc(alx->rx_ringsz,
buf : 				sizeof(struct alx_buffer),
buf : 				GFP_KERNEL);
buf : 	if (!alx->rxq.bufs)
if (!alx->rxq.bufs) 
buf : 		goto out_free;
buf : 
buf : 	/* physical tx/rx ring descriptors
buf : 	 *
buf : 	 * Allocate them as a single chunk because they must not cross a
buf : 	 * 4G boundary (hardware has a single register for high 32 bits
for high 32 bits 
buf : 	 * of addresses only)
buf : 	 */
buf : 	alx->descmem.size = sizeof(struct alx_txd) * alx->tx_ringsz +
buf : 			    sizeof(struct alx_rrd) * alx->rx_ringsz +
buf : 			    sizeof(struct alx_rfd) * alx->rx_ringsz;
buf : 	alx->descmem.virt = dma_zalloc_coherent(&alx->hw.pdev->dev,
buf : 						alx->descmem.size,
buf : 						&alx->descmem.dma,
buf : 						GFP_KERNEL);
buf : 	if (!alx->descmem.virt)
if (!alx->descmem.virt) 
buf : 		goto out_free;
buf : 
buf : 	alx->txq.tpd = alx->descmem.virt;
buf : 	alx->txq.tpd_dma = alx->descmem.dma;
buf : 
buf : 	/* alignment requirement for next block */
for next block */ 
buf : 	BUILD_BUG_ON(sizeof(struct alx_txd) % 8);
buf : 
buf : 	alx->rxq.rrd =
buf : 		(void *)((u8 *)alx->descmem.virt +
buf : 			 sizeof(struct alx_txd) * alx->tx_ringsz);
buf : 	alx->rxq.rrd_dma = alx->descmem.dma +
buf : 			   sizeof(struct alx_txd) * alx->tx_ringsz;
buf : 
buf : 	/* alignment requirement for next block */
for next block */ 
buf : 	BUILD_BUG_ON(sizeof(struct alx_rrd) % 8);
buf : 
buf : 	alx->rxq.rfd =
buf : 		(void *)((u8 *)alx->descmem.virt +
buf : 			 sizeof(struct alx_txd) * alx->tx_ringsz +
buf : 			 sizeof(struct alx_rrd) * alx->rx_ringsz);
buf : 	alx->rxq.rfd_dma = alx->descmem.dma +
buf : 			   sizeof(struct alx_txd) * alx->tx_ringsz +
buf : 			   sizeof(struct alx_rrd) * alx->rx_ringsz;
buf : 
buf : 	return 0;
buf : out_free:
buf : 	kfree(alx->txq.bufs);
buf : 	kfree(alx->rxq.bufs);
buf : 	return -ENOMEM;
buf : }
buf : 
buf : static int alx_alloc_rings(struct alx_priv *alx)
buf : {
buf : 	int err;
buf : 
buf : 	err = alx_alloc_descriptors(alx);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	alx->int_mask &= ~ALX_ISR_ALL_QUEUES;
buf : 	alx->int_mask |= ALX_ISR_TX_Q0 | ALX_ISR_RX_Q0;
buf : 	alx->tx_ringsz = alx->tx_ringsz;
buf : 
buf : 	netif_napi_add(alx->dev, &alx->napi, alx_poll, 64);
if_napi_add(alx->dev, &alx->napi, alx_poll, 64); 
buf : 
buf : 	alx_reinit_rings(alx);
buf : 	return 0;
buf : }
buf : 
buf : static void alx_free_rings(struct alx_priv *alx)
buf : {
buf : 	netif_napi_del(&alx->napi);
if_napi_del(&alx->napi); 
buf : 	alx_free_buffers(alx);
buf : 
buf : 	kfree(alx->txq.bufs);
buf : 	kfree(alx->rxq.bufs);
buf : 
buf : 	dma_free_coherent(&alx->hw.pdev->dev,
buf : 			  alx->descmem.size,
buf : 			  alx->descmem.virt,
buf : 			  alx->descmem.dma);
buf : }
buf : 
buf : static void alx_config_vector_mapping(struct alx_priv *alx)
buf : {
buf : 	struct alx_hw *hw = &alx->hw;
buf : 
buf : 	alx_write_mem32(hw, ALX_MSI_MAP_TBL1, 0);
buf : 	alx_write_mem32(hw, ALX_MSI_MAP_TBL2, 0);
buf : 	alx_write_mem32(hw, ALX_MSI_ID_MAP, 0);
buf : }
buf : 
buf : static void alx_irq_enable(struct alx_priv *alx)
buf : {
buf : 	struct alx_hw *hw = &alx->hw;
buf : 
buf : 	/* level-1 interrupt switch */
buf : 	alx_write_mem32(hw, ALX_ISR, 0);
buf : 	alx_write_mem32(hw, ALX_IMR, alx->int_mask);
buf : 	alx_post_write(hw);
buf : }
buf : 
buf : static void alx_irq_disable(struct alx_priv *alx)
buf : {
buf : 	struct alx_hw *hw = &alx->hw;
buf : 
buf : 	alx_write_mem32(hw, ALX_ISR, ALX_ISR_DIS);
buf : 	alx_write_mem32(hw, ALX_IMR, 0);
buf : 	alx_post_write(hw);
buf : 
buf : 	synchronize_irq(alx->hw.pdev->irq);
buf : }
buf : 
buf : static int alx_request_irq(struct alx_priv *alx)
buf : {
buf : 	struct pci_dev *pdev = alx->hw.pdev;
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	int err;
buf : 	u32 msi_ctrl;
buf : 
buf : 	msi_ctrl = (hw->imt >> 1) << ALX_MSI_RETRANS_TM_SHIFT;
buf : 
buf : 	if (!pci_enable_msi(alx->hw.pdev)) {
if (!pci_enable_msi(alx->hw.pdev)) { 
buf : 		alx->msi = true;
buf : 
buf : 		alx_write_mem32(hw, ALX_MSI_RETRANS_TIMER,
buf : 				msi_ctrl | ALX_MSI_MASK_SEL_LINE);
buf : 		err = request_irq(pdev->irq, alx_intr_msi, 0,
buf : 				  alx->dev->name, alx);
buf : 		if (!err)
if (!err) 
buf : 			goto out;
buf : 		/* fall back to legacy interrupt */
buf : 		pci_disable_msi(alx->hw.pdev);
buf : 	}
buf : 
buf : 	alx_write_mem32(hw, ALX_MSI_RETRANS_TIMER, 0);
buf : 	err = request_irq(pdev->irq, alx_intr_legacy, IRQF_SHARED,
buf : 			  alx->dev->name, alx);
buf : out:
buf : 	if (!err)
if (!err) 
buf : 		alx_config_vector_mapping(alx);
buf : 	return err;
buf : }
buf : 
buf : static void alx_free_irq(struct alx_priv *alx)
buf : {
buf : 	struct pci_dev *pdev = alx->hw.pdev;
buf : 
buf : 	free_irq(pdev->irq, alx);
buf : 
buf : 	if (alx->msi) {
if (alx->msi) { 
buf : 		pci_disable_msi(alx->hw.pdev);
buf : 		alx->msi = false;
buf : 	}
buf : }
buf : 
buf : static int alx_identify_hw(struct alx_priv *alx)
ify_hw(struct alx_priv *alx) 
buf : {
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	int rev = alx_hw_revision(hw);
buf : 
buf : 	if (rev > ALX_REV_C0)
if (rev > ALX_REV_C0) 
buf : 		return -EINVAL;
buf : 
buf : 	hw->max_dma_chnl = rev >= ALX_REV_B0 ? 4 : 2;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int alx_init_sw(struct alx_priv *alx)
buf : {
buf : 	struct pci_dev *pdev = alx->hw.pdev;
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	int err;
buf : 
buf : 	err = alx_identify_hw(alx);
ify_hw(alx); 
buf : 	if (err) {
buf : 		dev_err(&pdev->dev, "unrecognized chip, aborting\n");
buf : 		return err;
buf : 	}
buf : 
buf : 	alx->hw.lnk_patch =
buf : 		pdev->device == ALX_DEV_ID_AR8161 &&
buf : 		pdev->subsystem_vendor == PCI_VENDOR_ID_ATTANSIC &&
buf : 		pdev->subsystem_device == 0x0091 &&
buf : 		pdev->revision == 0;
buf : 
buf : 	hw->smb_timer = 400;
buf : 	hw->mtu = alx->dev->mtu;
buf : 	alx->rxbuf_size = ALIGN(ALX_RAW_MTU(hw->mtu), 8);
buf : 	alx->tx_ringsz = 256;
buf : 	alx->rx_ringsz = 512;
buf : 	hw->imt = 200;
buf : 	alx->int_mask = ALX_ISR_MISC;
buf : 	hw->dma_chnl = hw->max_dma_chnl;
buf : 	hw->ith_tpd = alx->tx_ringsz / 3;
buf : 	hw->link_speed = SPEED_UNKNOWN;
buf : 	hw->duplex = DUPLEX_UNKNOWN;
buf : 	hw->adv_cfg = ADVERTISED_Autoneg |
buf : 		      ADVERTISED_10baseT_Half |
buf : 		      ADVERTISED_10baseT_Full |
buf : 		      ADVERTISED_100baseT_Full |
buf : 		      ADVERTISED_100baseT_Half |
buf : 		      ADVERTISED_1000baseT_Full;
buf : 	hw->flowctrl = ALX_FC_ANEG | ALX_FC_RX | ALX_FC_TX;
buf : 
buf : 	hw->rx_ctrl = ALX_MAC_CTRL_WOLSPED_SWEN |
buf : 		      ALX_MAC_CTRL_MHASH_ALG_HI5B |
buf : 		      ALX_MAC_CTRL_BRD_EN |
buf : 		      ALX_MAC_CTRL_PCRCE |
buf : 		      ALX_MAC_CTRL_CRCE |
buf : 		      ALX_MAC_CTRL_RXFC_EN |
buf : 		      ALX_MAC_CTRL_TXFC_EN |
buf : 		      7 << ALX_MAC_CTRL_PRMBLEN_SHIFT;
buf : 
buf : 	return err;
buf : }
buf : 
buf : 
buf : static netdev_features_t alx_fix_features(struct net_device *netdev,
buf : 					  netdev_features_t features)
buf : {
buf : 	if (netdev->mtu > ALX_MAX_TSO_PKT_SIZE)
if (netdev->mtu > ALX_MAX_TSO_PKT_SIZE) 
buf : 		features &= ~(NETIF_F_TSO | NETIF_F_TSO6);
buf : 
buf : 	return features;
buf : }
buf : 
buf : static void alx_netif_stop(struct alx_priv *alx)
if_stop(struct alx_priv *alx) 
buf : {
buf : 	alx->dev->trans_start = jiffies;
buf : 	if (netif_carrier_ok(alx->dev)) {
if (netif_carrier_ok(alx->dev)) { 
buf : 		netif_carrier_off(alx->dev);
buf : 		netif_tx_disable(alx->dev);
if_tx_disable(alx->dev); 
buf : 		napi_disable(&alx->napi);
buf : 	}
buf : }
buf : 
buf : static void alx_halt(struct alx_priv *alx)
buf : {
buf : 	struct alx_hw *hw = &alx->hw;
buf : 
buf : 	alx_netif_stop(alx);
if_stop(alx); 
buf : 	hw->link_speed = SPEED_UNKNOWN;
buf : 	hw->duplex = DUPLEX_UNKNOWN;
buf : 
buf : 	alx_reset_mac(hw);
buf : 
buf : 	/* disable l0s/l1 */
buf : 	alx_enable_aspm(hw, false, false);
buf : 	alx_irq_disable(alx);
buf : 	alx_free_buffers(alx);
buf : }
buf : 
buf : static void alx_configure(struct alx_priv *alx)
buf : {
buf : 	struct alx_hw *hw = &alx->hw;
buf : 
buf : 	alx_configure_basic(hw);
buf : 	alx_disable_rss(hw);
buf : 	__alx_set_rx_mode(alx->dev);
buf : 
buf : 	alx_write_mem32(hw, ALX_MAC_CTRL, hw->rx_ctrl);
buf : }
buf : 
buf : static void alx_activate(struct alx_priv *alx)
buf : {
buf : 	/* hardware setting lost, restore it */
buf : 	alx_reinit_rings(alx);
buf : 	alx_configure(alx);
buf : 
buf : 	/* clear old interrupts */
buf : 	alx_write_mem32(&alx->hw, ALX_ISR, ~(u32)ALX_ISR_DIS);
buf : 
buf : 	alx_irq_enable(alx);
buf : 
buf : 	alx_schedule_link_check(alx);
buf : }
buf : 
buf : static void alx_reinit(struct alx_priv *alx)
buf : {
buf : 	ASSERT_RTNL();
buf : 
buf : 	alx_halt(alx);
buf : 	alx_activate(alx);
buf : }
buf : 
buf : static int alx_change_mtu(struct net_device *netdev, int mtu)
buf : {
buf : 	struct alx_priv *alx = netdev_priv(netdev);
buf : 	int max_frame = mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;
buf : 
buf : 	if ((max_frame < ALX_MIN_FRAME_SIZE) ||
if ((max_frame < ALX_MIN_FRAME_SIZE) || 
buf : 	    (max_frame > ALX_MAX_FRAME_SIZE))
buf : 		return -EINVAL;
buf : 
buf : 	if (netdev->mtu == mtu)
if (netdev->mtu == mtu) 
buf : 		return 0;
buf : 
buf : 	netdev->mtu = mtu;
buf : 	alx->hw.mtu = mtu;
buf : 	alx->rxbuf_size = mtu > ALX_DEF_RXBUF_SIZE ?
buf : 			   ALIGN(max_frame, 8) : ALX_DEF_RXBUF_SIZE;
buf : 	netdev_update_features(netdev);
buf : 	if (netif_running(netdev))
if (netif_running(netdev)) 
buf : 		alx_reinit(alx);
buf : 	return 0;
buf : }
buf : 
buf : static void alx_netif_start(struct alx_priv *alx)
if_start(struct alx_priv *alx) 
buf : {
buf : 	netif_tx_wake_all_queues(alx->dev);
buf : 	napi_enable(&alx->napi);
buf : 	netif_carrier_on(alx->dev);
if_carrier_on(alx->dev); 
buf : }
buf : 
buf : static int __alx_open(struct alx_priv *alx, bool resume)
buf : {
buf : 	int err;
buf : 
buf : 	if (!resume)
if (!resume) 
buf : 		netif_carrier_off(alx->dev);
buf : 
buf : 	err = alx_alloc_rings(alx);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	alx_configure(alx);
buf : 
buf : 	err = alx_request_irq(alx);
buf : 	if (err)
if (err) 
buf : 		goto out_free_rings;
buf : 
buf : 	/* clear old interrupts */
buf : 	alx_write_mem32(&alx->hw, ALX_ISR, ~(u32)ALX_ISR_DIS);
buf : 
buf : 	alx_irq_enable(alx);
buf : 
buf : 	if (!resume)
if (!resume) 
buf : 		netif_tx_start_all_queues(alx->dev);
buf : 
buf : 	alx_schedule_link_check(alx);
buf : 	return 0;
buf : 
buf : out_free_rings:
buf : 	alx_free_rings(alx);
buf : 	return err;
buf : }
buf : 
buf : static void __alx_stop(struct alx_priv *alx)
buf : {
buf : 	alx_halt(alx);
buf : 	alx_free_irq(alx);
buf : 	alx_free_rings(alx);
buf : }
buf : 
buf : static const char *alx_speed_desc(struct alx_hw *hw)
buf : {
buf : 	switch (alx_speed_to_ethadv(hw->link_speed, hw->duplex)) {
buf : 	case ADVERTISED_1000baseT_Full:
buf : 		return "1 Gbps Full";
buf : 	case ADVERTISED_100baseT_Full:
buf : 		return "100 Mbps Full";
buf : 	case ADVERTISED_100baseT_Half:
buf : 		return "100 Mbps Half";
buf : 	case ADVERTISED_10baseT_Full:
buf : 		return "10 Mbps Full";
buf : 	case ADVERTISED_10baseT_Half:
buf : 		return "10 Mbps Half";
buf : 	default:
buf : 		return "Unknown speed";
buf : 	}
buf : }
buf : 
buf : static void alx_check_link(struct alx_priv *alx)
buf : {
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	unsigned long flags;
buf : 	int old_speed;
buf : 	u8 old_duplex;
buf : 	int err;
buf : 
buf : 	/* clear PHY internal interrupt status, otherwise the main
buf : 	 * interrupt status will be asserted forever
forever 
buf : 	 */
buf : 	alx_clear_phy_intr(hw);
buf : 
buf : 	old_speed = hw->link_speed;
buf : 	old_duplex = hw->duplex;
buf : 	err = alx_read_phy_link(hw);
buf : 	if (err < 0)
if (err < 0) 
buf : 		goto reset;
buf : 
buf : 	spin_lock_irqsave(&alx->irq_lock, flags);
buf : 	alx->int_mask |= ALX_ISR_PHY;
buf : 	alx_write_mem32(hw, ALX_IMR, alx->int_mask);
buf : 	spin_unlock_irqrestore(&alx->irq_lock, flags);
buf : 
buf : 	if (old_speed == hw->link_speed)
if (old_speed == hw->link_speed) 
buf : 		return;
buf : 
buf : 	if (hw->link_speed != SPEED_UNKNOWN) {
if (hw->link_speed != SPEED_UNKNOWN) { 
buf : 		netif_info(alx, link, alx->dev,
buf : 			   "NIC Up: %s\n", alx_speed_desc(hw));
buf : 		alx_post_phy_link(hw);
buf : 		alx_enable_aspm(hw, true, true);
buf : 		alx_start_mac(hw);
buf : 
buf : 		if (old_speed == SPEED_UNKNOWN)
if (old_speed == SPEED_UNKNOWN) 
buf : 			alx_netif_start(alx);
buf : 	} else {
buf : 		/* link is now down */
buf : 		alx_netif_stop(alx);
if_stop(alx); 
buf : 		netif_info(alx, link, alx->dev, "Link Down\n");
buf : 		err = alx_reset_mac(hw);
buf : 		if (err)
if (err) 
buf : 			goto reset;
buf : 		alx_irq_disable(alx);
buf : 
buf : 		/* MAC reset causes all HW settings to be lost, restore all */
buf : 		err = alx_reinit_rings(alx);
buf : 		if (err)
if (err) 
buf : 			goto reset;
buf : 		alx_configure(alx);
buf : 		alx_enable_aspm(hw, false, true);
buf : 		alx_post_phy_link(hw);
buf : 		alx_irq_enable(alx);
buf : 	}
buf : 
buf : 	return;
buf : 
buf : reset:
buf : 	alx_schedule_reset(alx);
buf : }
buf : 
buf : static int alx_open(struct net_device *netdev)
buf : {
buf : 	return __alx_open(netdev_priv(netdev), false);
buf : }
buf : 
buf : static int alx_stop(struct net_device *netdev)
buf : {
buf : 	__alx_stop(netdev_priv(netdev));
buf : 	return 0;
buf : }
buf : 
buf : static void alx_link_check(struct work_struct *work)
buf : {
buf : 	struct alx_priv *alx;
buf : 
buf : 	alx = container_of(work, struct alx_priv, link_check_wk);
buf : 
buf : 	rtnl_lock();
buf : 	alx_check_link(alx);
buf : 	rtnl_unlock();
buf : }
buf : 
buf : static void alx_reset(struct work_struct *work)
buf : {
buf : 	struct alx_priv *alx = container_of(work, struct alx_priv, reset_wk);
buf : 
buf : 	rtnl_lock();
buf : 	alx_reinit(alx);
buf : 	rtnl_unlock();
buf : }
buf : 
buf : static int alx_tx_csum(struct sk_buff *skb, struct alx_txd *first)
buf : {
buf : 	u8 cso, css;
buf : 
buf : 	if (skb->ip_summed != CHECKSUM_PARTIAL)
if (skb->ip_summed != CHECKSUM_PARTIAL) 
buf : 		return 0;
buf : 
buf : 	cso = skb_checksum_start_offset(skb);
buf : 	if (cso & 1)
if (cso & 1) 
buf : 		return -EINVAL;
buf : 
buf : 	css = cso + skb->csum_offset;
buf : 	first->word1 |= cpu_to_le32((cso >> 1) << TPD_CXSUMSTART_SHIFT);
buf : 	first->word1 |= cpu_to_le32((css >> 1) << TPD_CXSUMOFFSET_SHIFT);
buf : 	first->word1 |= cpu_to_le32(1 << TPD_CXSUM_EN_SHIFT);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int alx_map_tx_skb(struct alx_priv *alx, struct sk_buff *skb)
buf : {
buf : 	struct alx_tx_queue *txq = &alx->txq;
buf : 	struct alx_txd *tpd, *first_tpd;
buf : 	dma_addr_t dma;
buf : 	int maplen, f, first_idx = txq->write_idx;
buf : 
buf : 	first_tpd = &txq->tpd[txq->write_idx];
buf : 	tpd = first_tpd;
buf : 
buf : 	maplen = skb_headlen(skb);
buf : 	dma = dma_map_single(&alx->hw.pdev->dev, skb->data, maplen,
buf : 			     DMA_TO_DEVICE);
buf : 	if (dma_mapping_error(&alx->hw.pdev->dev, dma))
if (dma_mapping_error(&alx->hw.pdev->dev, dma)) 
buf : 		goto err_dma;
buf : 
buf : 	dma_unmap_len_set(&txq->bufs[txq->write_idx], size, maplen);
buf : 	dma_unmap_addr_set(&txq->bufs[txq->write_idx], dma, dma);
buf : 
buf : 	tpd->adrl.addr = cpu_to_le64(dma);
buf : 	tpd->len = cpu_to_le16(maplen);
buf : 
buf : 	for (f = 0; f < skb_shinfo(skb)->nr_frags; f++) {
for (f = 0; f < skb_shinfo(skb)->nr_frags; f++) { 
buf : 		struct skb_frag_struct *frag;
buf : 
buf : 		frag = &skb_shinfo(skb)->frags[f];
buf : 
buf : 		if (++txq->write_idx == alx->tx_ringsz)
if (++txq->write_idx == alx->tx_ringsz) 
buf : 			txq->write_idx = 0;
buf : 		tpd = &txq->tpd[txq->write_idx];
buf : 
buf : 		tpd->word1 = first_tpd->word1;
buf : 
buf : 		maplen = skb_frag_size(frag);
buf : 		dma = skb_frag_dma_map(&alx->hw.pdev->dev, frag, 0,
buf : 				       maplen, DMA_TO_DEVICE);
buf : 		if (dma_mapping_error(&alx->hw.pdev->dev, dma))
if (dma_mapping_error(&alx->hw.pdev->dev, dma)) 
buf : 			goto err_dma;
buf : 		dma_unmap_len_set(&txq->bufs[txq->write_idx], size, maplen);
buf : 		dma_unmap_addr_set(&txq->bufs[txq->write_idx], dma, dma);
buf : 
buf : 		tpd->adrl.addr = cpu_to_le64(dma);
buf : 		tpd->len = cpu_to_le16(maplen);
buf : 	}
buf : 
buf : 	/* last TPD, set EOP flag and store skb */
buf : 	tpd->word1 |= cpu_to_le32(1 << TPD_EOP_SHIFT);
buf : 	txq->bufs[txq->write_idx].skb = skb;
buf : 
buf : 	if (++txq->write_idx == alx->tx_ringsz)
if (++txq->write_idx == alx->tx_ringsz) 
buf : 		txq->write_idx = 0;
buf : 
buf : 	return 0;
buf : 
buf : err_dma:
buf : 	f = first_idx;
buf : 	while (f != txq->write_idx) {
while (f != txq->write_idx) { 
buf : 		alx_free_txbuf(alx, f);
buf : 		if (++f == alx->tx_ringsz)
if (++f == alx->tx_ringsz) 
buf : 			f = 0;
buf : 	}
buf : 	return -ENOMEM;
buf : }
buf : 
buf : static netdev_tx_t alx_start_xmit(struct sk_buff *skb,
buf : 				  struct net_device *netdev)
buf : {
buf : 	struct alx_priv *alx = netdev_priv(netdev);
buf : 	struct alx_tx_queue *txq = &alx->txq;
buf : 	struct alx_txd *first;
buf : 	int tpdreq = skb_shinfo(skb)->nr_frags + 1;
buf : 
buf : 	if (alx_tpd_avail(alx) < tpdreq) {
if (alx_tpd_avail(alx) < tpdreq) { 
buf : 		netif_stop_queue(alx->dev);
buf : 		goto drop;
buf : 	}
buf : 
buf : 	first = &txq->tpd[txq->write_idx];
buf : 	memset(first, 0, sizeof(*first));
buf : 
buf : 	if (alx_tx_csum(skb, first))
if (alx_tx_csum(skb, first)) 
buf : 		goto drop;
buf : 
buf : 	if (alx_map_tx_skb(alx, skb) < 0)
if (alx_map_tx_skb(alx, skb) < 0) 
buf : 		goto drop;
buf : 
buf : 	netdev_sent_queue(alx->dev, skb->len);
buf : 
buf : 	/* flush updates before updating hardware */
fore updating hardware */ 
buf : 	wmb();
buf : 	alx_write_mem16(&alx->hw, ALX_TPD_PRI0_PIDX, txq->write_idx);
buf : 
buf : 	if (alx_tpd_avail(alx) < alx->tx_ringsz/8)
if (alx_tpd_avail(alx) < alx->tx_ringsz/8) 
buf : 		netif_stop_queue(alx->dev);
buf : 
buf : 	return NETDEV_TX_OK;
buf : 
buf : drop:
buf : 	dev_kfree_skb_any(skb);
buf : 	return NETDEV_TX_OK;
buf : }
buf : 
buf : static void alx_tx_timeout(struct net_device *dev)
buf : {
buf : 	struct alx_priv *alx = netdev_priv(dev);
buf : 
buf : 	alx_schedule_reset(alx);
buf : }
buf : 
buf : static int alx_mdio_read(struct net_device *netdev,
buf : 			 int prtad, int devad, u16 addr)
buf : {
buf : 	struct alx_priv *alx = netdev_priv(netdev);
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	u16 val;
buf : 	int err;
buf : 
buf : 	if (prtad != hw->mdio.prtad)
if (prtad != hw->mdio.prtad) 
buf : 		return -EINVAL;
buf : 
buf : 	if (devad == MDIO_DEVAD_NONE)
if (devad == MDIO_DEVAD_NONE) 
buf : 		err = alx_read_phy_reg(hw, addr, &val);
buf : 	else
buf : 		err = alx_read_phy_ext(hw, devad, addr, &val);
buf : 
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 	return val;
buf : }
buf : 
buf : static int alx_mdio_write(struct net_device *netdev,
buf : 			  int prtad, int devad, u16 addr, u16 val)
buf : {
buf : 	struct alx_priv *alx = netdev_priv(netdev);
buf : 	struct alx_hw *hw = &alx->hw;
buf : 
buf : 	if (prtad != hw->mdio.prtad)
if (prtad != hw->mdio.prtad) 
buf : 		return -EINVAL;
buf : 
buf : 	if (devad == MDIO_DEVAD_NONE)
if (devad == MDIO_DEVAD_NONE) 
buf : 		return alx_write_phy_reg(hw, addr, val);
buf : 
buf : 	return alx_write_phy_ext(hw, devad, addr, val);
buf : }
buf : 
buf : static int alx_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)
ifreq *ifr, int cmd) 
buf : {
buf : 	struct alx_priv *alx = netdev_priv(netdev);
buf : 
buf : 	if (!netif_running(netdev))
if (!netif_running(netdev)) 
buf : 		return -EAGAIN;
buf : 
buf : 	return mdio_mii_ioctl(&alx->hw.mdio, if_mii(ifr), cmd);
if_mii(ifr), cmd); 
buf : }
buf : 
buf : #ifdef CONFIG_NET_POLL_CONTROLLER
buf : static void alx_poll_controller(struct net_device *netdev)
buf : {
buf : 	struct alx_priv *alx = netdev_priv(netdev);
buf : 
buf : 	if (alx->msi)
if (alx->msi) 
buf : 		alx_intr_msi(0, alx);
buf : 	else
buf : 		alx_intr_legacy(0, alx);
buf : }
buf : #endif
if 
buf : 
buf : static struct rtnl_link_stats64 *alx_get_stats64(struct net_device *dev,
buf : 					struct rtnl_link_stats64 *net_stats)
buf : {
buf : 	struct alx_priv *alx = netdev_priv(dev);
buf : 	struct alx_hw_stats *hw_stats = &alx->hw.stats;
buf : 
buf : 	spin_lock(&alx->stats_lock);
buf : 
buf : 	alx_update_hw_stats(&alx->hw);
buf : 
buf : 	net_stats->tx_bytes   = hw_stats->tx_byte_cnt;
buf : 	net_stats->rx_bytes   = hw_stats->rx_byte_cnt;
buf : 	net_stats->multicast  = hw_stats->rx_mcast;
buf : 	net_stats->collisions = hw_stats->tx_single_col +
buf : 				hw_stats->tx_multi_col +
buf : 				hw_stats->tx_late_col +
buf : 				hw_stats->tx_abort_col;
buf : 
buf : 	net_stats->rx_errors  = hw_stats->rx_frag +
buf : 				hw_stats->rx_fcs_err +
buf : 				hw_stats->rx_len_err +
buf : 				hw_stats->rx_ov_sz +
buf : 				hw_stats->rx_ov_rrd +
buf : 				hw_stats->rx_align_err +
buf : 				hw_stats->rx_ov_rxf;
buf : 
buf : 	net_stats->rx_fifo_errors   = hw_stats->rx_ov_rxf;
ifo_errors   = hw_stats->rx_ov_rxf; 
buf : 	net_stats->rx_length_errors = hw_stats->rx_len_err;
buf : 	net_stats->rx_crc_errors    = hw_stats->rx_fcs_err;
buf : 	net_stats->rx_frame_errors  = hw_stats->rx_align_err;
buf : 	net_stats->rx_dropped       = hw_stats->rx_ov_rrd;
buf : 
buf : 	net_stats->tx_errors = hw_stats->tx_late_col +
buf : 			       hw_stats->tx_abort_col +
buf : 			       hw_stats->tx_underrun +
buf : 			       hw_stats->tx_trunc;
buf : 
buf : 	net_stats->tx_aborted_errors = hw_stats->tx_abort_col;
buf : 	net_stats->tx_fifo_errors    = hw_stats->tx_underrun;
ifo_errors    = hw_stats->tx_underrun; 
buf : 	net_stats->tx_window_errors  = hw_stats->tx_late_col;
buf : 
buf : 	net_stats->tx_packets = hw_stats->tx_ok + net_stats->tx_errors;
buf : 	net_stats->rx_packets = hw_stats->rx_ok + net_stats->rx_errors;
buf : 
buf : 	spin_unlock(&alx->stats_lock);
buf : 
buf : 	return net_stats;
buf : }
buf : 
buf : static const struct net_device_ops alx_netdev_ops = {
buf : 	.ndo_open               = alx_open,
buf : 	.ndo_stop               = alx_stop,
buf : 	.ndo_start_xmit         = alx_start_xmit,
buf : 	.ndo_get_stats64        = alx_get_stats64,
buf : 	.ndo_set_rx_mode        = alx_set_rx_mode,
buf : 	.ndo_validate_addr      = eth_validate_addr,
buf : 	.ndo_set_mac_address    = alx_set_mac_address,
buf : 	.ndo_change_mtu         = alx_change_mtu,
buf : 	.ndo_do_ioctl           = alx_ioctl,
buf : 	.ndo_tx_timeout         = alx_tx_timeout,
buf : 	.ndo_fix_features	= alx_fix_features,
buf : #ifdef CONFIG_NET_POLL_CONTROLLER
ifdef CONFIG_NET_POLL_CONTROLLER 
buf : 	.ndo_poll_controller    = alx_poll_controller,
buf : #endif
if 
buf : };
buf : 
buf : static int alx_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
buf : {
buf : 	struct net_device *netdev;
buf : 	struct alx_priv *alx;
buf : 	struct alx_hw *hw;
buf : 	bool phy_configured;
buf : 	int bars, err;
buf : 
buf : 	err = pci_enable_device_mem(pdev);
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	/* The alx chip can DMA to 64-bit addresses, but it uses a single
buf : 	 * shared register for the high 32 bits, so only a single, aligned,
for the high 32 bits, so only a single, aligned, 
buf : 	 * 4 GB physical address range can be used for descriptors.
buf : 	 */
buf : 	if (!dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64))) {
if (!dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64))) { 
buf : 		dev_dbg(&pdev->dev, "DMA to 64-BIT addresses\n");
buf : 	} else {
buf : 		err = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));
buf : 		if (err) {
if (err) { 
buf : 			dev_err(&pdev->dev, "No usable DMA config, aborting\n");
buf : 			goto out_pci_disable;
buf : 		}
buf : 	}
buf : 
buf : 	bars = pci_select_bars(pdev, IORESOURCE_MEM);
buf : 	err = pci_request_selected_regions(pdev, bars, alx_drv_name);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev,
buf : 			"pci_request_selected_regions failed(bars:%d)\n", bars);
buf : 		goto out_pci_disable;
buf : 	}
buf : 
buf : 	pci_enable_pcie_error_reporting(pdev);
buf : 	pci_set_master(pdev);
buf : 
buf : 	if (!pdev->pm_cap) {
if (!pdev->pm_cap) { 
buf : 		dev_err(&pdev->dev,
buf : 			"Can't find power management capability, aborting\n");
buf : 		err = -EIO;
buf : 		goto out_pci_release;
buf : 	}
buf : 
buf : 	netdev = alloc_etherdev(sizeof(*alx));
buf : 	if (!netdev) {
if (!netdev) { 
buf : 		err = -ENOMEM;
buf : 		goto out_pci_release;
buf : 	}
buf : 
buf : 	SET_NETDEV_DEV(netdev, &pdev->dev);
buf : 	alx = netdev_priv(netdev);
buf : 	spin_lock_init(&alx->hw.mdio_lock);
buf : 	spin_lock_init(&alx->irq_lock);
buf : 	spin_lock_init(&alx->stats_lock);
buf : 	alx->dev = netdev;
buf : 	alx->hw.pdev = pdev;
buf : 	alx->msg_enable = NETIF_MSG_LINK | NETIF_MSG_HW | NETIF_MSG_IFUP |
buf : 			  NETIF_MSG_TX_ERR | NETIF_MSG_RX_ERR | NETIF_MSG_WOL;
buf : 	hw = &alx->hw;
buf : 	pci_set_drvdata(pdev, alx);
buf : 
buf : 	hw->hw_addr = pci_ioremap_bar(pdev, 0);
buf : 	if (!hw->hw_addr) {
if (!hw->hw_addr) { 
buf : 		dev_err(&pdev->dev, "cannot map device registers\n");
buf : 		err = -EIO;
buf : 		goto out_free_netdev;
buf : 	}
buf : 
buf : 	netdev->netdev_ops = &alx_netdev_ops;
buf : 	netdev->ethtool_ops = &alx_ethtool_ops;
buf : 	netdev->irq = pdev->irq;
buf : 	netdev->watchdog_timeo = ALX_WATCHDOG_TIME;
buf : 
buf : 	if (ent->driver_data & ALX_DEV_QUIRK_MSI_INTX_DISABLE_BUG)
if (ent->driver_data & ALX_DEV_QUIRK_MSI_INTX_DISABLE_BUG) 
buf : 		pdev->dev_flags |= PCI_DEV_FLAGS_MSI_INTX_DISABLE_BUG;
buf : 
buf : 	err = alx_init_sw(alx);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "net device private data init failed\n");
buf : 		goto out_unmap;
buf : 	}
buf : 
buf : 	alx_reset_pcie(hw);
buf : 
buf : 	phy_configured = alx_phy_configured(hw);
buf : 
buf : 	if (!phy_configured)
if (!phy_configured) 
buf : 		alx_reset_phy(hw);
buf : 
buf : 	err = alx_reset_mac(hw);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "MAC Reset failed, error = %d\n", err);
buf : 		goto out_unmap;
buf : 	}
buf : 
buf : 	/* setup link to put it in a known good starting state */
buf : 	if (!phy_configured) {
if (!phy_configured) { 
buf : 		err = alx_setup_speed_duplex(hw, hw->adv_cfg, hw->flowctrl);
buf : 		if (err) {
if (err) { 
buf : 			dev_err(&pdev->dev,
buf : 				"failed to configure PHY speed/duplex (err=%d)\n",
buf : 				err);
buf : 			goto out_unmap;
buf : 		}
buf : 	}
buf : 
buf : 	netdev->hw_features = NETIF_F_SG | NETIF_F_HW_CSUM;
buf : 
buf : 	if (alx_get_perm_macaddr(hw, hw->perm_addr)) {
if (alx_get_perm_macaddr(hw, hw->perm_addr)) { 
buf : 		dev_warn(&pdev->dev,
buf : 			 "Invalid permanent address programmed, using random one\n");
buf : 		eth_hw_addr_random(netdev);
buf : 		memcpy(hw->perm_addr, netdev->dev_addr, netdev->addr_len);
buf : 	}
buf : 
buf : 	memcpy(hw->mac_addr, hw->perm_addr, ETH_ALEN);
buf : 	memcpy(netdev->dev_addr, hw->mac_addr, ETH_ALEN);
buf : 	memcpy(netdev->perm_addr, hw->perm_addr, ETH_ALEN);
buf : 
buf : 	hw->mdio.prtad = 0;
buf : 	hw->mdio.mmds = 0;
buf : 	hw->mdio.dev = netdev;
buf : 	hw->mdio.mode_support = MDIO_SUPPORTS_C45 |
buf : 				MDIO_SUPPORTS_C22 |
buf : 				MDIO_EMULATE_C22;
buf : 	hw->mdio.mdio_read = alx_mdio_read;
buf : 	hw->mdio.mdio_write = alx_mdio_write;
buf : 
buf : 	if (!alx_get_phy_info(hw)) {
if (!alx_get_phy_info(hw)) { 
buf : 		dev_err(&pdev->dev, "failed to identify PHY\n");
buf : 		err = -EIO;
buf : 		goto out_unmap;
buf : 	}
buf : 
buf : 	INIT_WORK(&alx->link_check_wk, alx_link_check);
buf : 	INIT_WORK(&alx->reset_wk, alx_reset);
buf : 	netif_carrier_off(netdev);
if_carrier_off(netdev); 
buf : 
buf : 	err = register_netdev(netdev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "register netdevice failed\n");
buf : 		goto out_unmap;
buf : 	}
buf : 
buf : 	netdev_info(netdev,
buf : 		    "Qualcomm Atheros AR816x/AR817x Ethernet [%pM]\n",
buf : 		    netdev->dev_addr);
buf : 
buf : 	return 0;
buf : 
buf : out_unmap:
buf : 	iounmap(hw->hw_addr);
buf : out_free_netdev:
buf : 	free_netdev(netdev);
buf : out_pci_release:
buf : 	pci_release_selected_regions(pdev, bars);
buf : out_pci_disable:
buf : 	pci_disable_device(pdev);
buf : 	return err;
buf : }
buf : 
buf : static void alx_remove(struct pci_dev *pdev)
buf : {
buf : 	struct alx_priv *alx = pci_get_drvdata(pdev);
buf : 	struct alx_hw *hw = &alx->hw;
buf : 
buf : 	cancel_work_sync(&alx->link_check_wk);
buf : 	cancel_work_sync(&alx->reset_wk);
buf : 
buf : 	/* restore permanent mac address */
buf : 	alx_set_macaddr(hw, hw->perm_addr);
buf : 
buf : 	unregister_netdev(alx->dev);
buf : 	iounmap(hw->hw_addr);
buf : 	pci_release_selected_regions(pdev,
buf : 				     pci_select_bars(pdev, IORESOURCE_MEM));
buf : 
buf : 	pci_disable_pcie_error_reporting(pdev);
buf : 	pci_disable_device(pdev);
buf : 
buf : 	free_netdev(alx->dev);
buf : }
buf : 
buf : #ifdef CONFIG_PM_SLEEP
ifdef CONFIG_PM_SLEEP 
buf : static int alx_suspend(struct device *dev)
buf : {
buf : 	struct pci_dev *pdev = to_pci_dev(dev);
buf : 	struct alx_priv *alx = pci_get_drvdata(pdev);
buf : 
buf : 	if (!netif_running(alx->dev))
if (!netif_running(alx->dev)) 
buf : 		return 0;
buf : 	netif_device_detach(alx->dev);
if_device_detach(alx->dev); 
buf : 	__alx_stop(alx);
buf : 	return 0;
buf : }
buf : 
buf : static int alx_resume(struct device *dev)
buf : {
buf : 	struct pci_dev *pdev = to_pci_dev(dev);
buf : 	struct alx_priv *alx = pci_get_drvdata(pdev);
buf : 	struct alx_hw *hw = &alx->hw;
buf : 
buf : 	alx_reset_phy(hw);
buf : 
buf : 	if (!netif_running(alx->dev))
if (!netif_running(alx->dev)) 
buf : 		return 0;
buf : 	netif_device_attach(alx->dev);
if_device_attach(alx->dev); 
buf : 	return __alx_open(alx, true);
buf : }
buf : 
buf : static SIMPLE_DEV_PM_OPS(alx_pm_ops, alx_suspend, alx_resume);
buf : #define ALX_PM_OPS      (&alx_pm_ops)
buf : #else
buf : #define ALX_PM_OPS      NULL
buf : #endif
if 
buf : 
buf : 
buf : static pci_ers_result_t alx_pci_error_detected(struct pci_dev *pdev,
buf : 					       pci_channel_state_t state)
buf : {
buf : 	struct alx_priv *alx = pci_get_drvdata(pdev);
buf : 	struct net_device *netdev = alx->dev;
buf : 	pci_ers_result_t rc = PCI_ERS_RESULT_NEED_RESET;
buf : 
buf : 	dev_info(&pdev->dev, "pci error detected\n");
buf : 
buf : 	rtnl_lock();
buf : 
buf : 	if (netif_running(netdev)) {
if (netif_running(netdev)) { 
buf : 		netif_device_detach(netdev);
buf : 		alx_halt(alx);
buf : 	}
buf : 
buf : 	if (state == pci_channel_io_perm_failure)
if (state == pci_channel_io_perm_failure) 
buf : 		rc = PCI_ERS_RESULT_DISCONNECT;
buf : 	else
buf : 		pci_disable_device(pdev);
buf : 
buf : 	rtnl_unlock();
buf : 
buf : 	return rc;
buf : }
buf : 
buf : static pci_ers_result_t alx_pci_error_slot_reset(struct pci_dev *pdev)
buf : {
buf : 	struct alx_priv *alx = pci_get_drvdata(pdev);
buf : 	struct alx_hw *hw = &alx->hw;
buf : 	pci_ers_result_t rc = PCI_ERS_RESULT_DISCONNECT;
buf : 
buf : 	dev_info(&pdev->dev, "pci error slot reset\n");
buf : 
buf : 	rtnl_lock();
buf : 
buf : 	if (pci_enable_device(pdev)) {
if (pci_enable_device(pdev)) { 
buf : 		dev_err(&pdev->dev, "Failed to re-enable PCI device after reset\n");
buf : 		goto out;
buf : 	}
buf : 
buf : 	pci_set_master(pdev);
buf : 
buf : 	alx_reset_pcie(hw);
buf : 	if (!alx_reset_mac(hw))
if (!alx_reset_mac(hw)) 
buf : 		rc = PCI_ERS_RESULT_RECOVERED;
buf : out:
buf : 	pci_cleanup_aer_uncorrect_error_status(pdev);
buf : 
buf : 	rtnl_unlock();
buf : 
buf : 	return rc;
buf : }
buf : 
buf : static void alx_pci_error_resume(struct pci_dev *pdev)
buf : {
buf : 	struct alx_priv *alx = pci_get_drvdata(pdev);
buf : 	struct net_device *netdev = alx->dev;
buf : 
buf : 	dev_info(&pdev->dev, "pci error resume\n");
buf : 
buf : 	rtnl_lock();
buf : 
buf : 	if (netif_running(netdev)) {
if (netif_running(netdev)) { 
buf : 		alx_activate(alx);
buf : 		netif_device_attach(netdev);
if_device_attach(netdev); 
buf : 	}
buf : 
buf : 	rtnl_unlock();
buf : }
buf : 
buf : static const struct pci_error_handlers alx_err_handlers = {
buf : 	.error_detected = alx_pci_error_detected,
buf : 	.slot_reset     = alx_pci_error_slot_reset,
buf : 	.resume         = alx_pci_error_resume,
buf : };
buf : 
buf : static DEFINE_PCI_DEVICE_TABLE(alx_pci_tbl) = {
buf : 	{ PCI_VDEVICE(ATTANSIC, ALX_DEV_ID_AR8161),
buf : 	  .driver_data = ALX_DEV_QUIRK_MSI_INTX_DISABLE_BUG },
buf : 	{ PCI_VDEVICE(ATTANSIC, ALX_DEV_ID_E2200),
buf : 	  .driver_data = ALX_DEV_QUIRK_MSI_INTX_DISABLE_BUG },
buf : 	{ PCI_VDEVICE(ATTANSIC, ALX_DEV_ID_AR8162),
buf : 	  .driver_data = ALX_DEV_QUIRK_MSI_INTX_DISABLE_BUG },
buf : 	{ PCI_VDEVICE(ATTANSIC, ALX_DEV_ID_AR8171) },
buf : 	{ PCI_VDEVICE(ATTANSIC, ALX_DEV_ID_AR8172) },
buf : 	{}
buf : };
buf : 
buf : static struct pci_driver alx_driver = {
buf : 	.name        = alx_drv_name,
buf : 	.id_table    = alx_pci_tbl,
buf : 	.probe       = alx_probe,
buf : 	.remove      = alx_remove,
buf : 	.err_handler = &alx_err_handlers,
buf : 	.driver.pm   = ALX_PM_OPS,
buf : };
buf : 
buf : module_pci_driver(alx_driver);
buf : MODULE_DEVICE_TABLE(pci, alx_pci_tbl);
buf : MODULE_AUTHOR("Johannes Berg <johannes@sipsolutions.net>");
buf : MODULE_AUTHOR("Qualcomm Corporation, <nic-devel@qualcomm.com>");
buf : MODULE_DESCRIPTION(
buf : 	"Qualcomm Atheros(R) AR816x/AR817x PCI-E Ethernet Network Driver");
buf : MODULE_LICENSE("GPL");
file : ./test/kernel/drivers/net/ethernet/mellanox/mlx5/core/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
buf :  *
buf :  * This software is available to you under a choice of one of two
buf :  * licenses.  You may choose to be licensed under the terms of the GNU
buf :  * General Public License (GPL) Version 2, available from the file
buf :  * COPYING in the main directory of this source tree, or the
buf :  * OpenIB.org BSD license below:
buf :  *
buf :  *     Redistribution and use in source and binary forms, with or
forms, with or 
buf :  *     without modification, are permitted provided that the following
buf :  *     conditions are met:
buf :  *
buf :  *      - Redistributions of source code must retain the above
buf :  *        copyright notice, this list of conditions and the following
buf :  *        disclaimer.
buf :  *
buf :  *      - Redistributions in binary form must reproduce the above
form must reproduce the above 
buf :  *        copyright notice, this list of conditions and the following
buf :  *        disclaimer in the documentation and/or other materials
buf :  *        provided with the distribution.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
buf :  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
buf :  * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
buf :  * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
buf :  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
buf :  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
buf :  * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
buf :  * SOFTWARE.
buf :  */
buf : 
buf : #include <asm-generic/kmap_types.h>
buf : #include <linux/module.h>
buf : #include <linux/init.h>
buf : #include <linux/errno.h>
buf : #include <linux/pci.h>
buf : #include <linux/dma-mapping.h>
buf : #include <linux/slab.h>
buf : #include <linux/io-mapping.h>
buf : #include <linux/mlx5/driver.h>
buf : #include <linux/mlx5/cq.h>
buf : #include <linux/mlx5/qp.h>
buf : #include <linux/mlx5/srq.h>
buf : #include <linux/debugfs.h>
buf : #include "mlx5_core.h"
buf : 
buf : #define DRIVER_NAME "mlx5_core"
buf : #define DRIVER_VERSION "2.2-1"
buf : #define DRIVER_RELDATE	"Feb 2014"
buf : 
buf : MODULE_AUTHOR("Eli Cohen <eli@mellanox.com>");
buf : MODULE_DESCRIPTION("Mellanox ConnectX-IB HCA core library");
buf : MODULE_LICENSE("Dual BSD/GPL");
buf : MODULE_VERSION(DRIVER_VERSION);
buf : 
buf : int mlx5_core_debug_mask;
buf : module_param_named(debug_mask, mlx5_core_debug_mask, int, 0644);
buf : MODULE_PARM_DESC(debug_mask, "debug mask: 1 = dump cmd data, 2 = dump cmd exec time, 3 = both. Default=0");
buf : 
buf : struct workqueue_struct *mlx5_core_wq;
buf : 
buf : static int set_dma_caps(struct pci_dev *pdev)
buf : {
buf : 	int err;
buf : 
buf : 	err = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));
buf : 	if (err) {
if (err) { 
buf : 		dev_warn(&pdev->dev, "Warning: couldn't set 64-bit PCI DMA mask\n");
buf : 		err = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
buf : 		if (err) {
if (err) { 
buf : 			dev_err(&pdev->dev, "Can't set PCI DMA mask, aborting\n");
buf : 			return err;
buf : 		}
buf : 	}
buf : 
buf : 	err = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));
buf : 	if (err) {
if (err) { 
buf : 		dev_warn(&pdev->dev,
buf : 			 "Warning: couldn't set 64-bit consistent PCI DMA mask\n");
buf : 		err = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
buf : 		if (err) {
if (err) { 
buf : 			dev_err(&pdev->dev,
buf : 				"Can't set consistent PCI DMA mask, aborting\n");
buf : 			return err;
buf : 		}
buf : 	}
buf : 
buf : 	dma_set_max_seg_size(&pdev->dev, 2u * 1024 * 1024 * 1024);
buf : 	return err;
buf : }
buf : 
buf : static int request_bar(struct pci_dev *pdev)
buf : {
buf : 	int err = 0;
buf : 
buf : 	if (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {
if (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) { 
buf : 		dev_err(&pdev->dev, "Missing registers BAR, aborting\n");
buf : 		return -ENODEV;
buf : 	}
buf : 
buf : 	err = pci_request_regions(pdev, DRIVER_NAME);
buf : 	if (err)
if (err) 
buf : 		dev_err(&pdev->dev, "Couldn't get PCI resources, aborting\n");
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void release_bar(struct pci_dev *pdev)
buf : {
buf : 	pci_release_regions(pdev);
buf : }
buf : 
buf : static int mlx5_enable_msix(struct mlx5_core_dev *dev)
buf : {
buf : 	struct mlx5_eq_table *table = &dev->priv.eq_table;
buf : 	int num_eqs = 1 << dev->caps.log_max_eq;
buf : 	int nvec;
buf : 	int i;
buf : 
buf : 	nvec = dev->caps.num_ports * num_online_cpus() + MLX5_EQ_VEC_COMP_BASE;
buf : 	nvec = min_t(int, nvec, num_eqs);
buf : 	if (nvec <= MLX5_EQ_VEC_COMP_BASE)
if (nvec <= MLX5_EQ_VEC_COMP_BASE) 
buf : 		return -ENOMEM;
buf : 
buf : 	table->msix_arr = kzalloc(nvec * sizeof(*table->msix_arr), GFP_KERNEL);
buf : 	if (!table->msix_arr)
if (!table->msix_arr) 
buf : 		return -ENOMEM;
buf : 
buf : 	for (i = 0; i < nvec; i++)
for (i = 0; i < nvec; i++) 
buf : 		table->msix_arr[i].entry = i;
buf : 
buf : 	nvec = pci_enable_msix_range(dev->pdev, table->msix_arr,
buf : 				     MLX5_EQ_VEC_COMP_BASE, nvec);
buf : 	if (nvec < 0)
if (nvec < 0) 
buf : 		return nvec;
buf : 
buf : 	table->num_comp_vectors = nvec - MLX5_EQ_VEC_COMP_BASE;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void mlx5_disable_msix(struct mlx5_core_dev *dev)
buf : {
buf : 	struct mlx5_eq_table *table = &dev->priv.eq_table;
buf : 
buf : 	pci_disable_msix(dev->pdev);
buf : 	kfree(table->msix_arr);
buf : }
buf : 
buf : struct mlx5_reg_host_endianess {
buf : 	u8	he;
buf : 	u8      rsvd[15];
buf : };
buf : 
buf : 
buf : #define CAP_MASK(pos, size) ((u64)((1 << (size)) - 1) << (pos))
buf : 
buf : enum {
buf : 	MLX5_CAP_BITS_RW_MASK	= CAP_MASK(MLX5_CAP_OFF_CMDIF_CSUM, 2) |
buf : 				  CAP_MASK(MLX5_CAP_OFF_DCT, 1),
buf : };
buf : 
buf : /* selectively copy writable fields clearing any reserved area
buf :  */
buf : static void copy_rw_fields(struct mlx5_hca_cap *to, struct mlx5_hca_cap *from)
buf : {
buf : 	u64 v64;
buf : 
buf : 	to->log_max_qp = from->log_max_qp & 0x1f;
buf : 	to->log_max_ra_req_dc = from->log_max_ra_req_dc & 0x3f;
buf : 	to->log_max_ra_res_dc = from->log_max_ra_res_dc & 0x3f;
buf : 	to->log_max_ra_req_qp = from->log_max_ra_req_qp & 0x3f;
buf : 	to->log_max_ra_res_qp = from->log_max_ra_res_qp & 0x3f;
buf : 	to->log_max_atomic_size_qp = from->log_max_atomic_size_qp;
buf : 	to->log_max_atomic_size_dc = from->log_max_atomic_size_dc;
buf : 	v64 = be64_to_cpu(from->flags) & MLX5_CAP_BITS_RW_MASK;
buf : 	to->flags = cpu_to_be64(v64);
buf : }
buf : 
buf : enum {
buf : 	HCA_CAP_OPMOD_GET_MAX	= 0,
buf : 	HCA_CAP_OPMOD_GET_CUR	= 1,
buf : };
buf : 
buf : static int handle_hca_cap(struct mlx5_core_dev *dev)
buf : {
buf : 	struct mlx5_cmd_query_hca_cap_mbox_out *query_out = NULL;
buf : 	struct mlx5_cmd_set_hca_cap_mbox_in *set_ctx = NULL;
buf : 	struct mlx5_cmd_query_hca_cap_mbox_in query_ctx;
buf : 	struct mlx5_cmd_set_hca_cap_mbox_out set_out;
buf : 	u64 flags;
buf : 	int err;
buf : 
buf : 	memset(&query_ctx, 0, sizeof(query_ctx));
buf : 	query_out = kzalloc(sizeof(*query_out), GFP_KERNEL);
buf : 	if (!query_out)
if (!query_out) 
buf : 		return -ENOMEM;
buf : 
buf : 	set_ctx = kzalloc(sizeof(*set_ctx), GFP_KERNEL);
buf : 	if (!set_ctx) {
if (!set_ctx) { 
buf : 		err = -ENOMEM;
buf : 		goto query_ex;
buf : 	}
buf : 
buf : 	query_ctx.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_HCA_CAP);
buf : 	query_ctx.hdr.opmod  = cpu_to_be16(HCA_CAP_OPMOD_GET_CUR);
buf : 	err = mlx5_cmd_exec(dev, &query_ctx, sizeof(query_ctx),
buf : 				 query_out, sizeof(*query_out));
buf : 	if (err)
if (err) 
buf : 		goto query_ex;
buf : 
buf : 	err = mlx5_cmd_status_to_err(&query_out->hdr);
buf : 	if (err) {
if (err) { 
buf : 		mlx5_core_warn(dev, "query hca cap failed, %d\n", err);
buf : 		goto query_ex;
buf : 	}
buf : 
buf : 	copy_rw_fields(&set_ctx->hca_cap, &query_out->hca_cap);
buf : 
buf : 	if (dev->profile->mask & MLX5_PROF_MASK_QP_SIZE)
if (dev->profile->mask & MLX5_PROF_MASK_QP_SIZE) 
buf : 		set_ctx->hca_cap.log_max_qp = dev->profile->log_max_qp;
buf : 
buf : 	flags = be64_to_cpu(query_out->hca_cap.flags);
buf : 	/* disable checksum */
buf : 	flags &= ~MLX5_DEV_CAP_FLAG_CMDIF_CSUM;
buf : 
buf : 	set_ctx->hca_cap.flags = cpu_to_be64(flags);
buf : 	memset(&set_out, 0, sizeof(set_out));
buf : 	set_ctx->hca_cap.log_uar_page_sz = cpu_to_be16(PAGE_SHIFT - 12);
buf : 	set_ctx->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_SET_HCA_CAP);
buf : 	err = mlx5_cmd_exec(dev, set_ctx, sizeof(*set_ctx),
buf : 				 &set_out, sizeof(set_out));
buf : 	if (err) {
if (err) { 
buf : 		mlx5_core_warn(dev, "set hca cap failed, %d\n", err);
buf : 		goto query_ex;
buf : 	}
buf : 
buf : 	err = mlx5_cmd_status_to_err(&set_out.hdr);
buf : 	if (err)
if (err) 
buf : 		goto query_ex;
buf : 
buf : query_ex:
buf : 	kfree(query_out);
buf : 	kfree(set_ctx);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static int set_hca_ctrl(struct mlx5_core_dev *dev)
buf : {
buf : 	struct mlx5_reg_host_endianess he_in;
buf : 	struct mlx5_reg_host_endianess he_out;
buf : 	int err;
buf : 
buf : 	memset(&he_in, 0, sizeof(he_in));
buf : 	he_in.he = MLX5_SET_HOST_ENDIANNESS;
buf : 	err = mlx5_core_access_reg(dev, &he_in,  sizeof(he_in),
buf : 					&he_out, sizeof(he_out),
buf : 					MLX5_REG_HOST_ENDIANNESS, 0, 1);
buf : 	return err;
buf : }
buf : 
buf : static int mlx5_core_enable_hca(struct mlx5_core_dev *dev)
buf : {
buf : 	int err;
buf : 	struct mlx5_enable_hca_mbox_in in;
buf : 	struct mlx5_enable_hca_mbox_out out;
buf : 
buf : 	memset(&in, 0, sizeof(in));
buf : 	memset(&out, 0, sizeof(out));
buf : 	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_ENABLE_HCA);
buf : 	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	if (out.hdr.status)
if (out.hdr.status) 
buf : 		return mlx5_cmd_status_to_err(&out.hdr);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int mlx5_core_disable_hca(struct mlx5_core_dev *dev)
buf : {
buf : 	int err;
buf : 	struct mlx5_disable_hca_mbox_in in;
buf : 	struct mlx5_disable_hca_mbox_out out;
buf : 
buf : 	memset(&in, 0, sizeof(in));
buf : 	memset(&out, 0, sizeof(out));
buf : 	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DISABLE_HCA);
buf : 	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
buf : 	if (err)
if (err) 
buf : 		return err;
buf : 
buf : 	if (out.hdr.status)
if (out.hdr.status) 
buf : 		return mlx5_cmd_status_to_err(&out.hdr);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int mlx5_dev_init(struct mlx5_core_dev *dev, struct pci_dev *pdev)
buf : {
buf : 	struct mlx5_priv *priv = &dev->priv;
buf : 	int err;
buf : 
buf : 	dev->pdev = pdev;
buf : 	pci_set_drvdata(dev->pdev, dev);
buf : 	strncpy(priv->name, dev_name(&pdev->dev), MLX5_MAX_NAME_LEN);
buf : 	priv->name[MLX5_MAX_NAME_LEN - 1] = 0;
buf : 
buf : 	mutex_init(&priv->pgdir_mutex);
buf : 	INIT_LIST_HEAD(&priv->pgdir_list);
buf : 	spin_lock_init(&priv->mkey_lock);
buf : 
buf : 	priv->dbg_root = debugfs_create_dir(dev_name(&pdev->dev), mlx5_debugfs_root);
buf : 	if (!priv->dbg_root)
if (!priv->dbg_root) 
buf : 		return -ENOMEM;
buf : 
buf : 	err = pci_enable_device(pdev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "Cannot enable PCI device, aborting\n");
buf : 		goto err_dbg;
buf : 	}
buf : 
buf : 	err = request_bar(pdev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "error requesting BARs, aborting\n");
buf : 		goto err_disable;
buf : 	}
buf : 
buf : 	pci_set_master(pdev);
buf : 
buf : 	err = set_dma_caps(pdev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "Failed setting DMA capabilities mask, aborting\n");
buf : 		goto err_clr_master;
buf : 	}
buf : 
buf : 	dev->iseg_base = pci_resource_start(dev->pdev, 0);
buf : 	dev->iseg = ioremap(dev->iseg_base, sizeof(*dev->iseg));
buf : 	if (!dev->iseg) {
if (!dev->iseg) { 
buf : 		err = -ENOMEM;
buf : 		dev_err(&pdev->dev, "Failed mapping initialization segment, aborting\n");
buf : 		goto err_clr_master;
buf : 	}
buf : 	dev_info(&pdev->dev, "firmware version: %d.%d.%d\n", fw_rev_maj(dev),
buf : 		 fw_rev_min(dev), fw_rev_sub(dev));
buf : 
buf : 	err = mlx5_cmd_init(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "Failed initializing command interface, aborting\n");
buf : 		goto err_unmap;
buf : 	}
buf : 
buf : 	mlx5_pagealloc_init(dev);
buf : 
buf : 	err = mlx5_core_enable_hca(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "enable hca failed\n");
buf : 		goto err_pagealloc_cleanup;
buf : 	}
buf : 
buf : 	err = mlx5_satisfy_startup_pages(dev, 1);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "failed to allocate boot pages\n");
buf : 		goto err_disable_hca;
buf : 	}
buf : 
buf : 	err = set_hca_ctrl(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "set_hca_ctrl failed\n");
buf : 		goto reclaim_boot_pages;
buf : 	}
buf : 
buf : 	err = handle_hca_cap(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "handle_hca_cap failed\n");
buf : 		goto reclaim_boot_pages;
buf : 	}
buf : 
buf : 	err = mlx5_satisfy_startup_pages(dev, 0);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "failed to allocate init pages\n");
buf : 		goto reclaim_boot_pages;
buf : 	}
buf : 
buf : 	err = mlx5_pagealloc_start(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "mlx5_pagealloc_start failed\n");
buf : 		goto reclaim_boot_pages;
buf : 	}
buf : 
buf : 	err = mlx5_cmd_init_hca(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "init hca failed\n");
buf : 		goto err_pagealloc_stop;
buf : 	}
buf : 
buf : 	mlx5_start_health_poll(dev);
buf : 
buf : 	err = mlx5_cmd_query_hca_cap(dev, &dev->caps);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "query hca failed\n");
buf : 		goto err_stop_poll;
buf : 	}
buf : 
buf : 	err = mlx5_cmd_query_adapter(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "query adapter failed\n");
buf : 		goto err_stop_poll;
buf : 	}
buf : 
buf : 	err = mlx5_enable_msix(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "enable msix failed\n");
buf : 		goto err_stop_poll;
buf : 	}
buf : 
buf : 	err = mlx5_eq_init(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "failed to initialize eq\n");
buf : 		goto disable_msix;
buf : 	}
buf : 
buf : 	err = mlx5_alloc_uuars(dev, &priv->uuari);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "Failed allocating uar, aborting\n");
buf : 		goto err_eq_cleanup;
buf : 	}
buf : 
buf : 	err = mlx5_start_eqs(dev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "Failed to start pages and async EQs\n");
buf : 		goto err_free_uar;
buf : 	}
buf : 
buf : 	MLX5_INIT_DOORBELL_LOCK(&priv->cq_uar_lock);
buf : 
buf : 	mlx5_init_cq_table(dev);
buf : 	mlx5_init_qp_table(dev);
buf : 	mlx5_init_srq_table(dev);
buf : 	mlx5_init_mr_table(dev);
buf : 
buf : 	return 0;
buf : 
buf : err_free_uar:
buf : 	mlx5_free_uuars(dev, &priv->uuari);
buf : 
buf : err_eq_cleanup:
buf : 	mlx5_eq_cleanup(dev);
buf : 
buf : disable_msix:
buf : 	mlx5_disable_msix(dev);
buf : 
buf : err_stop_poll:
buf : 	mlx5_stop_health_poll(dev);
buf : 	if (mlx5_cmd_teardown_hca(dev)) {
if (mlx5_cmd_teardown_hca(dev)) { 
buf : 		dev_err(&dev->pdev->dev, "tear_down_hca failed, skip cleanup\n");
buf : 		return err;
buf : 	}
buf : 
buf : err_pagealloc_stop:
buf : 	mlx5_pagealloc_stop(dev);
buf : 
buf : reclaim_boot_pages:
buf : 	mlx5_reclaim_startup_pages(dev);
buf : 
buf : err_disable_hca:
buf : 	mlx5_core_disable_hca(dev);
buf : 
buf : err_pagealloc_cleanup:
buf : 	mlx5_pagealloc_cleanup(dev);
buf : 	mlx5_cmd_cleanup(dev);
buf : 
buf : err_unmap:
buf : 	iounmap(dev->iseg);
buf : 
buf : err_clr_master:
buf : 	pci_clear_master(dev->pdev);
buf : 	release_bar(dev->pdev);
buf : 
buf : err_disable:
buf : 	pci_disable_device(dev->pdev);
buf : 
buf : err_dbg:
buf : 	debugfs_remove(priv->dbg_root);
buf : 	return err;
buf : }
buf : EXPORT_SYMBOL(mlx5_dev_init);
buf : 
buf : void mlx5_dev_cleanup(struct mlx5_core_dev *dev)
buf : {
buf : 	struct mlx5_priv *priv = &dev->priv;
buf : 
buf : 	mlx5_cleanup_srq_table(dev);
buf : 	mlx5_cleanup_qp_table(dev);
buf : 	mlx5_cleanup_cq_table(dev);
buf : 	mlx5_stop_eqs(dev);
buf : 	mlx5_free_uuars(dev, &priv->uuari);
buf : 	mlx5_eq_cleanup(dev);
buf : 	mlx5_disable_msix(dev);
buf : 	mlx5_stop_health_poll(dev);
buf : 	if (mlx5_cmd_teardown_hca(dev)) {
if (mlx5_cmd_teardown_hca(dev)) { 
buf : 		dev_err(&dev->pdev->dev, "tear_down_hca failed, skip cleanup\n");
buf : 		return;
buf : 	}
buf : 	mlx5_pagealloc_stop(dev);
buf : 	mlx5_reclaim_startup_pages(dev);
buf : 	mlx5_core_disable_hca(dev);
buf : 	mlx5_pagealloc_cleanup(dev);
buf : 	mlx5_cmd_cleanup(dev);
buf : 	iounmap(dev->iseg);
buf : 	pci_clear_master(dev->pdev);
buf : 	release_bar(dev->pdev);
buf : 	pci_disable_device(dev->pdev);
buf : 	debugfs_remove(priv->dbg_root);
buf : }
buf : EXPORT_SYMBOL(mlx5_dev_cleanup);
buf : 
buf : static int __init init(void)
buf : {
buf : 	int err;
buf : 
buf : 	mlx5_register_debugfs();
buf : 	mlx5_core_wq = create_singlethread_workqueue("mlx5_core_wq");
buf : 	if (!mlx5_core_wq) {
if (!mlx5_core_wq) { 
buf : 		err = -ENOMEM;
buf : 		goto err_debug;
buf : 	}
buf : 	mlx5_health_init();
buf : 
buf : 	return 0;
buf : 
buf : err_debug:
buf : 	mlx5_unregister_debugfs();
buf : 	return err;
buf : }
buf : 
buf : static void __exit cleanup(void)
buf : {
buf : 	mlx5_health_cleanup();
buf : 	destroy_workqueue(mlx5_core_wq);
buf : 	mlx5_unregister_debugfs();
buf : }
buf : 
buf : module_init(init);
buf : module_exit(cleanup);
file : ./test/kernel/drivers/net/ethernet/mellanox/mlx4/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.
buf :  * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.
buf :  * Copyright (c) 2005, 2006, 2007, 2008 Mellanox Technologies. All rights reserved.
buf :  * Copyright (c) 2006, 2007 Cisco Systems, Inc. All rights reserved.
buf :  *
buf :  * This software is available to you under a choice of one of two
buf :  * licenses.  You may choose to be licensed under the terms of the GNU
buf :  * General Public License (GPL) Version 2, available from the file
buf :  * COPYING in the main directory of this source tree, or the
buf :  * OpenIB.org BSD license below:
buf :  *
buf :  *     Redistribution and use in source and binary forms, with or
forms, with or 
buf :  *     without modification, are permitted provided that the following
buf :  *     conditions are met:
buf :  *
buf :  *      - Redistributions of source code must retain the above
buf :  *        copyright notice, this list of conditions and the following
buf :  *        disclaimer.
buf :  *
buf :  *      - Redistributions in binary form must reproduce the above
form must reproduce the above 
buf :  *        copyright notice, this list of conditions and the following
buf :  *        disclaimer in the documentation and/or other materials
buf :  *        provided with the distribution.
buf :  *
buf :  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
buf :  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
buf :  * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
buf :  * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
buf :  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
buf :  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
buf :  * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
buf :  * SOFTWARE.
buf :  */
buf : 
buf : #include <linux/module.h>
buf : #include <linux/init.h>
buf : #include <linux/errno.h>
buf : #include <linux/pci.h>
buf : #include <linux/dma-mapping.h>
buf : #include <linux/slab.h>
buf : #include <linux/io-mapping.h>
buf : #include <linux/delay.h>
buf : #include <linux/kmod.h>
buf : 
buf : #include <linux/mlx4/device.h>
buf : #include <linux/mlx4/doorbell.h>
buf : 
buf : #include "mlx4.h"
buf : #include "fw.h"
buf : #include "icm.h"
buf : 
buf : MODULE_AUTHOR("Roland Dreier");
buf : MODULE_DESCRIPTION("Mellanox ConnectX HCA low-level driver");
buf : MODULE_LICENSE("Dual BSD/GPL");
buf : MODULE_VERSION(DRV_VERSION);
buf : 
buf : struct workqueue_struct *mlx4_wq;
buf : 
buf : #ifdef CONFIG_MLX4_DEBUG
ifdef CONFIG_MLX4_DEBUG 
buf : 
buf : int mlx4_debug_level = 0;
buf : module_param_named(debug_level, mlx4_debug_level, int, 0644);
buf : MODULE_PARM_DESC(debug_level, "Enable debug tracing if > 0");
if > 0"); 
buf : 
buf : #endif /* CONFIG_MLX4_DEBUG */
buf : 
buf : #ifdef CONFIG_PCI_MSI
ifdef CONFIG_PCI_MSI 
buf : 
buf : static int msi_x = 1;
buf : module_param(msi_x, int, 0444);
buf : MODULE_PARM_DESC(msi_x, "attempt to use MSI-X if nonzero");
if nonzero"); 
buf : 
buf : #else /* CONFIG_PCI_MSI */
buf : 
buf : #define msi_x (0)
buf : 
buf : #endif /* CONFIG_PCI_MSI */
if /* CONFIG_PCI_MSI */ 
buf : 
buf : static uint8_t num_vfs[3] = {0, 0, 0};
buf : static int num_vfs_argc = 3;
buf : module_param_array(num_vfs, byte , &num_vfs_argc, 0444);
buf : MODULE_PARM_DESC(num_vfs, "enable #num_vfs functions if num_vfs > 0\n"
if num_vfs > 0\n" 
buf : 			  "num_vfs=port1,port2,port1+2");
buf : 
buf : static uint8_t probe_vf[3] = {0, 0, 0};
buf : static int probe_vfs_argc = 3;
buf : module_param_array(probe_vf, byte, &probe_vfs_argc, 0444);
buf : MODULE_PARM_DESC(probe_vf, "number of vfs to probe by pf driver (num_vfs > 0)\n"
buf : 			   "probe_vf=port1,port2,port1+2");
buf : 
buf : int mlx4_log_num_mgm_entry_size = MLX4_DEFAULT_MGM_LOG_ENTRY_SIZE;
buf : module_param_named(log_num_mgm_entry_size,
buf : 			mlx4_log_num_mgm_entry_size, int, 0444);
buf : MODULE_PARM_DESC(log_num_mgm_entry_size, "log mgm size, that defines the num"
buf : 					 " of qp per mcg, for example:"
for example:" 
buf : 					 " 10 gives 248.range: 7 <="
buf : 					 " log_num_mgm_entry_size <= 12."
buf : 					 " To activate device managed"
buf : 					 " flow steering when available, set to -1");
buf : 
buf : static bool enable_64b_cqe_eqe = true;
buf : module_param(enable_64b_cqe_eqe, bool, 0444);
buf : MODULE_PARM_DESC(enable_64b_cqe_eqe,
buf : 		 "Enable 64 byte CQEs/EQEs when the FW supports this (default: True)");
buf : 
buf : #define PF_CONTEXT_BEHAVIOUR_MASK	MLX4_FUNC_CAP_64B_EQE_CQE
buf : 
buf : static char mlx4_version[] =
buf : 	DRV_NAME ": Mellanox ConnectX core driver v"
buf : 	DRV_VERSION " (" DRV_RELDATE ")\n";
buf : 
buf : static struct mlx4_profile default_profile = {
buf : 	.num_qp		= 1 << 18,
buf : 	.num_srq	= 1 << 16,
buf : 	.rdmarc_per_qp	= 1 << 4,
buf : 	.num_cq		= 1 << 16,
buf : 	.num_mcg	= 1 << 13,
buf : 	.num_mpt	= 1 << 19,
buf : 	.num_mtt	= 1 << 20, /* It is really num mtt segements */
buf : };
buf : 
buf : static int log_num_mac = 7;
buf : module_param_named(log_num_mac, log_num_mac, int, 0444);
buf : MODULE_PARM_DESC(log_num_mac, "Log2 max number of MACs per ETH port (1-7)");
buf : 
buf : static int log_num_vlan;
buf : module_param_named(log_num_vlan, log_num_vlan, int, 0444);
buf : MODULE_PARM_DESC(log_num_vlan, "Log2 max number of VLANs per ETH port (0-7)");
buf : /* Log2 max number of VLANs per ETH port (0-7) */
buf : #define MLX4_LOG_NUM_VLANS 7
buf : 
buf : static bool use_prio;
buf : module_param_named(use_prio, use_prio, bool, 0444);
buf : MODULE_PARM_DESC(use_prio, "Enable steering by VLAN priority on ETH ports (deprecated)");
buf : 
buf : int log_mtts_per_seg = ilog2(MLX4_MTT_ENTRY_PER_SEG);
buf : module_param_named(log_mtts_per_seg, log_mtts_per_seg, int, 0444);
buf : MODULE_PARM_DESC(log_mtts_per_seg, "Log2 number of MTT entries per segment (1-7)");
buf : 
buf : static int port_type_array[2] = {MLX4_PORT_TYPE_NONE, MLX4_PORT_TYPE_NONE};
buf : static int arr_argc = 2;
buf : module_param_array(port_type_array, int, &arr_argc, 0444);
buf : MODULE_PARM_DESC(port_type_array, "Array of port types: HW_DEFAULT (0) is default "
buf : 				"1 for IB, 2 for Ethernet");
for IB, 2 for Ethernet"); 
buf : 
buf : struct mlx4_port_config {
buf : 	struct list_head list;
buf : 	enum mlx4_port_type port_type[MLX4_MAX_PORTS + 1];
buf : 	struct pci_dev *pdev;
buf : };
buf : 
buf : static atomic_t pf_loading = ATOMIC_INIT(0);
buf : 
buf : int mlx4_check_port_params(struct mlx4_dev *dev,
buf : 			   enum mlx4_port_type *port_type)
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 0; i < dev->caps.num_ports - 1; i++) {
for (i = 0; i < dev->caps.num_ports - 1; i++) { 
buf : 		if (port_type[i] != port_type[i + 1]) {
buf : 			if (!(dev->caps.flags & MLX4_DEV_CAP_FLAG_DPDP)) {
if (!(dev->caps.flags & MLX4_DEV_CAP_FLAG_DPDP)) { 
buf : 				mlx4_err(dev, "Only same port types supported on this HCA, aborting\n");
buf : 				return -EINVAL;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	for (i = 0; i < dev->caps.num_ports; i++) {
for (i = 0; i < dev->caps.num_ports; i++) { 
buf : 		if (!(port_type[i] & dev->caps.supported_type[i+1])) {
buf : 			mlx4_err(dev, "Requested port type for port %d is not supported on this HCA\n",
for port %d is not supported on this HCA\n", 
buf : 				 i + 1);
buf : 			return -EINVAL;
buf : 		}
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static void mlx4_set_port_mask(struct mlx4_dev *dev)
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 1; i <= dev->caps.num_ports; ++i)
for (i = 1; i <= dev->caps.num_ports; ++i) 
buf : 		dev->caps.port_mask[i] = dev->caps.port_type[i];
buf : }
buf : 
buf : static int mlx4_dev_cap(struct mlx4_dev *dev, struct mlx4_dev_cap *dev_cap)
buf : {
buf : 	int err;
buf : 	int i;
buf : 
buf : 	err = mlx4_QUERY_DEV_CAP(dev, dev_cap);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "QUERY_DEV_CAP command failed, aborting\n");
buf : 		return err;
buf : 	}
buf : 
buf : 	if (dev_cap->min_page_sz > PAGE_SIZE) {
if (dev_cap->min_page_sz > PAGE_SIZE) { 
buf : 		mlx4_err(dev, "HCA minimum page size of %d bigger than kernel PAGE_SIZE of %ld, aborting\n",
buf : 			 dev_cap->min_page_sz, PAGE_SIZE);
buf : 		return -ENODEV;
buf : 	}
buf : 	if (dev_cap->num_ports > MLX4_MAX_PORTS) {
if (dev_cap->num_ports > MLX4_MAX_PORTS) { 
buf : 		mlx4_err(dev, "HCA has %d ports, but we only support %d, aborting\n",
buf : 			 dev_cap->num_ports, MLX4_MAX_PORTS);
buf : 		return -ENODEV;
buf : 	}
buf : 
buf : 	if (dev_cap->uar_size > pci_resource_len(dev->pdev, 2)) {
if (dev_cap->uar_size > pci_resource_len(dev->pdev, 2)) { 
buf : 		mlx4_err(dev, "HCA reported UAR size of 0x%x bigger than PCI resource 2 size of 0x%llx, aborting\n",
buf : 			 dev_cap->uar_size,
buf : 			 (unsigned long long) pci_resource_len(dev->pdev, 2));
buf : 		return -ENODEV;
buf : 	}
buf : 
buf : 	dev->caps.num_ports	     = dev_cap->num_ports;
buf : 	dev->phys_caps.num_phys_eqs  = MLX4_MAX_EQ_NUM;
buf : 	for (i = 1; i <= dev->caps.num_ports; ++i) {
for (i = 1; i <= dev->caps.num_ports; ++i) { 
buf : 		dev->caps.vl_cap[i]	    = dev_cap->max_vl[i];
buf : 		dev->caps.ib_mtu_cap[i]	    = dev_cap->ib_mtu[i];
buf : 		dev->phys_caps.gid_phys_table_len[i]  = dev_cap->max_gids[i];
buf : 		dev->phys_caps.pkey_phys_table_len[i] = dev_cap->max_pkeys[i];
buf : 		/* set gid and pkey table operating lengths by default
buf : 		 * to non-sriov values */
buf : 		dev->caps.gid_table_len[i]  = dev_cap->max_gids[i];
buf : 		dev->caps.pkey_table_len[i] = dev_cap->max_pkeys[i];
buf : 		dev->caps.port_width_cap[i] = dev_cap->max_port_width[i];
buf : 		dev->caps.eth_mtu_cap[i]    = dev_cap->eth_mtu[i];
buf : 		dev->caps.def_mac[i]        = dev_cap->def_mac[i];
buf : 		dev->caps.supported_type[i] = dev_cap->supported_port_types[i];
buf : 		dev->caps.suggested_type[i] = dev_cap->suggested_type[i];
buf : 		dev->caps.default_sense[i] = dev_cap->default_sense[i];
buf : 		dev->caps.trans_type[i]	    = dev_cap->trans_type[i];
buf : 		dev->caps.vendor_oui[i]     = dev_cap->vendor_oui[i];
buf : 		dev->caps.wavelength[i]     = dev_cap->wavelength[i];
buf : 		dev->caps.trans_code[i]     = dev_cap->trans_code[i];
buf : 	}
buf : 
buf : 	dev->caps.uar_page_size	     = PAGE_SIZE;
buf : 	dev->caps.num_uars	     = dev_cap->uar_size / PAGE_SIZE;
buf : 	dev->caps.local_ca_ack_delay = dev_cap->local_ca_ack_delay;
buf : 	dev->caps.bf_reg_size	     = dev_cap->bf_reg_size;
buf : 	dev->caps.bf_regs_per_page   = dev_cap->bf_regs_per_page;
buf : 	dev->caps.max_sq_sg	     = dev_cap->max_sq_sg;
buf : 	dev->caps.max_rq_sg	     = dev_cap->max_rq_sg;
buf : 	dev->caps.max_wqes	     = dev_cap->max_qp_sz;
buf : 	dev->caps.max_qp_init_rdma   = dev_cap->max_requester_per_qp;
buf : 	dev->caps.max_srq_wqes	     = dev_cap->max_srq_sz;
buf : 	dev->caps.max_srq_sge	     = dev_cap->max_rq_sg - 1;
buf : 	dev->caps.reserved_srqs	     = dev_cap->reserved_srqs;
buf : 	dev->caps.max_sq_desc_sz     = dev_cap->max_sq_desc_sz;
buf : 	dev->caps.max_rq_desc_sz     = dev_cap->max_rq_desc_sz;
buf : 	/*
buf : 	 * Subtract 1 from the limit because we need to allocate a
buf : 	 * spare CQE so the HCA HW can tell the difference between an
ifference between an 
buf : 	 * empty CQ and a full CQ.
buf : 	 */
buf : 	dev->caps.max_cqes	     = dev_cap->max_cq_sz - 1;
buf : 	dev->caps.reserved_cqs	     = dev_cap->reserved_cqs;
buf : 	dev->caps.reserved_eqs	     = dev_cap->reserved_eqs;
buf : 	dev->caps.reserved_mtts      = dev_cap->reserved_mtts;
buf : 	dev->caps.reserved_mrws	     = dev_cap->reserved_mrws;
buf : 
buf : 	/* The first 128 UARs are used for EQ doorbells */
for EQ doorbells */ 
buf : 	dev->caps.reserved_uars	     = max_t(int, 128, dev_cap->reserved_uars);
buf : 	dev->caps.reserved_pds	     = dev_cap->reserved_pds;
buf : 	dev->caps.reserved_xrcds     = (dev->caps.flags & MLX4_DEV_CAP_FLAG_XRC) ?
buf : 					dev_cap->reserved_xrcds : 0;
buf : 	dev->caps.max_xrcds          = (dev->caps.flags & MLX4_DEV_CAP_FLAG_XRC) ?
buf : 					dev_cap->max_xrcds : 0;
buf : 	dev->caps.mtt_entry_sz       = dev_cap->mtt_entry_sz;
buf : 
buf : 	dev->caps.max_msg_sz         = dev_cap->max_msg_sz;
buf : 	dev->caps.page_size_cap	     = ~(u32) (dev_cap->min_page_sz - 1);
buf : 	dev->caps.flags		     = dev_cap->flags;
buf : 	dev->caps.flags2	     = dev_cap->flags2;
buf : 	dev->caps.bmme_flags	     = dev_cap->bmme_flags;
buf : 	dev->caps.reserved_lkey	     = dev_cap->reserved_lkey;
buf : 	dev->caps.stat_rate_support  = dev_cap->stat_rate_support;
buf : 	dev->caps.max_gso_sz	     = dev_cap->max_gso_sz;
buf : 	dev->caps.max_rss_tbl_sz     = dev_cap->max_rss_tbl_sz;
buf : 
buf : 	/* Sense port always allowed on supported devices for ConnectX-1 and -2 */
for ConnectX-1 and -2 */ 
buf : 	if (mlx4_priv(dev)->pci_dev_data & MLX4_PCI_DEV_FORCE_SENSE_PORT)
buf : 		dev->caps.flags |= MLX4_DEV_CAP_FLAG_SENSE_SUPPORT;
buf : 	/* Don't do sense port on multifunction devices (for now at least) */
ifunction devices (for now at least) */ 
buf : 	if (mlx4_is_mfunc(dev))
buf : 		dev->caps.flags &= ~MLX4_DEV_CAP_FLAG_SENSE_SUPPORT;
buf : 
buf : 	dev->caps.log_num_macs  = log_num_mac;
buf : 	dev->caps.log_num_vlans = MLX4_LOG_NUM_VLANS;
buf : 
buf : 	for (i = 1; i <= dev->caps.num_ports; ++i) {
for (i = 1; i <= dev->caps.num_ports; ++i) { 
buf : 		dev->caps.port_type[i] = MLX4_PORT_TYPE_NONE;
buf : 		if (dev->caps.supported_type[i]) {
if (dev->caps.supported_type[i]) { 
buf : 			/* if only ETH is supported - assign ETH */
buf : 			if (dev->caps.supported_type[i] == MLX4_PORT_TYPE_ETH)
if (dev->caps.supported_type[i] == MLX4_PORT_TYPE_ETH) 
buf : 				dev->caps.port_type[i] = MLX4_PORT_TYPE_ETH;
buf : 			/* if only IB is supported, assign IB */
if only IB is supported, assign IB */ 
buf : 			else if (dev->caps.supported_type[i] ==
buf : 				 MLX4_PORT_TYPE_IB)
buf : 				dev->caps.port_type[i] = MLX4_PORT_TYPE_IB;
buf : 			else {
buf : 				/* if IB and ETH are supported, we set the port
if IB and ETH are supported, we set the port 
buf : 				 * type according to user selection of port type;
buf : 				 * if user selected none, take the FW hint */
if user selected none, take the FW hint */ 
buf : 				if (port_type_array[i - 1] == MLX4_PORT_TYPE_NONE)
buf : 					dev->caps.port_type[i] = dev->caps.suggested_type[i] ?
buf : 						MLX4_PORT_TYPE_ETH : MLX4_PORT_TYPE_IB;
buf : 				else
buf : 					dev->caps.port_type[i] = port_type_array[i - 1];
buf : 			}
buf : 		}
buf : 		/*
buf : 		 * Link sensing is allowed on the port if 3 conditions are true:
if 3 conditions are true: 
buf : 		 * 1. Both protocols are supported on the port.
buf : 		 * 2. Different types are supported on the port
ifferent types are supported on the port 
buf : 		 * 3. FW declared that it supports link sensing
buf : 		 */
buf : 		mlx4_priv(dev)->sense.sense_allowed[i] =
buf : 			((dev->caps.supported_type[i] == MLX4_PORT_TYPE_AUTO) &&
buf : 			 (dev->caps.flags & MLX4_DEV_CAP_FLAG_DPDP) &&
buf : 			 (dev->caps.flags & MLX4_DEV_CAP_FLAG_SENSE_SUPPORT));
buf : 
buf : 		/*
buf : 		 * If "default_sense" bit is set, we move the port to "AUTO" mode
buf : 		 * and perform sense_port FW command to try and set the correct
form sense_port FW command to try and set the correct 
buf : 		 * port type from beginning
buf : 		 */
buf : 		if (mlx4_priv(dev)->sense.sense_allowed[i] && dev->caps.default_sense[i]) {
if (mlx4_priv(dev)->sense.sense_allowed[i] && dev->caps.default_sense[i]) { 
buf : 			enum mlx4_port_type sensed_port = MLX4_PORT_TYPE_NONE;
buf : 			dev->caps.possible_type[i] = MLX4_PORT_TYPE_AUTO;
buf : 			mlx4_SENSE_PORT(dev, i, &sensed_port);
buf : 			if (sensed_port != MLX4_PORT_TYPE_NONE)
if (sensed_port != MLX4_PORT_TYPE_NONE) 
buf : 				dev->caps.port_type[i] = sensed_port;
buf : 		} else {
buf : 			dev->caps.possible_type[i] = dev->caps.port_type[i];
buf : 		}
buf : 
buf : 		if (dev->caps.log_num_macs > dev_cap->log_max_macs[i]) {
if (dev->caps.log_num_macs > dev_cap->log_max_macs[i]) { 
buf : 			dev->caps.log_num_macs = dev_cap->log_max_macs[i];
buf : 			mlx4_warn(dev, "Requested number of MACs is too much for port %d, reducing to %d\n",
for port %d, reducing to %d\n", 
buf : 				  i, 1 << dev->caps.log_num_macs);
buf : 		}
buf : 		if (dev->caps.log_num_vlans > dev_cap->log_max_vlans[i]) {
if (dev->caps.log_num_vlans > dev_cap->log_max_vlans[i]) { 
buf : 			dev->caps.log_num_vlans = dev_cap->log_max_vlans[i];
buf : 			mlx4_warn(dev, "Requested number of VLANs is too much for port %d, reducing to %d\n",
for port %d, reducing to %d\n", 
buf : 				  i, 1 << dev->caps.log_num_vlans);
buf : 		}
buf : 	}
buf : 
buf : 	dev->caps.max_counters = 1 << ilog2(dev_cap->max_counters);
buf : 
buf : 	dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FW] = dev_cap->reserved_qps;
buf : 	dev->caps.reserved_qps_cnt[MLX4_QP_REGION_ETH_ADDR] =
buf : 		dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FC_ADDR] =
buf : 		(1 << dev->caps.log_num_macs) *
buf : 		(1 << dev->caps.log_num_vlans) *
buf : 		dev->caps.num_ports;
buf : 	dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FC_EXCH] = MLX4_NUM_FEXCH;
buf : 
buf : 	dev->caps.reserved_qps = dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FW] +
buf : 		dev->caps.reserved_qps_cnt[MLX4_QP_REGION_ETH_ADDR] +
buf : 		dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FC_ADDR] +
buf : 		dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FC_EXCH];
buf : 
buf : 	dev->caps.sqp_demux = (mlx4_is_master(dev)) ? MLX4_MAX_NUM_SLAVES : 0;
buf : 
buf : 	if (!enable_64b_cqe_eqe && !mlx4_is_slave(dev)) {
if (!enable_64b_cqe_eqe && !mlx4_is_slave(dev)) { 
buf : 		if (dev_cap->flags &
buf : 		    (MLX4_DEV_CAP_FLAG_64B_CQE | MLX4_DEV_CAP_FLAG_64B_EQE)) {
buf : 			mlx4_warn(dev, "64B EQEs/CQEs supported by the device but not enabled\n");
buf : 			dev->caps.flags &= ~MLX4_DEV_CAP_FLAG_64B_CQE;
buf : 			dev->caps.flags &= ~MLX4_DEV_CAP_FLAG_64B_EQE;
buf : 		}
buf : 	}
buf : 
buf : 	if ((dev->caps.flags &
if ((dev->caps.flags & 
buf : 	    (MLX4_DEV_CAP_FLAG_64B_CQE | MLX4_DEV_CAP_FLAG_64B_EQE)) &&
buf : 	    mlx4_is_master(dev))
buf : 		dev->caps.function_caps |= MLX4_FUNC_CAP_64B_EQE_CQE;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int mlx4_get_pcie_dev_link_caps(struct mlx4_dev *dev,
buf : 				       enum pci_bus_speed *speed,
buf : 				       enum pcie_link_width *width)
buf : {
buf : 	u32 lnkcap1, lnkcap2;
buf : 	int err1, err2;
buf : 
buf : #define  PCIE_MLW_CAP_SHIFT 4	/* start of MLW mask in link capabilities */
buf : 
buf : 	*speed = PCI_SPEED_UNKNOWN;
buf : 	*width = PCIE_LNK_WIDTH_UNKNOWN;
buf : 
buf : 	err1 = pcie_capability_read_dword(dev->pdev, PCI_EXP_LNKCAP, &lnkcap1);
buf : 	err2 = pcie_capability_read_dword(dev->pdev, PCI_EXP_LNKCAP2, &lnkcap2);
buf : 	if (!err2 && lnkcap2) { /* PCIe r3.0-compliant */
if (!err2 && lnkcap2) { /* PCIe r3.0-compliant */ 
buf : 		if (lnkcap2 & PCI_EXP_LNKCAP2_SLS_8_0GB)
buf : 			*speed = PCIE_SPEED_8_0GT;
buf : 		else if (lnkcap2 & PCI_EXP_LNKCAP2_SLS_5_0GB)
if (lnkcap2 & PCI_EXP_LNKCAP2_SLS_5_0GB) 
buf : 			*speed = PCIE_SPEED_5_0GT;
buf : 		else if (lnkcap2 & PCI_EXP_LNKCAP2_SLS_2_5GB)
if (lnkcap2 & PCI_EXP_LNKCAP2_SLS_2_5GB) 
buf : 			*speed = PCIE_SPEED_2_5GT;
buf : 	}
buf : 	if (!err1) {
if (!err1) { 
buf : 		*width = (lnkcap1 & PCI_EXP_LNKCAP_MLW) >> PCIE_MLW_CAP_SHIFT;
buf : 		if (!lnkcap2) { /* pre-r3.0 */
if (!lnkcap2) { /* pre-r3.0 */ 
buf : 			if (lnkcap1 & PCI_EXP_LNKCAP_SLS_5_0GB)
buf : 				*speed = PCIE_SPEED_5_0GT;
buf : 			else if (lnkcap1 & PCI_EXP_LNKCAP_SLS_2_5GB)
if (lnkcap1 & PCI_EXP_LNKCAP_SLS_2_5GB) 
buf : 				*speed = PCIE_SPEED_2_5GT;
buf : 		}
buf : 	}
buf : 
buf : 	if (*speed == PCI_SPEED_UNKNOWN || *width == PCIE_LNK_WIDTH_UNKNOWN) {
if (*speed == PCI_SPEED_UNKNOWN || *width == PCIE_LNK_WIDTH_UNKNOWN) { 
buf : 		return err1 ? err1 :
buf : 			err2 ? err2 : -EINVAL;
buf : 	}
buf : 	return 0;
buf : }
buf : 
buf : static void mlx4_check_pcie_caps(struct mlx4_dev *dev)
buf : {
buf : 	enum pcie_link_width width, width_cap;
buf : 	enum pci_bus_speed speed, speed_cap;
buf : 	int err;
buf : 
buf : #define PCIE_SPEED_STR(speed) \
buf : 	(speed == PCIE_SPEED_8_0GT ? "8.0GT/s" : \
buf : 	 speed == PCIE_SPEED_5_0GT ? "5.0GT/s" : \
buf : 	 speed == PCIE_SPEED_2_5GT ? "2.5GT/s" : \
buf : 	 "Unknown")
buf : 
buf : 	err = mlx4_get_pcie_dev_link_caps(dev, &speed_cap, &width_cap);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_warn(dev,
buf : 			  "Unable to determine PCIe device BW capabilities\n");
buf : 		return;
buf : 	}
buf : 
buf : 	err = pcie_get_minimum_link(dev->pdev, &speed, &width);
buf : 	if (err || speed == PCI_SPEED_UNKNOWN ||
if (err || speed == PCI_SPEED_UNKNOWN || 
buf : 	    width == PCIE_LNK_WIDTH_UNKNOWN) {
buf : 		mlx4_warn(dev,
buf : 			  "Unable to determine PCI device chain minimum BW\n");
buf : 		return;
buf : 	}
buf : 
buf : 	if (width != width_cap || speed != speed_cap)
if (width != width_cap || speed != speed_cap) 
buf : 		mlx4_warn(dev,
buf : 			  "PCIe BW is different than device's capability\n");
ifferent than device's capability\n"); 
buf : 
buf : 	mlx4_info(dev, "PCIe link speed is %s, device supports %s\n",
buf : 		  PCIE_SPEED_STR(speed), PCIE_SPEED_STR(speed_cap));
buf : 	mlx4_info(dev, "PCIe link width is x%d, device supports x%d\n",
buf : 		  width, width_cap);
buf : 	return;
buf : }
buf : 
buf : /*The function checks if there are live vf, return the num of them*/
if there are live vf, return the num of them*/ 
buf : static int mlx4_how_many_lives_vf(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	struct mlx4_slave_state *s_state;
buf : 	int i;
buf : 	int ret = 0;
buf : 
buf : 	for (i = 1/*the ppf is 0*/; i < dev->num_slaves; ++i) {
for (i = 1/*the ppf is 0*/; i < dev->num_slaves; ++i) { 
buf : 		s_state = &priv->mfunc.master.slave_state[i];
buf : 		if (s_state->active && s_state->last_cmd !=
if (s_state->active && s_state->last_cmd != 
buf : 		    MLX4_COMM_CMD_RESET) {
buf : 			mlx4_warn(dev, "%s: slave: %d is still active\n",
buf : 				  __func__, i);
buf : 			ret++;
buf : 		}
buf : 	}
buf : 	return ret;
buf : }
buf : 
buf : int mlx4_get_parav_qkey(struct mlx4_dev *dev, u32 qpn, u32 *qkey)
buf : {
buf : 	u32 qk = MLX4_RESERVED_QKEY_BASE;
buf : 
buf : 	if (qpn >= dev->phys_caps.base_tunnel_sqpn + 8 * MLX4_MFUNC_MAX ||
if (qpn >= dev->phys_caps.base_tunnel_sqpn + 8 * MLX4_MFUNC_MAX || 
buf : 	    qpn < dev->phys_caps.base_proxy_sqpn)
buf : 		return -EINVAL;
buf : 
buf : 	if (qpn >= dev->phys_caps.base_tunnel_sqpn)
if (qpn >= dev->phys_caps.base_tunnel_sqpn) 
buf : 		/* tunnel qp */
buf : 		qk += qpn - dev->phys_caps.base_tunnel_sqpn;
buf : 	else
buf : 		qk += qpn - dev->phys_caps.base_proxy_sqpn;
buf : 	*qkey = qk;
buf : 	return 0;
buf : }
buf : EXPORT_SYMBOL(mlx4_get_parav_qkey);
buf : 
buf : void mlx4_sync_pkey_table(struct mlx4_dev *dev, int slave, int port, int i, int val)
buf : {
buf : 	struct mlx4_priv *priv = container_of(dev, struct mlx4_priv, dev);
buf : 
buf : 	if (!mlx4_is_master(dev))
if (!mlx4_is_master(dev)) 
buf : 		return;
buf : 
buf : 	priv->virt2phys_pkey[slave][port - 1][i] = val;
buf : }
buf : EXPORT_SYMBOL(mlx4_sync_pkey_table);
buf : 
buf : void mlx4_put_slave_node_guid(struct mlx4_dev *dev, int slave, __be64 guid)
buf : {
buf : 	struct mlx4_priv *priv = container_of(dev, struct mlx4_priv, dev);
buf : 
buf : 	if (!mlx4_is_master(dev))
if (!mlx4_is_master(dev)) 
buf : 		return;
buf : 
buf : 	priv->slave_node_guids[slave] = guid;
buf : }
buf : EXPORT_SYMBOL(mlx4_put_slave_node_guid);
buf : 
buf : __be64 mlx4_get_slave_node_guid(struct mlx4_dev *dev, int slave)
buf : {
buf : 	struct mlx4_priv *priv = container_of(dev, struct mlx4_priv, dev);
buf : 
buf : 	if (!mlx4_is_master(dev))
if (!mlx4_is_master(dev)) 
buf : 		return 0;
buf : 
buf : 	return priv->slave_node_guids[slave];
buf : }
buf : EXPORT_SYMBOL(mlx4_get_slave_node_guid);
buf : 
buf : int mlx4_is_slave_active(struct mlx4_dev *dev, int slave)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	struct mlx4_slave_state *s_slave;
buf : 
buf : 	if (!mlx4_is_master(dev))
if (!mlx4_is_master(dev)) 
buf : 		return 0;
buf : 
buf : 	s_slave = &priv->mfunc.master.slave_state[slave];
buf : 	return !!s_slave->active;
buf : }
buf : EXPORT_SYMBOL(mlx4_is_slave_active);
buf : 
buf : static void slave_adjust_steering_mode(struct mlx4_dev *dev,
buf : 				       struct mlx4_dev_cap *dev_cap,
buf : 				       struct mlx4_init_hca_param *hca_param)
buf : {
buf : 	dev->caps.steering_mode = hca_param->steering_mode;
buf : 	if (dev->caps.steering_mode == MLX4_STEERING_MODE_DEVICE_MANAGED) {
if (dev->caps.steering_mode == MLX4_STEERING_MODE_DEVICE_MANAGED) { 
buf : 		dev->caps.num_qp_per_mgm = dev_cap->fs_max_num_qp_per_entry;
buf : 		dev->caps.fs_log_max_ucast_qp_range_size =
buf : 			dev_cap->fs_log_max_ucast_qp_range_size;
buf : 	} else
buf : 		dev->caps.num_qp_per_mgm =
buf : 			4 * ((1 << hca_param->log_mc_entry_sz)/16 - 2);
buf : 
buf : 	mlx4_dbg(dev, "Steering mode is: %s\n",
buf : 		 mlx4_steering_mode_str(dev->caps.steering_mode));
buf : }
buf : 
buf : static int mlx4_slave_cap(struct mlx4_dev *dev)
buf : {
buf : 	int			   err;
buf : 	u32			   page_size;
buf : 	struct mlx4_dev_cap	   dev_cap;
buf : 	struct mlx4_func_cap	   func_cap;
buf : 	struct mlx4_init_hca_param hca_param;
buf : 	int			   i;
buf : 
buf : 	memset(&hca_param, 0, sizeof(hca_param));
buf : 	err = mlx4_QUERY_HCA(dev, &hca_param);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "QUERY_HCA command failed, aborting\n");
buf : 		return err;
buf : 	}
buf : 
buf : 	/* fail if the hca has an unknown global capability
if the hca has an unknown global capability 
buf : 	 * at this time global_caps should be always zeroed
buf : 	 */
buf : 	if (hca_param.global_caps) {
if (hca_param.global_caps) { 
buf : 		mlx4_err(dev, "Unknown hca global capabilities\n");
buf : 		return -ENOSYS;
buf : 	}
buf : 
buf : 	mlx4_log_num_mgm_entry_size = hca_param.log_mc_entry_sz;
buf : 
buf : 	dev->caps.hca_core_clock = hca_param.hca_core_clock;
buf : 
buf : 	memset(&dev_cap, 0, sizeof(dev_cap));
buf : 	dev->caps.max_qp_dest_rdma = 1 << hca_param.log_rd_per_qp;
buf : 	err = mlx4_dev_cap(dev, &dev_cap);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "QUERY_DEV_CAP command failed, aborting\n");
buf : 		return err;
buf : 	}
buf : 
buf : 	err = mlx4_QUERY_FW(dev);
buf : 	if (err)
if (err) 
buf : 		mlx4_err(dev, "QUERY_FW command failed: could not get FW version\n");
buf : 
buf : 	page_size = ~dev->caps.page_size_cap + 1;
buf : 	mlx4_warn(dev, "HCA minimum page size:%d\n", page_size);
buf : 	if (page_size > PAGE_SIZE) {
if (page_size > PAGE_SIZE) { 
buf : 		mlx4_err(dev, "HCA minimum page size of %d bigger than kernel PAGE_SIZE of %ld, aborting\n",
buf : 			 page_size, PAGE_SIZE);
buf : 		return -ENODEV;
buf : 	}
buf : 
buf : 	/* slave gets uar page size from QUERY_HCA fw command */
buf : 	dev->caps.uar_page_size = 1 << (hca_param.uar_page_sz + 12);
buf : 
buf : 	/* TODO: relax this assumption */
buf : 	if (dev->caps.uar_page_size != PAGE_SIZE) {
if (dev->caps.uar_page_size != PAGE_SIZE) { 
buf : 		mlx4_err(dev, "UAR size:%d != kernel PAGE_SIZE of %ld\n",
buf : 			 dev->caps.uar_page_size, PAGE_SIZE);
buf : 		return -ENODEV;
buf : 	}
buf : 
buf : 	memset(&func_cap, 0, sizeof(func_cap));
buf : 	err = mlx4_QUERY_FUNC_CAP(dev, 0, &func_cap);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "QUERY_FUNC_CAP general command failed, aborting (%d)\n",
buf : 			 err);
buf : 		return err;
buf : 	}
buf : 
buf : 	if ((func_cap.pf_context_behaviour | PF_CONTEXT_BEHAVIOUR_MASK) !=
if ((func_cap.pf_context_behaviour | PF_CONTEXT_BEHAVIOUR_MASK) != 
buf : 	    PF_CONTEXT_BEHAVIOUR_MASK) {
buf : 		mlx4_err(dev, "Unknown pf context behaviour\n");
buf : 		return -ENOSYS;
buf : 	}
buf : 
buf : 	dev->caps.num_ports		= func_cap.num_ports;
buf : 	dev->quotas.qp			= func_cap.qp_quota;
buf : 	dev->quotas.srq			= func_cap.srq_quota;
buf : 	dev->quotas.cq			= func_cap.cq_quota;
buf : 	dev->quotas.mpt			= func_cap.mpt_quota;
buf : 	dev->quotas.mtt			= func_cap.mtt_quota;
buf : 	dev->caps.num_qps		= 1 << hca_param.log_num_qps;
buf : 	dev->caps.num_srqs		= 1 << hca_param.log_num_srqs;
buf : 	dev->caps.num_cqs		= 1 << hca_param.log_num_cqs;
buf : 	dev->caps.num_mpts		= 1 << hca_param.log_mpt_sz;
buf : 	dev->caps.num_eqs		= func_cap.max_eq;
buf : 	dev->caps.reserved_eqs		= func_cap.reserved_eq;
buf : 	dev->caps.num_pds               = MLX4_NUM_PDS;
buf : 	dev->caps.num_mgms              = 0;
buf : 	dev->caps.num_amgms             = 0;
buf : 
buf : 	if (dev->caps.num_ports > MLX4_MAX_PORTS) {
if (dev->caps.num_ports > MLX4_MAX_PORTS) { 
buf : 		mlx4_err(dev, "HCA has %d ports, but we only support %d, aborting\n",
buf : 			 dev->caps.num_ports, MLX4_MAX_PORTS);
buf : 		return -ENODEV;
buf : 	}
buf : 
buf : 	dev->caps.qp0_qkey = kcalloc(dev->caps.num_ports, sizeof(u32), GFP_KERNEL);
buf : 	dev->caps.qp0_tunnel = kcalloc(dev->caps.num_ports, sizeof (u32), GFP_KERNEL);
buf : 	dev->caps.qp0_proxy = kcalloc(dev->caps.num_ports, sizeof (u32), GFP_KERNEL);
buf : 	dev->caps.qp1_tunnel = kcalloc(dev->caps.num_ports, sizeof (u32), GFP_KERNEL);
buf : 	dev->caps.qp1_proxy = kcalloc(dev->caps.num_ports, sizeof (u32), GFP_KERNEL);
buf : 
buf : 	if (!dev->caps.qp0_tunnel || !dev->caps.qp0_proxy ||
if (!dev->caps.qp0_tunnel || !dev->caps.qp0_proxy || 
buf : 	    !dev->caps.qp1_tunnel || !dev->caps.qp1_proxy ||
buf : 	    !dev->caps.qp0_qkey) {
buf : 		err = -ENOMEM;
buf : 		goto err_mem;
buf : 	}
buf : 
buf : 	for (i = 1; i <= dev->caps.num_ports; ++i) {
for (i = 1; i <= dev->caps.num_ports; ++i) { 
buf : 		err = mlx4_QUERY_FUNC_CAP(dev, (u32) i, &func_cap);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(dev, "QUERY_FUNC_CAP port command failed for port %d, aborting (%d)\n",
for port %d, aborting (%d)\n", 
buf : 				 i, err);
buf : 			goto err_mem;
buf : 		}
buf : 		dev->caps.qp0_qkey[i - 1] = func_cap.qp0_qkey;
buf : 		dev->caps.qp0_tunnel[i - 1] = func_cap.qp0_tunnel_qpn;
buf : 		dev->caps.qp0_proxy[i - 1] = func_cap.qp0_proxy_qpn;
buf : 		dev->caps.qp1_tunnel[i - 1] = func_cap.qp1_tunnel_qpn;
buf : 		dev->caps.qp1_proxy[i - 1] = func_cap.qp1_proxy_qpn;
buf : 		dev->caps.port_mask[i] = dev->caps.port_type[i];
buf : 		dev->caps.phys_port_id[i] = func_cap.phys_port_id;
buf : 		if (mlx4_get_slave_pkey_gid_tbl_len(dev, i,
if (mlx4_get_slave_pkey_gid_tbl_len(dev, i, 
buf : 						    &dev->caps.gid_table_len[i],
buf : 						    &dev->caps.pkey_table_len[i]))
buf : 			goto err_mem;
buf : 	}
buf : 
buf : 	if (dev->caps.uar_page_size * (dev->caps.num_uars -
if (dev->caps.uar_page_size * (dev->caps.num_uars - 
buf : 				       dev->caps.reserved_uars) >
buf : 				       pci_resource_len(dev->pdev, 2)) {
buf : 		mlx4_err(dev, "HCA reported UAR region size of 0x%x bigger than PCI resource 2 size of 0x%llx, aborting\n",
buf : 			 dev->caps.uar_page_size * dev->caps.num_uars,
buf : 			 (unsigned long long) pci_resource_len(dev->pdev, 2));
buf : 		goto err_mem;
buf : 	}
buf : 
buf : 	if (hca_param.dev_cap_enabled & MLX4_DEV_CAP_64B_EQE_ENABLED) {
if (hca_param.dev_cap_enabled & MLX4_DEV_CAP_64B_EQE_ENABLED) { 
buf : 		dev->caps.eqe_size   = 64;
buf : 		dev->caps.eqe_factor = 1;
buf : 	} else {
buf : 		dev->caps.eqe_size   = 32;
buf : 		dev->caps.eqe_factor = 0;
buf : 	}
buf : 
buf : 	if (hca_param.dev_cap_enabled & MLX4_DEV_CAP_64B_CQE_ENABLED) {
if (hca_param.dev_cap_enabled & MLX4_DEV_CAP_64B_CQE_ENABLED) { 
buf : 		dev->caps.cqe_size   = 64;
buf : 		dev->caps.userspace_caps |= MLX4_USER_DEV_CAP_64B_CQE;
buf : 	} else {
buf : 		dev->caps.cqe_size   = 32;
buf : 	}
buf : 
buf : 	dev->caps.flags2 &= ~MLX4_DEV_CAP_FLAG2_TS;
buf : 	mlx4_warn(dev, "Timestamping is not supported in slave mode\n");
buf : 
buf : 	slave_adjust_steering_mode(dev, &dev_cap, &hca_param);
buf : 
buf : 	return 0;
buf : 
buf : err_mem:
buf : 	kfree(dev->caps.qp0_qkey);
buf : 	kfree(dev->caps.qp0_tunnel);
buf : 	kfree(dev->caps.qp0_proxy);
buf : 	kfree(dev->caps.qp1_tunnel);
buf : 	kfree(dev->caps.qp1_proxy);
buf : 	dev->caps.qp0_qkey = NULL;
buf : 	dev->caps.qp0_tunnel = NULL;
buf : 	dev->caps.qp0_proxy = NULL;
buf : 	dev->caps.qp1_tunnel = NULL;
buf : 	dev->caps.qp1_proxy = NULL;
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void mlx4_request_modules(struct mlx4_dev *dev)
buf : {
buf : 	int port;
buf : 	int has_ib_port = false;
buf : 	int has_eth_port = false;
buf : #define EN_DRV_NAME	"mlx4_en"
buf : #define IB_DRV_NAME	"mlx4_ib"
buf : 
buf : 	for (port = 1; port <= dev->caps.num_ports; port++) {
for (port = 1; port <= dev->caps.num_ports; port++) { 
buf : 		if (dev->caps.port_type[port] == MLX4_PORT_TYPE_IB)
buf : 			has_ib_port = true;
buf : 		else if (dev->caps.port_type[port] == MLX4_PORT_TYPE_ETH)
if (dev->caps.port_type[port] == MLX4_PORT_TYPE_ETH) 
buf : 			has_eth_port = true;
buf : 	}
buf : 
buf : 	if (has_eth_port)
if (has_eth_port) 
buf : 		request_module_nowait(EN_DRV_NAME);
buf : 	if (has_ib_port || (dev->caps.flags & MLX4_DEV_CAP_FLAG_IBOE))
if (has_ib_port || (dev->caps.flags & MLX4_DEV_CAP_FLAG_IBOE)) 
buf : 		request_module_nowait(IB_DRV_NAME);
buf : }
buf : 
buf : /*
buf :  * Change the port configuration of the device.
buf :  * Every user of this function must hold the port mutex.
buf :  */
buf : int mlx4_change_port_types(struct mlx4_dev *dev,
buf : 			   enum mlx4_port_type *port_types)
buf : {
buf : 	int err = 0;
buf : 	int change = 0;
buf : 	int port;
buf : 
buf : 	for (port = 0; port <  dev->caps.num_ports; port++) {
for (port = 0; port <  dev->caps.num_ports; port++) { 
buf : 		/* Change the port type only if the new type is different
buf : 		 * from the current, and not set to Auto */
buf : 		if (port_types[port] != dev->caps.port_type[port + 1])
if (port_types[port] != dev->caps.port_type[port + 1]) 
buf : 			change = 1;
buf : 	}
buf : 	if (change) {
if (change) { 
buf : 		mlx4_unregister_device(dev);
buf : 		for (port = 1; port <= dev->caps.num_ports; port++) {
for (port = 1; port <= dev->caps.num_ports; port++) { 
buf : 			mlx4_CLOSE_PORT(dev, port);
buf : 			dev->caps.port_type[port] = port_types[port - 1];
buf : 			err = mlx4_SET_PORT(dev, port, -1);
buf : 			if (err) {
if (err) { 
buf : 				mlx4_err(dev, "Failed to set port %d, aborting\n",
buf : 					 port);
buf : 				goto out;
buf : 			}
buf : 		}
buf : 		mlx4_set_port_mask(dev);
buf : 		err = mlx4_register_device(dev);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(dev, "Failed to register device\n");
buf : 			goto out;
buf : 		}
buf : 		mlx4_request_modules(dev);
buf : 	}
buf : 
buf : out:
buf : 	return err;
buf : }
buf : 
buf : static ssize_t show_port_type(struct device *dev,
buf : 			      struct device_attribute *attr,
buf : 			      char *buf)
buf : {
buf : 	struct mlx4_port_info *info = container_of(attr, struct mlx4_port_info,
buf : 						   port_attr);
buf : 	struct mlx4_dev *mdev = info->dev;
buf : 	char type[8];
buf : 
buf : 	sprintf(type, "%s",
buf : 		(mdev->caps.port_type[info->port] == MLX4_PORT_TYPE_IB) ?
buf : 		"ib" : "eth");
buf : 	if (mdev->caps.possible_type[info->port] == MLX4_PORT_TYPE_AUTO)
if (mdev->caps.possible_type[info->port] == MLX4_PORT_TYPE_AUTO) 
buf : 		sprintf(buf, "auto (%s)\n", type);
buf : 	else
buf : 		sprintf(buf, "%s\n", type);
buf : 
buf : 	return strlen(buf);
buf : }
buf : 
buf : static ssize_t set_port_type(struct device *dev,
buf : 			     struct device_attribute *attr,
buf : 			     const char *buf, size_t count)
buf : {
buf : 	struct mlx4_port_info *info = container_of(attr, struct mlx4_port_info,
buf : 						   port_attr);
buf : 	struct mlx4_dev *mdev = info->dev;
buf : 	struct mlx4_priv *priv = mlx4_priv(mdev);
buf : 	enum mlx4_port_type types[MLX4_MAX_PORTS];
buf : 	enum mlx4_port_type new_types[MLX4_MAX_PORTS];
buf : 	int i;
buf : 	int err = 0;
buf : 
buf : 	if (!strcmp(buf, "ib\n"))
if (!strcmp(buf, "ib\n")) 
buf : 		info->tmp_type = MLX4_PORT_TYPE_IB;
buf : 	else if (!strcmp(buf, "eth\n"))
if (!strcmp(buf, "eth\n")) 
buf : 		info->tmp_type = MLX4_PORT_TYPE_ETH;
buf : 	else if (!strcmp(buf, "auto\n"))
if (!strcmp(buf, "auto\n")) 
buf : 		info->tmp_type = MLX4_PORT_TYPE_AUTO;
buf : 	else {
buf : 		mlx4_err(mdev, "%s is not supported port type\n", buf);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	mlx4_stop_sense(mdev);
buf : 	mutex_lock(&priv->port_mutex);
buf : 	/* Possible type is always the one that was delivered */
buf : 	mdev->caps.possible_type[info->port] = info->tmp_type;
buf : 
buf : 	for (i = 0; i < mdev->caps.num_ports; i++) {
for (i = 0; i < mdev->caps.num_ports; i++) { 
buf : 		types[i] = priv->port[i+1].tmp_type ? priv->port[i+1].tmp_type :
buf : 					mdev->caps.possible_type[i+1];
buf : 		if (types[i] == MLX4_PORT_TYPE_AUTO)
if (types[i] == MLX4_PORT_TYPE_AUTO) 
buf : 			types[i] = mdev->caps.port_type[i+1];
buf : 	}
buf : 
buf : 	if (!(mdev->caps.flags & MLX4_DEV_CAP_FLAG_DPDP) &&
if (!(mdev->caps.flags & MLX4_DEV_CAP_FLAG_DPDP) && 
buf : 	    !(mdev->caps.flags & MLX4_DEV_CAP_FLAG_SENSE_SUPPORT)) {
buf : 		for (i = 1; i <= mdev->caps.num_ports; i++) {
for (i = 1; i <= mdev->caps.num_ports; i++) { 
buf : 			if (mdev->caps.possible_type[i] == MLX4_PORT_TYPE_AUTO) {
buf : 				mdev->caps.possible_type[i] = mdev->caps.port_type[i];
buf : 				err = -EINVAL;
buf : 			}
buf : 		}
buf : 	}
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(mdev, "Auto sensing is not supported on this HCA. Set only 'eth' or 'ib' for both ports (should be the same)\n");
for both ports (should be the same)\n"); 
buf : 		goto out;
buf : 	}
buf : 
buf : 	mlx4_do_sense_ports(mdev, new_types, types);
buf : 
buf : 	err = mlx4_check_port_params(mdev, new_types);
buf : 	if (err)
if (err) 
buf : 		goto out;
buf : 
buf : 	/* We are about to apply the changes after the configuration
buf : 	 * was verified, no need to remember the temporary types
ified, no need to remember the temporary types 
buf : 	 * any more */
buf : 	for (i = 0; i < mdev->caps.num_ports; i++)
for (i = 0; i < mdev->caps.num_ports; i++) 
buf : 		priv->port[i + 1].tmp_type = 0;
buf : 
buf : 	err = mlx4_change_port_types(mdev, new_types);
buf : 
buf : out:
buf : 	mlx4_start_sense(mdev);
buf : 	mutex_unlock(&priv->port_mutex);
buf : 	return err ? err : count;
buf : }
buf : 
buf : enum ibta_mtu {
buf : 	IB_MTU_256  = 1,
buf : 	IB_MTU_512  = 2,
buf : 	IB_MTU_1024 = 3,
buf : 	IB_MTU_2048 = 4,
buf : 	IB_MTU_4096 = 5
buf : };
buf : 
buf : static inline int int_to_ibta_mtu(int mtu)
buf : {
buf : 	switch (mtu) {
buf : 	case 256:  return IB_MTU_256;
buf : 	case 512:  return IB_MTU_512;
buf : 	case 1024: return IB_MTU_1024;
buf : 	case 2048: return IB_MTU_2048;
buf : 	case 4096: return IB_MTU_4096;
buf : 	default: return -1;
buf : 	}
buf : }
buf : 
buf : static inline int ibta_mtu_to_int(enum ibta_mtu mtu)
buf : {
buf : 	switch (mtu) {
buf : 	case IB_MTU_256:  return  256;
buf : 	case IB_MTU_512:  return  512;
buf : 	case IB_MTU_1024: return 1024;
buf : 	case IB_MTU_2048: return 2048;
buf : 	case IB_MTU_4096: return 4096;
buf : 	default: return -1;
buf : 	}
buf : }
buf : 
buf : static ssize_t show_port_ib_mtu(struct device *dev,
buf : 			     struct device_attribute *attr,
buf : 			     char *buf)
buf : {
buf : 	struct mlx4_port_info *info = container_of(attr, struct mlx4_port_info,
buf : 						   port_mtu_attr);
buf : 	struct mlx4_dev *mdev = info->dev;
buf : 
buf : 	if (mdev->caps.port_type[info->port] == MLX4_PORT_TYPE_ETH)
if (mdev->caps.port_type[info->port] == MLX4_PORT_TYPE_ETH) 
buf : 		mlx4_warn(mdev, "port level mtu is only used for IB ports\n");
for IB ports\n"); 
buf : 
buf : 	sprintf(buf, "%d\n",
buf : 			ibta_mtu_to_int(mdev->caps.port_ib_mtu[info->port]));
buf : 	return strlen(buf);
buf : }
buf : 
buf : static ssize_t set_port_ib_mtu(struct device *dev,
buf : 			     struct device_attribute *attr,
buf : 			     const char *buf, size_t count)
buf : {
buf : 	struct mlx4_port_info *info = container_of(attr, struct mlx4_port_info,
buf : 						   port_mtu_attr);
buf : 	struct mlx4_dev *mdev = info->dev;
buf : 	struct mlx4_priv *priv = mlx4_priv(mdev);
buf : 	int err, port, mtu, ibta_mtu = -1;
buf : 
buf : 	if (mdev->caps.port_type[info->port] == MLX4_PORT_TYPE_ETH) {
if (mdev->caps.port_type[info->port] == MLX4_PORT_TYPE_ETH) { 
buf : 		mlx4_warn(mdev, "port level mtu is only used for IB ports\n");
for IB ports\n"); 
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	err = kstrtoint(buf, 0, &mtu);
buf : 	if (!err)
if (!err) 
buf : 		ibta_mtu = int_to_ibta_mtu(mtu);
buf : 
buf : 	if (err || ibta_mtu < 0) {
if (err || ibta_mtu < 0) { 
buf : 		mlx4_err(mdev, "%s is invalid IBTA mtu\n", buf);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	mdev->caps.port_ib_mtu[info->port] = ibta_mtu;
buf : 
buf : 	mlx4_stop_sense(mdev);
buf : 	mutex_lock(&priv->port_mutex);
buf : 	mlx4_unregister_device(mdev);
buf : 	for (port = 1; port <= mdev->caps.num_ports; port++) {
for (port = 1; port <= mdev->caps.num_ports; port++) { 
buf : 		mlx4_CLOSE_PORT(mdev, port);
buf : 		err = mlx4_SET_PORT(mdev, port, -1);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(mdev, "Failed to set port %d, aborting\n",
buf : 				 port);
buf : 			goto err_set_port;
buf : 		}
buf : 	}
buf : 	err = mlx4_register_device(mdev);
buf : err_set_port:
buf : 	mutex_unlock(&priv->port_mutex);
buf : 	mlx4_start_sense(mdev);
buf : 	return err ? err : count;
buf : }
buf : 
buf : static int mlx4_load_fw(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	int err;
buf : 
buf : 	priv->fw.fw_icm = mlx4_alloc_icm(dev, priv->fw.fw_pages,
buf : 					 GFP_HIGHUSER | __GFP_NOWARN, 0);
buf : 	if (!priv->fw.fw_icm) {
if (!priv->fw.fw_icm) { 
buf : 		mlx4_err(dev, "Couldn't allocate FW area, aborting\n");
buf : 		return -ENOMEM;
buf : 	}
buf : 
buf : 	err = mlx4_MAP_FA(dev, priv->fw.fw_icm);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "MAP_FA command failed, aborting\n");
buf : 		goto err_free;
buf : 	}
buf : 
buf : 	err = mlx4_RUN_FW(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "RUN_FW command failed, aborting\n");
buf : 		goto err_unmap_fa;
buf : 	}
buf : 
buf : 	return 0;
buf : 
buf : err_unmap_fa:
buf : 	mlx4_UNMAP_FA(dev);
buf : 
buf : err_free:
buf : 	mlx4_free_icm(dev, priv->fw.fw_icm, 0);
buf : 	return err;
buf : }
buf : 
buf : static int mlx4_init_cmpt_table(struct mlx4_dev *dev, u64 cmpt_base,
buf : 				int cmpt_entry_sz)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	int err;
buf : 	int num_eqs;
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->qp_table.cmpt_table,
buf : 				  cmpt_base +
buf : 				  ((u64) (MLX4_CMPT_TYPE_QP *
buf : 					  cmpt_entry_sz) << MLX4_CMPT_SHIFT),
buf : 				  cmpt_entry_sz, dev->caps.num_qps,
buf : 				  dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FW],
buf : 				  0, 0);
buf : 	if (err)
if (err) 
buf : 		goto err;
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->srq_table.cmpt_table,
buf : 				  cmpt_base +
buf : 				  ((u64) (MLX4_CMPT_TYPE_SRQ *
buf : 					  cmpt_entry_sz) << MLX4_CMPT_SHIFT),
buf : 				  cmpt_entry_sz, dev->caps.num_srqs,
buf : 				  dev->caps.reserved_srqs, 0, 0);
buf : 	if (err)
if (err) 
buf : 		goto err_qp;
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->cq_table.cmpt_table,
buf : 				  cmpt_base +
buf : 				  ((u64) (MLX4_CMPT_TYPE_CQ *
buf : 					  cmpt_entry_sz) << MLX4_CMPT_SHIFT),
buf : 				  cmpt_entry_sz, dev->caps.num_cqs,
buf : 				  dev->caps.reserved_cqs, 0, 0);
buf : 	if (err)
if (err) 
buf : 		goto err_srq;
buf : 
buf : 	num_eqs = (mlx4_is_master(dev)) ? dev->phys_caps.num_phys_eqs :
buf : 		  dev->caps.num_eqs;
buf : 	err = mlx4_init_icm_table(dev, &priv->eq_table.cmpt_table,
buf : 				  cmpt_base +
buf : 				  ((u64) (MLX4_CMPT_TYPE_EQ *
buf : 					  cmpt_entry_sz) << MLX4_CMPT_SHIFT),
buf : 				  cmpt_entry_sz, num_eqs, num_eqs, 0, 0);
buf : 	if (err)
if (err) 
buf : 		goto err_cq;
buf : 
buf : 	return 0;
buf : 
buf : err_cq:
buf : 	mlx4_cleanup_icm_table(dev, &priv->cq_table.cmpt_table);
buf : 
buf : err_srq:
buf : 	mlx4_cleanup_icm_table(dev, &priv->srq_table.cmpt_table);
buf : 
buf : err_qp:
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.cmpt_table);
buf : 
buf : err:
buf : 	return err;
buf : }
buf : 
buf : static int mlx4_init_icm(struct mlx4_dev *dev, struct mlx4_dev_cap *dev_cap,
buf : 			 struct mlx4_init_hca_param *init_hca, u64 icm_size)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	u64 aux_pages;
buf : 	int num_eqs;
buf : 	int err;
buf : 
buf : 	err = mlx4_SET_ICM_SIZE(dev, icm_size, &aux_pages);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "SET_ICM_SIZE command failed, aborting\n");
buf : 		return err;
buf : 	}
buf : 
buf : 	mlx4_dbg(dev, "%lld KB of HCA context requires %lld KB aux memory\n",
buf : 		 (unsigned long long) icm_size >> 10,
buf : 		 (unsigned long long) aux_pages << 2);
buf : 
buf : 	priv->fw.aux_icm = mlx4_alloc_icm(dev, aux_pages,
buf : 					  GFP_HIGHUSER | __GFP_NOWARN, 0);
buf : 	if (!priv->fw.aux_icm) {
if (!priv->fw.aux_icm) { 
buf : 		mlx4_err(dev, "Couldn't allocate aux memory, aborting\n");
buf : 		return -ENOMEM;
buf : 	}
buf : 
buf : 	err = mlx4_MAP_ICM_AUX(dev, priv->fw.aux_icm);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "MAP_ICM_AUX command failed, aborting\n");
buf : 		goto err_free_aux;
buf : 	}
buf : 
buf : 	err = mlx4_init_cmpt_table(dev, init_hca->cmpt_base, dev_cap->cmpt_entry_sz);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map cMPT context memory, aborting\n");
buf : 		goto err_unmap_aux;
buf : 	}
buf : 
buf : 
buf : 	num_eqs = (mlx4_is_master(dev)) ? dev->phys_caps.num_phys_eqs :
buf : 		   dev->caps.num_eqs;
buf : 	err = mlx4_init_icm_table(dev, &priv->eq_table.table,
buf : 				  init_hca->eqc_base, dev_cap->eqc_entry_sz,
buf : 				  num_eqs, num_eqs, 0, 0);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map EQ context memory, aborting\n");
buf : 		goto err_unmap_cmpt;
buf : 	}
buf : 
buf : 	/*
buf : 	 * Reserved MTT entries must be aligned up to a cacheline
buf : 	 * boundary, since the FW will write to them, while the driver
while the driver 
buf : 	 * writes to all other MTT entries. (The variable
buf : 	 * dev->caps.mtt_entry_sz below is really the MTT segment
buf : 	 * size, not the raw entry size)
buf : 	 */
buf : 	dev->caps.reserved_mtts =
buf : 		ALIGN(dev->caps.reserved_mtts * dev->caps.mtt_entry_sz,
buf : 		      dma_get_cache_alignment()) / dev->caps.mtt_entry_sz;
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->mr_table.mtt_table,
buf : 				  init_hca->mtt_base,
buf : 				  dev->caps.mtt_entry_sz,
buf : 				  dev->caps.num_mtts,
buf : 				  dev->caps.reserved_mtts, 1, 0);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map MTT context memory, aborting\n");
buf : 		goto err_unmap_eq;
buf : 	}
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->mr_table.dmpt_table,
buf : 				  init_hca->dmpt_base,
buf : 				  dev_cap->dmpt_entry_sz,
buf : 				  dev->caps.num_mpts,
buf : 				  dev->caps.reserved_mrws, 1, 1);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map dMPT context memory, aborting\n");
buf : 		goto err_unmap_mtt;
buf : 	}
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->qp_table.qp_table,
buf : 				  init_hca->qpc_base,
buf : 				  dev_cap->qpc_entry_sz,
buf : 				  dev->caps.num_qps,
buf : 				  dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FW],
buf : 				  0, 0);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map QP context memory, aborting\n");
buf : 		goto err_unmap_dmpt;
buf : 	}
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->qp_table.auxc_table,
buf : 				  init_hca->auxc_base,
buf : 				  dev_cap->aux_entry_sz,
buf : 				  dev->caps.num_qps,
buf : 				  dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FW],
buf : 				  0, 0);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map AUXC context memory, aborting\n");
buf : 		goto err_unmap_qp;
buf : 	}
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->qp_table.altc_table,
buf : 				  init_hca->altc_base,
buf : 				  dev_cap->altc_entry_sz,
buf : 				  dev->caps.num_qps,
buf : 				  dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FW],
buf : 				  0, 0);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map ALTC context memory, aborting\n");
buf : 		goto err_unmap_auxc;
buf : 	}
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->qp_table.rdmarc_table,
buf : 				  init_hca->rdmarc_base,
buf : 				  dev_cap->rdmarc_entry_sz << priv->qp_table.rdmarc_shift,
ift, 
buf : 				  dev->caps.num_qps,
buf : 				  dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FW],
buf : 				  0, 0);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map RDMARC context memory, aborting\n");
buf : 		goto err_unmap_altc;
buf : 	}
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->cq_table.table,
buf : 				  init_hca->cqc_base,
buf : 				  dev_cap->cqc_entry_sz,
buf : 				  dev->caps.num_cqs,
buf : 				  dev->caps.reserved_cqs, 0, 0);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map CQ context memory, aborting\n");
buf : 		goto err_unmap_rdmarc;
buf : 	}
buf : 
buf : 	err = mlx4_init_icm_table(dev, &priv->srq_table.table,
buf : 				  init_hca->srqc_base,
buf : 				  dev_cap->srq_entry_sz,
buf : 				  dev->caps.num_srqs,
buf : 				  dev->caps.reserved_srqs, 0, 0);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map SRQ context memory, aborting\n");
buf : 		goto err_unmap_cq;
buf : 	}
buf : 
buf : 	/*
buf : 	 * For flow steering device managed mode it is required to use
buf : 	 * mlx4_init_icm_table. For B0 steering mode it's not strictly
buf : 	 * required, but for simplicity just map the whole multicast
for simplicity just map the whole multicast 
buf : 	 * group table now.  The table isn't very big and it's a lot
buf : 	 * easier than trying to track ref counts.
buf : 	 */
buf : 	err = mlx4_init_icm_table(dev, &priv->mcg_table.table,
buf : 				  init_hca->mc_base,
buf : 				  mlx4_get_mgm_entry_size(dev),
buf : 				  dev->caps.num_mgms + dev->caps.num_amgms,
buf : 				  dev->caps.num_mgms + dev->caps.num_amgms,
buf : 				  0, 0);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to map MCG context memory, aborting\n");
buf : 		goto err_unmap_srq;
buf : 	}
buf : 
buf : 	return 0;
buf : 
buf : err_unmap_srq:
buf : 	mlx4_cleanup_icm_table(dev, &priv->srq_table.table);
buf : 
buf : err_unmap_cq:
buf : 	mlx4_cleanup_icm_table(dev, &priv->cq_table.table);
buf : 
buf : err_unmap_rdmarc:
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.rdmarc_table);
buf : 
buf : err_unmap_altc:
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.altc_table);
buf : 
buf : err_unmap_auxc:
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.auxc_table);
buf : 
buf : err_unmap_qp:
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.qp_table);
buf : 
buf : err_unmap_dmpt:
buf : 	mlx4_cleanup_icm_table(dev, &priv->mr_table.dmpt_table);
buf : 
buf : err_unmap_mtt:
buf : 	mlx4_cleanup_icm_table(dev, &priv->mr_table.mtt_table);
buf : 
buf : err_unmap_eq:
buf : 	mlx4_cleanup_icm_table(dev, &priv->eq_table.table);
buf : 
buf : err_unmap_cmpt:
buf : 	mlx4_cleanup_icm_table(dev, &priv->eq_table.cmpt_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->cq_table.cmpt_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->srq_table.cmpt_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.cmpt_table);
buf : 
buf : err_unmap_aux:
buf : 	mlx4_UNMAP_ICM_AUX(dev);
buf : 
buf : err_free_aux:
buf : 	mlx4_free_icm(dev, priv->fw.aux_icm, 0);
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void mlx4_free_icms(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 
buf : 	mlx4_cleanup_icm_table(dev, &priv->mcg_table.table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->srq_table.table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->cq_table.table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.rdmarc_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.altc_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.auxc_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.qp_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->mr_table.dmpt_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->mr_table.mtt_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->eq_table.table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->eq_table.cmpt_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->cq_table.cmpt_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->srq_table.cmpt_table);
buf : 	mlx4_cleanup_icm_table(dev, &priv->qp_table.cmpt_table);
buf : 
buf : 	mlx4_UNMAP_ICM_AUX(dev);
buf : 	mlx4_free_icm(dev, priv->fw.aux_icm, 0);
buf : }
buf : 
buf : static void mlx4_slave_exit(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 
buf : 	mutex_lock(&priv->cmd.slave_cmd_mutex);
buf : 	if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_RESET, 0, MLX4_COMM_TIME))
if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_RESET, 0, MLX4_COMM_TIME)) 
buf : 		mlx4_warn(dev, "Failed to close slave function\n");
buf : 	mutex_unlock(&priv->cmd.slave_cmd_mutex);
buf : }
buf : 
buf : static int map_bf_area(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	resource_size_t bf_start;
buf : 	resource_size_t bf_len;
buf : 	int err = 0;
buf : 
buf : 	if (!dev->caps.bf_reg_size)
if (!dev->caps.bf_reg_size) 
buf : 		return -ENXIO;
buf : 
buf : 	bf_start = pci_resource_start(dev->pdev, 2) +
buf : 			(dev->caps.num_uars << PAGE_SHIFT);
buf : 	bf_len = pci_resource_len(dev->pdev, 2) -
buf : 			(dev->caps.num_uars << PAGE_SHIFT);
buf : 	priv->bf_mapping = io_mapping_create_wc(bf_start, bf_len);
buf : 	if (!priv->bf_mapping)
if (!priv->bf_mapping) 
buf : 		err = -ENOMEM;
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void unmap_bf_area(struct mlx4_dev *dev)
buf : {
buf : 	if (mlx4_priv(dev)->bf_mapping)
if (mlx4_priv(dev)->bf_mapping) 
buf : 		io_mapping_free(mlx4_priv(dev)->bf_mapping);
buf : }
buf : 
buf : cycle_t mlx4_read_clock(struct mlx4_dev *dev)
buf : {
buf : 	u32 clockhi, clocklo, clockhi1;
buf : 	cycle_t cycles;
buf : 	int i;
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 
buf : 	for (i = 0; i < 10; i++) {
for (i = 0; i < 10; i++) { 
buf : 		clockhi = swab32(readl(priv->clock_mapping));
buf : 		clocklo = swab32(readl(priv->clock_mapping + 4));
buf : 		clockhi1 = swab32(readl(priv->clock_mapping));
buf : 		if (clockhi == clockhi1)
if (clockhi == clockhi1) 
buf : 			break;
buf : 	}
buf : 
buf : 	cycles = (u64) clockhi << 32 | (u64) clocklo;
buf : 
buf : 	return cycles;
buf : }
buf : EXPORT_SYMBOL_GPL(mlx4_read_clock);
buf : 
buf : 
buf : static int map_internal_clock(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 
buf : 	priv->clock_mapping =
buf : 		ioremap(pci_resource_start(dev->pdev, priv->fw.clock_bar) +
buf : 			priv->fw.clock_offset, MLX4_CLOCK_SIZE);
buf : 
buf : 	if (!priv->clock_mapping)
if (!priv->clock_mapping) 
buf : 		return -ENOMEM;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void unmap_internal_clock(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 
buf : 	if (priv->clock_mapping)
if (priv->clock_mapping) 
buf : 		iounmap(priv->clock_mapping);
buf : }
buf : 
buf : static void mlx4_close_hca(struct mlx4_dev *dev)
buf : {
buf : 	unmap_internal_clock(dev);
buf : 	unmap_bf_area(dev);
buf : 	if (mlx4_is_slave(dev))
if (mlx4_is_slave(dev)) 
buf : 		mlx4_slave_exit(dev);
buf : 	else {
buf : 		mlx4_CLOSE_HCA(dev, 0);
buf : 		mlx4_free_icms(dev);
buf : 		mlx4_UNMAP_FA(dev);
buf : 		mlx4_free_icm(dev, mlx4_priv(dev)->fw.fw_icm, 0);
buf : 	}
buf : }
buf : 
buf : static int mlx4_init_slave(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	u64 dma = (u64) priv->mfunc.vhcr_dma;
buf : 	int ret_from_reset = 0;
buf : 	u32 slave_read;
buf : 	u32 cmd_channel_ver;
buf : 
buf : 	if (atomic_read(&pf_loading)) {
if (atomic_read(&pf_loading)) { 
buf : 		mlx4_warn(dev, "PF is not ready - Deferring probe\n");
buf : 		return -EPROBE_DEFER;
buf : 	}
buf : 
buf : 	mutex_lock(&priv->cmd.slave_cmd_mutex);
buf : 	priv->cmd.max_cmds = 1;
buf : 	mlx4_warn(dev, "Sending reset\n");
buf : 	ret_from_reset = mlx4_comm_cmd(dev, MLX4_COMM_CMD_RESET, 0,
buf : 				       MLX4_COMM_TIME);
buf : 	/* if we are in the middle of flr the slave will try
if we are in the middle of flr the slave will try 
buf : 	 * NUM_OF_RESET_RETRIES times before leaving.*/
fore leaving.*/ 
buf : 	if (ret_from_reset) {
buf : 		if (MLX4_DELAY_RESET_SLAVE == ret_from_reset) {
if (MLX4_DELAY_RESET_SLAVE == ret_from_reset) { 
buf : 			mlx4_warn(dev, "slave is currently in the middle of FLR - Deferring probe\n");
buf : 			mutex_unlock(&priv->cmd.slave_cmd_mutex);
buf : 			return -EPROBE_DEFER;
buf : 		} else
buf : 			goto err;
buf : 	}
buf : 
buf : 	/* check the driver version - the slave I/F revision
buf : 	 * must match the master's */
buf : 	slave_read = swab32(readl(&priv->mfunc.comm->slave_read));
buf : 	cmd_channel_ver = mlx4_comm_get_version();
buf : 
buf : 	if (MLX4_COMM_GET_IF_REV(cmd_channel_ver) !=
if (MLX4_COMM_GET_IF_REV(cmd_channel_ver) != 
buf : 		MLX4_COMM_GET_IF_REV(slave_read)) {
buf : 		mlx4_err(dev, "slave driver version is not supported by the master\n");
buf : 		goto err;
buf : 	}
buf : 
buf : 	mlx4_warn(dev, "Sending vhcr0\n");
buf : 	if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_VHCR0, dma >> 48,
if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_VHCR0, dma >> 48, 
buf : 						    MLX4_COMM_TIME))
buf : 		goto err;
buf : 	if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_VHCR1, dma >> 32,
if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_VHCR1, dma >> 32, 
buf : 						    MLX4_COMM_TIME))
buf : 		goto err;
buf : 	if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_VHCR2, dma >> 16,
if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_VHCR2, dma >> 16, 
buf : 						    MLX4_COMM_TIME))
buf : 		goto err;
buf : 	if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_VHCR_EN, dma, MLX4_COMM_TIME))
if (mlx4_comm_cmd(dev, MLX4_COMM_CMD_VHCR_EN, dma, MLX4_COMM_TIME)) 
buf : 		goto err;
buf : 
buf : 	mutex_unlock(&priv->cmd.slave_cmd_mutex);
buf : 	return 0;
buf : 
buf : err:
buf : 	mlx4_comm_cmd(dev, MLX4_COMM_CMD_RESET, 0, 0);
buf : 	mutex_unlock(&priv->cmd.slave_cmd_mutex);
buf : 	return -EIO;
buf : }
buf : 
buf : static void mlx4_parav_master_pf_caps(struct mlx4_dev *dev)
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 1; i <= dev->caps.num_ports; i++) {
for (i = 1; i <= dev->caps.num_ports; i++) { 
buf : 		if (dev->caps.port_type[i] == MLX4_PORT_TYPE_ETH)
buf : 			dev->caps.gid_table_len[i] =
buf : 				mlx4_get_slave_num_gids(dev, 0, i);
buf : 		else
buf : 			dev->caps.gid_table_len[i] = 1;
buf : 		dev->caps.pkey_table_len[i] =
buf : 			dev->phys_caps.pkey_phys_table_len[i] - 1;
buf : 	}
buf : }
buf : 
buf : static int choose_log_fs_mgm_entry_size(int qp_per_entry)
buf : {
buf : 	int i = MLX4_MIN_MGM_LOG_ENTRY_SIZE;
buf : 
buf : 	for (i = MLX4_MIN_MGM_LOG_ENTRY_SIZE; i <= MLX4_MAX_MGM_LOG_ENTRY_SIZE;
for (i = MLX4_MIN_MGM_LOG_ENTRY_SIZE; i <= MLX4_MAX_MGM_LOG_ENTRY_SIZE; 
buf : 	      i++) {
buf : 		if (qp_per_entry <= 4 * ((1 << i) / 16 - 2))
if (qp_per_entry <= 4 * ((1 << i) / 16 - 2)) 
buf : 			break;
buf : 	}
buf : 
buf : 	return (i <= MLX4_MAX_MGM_LOG_ENTRY_SIZE) ? i : -1;
buf : }
buf : 
buf : static void choose_steering_mode(struct mlx4_dev *dev,
buf : 				 struct mlx4_dev_cap *dev_cap)
buf : {
buf : 	if (mlx4_log_num_mgm_entry_size == -1 &&
if (mlx4_log_num_mgm_entry_size == -1 && 
buf : 	    dev_cap->flags2 & MLX4_DEV_CAP_FLAG2_FS_EN &&
buf : 	    (!mlx4_is_mfunc(dev) ||
buf : 	     (dev_cap->fs_max_num_qp_per_entry >= (dev->num_vfs + 1))) &&
buf : 	    choose_log_fs_mgm_entry_size(dev_cap->fs_max_num_qp_per_entry) >=
buf : 		MLX4_MIN_MGM_LOG_ENTRY_SIZE) {
buf : 		dev->oper_log_mgm_entry_size =
buf : 			choose_log_fs_mgm_entry_size(dev_cap->fs_max_num_qp_per_entry);
buf : 		dev->caps.steering_mode = MLX4_STEERING_MODE_DEVICE_MANAGED;
buf : 		dev->caps.num_qp_per_mgm = dev_cap->fs_max_num_qp_per_entry;
buf : 		dev->caps.fs_log_max_ucast_qp_range_size =
buf : 			dev_cap->fs_log_max_ucast_qp_range_size;
buf : 	} else {
buf : 		if (dev->caps.flags & MLX4_DEV_CAP_FLAG_VEP_UC_STEER &&
if (dev->caps.flags & MLX4_DEV_CAP_FLAG_VEP_UC_STEER && 
buf : 		    dev->caps.flags & MLX4_DEV_CAP_FLAG_VEP_MC_STEER)
buf : 			dev->caps.steering_mode = MLX4_STEERING_MODE_B0;
buf : 		else {
buf : 			dev->caps.steering_mode = MLX4_STEERING_MODE_A0;
buf : 
buf : 			if (dev->caps.flags & MLX4_DEV_CAP_FLAG_VEP_UC_STEER ||
if (dev->caps.flags & MLX4_DEV_CAP_FLAG_VEP_UC_STEER || 
buf : 			    dev->caps.flags & MLX4_DEV_CAP_FLAG_VEP_MC_STEER)
buf : 				mlx4_warn(dev, "Must have both UC_STEER and MC_STEER flags set to use B0 steering - falling back to A0 steering mode\n");
buf : 		}
buf : 		dev->oper_log_mgm_entry_size =
buf : 			mlx4_log_num_mgm_entry_size > 0 ?
buf : 			mlx4_log_num_mgm_entry_size :
buf : 			MLX4_DEFAULT_MGM_LOG_ENTRY_SIZE;
buf : 		dev->caps.num_qp_per_mgm = mlx4_get_qp_per_mgm(dev);
buf : 	}
buf : 	mlx4_dbg(dev, "Steering mode is: %s, oper_log_mgm_entry_size = %d, modparam log_num_mgm_entry_size = %d\n",
buf : 		 mlx4_steering_mode_str(dev->caps.steering_mode),
buf : 		 dev->oper_log_mgm_entry_size,
buf : 		 mlx4_log_num_mgm_entry_size);
buf : }
buf : 
buf : static void choose_tunnel_offload_mode(struct mlx4_dev *dev,
buf : 				       struct mlx4_dev_cap *dev_cap)
buf : {
buf : 	if (dev->caps.steering_mode == MLX4_STEERING_MODE_DEVICE_MANAGED &&
if (dev->caps.steering_mode == MLX4_STEERING_MODE_DEVICE_MANAGED && 
buf : 	    dev_cap->flags2 & MLX4_DEV_CAP_FLAG2_VXLAN_OFFLOADS)
buf : 		dev->caps.tunnel_offload_mode = MLX4_TUNNEL_OFFLOAD_MODE_VXLAN;
buf : 	else
buf : 		dev->caps.tunnel_offload_mode = MLX4_TUNNEL_OFFLOAD_MODE_NONE;
buf : 
buf : 	mlx4_dbg(dev, "Tunneling offload mode is: %s\n",  (dev->caps.tunnel_offload_mode
buf : 		 == MLX4_TUNNEL_OFFLOAD_MODE_VXLAN) ? "vxlan" : "none");
buf : }
buf : 
buf : static int mlx4_init_hca(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv	  *priv = mlx4_priv(dev);
buf : 	struct mlx4_adapter	   adapter;
buf : 	struct mlx4_dev_cap	   dev_cap;
buf : 	struct mlx4_mod_stat_cfg   mlx4_cfg;
buf : 	struct mlx4_profile	   profile;
buf : 	struct mlx4_init_hca_param init_hca;
buf : 	u64 icm_size;
buf : 	int err;
buf : 
buf : 	if (!mlx4_is_slave(dev)) {
if (!mlx4_is_slave(dev)) { 
buf : 		err = mlx4_QUERY_FW(dev);
buf : 		if (err) {
if (err) { 
buf : 			if (err == -EACCES)
buf : 				mlx4_info(dev, "non-primary physical function, skipping\n");
buf : 			else
buf : 				mlx4_err(dev, "QUERY_FW command failed, aborting\n");
buf : 			return err;
buf : 		}
buf : 
buf : 		err = mlx4_load_fw(dev);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(dev, "Failed to start FW, aborting\n");
buf : 			return err;
buf : 		}
buf : 
buf : 		mlx4_cfg.log_pg_sz_m = 1;
buf : 		mlx4_cfg.log_pg_sz = 0;
buf : 		err = mlx4_MOD_STAT_CFG(dev, &mlx4_cfg);
buf : 		if (err)
if (err) 
buf : 			mlx4_warn(dev, "Failed to override log_pg_sz parameter\n");
buf : 
buf : 		err = mlx4_dev_cap(dev, &dev_cap);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(dev, "QUERY_DEV_CAP command failed, aborting\n");
buf : 			goto err_stop_fw;
buf : 		}
buf : 
buf : 		choose_steering_mode(dev, &dev_cap);
buf : 		choose_tunnel_offload_mode(dev, &dev_cap);
buf : 
buf : 		err = mlx4_get_phys_port_id(dev);
buf : 		if (err)
if (err) 
buf : 			mlx4_err(dev, "Fail to get physical port id\n");
buf : 
buf : 		if (mlx4_is_master(dev))
if (mlx4_is_master(dev)) 
buf : 			mlx4_parav_master_pf_caps(dev);
buf : 
buf : 		profile = default_profile;
buf : 		if (dev->caps.steering_mode ==
if (dev->caps.steering_mode == 
buf : 		    MLX4_STEERING_MODE_DEVICE_MANAGED)
buf : 			profile.num_mcg = MLX4_FS_NUM_MCG;
buf : 
buf : 		icm_size = mlx4_make_profile(dev, &profile, &dev_cap,
buf : 					     &init_hca);
buf : 		if ((long long) icm_size < 0) {
if ((long long) icm_size < 0) { 
buf : 			err = icm_size;
buf : 			goto err_stop_fw;
buf : 		}
buf : 
buf : 		dev->caps.max_fmr_maps = (1 << (32 - ilog2(dev->caps.num_mpts))) - 1;
buf : 
buf : 		init_hca.log_uar_sz = ilog2(dev->caps.num_uars);
buf : 		init_hca.uar_page_sz = PAGE_SHIFT - 12;
buf : 		init_hca.mw_enabled = 0;
buf : 		if (dev->caps.flags & MLX4_DEV_CAP_FLAG_MEM_WINDOW ||
if (dev->caps.flags & MLX4_DEV_CAP_FLAG_MEM_WINDOW || 
buf : 		    dev->caps.bmme_flags & MLX4_BMME_FLAG_TYPE_2_WIN)
buf : 			init_hca.mw_enabled = INIT_HCA_TPT_MW_ENABLE;
buf : 
buf : 		err = mlx4_init_icm(dev, &dev_cap, &init_hca, icm_size);
buf : 		if (err)
if (err) 
buf : 			goto err_stop_fw;
buf : 
buf : 		err = mlx4_INIT_HCA(dev, &init_hca);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(dev, "INIT_HCA command failed, aborting\n");
buf : 			goto err_free_icm;
buf : 		}
buf : 		/*
buf : 		 * If TS is supported by FW
buf : 		 * read HCA frequency by QUERY_HCA command
buf : 		 */
buf : 		if (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_TS) {
if (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_TS) { 
buf : 			memset(&init_hca, 0, sizeof(init_hca));
buf : 			err = mlx4_QUERY_HCA(dev, &init_hca);
buf : 			if (err) {
if (err) { 
buf : 				mlx4_err(dev, "QUERY_HCA command failed, disable timestamp\n");
buf : 				dev->caps.flags2 &= ~MLX4_DEV_CAP_FLAG2_TS;
buf : 			} else {
buf : 				dev->caps.hca_core_clock =
buf : 					init_hca.hca_core_clock;
buf : 			}
buf : 
buf : 			/* In case we got HCA frequency 0 - disable timestamping
buf : 			 * to avoid dividing by zero
buf : 			 */
buf : 			if (!dev->caps.hca_core_clock) {
if (!dev->caps.hca_core_clock) { 
buf : 				dev->caps.flags2 &= ~MLX4_DEV_CAP_FLAG2_TS;
buf : 				mlx4_err(dev,
buf : 					 "HCA frequency is 0 - timestamping is not supported\n");
buf : 			} else if (map_internal_clock(dev)) {
if (map_internal_clock(dev)) { 
buf : 				/*
buf : 				 * Map internal clock,
buf : 				 * in case of failure disable timestamping
buf : 				 */
buf : 				dev->caps.flags2 &= ~MLX4_DEV_CAP_FLAG2_TS;
buf : 				mlx4_err(dev, "Failed to map internal clock. Timestamping is not supported\n");
buf : 			}
buf : 		}
buf : 	} else {
buf : 		err = mlx4_init_slave(dev);
buf : 		if (err) {
if (err) { 
buf : 			if (err != -EPROBE_DEFER)
buf : 				mlx4_err(dev, "Failed to initialize slave\n");
buf : 			return err;
buf : 		}
buf : 
buf : 		err = mlx4_slave_cap(dev);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(dev, "Failed to obtain slave caps\n");
buf : 			goto err_close;
buf : 		}
buf : 	}
buf : 
buf : 	if (map_bf_area(dev))
if (map_bf_area(dev)) 
buf : 		mlx4_dbg(dev, "Failed to map blue flame area\n");
buf : 
buf : 	/*Only the master set the ports, all the rest got it from it.*/
buf : 	if (!mlx4_is_slave(dev))
if (!mlx4_is_slave(dev)) 
buf : 		mlx4_set_port_mask(dev);
buf : 
buf : 	err = mlx4_QUERY_ADAPTER(dev, &adapter);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "QUERY_ADAPTER command failed, aborting\n");
buf : 		goto unmap_bf;
buf : 	}
buf : 
buf : 	priv->eq_table.inta_pin = adapter.inta_pin;
buf : 	memcpy(dev->board_id, adapter.board_id, sizeof dev->board_id);
buf : 
buf : 	return 0;
buf : 
buf : unmap_bf:
buf : 	unmap_internal_clock(dev);
buf : 	unmap_bf_area(dev);
buf : 
buf : 	if (mlx4_is_slave(dev)) {
if (mlx4_is_slave(dev)) { 
buf : 		kfree(dev->caps.qp0_qkey);
buf : 		kfree(dev->caps.qp0_tunnel);
buf : 		kfree(dev->caps.qp0_proxy);
buf : 		kfree(dev->caps.qp1_tunnel);
buf : 		kfree(dev->caps.qp1_proxy);
buf : 	}
buf : 
buf : err_close:
buf : 	if (mlx4_is_slave(dev))
if (mlx4_is_slave(dev)) 
buf : 		mlx4_slave_exit(dev);
buf : 	else
buf : 		mlx4_CLOSE_HCA(dev, 0);
buf : 
buf : err_free_icm:
buf : 	if (!mlx4_is_slave(dev))
if (!mlx4_is_slave(dev)) 
buf : 		mlx4_free_icms(dev);
buf : 
buf : err_stop_fw:
buf : 	if (!mlx4_is_slave(dev)) {
if (!mlx4_is_slave(dev)) { 
buf : 		mlx4_UNMAP_FA(dev);
buf : 		mlx4_free_icm(dev, priv->fw.fw_icm, 0);
buf : 	}
buf : 	return err;
buf : }
buf : 
buf : static int mlx4_init_counters_table(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	int nent;
buf : 
buf : 	if (!(dev->caps.flags & MLX4_DEV_CAP_FLAG_COUNTERS))
if (!(dev->caps.flags & MLX4_DEV_CAP_FLAG_COUNTERS)) 
buf : 		return -ENOENT;
buf : 
buf : 	nent = dev->caps.max_counters;
buf : 	return mlx4_bitmap_init(&priv->counters_bitmap, nent, nent - 1, 0, 0);
buf : }
buf : 
buf : static void mlx4_cleanup_counters_table(struct mlx4_dev *dev)
buf : {
buf : 	mlx4_bitmap_cleanup(&mlx4_priv(dev)->counters_bitmap);
buf : }
buf : 
buf : int __mlx4_counter_alloc(struct mlx4_dev *dev, u32 *idx)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 
buf : 	if (!(dev->caps.flags & MLX4_DEV_CAP_FLAG_COUNTERS))
if (!(dev->caps.flags & MLX4_DEV_CAP_FLAG_COUNTERS)) 
buf : 		return -ENOENT;
buf : 
buf : 	*idx = mlx4_bitmap_alloc(&priv->counters_bitmap);
buf : 	if (*idx == -1)
if (*idx == -1) 
buf : 		return -ENOMEM;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int mlx4_counter_alloc(struct mlx4_dev *dev, u32 *idx)
buf : {
buf : 	u64 out_param;
buf : 	int err;
buf : 
buf : 	if (mlx4_is_mfunc(dev)) {
if (mlx4_is_mfunc(dev)) { 
buf : 		err = mlx4_cmd_imm(dev, 0, &out_param, RES_COUNTER,
buf : 				   RES_OP_RESERVE, MLX4_CMD_ALLOC_RES,
buf : 				   MLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED);
buf : 		if (!err)
if (!err) 
buf : 			*idx = get_param_l(&out_param);
buf : 
buf : 		return err;
buf : 	}
buf : 	return __mlx4_counter_alloc(dev, idx);
buf : }
buf : EXPORT_SYMBOL_GPL(mlx4_counter_alloc);
buf : 
buf : void __mlx4_counter_free(struct mlx4_dev *dev, u32 idx)
buf : {
buf : 	mlx4_bitmap_free(&mlx4_priv(dev)->counters_bitmap, idx, MLX4_USE_RR);
buf : 	return;
buf : }
buf : 
buf : void mlx4_counter_free(struct mlx4_dev *dev, u32 idx)
buf : {
buf : 	u64 in_param = 0;
buf : 
buf : 	if (mlx4_is_mfunc(dev)) {
if (mlx4_is_mfunc(dev)) { 
buf : 		set_param_l(&in_param, idx);
buf : 		mlx4_cmd(dev, in_param, RES_COUNTER, RES_OP_RESERVE,
buf : 			 MLX4_CMD_FREE_RES, MLX4_CMD_TIME_CLASS_A,
buf : 			 MLX4_CMD_WRAPPED);
buf : 		return;
buf : 	}
buf : 	__mlx4_counter_free(dev, idx);
buf : }
buf : EXPORT_SYMBOL_GPL(mlx4_counter_free);
buf : 
buf : static int mlx4_setup_hca(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	int err;
buf : 	int port;
buf : 	__be32 ib_port_default_caps;
buf : 
buf : 	err = mlx4_init_uar_table(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to initialize user access region table, aborting\n");
buf : 		 return err;
buf : 	}
buf : 
buf : 	err = mlx4_uar_alloc(dev, &priv->driver_uar);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to allocate driver access region, aborting\n");
buf : 		goto err_uar_table_free;
buf : 	}
buf : 
buf : 	priv->kar = ioremap((phys_addr_t) priv->driver_uar.pfn << PAGE_SHIFT, PAGE_SIZE);
buf : 	if (!priv->kar) {
if (!priv->kar) { 
buf : 		mlx4_err(dev, "Couldn't map kernel access region, aborting\n");
buf : 		err = -ENOMEM;
buf : 		goto err_uar_free;
buf : 	}
buf : 
buf : 	err = mlx4_init_pd_table(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to initialize protection domain table, aborting\n");
buf : 		goto err_kar_unmap;
buf : 	}
buf : 
buf : 	err = mlx4_init_xrcd_table(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to initialize reliable connection domain table, aborting\n");
buf : 		goto err_pd_table_free;
buf : 	}
buf : 
buf : 	err = mlx4_init_mr_table(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to initialize memory region table, aborting\n");
buf : 		goto err_xrcd_table_free;
buf : 	}
buf : 
buf : 	if (!mlx4_is_slave(dev)) {
if (!mlx4_is_slave(dev)) { 
buf : 		err = mlx4_init_mcg_table(dev);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(dev, "Failed to initialize multicast group table, aborting\n");
buf : 			goto err_mr_table_free;
buf : 		}
buf : 	}
buf : 
buf : 	err = mlx4_init_eq_table(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to initialize event queue table, aborting\n");
buf : 		goto err_mcg_table_free;
buf : 	}
buf : 
buf : 	err = mlx4_cmd_use_events(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to switch to event-driven firmware commands, aborting\n");
buf : 		goto err_eq_table_free;
buf : 	}
buf : 
buf : 	err = mlx4_NOP(dev);
buf : 	if (err) {
if (err) { 
buf : 		if (dev->flags & MLX4_FLAG_MSI_X) {
buf : 			mlx4_warn(dev, "NOP command failed to generate MSI-X interrupt IRQ %d)\n",
buf : 				  priv->eq_table.eq[dev->caps.num_comp_vectors].irq);
buf : 			mlx4_warn(dev, "Trying again without MSI-X\n");
buf : 		} else {
buf : 			mlx4_err(dev, "NOP command failed to generate interrupt (IRQ %d), aborting\n",
buf : 				 priv->eq_table.eq[dev->caps.num_comp_vectors].irq);
buf : 			mlx4_err(dev, "BIOS or ACPI interrupt routing problem?\n");
buf : 		}
buf : 
buf : 		goto err_cmd_poll;
buf : 	}
buf : 
buf : 	mlx4_dbg(dev, "NOP command IRQ test passed\n");
buf : 
buf : 	err = mlx4_init_cq_table(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to initialize completion queue table, aborting\n");
buf : 		goto err_cmd_poll;
buf : 	}
buf : 
buf : 	err = mlx4_init_srq_table(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to initialize shared receive queue table, aborting\n");
buf : 		goto err_cq_table_free;
buf : 	}
buf : 
buf : 	err = mlx4_init_qp_table(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to initialize queue pair table, aborting\n");
buf : 		goto err_srq_table_free;
buf : 	}
buf : 
buf : 	err = mlx4_init_counters_table(dev);
buf : 	if (err && err != -ENOENT) {
if (err && err != -ENOENT) { 
buf : 		mlx4_err(dev, "Failed to initialize counters table, aborting\n");
buf : 		goto err_qp_table_free;
buf : 	}
buf : 
buf : 	if (!mlx4_is_slave(dev)) {
if (!mlx4_is_slave(dev)) { 
buf : 		for (port = 1; port <= dev->caps.num_ports; port++) {
for (port = 1; port <= dev->caps.num_ports; port++) { 
buf : 			ib_port_default_caps = 0;
buf : 			err = mlx4_get_port_ib_caps(dev, port,
buf : 						    &ib_port_default_caps);
buf : 			if (err)
if (err) 
buf : 				mlx4_warn(dev, "failed to get port %d default ib capabilities (%d). Continuing with caps = 0\n",
buf : 					  port, err);
buf : 			dev->caps.ib_port_def_cap[port] = ib_port_default_caps;
buf : 
buf : 			/* initialize per-slave default ib port capabilities */
buf : 			if (mlx4_is_master(dev)) {
if (mlx4_is_master(dev)) { 
buf : 				int i;
buf : 				for (i = 0; i < dev->num_slaves; i++) {
for (i = 0; i < dev->num_slaves; i++) { 
buf : 					if (i == mlx4_master_func_num(dev))
buf : 						continue;
buf : 					priv->mfunc.master.slave_state[i].ib_cap_mask[port] =
buf : 						ib_port_default_caps;
buf : 				}
buf : 			}
buf : 
buf : 			if (mlx4_is_mfunc(dev))
if (mlx4_is_mfunc(dev)) 
buf : 				dev->caps.port_ib_mtu[port] = IB_MTU_2048;
buf : 			else
buf : 				dev->caps.port_ib_mtu[port] = IB_MTU_4096;
buf : 
buf : 			err = mlx4_SET_PORT(dev, port, mlx4_is_master(dev) ?
buf : 					    dev->caps.pkey_table_len[port] : -1);
buf : 			if (err) {
if (err) { 
buf : 				mlx4_err(dev, "Failed to set port %d, aborting\n",
buf : 					 port);
buf : 				goto err_counters_table_free;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	return 0;
buf : 
buf : err_counters_table_free:
buf : 	mlx4_cleanup_counters_table(dev);
buf : 
buf : err_qp_table_free:
buf : 	mlx4_cleanup_qp_table(dev);
buf : 
buf : err_srq_table_free:
buf : 	mlx4_cleanup_srq_table(dev);
buf : 
buf : err_cq_table_free:
buf : 	mlx4_cleanup_cq_table(dev);
buf : 
buf : err_cmd_poll:
buf : 	mlx4_cmd_use_polling(dev);
buf : 
buf : err_eq_table_free:
buf : 	mlx4_cleanup_eq_table(dev);
buf : 
buf : err_mcg_table_free:
buf : 	if (!mlx4_is_slave(dev))
if (!mlx4_is_slave(dev)) 
buf : 		mlx4_cleanup_mcg_table(dev);
buf : 
buf : err_mr_table_free:
buf : 	mlx4_cleanup_mr_table(dev);
buf : 
buf : err_xrcd_table_free:
buf : 	mlx4_cleanup_xrcd_table(dev);
buf : 
buf : err_pd_table_free:
buf : 	mlx4_cleanup_pd_table(dev);
buf : 
buf : err_kar_unmap:
buf : 	iounmap(priv->kar);
buf : 
buf : err_uar_free:
buf : 	mlx4_uar_free(dev, &priv->driver_uar);
buf : 
buf : err_uar_table_free:
buf : 	mlx4_cleanup_uar_table(dev);
buf : 	return err;
buf : }
buf : 
buf : static void mlx4_enable_msi_x(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	struct msix_entry *entries;
buf : 	int nreq = min_t(int, dev->caps.num_ports *
buf : 			 min_t(int, num_online_cpus() + 1,
buf : 			       MAX_MSIX_P_PORT) + MSIX_LEGACY_SZ, MAX_MSIX);
buf : 	int i;
buf : 
buf : 	if (msi_x) {
if (msi_x) { 
buf : 		nreq = min_t(int, dev->caps.num_eqs - dev->caps.reserved_eqs,
buf : 			     nreq);
buf : 
buf : 		entries = kcalloc(nreq, sizeof *entries, GFP_KERNEL);
buf : 		if (!entries)
if (!entries) 
buf : 			goto no_msi;
buf : 
buf : 		for (i = 0; i < nreq; ++i)
for (i = 0; i < nreq; ++i) 
buf : 			entries[i].entry = i;
buf : 
buf : 		nreq = pci_enable_msix_range(dev->pdev, entries, 2, nreq);
buf : 
buf : 		if (nreq < 0) {
if (nreq < 0) { 
buf : 			kfree(entries);
buf : 			goto no_msi;
buf : 		} else if (nreq < MSIX_LEGACY_SZ +
if (nreq < MSIX_LEGACY_SZ + 
buf : 			   dev->caps.num_ports * MIN_MSIX_P_PORT) {
buf : 			/*Working in legacy mode , all EQ's shared*/
buf : 			dev->caps.comp_pool           = 0;
buf : 			dev->caps.num_comp_vectors = nreq - 1;
buf : 		} else {
buf : 			dev->caps.comp_pool           = nreq - MSIX_LEGACY_SZ;
buf : 			dev->caps.num_comp_vectors = MSIX_LEGACY_SZ - 1;
buf : 		}
buf : 		for (i = 0; i < nreq; ++i)
for (i = 0; i < nreq; ++i) 
buf : 			priv->eq_table.eq[i].irq = entries[i].vector;
buf : 
buf : 		dev->flags |= MLX4_FLAG_MSI_X;
buf : 
buf : 		kfree(entries);
buf : 		return;
buf : 	}
buf : 
buf : no_msi:
buf : 	dev->caps.num_comp_vectors = 1;
buf : 	dev->caps.comp_pool	   = 0;
buf : 
buf : 	for (i = 0; i < 2; ++i)
for (i = 0; i < 2; ++i) 
buf : 		priv->eq_table.eq[i].irq = dev->pdev->irq;
buf : }
buf : 
buf : static int mlx4_init_port_info(struct mlx4_dev *dev, int port)
buf : {
buf : 	struct mlx4_port_info *info = &mlx4_priv(dev)->port[port];
buf : 	int err = 0;
buf : 
buf : 	info->dev = dev;
buf : 	info->port = port;
buf : 	if (!mlx4_is_slave(dev)) {
if (!mlx4_is_slave(dev)) { 
buf : 		mlx4_init_mac_table(dev, &info->mac_table);
buf : 		mlx4_init_vlan_table(dev, &info->vlan_table);
buf : 		mlx4_init_roce_gid_table(dev, &info->gid_table);
buf : 		info->base_qpn = mlx4_get_base_qpn(dev, port);
buf : 	}
buf : 
buf : 	sprintf(info->dev_name, "mlx4_port%d", port);
buf : 	info->port_attr.attr.name = info->dev_name;
buf : 	if (mlx4_is_mfunc(dev))
if (mlx4_is_mfunc(dev)) 
buf : 		info->port_attr.attr.mode = S_IRUGO;
buf : 	else {
buf : 		info->port_attr.attr.mode = S_IRUGO | S_IWUSR;
buf : 		info->port_attr.store     = set_port_type;
buf : 	}
buf : 	info->port_attr.show      = show_port_type;
buf : 	sysfs_attr_init(&info->port_attr.attr);
buf : 
buf : 	err = device_create_file(&dev->pdev->dev, &info->port_attr);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to create file for port %d\n", port);
for port %d\n", port); 
buf : 		info->port = -1;
buf : 	}
buf : 
buf : 	sprintf(info->dev_mtu_name, "mlx4_port%d_mtu", port);
buf : 	info->port_mtu_attr.attr.name = info->dev_mtu_name;
buf : 	if (mlx4_is_mfunc(dev))
if (mlx4_is_mfunc(dev)) 
buf : 		info->port_mtu_attr.attr.mode = S_IRUGO;
buf : 	else {
buf : 		info->port_mtu_attr.attr.mode = S_IRUGO | S_IWUSR;
buf : 		info->port_mtu_attr.store     = set_port_ib_mtu;
buf : 	}
buf : 	info->port_mtu_attr.show      = show_port_ib_mtu;
buf : 	sysfs_attr_init(&info->port_mtu_attr.attr);
buf : 
buf : 	err = device_create_file(&dev->pdev->dev, &info->port_mtu_attr);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to create mtu file for port %d\n", port);
for port %d\n", port); 
buf : 		device_remove_file(&info->dev->pdev->dev, &info->port_attr);
buf : 		info->port = -1;
buf : 	}
buf : 
buf : 	return err;
buf : }
buf : 
buf : static void mlx4_cleanup_port_info(struct mlx4_port_info *info)
buf : {
buf : 	if (info->port < 0)
if (info->port < 0) 
buf : 		return;
buf : 
buf : 	device_remove_file(&info->dev->pdev->dev, &info->port_attr);
buf : 	device_remove_file(&info->dev->pdev->dev, &info->port_mtu_attr);
buf : }
buf : 
buf : static int mlx4_init_steering(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	int num_entries = dev->caps.num_ports;
buf : 	int i, j;
buf : 
buf : 	priv->steer = kzalloc(sizeof(struct mlx4_steer) * num_entries, GFP_KERNEL);
buf : 	if (!priv->steer)
if (!priv->steer) 
buf : 		return -ENOMEM;
buf : 
buf : 	for (i = 0; i < num_entries; i++)
for (i = 0; i < num_entries; i++) 
buf : 		for (j = 0; j < MLX4_NUM_STEERS; j++) {
buf : 			INIT_LIST_HEAD(&priv->steer[i].promisc_qps[j]);
buf : 			INIT_LIST_HEAD(&priv->steer[i].steer_entries[j]);
buf : 		}
buf : 	return 0;
buf : }
buf : 
buf : static void mlx4_clear_steering(struct mlx4_dev *dev)
buf : {
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	struct mlx4_steer_index *entry, *tmp_entry;
buf : 	struct mlx4_promisc_qp *pqp, *tmp_pqp;
buf : 	int num_entries = dev->caps.num_ports;
buf : 	int i, j;
buf : 
buf : 	for (i = 0; i < num_entries; i++) {
for (i = 0; i < num_entries; i++) { 
buf : 		for (j = 0; j < MLX4_NUM_STEERS; j++) {
buf : 			list_for_each_entry_safe(pqp, tmp_pqp,
for_each_entry_safe(pqp, tmp_pqp, 
buf : 						 &priv->steer[i].promisc_qps[j],
buf : 						 list) {
buf : 				list_del(&pqp->list);
buf : 				kfree(pqp);
buf : 			}
buf : 			list_for_each_entry_safe(entry, tmp_entry,
for_each_entry_safe(entry, tmp_entry, 
buf : 						 &priv->steer[i].steer_entries[j],
buf : 						 list) {
buf : 				list_del(&entry->list);
buf : 				list_for_each_entry_safe(pqp, tmp_pqp,
for_each_entry_safe(pqp, tmp_pqp, 
buf : 							 &entry->duplicates,
buf : 							 list) {
buf : 					list_del(&pqp->list);
buf : 					kfree(pqp);
buf : 				}
buf : 				kfree(entry);
buf : 			}
buf : 		}
buf : 	}
buf : 	kfree(priv->steer);
buf : }
buf : 
buf : static int extended_func_num(struct pci_dev *pdev)
buf : {
buf : 	return PCI_SLOT(pdev->devfn) * 8 + PCI_FUNC(pdev->devfn);
buf : }
buf : 
buf : #define MLX4_OWNER_BASE	0x8069c
buf : #define MLX4_OWNER_SIZE	4
buf : 
buf : static int mlx4_get_ownership(struct mlx4_dev *dev)
buf : {
buf : 	void __iomem *owner;
buf : 	u32 ret;
buf : 
buf : 	if (pci_channel_offline(dev->pdev))
if (pci_channel_offline(dev->pdev)) 
buf : 		return -EIO;
buf : 
buf : 	owner = ioremap(pci_resource_start(dev->pdev, 0) + MLX4_OWNER_BASE,
buf : 			MLX4_OWNER_SIZE);
buf : 	if (!owner) {
if (!owner) { 
buf : 		mlx4_err(dev, "Failed to obtain ownership bit\n");
buf : 		return -ENOMEM;
buf : 	}
buf : 
buf : 	ret = readl(owner);
buf : 	iounmap(owner);
buf : 	return (int) !!ret;
buf : }
buf : 
buf : static void mlx4_free_ownership(struct mlx4_dev *dev)
buf : {
buf : 	void __iomem *owner;
buf : 
buf : 	if (pci_channel_offline(dev->pdev))
if (pci_channel_offline(dev->pdev)) 
buf : 		return;
buf : 
buf : 	owner = ioremap(pci_resource_start(dev->pdev, 0) + MLX4_OWNER_BASE,
buf : 			MLX4_OWNER_SIZE);
buf : 	if (!owner) {
if (!owner) { 
buf : 		mlx4_err(dev, "Failed to obtain ownership bit\n");
buf : 		return;
buf : 	}
buf : 	writel(0, owner);
buf : 	msleep(1000);
buf : 	iounmap(owner);
buf : }
buf : 
buf : static int __mlx4_init_one(struct pci_dev *pdev, int pci_dev_data)
buf : {
buf : 	struct mlx4_priv *priv;
buf : 	struct mlx4_dev *dev;
buf : 	int err;
buf : 	int port;
buf : 	int nvfs[MLX4_MAX_PORTS + 1] = {0, 0, 0};
buf : 	int prb_vf[MLX4_MAX_PORTS + 1] = {0, 0, 0};
buf : 	const int param_map[MLX4_MAX_PORTS + 1][MLX4_MAX_PORTS + 1] = {
buf : 		{2, 0, 0}, {0, 1, 2}, {0, 1, 2} };
buf : 	unsigned total_vfs = 0;
buf : 	int sriov_initialized = 0;
buf : 	unsigned int i;
buf : 
buf : 	pr_info(DRV_NAME ": Initializing %s\n", pci_name(pdev));
buf : 
buf : 	err = pci_enable_device(pdev);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "Cannot enable PCI device, aborting\n");
buf : 		return err;
buf : 	}
buf : 
buf : 	/* Due to requirement that all VFs and the PF are *guaranteed* 2 MACS
buf : 	 * per port, we must limit the number of VFs to 63 (since their are
buf : 	 * 128 MACs)
buf : 	 */
buf : 	for (i = 0; i < sizeof(nvfs)/sizeof(nvfs[0]) && i < num_vfs_argc;
for (i = 0; i < sizeof(nvfs)/sizeof(nvfs[0]) && i < num_vfs_argc; 
buf : 	     total_vfs += nvfs[param_map[num_vfs_argc - 1][i]], i++) {
buf : 		nvfs[param_map[num_vfs_argc - 1][i]] = num_vfs[i];
buf : 		if (nvfs[i] < 0) {
if (nvfs[i] < 0) { 
buf : 			dev_err(&pdev->dev, "num_vfs module parameter cannot be negative\n");
buf : 			return -EINVAL;
buf : 		}
buf : 	}
buf : 	for (i = 0; i < sizeof(prb_vf)/sizeof(prb_vf[0]) && i < probe_vfs_argc;
for (i = 0; i < sizeof(prb_vf)/sizeof(prb_vf[0]) && i < probe_vfs_argc; 
buf : 	     i++) {
buf : 		prb_vf[param_map[probe_vfs_argc - 1][i]] = probe_vf[i];
buf : 		if (prb_vf[i] < 0 || prb_vf[i] > nvfs[i]) {
if (prb_vf[i] < 0 || prb_vf[i] > nvfs[i]) { 
buf : 			dev_err(&pdev->dev, "probe_vf module parameter cannot be negative or greater than num_vfs\n");
buf : 			return -EINVAL;
buf : 		}
buf : 	}
buf : 	if (total_vfs >= MLX4_MAX_NUM_VF) {
if (total_vfs >= MLX4_MAX_NUM_VF) { 
buf : 		dev_err(&pdev->dev,
buf : 			"Requested more VF's (%d) than allowed (%d)\n",
buf : 			total_vfs, MLX4_MAX_NUM_VF - 1);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	for (i = 0; i < MLX4_MAX_PORTS; i++) {
for (i = 0; i < MLX4_MAX_PORTS; i++) { 
buf : 		if (nvfs[i] + nvfs[2] >= MLX4_MAX_NUM_VF_P_PORT) {
buf : 			dev_err(&pdev->dev,
buf : 				"Requested more VF's (%d) for port (%d) than allowed (%d)\n",
for port (%d) than allowed (%d)\n", 
buf : 				nvfs[i] + nvfs[2], i + 1,
buf : 				MLX4_MAX_NUM_VF_P_PORT - 1);
buf : 			return -EINVAL;
buf : 		}
buf : 	}
buf : 
buf : 
buf : 	/*
buf : 	 * Check for BARs.
for BARs. 
buf : 	 */
buf : 	if (!(pci_dev_data & MLX4_PCI_DEV_IS_VF) &&
if (!(pci_dev_data & MLX4_PCI_DEV_IS_VF) && 
buf : 	    !(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {
buf : 		dev_err(&pdev->dev, "Missing DCS, aborting (driver_data: 0x%x, pci_resource_flags(pdev, 0):0x%lx)\n",
buf : 			pci_dev_data, pci_resource_flags(pdev, 0));
buf : 		err = -ENODEV;
buf : 		goto err_disable_pdev;
buf : 	}
buf : 	if (!(pci_resource_flags(pdev, 2) & IORESOURCE_MEM)) {
if (!(pci_resource_flags(pdev, 2) & IORESOURCE_MEM)) { 
buf : 		dev_err(&pdev->dev, "Missing UAR, aborting\n");
buf : 		err = -ENODEV;
buf : 		goto err_disable_pdev;
buf : 	}
buf : 
buf : 	err = pci_request_regions(pdev, DRV_NAME);
buf : 	if (err) {
if (err) { 
buf : 		dev_err(&pdev->dev, "Couldn't get PCI resources, aborting\n");
buf : 		goto err_disable_pdev;
buf : 	}
buf : 
buf : 	pci_set_master(pdev);
buf : 
buf : 	err = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));
buf : 	if (err) {
if (err) { 
buf : 		dev_warn(&pdev->dev, "Warning: couldn't set 64-bit PCI DMA mask\n");
buf : 		err = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
buf : 		if (err) {
if (err) { 
buf : 			dev_err(&pdev->dev, "Can't set PCI DMA mask, aborting\n");
buf : 			goto err_release_regions;
buf : 		}
buf : 	}
buf : 	err = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));
buf : 	if (err) {
if (err) { 
buf : 		dev_warn(&pdev->dev, "Warning: couldn't set 64-bit consistent PCI DMA mask\n");
buf : 		err = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
buf : 		if (err) {
if (err) { 
buf : 			dev_err(&pdev->dev, "Can't set consistent PCI DMA mask, aborting\n");
buf : 			goto err_release_regions;
buf : 		}
buf : 	}
buf : 
buf : 	/* Allow large DMA segments, up to the firmware limit of 1 GB */
buf : 	dma_set_max_seg_size(&pdev->dev, 1024 * 1024 * 1024);
buf : 
buf : 	dev       = pci_get_drvdata(pdev);
buf : 	priv      = mlx4_priv(dev);
buf : 	dev->pdev = pdev;
buf : 	INIT_LIST_HEAD(&priv->ctx_list);
buf : 	spin_lock_init(&priv->ctx_lock);
buf : 
buf : 	mutex_init(&priv->port_mutex);
buf : 
buf : 	INIT_LIST_HEAD(&priv->pgdir_list);
buf : 	mutex_init(&priv->pgdir_mutex);
buf : 
buf : 	INIT_LIST_HEAD(&priv->bf_list);
buf : 	mutex_init(&priv->bf_mutex);
buf : 
buf : 	dev->rev_id = pdev->revision;
buf : 	dev->numa_node = dev_to_node(&pdev->dev);
buf : 	/* Detect if this device is a virtual function */
if this device is a virtual function */ 
buf : 	if (pci_dev_data & MLX4_PCI_DEV_IS_VF) {
buf : 		/* When acting as pf, we normally skip vfs unless explicitly
buf : 		 * requested to probe them. */
buf : 		if (total_vfs) {
if (total_vfs) { 
buf : 			unsigned vfs_offset = 0;
buf : 			for (i = 0; i < sizeof(nvfs)/sizeof(nvfs[0]) &&
for (i = 0; i < sizeof(nvfs)/sizeof(nvfs[0]) && 
buf : 				     vfs_offset + nvfs[i] < extended_func_num(pdev);
buf : 			     vfs_offset += nvfs[i], i++)
buf : 				;
buf : 			if (i == sizeof(nvfs)/sizeof(nvfs[0])) {
if (i == sizeof(nvfs)/sizeof(nvfs[0])) { 
buf : 				err = -ENODEV;
buf : 				goto err_free_dev;
buf : 			}
buf : 			if ((extended_func_num(pdev) - vfs_offset)
if ((extended_func_num(pdev) - vfs_offset) 
buf : 			    > prb_vf[i]) {
buf : 				mlx4_warn(dev, "Skipping virtual function:%d\n",
buf : 					  extended_func_num(pdev));
buf : 				err = -ENODEV;
buf : 				goto err_free_dev;
buf : 			}
buf : 		}
buf : 		mlx4_warn(dev, "Detected virtual function - running in slave mode\n");
buf : 		dev->flags |= MLX4_FLAG_SLAVE;
buf : 	} else {
buf : 		/* We reset the device and enable SRIOV only for physical
for physical 
buf : 		 * devices.  Try to claim ownership on the device;
buf : 		 * if already taken, skip -- do not allow multiple PFs */
if already taken, skip -- do not allow multiple PFs */ 
buf : 		err = mlx4_get_ownership(dev);
buf : 		if (err) {
if (err) { 
buf : 			if (err < 0)
buf : 				goto err_free_dev;
buf : 			else {
buf : 				mlx4_warn(dev, "Multiple PFs not yet supported - Skipping PF\n");
buf : 				err = -EINVAL;
buf : 				goto err_free_dev;
buf : 			}
buf : 		}
buf : 
buf : 		if (total_vfs) {
if (total_vfs) { 
buf : 			mlx4_warn(dev, "Enabling SR-IOV with %d VFs\n",
buf : 				  total_vfs);
buf : 			dev->dev_vfs = kzalloc(
buf : 				total_vfs * sizeof(*dev->dev_vfs),
buf : 				GFP_KERNEL);
buf : 			if (NULL == dev->dev_vfs) {
if (NULL == dev->dev_vfs) { 
buf : 				mlx4_err(dev, "Failed to allocate memory for VFs\n");
for VFs\n"); 
buf : 				err = 0;
buf : 			} else {
buf : 				atomic_inc(&pf_loading);
buf : 				err = pci_enable_sriov(pdev, total_vfs);
buf : 				if (err) {
if (err) { 
buf : 					mlx4_err(dev, "Failed to enable SR-IOV, continuing without SR-IOV (err = %d)\n",
buf : 						 err);
buf : 					atomic_dec(&pf_loading);
buf : 					err = 0;
buf : 				} else {
buf : 					mlx4_warn(dev, "Running in master mode\n");
buf : 					dev->flags |= MLX4_FLAG_SRIOV |
buf : 						MLX4_FLAG_MASTER;
buf : 					dev->num_vfs = total_vfs;
buf : 					sriov_initialized = 1;
buf : 				}
buf : 			}
buf : 		}
buf : 
buf : 		atomic_set(&priv->opreq_count, 0);
buf : 		INIT_WORK(&priv->opreq_task, mlx4_opreq_action);
buf : 
buf : 		/*
buf : 		 * Now reset the HCA before we touch the PCI capabilities or
fore we touch the PCI capabilities or 
buf : 		 * attempt a firmware command, since a boot ROM may have left
buf : 		 * the HCA in an undefined state.
buf : 		 */
buf : 		err = mlx4_reset(dev);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(dev, "Failed to reset HCA, aborting\n");
buf : 			goto err_rel_own;
buf : 		}
buf : 	}
buf : 
buf : slave_start:
buf : 	err = mlx4_cmd_init(dev);
buf : 	if (err) {
if (err) { 
buf : 		mlx4_err(dev, "Failed to init command interface, aborting\n");
buf : 		goto err_sriov;
buf : 	}
buf : 
buf : 	/* In slave functions, the communication channel must be initialized
buf : 	 * before posting commands. Also, init num_slaves before calling
fore posting commands. Also, init num_slaves before calling 
buf : 	 * mlx4_init_hca */
buf : 	if (mlx4_is_mfunc(dev)) {
if (mlx4_is_mfunc(dev)) { 
buf : 		if (mlx4_is_master(dev))
buf : 			dev->num_slaves = MLX4_MAX_NUM_SLAVES;
buf : 		else {
buf : 			dev->num_slaves = 0;
buf : 			err = mlx4_multi_func_init(dev);
buf : 			if (err) {
if (err) { 
buf : 				mlx4_err(dev, "Failed to init slave mfunc interface, aborting\n");
buf : 				goto err_cmd;
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	err = mlx4_init_hca(dev);
buf : 	if (err) {
if (err) { 
buf : 		if (err == -EACCES) {
buf : 			/* Not primary Physical function
buf : 			 * Running in slave mode */
buf : 			mlx4_cmd_cleanup(dev);
buf : 			dev->flags |= MLX4_FLAG_SLAVE;
buf : 			dev->flags &= ~MLX4_FLAG_MASTER;
buf : 			goto slave_start;
buf : 		} else
buf : 			goto err_mfunc;
buf : 	}
buf : 
buf : 	/* check if the device is functioning at its maximum possible speed.
if the device is functioning at its maximum possible speed. 
buf : 	 * No return code for this call, just warn the user in case of PCI
for this call, just warn the user in case of PCI 
buf : 	 * express device capabilities are under-satisfied by the bus.
buf : 	 */
buf : 	if (!mlx4_is_slave(dev))
if (!mlx4_is_slave(dev)) 
buf : 		mlx4_check_pcie_caps(dev);
buf : 
buf : 	/* In master functions, the communication channel must be initialized
buf : 	 * after obtaining its address from fw */
buf : 	if (mlx4_is_master(dev)) {
if (mlx4_is_master(dev)) { 
buf : 		unsigned sum = 0;
buf : 		err = mlx4_multi_func_init(dev);
buf : 		if (err) {
if (err) { 
buf : 			mlx4_err(dev, "Failed to init master mfunc interface, aborting\n");
buf : 			goto err_close;
buf : 		}
buf : 		if (sriov_initialized) {
if (sriov_initialized) { 
buf : 			int ib_ports = 0;
buf : 			mlx4_foreach_port(i, dev, MLX4_PORT_TYPE_IB)
foreach_port(i, dev, MLX4_PORT_TYPE_IB) 
buf : 				ib_ports++;
buf : 
buf : 			if (ib_ports &&
if (ib_ports && 
buf : 			    (num_vfs_argc > 1 || probe_vfs_argc > 1)) {
buf : 				mlx4_err(dev,
buf : 					 "Invalid syntax of num_vfs/probe_vfs with IB port - single port VFs syntax is only supported when all ports are configured as ethernet\n");
buf : 				err = -EINVAL;
buf : 				goto err_master_mfunc;
buf : 			}
buf : 			for (i = 0; i < sizeof(nvfs)/sizeof(nvfs[0]); i++) {
for (i = 0; i < sizeof(nvfs)/sizeof(nvfs[0]); i++) { 
buf : 				unsigned j;
buf : 				for (j = 0; j < nvfs[i]; ++sum, ++j) {
for (j = 0; j < nvfs[i]; ++sum, ++j) { 
buf : 					dev->dev_vfs[sum].min_port =
buf : 						i < 2 ? i + 1 : 1;
buf : 					dev->dev_vfs[sum].n_ports = i < 2 ? 1 :
buf : 						dev->caps.num_ports;
buf : 				}
buf : 			}
buf : 		}
buf : 	}
buf : 
buf : 	err = mlx4_alloc_eq_table(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_master_mfunc;
buf : 
buf : 	priv->msix_ctl.pool_bm = 0;
buf : 	mutex_init(&priv->msix_ctl.pool_lock);
buf : 
buf : 	mlx4_enable_msi_x(dev);
buf : 	if ((mlx4_is_mfunc(dev)) &&
if ((mlx4_is_mfunc(dev)) && 
buf : 	    !(dev->flags & MLX4_FLAG_MSI_X)) {
buf : 		err = -ENOSYS;
buf : 		mlx4_err(dev, "INTx is not supported in multi-function mode, aborting\n");
buf : 		goto err_free_eq;
buf : 	}
buf : 
buf : 	if (!mlx4_is_slave(dev)) {
if (!mlx4_is_slave(dev)) { 
buf : 		err = mlx4_init_steering(dev);
buf : 		if (err)
if (err) 
buf : 			goto err_free_eq;
buf : 	}
buf : 
buf : 	err = mlx4_setup_hca(dev);
buf : 	if (err == -EBUSY && (dev->flags & MLX4_FLAG_MSI_X) &&
if (err == -EBUSY && (dev->flags & MLX4_FLAG_MSI_X) && 
buf : 	    !mlx4_is_mfunc(dev)) {
buf : 		dev->flags &= ~MLX4_FLAG_MSI_X;
buf : 		dev->caps.num_comp_vectors = 1;
buf : 		dev->caps.comp_pool	   = 0;
buf : 		pci_disable_msix(pdev);
buf : 		err = mlx4_setup_hca(dev);
buf : 	}
buf : 
buf : 	if (err)
if (err) 
buf : 		goto err_steer;
buf : 
buf : 	mlx4_init_quotas(dev);
buf : 
buf : 	for (port = 1; port <= dev->caps.num_ports; port++) {
for (port = 1; port <= dev->caps.num_ports; port++) { 
buf : 		err = mlx4_init_port_info(dev, port);
buf : 		if (err)
if (err) 
buf : 			goto err_port;
buf : 	}
buf : 
buf : 	err = mlx4_register_device(dev);
buf : 	if (err)
if (err) 
buf : 		goto err_port;
buf : 
buf : 	mlx4_request_modules(dev);
buf : 
buf : 	mlx4_sense_init(dev);
buf : 	mlx4_start_sense(dev);
buf : 
buf : 	priv->removed = 0;
buf : 
buf : 	if (mlx4_is_master(dev) && dev->num_vfs)
if (mlx4_is_master(dev) && dev->num_vfs) 
buf : 		atomic_dec(&pf_loading);
buf : 
buf : 	return 0;
buf : 
buf : err_port:
buf : 	for (--port; port >= 1; --port)
for (--port; port >= 1; --port) 
buf : 		mlx4_cleanup_port_info(&priv->port[port]);
buf : 
buf : 	mlx4_cleanup_counters_table(dev);
buf : 	mlx4_cleanup_qp_table(dev);
buf : 	mlx4_cleanup_srq_table(dev);
buf : 	mlx4_cleanup_cq_table(dev);
buf : 	mlx4_cmd_use_polling(dev);
buf : 	mlx4_cleanup_eq_table(dev);
buf : 	mlx4_cleanup_mcg_table(dev);
buf : 	mlx4_cleanup_mr_table(dev);
buf : 	mlx4_cleanup_xrcd_table(dev);
buf : 	mlx4_cleanup_pd_table(dev);
buf : 	mlx4_cleanup_uar_table(dev);
buf : 
buf : err_steer:
buf : 	if (!mlx4_is_slave(dev))
if (!mlx4_is_slave(dev)) 
buf : 		mlx4_clear_steering(dev);
buf : 
buf : err_free_eq:
buf : 	mlx4_free_eq_table(dev);
buf : 
buf : err_master_mfunc:
buf : 	if (mlx4_is_master(dev))
if (mlx4_is_master(dev)) 
buf : 		mlx4_multi_func_cleanup(dev);
buf : 
buf : 	if (mlx4_is_slave(dev)) {
if (mlx4_is_slave(dev)) { 
buf : 		kfree(dev->caps.qp0_qkey);
buf : 		kfree(dev->caps.qp0_tunnel);
buf : 		kfree(dev->caps.qp0_proxy);
buf : 		kfree(dev->caps.qp1_tunnel);
buf : 		kfree(dev->caps.qp1_proxy);
buf : 	}
buf : 
buf : err_close:
buf : 	if (dev->flags & MLX4_FLAG_MSI_X)
if (dev->flags & MLX4_FLAG_MSI_X) 
buf : 		pci_disable_msix(pdev);
buf : 
buf : 	mlx4_close_hca(dev);
buf : 
buf : err_mfunc:
buf : 	if (mlx4_is_slave(dev))
if (mlx4_is_slave(dev)) 
buf : 		mlx4_multi_func_cleanup(dev);
buf : 
buf : err_cmd:
buf : 	mlx4_cmd_cleanup(dev);
buf : 
buf : err_sriov:
buf : 	if (dev->flags & MLX4_FLAG_SRIOV)
if (dev->flags & MLX4_FLAG_SRIOV) 
buf : 		pci_disable_sriov(pdev);
buf : 
buf : err_rel_own:
buf : 	if (!mlx4_is_slave(dev))
if (!mlx4_is_slave(dev)) 
buf : 		mlx4_free_ownership(dev);
buf : 
buf : 	if (mlx4_is_master(dev) && dev->num_vfs)
if (mlx4_is_master(dev) && dev->num_vfs) 
buf : 		atomic_dec(&pf_loading);
buf : 
buf : 	kfree(priv->dev.dev_vfs);
buf : 
buf : err_free_dev:
buf : 	kfree(priv);
buf : 
buf : err_release_regions:
buf : 	pci_release_regions(pdev);
buf : 
buf : err_disable_pdev:
buf : 	pci_disable_device(pdev);
buf : 	pci_set_drvdata(pdev, NULL);
buf : 	return err;
buf : }
buf : 
buf : static int mlx4_init_one(struct pci_dev *pdev, const struct pci_device_id *id)
buf : {
buf : 	struct mlx4_priv *priv;
buf : 	struct mlx4_dev *dev;
buf : 
buf : 	printk_once(KERN_INFO "%s", mlx4_version);
buf : 
buf : 	priv = kzalloc(sizeof(*priv), GFP_KERNEL);
buf : 	if (!priv)
if (!priv) 
buf : 		return -ENOMEM;
buf : 
buf : 	dev       = &priv->dev;
buf : 	pci_set_drvdata(pdev, dev);
buf : 	priv->pci_dev_data = id->driver_data;
buf : 
buf : 	return __mlx4_init_one(pdev, id->driver_data);
buf : }
buf : 
buf : static void __mlx4_remove_one(struct pci_dev *pdev)
buf : {
buf : 	struct mlx4_dev  *dev  = pci_get_drvdata(pdev);
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	int               pci_dev_data;
buf : 	int p;
buf : 
buf : 	if (priv->removed)
if (priv->removed) 
buf : 		return;
buf : 
buf : 	pci_dev_data = priv->pci_dev_data;
buf : 
buf : 	/* in SRIOV it is not allowed to unload the pf's
buf : 	 * driver while there are alive vf's */
while there are alive vf's */ 
buf : 	if (mlx4_is_master(dev) && mlx4_how_many_lives_vf(dev))
buf : 		pr_warn("Removing PF when there are assigned VF's !!!\n");
buf : 	mlx4_stop_sense(dev);
buf : 	mlx4_unregister_device(dev);
buf : 
buf : 	for (p = 1; p <= dev->caps.num_ports; p++) {
for (p = 1; p <= dev->caps.num_ports; p++) { 
buf : 		mlx4_cleanup_port_info(&priv->port[p]);
buf : 		mlx4_CLOSE_PORT(dev, p);
buf : 	}
buf : 
buf : 	if (mlx4_is_master(dev))
if (mlx4_is_master(dev)) 
buf : 		mlx4_free_resource_tracker(dev,
buf : 					   RES_TR_FREE_SLAVES_ONLY);
buf : 
buf : 	mlx4_cleanup_counters_table(dev);
buf : 	mlx4_cleanup_qp_table(dev);
buf : 	mlx4_cleanup_srq_table(dev);
buf : 	mlx4_cleanup_cq_table(dev);
buf : 	mlx4_cmd_use_polling(dev);
buf : 	mlx4_cleanup_eq_table(dev);
buf : 	mlx4_cleanup_mcg_table(dev);
buf : 	mlx4_cleanup_mr_table(dev);
buf : 	mlx4_cleanup_xrcd_table(dev);
buf : 	mlx4_cleanup_pd_table(dev);
buf : 
buf : 	if (mlx4_is_master(dev))
if (mlx4_is_master(dev)) 
buf : 		mlx4_free_resource_tracker(dev,
buf : 					   RES_TR_FREE_STRUCTS_ONLY);
buf : 
buf : 	iounmap(priv->kar);
buf : 	mlx4_uar_free(dev, &priv->driver_uar);
buf : 	mlx4_cleanup_uar_table(dev);
buf : 	if (!mlx4_is_slave(dev))
if (!mlx4_is_slave(dev)) 
buf : 		mlx4_clear_steering(dev);
buf : 	mlx4_free_eq_table(dev);
buf : 	if (mlx4_is_master(dev))
if (mlx4_is_master(dev)) 
buf : 		mlx4_multi_func_cleanup(dev);
buf : 	mlx4_close_hca(dev);
buf : 	if (mlx4_is_slave(dev))
if (mlx4_is_slave(dev)) 
buf : 		mlx4_multi_func_cleanup(dev);
buf : 	mlx4_cmd_cleanup(dev);
buf : 
buf : 	if (dev->flags & MLX4_FLAG_MSI_X)
if (dev->flags & MLX4_FLAG_MSI_X) 
buf : 		pci_disable_msix(pdev);
buf : 	if (dev->flags & MLX4_FLAG_SRIOV) {
if (dev->flags & MLX4_FLAG_SRIOV) { 
buf : 		mlx4_warn(dev, "Disabling SR-IOV\n");
buf : 		pci_disable_sriov(pdev);
buf : 		dev->num_vfs = 0;
buf : 	}
buf : 
buf : 	if (!mlx4_is_slave(dev))
if (!mlx4_is_slave(dev)) 
buf : 		mlx4_free_ownership(dev);
buf : 
buf : 	kfree(dev->caps.qp0_qkey);
buf : 	kfree(dev->caps.qp0_tunnel);
buf : 	kfree(dev->caps.qp0_proxy);
buf : 	kfree(dev->caps.qp1_tunnel);
buf : 	kfree(dev->caps.qp1_proxy);
buf : 	kfree(dev->dev_vfs);
buf : 
buf : 	pci_release_regions(pdev);
buf : 	pci_disable_device(pdev);
buf : 	memset(priv, 0, sizeof(*priv));
buf : 	priv->pci_dev_data = pci_dev_data;
buf : 	priv->removed = 1;
buf : }
buf : 
buf : static void mlx4_remove_one(struct pci_dev *pdev)
buf : {
buf : 	struct mlx4_dev  *dev  = pci_get_drvdata(pdev);
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 
buf : 	__mlx4_remove_one(pdev);
buf : 	kfree(priv);
buf : 	pci_set_drvdata(pdev, NULL);
buf : }
buf : 
buf : int mlx4_restart_one(struct pci_dev *pdev)
buf : {
buf : 	struct mlx4_dev	 *dev  = pci_get_drvdata(pdev);
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	int		  pci_dev_data;
buf : 
buf : 	pci_dev_data = priv->pci_dev_data;
buf : 	__mlx4_remove_one(pdev);
buf : 	return __mlx4_init_one(pdev, pci_dev_data);
buf : }
buf : 
buf : static DEFINE_PCI_DEVICE_TABLE(mlx4_pci_table) = {
buf : 	/* MT25408 "Hermon" SDR */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x6340), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT25408 "Hermon" DDR */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x634a), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT25408 "Hermon" QDR */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x6354), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT25408 "Hermon" DDR PCIe gen2 */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x6732), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT25408 "Hermon" QDR PCIe gen2 */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x673c), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT25408 "Hermon" EN 10GigE */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x6368), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT25408 "Hermon" EN 10GigE PCIe gen2 */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x6750), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT25458 ConnectX EN 10GBASE-T 10GigE */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x6372), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT25458 ConnectX EN 10GBASE-T+Gen2 10GigE */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x675a), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT26468 ConnectX EN 10GigE PCIe gen2*/
buf : 	{ PCI_VDEVICE(MELLANOX, 0x6764), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT26438 ConnectX EN 40GigE PCIe gen2 5GT/s */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x6746), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT26478 ConnectX2 40GigE PCIe gen2 */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x676e), MLX4_PCI_DEV_FORCE_SENSE_PORT },
buf : 	/* MT25400 Family [ConnectX-2 Virtual Function] */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x1002), MLX4_PCI_DEV_IS_VF },
buf : 	/* MT27500 Family [ConnectX-3] */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x1003), 0 },
buf : 	/* MT27500 Family [ConnectX-3 Virtual Function] */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x1004), MLX4_PCI_DEV_IS_VF },
buf : 	{ PCI_VDEVICE(MELLANOX, 0x1005), 0 }, /* MT27510 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x1006), 0 }, /* MT27511 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x1007), 0 }, /* MT27520 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x1008), 0 }, /* MT27521 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x1009), 0 }, /* MT27530 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x100a), 0 }, /* MT27531 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x100b), 0 }, /* MT27540 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x100c), 0 }, /* MT27541 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x100d), 0 }, /* MT27550 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x100e), 0 }, /* MT27551 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x100f), 0 }, /* MT27560 Family */
buf : 	{ PCI_VDEVICE(MELLANOX, 0x1010), 0 }, /* MT27561 Family */
buf : 	{ 0, }
buf : };
buf : 
buf : MODULE_DEVICE_TABLE(pci, mlx4_pci_table);
buf : 
buf : static pci_ers_result_t mlx4_pci_err_detected(struct pci_dev *pdev,
buf : 					      pci_channel_state_t state)
buf : {
buf : 	__mlx4_remove_one(pdev);
buf : 
buf : 	return state == pci_channel_io_perm_failure ?
buf : 		PCI_ERS_RESULT_DISCONNECT : PCI_ERS_RESULT_NEED_RESET;
buf : }
buf : 
buf : static pci_ers_result_t mlx4_pci_slot_reset(struct pci_dev *pdev)
buf : {
buf : 	struct mlx4_dev	 *dev  = pci_get_drvdata(pdev);
buf : 	struct mlx4_priv *priv = mlx4_priv(dev);
buf : 	int               ret;
buf : 
buf : 	ret = __mlx4_init_one(pdev, priv->pci_dev_data);
buf : 
buf : 	return ret ? PCI_ERS_RESULT_DISCONNECT : PCI_ERS_RESULT_RECOVERED;
buf : }
buf : 
buf : static const struct pci_error_handlers mlx4_err_handler = {
buf : 	.error_detected = mlx4_pci_err_detected,
buf : 	.slot_reset     = mlx4_pci_slot_reset,
buf : };
buf : 
buf : static struct pci_driver mlx4_driver = {
buf : 	.name		= DRV_NAME,
buf : 	.id_table	= mlx4_pci_table,
buf : 	.probe		= mlx4_init_one,
buf : 	.shutdown	= __mlx4_remove_one,
buf : 	.remove		= mlx4_remove_one,
buf : 	.err_handler    = &mlx4_err_handler,
buf : };
buf : 
buf : static int __init mlx4_verify_params(void)
ify_params(void) 
buf : {
buf : 	if ((log_num_mac < 0) || (log_num_mac > 7)) {
buf : 		pr_warn("mlx4_core: bad num_mac: %d\n", log_num_mac);
buf : 		return -1;
buf : 	}
buf : 
buf : 	if (log_num_vlan != 0)
if (log_num_vlan != 0) 
buf : 		pr_warn("mlx4_core: log_num_vlan - obsolete module param, using %d\n",
buf : 			MLX4_LOG_NUM_VLANS);
buf : 
buf : 	if (use_prio != 0)
if (use_prio != 0) 
buf : 		pr_warn("mlx4_core: use_prio - obsolete module param, ignored\n");
buf : 
buf : 	if ((log_mtts_per_seg < 1) || (log_mtts_per_seg > 7)) {
if ((log_mtts_per_seg < 1) || (log_mtts_per_seg > 7)) { 
buf : 		pr_warn("mlx4_core: bad log_mtts_per_seg: %d\n",
buf : 			log_mtts_per_seg);
buf : 		return -1;
buf : 	}
buf : 
buf : 	/* Check if module param for ports type has legal combination */
if module param for ports type has legal combination */ 
buf : 	if (port_type_array[0] == false && port_type_array[1] == true) {
buf : 		pr_warn("Module parameter configuration ETH/IB is not supported. Switching to default configuration IB/IB\n");
buf : 		port_type_array[0] = true;
buf : 	}
buf : 
buf : 	if (mlx4_log_num_mgm_entry_size != -1 &&
if (mlx4_log_num_mgm_entry_size != -1 && 
buf : 	    (mlx4_log_num_mgm_entry_size < MLX4_MIN_MGM_LOG_ENTRY_SIZE ||
buf : 	     mlx4_log_num_mgm_entry_size > MLX4_MAX_MGM_LOG_ENTRY_SIZE)) {
buf : 		pr_warn("mlx4_core: mlx4_log_num_mgm_entry_size (%d) not in legal range (-1 or %d..%d)\n",
buf : 			mlx4_log_num_mgm_entry_size,
buf : 			MLX4_MIN_MGM_LOG_ENTRY_SIZE,
buf : 			MLX4_MAX_MGM_LOG_ENTRY_SIZE);
buf : 		return -1;
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static int __init mlx4_init(void)
buf : {
buf : 	int ret;
buf : 
buf : 	if (mlx4_verify_params())
if (mlx4_verify_params()) 
buf : 		return -EINVAL;
buf : 
buf : 	mlx4_catas_init();
buf : 
buf : 	mlx4_wq = create_singlethread_workqueue("mlx4");
buf : 	if (!mlx4_wq)
if (!mlx4_wq) 
buf : 		return -ENOMEM;
buf : 
buf : 	ret = pci_register_driver(&mlx4_driver);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		destroy_workqueue(mlx4_wq);
buf : 	return ret < 0 ? ret : 0;
buf : }
buf : 
buf : static void __exit mlx4_cleanup(void)
buf : {
buf : 	pci_unregister_driver(&mlx4_driver);
buf : 	destroy_workqueue(mlx4_wq);
buf : }
buf : 
buf : module_init(mlx4_init);
buf : module_exit(mlx4_cleanup);
file : ./test/kernel/net/batman-adv/main.c 
[ OK ] open : 4 ok... 
buf : /* Copyright (C) 2007-2014 B.A.T.M.A.N. contributors:
buf :  *
buf :  * Marek Lindner, Simon Wunderlich
buf :  *
buf :  * This program is free software; you can redistribute it and/or
buf :  * modify it under the terms of version 2 of the GNU General Public
ify it under the terms of version 2 of the GNU General Public 
buf :  * License as published by the Free Software Foundation.
buf :  *
buf :  * This program is distributed in the hope that it will be useful, but
buf :  * WITHOUT ANY WARRANTY; without even the implied warranty of
buf :  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
buf :  * General Public License for more details.
for more details. 
buf :  *
buf :  * You should have received a copy of the GNU General Public License
buf :  * along with this program; if not, see <http://www.gnu.org/licenses/>.
if not, see <http://www.gnu.org/licenses/>. 
buf :  */
buf : 
buf : #include <linux/crc32c.h>
buf : #include <linux/highmem.h>
buf : #include <linux/if_vlan.h>
if_vlan.h> 
buf : #include <net/ip.h>
buf : #include <net/ipv6.h>
buf : #include <net/dsfield.h>
buf : #include "main.h"
buf : #include "sysfs.h"
buf : #include "debugfs.h"
buf : #include "routing.h"
buf : #include "send.h"
buf : #include "originator.h"
buf : #include "soft-interface.h"
buf : #include "icmp_socket.h"
buf : #include "translation-table.h"
buf : #include "hard-interface.h"
buf : #include "gateway_client.h"
buf : #include "bridge_loop_avoidance.h"
buf : #include "distributed-arp-table.h"
buf : #include "multicast.h"
buf : #include "gateway_common.h"
buf : #include "hash.h"
buf : #include "bat_algo.h"
buf : #include "network-coding.h"
buf : #include "fragmentation.h"
buf : 
buf : 
buf : /* List manipulations on hardif_list have to be rtnl_lock()'ed,
if_list have to be rtnl_lock()'ed, 
buf :  * list traversals just rcu-locked
buf :  */
buf : struct list_head batadv_hardif_list;
if_list; 
buf : static int (*batadv_rx_handler[256])(struct sk_buff *,
buf : 				     struct batadv_hard_iface *);
iface *); 
buf : char batadv_routing_algo[20] = "BATMAN_IV";
buf : static struct hlist_head batadv_algo_list;
buf : 
buf : unsigned char batadv_broadcast_addr[] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff};
buf : 
buf : struct workqueue_struct *batadv_event_workqueue;
buf : 
buf : static void batadv_recv_handler_init(void);
buf : 
buf : static int __init batadv_init(void)
buf : {
buf : 	INIT_LIST_HEAD(&batadv_hardif_list);
if_list); 
buf : 	INIT_HLIST_HEAD(&batadv_algo_list);
buf : 
buf : 	batadv_recv_handler_init();
buf : 
buf : 	batadv_iv_init();
buf : 	batadv_nc_init();
buf : 
buf : 	batadv_event_workqueue = create_singlethread_workqueue("bat_events");
buf : 
buf : 	if (!batadv_event_workqueue)
if (!batadv_event_workqueue) 
buf : 		return -ENOMEM;
buf : 
buf : 	batadv_socket_init();
buf : 	batadv_debugfs_init();
buf : 
buf : 	register_netdevice_notifier(&batadv_hard_if_notifier);
ifier(&batadv_hard_if_notifier); 
buf : 	rtnl_link_register(&batadv_link_ops);
buf : 
buf : 	pr_info("B.A.T.M.A.N. advanced %s (compatibility version %i) loaded\n",
buf : 		BATADV_SOURCE_VERSION, BATADV_COMPAT_VERSION);
buf : 
buf : 	return 0;
buf : }
buf : 
buf : static void __exit batadv_exit(void)
buf : {
buf : 	batadv_debugfs_destroy();
buf : 	rtnl_link_unregister(&batadv_link_ops);
buf : 	unregister_netdevice_notifier(&batadv_hard_if_notifier);
ifier(&batadv_hard_if_notifier); 
buf : 	batadv_hardif_remove_interfaces();
buf : 
buf : 	flush_workqueue(batadv_event_workqueue);
buf : 	destroy_workqueue(batadv_event_workqueue);
buf : 	batadv_event_workqueue = NULL;
buf : 
buf : 	rcu_barrier();
buf : }
buf : 
buf : int batadv_mesh_init(struct net_device *soft_iface)
iface) 
buf : {
buf : 	struct batadv_priv *bat_priv = netdev_priv(soft_iface);
buf : 	int ret;
buf : 
buf : 	spin_lock_init(&bat_priv->forw_bat_list_lock);
forw_bat_list_lock); 
buf : 	spin_lock_init(&bat_priv->forw_bcast_list_lock);
buf : 	spin_lock_init(&bat_priv->tt.changes_list_lock);
buf : 	spin_lock_init(&bat_priv->tt.req_list_lock);
buf : 	spin_lock_init(&bat_priv->tt.roam_list_lock);
buf : 	spin_lock_init(&bat_priv->tt.last_changeset_lock);
buf : 	spin_lock_init(&bat_priv->tt.commit_lock);
buf : 	spin_lock_init(&bat_priv->gw.list_lock);
buf : #ifdef CONFIG_BATMAN_ADV_MCAST
ifdef CONFIG_BATMAN_ADV_MCAST 
buf : 	spin_lock_init(&bat_priv->mcast.want_lists_lock);
buf : #endif
if 
buf : 	spin_lock_init(&bat_priv->tvlv.container_list_lock);
buf : 	spin_lock_init(&bat_priv->tvlv.handler_list_lock);
buf : 	spin_lock_init(&bat_priv->softif_vlan_list_lock);
if_vlan_list_lock); 
buf : 
buf : 	INIT_HLIST_HEAD(&bat_priv->forw_bat_list);
forw_bat_list); 
buf : 	INIT_HLIST_HEAD(&bat_priv->forw_bcast_list);
buf : 	INIT_HLIST_HEAD(&bat_priv->gw.list);
buf : #ifdef CONFIG_BATMAN_ADV_MCAST
ifdef CONFIG_BATMAN_ADV_MCAST 
buf : 	INIT_HLIST_HEAD(&bat_priv->mcast.want_all_unsnoopables_list);
buf : 	INIT_HLIST_HEAD(&bat_priv->mcast.want_all_ipv4_list);
buf : 	INIT_HLIST_HEAD(&bat_priv->mcast.want_all_ipv6_list);
buf : #endif
if 
buf : 	INIT_LIST_HEAD(&bat_priv->tt.changes_list);
buf : 	INIT_LIST_HEAD(&bat_priv->tt.req_list);
buf : 	INIT_LIST_HEAD(&bat_priv->tt.roam_list);
buf : #ifdef CONFIG_BATMAN_ADV_MCAST
ifdef CONFIG_BATMAN_ADV_MCAST 
buf : 	INIT_HLIST_HEAD(&bat_priv->mcast.mla_list);
buf : #endif
if 
buf : 	INIT_HLIST_HEAD(&bat_priv->tvlv.container_list);
buf : 	INIT_HLIST_HEAD(&bat_priv->tvlv.handler_list);
buf : 	INIT_HLIST_HEAD(&bat_priv->softif_vlan_list);
if_vlan_list); 
buf : 
buf : 	ret = batadv_originator_init(bat_priv);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto err;
buf : 
buf : 	ret = batadv_tt_init(bat_priv);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto err;
buf : 
buf : 	ret = batadv_bla_init(bat_priv);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto err;
buf : 
buf : 	ret = batadv_dat_init(bat_priv);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto err;
buf : 
buf : 	ret = batadv_nc_mesh_init(bat_priv);
buf : 	if (ret < 0)
if (ret < 0) 
buf : 		goto err;
buf : 
buf : 	batadv_gw_init(bat_priv);
buf : 	batadv_mcast_init(bat_priv);
buf : 
buf : 	atomic_set(&bat_priv->gw.reselect, 0);
buf : 	atomic_set(&bat_priv->mesh_state, BATADV_MESH_ACTIVE);
buf : 
buf : 	return 0;
buf : 
buf : err:
buf : 	batadv_mesh_free(soft_iface);
iface); 
buf : 	return ret;
buf : }
buf : 
buf : void batadv_mesh_free(struct net_device *soft_iface)
iface) 
buf : {
buf : 	struct batadv_priv *bat_priv = netdev_priv(soft_iface);
buf : 
buf : 	atomic_set(&bat_priv->mesh_state, BATADV_MESH_DEACTIVATING);
buf : 
buf : 	batadv_purge_outstanding_packets(bat_priv, NULL);
buf : 
buf : 	batadv_gw_node_purge(bat_priv);
buf : 	batadv_nc_mesh_free(bat_priv);
buf : 	batadv_dat_free(bat_priv);
buf : 	batadv_bla_free(bat_priv);
buf : 
buf : 	batadv_mcast_free(bat_priv);
buf : 
buf : 	/* Free the TT and the originator tables only after having terminated
buf : 	 * all the other depending components which may use these structures for
for 
buf : 	 * their purposes.
buf : 	 */
buf : 	batadv_tt_free(bat_priv);
buf : 
buf : 	/* Since the originator table clean up routine is accessing the TT
buf : 	 * tables as well, it has to be invoked after the TT tables have been
buf : 	 * freed and marked as empty. This ensures that no cleanup RCU callbacks
buf : 	 * accessing the TT data are scheduled for later execution.
for later execution. 
buf : 	 */
buf : 	batadv_originator_free(bat_priv);
buf : 
buf : 	batadv_gw_free(bat_priv);
buf : 
buf : 	free_percpu(bat_priv->bat_counters);
buf : 	bat_priv->bat_counters = NULL;
buf : 
buf : 	atomic_set(&bat_priv->mesh_state, BATADV_MESH_INACTIVE);
buf : }
buf : 
buf : /**
buf :  * batadv_is_my_mac - check if the given mac address belongs to any of the real
if the given mac address belongs to any of the real 
buf :  * interfaces in the current mesh
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @addr: the address to check
buf :  */
buf : int batadv_is_my_mac(struct batadv_priv *bat_priv, const uint8_t *addr)
buf : {
buf : 	const struct batadv_hard_iface *hard_iface;
iface *hard_iface; 
buf : 
buf : 	rcu_read_lock();
buf : 	list_for_each_entry_rcu(hard_iface, &batadv_hardif_list, list) {
iface, &batadv_hardif_list, list) { 
buf : 		if (hard_iface->if_status != BATADV_IF_ACTIVE)
buf : 			continue;
buf : 
buf : 		if (hard_iface->soft_iface != bat_priv->soft_iface)
if (hard_iface->soft_iface != bat_priv->soft_iface) 
buf : 			continue;
buf : 
buf : 		if (batadv_compare_eth(hard_iface->net_dev->dev_addr, addr)) {
if (batadv_compare_eth(hard_iface->net_dev->dev_addr, addr)) { 
buf : 			rcu_read_unlock();
buf : 			return 1;
buf : 		}
buf : 	}
buf : 	rcu_read_unlock();
buf : 	return 0;
buf : }
buf : 
buf : /**
buf :  * batadv_seq_print_text_primary_if_get - called from debugfs table printing
if_get - called from debugfs table printing 
buf :  *  function that requires the primary interface
buf :  * @seq: debugfs table seq_file struct
buf :  *
buf :  * Returns primary interface if found or NULL otherwise.
if found or NULL otherwise. 
buf :  */
buf : struct batadv_hard_iface *
iface * 
buf : batadv_seq_print_text_primary_if_get(struct seq_file *seq)
buf : {
buf : 	struct net_device *net_dev = (struct net_device *)seq->private;
buf : 	struct batadv_priv *bat_priv = netdev_priv(net_dev);
buf : 	struct batadv_hard_iface *primary_if;
iface *primary_if; 
buf : 
buf : 	primary_if = batadv_primary_if_get_selected(bat_priv);
buf : 
buf : 	if (!primary_if) {
if (!primary_if) { 
buf : 		seq_printf(seq,
buf : 			   "BATMAN mesh %s disabled - please specify interfaces to enable it\n",
ify interfaces to enable it\n", 
buf : 			   net_dev->name);
buf : 		goto out;
buf : 	}
buf : 
buf : 	if (primary_if->if_status == BATADV_IF_ACTIVE)
if (primary_if->if_status == BATADV_IF_ACTIVE) 
buf : 		goto out;
buf : 
buf : 	seq_printf(seq,
buf : 		   "BATMAN mesh %s disabled - primary interface not active\n",
buf : 		   net_dev->name);
buf : 	batadv_hardif_free_ref(primary_if);
if_free_ref(primary_if); 
buf : 	primary_if = NULL;
buf : 
buf : out:
buf : 	return primary_if;
if; 
buf : }
buf : 
buf : /**
buf :  * batadv_max_header_len - calculate maximum encapsulation overhead for a
for a 
buf :  *  payload packet
buf :  *
buf :  * Return the maximum encapsulation overhead in bytes.
buf :  */
buf : int batadv_max_header_len(void)
buf : {
buf : 	int header_len = 0;
buf : 
buf : 	header_len = max_t(int, header_len,
buf : 			   sizeof(struct batadv_unicast_packet));
buf : 	header_len = max_t(int, header_len,
buf : 			   sizeof(struct batadv_unicast_4addr_packet));
buf : 	header_len = max_t(int, header_len,
buf : 			   sizeof(struct batadv_bcast_packet));
buf : 
buf : #ifdef CONFIG_BATMAN_ADV_NC
ifdef CONFIG_BATMAN_ADV_NC 
buf : 	header_len = max_t(int, header_len,
buf : 			   sizeof(struct batadv_coded_packet));
buf : #endif
if 
buf : 
buf : 	return header_len + ETH_HLEN;
buf : }
buf : 
buf : /**
buf :  * batadv_skb_set_priority - sets skb priority according to packet content
buf :  * @skb: the packet to be sent
buf :  * @offset: offset to the packet content
buf :  *
buf :  * This function sets a value between 256 and 263 (802.1d priority), which
buf :  * can be interpreted by the cfg80211 or other drivers.
buf :  */
buf : void batadv_skb_set_priority(struct sk_buff *skb, int offset)
buf : {
buf : 	struct iphdr ip_hdr_tmp, *ip_hdr;
buf : 	struct ipv6hdr ip6_hdr_tmp, *ip6_hdr;
buf : 	struct ethhdr ethhdr_tmp, *ethhdr;
buf : 	struct vlan_ethhdr *vhdr, vhdr_tmp;
buf : 	u32 prio;
buf : 
buf : 	/* already set, do nothing */
buf : 	if (skb->priority >= 256 && skb->priority <= 263)
if (skb->priority >= 256 && skb->priority <= 263) 
buf : 		return;
buf : 
buf : 	ethhdr = skb_header_pointer(skb, offset, sizeof(*ethhdr), &ethhdr_tmp);
buf : 	if (!ethhdr)
if (!ethhdr) 
buf : 		return;
buf : 
buf : 	switch (ethhdr->h_proto) {
buf : 	case htons(ETH_P_8021Q):
buf : 		vhdr = skb_header_pointer(skb, offset + sizeof(*vhdr),
buf : 					  sizeof(*vhdr), &vhdr_tmp);
buf : 		if (!vhdr)
if (!vhdr) 
buf : 			return;
buf : 		prio = ntohs(vhdr->h_vlan_TCI) & VLAN_PRIO_MASK;
buf : 		prio = prio >> VLAN_PRIO_SHIFT;
buf : 		break;
buf : 	case htons(ETH_P_IP):
buf : 		ip_hdr = skb_header_pointer(skb, offset + sizeof(*ethhdr),
buf : 					    sizeof(*ip_hdr), &ip_hdr_tmp);
buf : 		if (!ip_hdr)
if (!ip_hdr) 
buf : 			return;
buf : 		prio = (ipv4_get_dsfield(ip_hdr) & 0xfc) >> 5;
buf : 		break;
buf : 	case htons(ETH_P_IPV6):
buf : 		ip6_hdr = skb_header_pointer(skb, offset + sizeof(*ethhdr),
buf : 					     sizeof(*ip6_hdr), &ip6_hdr_tmp);
buf : 		if (!ip6_hdr)
if (!ip6_hdr) 
buf : 			return;
buf : 		prio = (ipv6_get_dsfield(ip6_hdr) & 0xfc) >> 5;
buf : 		break;
buf : 	default:
buf : 		return;
buf : 	}
buf : 
buf : 	skb->priority = prio + 256;
buf : }
buf : 
buf : static int batadv_recv_unhandled_packet(struct sk_buff *skb,
buf : 					struct batadv_hard_iface *recv_if)
iface *recv_if) 
buf : {
buf : 	return NET_RX_DROP;
buf : }
buf : 
buf : /* incoming packets with the batman ethertype received on any active hard
buf :  * interface
buf :  */
buf : int batadv_batman_skb_recv(struct sk_buff *skb, struct net_device *dev,
buf : 			   struct packet_type *ptype,
buf : 			   struct net_device *orig_dev)
buf : {
buf : 	struct batadv_priv *bat_priv;
buf : 	struct batadv_ogm_packet *batadv_ogm_packet;
buf : 	struct batadv_hard_iface *hard_iface;
iface *hard_iface; 
buf : 	uint8_t idx;
buf : 	int ret;
buf : 
buf : 	hard_iface = container_of(ptype, struct batadv_hard_iface,
iface = container_of(ptype, struct batadv_hard_iface, 
buf : 				  batman_adv_ptype);
buf : 	skb = skb_share_check(skb, GFP_ATOMIC);
buf : 
buf : 	/* skb was released by skb_share_check() */
buf : 	if (!skb)
if (!skb) 
buf : 		goto err_out;
buf : 
buf : 	/* packet should hold at least type and version */
buf : 	if (unlikely(!pskb_may_pull(skb, 2)))
if (unlikely(!pskb_may_pull(skb, 2))) 
buf : 		goto err_free;
buf : 
buf : 	/* expect a valid ethernet header here. */
buf : 	if (unlikely(skb->mac_len != ETH_HLEN || !skb_mac_header(skb)))
if (unlikely(skb->mac_len != ETH_HLEN || !skb_mac_header(skb))) 
buf : 		goto err_free;
buf : 
buf : 	if (!hard_iface->soft_iface)
if (!hard_iface->soft_iface) 
buf : 		goto err_free;
buf : 
buf : 	bat_priv = netdev_priv(hard_iface->soft_iface);
iface->soft_iface); 
buf : 
buf : 	if (atomic_read(&bat_priv->mesh_state) != BATADV_MESH_ACTIVE)
buf : 		goto err_free;
buf : 
buf : 	/* discard frames on not active interfaces */
buf : 	if (hard_iface->if_status != BATADV_IF_ACTIVE)
if (hard_iface->if_status != BATADV_IF_ACTIVE) 
buf : 		goto err_free;
buf : 
buf : 	batadv_ogm_packet = (struct batadv_ogm_packet *)skb->data;
buf : 
buf : 	if (batadv_ogm_packet->version != BATADV_COMPAT_VERSION) {
if (batadv_ogm_packet->version != BATADV_COMPAT_VERSION) { 
buf : 		batadv_dbg(BATADV_DBG_BATMAN, bat_priv,
buf : 			   "Drop packet: incompatible batman version (%i)\n",
buf : 			   batadv_ogm_packet->version);
buf : 		goto err_free;
buf : 	}
buf : 
buf : 	/* all receive handlers return whether they received or reused
buf : 	 * the supplied skb. if not, we have to free the skb.
if not, we have to free the skb. 
buf : 	 */
buf : 	idx = batadv_ogm_packet->packet_type;
buf : 	ret = (*batadv_rx_handler[idx])(skb, hard_iface);
iface); 
buf : 
buf : 	if (ret == NET_RX_DROP)
buf : 		kfree_skb(skb);
buf : 
buf : 	/* return NET_RX_SUCCESS in any case as we
buf : 	 * most probably dropped the packet for
for 
buf : 	 * routing-logical reasons.
buf : 	 */
buf : 	return NET_RX_SUCCESS;
buf : 
buf : err_free:
buf : 	kfree_skb(skb);
buf : err_out:
buf : 	return NET_RX_DROP;
buf : }
buf : 
buf : static void batadv_recv_handler_init(void)
buf : {
buf : 	int i;
buf : 
buf : 	for (i = 0; i < ARRAY_SIZE(batadv_rx_handler); i++)
for (i = 0; i < ARRAY_SIZE(batadv_rx_handler); i++) 
buf : 		batadv_rx_handler[i] = batadv_recv_unhandled_packet;
buf : 
buf : 	for (i = BATADV_UNICAST_MIN; i <= BATADV_UNICAST_MAX; i++)
for (i = BATADV_UNICAST_MIN; i <= BATADV_UNICAST_MAX; i++) 
buf : 		batadv_rx_handler[i] = batadv_recv_unhandled_unicast_packet;
buf : 
buf : 	/* compile time checks for sizes */
for sizes */ 
buf : 	BUILD_BUG_ON(sizeof(struct batadv_bla_claim_dst) != 6);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_ogm_packet) != 24);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_icmp_header) != 20);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_icmp_packet) != 20);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_icmp_packet_rr) != 116);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_unicast_packet) != 10);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_unicast_4addr_packet) != 18);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_frag_packet) != 20);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_bcast_packet) != 14);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_coded_packet) != 46);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_unicast_tvlv_packet) != 20);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_tvlv_hdr) != 4);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_tvlv_gateway_data) != 8);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_tvlv_tt_vlan_data) != 8);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_tvlv_tt_change) != 12);
buf : 	BUILD_BUG_ON(sizeof(struct batadv_tvlv_roam_adv) != 8);
buf : 
buf : 	/* broadcast packet */
buf : 	batadv_rx_handler[BATADV_BCAST] = batadv_recv_bcast_packet;
buf : 
buf : 	/* unicast packets ... */
buf : 	/* unicast with 4 addresses packet */
buf : 	batadv_rx_handler[BATADV_UNICAST_4ADDR] = batadv_recv_unicast_packet;
buf : 	/* unicast packet */
buf : 	batadv_rx_handler[BATADV_UNICAST] = batadv_recv_unicast_packet;
buf : 	/* unicast tvlv packet */
buf : 	batadv_rx_handler[BATADV_UNICAST_TVLV] = batadv_recv_unicast_tvlv;
buf : 	/* batman icmp packet */
buf : 	batadv_rx_handler[BATADV_ICMP] = batadv_recv_icmp_packet;
buf : 	/* Fragmented packets */
buf : 	batadv_rx_handler[BATADV_UNICAST_FRAG] = batadv_recv_frag_packet;
buf : }
buf : 
buf : int
buf : batadv_recv_handler_register(uint8_t packet_type,
buf : 			     int (*recv_handler)(struct sk_buff *,
buf : 						 struct batadv_hard_iface *))
iface *)) 
buf : {
buf : 	int (*curr)(struct sk_buff *,
buf : 		    struct batadv_hard_iface *);
iface *); 
buf : 	curr = batadv_rx_handler[packet_type];
buf : 
buf : 	if ((curr != batadv_recv_unhandled_packet) &&
if ((curr != batadv_recv_unhandled_packet) && 
buf : 	    (curr != batadv_recv_unhandled_unicast_packet))
buf : 		return -EBUSY;
buf : 
buf : 	batadv_rx_handler[packet_type] = recv_handler;
buf : 	return 0;
buf : }
buf : 
buf : void batadv_recv_handler_unregister(uint8_t packet_type)
buf : {
buf : 	batadv_rx_handler[packet_type] = batadv_recv_unhandled_packet;
buf : }
buf : 
buf : static struct batadv_algo_ops *batadv_algo_get(char *name)
buf : {
buf : 	struct batadv_algo_ops *bat_algo_ops = NULL, *bat_algo_ops_tmp;
buf : 
buf : 	hlist_for_each_entry(bat_algo_ops_tmp, &batadv_algo_list, list) {
for_each_entry(bat_algo_ops_tmp, &batadv_algo_list, list) { 
buf : 		if (strcmp(bat_algo_ops_tmp->name, name) != 0)
buf : 			continue;
buf : 
buf : 		bat_algo_ops = bat_algo_ops_tmp;
buf : 		break;
buf : 	}
buf : 
buf : 	return bat_algo_ops;
buf : }
buf : 
buf : int batadv_algo_register(struct batadv_algo_ops *bat_algo_ops)
buf : {
buf : 	struct batadv_algo_ops *bat_algo_ops_tmp;
buf : 	int ret;
buf : 
buf : 	bat_algo_ops_tmp = batadv_algo_get(bat_algo_ops->name);
buf : 	if (bat_algo_ops_tmp) {
if (bat_algo_ops_tmp) { 
buf : 		pr_info("Trying to register already registered routing algorithm: %s\n",
buf : 			bat_algo_ops->name);
buf : 		ret = -EEXIST;
buf : 		goto out;
buf : 	}
buf : 
buf : 	/* all algorithms must implement all ops (for now) */
for now) */ 
buf : 	if (!bat_algo_ops->bat_iface_enable ||
buf : 	    !bat_algo_ops->bat_iface_disable ||
iface_disable || 
buf : 	    !bat_algo_ops->bat_iface_update_mac ||
buf : 	    !bat_algo_ops->bat_primary_iface_set ||
iface_set || 
buf : 	    !bat_algo_ops->bat_ogm_schedule ||
buf : 	    !bat_algo_ops->bat_ogm_emit ||
buf : 	    !bat_algo_ops->bat_neigh_cmp ||
buf : 	    !bat_algo_ops->bat_neigh_is_equiv_or_better) {
buf : 		pr_info("Routing algo '%s' does not implement required ops\n",
buf : 			bat_algo_ops->name);
buf : 		ret = -EINVAL;
buf : 		goto out;
buf : 	}
buf : 
buf : 	INIT_HLIST_NODE(&bat_algo_ops->list);
buf : 	hlist_add_head(&bat_algo_ops->list, &batadv_algo_list);
buf : 	ret = 0;
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : int batadv_algo_select(struct batadv_priv *bat_priv, char *name)
buf : {
buf : 	struct batadv_algo_ops *bat_algo_ops;
buf : 	int ret = -EINVAL;
buf : 
buf : 	bat_algo_ops = batadv_algo_get(name);
buf : 	if (!bat_algo_ops)
if (!bat_algo_ops) 
buf : 		goto out;
buf : 
buf : 	bat_priv->bat_algo_ops = bat_algo_ops;
buf : 	ret = 0;
buf : 
buf : out:
buf : 	return ret;
buf : }
buf : 
buf : int batadv_algo_seq_print_text(struct seq_file *seq, void *offset)
buf : {
buf : 	struct batadv_algo_ops *bat_algo_ops;
buf : 
buf : 	seq_puts(seq, "Available routing algorithms:\n");
buf : 
buf : 	hlist_for_each_entry(bat_algo_ops, &batadv_algo_list, list) {
for_each_entry(bat_algo_ops, &batadv_algo_list, list) { 
buf : 		seq_printf(seq, "%s\n", bat_algo_ops->name);
buf : 	}
buf : 
buf : 	return 0;
buf : }
buf : 
buf : /**
buf :  * batadv_skb_crc32 - calculate CRC32 of the whole packet and skip bytes in
buf :  *  the header
buf :  * @skb: skb pointing to fragmented socket buffers
buf :  * @payload_ptr: Pointer to position inside the head buffer of the skb
buf :  *  marking the start of the data to be CRC'ed
buf :  *
buf :  * payload_ptr must always point to an address in the skb head buffer and not to
buf :  * a fragment.
buf :  */
buf : __be32 batadv_skb_crc32(struct sk_buff *skb, u8 *payload_ptr)
buf : {
buf : 	u32 crc = 0;
buf : 	unsigned int from;
buf : 	unsigned int to = skb->len;
buf : 	struct skb_seq_state st;
buf : 	const u8 *data;
buf : 	unsigned int len;
buf : 	unsigned int consumed = 0;
buf : 
buf : 	from = (unsigned int)(payload_ptr - skb->data);
buf : 
buf : 	skb_prepare_seq_read(skb, from, to, &st);
buf : 	while ((len = skb_seq_read(consumed, &data, &st)) != 0) {
while ((len = skb_seq_read(consumed, &data, &st)) != 0) { 
buf : 		crc = crc32c(crc, data, len);
buf : 		consumed += len;
buf : 	}
buf : 
buf : 	return htonl(crc);
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_handler_free_ref - decrement the tvlv handler refcounter and
buf :  *  possibly free it
buf :  * @tvlv_handler: the tvlv handler to free
buf :  */
buf : static void
buf : batadv_tvlv_handler_free_ref(struct batadv_tvlv_handler *tvlv_handler)
buf : {
buf : 	if (atomic_dec_and_test(&tvlv_handler->refcount))
if (atomic_dec_and_test(&tvlv_handler->refcount)) 
buf : 		kfree_rcu(tvlv_handler, rcu);
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_handler_get - retrieve tvlv handler from the tvlv handler list
buf :  *  based on the provided type and version (both need to match)
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @type: tvlv handler type to look for
buf :  * @version: tvlv handler version to look for
for 
buf :  *
buf :  * Returns tvlv handler if found or NULL otherwise.
buf :  */
buf : static struct batadv_tvlv_handler
buf : *batadv_tvlv_handler_get(struct batadv_priv *bat_priv,
buf : 			 uint8_t type, uint8_t version)
buf : {
buf : 	struct batadv_tvlv_handler *tvlv_handler_tmp, *tvlv_handler = NULL;
buf : 
buf : 	rcu_read_lock();
buf : 	hlist_for_each_entry_rcu(tvlv_handler_tmp,
for_each_entry_rcu(tvlv_handler_tmp, 
buf : 				 &bat_priv->tvlv.handler_list, list) {
buf : 		if (tvlv_handler_tmp->type != type)
if (tvlv_handler_tmp->type != type) 
buf : 			continue;
buf : 
buf : 		if (tvlv_handler_tmp->version != version)
if (tvlv_handler_tmp->version != version) 
buf : 			continue;
buf : 
buf : 		if (!atomic_inc_not_zero(&tvlv_handler_tmp->refcount))
if (!atomic_inc_not_zero(&tvlv_handler_tmp->refcount)) 
buf : 			continue;
buf : 
buf : 		tvlv_handler = tvlv_handler_tmp;
buf : 		break;
buf : 	}
buf : 	rcu_read_unlock();
buf : 
buf : 	return tvlv_handler;
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_container_free_ref - decrement the tvlv container refcounter and
buf :  *  possibly free it
buf :  * @tvlv_handler: the tvlv container to free
buf :  */
buf : static void batadv_tvlv_container_free_ref(struct batadv_tvlv_container *tvlv)
buf : {
buf : 	if (atomic_dec_and_test(&tvlv->refcount))
if (atomic_dec_and_test(&tvlv->refcount)) 
buf : 		kfree(tvlv);
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_container_get - retrieve tvlv container from the tvlv container
buf :  *  list based on the provided type and version (both need to match)
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @type: tvlv container type to look for
buf :  * @version: tvlv container version to look for
for 
buf :  *
buf :  * Has to be called with the appropriate locks being acquired
buf :  * (tvlv.container_list_lock).
buf :  *
buf :  * Returns tvlv container if found or NULL otherwise.
if found or NULL otherwise. 
buf :  */
buf : static struct batadv_tvlv_container
buf : *batadv_tvlv_container_get(struct batadv_priv *bat_priv,
buf : 			   uint8_t type, uint8_t version)
buf : {
buf : 	struct batadv_tvlv_container *tvlv_tmp, *tvlv = NULL;
buf : 
buf : 	hlist_for_each_entry(tvlv_tmp, &bat_priv->tvlv.container_list, list) {
for_each_entry(tvlv_tmp, &bat_priv->tvlv.container_list, list) { 
buf : 		if (tvlv_tmp->tvlv_hdr.type != type)
buf : 			continue;
buf : 
buf : 		if (tvlv_tmp->tvlv_hdr.version != version)
if (tvlv_tmp->tvlv_hdr.version != version) 
buf : 			continue;
buf : 
buf : 		if (!atomic_inc_not_zero(&tvlv_tmp->refcount))
if (!atomic_inc_not_zero(&tvlv_tmp->refcount)) 
buf : 			continue;
buf : 
buf : 		tvlv = tvlv_tmp;
buf : 		break;
buf : 	}
buf : 
buf : 	return tvlv;
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_container_list_size - calculate the size of the tvlv container
buf :  *  list entries
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  *
buf :  * Has to be called with the appropriate locks being acquired
buf :  * (tvlv.container_list_lock).
buf :  *
buf :  * Returns size of all currently registered tvlv containers in bytes.
buf :  */
buf : static uint16_t batadv_tvlv_container_list_size(struct batadv_priv *bat_priv)
buf : {
buf : 	struct batadv_tvlv_container *tvlv;
buf : 	uint16_t tvlv_len = 0;
buf : 
buf : 	hlist_for_each_entry(tvlv, &bat_priv->tvlv.container_list, list) {
for_each_entry(tvlv, &bat_priv->tvlv.container_list, list) { 
buf : 		tvlv_len += sizeof(struct batadv_tvlv_hdr);
buf : 		tvlv_len += ntohs(tvlv->tvlv_hdr.len);
buf : 	}
buf : 
buf : 	return tvlv_len;
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_container_remove - remove tvlv container from the tvlv container
buf :  *  list
buf :  * @tvlv: the to be removed tvlv container
buf :  *
buf :  * Has to be called with the appropriate locks being acquired
buf :  * (tvlv.container_list_lock).
buf :  */
buf : static void batadv_tvlv_container_remove(struct batadv_tvlv_container *tvlv)
buf : {
buf : 	if (!tvlv)
if (!tvlv) 
buf : 		return;
buf : 
buf : 	hlist_del(&tvlv->list);
buf : 
buf : 	/* first call to decrement the counter, second call to free */
buf : 	batadv_tvlv_container_free_ref(tvlv);
buf : 	batadv_tvlv_container_free_ref(tvlv);
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_container_unregister - unregister tvlv container based on the
buf :  *  provided type and version (both need to match)
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @type: tvlv container type to unregister
buf :  * @version: tvlv container type to unregister
buf :  */
buf : void batadv_tvlv_container_unregister(struct batadv_priv *bat_priv,
buf : 				      uint8_t type, uint8_t version)
buf : {
buf : 	struct batadv_tvlv_container *tvlv;
buf : 
buf : 	spin_lock_bh(&bat_priv->tvlv.container_list_lock);
buf : 	tvlv = batadv_tvlv_container_get(bat_priv, type, version);
buf : 	batadv_tvlv_container_remove(tvlv);
buf : 	spin_unlock_bh(&bat_priv->tvlv.container_list_lock);
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_container_register - register tvlv type, version and content
buf :  *  to be propagated with each (primary interface) OGM
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @type: tvlv container type
buf :  * @version: tvlv container version
buf :  * @tvlv_value: tvlv container content
buf :  * @tvlv_value_len: tvlv container content length
buf :  *
buf :  * If a container of the same type and version was already registered the new
buf :  * content is going to replace the old one.
buf :  */
buf : void batadv_tvlv_container_register(struct batadv_priv *bat_priv,
buf : 				    uint8_t type, uint8_t version,
buf : 				    void *tvlv_value, uint16_t tvlv_value_len)
buf : {
buf : 	struct batadv_tvlv_container *tvlv_old, *tvlv_new;
buf : 
buf : 	if (!tvlv_value)
if (!tvlv_value) 
buf : 		tvlv_value_len = 0;
buf : 
buf : 	tvlv_new = kzalloc(sizeof(*tvlv_new) + tvlv_value_len, GFP_ATOMIC);
buf : 	if (!tvlv_new)
if (!tvlv_new) 
buf : 		return;
buf : 
buf : 	tvlv_new->tvlv_hdr.version = version;
buf : 	tvlv_new->tvlv_hdr.type = type;
buf : 	tvlv_new->tvlv_hdr.len = htons(tvlv_value_len);
buf : 
buf : 	memcpy(tvlv_new + 1, tvlv_value, ntohs(tvlv_new->tvlv_hdr.len));
buf : 	INIT_HLIST_NODE(&tvlv_new->list);
buf : 	atomic_set(&tvlv_new->refcount, 1);
buf : 
buf : 	spin_lock_bh(&bat_priv->tvlv.container_list_lock);
buf : 	tvlv_old = batadv_tvlv_container_get(bat_priv, type, version);
buf : 	batadv_tvlv_container_remove(tvlv_old);
buf : 	hlist_add_head(&tvlv_new->list, &bat_priv->tvlv.container_list);
buf : 	spin_unlock_bh(&bat_priv->tvlv.container_list_lock);
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_realloc_packet_buff - reallocate packet buffer to accomodate
buf :  *  requested packet size
buf :  * @packet_buff: packet buffer
buf :  * @packet_buff_len: packet buffer size
buf :  * @packet_min_len: requested packet minimum size
buf :  * @additional_packet_len: requested additional packet size on top of minimum
buf :  *  size
buf :  *
buf :  * Returns true of the packet buffer could be changed to the requested size,
buf :  * false otherwise.
buf :  */
buf : static bool batadv_tvlv_realloc_packet_buff(unsigned char **packet_buff,
buf : 					    int *packet_buff_len,
buf : 					    int min_packet_len,
buf : 					    int additional_packet_len)
buf : {
buf : 	unsigned char *new_buff;
buf : 
buf : 	new_buff = kmalloc(min_packet_len + additional_packet_len, GFP_ATOMIC);
buf : 
buf : 	/* keep old buffer if kmalloc should fail */
if kmalloc should fail */ 
buf : 	if (new_buff) {
buf : 		memcpy(new_buff, *packet_buff, min_packet_len);
buf : 		kfree(*packet_buff);
buf : 		*packet_buff = new_buff;
buf : 		*packet_buff_len = min_packet_len + additional_packet_len;
buf : 		return true;
buf : 	}
buf : 
buf : 	return false;
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_container_ogm_append - append tvlv container content to given
buf :  *  OGM packet buffer
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @packet_buff: ogm packet buffer
buf :  * @packet_buff_len: ogm packet buffer size including ogm header and tvlv
buf :  *  content
buf :  * @packet_min_len: ogm header size to be preserved for the OGM itself
for the OGM itself 
buf :  *
buf :  * The ogm packet might be enlarged or shrunk depending on the current size
buf :  * and the size of the to-be-appended tvlv containers.
buf :  *
buf :  * Returns size of all appended tvlv containers in bytes.
buf :  */
buf : uint16_t batadv_tvlv_container_ogm_append(struct batadv_priv *bat_priv,
buf : 					  unsigned char **packet_buff,
buf : 					  int *packet_buff_len,
buf : 					  int packet_min_len)
buf : {
buf : 	struct batadv_tvlv_container *tvlv;
buf : 	struct batadv_tvlv_hdr *tvlv_hdr;
buf : 	uint16_t tvlv_value_len;
buf : 	void *tvlv_value;
buf : 	bool ret;
buf : 
buf : 	spin_lock_bh(&bat_priv->tvlv.container_list_lock);
buf : 	tvlv_value_len = batadv_tvlv_container_list_size(bat_priv);
buf : 
buf : 	ret = batadv_tvlv_realloc_packet_buff(packet_buff, packet_buff_len,
buf : 					      packet_min_len, tvlv_value_len);
buf : 
buf : 	if (!ret)
if (!ret) 
buf : 		goto end;
buf : 
buf : 	if (!tvlv_value_len)
if (!tvlv_value_len) 
buf : 		goto end;
buf : 
buf : 	tvlv_value = (*packet_buff) + packet_min_len;
buf : 
buf : 	hlist_for_each_entry(tvlv, &bat_priv->tvlv.container_list, list) {
for_each_entry(tvlv, &bat_priv->tvlv.container_list, list) { 
buf : 		tvlv_hdr = tvlv_value;
buf : 		tvlv_hdr->type = tvlv->tvlv_hdr.type;
buf : 		tvlv_hdr->version = tvlv->tvlv_hdr.version;
buf : 		tvlv_hdr->len = tvlv->tvlv_hdr.len;
buf : 		tvlv_value = tvlv_hdr + 1;
buf : 		memcpy(tvlv_value, tvlv + 1, ntohs(tvlv->tvlv_hdr.len));
buf : 		tvlv_value = (uint8_t *)tvlv_value + ntohs(tvlv->tvlv_hdr.len);
buf : 	}
buf : 
buf : end:
buf : 	spin_unlock_bh(&bat_priv->tvlv.container_list_lock);
buf : 	return tvlv_value_len;
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_call_handler - parse the given tvlv buffer to call the
buf :  *  appropriate handlers
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @tvlv_handler: tvlv callback function handling the tvlv content
buf :  * @ogm_source: flag indicating wether the tvlv is an ogm or a unicast packet
buf :  * @orig_node: orig node emitting the ogm packet
buf :  * @src: source mac address of the unicast packet
buf :  * @dst: destination mac address of the unicast packet
buf :  * @tvlv_value: tvlv content
buf :  * @tvlv_value_len: tvlv content length
buf :  *
buf :  * Returns success if handler was not found or the return value of the handler
if handler was not found or the return value of the handler 
buf :  * callback.
buf :  */
buf : static int batadv_tvlv_call_handler(struct batadv_priv *bat_priv,
buf : 				    struct batadv_tvlv_handler *tvlv_handler,
buf : 				    bool ogm_source,
buf : 				    struct batadv_orig_node *orig_node,
buf : 				    uint8_t *src, uint8_t *dst,
buf : 				    void *tvlv_value, uint16_t tvlv_value_len)
buf : {
buf : 	if (!tvlv_handler)
if (!tvlv_handler) 
buf : 		return NET_RX_SUCCESS;
buf : 
buf : 	if (ogm_source) {
if (ogm_source) { 
buf : 		if (!tvlv_handler->ogm_handler)
buf : 			return NET_RX_SUCCESS;
buf : 
buf : 		if (!orig_node)
if (!orig_node) 
buf : 			return NET_RX_SUCCESS;
buf : 
buf : 		tvlv_handler->ogm_handler(bat_priv, orig_node,
buf : 					  BATADV_NO_FLAGS,
buf : 					  tvlv_value, tvlv_value_len);
buf : 		tvlv_handler->flags |= BATADV_TVLV_HANDLER_OGM_CALLED;
buf : 	} else {
buf : 		if (!src)
if (!src) 
buf : 			return NET_RX_SUCCESS;
buf : 
buf : 		if (!dst)
if (!dst) 
buf : 			return NET_RX_SUCCESS;
buf : 
buf : 		if (!tvlv_handler->unicast_handler)
if (!tvlv_handler->unicast_handler) 
buf : 			return NET_RX_SUCCESS;
buf : 
buf : 		return tvlv_handler->unicast_handler(bat_priv, src,
buf : 						     dst, tvlv_value,
buf : 						     tvlv_value_len);
buf : 	}
buf : 
buf : 	return NET_RX_SUCCESS;
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_containers_process - parse the given tvlv buffer to call the
buf :  *  appropriate handlers
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @ogm_source: flag indicating wether the tvlv is an ogm or a unicast packet
buf :  * @orig_node: orig node emitting the ogm packet
buf :  * @src: source mac address of the unicast packet
buf :  * @dst: destination mac address of the unicast packet
buf :  * @tvlv_value: tvlv content
buf :  * @tvlv_value_len: tvlv content length
buf :  *
buf :  * Returns success when processing an OGM or the return value of all called
buf :  * handler callbacks.
buf :  */
buf : int batadv_tvlv_containers_process(struct batadv_priv *bat_priv,
buf : 				   bool ogm_source,
buf : 				   struct batadv_orig_node *orig_node,
buf : 				   uint8_t *src, uint8_t *dst,
buf : 				   void *tvlv_value, uint16_t tvlv_value_len)
buf : {
buf : 	struct batadv_tvlv_handler *tvlv_handler;
buf : 	struct batadv_tvlv_hdr *tvlv_hdr;
buf : 	uint16_t tvlv_value_cont_len;
buf : 	uint8_t cifnotfound = BATADV_TVLV_HANDLER_OGM_CIFNOTFND;
ifnotfound = BATADV_TVLV_HANDLER_OGM_CIFNOTFND; 
buf : 	int ret = NET_RX_SUCCESS;
buf : 
buf : 	while (tvlv_value_len >= sizeof(*tvlv_hdr)) {
while (tvlv_value_len >= sizeof(*tvlv_hdr)) { 
buf : 		tvlv_hdr = tvlv_value;
buf : 		tvlv_value_cont_len = ntohs(tvlv_hdr->len);
buf : 		tvlv_value = tvlv_hdr + 1;
buf : 		tvlv_value_len -= sizeof(*tvlv_hdr);
buf : 
buf : 		if (tvlv_value_cont_len > tvlv_value_len)
if (tvlv_value_cont_len > tvlv_value_len) 
buf : 			break;
buf : 
buf : 		tvlv_handler = batadv_tvlv_handler_get(bat_priv,
buf : 						       tvlv_hdr->type,
buf : 						       tvlv_hdr->version);
buf : 
buf : 		ret |= batadv_tvlv_call_handler(bat_priv, tvlv_handler,
buf : 						ogm_source, orig_node,
buf : 						src, dst, tvlv_value,
buf : 						tvlv_value_cont_len);
buf : 		if (tvlv_handler)
if (tvlv_handler) 
buf : 			batadv_tvlv_handler_free_ref(tvlv_handler);
buf : 		tvlv_value = (uint8_t *)tvlv_value + tvlv_value_cont_len;
buf : 		tvlv_value_len -= tvlv_value_cont_len;
buf : 	}
buf : 
buf : 	if (!ogm_source)
if (!ogm_source) 
buf : 		return ret;
buf : 
buf : 	rcu_read_lock();
buf : 	hlist_for_each_entry_rcu(tvlv_handler,
for_each_entry_rcu(tvlv_handler, 
buf : 				 &bat_priv->tvlv.handler_list, list) {
buf : 		if ((tvlv_handler->flags & BATADV_TVLV_HANDLER_OGM_CIFNOTFND) &&
if ((tvlv_handler->flags & BATADV_TVLV_HANDLER_OGM_CIFNOTFND) && 
buf : 		    !(tvlv_handler->flags & BATADV_TVLV_HANDLER_OGM_CALLED))
buf : 			tvlv_handler->ogm_handler(bat_priv, orig_node,
buf : 						  cifnotfound, NULL, 0);
ifnotfound, NULL, 0); 
buf : 
buf : 		tvlv_handler->flags &= ~BATADV_TVLV_HANDLER_OGM_CALLED;
buf : 	}
buf : 	rcu_read_unlock();
buf : 
buf : 	return NET_RX_SUCCESS;
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_ogm_receive - process an incoming ogm and call the appropriate
buf :  *  handlers
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @batadv_ogm_packet: ogm packet containing the tvlv containers
buf :  * @orig_node: orig node emitting the ogm packet
buf :  */
buf : void batadv_tvlv_ogm_receive(struct batadv_priv *bat_priv,
buf : 			     struct batadv_ogm_packet *batadv_ogm_packet,
buf : 			     struct batadv_orig_node *orig_node)
buf : {
buf : 	void *tvlv_value;
buf : 	uint16_t tvlv_value_len;
buf : 
buf : 	if (!batadv_ogm_packet)
if (!batadv_ogm_packet) 
buf : 		return;
buf : 
buf : 	tvlv_value_len = ntohs(batadv_ogm_packet->tvlv_len);
buf : 	if (!tvlv_value_len)
if (!tvlv_value_len) 
buf : 		return;
buf : 
buf : 	tvlv_value = batadv_ogm_packet + 1;
buf : 
buf : 	batadv_tvlv_containers_process(bat_priv, true, orig_node, NULL, NULL,
buf : 				       tvlv_value, tvlv_value_len);
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_handler_register - register tvlv handler based on the provided
buf :  *  type and version (both need to match) for ogm tvlv payload and/or unicast
for ogm tvlv payload and/or unicast 
buf :  *  payload
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @optr: ogm tvlv handler callback function. This function receives the orig
buf :  *  node, flags and the tvlv content as argument to process.
buf :  * @uptr: unicast tvlv handler callback function. This function receives the
buf :  *  source & destination of the unicast packet as well as the tvlv content
buf :  *  to process.
buf :  * @type: tvlv handler type to be registered
buf :  * @version: tvlv handler version to be registered
buf :  * @flags: flags to enable or disable TVLV API behavior
buf :  */
buf : void batadv_tvlv_handler_register(struct batadv_priv *bat_priv,
buf : 				  void (*optr)(struct batadv_priv *bat_priv,
buf : 					       struct batadv_orig_node *orig,
buf : 					       uint8_t flags,
buf : 					       void *tvlv_value,
buf : 					       uint16_t tvlv_value_len),
buf : 				  int (*uptr)(struct batadv_priv *bat_priv,
buf : 					      uint8_t *src, uint8_t *dst,
buf : 					      void *tvlv_value,
buf : 					      uint16_t tvlv_value_len),
buf : 				  uint8_t type, uint8_t version, uint8_t flags)
buf : {
buf : 	struct batadv_tvlv_handler *tvlv_handler;
buf : 
buf : 	tvlv_handler = batadv_tvlv_handler_get(bat_priv, type, version);
buf : 	if (tvlv_handler) {
if (tvlv_handler) { 
buf : 		batadv_tvlv_handler_free_ref(tvlv_handler);
buf : 		return;
buf : 	}
buf : 
buf : 	tvlv_handler = kzalloc(sizeof(*tvlv_handler), GFP_ATOMIC);
buf : 	if (!tvlv_handler)
if (!tvlv_handler) 
buf : 		return;
buf : 
buf : 	tvlv_handler->ogm_handler = optr;
buf : 	tvlv_handler->unicast_handler = uptr;
buf : 	tvlv_handler->type = type;
buf : 	tvlv_handler->version = version;
buf : 	tvlv_handler->flags = flags;
buf : 	atomic_set(&tvlv_handler->refcount, 1);
buf : 	INIT_HLIST_NODE(&tvlv_handler->list);
buf : 
buf : 	spin_lock_bh(&bat_priv->tvlv.handler_list_lock);
buf : 	hlist_add_head_rcu(&tvlv_handler->list, &bat_priv->tvlv.handler_list);
buf : 	spin_unlock_bh(&bat_priv->tvlv.handler_list_lock);
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_handler_unregister - unregister tvlv handler based on the
buf :  *  provided type and version (both need to match)
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @type: tvlv handler type to be unregistered
buf :  * @version: tvlv handler version to be unregistered
buf :  */
buf : void batadv_tvlv_handler_unregister(struct batadv_priv *bat_priv,
buf : 				    uint8_t type, uint8_t version)
buf : {
buf : 	struct batadv_tvlv_handler *tvlv_handler;
buf : 
buf : 	tvlv_handler = batadv_tvlv_handler_get(bat_priv, type, version);
buf : 	if (!tvlv_handler)
if (!tvlv_handler) 
buf : 		return;
buf : 
buf : 	batadv_tvlv_handler_free_ref(tvlv_handler);
buf : 	spin_lock_bh(&bat_priv->tvlv.handler_list_lock);
buf : 	hlist_del_rcu(&tvlv_handler->list);
buf : 	spin_unlock_bh(&bat_priv->tvlv.handler_list_lock);
buf : 	batadv_tvlv_handler_free_ref(tvlv_handler);
buf : }
buf : 
buf : /**
buf :  * batadv_tvlv_unicast_send - send a unicast packet with tvlv payload to the
buf :  *  specified host
ified host 
buf :  * @bat_priv: the bat priv with all the soft interface information
formation 
buf :  * @src: source mac address of the unicast packet
buf :  * @dst: destination mac address of the unicast packet
buf :  * @type: tvlv type
buf :  * @version: tvlv version
buf :  * @tvlv_value: tvlv content
buf :  * @tvlv_value_len: tvlv content length
buf :  */
buf : void batadv_tvlv_unicast_send(struct batadv_priv *bat_priv, uint8_t *src,
buf : 			      uint8_t *dst, uint8_t type, uint8_t version,
buf : 			      void *tvlv_value, uint16_t tvlv_value_len)
buf : {
buf : 	struct batadv_unicast_tvlv_packet *unicast_tvlv_packet;
buf : 	struct batadv_tvlv_hdr *tvlv_hdr;
buf : 	struct batadv_orig_node *orig_node;
buf : 	struct sk_buff *skb = NULL;
buf : 	unsigned char *tvlv_buff;
buf : 	unsigned int tvlv_len;
buf : 	ssize_t hdr_len = sizeof(*unicast_tvlv_packet);
buf : 	bool ret = false;
buf : 
buf : 	orig_node = batadv_orig_hash_find(bat_priv, dst);
buf : 	if (!orig_node)
if (!orig_node) 
buf : 		goto out;
buf : 
buf : 	tvlv_len = sizeof(*tvlv_hdr) + tvlv_value_len;
buf : 
buf : 	skb = netdev_alloc_skb_ip_align(NULL, ETH_HLEN + hdr_len + tvlv_len);
buf : 	if (!skb)
if (!skb) 
buf : 		goto out;
buf : 
buf : 	skb->priority = TC_PRIO_CONTROL;
buf : 	skb_reserve(skb, ETH_HLEN);
buf : 	tvlv_buff = skb_put(skb, sizeof(*unicast_tvlv_packet) + tvlv_len);
buf : 	unicast_tvlv_packet = (struct batadv_unicast_tvlv_packet *)tvlv_buff;
buf : 	unicast_tvlv_packet->packet_type = BATADV_UNICAST_TVLV;
buf : 	unicast_tvlv_packet->version = BATADV_COMPAT_VERSION;
buf : 	unicast_tvlv_packet->ttl = BATADV_TTL;
buf : 	unicast_tvlv_packet->reserved = 0;
buf : 	unicast_tvlv_packet->tvlv_len = htons(tvlv_len);
buf : 	unicast_tvlv_packet->align = 0;
buf : 	ether_addr_copy(unicast_tvlv_packet->src, src);
buf : 	ether_addr_copy(unicast_tvlv_packet->dst, dst);
buf : 
buf : 	tvlv_buff = (unsigned char *)(unicast_tvlv_packet + 1);
buf : 	tvlv_hdr = (struct batadv_tvlv_hdr *)tvlv_buff;
buf : 	tvlv_hdr->version = version;
buf : 	tvlv_hdr->type = type;
buf : 	tvlv_hdr->len = htons(tvlv_value_len);
buf : 	tvlv_buff += sizeof(*tvlv_hdr);
buf : 	memcpy(tvlv_buff, tvlv_value, tvlv_value_len);
buf : 
buf : 	if (batadv_send_skb_to_orig(skb, orig_node, NULL) != NET_XMIT_DROP)
if (batadv_send_skb_to_orig(skb, orig_node, NULL) != NET_XMIT_DROP) 
buf : 		ret = true;
buf : 
buf : out:
buf : 	if (skb && !ret)
if (skb && !ret) 
buf : 		kfree_skb(skb);
buf : 	if (orig_node)
if (orig_node) 
buf : 		batadv_orig_node_free_ref(orig_node);
buf : }
buf : 
buf : /**
buf :  * batadv_get_vid - extract the VLAN identifier from skb if any
ifier from skb if any 
buf :  * @skb: the buffer containing the packet
buf :  * @header_len: length of the batman header preceding the ethernet header
buf :  *
buf :  * If the packet embedded in the skb is vlan tagged this function returns the
buf :  * VID with the BATADV_VLAN_HAS_TAG flag. Otherwise BATADV_NO_FLAGS is returned.
buf :  */
buf : unsigned short batadv_get_vid(struct sk_buff *skb, size_t header_len)
buf : {
buf : 	struct ethhdr *ethhdr = (struct ethhdr *)(skb->data + header_len);
buf : 	struct vlan_ethhdr *vhdr;
buf : 	unsigned short vid;
buf : 
buf : 	if (ethhdr->h_proto != htons(ETH_P_8021Q))
if (ethhdr->h_proto != htons(ETH_P_8021Q)) 
buf : 		return BATADV_NO_FLAGS;
buf : 
buf : 	if (!pskb_may_pull(skb, header_len + VLAN_ETH_HLEN))
if (!pskb_may_pull(skb, header_len + VLAN_ETH_HLEN)) 
buf : 		return BATADV_NO_FLAGS;
buf : 
buf : 	vhdr = (struct vlan_ethhdr *)(skb->data + header_len);
buf : 	vid = ntohs(vhdr->h_vlan_TCI) & VLAN_VID_MASK;
buf : 	vid |= BATADV_VLAN_HAS_TAG;
buf : 
buf : 	return vid;
buf : }
buf : 
buf : /**
buf :  * batadv_vlan_ap_isola_get - return the AP isolation status for the given vlan
for the given vlan 
buf :  * @bat_priv: the bat priv with all the soft interface information
buf :  * @vid: the VLAN identifier for which the AP isolation attributed as to be
ifier for which the AP isolation attributed as to be 
buf :  *  looked up
buf :  *
buf :  * Returns true if AP isolation is on for the VLAN idenfied by vid, false
if AP isolation is on for the VLAN idenfied by vid, false 
buf :  * otherwise
buf :  */
buf : bool batadv_vlan_ap_isola_get(struct batadv_priv *bat_priv, unsigned short vid)
buf : {
buf : 	bool ap_isolation_enabled = false;
buf : 	struct batadv_softif_vlan *vlan;
if_vlan *vlan; 
buf : 
buf : 	/* if the AP isolation is requested on a VLAN, then check for its
for its 
buf : 	 * setting in the proper VLAN private data structure
buf : 	 */
buf : 	vlan = batadv_softif_vlan_get(bat_priv, vid);
if_vlan_get(bat_priv, vid); 
buf : 	if (vlan) {
buf : 		ap_isolation_enabled = atomic_read(&vlan->ap_isolation);
buf : 		batadv_softif_vlan_free_ref(vlan);
if_vlan_free_ref(vlan); 
buf : 	}
buf : 
buf : 	return ap_isolation_enabled;
buf : }
buf : 
buf : static int batadv_param_set_ra(const char *val, const struct kernel_param *kp)
buf : {
buf : 	struct batadv_algo_ops *bat_algo_ops;
buf : 	char *algo_name = (char *)val;
buf : 	size_t name_len = strlen(algo_name);
buf : 
buf : 	if (name_len > 0 && algo_name[name_len - 1] == '\n')
if (name_len > 0 && algo_name[name_len - 1] == '\n') 
buf : 		algo_name[name_len - 1] = '\0';
buf : 
buf : 	bat_algo_ops = batadv_algo_get(algo_name);
buf : 	if (!bat_algo_ops) {
if (!bat_algo_ops) { 
buf : 		pr_err("Routing algorithm '%s' is not supported\n", algo_name);
buf : 		return -EINVAL;
buf : 	}
buf : 
buf : 	return param_set_copystring(algo_name, kp);
buf : }
buf : 
buf : static const struct kernel_param_ops batadv_param_ops_ra = {
buf : 	.set = batadv_param_set_ra,
buf : 	.get = param_get_string,
buf : };
buf : 
buf : static struct kparam_string batadv_param_string_ra = {
buf : 	.maxlen = sizeof(batadv_routing_algo),
buf : 	.string = batadv_routing_algo,
buf : };
buf : 
buf : module_param_cb(routing_algo, &batadv_param_ops_ra, &batadv_param_string_ra,
buf : 		0644);
buf : module_init(batadv_init);
buf : module_exit(batadv_exit);
buf : 
buf : MODULE_LICENSE("GPL");
buf : 
buf : MODULE_AUTHOR(BATADV_DRIVER_AUTHOR);
buf : MODULE_DESCRIPTION(BATADV_DRIVER_DESC);
buf : MODULE_SUPPORTED_DEVICE(BATADV_DRIVER_DEVICE);
buf : MODULE_VERSION(BATADV_SOURCE_VERSION);
file : ./test/kernel/net/mac80211/main.c 
[ OK ] open : 4 ok... 
buf : /*
buf :  * Copyright 2002-2005, Instant802 Networks, Inc.
buf :  * Copyright 2005-2006, Devicescape Software, Inc.
buf :  * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>
buf :  *
buf :  * This program is free software; you can redistribute it and/or modify
ify 
buf :  * it under the terms of the GNU General Public License version 2 as
buf :  * published by the Free Software Foundation.
buf :  */
buf : 
buf : #include <net/mac80211.h>
buf : #include <linux/module.h>
buf : #include <linux/init.h>
buf : #include <linux/netdevice.h>
buf : #include <linux/types.h>
buf : #include <linux/slab.h>
buf : #include <linux/skbuff.h>
buf : #include <linux/etherdevice.h>
buf : #include <linux/if_arp.h>
if_arp.h> 
buf : #include <linux/rtnetlink.h>
buf : #include <linux/bitmap.h>
buf : #include <linux/pm_qos.h>
buf : #include <linux/inetdevice.h>
buf : #include <net/net_namespace.h>
buf : #include <net/cfg80211.h>
buf : #include <net/addrconf.h>
buf : 
buf : #include "ieee80211_i.h"
buf : #include "driver-ops.h"
buf : #include "rate.h"
buf : #include "mesh.h"
buf : #include "wep.h"
buf : #include "led.h"
buf : #include "cfg.h"
buf : #include "debugfs.h"
buf : 
buf : void ieee80211_configure_filter(struct ieee80211_local *local)
buf : {
buf : 	u64 mc;
buf : 	unsigned int changed_flags;
buf : 	unsigned int new_flags = 0;
buf : 
buf : 	if (atomic_read(&local->iff_promiscs))
if (atomic_read(&local->iff_promiscs)) 
buf : 		new_flags |= FIF_PROMISC_IN_BSS;
buf : 
buf : 	if (atomic_read(&local->iff_allmultis))
if (atomic_read(&local->iff_allmultis)) 
buf : 		new_flags |= FIF_ALLMULTI;
buf : 
buf : 	if (local->monitors || test_bit(SCAN_SW_SCANNING, &local->scanning) ||
if (local->monitors || test_bit(SCAN_SW_SCANNING, &local->scanning) || 
buf : 	    test_bit(SCAN_ONCHANNEL_SCANNING, &local->scanning))
buf : 		new_flags |= FIF_BCN_PRBRESP_PROMISC;
buf : 
buf : 	if (local->fif_probe_req || local->probe_req_reg)
if (local->fif_probe_req || local->probe_req_reg) 
buf : 		new_flags |= FIF_PROBE_REQ;
buf : 
buf : 	if (local->fif_fcsfail)
if (local->fif_fcsfail) 
buf : 		new_flags |= FIF_FCSFAIL;
buf : 
buf : 	if (local->fif_plcpfail)
if (local->fif_plcpfail) 
buf : 		new_flags |= FIF_PLCPFAIL;
buf : 
buf : 	if (local->fif_control)
if (local->fif_control) 
buf : 		new_flags |= FIF_CONTROL;
buf : 
buf : 	if (local->fif_other_bss)
if (local->fif_other_bss) 
buf : 		new_flags |= FIF_OTHER_BSS;
buf : 
buf : 	if (local->fif_pspoll)
if (local->fif_pspoll) 
buf : 		new_flags |= FIF_PSPOLL;
buf : 
buf : 	spin_lock_bh(&local->filter_lock);
buf : 	changed_flags = local->filter_flags ^ new_flags;
buf : 
buf : 	mc = drv_prepare_multicast(local, &local->mc_list);
buf : 	spin_unlock_bh(&local->filter_lock);
buf : 
buf : 	/* be a bit nasty */
buf : 	new_flags |= (1<<31);
buf : 
buf : 	drv_configure_filter(local, changed_flags, &new_flags, mc);
buf : 
buf : 	WARN_ON(new_flags & (1<<31));
buf : 
buf : 	local->filter_flags = new_flags & ~(1<<31);
buf : }
buf : 
buf : static void ieee80211_reconfig_filter(struct work_struct *work)
buf : {
buf : 	struct ieee80211_local *local =
buf : 		container_of(work, struct ieee80211_local, reconfig_filter);
buf : 
buf : 	ieee80211_configure_filter(local);
buf : }
buf : 
buf : static u32 ieee80211_hw_conf_chan(struct ieee80211_local *local)
buf : {
buf : 	struct ieee80211_sub_if_data *sdata;
if_data *sdata; 
buf : 	struct cfg80211_chan_def chandef = {};
buf : 	u32 changed = 0;
buf : 	int power;
buf : 	u32 offchannel_flag;
buf : 
buf : 	offchannel_flag = local->hw.conf.flags & IEEE80211_CONF_OFFCHANNEL;
buf : 
buf : 	if (local->scan_chandef.chan) {
if (local->scan_chandef.chan) { 
buf : 		chandef = local->scan_chandef;
buf : 	} else if (local->tmp_channel) {
if (local->tmp_channel) { 
buf : 		chandef.chan = local->tmp_channel;
buf : 		chandef.width = NL80211_CHAN_WIDTH_20_NOHT;
buf : 		chandef.center_freq1 = chandef.chan->center_freq;
buf : 	} else
buf : 		chandef = local->_oper_chandef;
buf : 
buf : 	WARN(!cfg80211_chandef_valid(&chandef),
buf : 	     "control:%d MHz width:%d center: %d/%d MHz",
buf : 	     chandef.chan->center_freq, chandef.width,
buf : 	     chandef.center_freq1, chandef.center_freq2);
buf : 
buf : 	if (!cfg80211_chandef_identical(&chandef, &local->_oper_chandef))
if (!cfg80211_chandef_identical(&chandef, &local->_oper_chandef)) 
buf : 		local->hw.conf.flags |= IEEE80211_CONF_OFFCHANNEL;
buf : 	else
buf : 		local->hw.conf.flags &= ~IEEE80211_CONF_OFFCHANNEL;
buf : 
buf : 	offchannel_flag ^= local->hw.conf.flags & IEEE80211_CONF_OFFCHANNEL;
buf : 
buf : 	if (offchannel_flag ||
if (offchannel_flag || 
buf : 	    !cfg80211_chandef_identical(&local->hw.conf.chandef,
buf : 					&local->_oper_chandef)) {
buf : 		local->hw.conf.chandef = chandef;
buf : 		changed |= IEEE80211_CONF_CHANGE_CHANNEL;
buf : 	}
buf : 
buf : 	if (!conf_is_ht(&local->hw.conf)) {
if (!conf_is_ht(&local->hw.conf)) { 
buf : 		/*
buf : 		 * mac80211.h documents that this is only valid
buf : 		 * when the channel is set to an HT type, and
buf : 		 * that otherwise STATIC is used.
buf : 		 */
buf : 		local->hw.conf.smps_mode = IEEE80211_SMPS_STATIC;
buf : 	} else if (local->hw.conf.smps_mode != local->smps_mode) {
if (local->hw.conf.smps_mode != local->smps_mode) { 
buf : 		local->hw.conf.smps_mode = local->smps_mode;
buf : 		changed |= IEEE80211_CONF_CHANGE_SMPS;
buf : 	}
buf : 
buf : 	power = ieee80211_chandef_max_power(&chandef);
buf : 
buf : 	rcu_read_lock();
buf : 	list_for_each_entry_rcu(sdata, &local->interfaces, list) {
for_each_entry_rcu(sdata, &local->interfaces, list) { 
buf : 		if (!rcu_access_pointer(sdata->vif.chanctx_conf))
buf : 			continue;
buf : 		if (sdata->vif.type == NL80211_IFTYPE_AP_VLAN)
if (sdata->vif.type == NL80211_IFTYPE_AP_VLAN) 
buf : 			continue;
buf : 		power = min(power, sdata->vif.bss_conf.txpower);
if.bss_conf.txpower); 
buf : 	}
buf : 	rcu_read_unlock();
buf : 
buf : 	if (local->hw.conf.power_level != power) {
if (local->hw.conf.power_level != power) { 
buf : 		changed |= IEEE80211_CONF_CHANGE_POWER;
buf : 		local->hw.conf.power_level = power;
buf : 	}
buf : 
buf : 	return changed;
buf : }
buf : 
buf : int ieee80211_hw_config(struct ieee80211_local *local, u32 changed)
buf : {
buf : 	int ret = 0;
buf : 
buf : 	might_sleep();
buf : 
buf : 	if (!local->use_chanctx)
if (!local->use_chanctx) 
buf : 		changed |= ieee80211_hw_conf_chan(local);
buf : 	else
buf : 		changed &= ~(IEEE80211_CONF_CHANGE_CHANNEL |
buf : 			     IEEE80211_CONF_CHANGE_POWER);
buf : 
buf : 	if (changed && local->open_count) {
if (changed && local->open_count) { 
buf : 		ret = drv_config(local, changed);
buf : 		/*
buf : 		 * Goal:
buf : 		 * HW reconfiguration should never fail, the driver has told
buf : 		 * us what it can support so it should live up to that promise.
buf : 		 *
buf : 		 * Current status:
buf : 		 * rfkill is not integrated with mac80211 and a
buf : 		 * configuration command can thus fail if hardware rfkill
if hardware rfkill 
buf : 		 * is enabled
buf : 		 *
buf : 		 * FIXME: integrate rfkill with mac80211 and then add this
buf : 		 * WARN_ON() back
buf : 		 *
buf : 		 */
buf : 		/* WARN_ON(ret); */
buf : 	}
buf : 
buf : 	return ret;
buf : }
buf : 
buf : void ieee80211_bss_info_change_notify(struct ieee80211_sub_if_data *sdata,
ify(struct ieee80211_sub_if_data *sdata, 
buf : 				      u32 changed)
buf : {
buf : 	struct ieee80211_local *local = sdata->local;
buf : 
buf : 	if (!changed || sdata->vif.type == NL80211_IFTYPE_AP_VLAN)
if (!changed || sdata->vif.type == NL80211_IFTYPE_AP_VLAN) 
buf : 		return;
buf : 
buf : 	drv_bss_info_changed(local, sdata, &sdata->vif.bss_conf, changed);
if.bss_conf, changed); 
buf : }
buf : 
buf : u32 ieee80211_reset_erp_info(struct ieee80211_sub_if_data *sdata)
buf : {
buf : 	sdata->vif.bss_conf.use_cts_prot = false;
if.bss_conf.use_cts_prot = false; 
buf : 	sdata->vif.bss_conf.use_short_preamble = false;
buf : 	sdata->vif.bss_conf.use_short_slot = false;
if.bss_conf.use_short_slot = false; 
buf : 	return BSS_CHANGED_ERP_CTS_PROT |
buf : 	       BSS_CHANGED_ERP_PREAMBLE |
buf : 	       BSS_CHANGED_ERP_SLOT;
buf : }
buf : 
buf : static void ieee80211_tasklet_handler(unsigned long data)
buf : {
buf : 	struct ieee80211_local *local = (struct ieee80211_local *) data;
buf : 	struct sk_buff *skb;
buf : 
buf : 	while ((skb = skb_dequeue(&local->skb_queue)) ||
while ((skb = skb_dequeue(&local->skb_queue)) || 
buf : 	       (skb = skb_dequeue(&local->skb_queue_unreliable))) {
buf : 		switch (skb->pkt_type) {
buf : 		case IEEE80211_RX_MSG:
buf : 			/* Clear skb->pkt_type in order to not confuse kernel
buf : 			 * netstack. */
buf : 			skb->pkt_type = 0;
buf : 			ieee80211_rx(&local->hw, skb);
buf : 			break;
buf : 		case IEEE80211_TX_STATUS_MSG:
buf : 			skb->pkt_type = 0;
buf : 			ieee80211_tx_status(&local->hw, skb);
buf : 			break;
buf : 		default:
buf : 			WARN(1, "mac80211: Packet is of unknown type %d\n",
buf : 			     skb->pkt_type);
buf : 			dev_kfree_skb(skb);
buf : 			break;
buf : 		}
buf : 	}
buf : }
buf : 
buf : static void ieee80211_restart_work(struct work_struct *work)
buf : {
buf : 	struct ieee80211_local *local =
buf : 		container_of(work, struct ieee80211_local, restart_work);
buf : 
buf : 	/* wait for scan work complete */
for scan work complete */ 
buf : 	flush_workqueue(local->workqueue);
buf : 
buf : 	WARN(test_bit(SCAN_HW_SCANNING, &local->scanning),
buf : 	     "%s called with hardware scan in progress\n", __func__);
buf : 
buf : 	rtnl_lock();
buf : 	ieee80211_scan_cancel(local);
buf : 	ieee80211_reconfig(local);
buf : 	rtnl_unlock();
buf : }
buf : 
buf : void ieee80211_restart_hw(struct ieee80211_hw *hw)
buf : {
buf : 	struct ieee80211_local *local = hw_to_local(hw);
buf : 
buf : 	trace_api_restart_hw(local);
buf : 
buf : 	wiphy_info(hw->wiphy,
buf : 		   "Hardware restart was requested\n");
buf : 
buf : 	/* use this reason, ieee80211_reconfig will unblock it */
buf : 	ieee80211_stop_queues_by_reason(hw, IEEE80211_MAX_QUEUE_MAP,
buf : 					IEEE80211_QUEUE_STOP_REASON_SUSPEND);
buf : 
buf : 	/*
buf : 	 * Stop all Rx during the reconfig. We don't want state changes
buf : 	 * or driver callbacks while this is in progress.
while this is in progress. 
buf : 	 */
buf : 	local->in_reconfig = true;
buf : 	barrier();
buf : 
buf : 	schedule_work(&local->restart_work);
buf : }
buf : EXPORT_SYMBOL(ieee80211_restart_hw);
buf : 
buf : #ifdef CONFIG_INET
ifdef CONFIG_INET 
buf : static int ieee80211_ifa_changed(struct notifier_block *nb,
buf : 				 unsigned long data, void *arg)
buf : {
buf : 	struct in_ifaddr *ifa = arg;
ifaddr *ifa = arg; 
buf : 	struct ieee80211_local *local =
buf : 		container_of(nb, struct ieee80211_local,
buf : 			     ifa_notifier);
ifa_notifier); 
buf : 	struct net_device *ndev = ifa->ifa_dev->dev;
buf : 	struct wireless_dev *wdev = ndev->ieee80211_ptr;
buf : 	struct in_device *idev;
buf : 	struct ieee80211_sub_if_data *sdata;
if_data *sdata; 
buf : 	struct ieee80211_bss_conf *bss_conf;
buf : 	struct ieee80211_if_managed *ifmgd;
if_managed *ifmgd; 
buf : 	int c = 0;
buf : 
buf : 	/* Make sure it's our interface that got changed */
buf : 	if (!wdev)
if (!wdev) 
buf : 		return NOTIFY_DONE;
buf : 
buf : 	if (wdev->wiphy != local->hw.wiphy)
if (wdev->wiphy != local->hw.wiphy) 
buf : 		return NOTIFY_DONE;
buf : 
buf : 	sdata = IEEE80211_DEV_TO_SUB_IF(ndev);
buf : 	bss_conf = &sdata->vif.bss_conf;
if.bss_conf; 
buf : 
buf : 	/* ARP filtering is only supported in managed mode */
buf : 	if (sdata->vif.type != NL80211_IFTYPE_STATION)
if (sdata->vif.type != NL80211_IFTYPE_STATION) 
buf : 		return NOTIFY_DONE;
buf : 
buf : 	idev = __in_dev_get_rtnl(sdata->dev);
buf : 	if (!idev)
if (!idev) 
buf : 		return NOTIFY_DONE;
buf : 
buf : 	ifmgd = &sdata->u.mgd;
ifmgd = &sdata->u.mgd; 
buf : 	sdata_lock(sdata);
buf : 
buf : 	/* Copy the addresses to the bss_conf list */
buf : 	ifa = idev->ifa_list;
ifa = idev->ifa_list; 
buf : 	while (ifa) {
while (ifa) { 
buf : 		if (c < IEEE80211_BSS_ARP_ADDR_LIST_LEN)
buf : 			bss_conf->arp_addr_list[c] = ifa->ifa_address;
ifa->ifa_address; 
buf : 		ifa = ifa->ifa_next;
buf : 		c++;
buf : 	}
buf : 
buf : 	bss_conf->arp_addr_cnt = c;
buf : 
buf : 	/* Configure driver only if associated (which also implies it is up) */
if associated (which also implies it is up) */ 
buf : 	if (ifmgd->associated)
buf : 		ieee80211_bss_info_change_notify(sdata,
ify(sdata, 
buf : 						 BSS_CHANGED_ARP_FILTER);
buf : 
buf : 	sdata_unlock(sdata);
buf : 
buf : 	return NOTIFY_OK;
buf : }
buf : #endif
if 
buf : 
buf : #if IS_ENABLED(CONFIG_IPV6)
buf : static int ieee80211_ifa6_changed(struct notifier_block *nb,
ifa6_changed(struct notifier_block *nb, 
buf : 				  unsigned long data, void *arg)
buf : {
buf : 	struct inet6_ifaddr *ifa = (struct inet6_ifaddr *)arg;
ifaddr *ifa = (struct inet6_ifaddr *)arg; 
buf : 	struct inet6_dev *idev = ifa->idev;
buf : 	struct net_device *ndev = ifa->idev->dev;
ifa->idev->dev; 
buf : 	struct ieee80211_local *local =
buf : 		container_of(nb, struct ieee80211_local, ifa6_notifier);
ifa6_notifier); 
buf : 	struct wireless_dev *wdev = ndev->ieee80211_ptr;
buf : 	struct ieee80211_sub_if_data *sdata;
if_data *sdata; 
buf : 
buf : 	/* Make sure it's our interface that got changed */
buf : 	if (!wdev || wdev->wiphy != local->hw.wiphy)
if (!wdev || wdev->wiphy != local->hw.wiphy) 
buf : 		return NOTIFY_DONE;
buf : 
buf : 	sdata = IEEE80211_DEV_TO_SUB_IF(ndev);
buf : 
buf : 	/*
buf : 	 * For now only support station mode. This is mostly because
buf : 	 * doing AP would have to handle AP_VLAN in some way ...
buf : 	 */
buf : 	if (sdata->vif.type != NL80211_IFTYPE_STATION)
if (sdata->vif.type != NL80211_IFTYPE_STATION) 
buf : 		return NOTIFY_DONE;
buf : 
buf : 	drv_ipv6_addr_change(local, sdata, idev);
buf : 
buf : 	return NOTIFY_OK;
buf : }
buf : #endif
if 
buf : 
buf : /* There isn't a lot of sense in it, but you can transmit anything you like */
buf : static const struct ieee80211_txrx_stypes
buf : ieee80211_default_mgmt_stypes[NUM_NL80211_IFTYPES] = {
buf : 	[NL80211_IFTYPE_ADHOC] = {
buf : 		.tx = 0xffff,
buf : 		.rx = BIT(IEEE80211_STYPE_ACTION >> 4) |
buf : 			BIT(IEEE80211_STYPE_AUTH >> 4) |
buf : 			BIT(IEEE80211_STYPE_DEAUTH >> 4) |
buf : 			BIT(IEEE80211_STYPE_PROBE_REQ >> 4),
buf : 	},
buf : 	[NL80211_IFTYPE_STATION] = {
buf : 		.tx = 0xffff,
buf : 		.rx = BIT(IEEE80211_STYPE_ACTION >> 4) |
buf : 			BIT(IEEE80211_STYPE_PROBE_REQ >> 4),
buf : 	},
buf : 	[NL80211_IFTYPE_AP] = {
buf : 		.tx = 0xffff,
buf : 		.rx = BIT(IEEE80211_STYPE_ASSOC_REQ >> 4) |
buf : 			BIT(IEEE80211_STYPE_REASSOC_REQ >> 4) |
buf : 			BIT(IEEE80211_STYPE_PROBE_REQ >> 4) |
buf : 			BIT(IEEE80211_STYPE_DISASSOC >> 4) |
buf : 			BIT(IEEE80211_STYPE_AUTH >> 4) |
buf : 			BIT(IEEE80211_STYPE_DEAUTH >> 4) |
buf : 			BIT(IEEE80211_STYPE_ACTION >> 4),
buf : 	},
buf : 	[NL80211_IFTYPE_AP_VLAN] = {
buf : 		/* copy AP */
buf : 		.tx = 0xffff,
buf : 		.rx = BIT(IEEE80211_STYPE_ASSOC_REQ >> 4) |
buf : 			BIT(IEEE80211_STYPE_REASSOC_REQ >> 4) |
buf : 			BIT(IEEE80211_STYPE_PROBE_REQ >> 4) |
buf : 			BIT(IEEE80211_STYPE_DISASSOC >> 4) |
buf : 			BIT(IEEE80211_STYPE_AUTH >> 4) |
buf : 			BIT(IEEE80211_STYPE_DEAUTH >> 4) |
buf : 			BIT(IEEE80211_STYPE_ACTION >> 4),
buf : 	},
buf : 	[NL80211_IFTYPE_P2P_CLIENT] = {
buf : 		.tx = 0xffff,
buf : 		.rx = BIT(IEEE80211_STYPE_ACTION >> 4) |
buf : 			BIT(IEEE80211_STYPE_PROBE_REQ >> 4),
buf : 	},
buf : 	[NL80211_IFTYPE_P2P_GO] = {
buf : 		.tx = 0xffff,
buf : 		.rx = BIT(IEEE80211_STYPE_ASSOC_REQ >> 4) |
buf : 			BIT(IEEE80211_STYPE_REASSOC_REQ >> 4) |
buf : 			BIT(IEEE80211_STYPE_PROBE_REQ >> 4) |
buf : 			BIT(IEEE80211_STYPE_DISASSOC >> 4) |
buf : 			BIT(IEEE80211_STYPE_AUTH >> 4) |
buf : 			BIT(IEEE80211_STYPE_DEAUTH >> 4) |
buf : 			BIT(IEEE80211_STYPE_ACTION >> 4),
buf : 	},
buf : 	[NL80211_IFTYPE_MESH_POINT] = {
buf : 		.tx = 0xffff,
buf : 		.rx = BIT(IEEE80211_STYPE_ACTION >> 4) |
buf : 			BIT(IEEE80211_STYPE_AUTH >> 4) |
buf : 			BIT(IEEE80211_STYPE_DEAUTH >> 4),
buf : 	},
buf : 	[NL80211_IFTYPE_P2P_DEVICE] = {
buf : 		.tx = 0xffff,
buf : 		.rx = BIT(IEEE80211_STYPE_ACTION >> 4) |
buf : 			BIT(IEEE80211_STYPE_PROBE_REQ >> 4),
buf : 	},
buf : };
buf : 
buf : static const struct ieee80211_ht_cap mac80211_ht_capa_mod_mask = {
buf : 	.ampdu_params_info = IEEE80211_HT_AMPDU_PARM_FACTOR |
buf : 			     IEEE80211_HT_AMPDU_PARM_DENSITY,
buf : 
buf : 	.cap_info = cpu_to_le16(IEEE80211_HT_CAP_SUP_WIDTH_20_40 |
buf : 				IEEE80211_HT_CAP_MAX_AMSDU |
buf : 				IEEE80211_HT_CAP_SGI_20 |
buf : 				IEEE80211_HT_CAP_SGI_40 |
buf : 				IEEE80211_HT_CAP_LDPC_CODING |
buf : 				IEEE80211_HT_CAP_40MHZ_INTOLERANT),
buf : 	.mcs = {
buf : 		.rx_mask = { 0xff, 0xff, 0xff, 0xff, 0xff,
buf : 			     0xff, 0xff, 0xff, 0xff, 0xff, },
buf : 	},
buf : };
buf : 
buf : static const struct ieee80211_vht_cap mac80211_vht_capa_mod_mask = {
buf : 	.vht_cap_info =
buf : 		cpu_to_le32(IEEE80211_VHT_CAP_RXLDPC |
buf : 			    IEEE80211_VHT_CAP_SHORT_GI_80 |
buf : 			    IEEE80211_VHT_CAP_SHORT_GI_160 |
buf : 			    IEEE80211_VHT_CAP_RXSTBC_1 |
buf : 			    IEEE80211_VHT_CAP_RXSTBC_2 |
buf : 			    IEEE80211_VHT_CAP_RXSTBC_3 |
buf : 			    IEEE80211_VHT_CAP_RXSTBC_4 |
buf : 			    IEEE80211_VHT_CAP_TXSTBC |
buf : 			    IEEE80211_VHT_CAP_SU_BEAMFORMER_CAPABLE |
buf : 			    IEEE80211_VHT_CAP_SU_BEAMFORMEE_CAPABLE |
buf : 			    IEEE80211_VHT_CAP_TX_ANTENNA_PATTERN |
buf : 			    IEEE80211_VHT_CAP_RX_ANTENNA_PATTERN |
buf : 			    IEEE80211_VHT_CAP_MAX_A_MPDU_LENGTH_EXPONENT_MASK),
buf : 	.supp_mcs = {
buf : 		.rx_mcs_map = cpu_to_le16(~0),
buf : 		.tx_mcs_map = cpu_to_le16(~0),
buf : 	},
buf : };
buf : 
buf : static const u8 extended_capabilities[] = {
buf : 	0, 0, 0, 0, 0, 0, 0,
buf : 	WLAN_EXT_CAPA8_OPMODE_NOTIF,
buf : };
buf : 
buf : struct ieee80211_hw *ieee80211_alloc_hw(size_t priv_data_len,
buf : 					const struct ieee80211_ops *ops)
buf : {
buf : 	struct ieee80211_local *local;
buf : 	int priv_size, i;
buf : 	struct wiphy *wiphy;
buf : 	bool use_chanctx;
buf : 
buf : 	if (WARN_ON(!ops->tx || !ops->start || !ops->stop || !ops->config ||
if (WARN_ON(!ops->tx || !ops->start || !ops->stop || !ops->config || 
buf : 		    !ops->add_interface || !ops->remove_interface ||
buf : 		    !ops->configure_filter))
buf : 		return NULL;
buf : 
buf : 	if (WARN_ON(ops->sta_state && (ops->sta_add || ops->sta_remove)))
if (WARN_ON(ops->sta_state && (ops->sta_add || ops->sta_remove))) 
buf : 		return NULL;
buf : 
buf : 	/* check all or no channel context operations exist */
buf : 	i = !!ops->add_chanctx + !!ops->remove_chanctx +
buf : 	    !!ops->change_chanctx + !!ops->assign_vif_chanctx +
if_chanctx + 
buf : 	    !!ops->unassign_vif_chanctx;
buf : 	if (WARN_ON(i != 0 && i != 5))
if (WARN_ON(i != 0 && i != 5)) 
buf : 		return NULL;
buf : 	use_chanctx = i == 5;
buf : 
buf : 	/* Ensure 32-byte alignment of our private data and hw private data.
buf : 	 * We use the wiphy priv data for both our ieee80211_local and for
for both our ieee80211_local and for 
buf : 	 * the driver's private data
buf : 	 *
buf : 	 * In memory it'll be like this:
buf : 	 *
buf : 	 * +-------------------------+
buf : 	 * | struct wiphy	    |
buf : 	 * +-------------------------+
buf : 	 * | struct ieee80211_local  |
buf : 	 * +-------------------------+
buf : 	 * | driver's private data   |
buf : 	 * +-------------------------+
buf : 	 *
buf : 	 */
buf : 	priv_size = ALIGN(sizeof(*local), NETDEV_ALIGN) + priv_data_len;
buf : 
buf : 	wiphy = wiphy_new(&mac80211_config_ops, priv_size);
buf : 
buf : 	if (!wiphy)
if (!wiphy) 
buf : 		return NULL;
buf : 
buf : 	wiphy->mgmt_stypes = ieee80211_default_mgmt_stypes;
buf : 
buf : 	wiphy->privid = mac80211_wiphy_privid;
buf : 
buf : 	wiphy->flags |= WIPHY_FLAG_NETNS_OK |
buf : 			WIPHY_FLAG_4ADDR_AP |
buf : 			WIPHY_FLAG_4ADDR_STATION |
buf : 			WIPHY_FLAG_REPORTS_OBSS |
buf : 			WIPHY_FLAG_OFFCHAN_TX;
buf : 
buf : 	wiphy->extended_capabilities = extended_capabilities;
buf : 	wiphy->extended_capabilities_mask = extended_capabilities;
buf : 	wiphy->extended_capabilities_len = ARRAY_SIZE(extended_capabilities);
buf : 
buf : 	if (ops->remain_on_channel)
if (ops->remain_on_channel) 
buf : 		wiphy->flags |= WIPHY_FLAG_HAS_REMAIN_ON_CHANNEL;
buf : 
buf : 	wiphy->features |= NL80211_FEATURE_SK_TX_STATUS |
buf : 			   NL80211_FEATURE_SAE |
buf : 			   NL80211_FEATURE_HT_IBSS |
buf : 			   NL80211_FEATURE_VIF_TXPOWER |
buf : 			   NL80211_FEATURE_USERSPACE_MPM;
buf : 
buf : 	if (!ops->hw_scan)
if (!ops->hw_scan) 
buf : 		wiphy->features |= NL80211_FEATURE_LOW_PRIORITY_SCAN |
buf : 				   NL80211_FEATURE_AP_SCAN;
buf : 
buf : 
buf : 	if (!ops->set_key)
if (!ops->set_key) 
buf : 		wiphy->flags |= WIPHY_FLAG_IBSS_RSN;
buf : 
buf : 	wiphy->bss_priv_size = sizeof(struct ieee80211_bss);
buf : 
buf : 	local = wiphy_priv(wiphy);
buf : 
buf : 	local->hw.wiphy = wiphy;
buf : 
buf : 	local->hw.priv = (char *)local + ALIGN(sizeof(*local), NETDEV_ALIGN);
buf : 
buf : 	local->ops = ops;
buf : 	local->use_chanctx = use_chanctx;
buf : 
buf : 	/* set up some defaults */
buf : 	local->hw.queues = 1;
buf : 	local->hw.max_rates = 1;
buf : 	local->hw.max_report_rates = 0;
buf : 	local->hw.max_rx_aggregation_subframes = IEEE80211_MAX_AMPDU_BUF;
buf : 	local->hw.max_tx_aggregation_subframes = IEEE80211_MAX_AMPDU_BUF;
buf : 	local->hw.offchannel_tx_hw_queue = IEEE80211_INVAL_HW_QUEUE;
buf : 	local->hw.conf.long_frame_max_tx_count = wiphy->retry_long;
buf : 	local->hw.conf.short_frame_max_tx_count = wiphy->retry_short;
buf : 	local->hw.radiotap_mcs_details = IEEE80211_RADIOTAP_MCS_HAVE_MCS |
buf : 					 IEEE80211_RADIOTAP_MCS_HAVE_GI |
buf : 					 IEEE80211_RADIOTAP_MCS_HAVE_BW;
buf : 	local->hw.radiotap_vht_details = IEEE80211_RADIOTAP_VHT_KNOWN_GI |
buf : 					 IEEE80211_RADIOTAP_VHT_KNOWN_BANDWIDTH;
buf : 	local->hw.uapsd_queues = IEEE80211_DEFAULT_UAPSD_QUEUES;
buf : 	local->hw.uapsd_max_sp_len = IEEE80211_DEFAULT_MAX_SP_LEN;
buf : 	local->user_power_level = IEEE80211_UNSET_POWER_LEVEL;
buf : 	wiphy->ht_capa_mod_mask = &mac80211_ht_capa_mod_mask;
buf : 	wiphy->vht_capa_mod_mask = &mac80211_vht_capa_mod_mask;
buf : 
buf : 	INIT_LIST_HEAD(&local->interfaces);
buf : 
buf : 	__hw_addr_init(&local->mc_list);
buf : 
buf : 	mutex_init(&local->iflist_mtx);
iflist_mtx); 
buf : 	mutex_init(&local->mtx);
buf : 
buf : 	mutex_init(&local->key_mtx);
buf : 	spin_lock_init(&local->filter_lock);
buf : 	spin_lock_init(&local->rx_path_lock);
buf : 	spin_lock_init(&local->queue_stop_reason_lock);
buf : 
buf : 	INIT_LIST_HEAD(&local->chanctx_list);
buf : 	mutex_init(&local->chanctx_mtx);
buf : 
buf : 	INIT_DELAYED_WORK(&local->scan_work, ieee80211_scan_work);
buf : 
buf : 	INIT_WORK(&local->restart_work, ieee80211_restart_work);
buf : 
buf : 	INIT_WORK(&local->radar_detected_work,
buf : 		  ieee80211_dfs_radar_detected_work);
buf : 
buf : 	INIT_WORK(&local->reconfig_filter, ieee80211_reconfig_filter);
buf : 	local->smps_mode = IEEE80211_SMPS_OFF;
buf : 
buf : 	INIT_WORK(&local->dynamic_ps_enable_work,
buf : 		  ieee80211_dynamic_ps_enable_work);
buf : 	INIT_WORK(&local->dynamic_ps_disable_work,
buf : 		  ieee80211_dynamic_ps_disable_work);
buf : 	setup_timer(&local->dynamic_ps_timer,
buf : 		    ieee80211_dynamic_ps_timer, (unsigned long) local);
buf : 
buf : 	INIT_WORK(&local->sched_scan_stopped_work,
buf : 		  ieee80211_sched_scan_stopped_work);
buf : 
buf : 	spin_lock_init(&local->ack_status_lock);
buf : 	idr_init(&local->ack_status_frames);
buf : 
buf : 	sta_info_init(local);
buf : 
buf : 	for (i = 0; i < IEEE80211_MAX_QUEUES; i++) {
for (i = 0; i < IEEE80211_MAX_QUEUES; i++) { 
buf : 		skb_queue_head_init(&local->pending[i]);
buf : 		atomic_set(&local->agg_queue_stop[i], 0);
buf : 	}
buf : 	tasklet_init(&local->tx_pending_tasklet, ieee80211_tx_pending,
buf : 		     (unsigned long)local);
buf : 
buf : 	tasklet_init(&local->tasklet,
buf : 		     ieee80211_tasklet_handler,
buf : 		     (unsigned long) local);
buf : 
buf : 	skb_queue_head_init(&local->skb_queue);
buf : 	skb_queue_head_init(&local->skb_queue_unreliable);
buf : 
buf : 	ieee80211_led_names(local);
buf : 
buf : 	ieee80211_roc_setup(local);
buf : 
buf : 	return &local->hw;
buf : }
buf : EXPORT_SYMBOL(ieee80211_alloc_hw);
buf : 
buf : static int ieee80211_init_cipher_suites(struct ieee80211_local *local)
buf : {
buf : 	bool have_wep = !(IS_ERR(local->wep_tx_tfm) ||
buf : 			  IS_ERR(local->wep_rx_tfm));
buf : 	bool have_mfp = local->hw.flags & IEEE80211_HW_MFP_CAPABLE;
buf : 	const struct ieee80211_cipher_scheme *cs = local->hw.cipher_schemes;
buf : 	int n_suites = 0, r = 0, w = 0;
buf : 	u32 *suites;
buf : 	static const u32 cipher_suites[] = {
buf : 		/* keep WEP first, it may be removed below */
buf : 		WLAN_CIPHER_SUITE_WEP40,
buf : 		WLAN_CIPHER_SUITE_WEP104,
buf : 		WLAN_CIPHER_SUITE_TKIP,
buf : 		WLAN_CIPHER_SUITE_CCMP,
buf : 
buf : 		/* keep last -- depends on hw flags! */
buf : 		WLAN_CIPHER_SUITE_AES_CMAC
buf : 	};
buf : 
buf : 	/* Driver specifies the ciphers, we have nothing to do... */
ifies the ciphers, we have nothing to do... */ 
buf : 	if (local->hw.wiphy->cipher_suites && have_wep)
buf : 		return 0;
buf : 
buf : 	/* Set up cipher suites if driver relies on mac80211 cipher defs */
if driver relies on mac80211 cipher defs */ 
buf : 	if (!local->hw.wiphy->cipher_suites && !cs) {
buf : 		local->hw.wiphy->cipher_suites = cipher_suites;
buf : 		local->hw.wiphy->n_cipher_suites = ARRAY_SIZE(cipher_suites);
buf : 
buf : 		if (!have_mfp)
if (!have_mfp) 
buf : 			local->hw.wiphy->n_cipher_suites--;
buf : 
buf : 		if (!have_wep) {
if (!have_wep) { 
buf : 			local->hw.wiphy->cipher_suites += 2;
buf : 			local->hw.wiphy->n_cipher_suites -= 2;
buf : 		}
buf : 
buf : 		return 0;
buf : 	}
buf : 
buf : 	if (!local->hw.wiphy->cipher_suites) {
if (!local->hw.wiphy->cipher_suites) { 
buf : 		/*
buf : 		 * Driver specifies cipher schemes only
ifies cipher schemes only 
buf : 		 * We start counting ciphers defined by schemes, TKIP and CCMP
buf : 		 */
buf : 		n_suites = local->hw.n_cipher_schemes + 2;
buf : 
buf : 		/* check if we have WEP40 and WEP104 */
if we have WEP40 and WEP104 */ 
buf : 		if (have_wep)
buf : 			n_suites += 2;
buf : 
buf : 		/* check if we have AES_CMAC */
if we have AES_CMAC */ 
buf : 		if (have_mfp)
buf : 			n_suites++;
buf : 
buf : 		suites = kmalloc(sizeof(u32) * n_suites, GFP_KERNEL);
buf : 		if (!suites)
if (!suites) 
buf : 			return -ENOMEM;
buf : 
buf : 		suites[w++] = WLAN_CIPHER_SUITE_CCMP;
buf : 		suites[w++] = WLAN_CIPHER_SUITE_TKIP;
buf : 
buf : 		if (have_wep) {
if (have_wep) { 
buf : 			suites[w++] = WLAN_CIPHER_SUITE_WEP40;
buf : 			suites[w++] = WLAN_CIPHER_SUITE_WEP104;
buf : 		}
buf : 
buf : 		if (have_mfp)
if (have_mfp) 
buf : 			suites[w++] = WLAN_CIPHER_SUITE_AES_CMAC;
buf : 
buf : 		for (r = 0; r < local->hw.n_cipher_schemes; r++)
for (r = 0; r < local->hw.n_cipher_schemes; r++) 
buf : 			suites[w++] = cs[r].cipher;
buf : 	} else {
buf : 		/* Driver provides cipher suites, but we need to exclude WEP */
buf : 		suites = kmemdup(local->hw.wiphy->cipher_suites,
buf : 				 sizeof(u32) * local->hw.wiphy->n_cipher_suites,
buf : 				 GFP_KERNEL);
buf : 		if (!suites)
if (!suites) 
buf : 			return -ENOMEM;
buf : 
buf : 		for (r = 0; r < local->hw.wiphy->n_cipher_suites; r++) {
for (r = 0; r < local->hw.wiphy->n_cipher_suites; r++) { 
buf : 			u32 suite = local->hw.wiphy->cipher_suites[r];
buf : 
buf : 			if (suite == WLAN_CIPHER_SUITE_WEP40 ||
if (suite == WLAN_CIPHER_SUITE_WEP40 || 
buf : 			    suite == WLAN_CIPHER_SUITE_WEP104)
buf : 				continue;
buf : 			suites[w++] = suite;
buf : 		}
buf : 	}
buf : 
buf : 	local->hw.wiphy->cipher_suites = suites;
buf : 	local->hw.wiphy->n_cipher_suites = w;
buf : 	local->wiphy_ciphers_allocated = true;
buf : 
buf : 	return 0;
buf : }
buf : 
buf : int ieee80211_register_hw(struct ieee80211_hw *hw)
buf : {
buf : 	struct ieee80211_local *local = hw_to_local(hw);
buf : 	int result, i;
buf : 	enum ieee80211_band band;
buf : 	int channels, max_bitrates;
buf : 	bool supp_ht, supp_vht;
buf : 	netdev_features_t feature_whitelist;
buf : 	struct cfg80211_chan_def dflt_chandef = {};
buf : 
buf : 	if (hw->flags & IEEE80211_HW_QUEUE_CONTROL &&
if (hw->flags & IEEE80211_HW_QUEUE_CONTROL && 
buf : 	    (local->hw.offchannel_tx_hw_queue == IEEE80211_INVAL_HW_QUEUE ||
buf : 	     local->hw.offchannel_tx_hw_queue >= local->hw.queues))
buf : 		return -EINVAL;
buf : 
buf : #ifdef CONFIG_PM
ifdef CONFIG_PM 
buf : 	if (hw->wiphy->wowlan && (!local->ops->suspend || !local->ops->resume))
buf : 		return -EINVAL;
buf : #endif
if 
buf : 
buf : 	if (!local->use_chanctx) {
buf : 		for (i = 0; i < local->hw.wiphy->n_iface_combinations; i++) {
iface_combinations; i++) { 
buf : 			const struct ieee80211_iface_combination *comb;
buf : 
buf : 			comb = &local->hw.wiphy->iface_combinations[i];
iface_combinations[i]; 
buf : 
buf : 			if (comb->num_different_channels > 1)
buf : 				return -EINVAL;
buf : 		}
buf : 	} else {
buf : 		/*
buf : 		 * WDS is currently prohibited when channel contexts are used
buf : 		 * because there's no clear definition of which channel WDS
buf : 		 * type interfaces use
buf : 		 */
buf : 		if (local->hw.wiphy->interface_modes & BIT(NL80211_IFTYPE_WDS))
if (local->hw.wiphy->interface_modes & BIT(NL80211_IFTYPE_WDS)) 
buf : 			return -EINVAL;
buf : 
buf : 		/* DFS currently not supported with channel context drivers */
buf : 		for (i = 0; i < local->hw.wiphy->n_iface_combinations; i++) {
iface_combinations; i++) { 
buf : 			const struct ieee80211_iface_combination *comb;
buf : 
buf : 			comb = &local->hw.wiphy->iface_combinations[i];
iface_combinations[i]; 
buf : 
buf : 			if (comb->radar_detect_widths)
buf : 				return -EINVAL;
buf : 		}
buf : 	}
buf : 
buf : 	/* Only HW csum features are currently compatible with mac80211 */
buf : 	feature_whitelist = NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |
buf : 			    NETIF_F_HW_CSUM;
buf : 	if (WARN_ON(hw->netdev_features & ~feature_whitelist))
if (WARN_ON(hw->netdev_features & ~feature_whitelist)) 
buf : 		return -EINVAL;
buf : 
buf : 	if (hw->max_report_rates == 0)
if (hw->max_report_rates == 0) 
buf : 		hw->max_report_rates = hw->max_rates;
buf : 
buf : 	local->rx_chains = 1;
buf : 
buf : 	/*
buf : 	 * generic code guarantees at least one band,
buf : 	 * set this very early because much code assumes
buf : 	 * that hw.conf.channel is assigned
buf : 	 */
buf : 	channels = 0;
buf : 	max_bitrates = 0;
buf : 	supp_ht = false;
buf : 	supp_vht = false;
buf : 	for (band = 0; band < IEEE80211_NUM_BANDS; band++) {
for (band = 0; band < IEEE80211_NUM_BANDS; band++) { 
buf : 		struct ieee80211_supported_band *sband;
buf : 
buf : 		sband = local->hw.wiphy->bands[band];
buf : 		if (!sband)
if (!sband) 
buf : 			continue;
buf : 
buf : 		if (!dflt_chandef.chan) {
if (!dflt_chandef.chan) { 
buf : 			cfg80211_chandef_create(&dflt_chandef,
buf : 						&sband->channels[0],
buf : 						NL80211_CHAN_NO_HT);
buf : 			/* init channel we're on */
buf : 			if (!local->use_chanctx && !local->_oper_chandef.chan) {
if (!local->use_chanctx && !local->_oper_chandef.chan) { 
buf : 				local->hw.conf.chandef = dflt_chandef;
buf : 				local->_oper_chandef = dflt_chandef;
buf : 			}
buf : 			local->monitor_chandef = dflt_chandef;
buf : 		}
buf : 
buf : 		channels += sband->n_channels;
buf : 
buf : 		if (max_bitrates < sband->n_bitrates)
if (max_bitrates < sband->n_bitrates) 
buf : 			max_bitrates = sband->n_bitrates;
buf : 		supp_ht = supp_ht || sband->ht_cap.ht_supported;
buf : 		supp_vht = supp_vht || sband->vht_cap.vht_supported;
buf : 
buf : 		if (sband->ht_cap.ht_supported)
if (sband->ht_cap.ht_supported) 
buf : 			local->rx_chains =
buf : 				max(ieee80211_mcs_to_chains(&sband->ht_cap.mcs),
buf : 				    local->rx_chains);
buf : 
buf : 		/* TODO: consider VHT for RX chains, hopefully it's the same */
for RX chains, hopefully it's the same */ 
buf : 	}
buf : 
buf : 	/* if low-level driver supports AP, we also support VLAN */
buf : 	if (local->hw.wiphy->interface_modes & BIT(NL80211_IFTYPE_AP)) {
if (local->hw.wiphy->interface_modes & BIT(NL80211_IFTYPE_AP)) { 
buf : 		hw->wiphy->interface_modes |= BIT(NL80211_IFTYPE_AP_VLAN);
buf : 		hw->wiphy->software_iftypes |= BIT(NL80211_IFTYPE_AP_VLAN);
iftypes |= BIT(NL80211_IFTYPE_AP_VLAN); 
buf : 	}
buf : 
buf : 	/* mac80211 always supports monitor */
buf : 	hw->wiphy->interface_modes |= BIT(NL80211_IFTYPE_MONITOR);
buf : 	hw->wiphy->software_iftypes |= BIT(NL80211_IFTYPE_MONITOR);
iftypes |= BIT(NL80211_IFTYPE_MONITOR); 
buf : 
buf : 	/* mac80211 doesn't support more than one IBSS interface right now */
buf : 	for (i = 0; i < hw->wiphy->n_iface_combinations; i++) {
iface_combinations; i++) { 
buf : 		const struct ieee80211_iface_combination *c;
buf : 		int j;
buf : 
buf : 		c = &hw->wiphy->iface_combinations[i];
iface_combinations[i]; 
buf : 
buf : 		for (j = 0; j < c->n_limits; j++)
for (j = 0; j < c->n_limits; j++) 
buf : 			if ((c->limits[j].types & BIT(NL80211_IFTYPE_ADHOC)) &&
buf : 			    c->limits[j].max > 1)
buf : 				return -EINVAL;
buf : 	}
buf : 
buf : 	local->int_scan_req = kzalloc(sizeof(*local->int_scan_req) +
buf : 				      sizeof(void *) * channels, GFP_KERNEL);
buf : 	if (!local->int_scan_req)
if (!local->int_scan_req) 
buf : 		return -ENOMEM;
buf : 
buf : 	for (band = 0; band < IEEE80211_NUM_BANDS; band++) {
for (band = 0; band < IEEE80211_NUM_BANDS; band++) { 
buf : 		if (!local->hw.wiphy->bands[band])
buf : 			continue;
buf : 		local->int_scan_req->rates[band] = (u32) -1;
buf : 	}
buf : 
buf : #ifndef CONFIG_MAC80211_MESH
ifndef CONFIG_MAC80211_MESH 
buf : 	/* mesh depends on Kconfig, but drivers should set it if they want */
buf : 	local->hw.wiphy->interface_modes &= ~BIT(NL80211_IFTYPE_MESH_POINT);
buf : #endif
if 
buf : 
buf : 	/* if the underlying driver supports mesh, mac80211 will (at least)
buf : 	 * provide routing of mesh authentication frames to userspace */
buf : 	if (local->hw.wiphy->interface_modes & BIT(NL80211_IFTYPE_MESH_POINT))
if (local->hw.wiphy->interface_modes & BIT(NL80211_IFTYPE_MESH_POINT)) 
buf : 		local->hw.wiphy->flags |= WIPHY_FLAG_MESH_AUTH;
buf : 
buf : 	/* mac80211 supports control port protocol changing */
buf : 	local->hw.wiphy->flags |= WIPHY_FLAG_CONTROL_PORT_PROTOCOL;
buf : 
buf : 	if (local->hw.flags & IEEE80211_HW_SIGNAL_DBM) {
if (local->hw.flags & IEEE80211_HW_SIGNAL_DBM) { 
buf : 		local->hw.wiphy->signal_type = CFG80211_SIGNAL_TYPE_MBM;
buf : 	} else if (local->hw.flags & IEEE80211_HW_SIGNAL_UNSPEC) {
if (local->hw.flags & IEEE80211_HW_SIGNAL_UNSPEC) { 
buf : 		local->hw.wiphy->signal_type = CFG80211_SIGNAL_TYPE_UNSPEC;
buf : 		if (hw->max_signal <= 0) {
if (hw->max_signal <= 0) { 
buf : 			result = -EINVAL;
buf : 			goto fail_wiphy_register;
buf : 		}
buf : 	}
buf : 
buf : 	WARN((local->hw.flags & IEEE80211_HW_SUPPORTS_UAPSD)
buf : 	     && (local->hw.flags & IEEE80211_HW_PS_NULLFUNC_STACK),
buf : 	     "U-APSD not supported with HW_PS_NULLFUNC_STACK\n");
buf : 
buf : 	/*
buf : 	 * Calculate scan IE length -- we need this to alloc
buf : 	 * memory and to subtract from the driver limit. It
buf : 	 * includes the DS Params, (extended) supported rates, and HT
buf : 	 * information -- SSID is the driver's responsibility.
formation -- SSID is the driver's responsibility. 
buf : 	 */
buf : 	local->scan_ies_len = 4 + max_bitrates /* (ext) supp rates */ +
buf : 		3 /* DS Params */;
buf : 	if (supp_ht)
if (supp_ht) 
buf : 		local->scan_ies_len += 2 + sizeof(struct ieee80211_ht_cap);
buf : 
buf : 	if (supp_vht)
if (supp_vht) 
buf : 		local->scan_ies_len +=
buf : 			2 + sizeof(struct ieee80211_vht_cap);
buf : 
buf : 	if (!local->ops->hw_scan) {
if (!local->ops->hw_scan) { 
buf : 		/* For hw_scan, driver needs to set these up. */
buf : 		local->hw.wiphy->max_scan_ssids = 4;
buf : 		local->hw.wiphy->max_scan_ie_len = IEEE80211_MAX_DATA_LEN;
buf : 	}
buf : 
buf : 	/*
buf : 	 * If the driver supports any scan IEs, then assume the
buf : 	 * limit includes the IEs mac80211 will add, otherwise
buf : 	 * leave it at zero and let the driver sort it out; we
buf : 	 * still pass our IEs to the driver but userspace will
buf : 	 * not be allowed to in that case.
buf : 	 */
buf : 	if (local->hw.wiphy->max_scan_ie_len)
if (local->hw.wiphy->max_scan_ie_len) 
buf : 		local->hw.wiphy->max_scan_ie_len -= local->scan_ies_len;
buf : 
buf : 	WARN_ON(!ieee80211_cs_list_valid(local->hw.cipher_schemes,
buf : 					 local->hw.n_cipher_schemes));
buf : 
buf : 	result = ieee80211_init_cipher_suites(local);
buf : 	if (result < 0)
if (result < 0) 
buf : 		goto fail_wiphy_register;
buf : 
buf : 	if (!local->ops->remain_on_channel)
if (!local->ops->remain_on_channel) 
buf : 		local->hw.wiphy->max_remain_on_channel_duration = 5000;
buf : 
buf : 	/* mac80211 based drivers don't support internal TDLS setup */
buf : 	if (local->hw.wiphy->flags & WIPHY_FLAG_SUPPORTS_TDLS)
if (local->hw.wiphy->flags & WIPHY_FLAG_SUPPORTS_TDLS) 
buf : 		local->hw.wiphy->flags |= WIPHY_FLAG_TDLS_EXTERNAL_SETUP;
buf : 
buf : 	local->hw.wiphy->max_num_csa_counters = IEEE80211_MAX_CSA_COUNTERS_NUM;
buf : 
buf : 	result = wiphy_register(local->hw.wiphy);
buf : 	if (result < 0)
if (result < 0) 
buf : 		goto fail_wiphy_register;
buf : 
buf : 	/*
buf : 	 * We use the number of queues for feature tests (QoS, HT) internally
for feature tests (QoS, HT) internally 
buf : 	 * so restrict them appropriately.
buf : 	 */
buf : 	if (hw->queues > IEEE80211_MAX_QUEUES)
if (hw->queues > IEEE80211_MAX_QUEUES) 
buf : 		hw->queues = IEEE80211_MAX_QUEUES;
buf : 
buf : 	local->workqueue =
buf : 		alloc_ordered_workqueue("%s", 0, wiphy_name(local->hw.wiphy));
buf : 	if (!local->workqueue) {
if (!local->workqueue) { 
buf : 		result = -ENOMEM;
buf : 		goto fail_workqueue;
buf : 	}
buf : 
buf : 	/*
buf : 	 * The hardware needs headroom for sending the frame,
for sending the frame, 
buf : 	 * and we need some headroom for passing the frame to monitor
buf : 	 * interfaces, but never both at the same time.
buf : 	 */
buf : 	local->tx_headroom = max_t(unsigned int , local->hw.extra_tx_headroom,
buf : 				   IEEE80211_TX_STATUS_HEADROOM);
buf : 
buf : 	debugfs_hw_add(local);
buf : 
buf : 	/*
buf : 	 * if the driver doesn't specify a max listen interval we
if the driver doesn't specify a max listen interval we 
buf : 	 * use 5 which should be a safe default
buf : 	 */
buf : 	if (local->hw.max_listen_interval == 0)
if (local->hw.max_listen_interval == 0) 
buf : 		local->hw.max_listen_interval = 5;
buf : 
buf : 	local->hw.conf.listen_interval = local->hw.max_listen_interval;
buf : 
buf : 	local->dynamic_ps_forced_timeout = -1;
forced_timeout = -1; 
buf : 
buf : 	result = ieee80211_wep_init(local);
buf : 	if (result < 0)
if (result < 0) 
buf : 		wiphy_debug(local->hw.wiphy, "Failed to initialize wep: %d\n",
buf : 			    result);
buf : 
buf : 	local->hw.conf.flags = IEEE80211_CONF_IDLE;
buf : 
buf : 	ieee80211_led_init(local);
buf : 
buf : 	rtnl_lock();
buf : 
buf : 	result = ieee80211_init_rate_ctrl_alg(local,
buf : 					      hw->rate_control_algorithm);
buf : 	if (result < 0) {
if (result < 0) { 
buf : 		wiphy_debug(local->hw.wiphy,
buf : 			    "Failed to initialize rate control algorithm\n");
buf : 		goto fail_rate;
buf : 	}
buf : 
buf : 	/* add one default STA interface if supported */
if supported */ 
buf : 	if (local->hw.wiphy->interface_modes & BIT(NL80211_IFTYPE_STATION)) {
buf : 		result = ieee80211_if_add(local, "wlan%d", NULL,
if_add(local, "wlan%d", NULL, 
buf : 					  NL80211_IFTYPE_STATION, NULL);
buf : 		if (result)
if (result) 
buf : 			wiphy_warn(local->hw.wiphy,
buf : 				   "Failed to add default virtual iface\n");
iface\n"); 
buf : 	}
buf : 
buf : 	rtnl_unlock();
buf : 
buf : 	local->network_latency_notifier.notifier_call =
ifier.notifier_call = 
buf : 		ieee80211_max_network_latency;
buf : 	result = pm_qos_add_notifier(PM_QOS_NETWORK_LATENCY,
ifier(PM_QOS_NETWORK_LATENCY, 
buf : 				     &local->network_latency_notifier);
buf : 	if (result) {
if (result) { 
buf : 		rtnl_lock();
buf : 		goto fail_pm_qos;
buf : 	}
buf : 
buf : #ifdef CONFIG_INET
ifdef CONFIG_INET 
buf : 	local->ifa_notifier.notifier_call = ieee80211_ifa_changed;
buf : 	result = register_inetaddr_notifier(&local->ifa_notifier);
ifier(&local->ifa_notifier); 
buf : 	if (result)
buf : 		goto fail_ifa;
ifa; 
buf : #endif
buf : 
buf : #if IS_ENABLED(CONFIG_IPV6)
if IS_ENABLED(CONFIG_IPV6) 
buf : 	local->ifa6_notifier.notifier_call = ieee80211_ifa6_changed;
buf : 	result = register_inet6addr_notifier(&local->ifa6_notifier);
ifier(&local->ifa6_notifier); 
buf : 	if (result)
buf : 		goto fail_ifa6;
ifa6; 
buf : #endif
buf : 
buf : 	return 0;
buf : 
buf : #if IS_ENABLED(CONFIG_IPV6)
if IS_ENABLED(CONFIG_IPV6) 
buf :  fail_ifa6:
buf : #ifdef CONFIG_INET
ifdef CONFIG_INET 
buf : 	unregister_inetaddr_notifier(&local->ifa_notifier);
buf : #endif
if 
buf : #endif
buf : #if defined(CONFIG_INET) || defined(CONFIG_IPV6)
if defined(CONFIG_INET) || defined(CONFIG_IPV6) 
buf :  fail_ifa:
buf : 	pm_qos_remove_notifier(PM_QOS_NETWORK_LATENCY,
ifier(PM_QOS_NETWORK_LATENCY, 
buf : 			       &local->network_latency_notifier);
buf : 	rtnl_lock();
buf : #endif
if 
buf :  fail_pm_qos:
buf : 	ieee80211_led_exit(local);
buf : 	ieee80211_remove_interfaces(local);
buf :  fail_rate:
buf : 	rtnl_unlock();
buf : 	ieee80211_wep_free(local);
buf : 	sta_info_stop(local);
buf : 	destroy_workqueue(local->workqueue);
buf :  fail_workqueue:
buf : 	wiphy_unregister(local->hw.wiphy);
buf :  fail_wiphy_register:
buf : 	if (local->wiphy_ciphers_allocated)
if (local->wiphy_ciphers_allocated) 
buf : 		kfree(local->hw.wiphy->cipher_suites);
buf : 	kfree(local->int_scan_req);
buf : 	return result;
buf : }
buf : EXPORT_SYMBOL(ieee80211_register_hw);
buf : 
buf : void ieee80211_napi_add(struct ieee80211_hw *hw, struct napi_struct *napi,
buf : 			struct net_device *napi_dev,
buf : 			int (*poll)(struct napi_struct *, int),
buf : 			int weight)
buf : {
buf : 	struct ieee80211_local *local = hw_to_local(hw);
buf : 
buf : 	netif_napi_add(napi_dev, napi, poll, weight);
if_napi_add(napi_dev, napi, poll, weight); 
buf : 	local->napi = napi;
buf : }
buf : EXPORT_SYMBOL_GPL(ieee80211_napi_add);
buf : 
buf : void ieee80211_unregister_hw(struct ieee80211_hw *hw)
buf : {
buf : 	struct ieee80211_local *local = hw_to_local(hw);
buf : 
buf : 	tasklet_kill(&local->tx_pending_tasklet);
buf : 	tasklet_kill(&local->tasklet);
buf : 
buf : 	pm_qos_remove_notifier(PM_QOS_NETWORK_LATENCY,
ifier(PM_QOS_NETWORK_LATENCY, 
buf : 			       &local->network_latency_notifier);
buf : #ifdef CONFIG_INET
ifdef CONFIG_INET 
buf : 	unregister_inetaddr_notifier(&local->ifa_notifier);
buf : #endif
if 
buf : #if IS_ENABLED(CONFIG_IPV6)
buf : 	unregister_inet6addr_notifier(&local->ifa6_notifier);
ifier(&local->ifa6_notifier); 
buf : #endif
buf : 
buf : 	rtnl_lock();
buf : 
buf : 	/*
buf : 	 * At this point, interface list manipulations are fine
buf : 	 * because the driver cannot be handing us frames any
buf : 	 * more and the tasklet is killed.
buf : 	 */
buf : 	ieee80211_remove_interfaces(local);
buf : 
buf : 	rtnl_unlock();
buf : 
buf : 	cancel_work_sync(&local->restart_work);
buf : 	cancel_work_sync(&local->reconfig_filter);
buf : 	flush_work(&local->sched_scan_stopped_work);
buf : 
buf : 	ieee80211_clear_tx_pending(local);
buf : 	rate_control_deinitialize(local);
buf : 
buf : 	if (skb_queue_len(&local->skb_queue) ||
if (skb_queue_len(&local->skb_queue) || 
buf : 	    skb_queue_len(&local->skb_queue_unreliable))
buf : 		wiphy_warn(local->hw.wiphy, "skb_queue not empty\n");
buf : 	skb_queue_purge(&local->skb_queue);
buf : 	skb_queue_purge(&local->skb_queue_unreliable);
buf : 
buf : 	destroy_workqueue(local->workqueue);
buf : 	wiphy_unregister(local->hw.wiphy);
buf : 	sta_info_stop(local);
buf : 	ieee80211_wep_free(local);
buf : 	ieee80211_led_exit(local);
buf : 	kfree(local->int_scan_req);
buf : }
buf : EXPORT_SYMBOL(ieee80211_unregister_hw);
buf : 
buf : static int ieee80211_free_ack_frame(int id, void *p, void *data)
buf : {
buf : 	WARN_ONCE(1, "Have pending ack frames!\n");
buf : 	kfree_skb(p);
buf : 	return 0;
buf : }
buf : 
buf : void ieee80211_free_hw(struct ieee80211_hw *hw)
buf : {
buf : 	struct ieee80211_local *local = hw_to_local(hw);
buf : 
buf : 	mutex_destroy(&local->iflist_mtx);
iflist_mtx); 
buf : 	mutex_destroy(&local->mtx);
buf : 
buf : 	if (local->wiphy_ciphers_allocated)
if (local->wiphy_ciphers_allocated) 
buf : 		kfree(local->hw.wiphy->cipher_suites);
buf : 
buf : 	idr_for_each(&local->ack_status_frames,
for_each(&local->ack_status_frames, 
buf : 		     ieee80211_free_ack_frame, NULL);
buf : 	idr_destroy(&local->ack_status_frames);
buf : 
buf : 	kfree(rcu_access_pointer(local->tx_latency));
buf : 
buf : 	wiphy_free(local->hw.wiphy);
buf : }
buf : EXPORT_SYMBOL(ieee80211_free_hw);
buf : 
buf : static int __init ieee80211_init(void)
buf : {
buf : 	struct sk_buff *skb;
buf : 	int ret;
buf : 
buf : 	BUILD_BUG_ON(sizeof(struct ieee80211_tx_info) > sizeof(skb->cb));
buf : 	BUILD_BUG_ON(offsetof(struct ieee80211_tx_info, driver_data) +
buf : 		     IEEE80211_TX_INFO_DRIVER_DATA_SIZE > sizeof(skb->cb));
buf : 
buf : 	ret = rc80211_minstrel_init();
buf : 	if (ret)
if (ret) 
buf : 		return ret;
buf : 
buf : 	ret = rc80211_minstrel_ht_init();
buf : 	if (ret)
if (ret) 
buf : 		goto err_minstrel;
buf : 
buf : 	ret = rc80211_pid_init();
buf : 	if (ret)
if (ret) 
buf : 		goto err_pid;
buf : 
buf : 	ret = ieee80211_iface_init();
iface_init(); 
buf : 	if (ret)
buf : 		goto err_netdev;
buf : 
buf : 	return 0;
buf :  err_netdev:
buf : 	rc80211_pid_exit();
buf :  err_pid:
buf : 	rc80211_minstrel_ht_exit();
buf :  err_minstrel:
buf : 	rc80211_minstrel_exit();
buf : 
buf : 	return ret;
buf : }
buf : 
buf : static void __exit ieee80211_exit(void)
buf : {
buf : 	rc80211_pid_exit();
buf : 	rc80211_minstrel_ht_exit();
buf : 	rc80211_minstrel_exit();
buf : 
buf : 	ieee80211s_stop();
buf : 
buf : 	ieee80211_iface_exit();
iface_exit(); 
buf : 
buf : 	rcu_barrier();
buf : }
buf : 
buf : 
buf : subsys_initcall(ieee80211_init);
buf : module_exit(ieee80211_exit);
buf : 
buf : MODULE_DESCRIPTION("IEEE 802.11 subsystem");
buf : MODULE_LICENSE("GPL");
